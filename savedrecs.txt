FN Clarivate Analytics Web of Science
VR 1.0
PT C
AU Shearer, J
   Olivier, P
   De Boni, M
   Hurling, R
AF Shearer, John
   Olivier, Patrick
   De Boni, Marco
   Hurling, Robert
BE DeKort, Y
   IJsselsteijn, W
   Midden, C
   Eggen, B
   Fogg, BJ
TI Exploring persuasive potential of embodied conversational agents
   utilizing synthetic embodied conversational agents
SO PERSUASIVE TECHNOLOGY
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 2nd International Conference on Persuasive Technology (PERSUASIVE 2007)
CY APR 26-27, 2007
CL Stanfore Univ, Palo Alto, CA
HO Stanfore Univ
DE persuasion; embodied conversational agents; virtual characters
AB This study presents synthetic embodied conversational agents, and how they can be used to explore the persuasive potential of real embodied conversational agents. Utilizing a novel Wizard-of-Oz style approach and a direct measure of behavior change we explore whether 'ideal' embodied conversational agents have a similar persuasive impact as real people, and demonstrate the importance of visually perceiving for embodied conversational agents to be persuasive.
C1 [Shearer, John; Olivier, Patrick; De Boni, Marco; Hurling, Robert] Newcastle Univ, Culture Lab Newcastle, Grand Assembly Rooms, Newcastle Upon Tyne NE1 7RU, Tyne & Wear, England.
EM john.shearer@ncl.ac.uk; p.l.olivier@ncl.ac.uk;
   marco.de-boni@unilever.com; bob.hurling@unilever.com
RI Olivier, Patrick/B-2909-2011; OLIVIER, PATRICK/V-5367-2019
OI Olivier, Patrick/0000-0003-2841-7580; 
CR BAILENSON JN, 2005, PSYCHOL SCI
   BAYLOR AL, 2006, CHI
   Blascovich J., 2002, P 4 INT C COLL VIRT, P25, DOI DOI 10.1145/571878.571883
   CAMURRI A, 2004, REAL TIME MULTIMODAL
   FISCHER J, 2005, WILHELM SCHICKARD I
   Fogg B. J., 1998, CHI 98. Human Factors in Computing Systems. CHI 98 Conference Proceedings, P225
   KIMBALL S, 2006, GNU IMAGE MANIPULATI
   Reeves B., 1996, MEDIA EQUATION PEOPL
   *SCREAM BEE LLC, 2006, SCREAM BEE MORPH VOX
   WANG J, SIGGRAPH, P574
NR 10
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-540-77005-3
J9 LECT NOTES COMPUT SC
PY 2007
VL 4744
BP 210
EP 213
PG 4
WC Computer Science, Theory & Methods; Information Science & Library
   Science; Social Issues
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Information Science & Library Science; Social Issues
GA BHB41
UT WOS:000252076100026
DA 2022-08-02
ER

PT C
AU Christoph, N
AF Christoph, N
BE Ruttkay, Z
   Pelachaud, C
TI Empirical evaluation methodology for embodied conversational agents - On
   conducting evaluation studies
SO FROM BROWS TO TRUST: EVALUATING EMBODIED CONVERSATIONAL AGENTS
SE Human-Computer Interaction Series
LA English
DT Proceedings Paper
CT Workshop on Embodied Conversational Agents held at the 2002 AAMAS
   Conference
CY MAR, 2003
CL Montreal, CANADA
DE embodied conversational agents; evaluation; methodology
ID COEFFICIENT
AB The objective of this chapter is to identify the common knowledge and practice in research methodology and to apply it to the field of software evaluation, especially of embodied conversational agents. Relevant issues. discussed are: how to formulate a good research question, what research strategy to use, which data collection methods are most appropriate and how to select the right participants. Reliability and validity of the data sets are dealt with and finally the chapter concludes with a list of guidelines that one should keep in mind when setting up and conducting empirical evaluation studies on embodied conversational agents.
C1 Univ Amsterdam, Dept Social Sci, NL-1012 WX Amsterdam, Netherlands.
RP Christoph, N (corresponding author), Univ Amsterdam, Dept Social Sci, NL-1012 WX Amsterdam, Netherlands.
EM noor@swi.psy.uva.nl
CR Berg B. L., 2001, QUALITATIVE RES METH
   BOEHM BW, 1988, COMPUTER, V21, P61, DOI 10.1109/2.59
   BUISINE S, 2002, P AAMAS 2002 WORKSH
   CAMPBELL DT, 1959, PSYCHOL BULL, V56, P81, DOI 10.1037/h0046016
   CHRISTOPH LH, 1999, WERKBOEK GEDRAGSBOSE
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Coolican H., 1994, RES METHODS STAT PSY, V2nd
   COWELL AJ, 2003, P AAMAS 2003 WORKSH
   Cronbach LJ, 1951, PSYCHOMETRIKA, V16, P297
   DEFURIA GL, 1996, THESIS ST JOHNS U SP
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   DEVOCHT A, 2002, BASISHANDBOOK SPSS 1
   Draper SW., 1986, USER CTR SYSTEM DESI, DOI 10.1201/b15703
   Erdfelder E, 1996, BEHAV RES METH INS C, V28, P1, DOI 10.3758/BF03203630
   Guilford J. P., 1978, FUNDAMENTALS STAT PS
   Hix D., 1993, DEV USER INTERFACES
   HOLM R, 2002, P EUR SHORT PRES SAA
   HOOK K, 2002, P AAMAS 2002 WORKSH
   HOWEL DC, 1982, STAT METHODS PSYCHOL
   Johnson R.R, 1988, ELEMENTARY STAT
   KABEL S, 1997, USER INTERFACE EVALU
   KRAHMER E, 2003, P AAMAS 2003 WORKSH
   Mangione T., 1995, MAIL SURVEYS IMPROVI
   MORISHIMA S, 2002, P AAMAS 2002 WORKSH
   Mosteller F., 1973, STURDY STAT NONPARAM
   Moundridou M, 2002, J COMPUT ASSIST LEAR, V18, P253, DOI 10.1046/j.0266-4909.2001.00237.x
   NEALE JM, 1986, SCI BEHAV INTRO METH
   Neter J., 1990, APPL LINEAR STAT MOD, V3rd
   Nielsen J, 1994, USABILITY ENG
   Norusis M.J, 2002, SPSS 11 0 GUIDE DATA
   OATES J, 2000, FOCUS CD ROM BASED A
   Paiva A, 2002, PERS UBIQUIT COMPUT, V6, P378, DOI 10.1007/s007790200043
   Preece J., 1994, HUM-COMPUT INTERACT
   Reeves T. C., 2003, INTERACTIVE LEARNING
   REMPEL JK, 1986, PSYCHOL TODAY, V20, P28
   RUTTKAY Z, 2002, P AAMAS 2002 WORKSH
   Silverman D., 2000, DOING QUALITATIVE RE
   Spradley J.P, 1980, PARTICIPANT OBSERVAT
   *SPSS INC, 2002, SPSS VERS 11 0 WIND
   *STAT, 2003, STATDISK VERS 9 5 WI
   SWANBORN PG, 1997, BASISBOEK SOCIAL OND
   TRIOLA M, 2002, ESSENTIALS STAT
   VANDESANDE JP, 1999, GEDRAGSBOSERVATIE IN
   Verschuren P., 1999, DESIGNING RES PROJEC
   WILKINSON J, 1995, RES METHODS PSYCHOL
   XIAO J, 2002, P AAMAS 2002 WORKSH
NR 46
TC 1
Z9 1
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS
SN 1571-5035
EI 2524-4477
BN 1-4020-2729-X
J9 HUM-COMPUT INT-SPRIN
PY 2004
VL 7
BP 67
EP 99
PG 33
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BBP07
UT WOS:000226830500003
DA 2022-08-02
ER

PT C
AU Barko-Sherif, S
   Elsweiler, D
   Harvey, M
AF Barko-Sherif, Sabrina
   Elsweiler, David
   Harvey, Morgan
GP Assoc Comp Machinery
TI Conversational Agents for Recipe Recommendation
SO CHIIR'20: PROCEEDINGS OF THE 2020 CONFERENCE ON HUMAN INFORMATION
   INTERACTION AND RETRIEVAL
LA English
DT Proceedings Paper
CT 5th ACM SIGIR Conference on Human Information Interaction and Retrieval
   (CHIIR)
CY AUG 13-14, 2020
CL ELECTR NETWORK
SP ACM Special Interest Grp Informat Retrieval, ACM SIGCHI, Assoc Comp Machinery
DE conversational agents; recipe recommendation
ID INFORMATION-SEEKING
AB As technology improves, the use of conversational agents to help users solve information seeking tasks is becoming ever more prevalent. To date we know little about how people behave with such systems, particularly in diverse contexts and for different tasks, their specific needs or how best to support these. By employing a Wizard of Oz (WoZ) methodology and developing a conversational framework, in this work we study how participants (n=28) interact with such a system in an attempt to solve recipe recommendation tasks. Our results are mostly encouraging for the future development of conversational agents in this context, however, they also provide insights into the complexities of building such a system that could convincingly engage with users in productive, human-like conversations.
C1 [Barko-Sherif, Sabrina; Elsweiler, David] Univ Regensburg, Regensburg, Germany.
   [Harvey, Morgan] Northumbria Univ, Newcastle Upon Tyne, Tyne & Wear, England.
RP Barko-Sherif, S (corresponding author), Univ Regensburg, Regensburg, Germany.
EM sabrina.barko-sherif@stud.uni-regensburg.de; david@elsweiler.co.uk;
   morgan.harvey@northumbria.ac.uk
OI Elsweiler, David/0000-0002-5791-0641; Harvey, Morgan/0000-0001-5504-2089
CR [Anonymous], 2015, DMRS
   Avula Sandeep, 2018, SIGIR 2 INT WORKSH C
   Azzopardi L., 2018, 2 INT WORKSH CONV AP
   BELKIN NJ, 1987, INT J MAN MACH STUD, V27, P127, DOI 10.1016/S0020-7373(87)80047-0
   Belkin NJ, 2001, INFORM PROCESS MANAG, V37, P403, DOI 10.1016/S0306-4573(00)00055-8
   Brandtzaeg PB, 2017, LECT NOTES COMPUT SC, V10673, P377, DOI 10.1007/978-3-319-70284-1_30
   BYSTROM K, 1995, INFORM PROCESS MANAG, V31, P191, DOI 10.1016/0306-4573(94)00041-Z
   Carenini G., 2003, IUI 03. 2003 International Conference on Intelligent User Interfaces, P12
   Cunningham Sally Jo, 2013, C 2013 P FORTWORTH T, P112, DOI [10.9776/13160, DOI 10.9776/13160]
   Department of Health, 2009, CHANGE4LIFE MARK STR
   Dubiel Mateusz, 2018, 2 INT WORKSH CONV AP
   Elsweiler D, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P575, DOI 10.1145/3077136.3080826
   Fraser N. M., 1991, Computer Speech and Language, V5, P81, DOI 10.1016/0885-2308(91)90019-M
   Freyne J, 2010, IUI 2010, P321
   Frummet Alexander, 2019, P 3 WORKSH NAT LANG
   Ghosh S, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1454, DOI 10.1145/3331184.3331422
   Graus David, 2016, P 2016 C US MOD AD P, P7, DOI DOI 10.1145/2930238.2930239
   Guy I, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P35, DOI 10.1145/2911451.2911525
   Harvey M, 2013, LECT NOTES COMPUT SC, V8214, P153, DOI 10.1007/978-3-319-02432-5_19
   Jiang JP, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P506, DOI 10.1145/2736277.2741669
   Joshi A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3124420
   KUHLTHAU CC, 1991, J AM SOC INFORM SCI, V42, P361, DOI 10.1002/(SICI)1097-4571(199106)42:5<361::AID-ASI6>3.0.CO;2-#
   LANDIS JR, 1977, BIOMETRICS, V33, P363, DOI 10.2307/2529786
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Ong Sheryl, 2016, UNPACKING BREAKOUT S, V12, P2018
   Pejtersen AM, 1979, 3 INT RES FOR INF SC
   Prekop P, 2002, J DOC, V58, P533, DOI 10.1108/00220410210441000
   Radlinski F, 2017, CHIIR'17: PROCEEDINGS OF THE 2017 CONFERENCE HUMAN INFORMATION INTERACTION AND RETRIEVAL, P117, DOI 10.1145/3020165.3020183
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Shiga S, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P715, DOI 10.1145/3077136.3080787
   TAYLOR RS, 1962, AM DOC, V13, P391, DOI 10.1002/asi.5090130405
   Teevan Jaime, 2004, P SIGCHI C HUM FACT, DOI DOI 10.1145/985692.985745
   Thomas P, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P42, DOI 10.1145/3176349.3176388
   Trattner C., 2017, ARXIV171102760
   Trattner C, 2017, FRONT PUBLIC HEALTH, V5, DOI 10.3389/fpubh.2017.00016
   Trippas JR, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P32, DOI 10.1145/3176349.3176387
   Trippas JR, 2017, CHIIR'17: PROCEEDINGS OF THE 2017 CONFERENCE HUMAN INFORMATION INTERACTION AND RETRIEVAL, P325, DOI 10.1145/3020165.3022144
   Vtyurina A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173782
   White Ryen W, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P255, DOI 10.1145/1277741.1277787
   Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496
   Young S, 2013, P IEEE, V101, P1160, DOI 10.1109/JPROC.2012.2225812
   Yuan XJ, 2014, J DOC, V70, P829, DOI 10.1108/JD-06-2013-0079
   Zhang YF, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P177, DOI 10.1145/3269206.3271776
NR 43
TC 1
Z9 1
U1 1
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6892-6
PY 2020
BP 73
EP 82
DI 10.1145/3343413.3377967
PG 10
WC Computer Science, Cybernetics; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ7EB
UT WOS:000614660700010
OA Green Accepted
DA 2022-08-02
ER

PT C
AU Pinto, ND
   Franca, JBD
   Sousa, HPD
   Vivacqua, AS
   Garcia, ACB
AF Pinto, Noemi da Paixao
   dos Santos Franca, Juliana Baptista
   de Sa Sousa, Henrique Prado
   Vivacqua, Adriana Santarosa
   Bicharra Garcia, Ana Cristina
BE Shen, W
   Barthes, JP
   Luo, J
   Shi, Y
   Zhang, J
TI Conversational Agents for Elderly Interaction
SO PROCEEDINGS OF THE 2021 IEEE 24TH INTERNATIONAL CONFERENCE ON COMPUTER
   SUPPORTED COOPERATIVE WORK IN DESIGN (CSCWD)
SE International Conference on Computer Supported Cooperative Work in
   Design
LA English
DT Proceedings Paper
CT 24th IEEE International Conference on Computer Supported Cooperative
   Work in Design (IEEE CSCWD)
CY MAY 05-07, 2021
CL Dalian, PEOPLES R CHINA
SP IEEE, Dalian Univ Technol, Int Working Grp Comp Supported Cooperat Work in Design, IEEE Syst Man & Cybernet Soc, Dalian Jiaotong Univ
DE conversational agents; elderly; personalization; collaboration
ID SOCIAL-INTERACTION; OLDER; ROBOT; CARE; TALK
AB Social isolation and loneliness are problems faced by the elderly that might be aggravated due to quarantine during the coronavirus pandemic. This motivates a search demand for automatic technological solutions, such as chatbots, to address the problem, and establish a collaborative interaction between elderly and conversational agents. We analyze the use of conversational agents and the main types of personalization used during interacting with the elderly. We mapped 53 papers in 5 sources to answer 5 research questions that guided our study. Our findings show these solutions may have a positive impact on elderly's life.
C1 [Pinto, Noemi da Paixao; de Sa Sousa, Henrique Prado; Bicharra Garcia, Ana Cristina] Univ Fed Estado Rio de Janeiro, Dept Appl Informat, Rio de Janeiro, Brazil.
   [dos Santos Franca, Juliana Baptista] UFRRJ, Comp Dept, Seropedica, Brazil.
   [Vivacqua, Adriana Santarosa] Univ Fed Rio de Janeiro, Inst Comp, Rio de Janeiro, Brazil.
RP Pinto, ND (corresponding author), Univ Fed Estado Rio de Janeiro, Dept Appl Informat, Rio de Janeiro, Brazil.
EM noemidpp@edu.unirio.br; julibsf@gmail.com; hsousa@uniriotec.br;
   avivacqua@dcc.ufij.br; cristina.bicharra@uniriotec.br
CR Ali MR, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P55
   Angelini L, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P620, DOI 10.1145/3316782.3322763
   Balsa J, 2019, LECT NOTES ARTIF INT, V11804, P372, DOI 10.1007/978-3-030-30241-2_32
   Bickmore TW, 2005, INTERACT COMPUT, V17, P711, DOI 10.1016/j.intcom.2005.09.002
   Bott N, 2019, J MED INTERNET RES, V21, DOI 10.2196/13440
   Carros F, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376402
   Chattaraman V, 2019, COMPUT HUM BEHAV, V90, P315, DOI 10.1016/j.chb.2018.08.048
   Chattaraman V, 2012, COMPUT HUM BEHAV, V28, P2055, DOI 10.1016/j.chb.2012.06.009
   Constantin A, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312811
   Crompton CJ, 2019, COMPUT HUM BEHAV, V101, P60, DOI 10.1016/j.chb.2019.07.006
   De Carolis B, 2017, MULTIMED TOOLS APPL, V76, P5073, DOI 10.1007/s11042-016-3797-0
   El Kamali M, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC'18 ADJUNCT), P1656, DOI 10.1145/3267305.3274188
   Esposito A, 2019, J AMB INTEL HUM COMP, P1
   Fasola J, 2012, P IEEE, V100, P2512, DOI 10.1109/JPROC.2012.2200539
   Fielding B, 2016, LECT NOTES ARTIF INT, V10011, P110, DOI 10.1007/978-3-319-47665-0_10
   Gorer B, 2017, AUTON ROBOT, V41, P657, DOI 10.1007/s10514-016-9598-5
   Griol D, 2016, COGN COMPUT, V8, P336, DOI 10.1007/s12559-015-9352-x
   Grossi G., 2019, PATTERN RECOGNITION
   Ienca M, 2017, J ALZHEIMERS DIS, V56, P1301, DOI 10.3233/JAD-161037
   Kachouie R, 2014, INT J HUM-COMPUT INT, V30, P369, DOI 10.1080/10447318.2013.873278
   Khosravi P, 2016, COMPUT HUM BEHAV, V63, P594, DOI 10.1016/j.chb.2016.05.092
   Kidd CD, 2006, IEEE INT CONF ROBOT, P3972, DOI 10.1109/ROBOT.2006.1642311
   Kitchenham B, 2013, INFORM SOFTWARE TECH, V55, P2049, DOI 10.1016/j.infsof.2013.07.010
   Kobayashi M, 2019, LECT NOTES COMPUT SC, V11749, P53, DOI 10.1007/978-3-030-29390-1_4
   Kocaballi AB, 2019, J MED INTERNET RES, V21, DOI 10.2196/15360
   Kopp S, 2018, P AAMAS WORKSH INT C, V2338
   Kowalski J, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312973
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lebherz DS, 2018, WINT SIMUL C PROC, P1025, DOI 10.1109/WSC.2018.8632293
   Lee MC, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P235, DOI 10.1145/3083187.3083220
   Lewis L, 2016, COMM COM INF SC, V616, P3, DOI 10.1007/978-3-319-39387-2_1
   Madjaroff G, 2016, P 2016 CHI C HUM FAC, P2200
   Maeda H, 2019, IIWAS2019: THE 21ST INTERNATIONAL CONFERENCE ON INFORMATION INTEGRATION AND WEB-BASED APPLICATIONS & SERVICES, P664, DOI 10.1145/3366030.3366114
   Marfil R, 2020, COGN COMPUT, V12, P479, DOI 10.1007/s12559-019-09685-5
   McGlynn SA, 2017, INT J HUM-COMPUT ST, V100, P33, DOI 10.1016/j.ijhcs.2016.12.004
   Miura C, 2019, IIWAS2019: THE 21ST INTERNATIONAL CONFERENCE ON INFORMATION INTEGRATION AND WEB-BASED APPLICATIONS & SERVICES, P437, DOI 10.1145/3366030.3366127
   Mollaret C, 2016, COMPUT VIS IMAGE UND, V149, P78, DOI 10.1016/j.cviu.2016.03.003
   Mostajeran F, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376565
   Ofli F, 2016, IEEE J BIOMED HEALTH, V20, P201, DOI 10.1109/JBHI.2015.2391671
   Pereira J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1237-1
   Piau A, 2019, INT J MED INFORM, V128, P18, DOI 10.1016/j.ijmedinf.2019.05.013
   Prakash A, 2013, ACMIEEE INT CONF HUM, P283, DOI 10.1109/HRI.2013.6483600
   Russo A, 2019, REJUV RES, V22, P109, DOI 10.1089/rej.2018.2075
   Sanders J, 2019, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES: COMPANION (IUI 2019), P95, DOI 10.1145/3308557.3308713
   ter Stal S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102409
   Trajkova M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376186
   Utami D, 2017, LECT NOTES ARTIF INT, V10498, P441, DOI 10.1007/978-3-319-67401-8_55
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   Vuono A, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P1835
   Wada K, 2005, IEEE INT CONF ROBOT, P2785
   Wada K, 2004, P IEEE, V92, P1780, DOI 10.1109/JPROC.2004.835378
   Wohlin C., 2014, P 18 INT C EV ASS SO, P1
   World Health Organization, 2018, AG HLTH
   Wu IY, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P21, DOI 10.1145/3316782.3321529
   Wu SH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P485, DOI 10.1109/IRI.2018.00077
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
NR 56
TC 2
Z9 2
U1 4
U2 5
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-6597-4
J9 INT C COMP SUPP COOP
PY 2021
BP 1
EP 6
DI 10.1109/CSCWD49262.2021.9437883
PG 6
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Operations Research & Management Science
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Operations Research & Management Science
GA BS3XQ
UT WOS:000716858200001
DA 2022-08-02
ER

PT C
AU Langevin, R
   Lordon, R
   Avrahami, T
   Cowan, B
   Hirsch, T
   Hsieh, G
AF Langevin, Raina
   Lordon, Ross
   Avrahami, Thi
   Cowan, Benjamin
   Hirsch, Tad
   Hsieh, Gary
GP ASSOC COMP MACHINERY
TI Heuristic Evaluation of Conversational Agents
SO CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN
   COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems
CY MAY 08-13, 2021
CL ELECTR NETWORK
SP ACM SIGCHI, Assoc Comp Machinery, Bloomberg, Facebook, Google, Kyocera, Microsoft, Monash Univ, Verizon Media
DE heuristic evaluation; conversational agents; user interface design
ID USABILITY HEURISTICS
AB Conversational interfaces have risen in popularity as businesses and users adopt a range of conversational agents, including chatbots and voice assistants. Although guidelines have been proposed, there is not yet an established set of usability heuristics to guide and evaluate conversational agent design. In this paper, we propose a set of heuristics for conversational agents adapted from Nielsen's heuristics and based on expert feedback. We then validate the heuristics through two rounds of evaluations conducted by participants on two conversational agents, one chatbot and one voice-based personal assistant. We find that, when using our heuristics to evaluate both interfaces, evaluators were able to identify more usability issues than when using Nielsen's heuristics. We propose that our heuristics successfully identify issues related to dialogue content, interaction design, help and guidance, human-like characteristics, and data privacy.
C1 [Langevin, Raina; Hsieh, Gary] Univ Washington, Human Ctr Design & Engn, Seattle, WA 98195 USA.
   [Lordon, Ross] Microsoft, Redmond, WA USA.
   [Avrahami, Thi] Rulai, Mountain View, CA USA.
   [Cowan, Benjamin] Univ Coll Dublin, Sch Informat & Commun Studies, Dublin, Ireland.
   [Hirsch, Tad] Northeastern Univ, Dept Art Design, Boston, MA 02115 USA.
RP Langevin, R (corresponding author), Univ Washington, Human Ctr Design & Engn, Seattle, WA 98195 USA.
EM rlangevi@uw.edu; rolordon@microsoft.com; thi@rul.ai;
   benjamin.cowan@ucd.ie; tad.hirsch@northeastern.edu; garyhs@uw.edu
FU Science Foundation Ireland ADAPT Centre [13/RC/2106]
FX We would like to thank all of the experts who reviewed the heuristics
   for their invaluable time and feedback. We also thank our study
   participants who conducted heuristic evaluations and the anonymous
   reviewers for their helpful feedback. This work was in part supported by
   the Science Foundation Ireland ADAPT Centre (13/RC/2106).
CR Amershi S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300233
   Apple Computer Inc, 1987, APPL HUM INT GUID AP
   Bickmore T, 2005, TEXT SPEECH LANG TEC, V30, P23
   Calak Piotr, 2013, THESIS
   Chisnell DE, 2006, TECH COMMUN-STC, V53, P39
   Clark L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300705
   Clark Leigh, 2018, ARXIV181006828
   Cowan BR, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3098539
   Glass J., 1999, P 1999 IEEE ASRU WOR
   GRICE HP, 1975, SYNTAX SEMANTICS, V3, DOI DOI 10.1111/J.1365-2664.2006.01229.X
   Hermawati S, 2016, APPL ERGON, V56, P34, DOI 10.1016/j.apergo.2015.11.016
   Instone Keith, 1997, SITE USABILITY HEURI
   Jain M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P895, DOI 10.1145/3196709.3196735
   Kocielnik Rafal, 2019, AMIA Annu Symp Proc, V2019, P552
   Liao QV, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P264, DOI 10.1145/2901790.2901842
   Lordon R.J., 2019, THESIS
   Manka JS, 2003, PROCEEDINGS OF THE TWENTY-NINTH ANNUAL CONFERENCE ON EXPLOSIVES AND BLASTING TECHNIQUE, VOL 1, P169
   MOLICH R, 1990, COMMUN ACM, V33, P338, DOI 10.1145/77481.77486
   Murad C, 2019, IEEE PERVAS COMPUT, V18, P33, DOI 10.1109/MPRV.2019.2906991
   Nielsen J., 1990, P SIGCHI C HUM FACT, V90, P249, DOI DOI 10.1145/97243.97281
   Nielsen Jakob, 1994, CONDUCT HEURISTIC EV
   Przegalinska A, 2019, BUS HORIZONS, V62, P785, DOI 10.1016/j.bushor.2019.08.005
   Svenningsson N., 2019, P 2019 2 ART INT CLO, P151
   Thomas P, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1171, DOI 10.1145/3397271.3401127
   Wei ZXN, 2018, IEEE PERVAS COMPUT, V17, P84, DOI 10.1109/MPRV.2018.022511249
   Wu Y., 2020, P 8 INT C LEARN REPR, P1
   Zhang JJ, 2003, J BIOMED INFORM, V36, P23, DOI 10.1016/S1532-0464(03)00060-1
NR 27
TC 1
Z9 1
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8096-6
PY 2021
DI 10.1145/3411764.3445312
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7AU
UT WOS:000758168003066
DA 2022-08-02
ER

PT J
AU Merdivan, E
   Singh, D
   Hanke, S
   Kropf, J
   Holzinger, A
   Geist, M
AF Merdivan, Erinc
   Singh, Deepika
   Hanke, Sten
   Kropf, Johannes
   Holzinger, Andreas
   Geist, Matthieu
TI Human Annotated Dialogues Dataset for Natural Conversational Agents
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE conversational agents; dialogue systems; chatbots
AB Conversational agents are gaining huge popularity in industrial applications such as digital assistants, chatbots, and particularly systems for natural language understanding (NLU). However, a major drawback is the unavailability of a common metric to evaluate the replies against human judgement for conversational agents. In this paper, we develop a benchmark dataset with human annotations and diverse replies that can be used to develop such metric for conversational agents. The paper introduces a high-quality human annotated movie dialogue dataset, HUMOD, that is developed from the Cornell movie dialogues dataset. This new dataset comprises 28,500 human responses from 9500 multi-turn dialogue history-reply pairs. Human responses include: (i) ratings of the dialogue reply in relevance to the dialogue history; and (ii) unique dialogue replies for each dialogue history from the users. Such unique dialogue replies enable researchers in evaluating their models against six unique human responses for each given history. Detailed analysis on how dialogues are structured and human perception on dialogue score in comparison with existing models are also presented.
C1 [Merdivan, Erinc; Singh, Deepika; Kropf, Johannes] AIT Austrian Inst Technol, A-2700 Wiener Neustadt, Austria.
   [Merdivan, Erinc] Univ Lorraine, CNRS, LORIA, Cent Supelec, F-57000 Metz, France.
   [Singh, Deepika; Holzinger, Andreas] Med Univ Graz, Inst Med Informat Stat, HCI KDD, Holzinger Grp, A-8036 Graz, Austria.
   [Hanke, Sten] FH Joanneum Gesell mbH, A-8020 Graz, Austria.
   [Geist, Matthieu] Univ Lorraine, CNRS, LIEC, F-57000 Metz, France.
RP Merdivan, E; Singh, D (corresponding author), AIT Austrian Inst Technol, A-2700 Wiener Neustadt, Austria.; Merdivan, E (corresponding author), Univ Lorraine, CNRS, LORIA, Cent Supelec, F-57000 Metz, France.; Singh, D (corresponding author), Med Univ Graz, Inst Med Informat Stat, HCI KDD, Holzinger Grp, A-8036 Graz, Austria.
EM merdivane@gmail.com; deepika.singh@medunigraz.at;
   sten.hanke@fh-joanneum.at; Johannes.Kropf@ait.ac.at;
   andreas.holzinger@medunigraz.at; matthieu.geist@univ-lorraine.fr
RI Hanke, Sten/AAQ-2093-2021; Holzinger, Andreas/E-9530-2010
OI Hanke, Sten/0000-0003-3833-4252; Holzinger, Andreas/0000-0002-6786-5194;
   Kropf, Johannes/0000-0003-1545-979X
FU European Union [616757]
FX This work has been funded by the European Union Horizon2020 MSCA ITN
   ACROSSING project (GA no. 616757).
CR Allen J.F., 1996, P 34 ANN M ASS COMP
   [Anonymous], 2014, EMNLP
   Artstein R., 2009, LANGUAGES FORMAL NAT
   Banchs R. E., 2012, P 50 ANN M ASS COMP
   Banerjee S., 2005, P ACL 2005 WORKSH UN
   Bordes A., 2017, P INT C LEARN REPR I
   Chen H., 2017, ACM SIGKDD EXPLOR NE, V19, P2
   COHEN J, 1968, PSYCHOL BULL, V70, P213, DOI 10.1037/h0026256
   Danescu-Niculescu-Mizil C., 2011, P 2 WORKSH COGN MOD
   Devlin Jacob, 2019, P 2019 C N AM CHAPT, V1
   Dodge J., 2016, P INT C LEARN REPR I
   Forchini P., 2009, P CORP LING C 2009 C
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Henderson M., 2014, P SIGDIAL 2014 C PHI
   Holzinger A., 2002, LECT NOTES COMPUTER, V2398, P34
   Holzinger A, 2019, LECT NOTES COMPUT SC, V11713, P1, DOI 10.1007/978-3-030-29726-8_1
   Holzinger A, 2018, LECT NOTES COMPUT SC, V11015, P1, DOI 10.1007/978-3-319-99740-7_1
   Hudec M, 2018, J OFF STAT, V34, P981, DOI 10.2478/JOS-2018-0048
   Li X.L., 2005, P EUR C MACH LEARN E
   Li XQ, 2010, 2010 INTERNATIONAL COLLOQUIUM ON COMPUTING, COMMUNICATION, CONTROL, AND MANAGEMENT (CCCM2010), VOL IV, P98, DOI 10.1109/ETCS.2010.558
   Li Yanran, 2017, P INT JOINT C NAT LA
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020
   Liu C. - W., 2016, ARXIV160308023
   Lowe R., 2015, P SIGDIAL 2015 C PRA
   Lowe R., 2016, P SIGDIAL 2016 C LOS
   Lowe R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1116, DOI 10.18653/v1/P17-1103
   Lu Z., 2013, P 2013 C EMP METH NA
   Merdivan E., 2017, P ADV NEURAL INFORM
   Papineni K, 2002, P 40 ANN M ASS COMP
   Petukhova V., 2014, TECHNICAL REPORT
   Raux A., 2005, P 9 EUR C SPEECH COM P 9 EUR C SPEECH COM
   Ritter A., 2011, P 2011 C EMP METH NA
   Sai A.B., 2019, AAAI, V30, P1
   Serban I. V., 2016, P 30 AAAI C ART INT
   Sharma Shikhar, 2017, ABS170609799 CORR
   Tiedemann J., 2012, P INT C LANG RES EV
   Vaswani A., 2017, P 2017 ADV NEURAL IN, P5998
   Williams H, 2013, TLS-TIMES LIT SUPPL, P22
   Yang CF, 2016, IEEE IC COMP COM NET
   Zhang S., 2018, ARXIV180107243
   ZUE V, 1994, SPEECH COMMUN, V15, P331, DOI 10.1016/0167-6393(94)90083-3
NR 41
TC 4
Z9 4
U1 0
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD FEB
PY 2020
VL 10
IS 3
AR 762
DI 10.3390/app10030762
PG 16
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA LC4PI
UT WOS:000525305900033
OA gold
DA 2022-08-02
ER

PT C
AU Ruttkay, Z
   Dormann, C
   Noot, H
AF Ruttkay, Z
   Dormann, C
   Noot, H
BE Ruttkay, Z
   Pelachaud, C
TI Embodied conversational agents on a common ground - A framework for
   design and evaluation
SO FROM BROWS TO TRUST: EVALUATING EMBODIED CONVERSATIONAL AGENTS
SE Human-Computer Interaction Series
LA English
DT Proceedings Paper
CT Workshop on Embodied Conversational Agents held at the 2002 AAMAS
   Conference
CY MAR, 2003
CL Montreal, CANADA
DE embodied conversational agents; design; evaluation framework;
   methodology
ID INTERFACE
AB One would like to rely on design guidelines for embodied conversational agents (ECAs), grounded on evaluation studies. How to define the physical and mental characteristics of an ECA, optimal for an envisioned application? What will be the added value of using an ECA? Although there have been studies addressing such issues, we are still far from getting a complete picture. This is not only due to the still relatively little experience with applications of ECAs, but also to the diversity in terms and experimental settings used. The lack of a common, established framework makes it difficult to compare ECAs, interpret evaluation results and judge their scope and relevance. In this chapter we propose a common taxonomy of the relevant design and evaluation aspects of ECAs. We refer to recent works to elicit evaluation concepts and discuss measurement issues.
C1 Ctr Math & Comp Sci, Amsterdam, Netherlands.
RP Ruttkay, Z (corresponding author), Ctr Math & Comp Sci, Amsterdam, Netherlands.
EM zsofia.ruttkay@cwi.nl; cdormann@ccs.carleton.ca; han@cwi.nl
CR ANDRE E, 2000, P 2 INT C INT US INT, P1
   Bailenson J. N., 2001, Intelligent Virtual Agents. Third International Workshop, IVA 2001. Proceedings (Lecture Notes in Artificial Intelligence Vol.2190), P86
   BARKER T, 2003, P AAMAS03 WORKSH EMB
   BAYLOR AL, 2003, P AAMAS03 WORKSH EMB
   BENBASAT I, 1981, COMMUN ACM, V24, P752, DOI 10.1145/358790.358795
   BICKMORE T, 2001, P ACM C HUM FACT COM, P396
   BUISINE S, 2003, P AAMAS03 WORKSH EMB
   Cassell J, 2000, COMMUN ACM, V43, P50, DOI 10.1145/355112.355123
   Cassell J., 1999, Autonomous Agents and Multi-Agent Systems, V2, P45, DOI 10.1023/A:1010027123541
   Cassell J, 1999, APPL ARTIF INTELL, V13, P519, DOI 10.1080/088395199117360
   COWELL AJ, 2003, P AAMAS03 WORKSH EMB
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   DEROSIS F, IN PRESS AGENT CULTU
   Dryer DC, 1999, APPL ARTIF INTELL, V13, P273, DOI 10.1080/088395199117423
   GRIFFIN P, 2003, P AAMAS03 WORKSH EMB
   Hofstede G., 1997, CULTURES ORG SOFTWAR
   Hook K, 2000, AI COMMUN, V13, P195
   Isbister K, 2000, INT J HUM-COMPUT ST, V53, P251, DOI 10.1006/ijhc.2000.0368
   ISBISTER K, 1998, KSL0801 KNOWL SYST L
   ISBISTER K, 2002, P AAMAS02 WORKSH EMB
   Isbister Katherine, 2000, P SIGCHI C HUM FACT, P57, DOI [10.1145/332040.332407, DOI 10.1145/332040.332407]
   Isla D. A., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P1356
   KING WJ, 1996, C COMP HUM FACT COMP, P00289
   KODA T, 1996, P HCI, P98
   LARSEN RJ, 1987, J RES PERS, V21, P1, DOI 10.1016/0092-6566(87)90023-7
   Lester J. C., 1997, P ACM SIGCHI C HUM F, P359, DOI DOI 10.1145/258549.258797
   Massaro D.W., 1998, PERCEIVING TALKING F
   McBreen H., 2000, Proceedings of the Fourth International Conference on Autonomous Agents, P39, DOI 10.1145/336595.336968
   MCBREEN HM, 2001, P AAMAS01 WORKSH REP
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   Mori J., 2003, P AAMAS03 WORKSH EMB
   Moundridou M, 2002, J COMPUT ASSIST LEAR, V18, P253, DOI 10.1046/j.0266-4909.2001.00237.x
   Nass C, 2000, EMBODIED CONVERSATIONAL AGENTS, P374
   Nass Clifford, 2000, P SIGCHI C HUM FACT, DOI [10.1145/332040.332452, DOI 10.1145/332040.332452]
   PARADISO A, 2001, P AAMAS01 WORKSH REP
   Pelachaud C, 2002, J VISUAL COMP ANIMAT, V13, P301, DOI 10.1002/vis.299
   Pelachaud C, 2002, P 1 INT JOINT C AUT
   Prendinger H, 2003, IEICE T INF SYST, VE86D, P1378
   PRENDINGER H, 2002, P AAMAS 02, P270
   Reeves B., 1996, MEDIA EQUATION PEOPL
   RESNIK PV, 1985, J SOC PSYCHOL, V125, P761, DOI 10.1080/00224545.1985.9713550
   Rickenberg Raoul, 2000, P SIGCHI C HUM FACT, P49
   RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X
   Sanders GA, 2000, EMBODIED CONVERSATIONAL AGENTS, P346
   Sproull L, 1996, HUM-COMPUT INTERACT, V11, P97, DOI 10.1207/s15327051hci1102_1
   van Mulken S, 1998, PEOPLE AND COMPUTER XIII, PROCEEDINGS, P53
   WITKOWSKI M, 2001, P WORKSH INF AG E CO
   Xiao J, 2002, P AAMAS02 WORKSH EMB
NR 48
TC 27
Z9 27
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS
SN 1571-5035
EI 2524-4477
BN 1-4020-2729-X
J9 HUM-COMPUT INT-SPRIN
PY 2004
VL 7
BP 27
EP 66
PG 40
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BBP07
UT WOS:000226830500002
DA 2022-08-02
ER

PT J
AU Montenegro, JLZ
   da Costa, CA
   Righi, RD
AF Zeni Montenegro, Joao Luis
   da Costa, Cristiano Andre
   Righi, Rodrigo da Rosa
TI Survey of conversational agents in health
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Review
DE Conversational agents; Chatbot; Expert systems; Systematic review;
   Health
ID USER ENGAGEMENT; MENTAL-HEALTH; ACCEPTABILITY; FRAMEWORK; SYSTEMS; CARE
AB Artificial intelligence (Al) has transformed the world and the relationships among humans as the learning capabilities of machines have allowed for a new means of communication between humans and machines. In the field of health, there is much interest in new technologies that help to improve and automate services in hospitals. This article aims to explore the literature related to conversational agents applied to health care, searching for definitions, patterns, methods, architectures, and data types. Furthermore, this work identifies an agent application taxonomy, current challenges, and research gaps. In this work, we use a systematic literature review approach.
   We guide and refine this study and the research questions by applying Population, Intervention, Comparison, Outcome, and Context (PICOC) criteria. The present study investigated approximately 4145 articles involving conversational agents in health published over the last ten years. In this context, we finally selected 40 articles based on their approaches and objectives as related to our main subject. As a result, we developed a taxonomy, identified the main challenges in the field, and defined the main types of dialog and contexts related to conversational agents in health. These results contributed to discussions regarding conversational health agents, and highlighted some research gaps for future study. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Zeni Montenegro, Joao Luis; da Costa, Cristiano Andre; Righi, Rodrigo da Rosa] Univ Vale Rio Sinos UNISINOS, Software Innovat Lab SOFTWARELAB, Appl Comp Grad Program, Av Unisinos 950, BR-93022750 Sao Leopoldo, Brazil.
RP da Costa, CA (corresponding author), Univ Vale Rio Sinos UNISINOS, Software Innovat Lab SOFTWARELAB, Appl Comp Grad Program, Av Unisinos 950, BR-93022750 Sao Leopoldo, Brazil.
EM cac@unisinos.br
RI da Rosa Righi, Rodrigo/T-9430-2019; da Costa, Cristiano
   André/AAV-1894-2020
OI da Rosa Righi, Rodrigo/0000-0001-5080-7660; da Costa, Cristiano
   André/0000-0003-3859-6199; Zeni Montenegro, Joao
   Luis/0000-0001-5326-6097; MONTENEGRO CAMACHO, LUIS
   ARTURO/0000-0002-5224-4854
FU Brazilian National Council for Scientific and Technological Development
   - CNPq [303640/2017-0, 405354/2016-9]
FX The authors would like to thank the Brazilian National Council for
   Scientific and Technological Development - CNPq (Grant Numbers
   303640/2017-0 and 405354/2016-9) for supporting this work.
CR Abdul-Kader SA, 2015, INT J ADV COMPUT SC, V6, P72
   Alesanco A., 2017, EUR MED BIOL ENG C N, P185
   Amato F, 2017, CHARBOTS MEET EHEALT, V14, P381
   Amrhein Antje, 2016, P 1 WORKSH ETH DES I, P14
   Aramaki E, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155195
   Baskar J, 2014, COMM COM INF SC, V430, P89
   Bickmore TW, 2011, J BIOMED INFORM, V44, P183, DOI 10.1016/j.jbi.2010.12.006
   Bickmore TW, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1265
   Breso A, 2016, EXPERT SYST, V33, P297, DOI 10.1111/exsy.12151
   Chiu Y-C, 2004, P AAAI FALL S DIAL S, P22
   Chuah JH, 2013, PRESENCE-VIRTUAL AUG, V22, P141, DOI 10.1162/PRES_a_00145
   D'Alfonso S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00796
   D'Haro LF, 2017, ASIAPAC SIGN INFO PR, P76, DOI 10.1109/APSIPA.2017.8282005
   Eisman EM, 2016, EXPERT SYST APPL, V53, P172, DOI 10.1016/j.eswa.2016.01.033
   Fadhil A., 2017, P 11 EAI INT C PERV, P261, DOI DOI 10.1145/3154862.3154914
   Fadhil A., 2018, P 12 EAI INT C PERV
   Fraser KC, 2016, J ALZHEIMERS DIS, V49, P407, DOI 10.3233/JAD-150520
   GALVAO AM, 2004, PERSONA AIML ARCHITE, P1266
   Ganesh S., 2008, P 2 WORKSH CROSS LIN
   Google, 2019, GOOGL SCHOL METR
   Heerink M, 2010, VIRTUAL REAL-LONDON, V14, P77, DOI 10.1007/s10055-009-0142-1
   Herbert D, 2018, EXPERT SYSTEMS APPL
   Hirano M, 2017, HEALTH PSYCHOL OPEN, V4, DOI 10.1177/2055102917707185
   Holotescu C., P INT C HUM COMP INT, P91, DOI [10.14687/ijhs.v13i1.3549, DOI 10.14687/IJHS.V13I1.3549]
   Hudlicka E, 2013, PATIENT EDUC COUNS, V92, P160, DOI 10.1016/j.pec.2013.05.007
   Ireland D, 2015, STUD HEALTH TECHNOL, V214, P128, DOI 10.3233/978-1-61499-558-6-128
   Jacquet B, 2018, INT C HUM SYST ENG D, P394
   Jin L., 2017, P 12 WORKSH INN US N, P11, DOI DOI 10.18653/V1/W17-4715.PDF
   Kar R, 2016, ARXIV161103799, P9
   Karpagam K, 2014, ICTACT J SOFT COMPUT, V4
   Kasinathan V, 2017, IEEE CONF OPEN SYST, P32, DOI 10.1109/ICOS.2017.8280270
   King AC, 2013, J HEALTH COMMUN, V18, P1449, DOI 10.1080/10810730.2013.798374
   Kowatsch T., 2017, P PERSUASIVE EMBODIE
   Laranjo Liliana, 2018, J AM MED INFORM ASS
   Lisetti C. L., 2012, FLAIRS C
   Lokman AS, 2010, COMM COM INF SC, V87, P31
   Lopez V, 2008, PROC INT C TOOLS ART, P194, DOI 10.1109/ICTAI.2008.50
   Magerko B, 2011, AAAI SPRING S AI HLT
   McArthur SDJ, 2007, IEEE T POWER SYST, V22, P1743, DOI 10.1109/TPWRS.2007.908471
   Ni L., 2017, INT S KNOWLEDGE SYST, P38, DOI DOI 10.1007/978-981-10-6989-5_4
   Nikitina S, 2018, ARXIV180406550, V1, P6
   Novielli N, 2010, J MULTIMODAL USER IN, V3, P131, DOI 10.1007/s12193-009-0026-4
   Ochs M., 2017, C COMP AN SOC AG CAS
   Pedrelli P, 2016, ACM SIGCH C HUM FACT
   Petticrew M., 2008, SYSTEMATIC REV SOCIA
   Rentea V., 2012, 2012 Third International Conference on Emerging Intelligent Data and Web Technologies (EIDWT 2012), P158, DOI 10.1109/EIDWT.2012.24
   Ring L, 2016, IPROC, V2, pe27, DOI DOI 10.2196/IPROC.6065
   Rishe N, 2013, ACM TMIS, V4, P1, DOI [10.1145/2544103, DOI 10.1145/2544103]
   Rizzo A, 2011, JVRB J VIRTUAL REALI, V8, P9
   Roehrs A, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.5876
   Sebastian J, 2017, COMPUT HUM BEHAV, V73, P479, DOI 10.1016/j.chb.2017.03.071
   Shaked NA, 2017, HEALTHC TECHNOL LETT, V4, P83, DOI 10.1049/htl.2017.0009
   Stapic Z, 2012, CEC 2012 23 INT C
   Tanaka H, 2017, PLOS ONE, V12, P15
   Tanaka H, 2017, IEEE J TRANSL ENG HE, V5, DOI 10.1109/JTEHM.2017.2752152
   Tielman M. L, 2017, TECHNOLOGY HLTH CARE, P1
   Tokunaga S, 2016, COMP INF SCI IC 2016, P1
   Torous J, 2018, EVID-BASED MENT HEAL, V21, P116, DOI 10.1136/eb-2018-102891
   Turner M, 2010, INFORM SOFTWARE TECH, V52, P463, DOI 10.1016/j.infsof.2009.11.005
   Turunen M, 2011, COMPUT SPEECH LANG, V25, P192, DOI 10.1016/j.csl.2010.04.004
   van Rooyen CJ, 2017, INT CONF SOFT COMP, P80, DOI 10.1109/ISCMI.2017.8279602
   Wang C, 2015, GENET MED, V17, P822, DOI 10.1038/gim.2014.198
   Wargnier P, 2016, IEEE INT CONF SERIOU
   Wargnier P, 2015, 2015 3RD IEEE VR INTERNATIONAL WORKSHOP ON VIRTUAL AND AUGMENTED ASSISTIVE TECHNOLOGY (VAAT), P23, DOI 10.1109/VAAT.2015.7155406
   Wells Kristen J, 2015, Hisp Health Care Int, V13, P179, DOI 10.1891/1540-4153.13.4.179
   Yaghoubzadeh Ramin, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P79, DOI 10.1007/978-3-642-40415-3_7
   Yasavur U, 2014, J MULTIMODAL USER IN, V8, P381, DOI 10.1007/s12193-014-0169-9
   Zaveri A, 2016, SEMANT WEB, V7, P63, DOI 10.3233/SW-150175
   Zhang Z, 2017, PATIENT EDUC COUNS, V100, P1730, DOI 10.1016/j.pec.2017.03.017
   Zhang Z, 2014, LECT NOTES ARTIF INT, V8637, P504, DOI 10.1007/978-3-319-09767-1_61
NR 70
TC 82
Z9 82
U1 11
U2 90
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD SEP 1
PY 2019
VL 129
BP 56
EP 67
DI 10.1016/j.eswa.2019.03.054
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Operations Research & Management Science
GA HZ9DT
UT WOS:000469156700005
DA 2022-08-02
ER

PT C
AU Nikitina, S
   Callaioli, S
   Baez, M
AF Nikitina, Svetlana
   Callaioli, Sara
   Baez, Marcos
GP IEEE
TI Smart Conversational Agents for Reminiscence
SO 2018 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON SOFTWARE ENGINEERING FOR
   COGNITIVE SERVICES (SE4COG)
LA English
DT Proceedings Paper
CT 1st ACM/IEEE International Workshop on Software Engineering for
   Cognitive Services (SE4COG)
CY MAY 28-29, 2018
CL Gothenburg, SWEDEN
SP NAVER LABS Europe, Assoc Comp Machinery, SIGSOFT, IEEE Comp Soc, IEEE Tech Council Software Engn
DE conversational agents; reminiscence; system requirements
ID PEOPLE; MEMORY; GUIDE
AB In this paper we describe the requirements and early system design for a smart conversational agent that can assist older adults in the reminiscence process. The practice of reminiscence has well documented benefits for the mental, social and emotional well-being of older adults. However, the technology support, valuable in many different ways, is still limited in terms of need of co-located human presence, data collection capabilities, and ability to support sustained engagement, thus missing key opportunities to improve care practices, facilitate social interactions, and bring the reminiscence practice closer to those with less opportunities to engage in co-located sessions with a (trained) companion. We discuss conversational agents and cognitive services as the platform for building the next generation of reminiscence applications, and introduce the concept application of a smart reminiscence agent.
C1 [Nikitina, Svetlana; Callaioli, Sara; Baez, Marcos] Univ Trento, Trento, Italy.
   [Nikitina, Svetlana; Baez, Marcos] Tomsk Polytech Univ, Tomsk, Russia.
RP Nikitina, S (corresponding author), Univ Trento, Trento, Italy.; Nikitina, S (corresponding author), Tomsk Polytech Univ, Tomsk, Russia.
EM svetlana.nikitina@unitn.it; sara.callaioli@studenti.unitn.it;
   baez@disi.unitn.it
RI Baez, Marcos/T-4656-2017
OI Baez, Marcos/0000-0003-1666-2474
FU EU; project "Evaluation and enhancement of social, economic and
   emotional wellbeing of older adults", Tomsk Polytechnic University
   [14.Z50.31.0029]
FX This work has received funding from the EU Horizon 2020 research and
   innovation programme under the Marie Sklodowska-Curie grant agreement.
   It was also supported by the project "Evaluation and enhancement of
   social, economic and emotional wellbeing of older adults" under the
   agreement No. 14.Z50.31.0029, Tomsk Polytechnic University.
CR Allen RS, 2009, CLIN GERONTOLOGIST, V32, P164, DOI 10.1080/07317110802677005
   Bender M, 1998, THERAPEUTIC PURPOSES
   Caforio V, 2017, LECT NOTES COMPUT SC, V10515, P72, DOI 10.1007/978-3-319-67687-6_6
   Cervone A, ROVING MIND BALANCIN
   Crete-Nishihata M, 2012, HUM-COMPUT INTERACT, V27, P92, DOI 10.1080/07370024.2012.656062
   Demiris George, 2016, AMIA Annu Symp Proc, V2016, P496
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Fivush R, 2011, INT J PSYCHOL, V46, P321, DOI 10.1080/00207594.2011.596541
   Hartup WW, 1999, CURR DIR PSYCHOL SCI, V8, P76, DOI 10.1111/1467-8721.00018
   Hawthorn D, 2000, INTERACT COMPUT, V12, P507, DOI 10.1016/S0953-5438(99)00021-1
   Huang Ting-Hao Kenneth, 2015, 3 AAAI C HUM COMP CR
   Huldtgren A, 2015, LECT NOTES COMPUT SC, V9298, P71, DOI 10.1007/978-3-319-22698-9_6
   Ibarra F, 2017, LECT NOTES COMPUT SC, V10515, P62, DOI 10.1007/978-3-319-67687-6_5
   Kim J., 2006, CHI 06, P953
   Konstantas I, 2016, P SAI INT SYST C, P1014
   Kopp S, 2005, LECT NOTES ARTIF INT, V3661, P329
   Lasecki W.S., 2013, P 26 ANN ACM S US IN, P151
   Lazar A, 2014, HEALTH EDUC BEHAV, V41, p51S, DOI 10.1177/1090198114537067
   Lee Hung-Chi, 2016, P 2016 CHI C HUM FAC, P3715, DOI DOI 10.1145/2851581.2890233
   Lee Hung-Chi, 2014, P 2014 COMP PUBL DES P 2014 COMP PUBL DES, P9
   Mostafazadeh N., 2016, ARXIV160306059
   Nurgalieva Leysan, 2017, ARXIV170306317
   Pfeifer Vardoulakis Laura, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P289, DOI 10.1007/978-3-642-33197-8_30
   Piper Anne Marie, 2013, P CSCW 13, P215
   Ring L, 2013, INT CONF AFFECT, P61, DOI 10.1109/ACII.2013.17
   Sanchiz E, 2016, 2016 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P26, DOI [10.1109/CTS.2016.22, 10.1109/CTS.2016.0024]
   Subramaniam P, 2016, CLIN INTERV AGING, V11, P1263, DOI 10.2147/CIA.S111097
   Subramaniam P, 2012, EXPERT REV NEUROTHER, V12, P545, DOI [10.1586/ern.12.35, 10.1586/ERN.12.35]
   Thorgrimsdottir SH, 2016, INT J OLDER PEOPLE N, V11, P70, DOI 10.1111/opn.12093
   Tran K, 2016, IEEE COMPUT SOC CONF, P434, DOI 10.1109/CVPRW.2016.61
   Tsiourti C., 2014, 8 INT C PERV COMP TE, P57
   Uriu D., 2009, CHI 09 EXT ABSTR HUM, P3205
   Vaughan, 2009, PSIGE NEWSLETTER, V64
   WEBSTER JD, 1993, J GERONTOL, V48, pP256, DOI 10.1093/geronj/48.5.P256
   Webster JD, 2007, INT J AGING HUM DEV, V64, P149, DOI 10.2190/Q8V4-X5H0-6457-5442
   Webster JD, 2010, RES AGING, V32, P527, DOI 10.1177/0164027510364122
   West D, 2007, PERS UBIQUIT COMPUT, V11, P313, DOI 10.1007/s00779-006-0090-7
NR 37
TC 6
Z9 6
U1 0
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-4503-5740-1
PY 2018
BP 52
EP 57
DI 10.1145/3195555.3195567
PG 6
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BL6WT
UT WOS:000454724300012
OA Green Submitted
DA 2022-08-02
ER

PT C
AU Crockett, K
   O'Shea, J
   Bandar, Z
AF Crockett, Keeley
   O'Shea, James
   Bandar, Zuhair
BE OShea, J
   Nguyen, NT
   Crockett, K
   Howlett, RJ
   Jain, LC
TI Goal Orientated Conversational Agents: Applications to Benefit Society
SO AGENT AND MULTI-AGENT SYSTEMS: TECHNOLOGIES AND APPLICATIONS
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 5th KES International Conference on Agent and Multi-Agent Systems -
   Technologies and Applications (KES-AMSTA)
CY JUN 29-JUL 01, 2011
CL Manchester Metropolitan Univ, Manchester, ENGLAND
SP KES Int
HO Manchester Metropolitan Univ
DE Goal-orientated conversational agents; pattern matching
ID MEASURING SEMANTIC SIMILARITY; LEARNING STYLES
AB Goal-orientated Conversational Agents are a specific family of conversational agents that are designed to converse with humans through the use of natural language dialogue to achieve a specific task. Traditionally, they utilise pattern matching algorithms to capture the values of specific attributes through their values through dialogue interaction with a user. This is achieved through the use of scripts which contain sets of rules about the domain and a knowledge base to guide the conversation towards achieving a specific goal. Such systems are ideal for providing clear and consistent advice 24 hours a day in many different scenarios, including advising employees about their organisations policies and procedures, guiding a user through buying a suitable product, and tutoring a student to understand a learning objective. This paper presents an overview of a methodology for constructing goal orientated conversational agents. Three case studies which employ this methodology are introduced and evaluated.
C1 [Crockett, Keeley; O'Shea, James; Bandar, Zuhair] Manchester Metropolitan Univ, Intelligent Syst Grp, Sch Comp Math & Digital Technol, Manchester M1 5GD, Lancs, England.
RP Crockett, K (corresponding author), Manchester Metropolitan Univ, Intelligent Syst Grp, Sch Comp Math & Digital Technol, Chester St, Manchester M1 5GD, Lancs, England.
EM K.Crockett@mmu.ac.uk; J.D.OShea@mmu.ac.uk; Z.Bandar@mmu.ac.uk
CR [Anonymous], 2011, BULLYING WORKPLACE
   Cassell J., 2000, EMBODIED CONVERSATIO
   CASSELL J, 2007, P WORKSH EMB NAT LAN
   Cha HJ, 2006, LECT NOTES COMPUT SC, V4053, P513
   Colby K, 1975, ARTIFICIAL PARANOIA
   Crockett K., 2010, IEEE WORLD C COMP IN, P1820
   FELDER RM, 1988, ENG EDUC, V78, P674
   Latham A, 2010, LECT NOTES COMPUT SC, V6483, P131, DOI 10.1007/978-3-642-17407-0_14
   Latham A, 2010, ICAART 2010: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 1: ARTIFICIAL INTELLIGENCE, P163
   Li YH, 2002, LECT NOTES COMPUT SC, V2412, P111
   Li YH, 2003, IEEE T KNOWL DATA EN, V15, P871, DOI 10.1109/TKDE.2003.1209005
   Li YH, 2006, IEEE T KNOWL DATA EN, V18, P1138, DOI 10.1109/TKDE.2006.130
   Massaro D., 2004, FRAMEWORK EVALUATING, P24
   Massaro DW, 2000, EMBODIED CONVERSATIONAL AGENTS, P287
   Mauldin M L, 1994, CHATTERBOTS TINYMUDS
   Michie D., 2001, INFOCHAT SCRIPTERS M
   O'Shea J., 2010, INT J INTELLIGENT IN, V4
   O'Shea J, 2011, INTEL SYST REF LIBR, V10, P201, DOI 10.1007/978-3-642-17931-0_8
   O'Shea K., 2009, ADV ELECT ENG COMPUT, V39, P1100
   Owda M, 2007, IEEE WIC ACM INT C W, P363
   Pudner K, 2007, LECT NOTES ENG COMP, P305
   Sanders GA, 2000, EMBODIED CONVERSATIONAL AGENTS, P346
   Turing AM., 1950, J MIND ASS, V59, P433, DOI [10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
NR 24
TC 7
Z9 7
U1 0
U2 4
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-21999-3; 978-3-642-22000-5
J9 LECT NOTES ARTIF INT
PY 2011
VL 6682
BP 16
EP 25
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BCX60
UT WOS:000311841600003
OA Green Submitted
DA 2022-08-02
ER

PT J
AU De Angeli, A
AF De Angeli, Antonella
TI Ethical implications of verbal disinhibition with conversational agents
SO PSYCHNOLOGY JOURNAL
LA English
DT Article
DE embodied conversational agents; Internet disinhibition; verbal abuse
AB This paper presents a reflection on the ethical implications of conversational agents. The reflection is motivated by recent empirical findings showing that, when interacting in natural language with artificial partners, users tend to indulge in disinhibited behaviour, such as flaming, bullying and sexual harassment. The paper then addresses the question whether conversational agents open any ethical issues and whether this new communication context requires the definition of new moral values and principles or could be addressed by ordinary moral norms.
C1 [De Angeli, Antonella] Univ Manchester, Manchester, Lancs, England.
RP De Angeli, A (corresponding author), Univ Manchester, Manchester Business Sch, Booth St West, Manchester, Lancs, England.
EM antonella.de-angeli@manchester.ac.uk
RI De Angeli, Antonella/AAN-6245-2021
CR ABBATTISTA F, 2004, PSYCHNOLOGY J, V2, P43
   Berry DC, 2005, INT J HUM-COMPUT ST, V63, P304, DOI 10.1016/j.ijhcs.2005.03.006
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Brahnam S, 2008, INTERACT COMPUT, V20, P287, DOI 10.1016/j.intcom.2008.02.001
   Brahnam Sheryl., 2006, P CHI06 WORKSH MIS A, P13
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   Cassell J, 2001, KNOWL-BASED SYST, V14, P55, DOI 10.1016/S0950-7051(00)00102-7
   De Angeli A., 2005, WORKSH INT 2005
   De Angeli A., 2000, P UM 99 WORKSH ATT P
   De Angeli A, 2008, INTERACT COMPUT, V20, P302, DOI 10.1016/j.intcom.2008.02.004
   Dix A, 2008, INTERACT COMPUT, V20, P334, DOI 10.1016/j.intcom.2008.02.003
   Fiske S. T., 1991, SOCIAL COGNITION
   Freier NG, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P343
   Johnson DG, 1997, COMMUN ACM, V40, P60, DOI 10.1145/242857.242875
   Khan R., 2009, INT 2009
   Lester J. C., 1997, P ACM SIGCHI C HUM F, P359, DOI DOI 10.1145/258549.258797
   Maner W., 1996, SCI ENG ETHICS, V2, P137, DOI DOI 10.1007/BF02583549
   Marakas GM, 2000, INT J HUM-COMPUT ST, V52, P719, DOI 10.1006/ijhc.1999.0348
   Moreno KN, 2002, LECT NOTES COMPUT SC, V2363, P963
   Nass C, 2000, EMBODIED CONVERSATIONAL AGENTS, P374
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Rehm M, 2008, INTERACT COMPUT, V20, P311, DOI 10.1016/j.intcom.2008.02.005
   Tavani H. T., 2002, Ethics and Information Technology, V4, P37, DOI 10.1023/A:1015283808882
   Thimbleby H, 2008, INTERACT COMPUT, V20, P338, DOI 10.1016/j.intcom.2008.02.006
   Veletsianos G, 2008, INTERACT COMPUT, V20, P292, DOI 10.1016/j.intcom.2008.02.007
   Whitby B, 2008, INTERACT COMPUT, V20, P326, DOI 10.1016/j.intcom.2008.02.002
   Yee N, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1
   Zanbaka C., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1153
NR 28
TC 9
Z9 9
U1 0
U2 0
PU PSYCHNOLOGY JOURNAL
PI PADOVA
PA PSYCHONOLOGY JOURNAL, PADOVA, 00000, ITALY
SN 1720-7525
J9 PSYCHNOLOGY J
JI PsychNology J.
PY 2009
VL 7
IS 1
SI SI
BP 49
EP 57
PG 9
WC Psychology, Experimental
WE Emerging Sources Citation Index (ESCI)
SC Psychology
GA VB7KB
UT WOS:000416898900003
DA 2022-08-02
ER

PT C
AU Moyo, S
   Piwek, P
AF Moyo, Sharon
   Piwek, Paul
BE Dimitrova, V
   Mizoguchi, R
   DuBoulay, B
   Graesser, A
TI Effective Tutoring with Affective Embodied Conversational Agents
SO ARTIFICIAL INTELLIGENCE IN EDUCATION: BUILDING LEARNING SYSTEMS THAT
   CARE: FROM KNOWLEDGE REPRESENTATION TO AFFECTIVE MODELLING
SE Frontiers in Artificial Intelligence and Applications
LA English
DT Proceedings Paper
CT 14th International Conference on Artificial Intelligence in Education
   (AIED 2009)
CY JUL 06-10, 2009
CL Brighton, ENGLAND
SP Int Artificial Intelligence Educ Soc, Natl Sci Fdn, Alelo, Amer Assoc Artificial Intelligence, Univ Sussex, Sch Sci & Technol, Univ Memphis, Inst Intelligent Syst, Univ Leeds, Sch Comp
DE Feedback; Affect; Embodied Conversational Agents
AB This PhD project aims to investigate the impact of affective embodied conversational agents (ECAs) on the learning of pupils. Based on the idea that there is a link between emotions and learning, we are developing an affective tutoring system in two domains: Information Technology and Business Studies. We will evaluate the system in a classroom setting over several weeks, with each student being assigned to one of the following two conditions: ECA with cognitive strategy only versus ECA with combined affective and cognitive strategy.
C1 [Moyo, Sharon; Piwek, Paul] Open Univ, Ctr Res Comp, Milton Keynes, Bucks, England.
RP Moyo, S (corresponding author), Open Univ, Ctr Res Comp, Milton Keynes, Bucks, England.
OI Piwek, Paul/0000-0003-1621-6124
CR DEHN D, 1999, INT J HUMAN COMPUTER, V52, P1
   DMELLO SK, 2006, INT J ARTIFICIAL INT, V16, P3
   Gulz A., 2004, INT J ARTIFICIAL INT, V14, P313
   Kort B, 2001, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P43, DOI 10.1109/ICALT.2001.943850
   Picard R. W., 1997, AFFECTIVE COMPUTING
NR 5
TC 0
Z9 0
U1 0
U2 1
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 0922-6389
EI 1879-8314
BN 978-1-60750-028-5
J9 FRONT ARTIF INTEL AP
PY 2009
VL 200
BP 767
EP +
DI 10.3233/978-1-60750-028-5-767
PG 2
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Education & Educational Research
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Education & Educational Research
GA BMS76
UT WOS:000273499000134
DA 2022-08-02
ER

PT C
AU Rehm, M
   Andre, E
   Nakano, Y
AF Rehm, Matthias
   Andre, Elisabeth
   Nakano, Yukiko
BE Jacko, JA
TI Some Pitfalls for Developing Enculturated Conversational Agents
SO HUMAN-COMPUTER INTERACTION, PT III: AMBIENT, UBIQUITOUS AND INTELLIGENT
   INTERACTION
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 13th International Conference on Human-Computer Interaction
CY JUL 19-24, 2009
CL San Diego, CA
DE Embodied Conversational Agents; Cultural Heuristics; Multimodal
   Interaction
ID ENGAGEMENT
AB A review of current agent-based systems exemplifies that a Western perspective is predominant in the field. But as conversational agents focus on rich multimodal interactive behaviors that underlie face-to-face encounters, it is indispensable to incorporate cultural heuristics of such behaviors into the system. In this paper we examine some of the pitfalls that arise in developing such systems.
C1 [Rehm, Matthias; Andre, Elisabeth] Univ Augsburg, Fac Appl Informat, D-8900 Augsburg, Germany.
   [Nakano, Yukiko] Seikei Univ Tokyo, Fac Sci & Tech, Tokyo, Japan.
RP Rehm, M (corresponding author), Univ Augsburg, Fac Appl Informat, D-8900 Augsburg, Germany.
EM rehm@informatik.uni-augsburg.de; andre@informatik.uni-augsburg.de;
   y.nakano@st.seikei.ac.jp
RI Andre, Elisabeth/AAW-4960-2021
FU German Research Foundation (DFG) [RE2619/2-1]; Japan Society for the
   Promotion of Science (JSPS) [19500104]; European Community (EC) in the
   eCIRCUS [IST-4-027656-STP]
FX The work described in this paper was partially supported by the German
   Research Foundation (DFG) with research grant RE2619/2-1, the Japan
   Society for the Promotion of Science (JSPS) with a grant-in-aid for
   scientific research (C) (19500104), and by the European Community (EC)
   in the eCIRCUS project IST-4-027656-STP.
CR ABRILIAN S, 2006, HUMAINE SUMMERSCHOOL
   Argyle M., 1975, BODILY COMMUNICATION
   Aylett R, 2009, P AAMAS
   Caridakis G, 2007, LANG RESOUR EVAL, V41, P367, DOI 10.1007/s10579-007-9057-1
   Cassell J, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P106
   Cassell J., 2000, EMBODIED CONVERSATIO
   CHAFAI NE, 2006, P LREC WORKSH MULT C
   Ekman P., 1992, TELLING LIES CLUES D
   Hall, 1966, HIDDEN DIMENSION
   Hall L, 2005, LECT NOTES COMPUT SC, V3784, P731
   Hofstede GH., 2001, CULTURES CONSEQUENCE
   JIM D, 2007, LNCS, V4722, P45
   Johnson WL, 2007, FRONT ARTIF INTEL AP, V158, P67
   KHALED R, 2006, 7 AUSTR US INT C AUI, P73
   Kipp M, 2007, LECT NOTES ARTIF INT, V4722, P15
   Kluckhohn FR, 1961, VARIATIONS VALUE ORI
   Lacobelli F, 2007, LECT NOTES ARTIF INT, V4722, P57
   Lane H.C., 2008, WORKSHOP CULTURALLY, P35
   Lee J, 2006, LECT NOTES ARTIF INT, V4133, P243
   McNeill D., 1992, HAND MIND WHAT GESTU
   NAKANO Y, 2003, P ASS COMPUTATIONAL
   NAKANO Y, 2005, P AISB 2005 S CONV I
   NAKANO Y, 2009, P HCI INT
   Reeves B., 1996, MEDIA EQUATION PEOPL
   REHM M, 2008, P BRIT HCI
   REHM M, 2008, P INT C AUT AG MULT
   REHM M, 2008, P INT C AUT AG MULT, P1249
   Rehm M, 2007, CONVERSATIONAL INFOR, P69
   Rehm M, 2008, INTERACT COMPUT, V20, P311, DOI 10.1016/j.intcom.2008.02.005
   Rehm M, 2006, LECT NOTES ARTIF INT, V4021, P197
   SCHWARTZ SH, 1995, J CROSS CULT PSYCHOL, V26, P92, DOI 10.1177/0022022195261007
   Ting-Toomey S., 1999, COMMUNICATING CULTUR
NR 32
TC 5
Z9 5
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-02579-2
J9 LECT NOTES COMPUT SC
PY 2009
VL 5612
BP 340
EP +
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Software Engineering; Computer Science,
   Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BKR82
UT WOS:000269034000037
OA Bronze, Green Submitted
DA 2022-08-02
ER

PT C
AU Yalcin, ON
AF Yalcin, Ozge Nilay
GP ACM
TI Modeling Empathy in Embodied Conversational Agents
SO ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON
   MULTIMODAL INTERACTION
LA English
DT Proceedings Paper
CT 20th ACM International Conference on Multimodal Interaction (ICMI)
CY OCT 16-20, 2018
CL Boulder, CO
SP Assoc Comp Machinery, Assoc Comp Machinery SIGCHI, Openstream, Microsoft, Univ Colorado Boulder, Inst Cognit Sci, audEERING
DE empathy; affective computing; embodied conversational agents
ID RECOGNITION; COMPANION; EMOTION
AB This paper is intended to outline the PhD research that is aimed to model empathy in embodied conversational systems. Our goal is to determine the requirements for implementation of an empathic interactive agent and develop evaluation methods that is aligned with the empathy research from various fields. The thesis is composed of three scientific contributions: (i) developing a computational model of empathy, (ii) implementation of the model in embodied conversational agents and (iii) enhance the understanding of empathy in interaction by generating data and build evaluation tools. The paper will give results for the contribution (i) and preliminary results for contribution (ii). Moreover, we will present the future plan for contribution (ii) and (iii).
C1 [Yalcin, Ozge Nilay] Simon Fraser Univ, Sch Interact Arts & Technol, Vancouver, BC, Canada.
RP Yalcin, ON (corresponding author), Simon Fraser Univ, Sch Interact Arts & Technol, Vancouver, BC, Canada.
EM oyalcin@sfu.ca
CR Alm Cecilia Ovesdotter, 2005, P C HUM LANG TECHN E, P579, DOI DOI 10.3115/1220575.1220648
   [Anonymous], [No title captured]
   Argyle M., 2013, BODILY COMMUNICATION
   Asada M, 2015, INT J SOC ROBOT, V7, P19, DOI 10.1007/s12369-014-0253-z
   Batson C Daniel, 2009, THESE THINGS CALLED
   Bellegarda J. R., 2010, P NAACL HLT WORKSH C, P1
   Bevacqua E., 2010, ARTIFICIAL COMPANION, P143
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Boukricha H, 2013, INT CONF AFFECT, P1, DOI 10.1109/ACII.2013.7
   Brave S, 2005, INT J HUM-COMPUT ST, V62, P161, DOI 10.1016/j.ijhcs.2004.11.002
   Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1
   Breazeal L, 2004, DESIGNING SOCIABLE R
   Burleson W., 2004, WORKSH SOC EM INT LE
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Cassell J., 2000, EMBODIED CONVERSATIO
   Cassell J., 1999, PRAGMAT COGNIT, V7, P1, DOI 10.1075/pc.7.1.03cas
   Cassell J., 1999, P SIGCHI C HUM FACT, P520, DOI DOI 10.1145/302979.303150
   Coplan A., 2011, EMPATHY PHILOS PSYCH
   Coplan Amy, 2011, EMPATHY PHILOS PSYCH
   de Waal FBM, 2017, NAT REV NEUROSCI, V18, P498, DOI 10.1038/nrn.2017.72
   EKMAN P, 1979, ANNU REV PSYCHOL, V30, P527, DOI 10.1146/annurev.ps.30.020179.002523
   Jaimes A, 2005, LECT NOTES COMPUT SC, V3766, P1
   Johnson WL, 2000, INT J ARTIFICIAL INT, V11, P47
   Karati Sabyasachi, 2012, Progress in Cryptology - AFRICACRYPT 2012. Proceedings 5th International Conference on Cryptology in Africa, P1, DOI 10.1007/978-3-642-31410-0_1
   Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534
   Leite I, 2014, INT J SOC ROBOT, V6, P329, DOI 10.1007/s12369-014-0227-1
   Lester, 2008, P 7 INT JOINT C AUT, V1, P167
   Lynn  Veronica, 2017, P 2017 C EMP METH NA, P1146
   McQuiggan SW, 2007, INT J HUM-COMPUT ST, V65, P348, DOI 10.1016/j.ijhcs.2006.11.015
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Ochs M, 2012, AUTON AGENT MULTI-AG, V24, P410, DOI 10.1007/s10458-010-9156-z
   OMDAHL BL, 1995, COGNITIVE APPRAISAL
   Paiva A, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2912150
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169
   Pittermann J, 2010, INT J SPEECH TECHNOL, V13, P49, DOI 10.1007/s10772-010-9068-y
   Prendinger H, 2005, APPL ARTIF INTELL, V19, P267, DOI 10.1080/08839510590910174
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Riek LD, 2010, J MULTIMODAL USER IN, V3, P99, DOI 10.1007/s12193-009-0028-2
   Rishe N, 2013, ACM TMIS, V4, P1, DOI [10.1145/2544103, DOI 10.1145/2544103]
   Rodrigues SH, 2015, INTERACT COMPUT, V27, P371, DOI 10.1093/iwc/iwu001
   Salovey P., 1990, IMAGIN COGN PERSONAL, V9, P185, DOI [10.2190/DUGG-P24E-52WK-6CDG, DOI 10.2190/DUGG-P24E-52WK-6CDG]
   Scherer K.R., 2010, BLUEPRINT AFFECTIVE, P47
   Skowron M, 2014, COGN COMPUT, V6, P872, DOI 10.1007/s12559-014-9271-2
   Thiebaux M., 2008, P 7 INT C AUTONOMOUS, V1, P151
   Vertegaal R., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P301
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Wheelwright S, 2006, BRAIN RES, V1079, P47, DOI 10.1016/j.brainres.2006.01.012
   Yalcin Ozge Nilay, 2018, BIOL INSPIRED COGNIT
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 49
TC 1
Z9 1
U1 2
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5692-3
PY 2018
BP 546
EP 550
DI 10.1145/3242969.3264977
PG 5
WC Computer Science, Cybernetics; Computer Science, Theory & Methods;
   Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BL9OE
UT WOS:000457913100079
DA 2022-08-02
ER

PT C
AU Castillo, S
   Hahn, P
   Legde, K
   Cunningham, DW
AF Castillo, Susana
   Hahn, Philipp
   Legde, Katharina
   Cunningham, Douglas W.
GP ACM
TI Personality Analysis of Embodied Conversational Agents
SO 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18)
LA English
DT Proceedings Paper
CT 18th ACM International Conference on Intelligent Virtual Agents (IVA)
CY NOV 05-08, 2018
CL Western Sydney Univ, New Parramatta City Campus, Sydney, AUSTRALIA
SP ACM, ACM SigAI, Wargaming, DXC, Macquarie Univ, MARCS Inst
HO Western Sydney Univ, New Parramatta City Campus
DE Embodied Conversational Agents; personality; multimodal communication
AB People tend to personify machines. Giving machines the ability to actually produce social information can help improve human-machine interactions. Embodied Conversational Agents (ECAs) are virtual software agents that can process and produce speech, facial expressions, gestures and eye gaze, enabling natural, multimodal, human-machine communication. On the one hand, the field of personality psychology provides insights into how we could describe and measure the virtual personality of ECAs. On the other hand, ECAs provide a method to systematically examine how different factors affect the perception of personality. This paper shows that standardized, validated personality questionnaires can be used to evaluate ECAs psychologically, and that state of the art ECAs can manipulate their perceived personality through appearance and behavior.
C1 [Castillo, Susana; Hahn, Philipp; Legde, Katharina; Cunningham, Douglas W.] BTU Cottbus Senftenberg, Cottbus, Germany.
RP Castillo, S (corresponding author), BTU Cottbus Senftenberg, Cottbus, Germany.
EM Susana.Castillo@b-tu.de; Philipp.Hahn@b-tu.de; Katharina.Legde@b-tu.de;
   Douglas.Cunningham@b-tu.de
RI Castillo, Susana/U-6432-2019
OI Castillo, Susana/0000-0003-1245-4758
CR [Anonymous], 1995, C COMP HUM FACT COMP
   Bevacqua E, 2012, J MULTIMODAL USER IN, V6, P27, DOI 10.1007/s12193-012-0094-8
   Cafaro Angelo, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P67, DOI 10.1007/978-3-642-33197-8_7
   Cassell J., 2000, EMBODIED CONVERSATIO
   Cattell H., 2008, SAGE HDB PERSONALITY, P135, DOI [DOI 10.4135/9781849200479.N7, 10.4135/9781849200479.n7]
   Cattell R.B., 1965, SCI ANAL PERSONALITY
   COSTA PT, 1995, J PERS ASSESS, V64, P21, DOI 10.1207/s15327752jpa6401_2
   de Sevin E, 2010, LECT NOTES ARTIF INT, V6356, P187, DOI 10.1007/978-3-642-15892-6_20
   DIGMAN JM, 1990, ANNU REV PSYCHOL, V41, P417, DOI 10.1146/annurev.psych.41.1.417
   Douglas-Cowie E., 2008, P LREC WORKSH CORP R, P1
   ELLSWORTH PC, 1972, J COMMUN, V22, P375, DOI 10.1111/j.1460-2466.1972.tb00164.x
   Eyben F., 2010, USER PROFILED HUMAN
   Eysenck H.J., 1947, DIMENSIONS PERSONALI
   Lee C, 2007, 2007 RO-MAN: 16TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1-3, P793
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   Mullins-Sweatt SN, 2006, ASSESSMENT, V13, P119, DOI 10.1177/1073191106286748
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Oppenheim AN, 1966, QUESTIONNAIRE DESIGN
   Pervin L.A., 2002, SCI PERSONALITY, VSecond
   Schroder M., 2008, 4 INT WORKSH HUM COM
   Schroder M, 2010, ADV HUM-COMPUT INTER, V2010, DOI 10.1155/2010/319406
   Vinayagamoorthy V., 2006, EUROGRAPHICS 2006 ST
   Zibrek K., 2014, P ACM S APPL PERC, P111
NR 23
TC 3
Z9 3
U1 1
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6013-5
PY 2018
BP 227
EP 232
DI 10.1145/3267851.3267853
PG 6
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BO3RU
UT WOS:000511376500034
DA 2022-08-02
ER

PT C
AU Gris, I
AF Gris, Ivan
GP ACM
TI Adaptive Virtual Rapport for Embodied Conversational Agents
SO ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON
   MULTIMODAL INTERACTION
LA English
DT Proceedings Paper
CT 15th ACM International Conference on Multimodal Interaction (ICMI)
CY DEC 09-13, 2013
CL Sydney, AUSTRALIA
SP ACM, Openstream, Natl ICT Australia, ACM SIGCHI
DE Virtual rapport; embodied conversational agents
AB In this paper I describe my research goals and hypotheses regarding human-computer relationships with embodied conversational agents (ECAs). I include important studies of related research that inform and direct my own efforts. I explain the current state and some technical aspects of the ECAs I have contributed to create, and past experiments regarding human-ECA familiarity, ECA design and analysis, and multiparty ECA interaction, including our semi-automated corpora collection techniques, analysis methodology, and their respective results to date. Finally, I conclude with an overall presentation of all current studies I have worked on, and future possibilities for my final dissertation and post-dissertation research related to virtual human-ECA rapport.
C1 [Gris, Ivan] Univ Texas El Paso, Dept Comp Sci, 500 West Univ Ave, El Paso, TX 79968 USA.
RP Gris, I (corresponding author), Univ Texas El Paso, Dept Comp Sci, 500 West Univ Ave, El Paso, TX 79968 USA.
EM igris@miners.utep.edu
CR Baylor AL, 2008, LECT NOTES COMPUT SC, V5208, P208
   BELL RA, 1984, COMMUN MONOGR, V51, P91, DOI 10.1080/03637758409390188
   Beun Robbert-Jan, 2003, P INT C INT
   Bickmore T., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P396
   Bond Paul, 2008, REUTERS
   Bosseler A, 2003, J AUTISM DEV DISORD, V33, P653, DOI 10.1023/B:JADD.0000006002.82367.4f
   Cassell J., 2000, EMBODIED CONVERSATIO
   Cole T, 2004, PERS RELATIONSHIP, V11, P135, DOI 10.1111/j.1475-6811.2004.00075.x
   Desurvire H., 2004, CHI 04 EXT HUM FAC C, P24, DOI DOI 10.1145/985921.986102
   KIPP M, 2006, P INT C INT VIRT AG
   Lixing Huang, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P68, DOI 10.1007/978-3-642-23974-8_8
   Reis HT., 1988, RELATIONSHIPS WELL B, DOI [10.4324/9780203732496-5, DOI 10.4324/9780203732496-5]
   Swartout W, 2010, LECT NOTES ARTIF INT, V6356, P286, DOI 10.1007/978-3-642-15892-6_30
   Tickle-Degnen L., 1987, REV PERSONALITY SOCI, VVolume 9, P113
   Van Rooden, 2007, P WORKSH MULT OUTP G, P105
   Wooldridge M., 1998, Proceedings of the Second International Conference on Autonomous Agents, P385, DOI 10.1145/280765.280867
   Zhang H., MODELING REAL TIME M
NR 17
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-2129-7
PY 2013
BP 341
EP 344
DI 10.1145/2522848.2532190
PG 4
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BF1AZ
UT WOS:000380272900057
DA 2022-08-02
ER

PT J
AU Allouch, M
   Azaria, A
   Azoulay, R
AF Allouch, Merav
   Azaria, Amos
   Azoulay, Rina
TI Conversational Agents: Goals, Technologies, Vision and Challenges
SO SENSORS
LA English
DT Article
DE smart environments; human-agent interaction; conversational agents
ID NATURAL-LANGUAGE GENERATION; OF-THE-ART; CHATBOT; DIALOGUE; CHILDREN;
   REAL
AB In recent years, conversational agents (CAs) have become ubiquitous and are a presence in our daily routines. It seems that the technology has finally ripened to advance the use of CAs in various domains, including commercial, healthcare, educational, political, industrial, and personal domains. In this study, the main areas in which CAs are successful are described along with the main technologies that enable the creation of CAs. Capable of conducting ongoing communication with humans, CAs are encountered in natural-language processing, deep learning, and technologies that integrate emotional aspects. The technologies used for the evaluation of CAs and publicly available datasets are outlined. In addition, several areas for future research are identified to address moral and security issues, given the current state of CA-related technological developments. The uniqueness of our review is that an overview of the concepts and building blocks of CAs is provided, and CAs are categorized according to their abilities and main application domains. In addition, the primary tools and datasets that may be useful for the development and evaluation of CAs of different categories are described. Finally, some thoughts and directions for future research are provided, and domains that may benefit from conversational agents are introduced.
C1 [Allouch, Merav; Azaria, Amos] Ariel Univ, Comp Sci Dept, IL-40700 Ariel, Israel.
   [Azoulay, Rina] Jerusalem Coll Technol, Dept Comp Sci, IL-9116001 Jerusalem, Israel.
RP Azoulay, R (corresponding author), Jerusalem Coll Technol, Dept Comp Sci, IL-9116001 Jerusalem, Israel.
EM merav@g.jct.ac.il; amos.azaria@ariel.ac.il; azrina@g.jct.ac.il
CR Abdellatif A, 2020, EMPIR SOFTW ENG, V25, P1834, DOI 10.1007/s10664-019-09788-5
   Abdul-Kader SA, 2015, INT J ADV COMPUT SC, V6, P72
   Acheampong FA, 2020, ENG REP, V2, DOI 10.1002/eng2.12189
   Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI [10.1016/j.mlwa.2020.100006, DOI 10.1016/J.MLWA.2020.100006]
   Adamopoulou E., 2020, ARTIF INTELL APPL IN
   Adams T, 2017, ARXIV170605143
   Adiwardana D., 2020, HUMAN LIKE OPENDOMAI, DOI DOI 10.3390/healthcare7020056
   Agarwal A, WRITE TWITTER BOT 5
   Agostaro R, 2005, LECT NOTES ARTIF INT, V3673, P381
   Aguilar-Ibanez C., 2018, P 2018 15 INT C ELEC, P1
   Ahmad N.A., 2018, INT J COMPUTER APPL, V181, DOI DOI 10.5120/IJCA2018917606
   Ait-Mlouk A, 2020, IEEE ACCESS, V8, P149220, DOI 10.1109/ACCESS.2020.3016142
   AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   Alizadeh K, LIMITATIONS TWITTER
   Allouch M, 2019, PROC INT C TOOLS ART, P1209, DOI 10.1109/ICTAI.2019.00167
   Allouch M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON THE SCIENCE OF ELECTRICAL ENGINEERING IN ISRAEL (ICSEE)
   Ameixa D., SUBTITLES HUMAN INTE
   [Anonymous], 2015, PROC C EMPIRICAL MET, DOI 10.18653/v1/D15-1199
   [Anonymous], 2018, CHATBOTS WILL TRANSF
   [Anonymous], 2009, NATURAL LANGUAGE PRO
   Arabshahi F, 2021, AAAI CONF ARTIF INTE, V35, P4902
   Asghar N, 2018, LECT NOTES COMPUT SC, V10772, P154, DOI 10.1007/978-3-319-76941-7_12
   Assenmacher D, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120939264
   Azaria A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195577
   Azaria A, 2020, AUTON AGENT MULTI-AG, V34, DOI 10.1007/s10458-019-09425-x
   Azaria A, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2681
   Azevedo Roger, 2012, Intelligent Tutoring Systems. Proceedings 11th International Conference (ITS 2012), P212, DOI 10.1007/978-3-642-30950-2_27
   Azoulay R., 2021, INTELLIGENT SYSTEMS
   Banchs R. E., 2012, P ACL 2012 SYST DEM, P37
   Banerjee S., 2005, P ACL WORKSHOP INTRI, P65
   Bao SQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P85
   Bavaresco R, 2020, COMPUT SCI REV, V36, DOI 10.1016/j.cosrev.2020.100239
   Beck A, 2012, ACM T INTERACT INTEL, V2, DOI 10.1145/2133366.2133368
   Benzeghiba M, 2007, SPEECH COMMUN, V49, P763, DOI 10.1016/j.specom.2007.02.006
   Bhat H.R., 2017, INT J ADV RES COMPUT, V8, P55
   Bird E., 2020, TECHNICAL REPORT PE, P634
   Bloom B.S., 1956, TAXONOMY ED OBJETIVE
   Bocklisch T., 2017, ARXIV171205181
   Borah B., 2018, P INT C COMP INT COM, P84
   Bosker B, HUFFINGTON POST
   Boucenna S, 2014, COGN COMPUT, V6, P722, DOI 10.1007/s12559-014-9276-x
   Breazeal C, 2017, ACMIEEE INT CONF HUM, P1, DOI 10.1145/2909824.3020258
   Bruno Marietto M., 2013, ARXIV201313073091, DOI DOI 10.5121/IJCSES.2013.4301
   Budzianowski P., 2018, P EMNLP 2018, P5016, DOI 10.18653/v1/d18-1547
   Burgoon J.K., 2011, SAGE HDB INTERPERSON, P239, DOI DOI 10.1177/0149206315621146
   Byrne B., 2019, P EMNLP IJCNLP 2019, P4516, DOI 10.18653/v1/d19-1459
   Cai WL, 2021, MACH LEARN, V110, P2389, DOI 10.1007/s10994-021-05983-y
   Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158
   Carfora V, 2020, MULTIMED TOOLS APPL, V79, P35949, DOI 10.1007/s11042-020-09178-w
   Chai YX, 2020, IEEE IJCNN
   Chaves Ana Paula, 2020, ARXIV190402743
   Chen JY, 2020, NEUROCOMPUTING, V416, P125, DOI 10.1016/j.neucom.2018.12.092
   Chkroun M., 2018, WORKSH 32 AAAI C ART
   Chkroun M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196641
   Chkroun M, 2019, INT J HUM-COMPUT INT, V35, P1596, DOI 10.1080/10447318.2018.1557972
   Clark L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300705
   Colby K.M., 1974, ACM SIGART B, V48, P5, DOI [10.1145/1045200.1045202, DOI 10.1145/1045200.1045202]
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Costa A, 2018, IEEE ROMAN, P534, DOI 10.1109/ROMAN.2018.8525747
   Cui L, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P97, DOI 10.18653/v1/P17-4017
   Danescu-Niculescu-Mizil C., 2011, P 2 WORKSH COGN MOD, P76
   Das A, 2017, IEEE I CONF COMP VIS, P2970, DOI 10.1109/ICCV.2017.321
   Delgado Kloos Carlos, 2018, 2018 Learning With MOOCS (LWMOOCS). Proceedings, P27, DOI 10.1109/LWMOOCS.2018.8534591
   Deriu J, 2021, ARTIF INTELL REV, V54, P755, DOI 10.1007/s10462-020-09866-x
   Devlin J., 2018, ARXIV
   Diederich S., 2019, TAXONOMY PLATFORMS C
   Diederich S., 2019, 14 INT C WIRTSCH, P1550
   Do Eun Park, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382948
   Dodge J., 2016, ICLR
   Dong Yu, 2016, AUTOMATIC SPEECH REC
   Donghui Feng, 2006, 2006 International Conference on Intelligent User Interfaces, P171
   Dosilovic FK, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P210, DOI 10.23919/MIPRO.2018.8400040
   Dusek O, 2020, COMPUT SPEECH LANG, V59, P123, DOI 10.1016/j.csl.2019.06.009
   Edwards RA, 2013, MATERN CHILD HLTH J, V17, P1961, DOI 10.1007/s10995-013-1222-0
   Eskenazi M., 2016, 17 ANN M SPEC INT GR, P1, DOI DOI 10.1109/QRS-C.2016.5
   Fadhil A, 2019, METHOD INFORM MED, V58, P9, DOI 10.1055/s-0039-1688757
   Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009
   Ferland L., 2020, P CHI EA 20 EXT ABST, P482, DOI [10.1109/ASRU.2017.8268975, DOI 10.1109/ASRU.2017.8268975]
   Fernandes A., NLP NLU NLG CHATBOTS
   Ferrara E, 2016, COMMUN ACM, V59, P96, DOI 10.1145/2818717
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Folstad A, 2018, LECT NOTES COMPUT SC, V11193, P194, DOI 10.1007/978-3-030-01437-7_16
   Gandhe A, 2018, IEEE W SP LANG TECH, P907, DOI 10.1109/SLT.2018.8639663
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   GEHL RW, 2014, J INCL SCHOLARSH PED, V24, P56
   Ghazvininejad M, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P5110
   Go E, 2019, COMPUT HUM BEHAV, V97, P304, DOI 10.1016/j.chb.2019.01.020
   Graesser A. C., 1999, Cognitive Systems Research, V1, P35, DOI 10.1016/S1389-0417(99)00005-4
   Griol D, 2013, APPL ARTIF INTELL, V27, P759, DOI 10.1080/08839514.2013.835230
   Guo F., 2018, ARXIV180103622
   Ham D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P583
   Harms JG, 2019, IEEE INTERNET COMPUT, V23, P13, DOI 10.1109/MIC.2018.2881519
   He SZ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P199, DOI 10.18653/v1/P17-1019
   Henderson M., 2014, P SIGDIAL 2014, P292
   Hermann KM, 2015, ADV NEUR IN, V28
   High R., 2012, ERA COGNITIVE SYSTEM
   Hill J, 2015, COMPUT HUM BEHAV, V49, P245, DOI 10.1016/j.chb.2015.02.026
   Hien HT, 2018, PROCEEDINGS OF THE NINTH INTERNATIONAL SYMPOSIUM ON INFORMATION AND COMMUNICATION TECHNOLOGY (SOICT 2018), P69, DOI 10.1145/3287921.3287937
   Hobert S., 2019, ICIS 2019 P
   Homburg D., 2019, P 52 HAW INT C SYST
   Hongshen Chen, 2017, ACM SIGKDD Explorations Newsletter, V19, P25, DOI 10.1145/3166054.3166058
   Hoy Matthew B., 2018, Medical Reference Services Quarterly, V37, P81, DOI 10.1080/02763869.2018.1404391
   Hussain Shafquat, 2019, Web, Artificial Intelligence and Network Applications. Proceedings of the Workshops of the 33rd International Conference on Advanced Information Networking and Applications (WAINA-2019). Advances in Intelligent Systems and Computing (927), P946, DOI 10.1007/978-3-030-15035-8_93
   Hutzler D, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE SCIENCE, TECHNOLOGY AND ENGINEERING (SWSTE), P54, DOI 10.1109/SWSTE.2014.16
   Inui N., 2003, P NAT LANG GEN SPOK
   Jianfeng Gao M.G., 2019, ARXIV180908267
   Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147
   Juraska J., 2018, P 2018 C N AM CHAPT, P152, DOI 10.18653/v1/N18-1014
   Kaghyan S., 2018, SOC IMAGING SCI TECH, V2018, P1, DOI 10.2352/ISSN.2470-1173.2018.06.MOBMU-117
   Keneshloo Y, 2020, IEEE T NEUR NET LEAR, V31, P2469, DOI 10.1109/TNNLS.2019.2929141
   Khurana D., 2017, ARXIV170805148
   Kim AY, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/5798684
   Kim J., 2021, P DSTC9 WORKSH ONL
   Klopfenstein L.C., 2018, P INT C INT SCI ST P, P87
   Kollanyi B, 2016, INT J COMMUN-US, V10, P20
   Krishnaswamy N., 2017, P 12 INT C COMP SEM
   Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288
   Lafferty J., 2001, P 18 INT C MACH LEAR, V2001, P282
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lee K., 2019, P INT C HUM COMP INT, P348
   Lee Kyumin, 2011, ICWSM
   Lee SJ, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P64
   Letaief K, 2017, PROC IEEE GLOBAL COM, P1
   Lewis M., 2017, EMNLP
   Li CH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376209
   Li J., 2016, ARXIV160601541, DOI DOI 10.18653/V1/D16-1127
   Li J., 2015, ARXIV PREPRINT ARXIV, P110
   Li JW, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P994
   Li TJJ, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6038, DOI 10.1145/3025453.3025483
   LI X., 2020, INT J MACH LEARN COM, V10, P1, DOI [10.18178/ijmlc.2020.10.4.967, DOI 10.18178/IJMLC.2020.10.4.967]
   Li Y, 2017, P 8 INT JOINT C NAT, P986
   Liao Y., 2020, INT C INT US INT P I, P430, DOI [10.1145/3377325.3377488, DOI 10.1145/3377325.3377488]
   Lin C.-Y, ROUGE PACKAGE AUTOMA
   Lin P., 2020, P AAAI C ARTIFICIAL, P13381
   Lin T., 2017, ARXIVPREPRINT1711027
   Lison P, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P923
   Liu B, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P482, DOI 10.1109/ASRU.2017.8268975
   Liu Chia-Wei, 2016, ARXIV160308023
   Lokman AS, 2019, ADV INTELL SYST, V881, P1012, DOI 10.1007/978-3-030-02683-7_75
   Lopatovska I, 2019, J LIBR INF SCI, V51, P984, DOI 10.1177/0961000618759414
   Lowe R, 2017, ARXIV PREPRINT ARXIV
   Lowe R., 2017, ARXIV150608909
   Luo XM, 2019, MARKET SCI, V38, P937, DOI 10.1287/mksc.2019.1192
   Maria A, GOT ALEXA YOU GOT PO
   Masche J, 2018, ADV INTELL SYST, V629, P212, DOI 10.1007/978-3-319-61911-8_19
   McKee GJ, 2010, AGR ISSUES POLICIES, P1
   McLeod S. A., 2007, SIMPLY PSYCHOL
   McTear M, 2010, HUMAN-CENTRIC INTERFACES FOR AMBIENT INTELLIGENCE, P225, DOI 10.1016/B978-0-12-374708-2.00009-7
   Mikolov T, 2012, IEEE W SP LANG TECH, P234, DOI 10.1109/SLT.2012.6424228
   Moore R.C., 1997, P 5 C APPL NAT LANG, P1
   Mrksic N, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1777, DOI 10.18653/v1/P17-1163
   Na-Young Kim, 2019, [Multimedia-Assisted Language Learning, 멀티미디어 언어교육], V22, P32
   Nadarzynski T, 2019, DIGIT HEALTH, V5, DOI [10.1177/2055207619871808, 10.1177/2055207619827193]
   Navigli R, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5697
   Neerincx MA, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00118
   Nguyen A., 2005, P 10 INT C INT US IN, P137
   Ni L., P INT S KNOWL SYST S, P38
   Nijholt A., 1980, LECT NOTES COMPUTER, VVolume 93
   Nimavat K., 2017, INT J SCI RES DEV, V5, P1019
   Noroozi V., 2020, ARXIV200812335
   Nuruzzaman M, 2018, INT CONF E BUS ENG, P54, DOI 10.1109/ICEBE.2018.00019
   Nuseibeh R., 2018, WHAT IS CHATBOT
   Paladines J, 2020, IEEE ACCESS, V8, P164246, DOI 10.1109/ACCESS.2020.3021383
   Palanica A, 2019, J MED INTERNET RES, V21, DOI 10.2196/12887
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Paschoal L.N., 2019, P 33 BRAZ S SOFTW EN, P57
   Paschoal LN, 2020, PROC FRONT EDUC CONF
   Peca A., 2020, ARXIV200303528
   Pennington J., 2014, P 2014 C EMPIRICAL M, P1532
   Peskov D., 2019, P 2019 C EMP METH NA, P4526
   Peterschmidt D, MAKE TWITTER BOT HOU
   Pradana Aditya, 2017, International Journal of Computer Information Systems and Industrial Management Applications, V9, P265
   Qiu MH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P498, DOI 10.18653/v1/P17-2079
   Radziwill N.M., 2017, ARXIV170404579
   Rajpurkar P., 2016, P 2016 C EMP METH NA, P2383, DOI DOI 10.18653/V1/D16-1264
   Rajpurkar P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P784
   Ramesh K, 2017, COMM COM INF SC, V750, P336, DOI 10.1007/978-981-10-6544-6_31
   Ranoliya BR, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1525, DOI 10.1109/ICACCI.2017.8126057
   Rashkin H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5370
   Rastogi A, 2020, AAAI CONF ARTIF INTE, V34, P8689
   Reiter E., 1997, Natural Language Engineering, P57, DOI 10.1017/S1351324997001502
   Resnik P., 1992, P 14 INT C COMP LING
   Ritter A., 2010, HUMAN LANGUAGE TECHN, P172
   Roccas S, 2002, PERS SOC PSYCHOL B, V28, P789, DOI 10.1177/0146167202289008
   Rosenfeld A, 2019, AUTON AGENT MULTI-AG, V33, P673, DOI 10.1007/s10458-019-09408-y
   Ross C, 2018, STAT-US, V25, P1
   Sadeghipour A, 2011, COGN COMPUT, V3, P419, DOI 10.1007/s12559-010-9082-z
   Sarder M.A., 2018, THESIS U TECHNOLOGY
   Saund E, CONVERSATIONAL AGENT
   Scassellati B, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aat7544
   Schachner T, 2020, J MED INTERNET RES, V22, DOI 10.2196/20701
   Schlesinger A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173889
   Scholten MR, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7351
   Schrading N., P 2015 C EMP METH NA, P2577
   Schuetzler RM, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P283
   Serban I.V., 2017, ARXIV151205742
   Serban I.V., 2017, ARXIV PREPRINT ARXIV
   Serban IV, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3776
   Sharma A, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P194, DOI 10.1145/3442381.3450097
   Singh S, 2000, ADV NEUR IN, V12, P956
   Singh S., 2012, INT J COMPUT APPL, V52, DOI [10.5120/8247-1758, DOI 10.5120/8247-1758]
   Smith E.M., 2020, ARXIV200408449
   Sordoni A., 2015, P 2015 C N AM CHAPT, P196, DOI DOI 10.3115/V1/N15-1020
   Stasaski K, 2020, INNOVATIVE USE OF NLP FOR BUILDING EDUCATIONAL APPLICATIONS, P52
   Stent A., 1999, P 37 ANN M ASS COMP, P183
   Stoner D.J., 2004, SIMULATING MILITARY
   Strickland E, 2019, IEEE SPECTRUM, V56, P24, DOI 10.1109/MSPEC.2019.8678513
   Su PH, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2007
   Subrahmanian VS, 2016, COMPUTER, V49, P38, DOI 10.1109/MC.2016.183
   Takanobu R., 2020, ARXIV200307490, DOI [10.1007/s11431-020-1692-3, DOI 10.1007/S11431-020-1692-3]
   Tao CY, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P722
   Taskbot A.P., 2021, ALEXA PRIZE TASKBOT
   Tellols D, 2020, PATTERN RECOGN LETT, V129, P317, DOI 10.1016/j.patrec.2019.11.035
   Thomas NT, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2740, DOI 10.1109/ICACCI.2016.7732476
   Tiedemann J., 2021, P INT C REC ADV NAT, P237
   Triantafyllidou C., 2020, THESIS U CENTRAL FLO
   Ueno M, 2018, IEEE T LEARN TECHNOL, V11, P415, DOI 10.1109/TLT.2017.2741960
   Valadão Carlos Torturella, 2016, Res. Biomed. Eng., V32, P161, DOI 10.1590/2446-4740.01316
   van Deemter K, 2005, COMPUT LINGUIST, V31, P15, DOI 10.1162/0891201053630291
   Tran VK, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P231
   Vanderborght B, 2012, INTERACT STUD, V13, P348, DOI 10.1075/is.13.3.02van
   Varol Onur, 2017, ARXIV170303107
   Venkatesh A., 2017, P 31 C NEUR INF PROC
   Vishnoi L, 2020, CONVERSATIONAL AGENT
   Volkel ST, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376210
   von Wolff RM, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P95
   Wallace RS, 2009, PARSING TURING TEST, P181, DOI DOI 10.1007/978-1-4020-6710-5_13
   Wang YF, 2013, INT J ADV COMPUT SC, V4, P124
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Williams J.D., 2015, SIGDIAL, P159
   Winkler R, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376781
   Wolska M., 2004, P INT C LANG RES EV, P1007
   Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496
   Xu L, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P7346
   Pham XL, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON EDUCATION AND E-LEARNING (ICEEL 2018), P16, DOI 10.1145/3291078.3291115
   Yalcin ON, 2020, COGN SYST RES, V59, P123, DOI 10.1016/j.cogsys.2019.09.016
   Yan Z, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4618
   Yang W., 2020, ARXIV200505442
   Yang X, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300772
   Yin Z, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2131, DOI 10.1145/3097983.3098148
   Zeng CC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217640
   Zeng G, 2020, EMNLP, P9241
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
   Zhang Y., 2019, ARXIV191100536
   Zhou H, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P730
   Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI [10.1162/coli_a_00368, 10.1162/COLI_a_00368]
   Zhu Q, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P142
NR 248
TC 1
Z9 1
U1 8
U2 8
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD DEC
PY 2021
VL 21
IS 24
AR 8448
DI 10.3390/s21248448
PG 48
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Chemistry; Engineering; Instruments & Instrumentation
GA XY9SU
UT WOS:000737305600001
PM 34960538
OA gold, Green Published
DA 2022-08-02
ER

PT C
AU Griol, D
   Molina, JM
   de Miguel, AS
AF Griol, David
   Manuel Molina, Jose
   Sanchis de Miguel, Araceli
BE Omatu, S
   Bersini, H
   Corchado, JM
   Rodriguez, S
   Pawlewski, P
   Bucciarelli, E
TI The Geranium System: Multimodal Conversational Agents for E-learning
SO DISTRIBUTED COMPUTING AND ARTIFICIAL INTELLIGENCE, 11TH INTERNATIONAL
   CONFERENCE
SE Advances in Intelligent Systems and Computing
LA English
DT Proceedings Paper
CT 11th International Symposium on Distributed Computing and Artificial
   Intelligence (DCAI)
CY JUN 04-06, 2014
CL Salamanca, SPAIN
SP Univ Salamanca, Bioinformat, Intelligent Syst & Educ Technol Res Grp, Ingn Software Avanzado S A, IBM, ICyL, IEEE Syst Man & Cybernet Soc Spain, Asociac Espanola Inteligencia Artificial, Assoc Portuguesa Para Inteligencia Artificial, Ctr Natl Rech Sci, Minist Economia & Competitividad
DE Conversational agents; multimodal interaction; chatbots; speech;
   e-learning
AB Many e-learning applications use conversational agents as means to obtain enhanced pedagogical results such as fostering motivation and engagement, incrementing significant learning and helping in the acquisition of meta-cognitive skills. In this paper, we present Geranium, a multimodal conversational agent that helps children to appreciate and protect their environment. The system, which integrates an interactive chatbot, provides a modular and scalable framework that eases building pedagogic conversational agents that can interact with the students using speech and natural language.
C1 [Griol, David; Manuel Molina, Jose; Sanchis de Miguel, Araceli] Univ Carlos III Madrid, Dept Comp Sci, Leganes 28911, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Avda Univ 30, Leganes 28911, Spain.
EM david.griol@uc3m.es; josemanuel.molina@uc3m.es; araceli.sanchis@uc3m.es
RI Griol, David/L-1258-2014
OI Griol, David/0000-0001-6266-5321
CR CAVAZZA M, 2010, AAMAS, P01629
   Fryer L, 2006, LANG LEARN TECHNOL, V10, P8
   Griol D, 2012, J UNIVERS COMPUT SCI, V18, P2516
   Kerly A, 2008, KNOWL-BASED SYST, V21, P238, DOI 10.1016/j.knosys.2007.11.015
   Pieraccini R, 2012, VOICE IN THE MACHINE: BUILDING COMPUTERS THAT UNDERSTAND SPEECH, P1
   Pinzon CI, 2011, EXPERT SYST APPL, V38, P5486, DOI 10.1016/j.eswa.2010.10.088
   Pon-Barry Heather, 2006, INT J ARTIFICIAL INT, V16, P171
   RODA C., 2001, P BOTSHOW 2001, P1
NR 8
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 2194-5357
BN 978-3-319-07593-8; 978-3-319-07592-1
J9 ADV INTELL SYST
PY 2014
VL 290
BP 219
EP 226
DI 10.1007/978-3-319-07593-8_26
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BB3NJ
UT WOS:000342905800026
OA Green Accepted
DA 2022-08-02
ER

PT J
AU Brahnam, S
   De Angeli, A
AF Brahnam, Sheryl
   De Angeli, Antonella
TI Gender affordances of conversational agents
SO INTERACTING WITH COMPUTERS
LA English
DT Article
DE Sexuality and HCI; LIWC; Gender; Agent abuse; Embodied conversational
   agents; Sex stereotypes
ID SEXUAL-HARASSMENT; PHYSICAL ATTRACTIVENESS; COMPUTER; COMMUNICATION;
   LANGUAGE; STEREOTYPES; SOMETIMES; STUDENTS; ETHICS; WOMEN
AB Conversational agents are attributed humanlike characteristics: in particular, they are often assumed to have a gender. There is evidence that gender sets up expectations that have an impact on user experiences with agents. The objective of this paper is to explore gender affordances of conversational agents. Our examination takes a holistic approach to the analysis of the application of gender stereotypes to nine chatterbots: six embodied (three male and three female), two disembodied (male and female), and a robot embodiment. Building on social psychology research, we test the persistence of gender stereotypes in the selection of conversation topics and in the elicitation of disinhibition and verbal abuse. Our study is based on quantitative textual analysis of interaction logs. A dictionary of English sexual slang and derogatory terms was developed for this study. Results show that gender stereotypes tend to affect interaction more at the relational (style) level then at the referential (content) level of conversation. People attribute negative stereotypes to female-presenting chatterbots more often than they do to male-presenting chatterbots, and female-presenting chatterbots are more often the objects of implicit and explicit sexual attention and swear words. We conclude by calling for a more informed analysis of user interactions that considers the full range of user interactions. (C) 2012 British Informatics Society Limited. All rights reserved.
C1 [Brahnam, Sheryl] Missouri State Univ, Coll Business Adm, Springfield, MO 65804 USA.
   [De Angeli, Antonella] Univ Manchester, Manchester Business Sch, Manchester M13 9PL, Lancs, England.
RP Brahnam, S (corresponding author), Missouri State Univ, Coll Business Adm, 901 S Natl, Springfield, MO 65804 USA.
EM sbrahnam@missouristate.edu; antonella.deange-li@disi.unitn.it
RI De Angeli, Antonella/AAN-6245-2021
FU Missouri State University
FX This research was funded in part by a 2006 Missouri State University
   faculty grant. We wish to thank Wendell Cowart for the use of Talk-Bot
   and some of the embodiments offered on C&C Creations' website. We also
   want to thank Cowart for hosting the agents and collecting the
   interaction logs used in this study.
CR ALLEN BP, 1976, SOC BEHAV PERSONAL, V4, P289, DOI 10.2224/sbp.1976.4.2.289
   AMALBERTI R, 1993, INT J MAN MACH STUD, V38, P547, DOI 10.1006/imms.1993.1026
   [Anonymous], 1996, STEREOTYPES STEREOTY
   Aquino K, 2000, ORGAN SCI, V11, P525, DOI 10.1287/orsc.11.5.525.15205
   Ashmore R. D., 1981, COGNITIVE PROCESS, P5
   Bandura A., 1977, SOCIAL FDN THOUGHT A
   BARTAL D, 1976, SEX ROLES, V2, P123
   Bartneck C, 2008, INTERACT STUD, V9, P397, DOI 10.1075/is.9.3.01edi
   Baumeister RF, 2002, REV GEN PSYCHOL, V6, P166, DOI 10.1037//1089-2680.6.2.166
   BAYLOR AL, 2004, INT TUT SYST MAC AL
   Berger J., 1974, EXPECTATION STATES T, P163
   Bickmore TW, 2010, INTERACT COMPUT, V22, P276, DOI 10.1016/j.intcom.2010.02.001
   Brahnam S., 2005, INT WORKSH AB DARK S
   Brahnam S, 2006, CHI 2006 WORKSH MIS
   Brahnam S, 2008, INTERACT COMPUT, V20, P287, DOI 10.1016/j.intcom.2008.02.001
   Brahnam S, 2009, PSYCHNOLOGY J, V7, P9
   Burgess D, 1999, PSYCHOL PUBLIC POL L, V5, P665, DOI 10.1037//1076-8971.5.3.665
   Carli LL, 1999, J SOC ISSUES, V55, P81, DOI 10.1111/0022-4537.00106
   CARLI LL, 1990, J PERS SOC PSYCHOL, V59, P941, DOI 10.1037/0022-3514.59.5.941
   Carter J., 2000, NEWS GENDER POWER
   Cassell J, 2001, KNOWL-BASED SYST, V14, P55, DOI 10.1016/S0950-7051(00)00102-7
   Cassell J., 1999, CHI 99 PITTSB PA
   Catrambone R, 2004, HUM-COMPUT INT-SPRIN, V7, P239
   Chung C, 2007, FRONT SOC PSYCHOL, P343
   Creed C, 2008, INTERACT STUD, V9, P481, DOI 10.1075/is.9.3.07cre
   Darves C, 2004, HUM-COMPUT INT-SPRIN, V7, P271
   De Angeli A., 2005, INT 2005 WORKSH AB D
   DE ANGELI A., 2001, INT C AFF HUM FACT D
   De Angeli A., 2006, AVI 2006 WORKSH GEND
   De Angeli A, 2008, INTERACT COMPUT, V20, P302, DOI 10.1016/j.intcom.2008.02.004
   De Angeli A, 2009, PSYCHNOLOGY J, V7, P49
   De Angell A., 2005, INT ROM IT
   De Angell A., 2006, CHI MONTR QUEB CAN
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   Denegri-Knott J, 2005, SOC SCI COMPUT REV, V23, P93, DOI 10.1177/0894439304271541
   DeWall CN, 2005, PSYCHOL WOMEN QUART, V29, P396, DOI 10.1111/j.1471-6402.2005.00239.x
   Dill KE, 2008, J EXP SOC PSYCHOL, V44, P1402, DOI 10.1016/j.jesp.2008.06.002
   DINDIA K, 1992, PSYCHOL BULL, V112, P106, DOI 10.1037/0033-2909.112.1.106
   Dix A, 2008, INTERACT COMPUT, V20, P334, DOI 10.1016/j.intcom.2008.02.003
   Dow B., 2006, HDB GENDER COMMUNICA
   Eagly A. H., 1994, EUROPEAN REV SOCIAL, V5, P1, DOI DOI 10.1080/14792779543000002
   Eagly A. H, 1987, SEX DIFFERENCES SOCI
   EAGLY AH, 1991, PSYCHOL BULL, V110, P109, DOI 10.1037/0033-2909.110.1.109
   Epley N, 2007, PSYCHOL REV, V114, P864, DOI 10.1037/0033-295X.114.4.864
   FEINGOLD A, 1992, PSYCHOL BULL, V111, P304, DOI 10.1037/0033-2909.111.2.304
   Fischer Kerstin, 2006, WHAT COMPUTER TALK I
   FONER LN, 1997, P 1 INT C AUT AG AA
   Forlizzi J., 2007, DPPI07
   Francis M E, 1992, Am J Health Promot, V6, P280
   FRIEDMAN H, 1992, PERS SOC PSYCHOL B, V18, P430, DOI 10.1177/0146167292184006
   Gillen B., 1981, PERSONALITY SOCIAL P, V7, P277, DOI [10.1177/014616728172015, DOI 10.1177/014616728172015]
   GOTTSCHALK L, 1995, CONTENT ANAL VERBAL
   Green R, 1997, PERSP SEX, P145
   Grenci RT, 2002, COMMUN ACM, V45, P64, DOI 10.1145/504729.504730
   GUTEK B, 1985, SEX WORKPLACE IMPACT
   Hamilton DL, 1986, PREJUDICE DISCRIMINA, P127
   HAMILTON MC, 1991, PSYCHOL WOMEN QUART, V15, P393, DOI 10.1111/j.1471-6402.1991.tb00415.x
   Heilman M.E., 1979, ORG BEHAV HUMAN DECI, V35, P202
   HEILMAN ME, 1985, ORGAN BEHAV HUM DEC, V35, P202, DOI 10.1016/0749-5978(85)90035-4
   Herring S. C, 2000, COMPUTER PROFESSIONA, V18
   HINSZ VB, 1991, PERS SOC PSYCHOL B, V17, P586, DOI 10.1177/0146167291175014
   Holzwarth M, 2006, J MARKETING, V70, P19, DOI 10.1509/jmkg.70.4.19
   Jackson L. A., 1992, PHYS APPEARANCE GEND
   John BE, 2001, BEHAV INFORM TECHNOL, V20, P329, DOI 10.1080/01449290110081686
   Johnstone A., 1994, INT J HUMAN COMPUTER, V41, P383
   Joinson Adam, 1998, PSYCHOL INTERNET INT, P43
   Kannabiran G., 2011, CHI 2011 SESS HCI AL
   Keating C. F., 2002, FACIAL ATTRACTIVENES, P153
   Khan R., 2009, INT
   Khoo PN, 2004, PSYCHOL WOMEN QUART, V28, P204, DOI 10.1111/j.1471-6402.2004.00137.x
   KIESLER S, 1992, ORGAN BEHAV HUM DEC, V52, P96, DOI 10.1016/0749-5978(92)90047-B
   Kim Y, 2005, INT J ARTIFICIAL INT, V15, P95, DOI [DOI 10.1007/BF02504991, DOI 10.1145/1067860.1067867]
   KLECK RE, 1975, J PERS SOC PSYCHOL, V31, P107, DOI 10.1037/h0076243
   Konijn E. A., 2008, MEDIATED INTERPERSON
   Kramer N., 2003, MC WORKSH 2003 ASS M
   LAKOFF R, 1975, LANGUAGE WOMENS PLAC
   Langlois JH, 2000, PSYCHOL BULL, V126, P390, DOI 10.1037/0033-2909.126.3.390
   LAPLANTE MN, 1980, J SEX RES, V16, P338, DOI 10.1080/00224498009551090
   LARKIN J, 1994, FEM PSYCHOL, V4, P213, DOI 10.1177/0959353594042002
   Laurel B, 1990, ART HUMAN COMPUTER I
   Lea M., 1992, CONTEXTS COMPUTER ME
   Lee EJ, 2003, INT J HUM-COMPUT ST, V58, P347, DOI 10.1016/S1071-5819(03)00009-0
   LESTER JC, 1997, COSMO LIFE LIKE ANIM
   lmaz Manuel, 2007, DESIGNING BLENDS CON
   LOTT B, 1982, SIGNS, V8, P296, DOI 10.1086/493964
   Maes P, 1999, COMMUN ACM, V42, P81, DOI 10.1145/295685.295716
   Martin KA, 1998, AM SOCIOL REV, V63, P494, DOI 10.2307/2657264
   MAULDIN ML, 1994, P AAAI 94 C SEATTL
   MCBREEN H, 2000, P 4 INT C AUT AG
   Miksch S., 1997, P 1 INT C AUT AG
   MOREL MA, 1989, STRUCTURE MULTIMODAL, P323
   Moreno K. N., 2002, AAAI S PERS AG CAP C
   Moreno R, 2001, COGNITION INSTRUCT, V19, P177, DOI 10.1207/S1532690XCI1902_02
   Morishima Y., 2002, EFFECTS VOICE UNPUB
   Morton H, 2004, HUM COM INT, V7, P293
   MULAC A, 1986, COMMUN MONOGR, V53, P115, DOI 10.1080/03637758609376131
   Murnen SK, 2000, SEX ROLES, V43, P1, DOI 10.1023/A:1007007727370
   Nass C, 1997, J APPL SOC PSYCHOL, V27, P864, DOI 10.1111/j.1559-1816.1997.tb00275.x
   Nass C, 2000, EMBODIED CONVERSATIONAL AGENTS, P374
   Niculescu A., 2010, 2010 INT C US SCI EN
   NORMAN, 2022, DESIGN EVERYDAY THIN
   NORRIS P, 1997, WOMEN MEDIA POLITICS
   Nowak Kristine L., 2005, J COMPUT-MEDIAT COMM, V11, P153, DOI [DOI 10.1111/J.1083-6101.2006.TB00308.X, 10.1111/j.1083-6101.2006.tb00308]
   O'Sullivan LF, 1998, J SEX RES, V35, P234, DOI 10.1080/00224499809551938
   OVIATT S, 1995, COMPUT SPEECH LANG, V9, P19, DOI 10.1006/csla.1995.0002
   Patzer G. L., 2006, POWER PARADOX PHYS A
   Pelachaud C, 2009, PHILOS T R SOC B, V364, P3539, DOI 10.1098/rstb.2009.0186
   Pennebaker J.W., 2007, DEV PSYCH PROP LIWC2
   Pennebaker JW, 2003, ANNU REV PSYCHOL, V54, P547, DOI 10.1146/annurev.psych.54.101601.145041
   Postmes T, 1998, COMMUN RES, V25, P689, DOI 10.1177/009365098025006006
   POWELL GN, 1986, SEX ROLES, V14, P9, DOI 10.1007/BF00287844
   Reeves B., 1996, MEDIA EQUATION PEOPL
   REILLY ME, 1986, SEX ROLES, V15, P333, DOI 10.1007/BF00287976
   Richards M., 1984, INT
   Rickenberg R., 2000, P CHI 2000 C HUM FAC
   Ridgeway C. L., 2004, PSYCHOL GENDER
   Roter DL, 2002, JAMA-J AM MED ASSOC, V288, P756, DOI 10.1001/jama.288.6.756
   Ruttkay Z., 2004, BROWS TRUST EVALUATI
   Schneider D, 2004, PSYCHOL STEREOTYPING
   Sengers P., 2006, CHI 06 QUEB CAN
   SHNEIDERMAN B, 1983, COMPUTER, V16, P57
   Spence J.T., 1978, MASCULINITY FEMININI
   Sproull L, 1996, HUM-COMPUT INTERACT, V11, P97, DOI 10.1207/s15327051hci1102_1
   STECKLER NA, 1985, J APPL PSYCHOL, V70, P157, DOI 10.1037/0021-9010.70.1.157
   Stevenage SV, 1999, BRIT J PSYCHOL, V90, P221, DOI 10.1348/000712699161369
   Struckman-Johnson C, 2003, J SEX RES, V40, P76, DOI 10.1080/00224490309552168
   Svenaeus F, 2000, LANGUAGE GENDER, V3, P3
   Svennevig Jan., 2000, GETTING ACQUAINTED C
   Thimbleby H, 2008, INTERACT COMPUT, V20, P338, DOI 10.1016/j.intcom.2008.02.006
   Timmerman G, 2003, SEX ROLES, V48, P231, DOI 10.1023/A:1022821320739
   Trautschold M., 2012, IPHONE 4S MADE SIMPL, P179
   Turkle S, 1997, LIFE SCREEN
   Veletsianos G, 2008, INTERACT COMPUT, V20, P292, DOI 10.1016/j.intcom.2008.02.007
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Weizenbaum J., 1976, COMPUTER POWER HUMAN
   Welle B., 2007, MANAGING SOCIAL ETHI, P135
   WEST C, 1998, LANGUAGE GENDER READ
   Whitby B, 2008, INTERACT COMPUT, V20, P326, DOI 10.1016/j.intcom.2008.02.002
   Williams J. E., 1990, MEASURING SEX STEREO
   WILLIAMS JE, 1975, SEX ROLES, V1, P327
   Williams JE, 1999, SEX ROLES, V40, P513, DOI 10.1023/A:1018831928829
   WILSON DW, 1978, J SOC PSYCHOL, V104, P313, DOI 10.1080/00224545.1978.9924081
   Wolf Naomi, 1991, BEAUTY MYTH IMAGES B
   Zdenek S., 2003, AI & Society, V17, P340, DOI 10.1007/s00146-003-0284-8
   Zimbardo P.G., 1969, NEBRASKA S MOTIVATIO, V17, P237
NR 145
TC 33
Z9 34
U1 1
U2 42
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 0953-5438
EI 1873-7951
J9 INTERACT COMPUT
JI Interact. Comput.
PD MAY
PY 2012
VL 24
IS 3
BP 139
EP 153
DI 10.1016/j.intcom.2012.05.001
PG 15
WC Computer Science, Cybernetics; Ergonomics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 973HO
UT WOS:000306351000004
DA 2022-08-02
ER

PT J
AU Bailey, JO
   Patel, B
   Gurari, D
AF Bailey, Jakki O.
   Patel, Barkha
   Gurari, Danna
TI A Perspective on Building Ethical Datasets for Children's Conversational
   Agents
SO FRONTIERS IN ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE conversational agents; artificial intelligence; children; ethic;
   datasets
ID MEDIA; STEREOTYPES; FUTURE; WOMEN
AB Artificial intelligence (AI)-powered technologies are becoming an integral part of youth's environments, impacting how they socialize and learn. Children (12 years of age and younger) often interact with AI through conversational agents (e.g., Siri and Alexa) that they speak with to receive information about the world. Conversational agents can mimic human social interactions, and it is important to develop socially intelligent agents appropriate for younger populations. Yet it is often unclear what data are curated to power many of these systems. This article applies a sociocultural developmental approach to examine child-centric intelligent conversational agents, including an overview of how children's development influences their social learning in the world and how that relates to AI. Examples are presented that reflect potential data types available for training AI models to generate children's conversational agents' speech. The ethical implications for building different datasets and training models using them are discussed as well as future directions for the use of social AI-driven technology for children.
C1 [Bailey, Jakki O.; Patel, Barkha; Gurari, Danna] Univ Texas Austin, Sch Informat, Austin, TX 78712 USA.
RP Bailey, JO (corresponding author), Univ Texas Austin, Sch Informat, Austin, TX 78712 USA.
EM j.bailey@ischool.utexas.edu
CR Baig E.C., 2019, US TODAY 1015
   Baker RSJD, 2010, INT J HUM-COMPUT ST, V68, P223, DOI 10.1016/j.ijhcs.2009.12.003
   Beneteau E, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300473
   Biswas G., 2010, RES PRACT TECH ENHAN, V05, P123, DOI 10.1142/S1793206810000839
   Bligh MC, 2012, J APPL SOC PSYCHOL, V42, P560, DOI 10.1111/j.1559-1816.2011.00781.x
   Bond BJ, 2018, MEDIA PSYCHOL, V21, P457, DOI 10.1080/15213269.2017.1416295
   Brunick KL, 2016, J CHILD MEDIA, V10, P181, DOI 10.1080/17482798.2015.1127839
   Cai Z., 2011, P 3 IEEE INT C INT C, P429
   Calvert SL, 2008, FUTURE CHILD, V18, P205, DOI 10.1353/foc.0.0001
   Calvert SL, 2020, CHILD DEV, V91, P1491, DOI 10.1111/cdev.13341
   Chase CC, 2009, J SCI EDUC TECHNOL, V18, P334, DOI 10.1007/s10956-009-9180-4
   Cheng Y, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P337, DOI 10.1145/3202185.3202749
   Chu E, 2017, IEEE DATA MINING, P829, DOI 10.1109/ICDM.2017.100
   D'Mello SK, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2682899
   Druga S, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P595, DOI 10.1145/3078072.3084330
   Faruqui M., 2015, P 2015 C N AM CHAPTE, P1606
   Forsyth CM, 2019, COMPUT ASSIST LANG L, V32, P398, DOI 10.1080/09588221.2018.1517126
   Forsyth CM, 2015, LECT NOTES ARTIF INT, V9112, P135, DOI 10.1007/978-3-319-19773-9_14
   Fox SE, 2010, CHILD DEV, V81, P28, DOI 10.1111/j.1467-8624.2009.01380.x
   Garg Radhika, 2020, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V4, DOI 10.1145/3381002
   Gleason TR, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00255
   Grabe S, 2008, PSYCHOL BULL, V134, P460, DOI 10.1037/0033-2909.134.3.460
   Harriger JA, 2018, BODY IMAGE, V26, P78, DOI 10.1016/j.bodyim.2018.06.004
   Harriger JA, 2010, SEX ROLES, V63, P609, DOI 10.1007/s11199-010-9868-1
   Hill F., 2016, INT C LEARNING REPRE, P1
   Kory-Westlund JM, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00081
   Le, 2014, ADV NEURAL INFORM PR, P3104
   Mediacom, 2018, CONN KIDS TREND WATC
   Montgomery KC, 2017, PEDIATRICS, V140, pS117, DOI 10.1542/peds.2016-1758O
   Noble S. U, 2018, ALGORITHMS OPPRESSIO
   Oertel C, 2013, J MULTIMODAL USER IN, V7, P19, DOI 10.1007/s12193-012-0108-6
   Paranjape B, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P71, DOI 10.1145/3267851.3267894
   Pecune F, 2019, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT INTERACTION (HAI'19), P135, DOI 10.1145/3349537.3351899
   Ramasubramanian S, 2011, COMMUN RES, V38, P497, DOI 10.1177/0093650210384854
   Reyes I., 2018, 14 S US PRIV SEC SOU
   Rideout V., 2019, COMMON SENSE CENSUS, P1
   Rogoff B., 1990, APPRENTICESHIP THINK
   Rosenwald M. S., 2017, WASH POST
   Ryokai K, 2003, J COMPUT ASSIST LEAR, V19, P195, DOI 10.1046/j.0266-4909.2003.00020.x
   Shaban H., 2018, WASHINGTON POST 0524
   Smith LB, 2003, TRENDS COGN SCI, V7, P343, DOI 10.1016/S1364-6613(03)00156-6
   Tahmahkera Dustin, 2008, AM INDIAN Q, V32, P324
   Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501
   Tukachinsky R, 2015, J SOC ISSUES, V71, P186, DOI 10.1111/josi.12104
   Vinyals O, 2015, COMPUTER SCI
   Ward LM, 2004, DEV PSYCHOL, V40, P284, DOI 10.1037/0012-1649.40.2.284
   Westlund JMK, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00295
NR 47
TC 0
Z9 0
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2624-8212
J9 FRONT ARTIF INTELL
JI Front. Artif. Intell.
PY 2021
VL 4
AR 637532
DI 10.3389/frai.2021.637532
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YT9WW
UT WOS:000751704800049
PM 34056578
OA gold, Green Published
DA 2022-08-02
ER

PT J
AU Siemon, D
   Ahmad, R
   Harms, H
   de Vreede, T
AF Siemon, Dominik
   Ahmad, Rangina
   Harms, Henrik
   de Vreede, Triparna
TI Requirements and Solution Approaches to Personality-Adaptive
   Conversational Agents in Mental Health Care
SO SUSTAINABILITY
LA English
DT Article
DE conversational agents; Personality-Adaptive Conversational Agents;
   mental health care
ID ELIZA
AB Artificial intelligence (AI) technologies enable Conversational Agents (CAs) to perform highly complex tasks in a human-like manner and may help people cope with anxiety to improve their mental health and well-being. To support patients with their mental well-being in an authentic way, CAs need to be imbued with human-like behavior, such as personality. In this paper we cover an innovative form of CA, so-called Personality-Adaptive Conversational Agents (PACAs) that automatically infer users' personality traits and adapt accordingly to their personality. We empirically investigate their benefits and caveats in mental health care. The results of our study show that PACAs can be beneficial for mental health support, but they also raise concerns about trust and privacy issues. We present a set of relevant requirements for designing PACAs and provide solution approaches that can be followed when designing and implementing PACAs for mental health care.
C1 [Siemon, Dominik] LUT Univ, Sch Engn Sci, Dept Software Engn, Lappeenranta 53850, Finland.
   [Ahmad, Rangina; Harms, Henrik] Tech Univ Carolo Wilhelmina Braunschweig, Inst Business Informat Syst, Chair Informat Management, D-38106 Braunschweig, Germany.
   [de Vreede, Triparna] Univ S Florida, Muma Coll Business, Sch Informat Syst & Management, Tampa, FL 33620 USA.
RP Ahmad, R (corresponding author), Tech Univ Carolo Wilhelmina Braunschweig, Inst Business Informat Syst, Chair Informat Management, D-38106 Braunschweig, Germany.
EM dominik.siemon@lut.fi; rangina.ahmad@tu-braunschweig.de;
   henrik.harms@tu-braunschweig.de; tdevreede@usf.edu
OI Siemon, Dominik/0000-0002-2945-4167
FU Open Access Publication Funds of the Technische Universitat Braunschweig
FX We acknowledge support by the Open Access Publication Funds of the
   Technische Universitat Braunschweig.
CR Ahmad R, P 54 HAW INT C SYST, P4043
   Ahmad R, P 55 HAW INT C SYST
   Ahmad R, 2022, INFORM SYST FRONT, DOI 10.1007/s10796-022-10254-9
   Alqahtani F, 2022, BEHAV INFORM TECHNOL, DOI 10.1080/0144929X.2022.2031296
   Babbie ER., 2015, PRACTICE SOCIAL RES
   Blashki G, 2019, ARTIF INTELL
   Brendel AB, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13041974
   Caron C., 2021, NEW YORK TIMES
   Chaveesuk S, 2019, PROCEEDINGS OF 9TH INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND MANAGEMENT (ICICM 2019), P181, DOI 10.1145/3357419.3357441
   Cho P.J, 2020, ARTIF INTELL MED, P151
   Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009
   Ferrucci DA, 2012, IBM J RES DEV, V56, DOI 10.1147/JRD.2012.2184356
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Gastermann B, 2015, PROCEDIA ENGINEER, V100, P574, DOI 10.1016/j.proeng.2015.01.407
   Gnewuch U., 2017, ICIS 2017 P KARLSR S
   Graham SA, 2020, PSYCHIAT RES, V284, DOI 10.1016/j.psychres.2019.112732
   Greenleaf G, 2012, GLOBAL DATA PRIVACY
   HEISER JF, 1979, J PSYCHIAT RES, V15, P149, DOI 10.1016/0022-3956(79)90008-6
   Hwang S, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13063173
   IBM Watson Personality Insights, PERS MOD
   Kerr IR., 2003, U OTT LAW TECHNOL J, V1, P285
   Kitsios F, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13042025
   Kocaballi AB, 2020, J MED INTERNET RES, V22, DOI 10.2196/15823
   Luxton D, 2021, INNOVATIONS GLOBAL M, P489
   Luxton DD, 2014, ARTIF INTELL MED, V62, P1, DOI 10.1016/j.artmed.2014.06.004
   Mairesse F, 2010, USER MODEL USER-ADAP, V20, P227, DOI 10.1007/s11257-010-9076-2
   Mateos-Sanchez M, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14031520
   MAYER RC, 1995, ACAD MANAGE REV, V20, P709, DOI 10.2307/258792
   Mayring P., 2014, QUALITATIVE CONTENT
   McCrae RR, 1997, AM PSYCHOL, V52, P509, DOI 10.1037/0003-066X.52.5.509
   McTear M. F., 2016, CONVERSATIONAL INTER, V6, P102
   NASS C, 1995, INT J HUM-COMPUT ST, V43, P223, DOI 10.1006/ijhc.1995.1042
   Natale S, 2019, NEW MEDIA SOC, V21, P712, DOI 10.1177/1461444818804980
   Phelps J, 2000, J PUBLIC POLICY MARK, V19, P27, DOI 10.1509/jppm.19.1.27.16941
   Porra J, 2020, INFORM SYST FRONT, V22, P533, DOI 10.1007/s10796-019-09969-z
   Rights (OCR), SUMM HIPAA PRIV RUL
   Robert L, 2020, SSRN, P3528496, DOI [10.48550/arXiv.2001.11777, DOI 10.48550/ARXIV.2001.11777]
   Saetra HS, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13041738
   Shah J. J., 2003, Design Studies, V24, P111, DOI 10.1016/S0142-694X(02)00034-0
   Shaw G.B, 2008, PYGMALION MAJOR BARB
   Shum HY, 2018, FRONT INFORM TECH EL, V19, P10, DOI 10.1631/FITEE.1700826
   Siemon D., P 24 PAC AS C INF SY
   Statista AU-Falle Aufgrund Psychischer, ERKR DEUTSCHL NACH G
   Stevovic J, SECURE HLTH DATA CLO
   Sun LF, 2020, IEEE ACCESS, V8, P101079, DOI 10.1109/ACCESS.2020.2997831
   Ta V, 2020, J MED INTERNET RES, V22, DOI 10.2196/16235
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Winston PH., 1992, ARTIF INTELL
   Woebot Health, 2022, WOEB HLTH FOR ORG
   Xie T., 2022, P 55 HAW INT C SYST
NR 51
TC 0
Z9 0
U1 4
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2071-1050
J9 SUSTAINABILITY-BASEL
JI Sustainability
PD APR
PY 2022
VL 14
IS 7
AR 3832
DI 10.3390/su14073832
PG 18
WC Green & Sustainable Science & Technology; Environmental Sciences;
   Environmental Studies
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Science & Technology - Other Topics; Environmental Sciences & Ecology
GA 0K2CL
UT WOS:000780601200001
OA Green Published, gold
DA 2022-08-02
ER

PT J
AU Griol, D
   Molina, JM
   de Miguel, AS
AF Griol, David
   Manuel Molina, Jose
   Sanchis de Miguel, Araceli
TI Developing multimodal conversational agents for an enhanced e-learning
   experience
SO ADCAIJ-ADVANCES IN DISTRIBUTED COMPUTING AND ARTIFICIAL INTELLIGENCE
   JOURNAL
LA English
DT Article
DE Conversational agents; Multimodal interaction; Chatbots; Speech;
   E-learning
ID INTELLIGENT TUTORING SYSTEM; DIALOGUE; MODEL
AB Conversational agents have become a strong alternative to enhance educational systems with intelligent communicative capabilities, provide motivation and engagement, and increment significant learning and helping in the acquisition of meta-cognitive skills. In this paper, we present Geranium, a multimodal conversational agent that helps children to appreciate and protect their environment. The system, which integrates an interactive chatbot, has been developed by means of a modular and scalable framework that eases building pedagogic conversational agents that can interact with the students using speech and natural language.
C1 [Griol, David; Manuel Molina, Jose; Sanchis de Miguel, Araceli] Carlos III Univ Madrid, Comp Sci Dept, Avda Univ 30, Leganes 28911, Spain.
RP Griol, D (corresponding author), Carlos III Univ Madrid, Comp Sci Dept, Avda Univ 30, Leganes 28911, Spain.
EM david.griol@uc3m.es; josemanuel.molina@uc3m.es; araceli.sanchis@uc3m.es
RI Molina, JOSE/B-1956-2008
OI Molina, JOSE/0000-0002-7484-7357
FU MINECO [TEC2012-37832-C02-01]; CICYT [TEC2011-28626-C02-02]; CAM
   CONTEXTS [S2009/TIC-1485]
FX This work was supported in part by Projects MINECO TEC2012-37832-C02-01,
   CICYT TEC2011-28626-C02-02, CAM CONTEXTS (S2009/TIC-1485).
CR ABU-SHAWAR B, 2007, P CORP LING, P1
   ALEVEN V., 2004, P 7 INT C INT TUT SY, P443, DOI DOI 10.1007/978-3-540-30139-4_42
   [Anonymous], 2003, ARTIFICIAL INTELLIGE, P341
   Bickmore T., 2003, PHD THESIS
   CASSELL J., 2001, EMBODIED DIALOG SYST
   CAVAZZA M, 2010, AAMAS, P01629
   Chou CY, 2003, COMPUT EDUC, V40, P255, DOI 10.1016/S0360-1315(02)00130-6
   Corchado JM, 2008, COMPUT INTELL-US, V24, P77, DOI 10.1111/j.1467-8640.2008.00323.x
   DE ROSIS F., 2005, P AISB 05 VIRT SOC C, P1
   DOMINGUEZ K, 2014, VOICEXML 31 SUCCESS
   Dowding J., 2006, AIAA FALL S ANN INF
   Edlund J, 2008, SPEECH COMMUN, V50, P630, DOI 10.1016/j.specom.2008.04.002
   FORBUS K-D., CYCLEPAD ARTICULATE, P347
   Fryer L, 2006, LANG LEARN TECHNOL, V10, P8
   Gorostiza JF, 2011, ROBOT AUTON SYST, V59, P1102, DOI 10.1016/j.robot.2011.07.009
   Graesser A. C., 2001, INT J ARTIFICIAL INT, V12, P23
   Graesser AC, 2005, IEEE T EDUC, V48, P612, DOI 10.1109/TE.2005.856149
   Gratch J, 2002, IEEE INTELL SYST, V17, P54, DOI 10.1109/MIS.2002.1024753
   GRIGORIADOU M., 2003, P WORKSH LEARN MOD R, P238
   Griol D, 2012, J UNIVERS COMPUT SCI, V18, P2516
   Griol D, 2012, J AMB INTEL SMART EN, V4, P183, DOI 10.3233/AIS-2012-0145
   Heffernan NT, 2003, FR ART INT, V97, P115
   Kerly A., 2008, P AI, P169
   Kerly A, 2008, LECT NOTES COMPUT SC, V5091, P132
   Kerly A, 2008, KNOWL-BASED SYST, V21, P238, DOI 10.1016/j.knosys.2007.11.015
   Kidd Cory D, 2004, P 9 INT C INT US INT, P78, DOI [10.1145/964442.964458, DOI 10.1145/964442.964458]
   Kumar R, 2011, IEEE T LEARN TECHNOL, V4, P21, DOI 10.1109/TLT.2010.41
   Latham A, 2012, COMPUT EDUC, V59, P95, DOI 10.1016/j.compedu.2011.11.001
   LI S., 2007, P AAAI SPRING S INT, P71
   Litman D. J., 2004, HLT NAACL, P5
   LOPEZ-COZAR R., 2005, MULTILINGUAL MULTIMO
   MARSELLA S-C., 2003, ARTIFICIAL INTELLIGE
   Matsui T, 2003, SPRINGER TRAC ADV RO, V6, P307
   McTear M., 2013, VOICE APPL DEV ANDRO
   MCTEAR M-F, 2004, SPOKEN DIALOG TECHNO
   Mostow J., 2012, P INT S AUT DET ERR, P43
   Nakano M, 2011, KNOWL-BASED SYST, V24, P248, DOI 10.1016/j.knosys.2010.08.004
   Pieraccini R, 2012, VOICE IN THE MACHINE: BUILDING COMPUTERS THAT UNDERSTAND SPEECH, P1
   Pieraccini R, 2009, LECT NOTES ARTIF INT, V5729, P3
   Pinzon CI, 2011, EXPERT SYST APPL, V38, P5486, DOI 10.1016/j.eswa.2010.10.088
   Pon-Barry Heather, 2006, INT J ARTIFICIAL INT, V16, P171
   RODA C., 2001, P BOTSHOW 2001, P1
   Rodriguez S, 2011, EXPERT SYST APPL, V38, P13005, DOI 10.1016/j.eswa.2011.04.101
   ROSE C-P., 2001, P COGN SCI SOC, P869
   VAQUERO C, 2006, 4 JORNADAS TECNOLOGI, P321
   Wang N, 2008, LECT NOTES COMPUT SC, V5091, P270
   Wang YH, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P1023
   Williams JD, 2007, COMPUT SPEECH LANG, V21, P393, DOI 10.1016/j.csl.2006.06.008
   [No title captured]
NR 49
TC 1
Z9 1
U1 2
U2 3
PU EDICIONES UNIV SALAMANCA
PI SALAMANCA
PA APARTADO DE CORREOS 325, SALAMANCA, 00000, SPAIN
SN 2255-2863
J9 ADCAIJ-ADV DISTRIB C
JI ADCAIJ-Adv. Distrib. Computing Artif. Intell. J.
PY 2014
VL 3
IS 1
BP 13
EP 25
DI 10.14201/ADCAIJ2014381326
PG 13
WC Computer Science, Artificial Intelligence
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA V9W7K
UT WOS:000422593900002
OA Green Published, Green Submitted, gold
DA 2022-08-02
ER

PT C
AU Santhanam, S
   Karduni, A
   Shaikh, S
AF Santhanam, Sashank
   Karduni, Alireza
   Shaikh, Samira
GP ACM
TI Studying the Effects of Cognitive Biases in Evaluation of Conversational
   Agents
SO PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING
   SYSTEMS (CHI'20)
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 25-30, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGCHI
DE Conversational agents; Human evaluation; Anchoring bias; Experiment
   design
ID NATURAL-LANGUAGE GENERATION; JUDGMENT
AB Humans quite frequently interact with conversational agents. The rapid advancement in generative language modeling through neural networks has helped advance the creation of intelligent conversational agents. Researchers typically evaluate the output of their models through crowdsourced judgments, but there are no established best practices for conducting such studies. Moreover, it is unclear if cognitive biases in decision-making are affecting crowdsourced workers' judgments when they undertake these tasks. To investigate, we conducted a between-subjects study with 77 crowdsourced workers to understand the role of cognitive biases, specifically anchoring bias, when humans are asked to evaluate the output of conversational agents. Our results provide insight into how best to evaluate conversational agents. We find increased consistency in ratings across two experimental conditions may be a result of anchoring bias. We also determine that external factors such as time and prior experience in similar tasks have effects on inter-rater consistency.
C1 [Santhanam, Sashank; Karduni, Alireza; Shaikh, Samira] Univ North Carolina Charlotte, Charlotte, NC 28223 USA.
RP Santhanam, S (corresponding author), Univ North Carolina Charlotte, Charlotte, NC 28223 USA.
EM ssanthal@uncc.edu; akarduni@uncc.edu; samirashaikh@uncc.edu
FU Defense Advanced Research Projects Agency (DARPA) [FA8650-18-C7881]
FX This work was supported by the Defense Advanced Research Projects Agency
   (DARPA) under Contract No FA8650-18-C7881. All statements of fact,
   opinion or conclusions contained herein are those of the authors and
   should not be construed as representing the official views or policies
   of AFRL, DARPA, or the U.S. Government. We thank the anonymous reviewers
   for the helpful feedback.
CR Amos A, 2001, PSYCHOL SCI
   [Anonymous], 2018, COGNITIVE BIASES VIS
   [Anonymous], 2011, J SOCIO-ECON, DOI [10.1016/j.socec.2010.10.008, DOI 10.1016/J.SOCEC.2010.10.008]
   Ariely D, 2003, Q J ECON, V118, P73, DOI 10.1162/00335530360535153
   Asghar N, 2018, LECT NOTES COMPUT SC, V10772, P154, DOI 10.1007/978-3-319-76941-7_12
   Bago B, 2017, COGNITION, V158, P90, DOI 10.1016/j.cognition.2016.10.014
   Bahdanau D., 2014, ARXIV14090473
   Banerjee S, 2005, P ACL WORKSH INTR EX, P65
   Bangalore S, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P464
   Bard EG, 1996, LANGUAGE, V72, P32, DOI 10.2307/416793
   Baumgartner H, 2001, J MARKETING RES, V38, P143, DOI 10.1509/jmkr.38.2.143.18840
   Belz A., 2010, P 6 INT NAT LANG GEN, P7
   Belz Anja, 2011, P 49 ANN M ASS COMP, P230
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Berzak Y., 2016, P 2016 C EMP METH NA, P2215, DOI [10.18653/v1/D16-1239, DOI 10.18653/V1/D16-1239]
   Bordes A., 2016, ARXIV160507683
   Chen HS, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1653, DOI 10.1145/3178876.3186077
   Cho I, 2017, IEEE CONF VIS ANAL, P116, DOI 10.1109/VAST.2017.8585665
   Colby K, 1975, ARTIFICIAL PARANOIA
   Dimara E., 2018, IEEE T VIS COMPUT GR
   Dinan E., 2018, ABS181101241 CORR
   Dziri Nouha, 2019, P 2019 C N AM CHAPT, V1, P3806, DOI 10.18653/v1/N19-1381
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Ghazvininejad M, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P5110
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hoffman M, 2010, ADV NEURAL INFORM PR, P856, DOI DOI 10.5555/2997189.2997285
   Kahneman, 2016, 36 HEURISTICS BIASES, P171
   Kahneman D, 2003, AM PSYCHOL, V58, P697, DOI 10.1037/0003-066X.58.9.697
   KAHNEMAN D, 1972, COGNITIVE PSYCHOL, V3, P430, DOI 10.1016/0010-0285(72)90016-3
   Keim Daniel, 2019, ACM CHI 2019 WORKSH
   Kincaid J. P., 1975, I SIMULATION TRAININ, P56
   Kiritchenko S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P465, DOI 10.18653/v1/P17-2074
   Knight, 2002, P ACL 02 DEM, P102
   Kosara R, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P102, DOI 10.1109/BELIV.2018.8634392
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Le, 2014, ADV NEURAL INFORM PR, P3104
   Li J., 2016, P 2016 C N AM CHAPT, P110, DOI DOI 10.18653/V1/N16-1014
   Li J., 2016, ARXIV160601541, DOI DOI 10.18653/V1/D16-1127
   Li X., 2017, P 8 INT JOINT C NAT, V1, P733
   Lin C.-Y., 2004, P ACL WORKSH TEXT SU
   Lipton Z, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P5237
   Liu Chia-Wei, 2016, ARXIV160308023
   Lowe R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1116, DOI 10.18653/v1/P17-1103
   Mathewson, 2018, ARXIV181101063, DOI [10.18653/v1/w19-4103, DOI 10.18653/V1/W19-4103]
   McRoy S. W., 2003, Natural Language Engineering, P381, DOI 10.1017/S1351324903003188
   Mei HY, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3252
   Novikova J., 2017, EMNLP, P2231
   Novikova Jekaterina, 2018, P 2018 C N AM CHAPT, V2, P72
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Schuman H.W., 1996, QUESTIONS ANSWERS AT
   See A, 2019, P 2019 C N AM CHAPT, V1, P1702, DOI DOI 10.18653/V1/N19-1170.HTTPS://WWW.ACLWEB.0RG/ANTH0L0GY/N19-1170
   Serban IV, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3776
   Tian ZL, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P231, DOI 10.18653/v1/P17-2036
   TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124
   van Deemter K, 2005, COMPUT LINGUIST, V31, P15, DOI 10.1162/0891201053630291
   Vaswani A, 2017, ADV NEUR IN, V30
   Venkatesh A, 2018, ARXIV PREPRINT ARXIV
   Vinyals O, 2015, COMPUTER SCI
   Walker MA, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P271
   Wang DL, 2019, 2019 22ND INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION 2019), DOI 10.1145/3290605.3300831
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wesslen R, 2019, COMPUT GRAPH FORUM, V38, P161, DOI 10.1111/cgf.13679
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
NR 63
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-6708-0
PY 2020
DI 10.1145/3313831.3376318
PG 13
WC Computer Science, Cybernetics; Computer Science, Information Systems;
   Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS1SG
UT WOS:000695432500191
OA Green Submitted
DA 2022-08-02
ER

PT J
AU Van Pinxteren, MME
   Pluymaekers, M
   Lemmink, JGAM
AF Van Pinxteren, Michelle M. E.
   Pluymaekers, Mark
   Lemmink, Jos G. A. M.
TI Human-like communication in conversational agents: a literature review
   and research agenda
SO JOURNAL OF SERVICE MANAGEMENT
LA English
DT Review
DE Conversational agents; Communicative behaviors; Relational outcomes;
   Chatbot; Avatar; Robot
ID RELATIONSHIP QUALITY; CUSTOMER EXPERIENCE; SOCIAL PRESENCE; ROBOT;
   TECHNOLOGY; TRUST; ANTHROPOMORPHISM; EMPLOYEES; DESIGN; STYLE
AB Purpose Conversational agents (chatbots, avatars and robots) are increasingly substituting human employees in service encounters. Their presence offers many potential benefits, but customers are reluctant to engage with them. A possible explanation is that conversational agents do not make optimal use of communicative behaviors that enhance relational outcomes. The purpose of this paper is to identify which human-like communicative behaviors used by conversational agents have positive effects on relational outcomes and which additional behaviors could be investigated in future research. Design/methodology/approach This paper presents a systematic review of 61 articles that investigated the effects of communicative behaviors used by conversational agents on relational outcomes. A taxonomy is created of all behaviors investigated in these studies, and a research agenda is constructed on the basis of an analysis of their effects and a comparison with the literature on human-to-human service encounters. Findings The communicative behaviors can be classified along two dimensions: modality (verbal, nonverbal, appearance) and footing (similarity, responsiveness). Regarding the research agenda, it is noteworthy that some categories of behaviors show mixed results and some behaviors that are effective in human-to-human interactions have not yet been investigated in conversational agents. Practical implications By identifying potentially effective communicative behaviors in conversational agents, this study assists managers in optimizing encounters between conversational agents and customers. Originality/value This is the first study that develops a taxonomy of communicative behaviors in conversational agents and uses it to identify avenues for future research.
C1 [Van Pinxteren, Michelle M. E.; Pluymaekers, Mark] Zuyd Univ Appl Sci, Dept Int Relationship Management, Maastricht, Netherlands.
   [Lemmink, Jos G. A. M.] Maastricht Univ, Sch Business & Econ, Dept Mkt & Supply Chain Management, Maastricht, Netherlands.
RP Van Pinxteren, MME (corresponding author), Zuyd Univ Appl Sci, Dept Int Relationship Management, Maastricht, Netherlands.
EM michelle.vanpinxteren@zuyd.nl; mark.pluymaekers@zuyd.nl;
   j.lemmink@maastrichtuniversity.nl
FU Province of Limburg, The Netherlands [SAS-2014-02207]
FX This research was supported by the Province of Limburg, The Netherlands,
   under grant number SAS-2014-02207.
CR Akesson M, 2014, J SERV MANAGE, V25, P677, DOI 10.1108/JOSM-01-2013-0016
   ANDERSON E, 1992, J MARKETING RES, V29, P18, DOI 10.2307/3172490
   Wood JA, 2006, J PERS SELL SALES M, V26, P197, DOI 10.2753/PSS0885-3134260206
   [Anonymous], 2015, ACM T INTERACTIVE IN
   [Anonymous], 2000, J SERV MARK, DOI DOI 10.1108/08876040010341008
   Bailenson JN, 2005, PSYCHOL SCI, V16, P814, DOI 10.1111/j.1467-9280.2005.01619.x
   Bainbridge WA, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P701, DOI 10.1109/ROMAN.2008.4600749
   Baron NS, 2015, INFORM SOC, V31, P257, DOI 10.1080/01972243.2015.1020211
   Bartneck C, 2007, 2007 RO-MAN: 16TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1-3, P367
   Bartneck C, 2009, INT J SOC ROBOT, V1, P195, DOI 10.1007/s12369-009-0013-7
   Bergmann Kirsten, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P126, DOI 10.1007/978-3-642-33197-8_13
   Bickmore T., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P396
   Boles JS, 2000, J BUS RES, V48, P75, DOI 10.1016/S0148-2963(98)00078-2
   Bolton RN, 2018, J SERV MANAGE, V29, P776, DOI 10.1108/JOSM-04-2018-0113
   Botanalytics, 2018, TOP IND DRIV CHATB I
   Brandtzaeg PB., 2018, INTERACTIONS, V25, P38, DOI 10.1145/3236669
   Brandtzaeg PB, 2017, LECT NOTES COMPUT SC, V10673, P377, DOI 10.1007/978-3-319-70284-1_30
   Broadbent E, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0072589
   Byrne D, 1997, J SOC PERS RELAT, V14, P417, DOI 10.1177/0265407597143008
   Caic M, 2018, J SERV MANAGE, V29, P178, DOI 10.1108/JOSM-07-2017-0179
   Canevello A, 2010, J PERS SOC PSYCHOL, V99, P78, DOI 10.1037/a0018186
   Cassell J, 2000, COMMUN ACM, V43, P50, DOI 10.1145/355112.355123
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   Cassell J., 2003, USER MODELLING USER, V13, P1
   Cassell J., 2001, AI MAG, V22, P4, DOI DOI 10.1609/AIMAG.V22I4.1593
   Coupland N., 1991, CONTEXTS ACCOMMODATI, P1, DOI [10.1017/CBO9780511663673, DOI 10.1017/CBO9780511663673.001]
   Cowell AJ, 2005, INT J HUM-COMPUT ST, V62, P281, DOI 10.1016/j.ijhcs.2004.11.008
   CRONIN JJ, 1994, J MARKETING, V58, P125, DOI 10.2307/1252256
   CROSBY LA, 1990, J MARKETING, V54, P68, DOI 10.2307/1251817
   Dabholkar PA, 2003, INT J SERV IND MANAG, V14, P59, DOI 10.1108/09564230310465994
   De Keyser A, 2019, J SERV MANAGE, V30, P156, DOI 10.1108/JOSM-03-2018-0082
   De Ruyter K., 2000, J SERV RES-US, P276
   De Wulf K, 2001, J MARKETING, V65, P33, DOI 10.1509/jmkg.65.4.33.18386
   Derrick DC, 2014, COMPUT HUM BEHAV, V33, P39, DOI 10.1016/j.chb.2013.12.027
   Duffy BR, 2003, ROBOT AUTON SYST, V42, P177, DOI 10.1016/S0921-8890(02)00374-3
   Epley N, 2007, PSYCHOL REV, V114, P864, DOI 10.1037/0033-295X.114.4.864
   Everett J., 2017, WHY ARE WE RELUCTANT
   Fryer L, 2006, LANG LEARN TECHNOL, V10, P8
   Giles H, 2016, COMMUNICATION ACCOMMODATION THEORY: NEGOTIATING PERSONAL RELATIONSHIPS AND SOCIAL IDENTITIES ACROSS CONTEXTS, P1
   Goffman Erving, 1979, SEMIOTICA, V25, P1, DOI DOI 10.1515/SEMI.1979.25.1-2.1
   Gratch J, 2007, LECT NOTES COMPUT SC, V4552, P286
   Gremler, 2002, J SERV RES-US, V4, P230, DOI [10.1177/1094670502004003006, DOI 10.1177/1094670502004003006]
   Gremler D. D., 2000, J SERV RES-US, V3, P82
   Gremler DD, 2008, J RETAILING, V84, P308, DOI 10.1016/j.jretai.2008.07.001
   Groom V, 2009, INT J HUM-COMPUT ST, V67, P842, DOI 10.1016/j.ijhcs.2009.07.001
   Hale J, 2016, SCI REP-UK, V6, DOI 10.1038/srep35295
   Hampes W.P., 2010, EUROPES J PSYCHOL, V6, P131
   Hoffman G, 2014, ACMIEEE INT CONF HUM, P1, DOI 10.1145/2559636.2559660
   Holmqvist J, 2017, J BUS RES, V72, P114, DOI 10.1016/j.jbusres.2016.10.005
   Holtgraves TM, 2007, COMPUT HUM BEHAV, V23, P2163, DOI 10.1016/j.chb.2006.02.017
   Ireland ME, 2011, PSYCHOL SCI, V22, P39, DOI 10.1177/0956797610392928
   Julia Fink, 2012, ANTHROPOMORPHISM HUM, P199, DOI [10.1007/978-3-642-34103-8_20, DOI 10.1007/978-3-642-34103-8_20]
   Kanda T, 2007, AUTON ROBOT, V22, P87, DOI 10.1007/s10514-006-9007-6
   Kaptein M, 2011, AI SOC, V26, P261, DOI 10.1007/s00146-010-0304-4
   Keeling K, 2010, J BUS RES, V63, P793, DOI 10.1016/j.jbusres.2008.12.015
   Kim C, 2012, COMPUT HUM BEHAV, V28, P1663, DOI 10.1016/j.chb.2012.04.004
   Klein J, 2002, INTERACT COMPUT, V14, P119, DOI 10.1016/S0953-5438(01)00053-4
   Konijn E.A, 2008, ACM T COMPUT INTERAC, V17, P1, DOI [10.1145/1746259.1746261, DOI 10.1145/1746259.1746261]
   Kramer NC, 2007, LECT NOTES ARTIF INT, V4722, P238
   Kulms P, 2014, LECT NOTES ARTIF INT, V8637, P250, DOI 10.1007/978-3-319-09767-1_32
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lariviere B, 2017, J BUS RES, V79, P238, DOI 10.1016/j.jbusres.2017.03.008
   Lecy J. D., 2012, REPRESENTATIVE LIT R, DOI 10.2139/ssrn.1992601
   Lee KM, 2006, J COMMUN, V56, P754, DOI 10.1111/j.1460-2466.2006.00318.x
   Lee KM, 2006, INT J HUM-COMPUT ST, V64, P962, DOI 10.1016/j.ijhcs.2006.05.002
   Lee MK, 2010, ACMIEEE INT CONF HUM, P203, DOI 10.1109/HRI.2010.5453195
   Lester J., 2004, PRACTICAL HDB INTERN
   Li MN, 2015, INT J INFORM MANAGE, V35, P229, DOI 10.1016/j.ijinfomgt.2014.12.004
   Lian J.-W., 2018, WHY IS SELF SERVICE
   Lin CY, 2017, J SERV MANAGE, V28, P107, DOI 10.1108/JOSM-08-2015-0251
   Luo J. T., 2006, J SERV MARK, V20, P112, DOI [10.1108/08876040610657048, DOI 10.1108/08876040610657048]
   Maisel NC, 2008, PERS RELATIONSHIP, V15, P317, DOI 10.1111/j.1475-6811.2008.00201.x
   Makarem SC, 2009, J SERV MARK, V23, P134, DOI 10.1108/08876040910955143
   Marinova D, 2017, J SERV RES-US, V20, P29, DOI 10.1177/1094670516679273
   McBreen HM, 2001, IEEE T SYST MAN CY A, V31, P394, DOI 10.1109/3468.952714
   McTear M., 2016, CONVERSATIONAL INTER, P283
   Meuter ML, 2005, J MARKETING, V69, P61, DOI 10.1509/jmkg.69.2.61.60759
   Mirnig N, 2017, ACMIEEE INT CONF HUM, P211, DOI 10.1145/3029798.3038337
   Moliner MA, 2009, J SERV MANAGE, V20, P76, DOI 10.1108/09564230910936869
   Morgan B, 2017, FORBES
   MORGAN RM, 1994, J MARKETING, V58, P20, DOI 10.2307/1252308
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   NASS C, 1995, INT J HUM-COMPUT ST, V43, P223, DOI 10.1006/ijhc.1995.1042
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nass C., 1996, IEEE SPECTRUM, V34, P9
   Niculescu Andreea I., 2019, 9th International Workshop on Spoken Dialogue System Technology. Lecture Notes in Electrical Engineering (LNEE 579), P285, DOI 10.1007/978-981-13-9443-0_25
   Nowak Kristine L., 2005, J COMPUT-MEDIAT COMM, V11, P153, DOI [DOI 10.1111/J.1083-6101.2006.TB00308.X, 10.1111/j.1083-6101.2006.tb00308]
   Packard G., 2014, CAN I HELP YOU IMPAC, P14
   Paiva A, 2005, APPL ARTIF INTELL, V19, P235, DOI 10.1080/08839510590910165
   Palmatier RW, 2006, J MARKETING, V70, P136, DOI 10.1509/jmkg.70.4.136
   Parasuraman R, 2004, COMMUN ACM, V47, P51, DOI 10.1145/975817.975844
   Parise S, 1999, COMPUT HUM BEHAV, V15, P123, DOI 10.1016/S0747-5632(98)00035-1
   Polani, 2017, MOT CATB AR TAK CUST
   Portela M, 2017, 8TH INTERNATIONAL CONFERENCE ON COMMUNITIES AND TECHNOLOGIES (C&T 2017), P100, DOI 10.1145/3083671.3083676
   Powers A, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P158
   Qiu LY, 2010, INT J HUM-COMPUT ST, V68, P669, DOI 10.1016/j.ijhcs.2010.05.005
   Radziwill N. M., 2017, EVALUATING QUALITY C
   Reis HT, 2007, PERS RELATIONSHIP, V14, P1, DOI 10.1111/j.1475-6811.2006.00139.x
   Richards D, 2014, INT J HUM-COMPUT ST, V72, P460, DOI 10.1016/j.ijhcs.2014.01.005
   Rust RT, 2014, MARKET SCI, V33, P206, DOI 10.1287/mksc.2013.0836
   Salem Maha, 2011, Social Robotics. Proceedings Third International Conference (ICSR 2011), P31, DOI 10.1007/978-3-642-25504-5_4
   Salem M, 2013, INT J SOC ROBOT, V5, P313, DOI 10.1007/s12369-013-0196-9
   Siegel M, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2563, DOI 10.1109/IROS.2009.5354116
   Sirdeshmukh D, 2002, J MARKETING, V66, P15, DOI 10.1509/jmkg.66.1.15.18449
   Sjobergh J, 2009, LECT NOTES ARTIF INT, V5447, P306
   Specht N, 2007, INT J SERV IND MANAG, V18, P534, DOI 10.1108/09564230710826287
   Stanton C, 2014, LECT NOTES ARTIF INT, V8755, P330, DOI 10.1007/978-3-319-11973-1_34
   Strait M, 2014, ACMIEEE INT CONF HUM, P479, DOI 10.1145/2559636.2559670
   Swan JE, 1999, J BUS RES, V44, P93, DOI 10.1016/S0148-2963(97)00244-0
   TAJFEL H, 1974, SOC SCI INFORM, V13, P65, DOI 10.1177/053901847401300204
   Tay BTC, 2016, COMPUT HUM BEHAV, V60, P19, DOI 10.1016/j.chb.2016.01.042
   Torrey C, 2013, ACMIEEE INT CONF HUM, P275, DOI 10.1109/HRI.2013.6483599
   Turner J. C., 2012, THEORIES SOCIAL PSYC, P399, DOI DOI 10.4135/9781446249222.N46
   Tzeng JY, 2004, INT J HUM-COMPUT ST, V61, P319, DOI 10.1016/j.ijhcs.2004.01.002
   van den Brule R, 2014, INT J SOC ROBOT, V6, P519, DOI 10.1007/s12369-014-0231-5
   van Doorn J, 2017, J SERV RES-US, V20, P43, DOI 10.1177/1094670516679272
   Vieira A., 2008, J CUSTOMER BEHAV, V7, P269, DOI DOI 10.1362/147539208X386833
   von der Putten AM, 2010, COMPUT HUM BEHAV, V26, P1641, DOI 10.1016/j.chb.2010.06.012
   Wang LC, 2007, J MARKETING, V71, P143, DOI 10.1509/jmkg.71.3.143
   Waytz A, 2014, J EXP SOC PSYCHOL, V52, P113, DOI 10.1016/j.jesp.2014.01.005
   Wirtz J, 2018, J SERV MANAGE, V29, P907, DOI 10.1108/JOSM-04-2018-0119
   Wolfswinkel JF, 2013, EUR J INFORM SYST, V22, P45, DOI 10.1057/ejis.2011.51
NR 122
TC 26
Z9 26
U1 33
U2 126
PU EMERALD GROUP PUBLISHING LTD
PI BINGLEY
PA HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN 1757-5818
EI 1757-5826
J9 J SERV MANAGE
JI J. Serv. Manage.
PD MAR 9
PY 2020
VL 31
IS 2
SI SI
BP 203
EP 225
DI 10.1108/JOSM-06-2019-0175
EA JUN 2020
PG 23
WC Management
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA NW7TQ
UT WOS:000541953800001
OA Bronze
DA 2022-08-02
ER

PT J
AU Bin Sawad, A
   Narayan, B
   Alnefaie, A
   Maqbool, A
   Mckie, I
   Smith, J
   Yuksel, B
   Puthal, D
   Prasad, M
   Kocaballi, AB
AF Bin Sawad, Abdullah
   Narayan, Bhuva
   Alnefaie, Ahlam
   Maqbool, Ashwaq
   Mckie, Indra
   Smith, Jemma
   Yuksel, Berkan
   Puthal, Deepak
   Prasad, Mukesh
   Kocaballi, A. Baki
TI A Systematic Review on Healthcare Artificial Intelligent Conversational
   Agents for Chronic Conditions
SO SENSORS
LA English
DT Review
DE conversational agents; dialogue systems; relational agents; chatbot
ID ASSISTANTS
AB This paper reviews different types of conversational agents used in health care for chronic conditions, examining their underlying communication technology, evaluation measures, and AI methods. A systematic search was performed in February 2021 on PubMed Medline, EMBASE, PsycINFO, CINAHL, Web of Science, and ACM Digital Library. Studies were included if they focused on consumers, caregivers, or healthcare professionals in the prevention, treatment, or rehabilitation of chronic diseases, involved conversational agents, and tested the system with human users. The search retrieved 1087 articles. Twenty-six studies met the inclusion criteria. Out of 26 conversational agents (CAs), 16 were chatbots, seven were embodied conversational agents (ECA), one was a conversational agent in a robot, and another was a relational agent. One agent was not specified. Based on this review, the overall acceptance of CAs by users for the self-management of their chronic conditions is promising. Users' feedback shows helpfulness, satisfaction, and ease of use in more than half of included studies. Although many users in the studies appear to feel more comfortable with CAs, there is still a lack of reliable and comparable evidence to determine the efficacy of AI-enabled CAs for chronic health conditions due to the insufficient reporting of technical implementation details.
C1 [Bin Sawad, Abdullah; Alnefaie, Ahlam; Yuksel, Berkan; Prasad, Mukesh; Kocaballi, A. Baki] Univ Technol Sydney, Fac Engn & IT, Sch Comp Sci, Sydney, NSW 2007, Australia.
   [Narayan, Bhuva; Mckie, Indra] Univ Technol Sydney, Fac Arts & Social Sci, Sch Commun, Sydney, NSW 2007, Australia.
   [Maqbool, Ashwaq] Univ Sydney, Fac Med & Hlth, Sch Publ Hlth, Sydney, NSW 2007, Australia.
   [Smith, Jemma] Univ Technol Sydney, Fac Engn & IT, Sch Biomed Engn, Sydney, NSW 2007, Australia.
   [Puthal, Deepak] Khalifa Univ, Dept Elect Engn & Comp Sci, POB 127788, Abu Dhabi, U Arab Emirates.
RP Puthal, D (corresponding author), Khalifa Univ, Dept Elect Engn & Comp Sci, POB 127788, Abu Dhabi, U Arab Emirates.
EM abdullahhatima.binsawad-1@student.uts.edu.au; bhuva.narayan@uts.edu.au;
   ahlam.alnefaie@student.uts.edu.au; amaq6135@uni.syndey.edu.au;
   indra.mckie@uts.edu.au; jemma.smith@student.uts.edu.au;
   berkan.yuksel@student.uts.edu.au; deepak.puthal@ieee.org;
   mukesh.prasad@uts.edu.au; baki.kocaballi@uts.edu.au
RI ; Narayan, Bhuva/M-4044-2015; Puthal, Deepak/P-8667-2017
OI Bin Sawad, Abdullah/0000-0002-0200-617X; Prasad,
   Mukesh/0000-0002-7745-9667; Narayan, Bhuva/0000-0001-8852-5589; Puthal,
   Deepak/0000-0002-8332-278X; Alnefaie, Ahlam/0000-0002-1172-902X
CR Australian Institute of Health and Welfare, 2018, 3 3 CHRON COND CAUS, V15
   Azzini Ivano, 2003, Stud Health Technol Inform, V95, P146
   Baptista S, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/17038
   Beaudry J, 2019, J PEDIATR NURS, V49, P85, DOI 10.1016/j.pedn.2019.09.004
   Bickmore TW, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P119, DOI 10.1145/3267851.3267908
   Bickmore TW, 2010, INTERACT COMPUT, V22, P289, DOI 10.1016/j.intcom.2009.12.001
   Bickmore TW, 2010, INTERACT COMPUT, V22, P276, DOI 10.1016/j.intcom.2010.02.001
   Bott N, 2019, J MED INTERNET RES, V21, DOI 10.2196/13440
   Chaix B, 2019, JMIR CANCER, V5, DOI 10.2196/12856
   Coffey S, 2017, CHILD ADOL PSYCH CL, V26, P105, DOI 10.1016/j.chc.2016.07.012
   Coiera E, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0066-9
   Darcy A, 2020, JAMA-J AM MED ASSOC, V324, P2444, DOI 10.1001/jama.2020.21509
   Dunkel-Jackson SM, 2012, RES AUTISM SPECT DIS, V6, P65, DOI 10.1016/j.rasd.2011.06.004
   Dworkin M, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/10211
   Easton K, 2019, J MED INTERNET RES, V21, DOI 10.2196/12996
   Fadhil A, 2019, METHOD INFORM MED, V58, P9, DOI 10.1055/s-0039-1688757
   Ferrand J, 2020, J MED INTERNET RES, V22, DOI 10.2196/19018
   Greer S, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/15018
   Griffin A.C, 2021, AMIA ANN S P, P504
   Hauser-Ulrich S, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/15806
   Hebbar A, 2017, 2017 THIRD IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P251, DOI 10.1109/ICRCICN.2017.8234515
   Hyeyoung Ryu, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3415223
   Inkster B, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/12106
   Kang J, 2021, PRACT RADIAT ONCOL, V11, P74, DOI 10.1016/j.prro.2020.06.001
   Kocaballi AB, 2020, J MED INTERNET RES, V22, DOI 10.2196/15823
   Kramer LL, 2020, J MED INTERNET RES, V22, DOI 10.2196/14058
   Kumar SS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3383749
   Kvedar JC, 2016, NAT BIOTECHNOL, V34, P239, DOI 10.1038/nbt.3495
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Liberati A, 2009, ANN INTERN MED, V151, pW65, DOI [10.1371/journal.pmed.1000100, 10.7326/0003-4819-151-4-200908180-00136, 10.1136/bmj.b2700]
   Lobo J, 2017, INT J E-HEALTH MED C, V8, P21, DOI 10.4018/IJEHMC.2017100102
   Ly KH, 2017, INTERNET INTERV, V10, P39, DOI 10.1016/j.invent.2017.10.002
   McGreevey JD, 2020, JAMA-J AM MED ASSOC, V324, P552, DOI 10.1001/jama.2020.2724
   Miner AS, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0280-0
   Miner AS, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00746
   Neerincx MA, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00118
   O'Hara DM, 2008, J TELEMED TELECARE, V14, P150, DOI 10.1258/jtt.2008.003016
   Pereira J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1237-1
   Philip P, 2017, SCI REP-UK, V7, DOI 10.1038/srep42656
   Piau A, 2019, INT J MED INFORM, V128, P18, DOI 10.1016/j.ijmedinf.2019.05.013
   Puskar K, 2011, J PSYCHOSOC NURS MEN, V49, P22, DOI 10.3928/02793695-20110705-01
   Puthal D, 2019, J PARALLEL DISTR COM, V124, P60, DOI 10.1016/j.jpdc.2018.10.007
   Puthal D, 2016, PROCEEDINGS OF 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS; IEEE 14TH INTERNATIONAL CONFERENCE ON SMART CITY; IEEE 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1218, DOI [10.1109/HPCC-SmartCity-DSS.2016.0170, 10.1109/HPCC-SmartCity-DSS.2016.48]
   Puthal D, 2013, INT CONF CONNECT VEH, P887, DOI [10.1109/ICCVE.2013.6799921, 10.1109/ICCVE.2013.122]
   Rehman UU, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072216
   Richards D, 2018, IEEE J BIOMED HEALTH, V22, P1699, DOI 10.1109/JBHI.2017.2782210
   Safi Z, 2020, J MED INTERNET RES, V22, DOI 10.2196/19127
   Sahoo B., 2012, INT J COMPUT APPL, V44, P43
   Schachner T, 2020, J MED INTERNET RES, V22, DOI 10.2196/20701
   Schroeder J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173972
   Sebastian J, 2017, COMPUT HUM BEHAV, V73, P479, DOI 10.1016/j.chb.2017.03.071
   Sezgin E, 2020, TRANSL BEHAV MED, V10, P606, DOI 10.1093/tbm/ibz141
   Shamekhi A, 2018, INT CONF PER COMP, P108, DOI 10.1145/3240925.3240940
   Stephens TN, 2019, TRANSL BEHAV MED, V9, P440, DOI 10.1093/tbm/ibz043
   Tielman ML, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0771-y
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
NR 56
TC 0
Z9 0
U1 7
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD APR
PY 2022
VL 22
IS 7
AR 2625
DI 10.3390/s22072625
PG 20
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Chemistry; Engineering; Instruments & Instrumentation
GA 0L2OL
UT WOS:000781319200001
PM 35408238
OA Green Published, gold
DA 2022-08-02
ER

PT S
AU Gnjatovic, M
   Borovac, B
AF Gnjatovic, Milan
   Borovac, Branislav
BE Esposito, A
   Jain, LC
TI Toward Conscious-Like Conversational Agents
SO TOWARD ROBOTIC SOCIALLY BELIEVABLE BEHAVING SYSTEMS, VOL II: MODELING
   SOCIAL SIGNALS
SE Intelligent Systems Reference Library
LA English
DT Article; Book Chapter
DE Consciousness; Socially believable behaviour; Conversational agents;
   Human-machine interaction; Focus tree
ID AUTONOMY; EMOTION; ROBOTS
AB Although considerable effort has been already devoted to studying various aspects of human-machine interaction, we are still a long way from developing socially believable conversational agents. This paper identifies some of the main causes of the current state in the field: (i) socially believable behaviour of a technical system is misinterpreted as a functional requirement, rather than a qualitative, (ii) the currently prevalent statistical approaches cannot address research problems of managing human-machine interaction that require some sort of contextual analysis, and (iii) the structure of human-machine interaction is unjustifiably reduced to a task structure. In addition, we propose a way to address these pitfalls. We consider the capability of a technical system to simulate fundamental features of human consciousness as one of the key desiderata to perform socially believable behaviour. In line with this, the paper discusses the possibilities for the computational realization of (iv) unified interpretation, (v) learning through interaction, and (vi) context-dependent perception in the context of human-machine interaction.
C1 [Gnjatovic, Milan] John Naisbitt Univ, Grad Sch Comp Sci, Bulevar Umetnosti 29, Belgrade 11070, Serbia.
   [Gnjatovic, Milan] Univ Novi Sad, Fac Tech Sci, Dositeja Obradovica 6, Novi Sad 21000, Serbia.
   [Borovac, Branislav] Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradovica 6, Novi Sad 21000, Serbia.
RP Gnjatovic, M (corresponding author), John Naisbitt Univ, Grad Sch Comp Sci, Bulevar Umetnosti 29, Belgrade 11070, Serbia.
EM milangnjatovic@yahoo.com; borovac@uns.ac.rs
CR Alexandersson J, 1997, P EUROSPEECH 97 RHOD, P2231
   Bacchiani Michiel, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P230, DOI 10.1109/ICASSP.2014.6853592
   Bernsen NO, 2009, HUM-COMPUT INT-SPRIN, P1
   Bilange E, 2000, STRUCTURE MULTIMODAL
   Bledowski C, 2010, BEHAV BRAIN RES, V214, P172, DOI 10.1016/j.bbr.2010.05.041
   BOEHM BW, 1988, COMPUTER, V21, P61, DOI 10.1109/2.59
   Brouwer H, 2012, BRAIN RES, V1446, P127, DOI 10.1016/j.brainres.2012.01.055
   Casadio M, 2009, CLIN REHABIL, V23, P217, DOI 10.1177/0269215508096759
   Chomsky N, 2000, NEW HORIZONS STUDY L
   Chomsky N, 2002, SYNTACTIC STRUCTURES
   Christensen HI, 2010, COGN SYST MONOGR, V8, P3, DOI 10.1007/978-3-642-11694-0_1
   Clodic Aurelie, 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P913
   Cortes U, 2008, WHITESTEIN SER SOFTW, P117, DOI 10.1007/978-3-7643-8547-7_7
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Douglas-Cowie E, 2007, LECT NOTES COMPUT SC, V4738, P488
   Esposito A, 2014, COGN COMPUT, V6, P623, DOI 10.1007/s12559-014-9309-5
   Esposito A, 2011, COGN COMPUT, V3, P417, DOI 10.1007/s12559-011-9107-2
   Garlan D, 2007, INT J SOFTW ENG KNOW, V17, P171, DOI 10.1142/S0218194007003033
   GNJATOVIC M, 2012, P 3 IEEE INT C COGN, P383
   Gnjatovic M, 2014, 2014 5th IEEE Conference on Cognitive Infocommunications (CogInfoCom), P367, DOI 10.1109/CogInfoCom.2014.7020480
   Gnjatovic M, 2014, COGN COMPUT, V6, P775, DOI 10.1007/s12559-014-9272-1
   Gnjatovic M, 2014, KNOWL-BASED SYST, V71, P25, DOI 10.1016/j.knosys.2014.05.001
   Gnjatovic M, 2013, INT CONF COGN INFO, P167, DOI 10.1109/CogInfoCom.2013.6719234
   Gnjatovic M, 2012, APPL INTELL, V37, P305, DOI 10.1007/s10489-011-0329-5
   Grosz B. J., 1986, Computational Linguistics, V12, P175
   Hawes N, 2010, COGN SYST MONOGR, V8, P51, DOI 10.1007/978-3-642-11694-0_2
   Hermansky H, 2006, P EUCOGNITION IN M E
   Karreman D. E., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P1059, DOI 10.1109/ROMAN.2012.6343889
   Kautz H., 2002, AAAI 2002 WORKSH AUT, P60
   Kutas M, 2000, TRENDS COGN SCI, V4, P463, DOI 10.1016/S1364-6613(00)01560-6
   Leishman T.R., 2002, J DEFENSE SOFTWARE E, V15, P4
   MacLeod C.M., 2007, INHIBITION COGNITION, P3, DOI [10.1037/11587-001, DOI 10.1037/11587-001]
   Maheswaran RT, 2004, LECT NOTES COMPUT SC, V2969, P187
   Reithinger N., 2006, P 8 INT C MULT INT I
   Rickheit G, 1996, ARTIF INTELL REV, V10, P165, DOI 10.1007/BF00127677
   Roulet E., 1992, SEARLE CONVERSATION, P91, DOI 10.1075/pbns.21.05rou
   Saffran JR, 2003, CURR DIR PSYCHOL SCI, V12, P110, DOI 10.1111/1467-8721.01243
   SCHEGLOFF EA, 1968, AM ANTHROPOL, V70, P1075, DOI 10.1525/aa.1968.70.6.02a00030
   Searle J, 2002, PROBLEM CONSCIOUSNES
   Searle J, 2002, CONSCIOUSNESS CONSCI
   Searle JR., 1992, SEARLE CONVERSATION, P7, DOI 10.1075/pbns.21.02sea
   Siekmann J, 2010, COGN TECHNOL, P1, DOI 10.1007/978-3-540-89408-7_1
   Tognini-Bonelli E, 2001, CORPUS LINGUISTICS W
   Tomasello M., 2003, CONSTRUCTING LANGUAG
   Turkle Sherry, 2011, ALONE TOGETHER WHY W
   Vergados D, 2008, INT C PERV TECHN REL, P1
   Wahlster Wolfgang, 2003, P HUM COMP INT STAT, P47
   Waibel A, 2009, HUM-COMPUT INT-SPRIN, P3, DOI 10.1007/978-1-84882-054-8_1
   Wendemuth Andreas, 2012, Cognitive Behavioural Systems (COST 2012). International Training School. Revised Selected Papers, P89, DOI 10.1007/978-3-642-34584-5_7
   Wendemuth A, 2008, LECT NOTES ARTIF INT, V5078, P141, DOI 10.1007/978-3-540-69369-7_16
   Wilks Y, 2010, CLOSE ENGAGEMENTS AR, P11
   Wilks Y, 2007, SCIENCE, V318, P927, DOI 10.1126/science.1148895
   Winkler I, 2009, TRENDS COGN SCI, V13, P532, DOI 10.1016/j.tics.2009.09.003
   Ziemke T, 2008, BIOSYSTEMS, V91, P401, DOI 10.1016/j.biosystems.2007.05.015
NR 54
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 1868-4394
EI 1868-4408
BN 978-3-319-31053-4; 978-3-319-31052-7
J9 INTEL SYST REF LIBR
PY 2016
VL 106
BP 23
EP 45
DI 10.1007/978-3-319-31053-4_4
D2 10.1007/978-3-319-31053-4
PG 23
WC Computer Science, Artificial Intelligence; Robotics
WE Book Citation Index – Science (BKCI-S)
SC Computer Science; Robotics
GA BE8JN
UT WOS:000376520200005
DA 2022-08-02
ER

PT J
AU Kopp, S
   Wachsmuth, P
AF Kopp, S
   Wachsmuth, P
TI Synthesizing multimodal utterances for conversational agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE multimodal conversational agents; gesture animation; model-based
   computer animation; motion control
ID ANIMATION
AB Conversational agents are supposed to combine speech with non-verbal modalities for intelligible multimodal utterances. In this paper, we focus on the generation of gesture and speech from XML-based descriptions of their overt form. An incremental production model is presented that combines the synthesis of synchronized gestural, verbal, and facial behaviors with mechanisms for linking them in fluent utterances with natural co-articulation and transition effects. In particular, an efficient kinematic approach for animating hand gestures from shape specifications is presented, which provides fine adaptation to temporal constraints that are imposed by cross-modal synchrony. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Bielefeld, Fac Technol, Artificial Intelligence Grp, D-33594 Bielefeld, Germany.
RP Kopp, S (corresponding author), Univ Bielefeld, Fac Technol, Artificial Intelligence Grp, D-33594 Bielefeld, Germany.
EM skopp@techfak.uni-bielefeld.de
RI Kopp, Stefan/K-3456-2013
OI Kopp, Stefan/0000-0002-4047-9277; Wachsmuth, Ipke/0000-0002-4786-5189
CR Cassell J, 2001, COMP GRAPH, P477
   Cassell J, 2000, EMBODIED CONVERSATIONAL AGENTS, P29
   CASSELL J, 2000, EMBODIED CONVERSATIO, P64
   CASSELL J, 1994, P SIGGRAPH 94
   Cassell J., 2000, EMBODIED CONVERSATIO
   Churchill EF, 2000, EMBODIED CONVERSATIONAL AGENTS, P64
   DERUITER JP, 1998, MPI SERIES PSYCHOLIN
   Gibet S, 2001, J VISUAL LANG COMPUT, V12, P657, DOI 10.1006/jvlc.2001.0202
   Kendon A, 1980, RELATIONSHIP VERBAL, V25, P207, DOI DOI 10.1515/9783110813098.207
   KOGA Y, 1994, P SIGGRAPH 94, P395
   Kopp S, 2002, COMP ANIM CONF PROC, P252, DOI 10.1109/CA.2002.1017547
   KOPP S, 2000, ECAI 2000 P 14 EUR C, P661
   Latash M.L., 1993, CONTROL HUMAN MOVEME, Vfirst
   Levelt Willem, 1989, SPEAKING
   Mataric M. J., 1999, Autonomous Agents and Multi-Agent Systems, V2, P23, DOI 10.1023/A:1010023022632
   McNeill D., 1992, HAND MIND WHAT GESTU
   MORASSO P, 1982, BIOL CYBERN, V45, P131, DOI 10.1007/BF00335240
   Nobe S., 2000, LANGUAGE GESTURE
   PERLIN K, 1995, IEEE T VIS COMPUT GR, V1, P5, DOI 10.1109/2945.468392
   Rickel J, 1999, APPL ARTIF INTELL, V13, P343, DOI 10.1080/088395199117315
   SOECHTING JF, 1989, J NEUROPHYSIOL, V62, P582, DOI 10.1152/jn.1989.62.2.582
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   WILHELMSJ, 2001, J GRAPHICS TOOLS, V2, P27
   ZELTZER D, 1982, IEEE COMPUT GRAPH, V2, P53
NR 24
TC 129
Z9 129
U1 1
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2004
VL 15
IS 1
BP 39
EP 52
DI 10.1002/cav.6
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 832EF
UT WOS:000222249300005
OA Green Published
DA 2022-08-02
ER

PT C
AU Palma, MDO
   Seeger, AM
   Heinzl, A
AF Palma, Maria del Carmen Ocon
   Seeger, Anna-Maria
   Heinzl, Armin
BE Davis, FD
   Riedl, R
   VomBrocke, J
   Leger, PM
   Randolph, A
   Fischer, T
TI Mitigating Information Overload in e-Commerce Interactions with
   Conversational Agents
SO INFORMATION SYSTEMS AND NEUROSCIENCE
SE Lecture Notes in Information Systems and Organization
LA English
DT Proceedings Paper
CT Information Systems and Neuroscience (NeuroIS) Retreat Workshop
CY JUN 02-06, 2019
CL Vienna, AUSTRIA
DE Information overload; Conversational agents; Skin conductance level
ID IMPACT
AB Information overload influences users' satisfaction and performance when completing a complex task. In e-commerce interactions, this has the effect that customers' decision making becomes confused, less accurate and less effective. For websites, numerous countermeasures to mitigate information overload have been presented, whereas not many attempts have been made to reduce cognitive load when conversational agents are used instead. Conversational agents are expected to increase the perceived overload due to the voice interface characteristics. In this pilot study, the cognitive load of subjects was measured during an online shopping task which required different custom shopping skills for Amazon Alexa. It was tested if the countermeasure filtered repetition can reduce subjects' perceived overload when using the voice assistant and which load differences can be found in comparison to a shopping website. To measure the mental load, the skin conductance level was recorded.
C1 [Palma, Maria del Carmen Ocon] Camelot ITLab GmbH, Mannheim, Germany.
   [Seeger, Anna-Maria; Heinzl, Armin] Univ Mannheim, Mannheim, Germany.
RP Palma, MDO (corresponding author), Camelot ITLab GmbH, Mannheim, Germany.
EM moco@camelot-itlab.com; seeger@uni-mannheim.de; heinzl@uni-mannheim.de
CR Brunken R., 2002, ED PSYCHOL, V38, P53
   Cohen M. J., 2004, VOICE USER INTERFACE, p6ff
   Eppler MJ, 2004, INFORM SOC, V20, P325, DOI 10.1080/01972240490507974
   HART S G, 1988, P139
   Huffman C, 1998, J RETAILING, V74, P491, DOI 10.1016/S0022-4359(99)80105-5
   Jacoby J, 1998, J PUBLIC POLICY MARK, V17, P97, DOI 10.1177/074391569801700110
   Jacoby J., J MARKETING RES, P569
   Leahy W, 2011, APPL COGNITIVE PSYCH, V25, P943, DOI 10.1002/acp.1787
   Lester J., 2004, PRACTICAL HDB INTERN
   Mitchell V., 1999, J PRODUCT BRAND MANA, V8, P319, DOI DOI 10.1108/10610429910284300
   Schmutz P, 2010, INT J HUM-COMPUT ST, V68, P423, DOI 10.1016/j.ijhcs.2010.02.001
   Schmutz P, 2009, ADV HUM-COMPUT INTER, V2009, DOI 10.1155/2009/121494
   Schnelle D., 2006, P 11 EUR C PATT LANG, P1
   Shi Y., 2007, P CHI 07 EXTENDED AB, P2651, DOI [10.1145/1240866.1241057, DOI 10.1145/1240866.1241057]
   Singh AM, 2012, APPL COGNITIVE PSYCH, V26, P848, DOI 10.1002/acp.2885
   SWELLER J, 1988, COGNITIVE SCI, V12, P257, DOI 10.1016/0364-0213(88)90023-7
   Vazquez-Alvarez Y, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2173
   Wong A, 2012, LEARN INSTR, V22, P449, DOI 10.1016/j.learninstruc.2012.05.004
   Wood E, 2012, COMPUT EDUC, V58, P365, DOI 10.1016/j.compedu.2011.08.029
NR 19
TC 3
Z9 3
U1 1
U2 7
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2195-4968
EI 2195-4976
BN 978-3-030-28144-1; 978-3-030-28143-4
J9 L N INF SYST ORGAN
PY 2020
VL 32
BP 221
EP 228
DI 10.1007/978-3-030-28144-1_24
PG 8
WC Psychology, Biological; Behavioral Sciences; Computer Science,
   Information Systems; Neurosciences
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Psychology; Behavioral Sciences; Computer Science; Neurosciences &
   Neurology
GA BQ3AH
UT WOS:000583593800024
DA 2022-08-02
ER

PT C
AU Osta, A
   Kokkinaki, A
   Chedrawi, C
AF Osta, Alain
   Kokkinaki, Angelika
   Chedrawi, Charbel
BE Themistocleous, M
   Papadaki, M
TI Online Health Communities: The Impact of AI Conversational Agents on
   Users
SO INFORMATION SYSTEMS (EMCIS 2021)
SE Lecture Notes in Business Information Processing
LA English
DT Proceedings Paper
CT 18th European, Mediterranean, and Middle Eastern Conference on
   Information Systems (EMCIS)
CY DEC 08-09, 2021
CL ELECTR NETWORK
SP Unov Nicosia, British Univ Dubai, Dubai Block Chain Ctr
DE Online Health Communities; AI conversational agents; Chatbots; UTAUT
ID INFORMATION-TECHNOLOGY; ACCEPTANCE; ADOPTION; DETERMINANTS; SERVICES;
   MODEL
AB The literature lacks evidence on the acceptability of AI conversational agents (chatbots) and the motivations for their adoption in healthcare industry. This paper aims to examine the acceptance of these chatbots based on the UTAUT model in Online Health Communities (OHCs) and to explore what kind of impact these particular features have on the users' intentions, and the actual use of these communities. Based on a quantitative methodology approach, we rely on the UTAUT model to study OHCs users' behavior and intentions towards such AI conversational agents/chatbots. The study shows that the UTAUT has proved to be a strong and reliable model for evaluating the adoption and application of AI conversational agents (chatbots) in OHCs. A questionnaire was employed to collect data, and respondents are chosen using the cluster sampling approach. On a 7 Likert scale, respondents were asked to select which choice best suited their reaction to any of the topics presented. A total of 632 answers from 62 countries were received, with 443 of them being complete. Many tests were used to examine the data such as the bivariate and multivariate analysis. Since the returned p-value for most of the hypotheses tested was 0.05, the majority of the hypotheses tested were accepted. Findings showed the interrelations between AI conversational agents/chatbots and OHCs on users' Behavioral Intention (BI). The main constructs of the UTAUT model (Performance Expectancy, Effort Expectancy, Social Influence, and Facilitating Conditions) had a significant impact on the participants' BI and Usage Behavior (UB) for AI conversational agents/chatbots in OHCs. As for moderators, gender and age had no effect on BI and UB. Understanding the main factors that have a significant impact on users' intentions to use chatbots in OHCs determines the significance of those results.
C1 [Osta, Alain] Univ Nicosia, Grad Sch, Nicosia, Cyprus.
   [Kokkinaki, Angelika; Chedrawi, Charbel] Univ Nicosia, Sch Business, Nicosia, Cyprus.
   [Chedrawi, Charbel] St Joseph Univ, Business & Management Fac, Beirut, Lebanon.
RP Osta, A (corresponding author), Univ Nicosia, Grad Sch, Nicosia, Cyprus.
EM osta.a@live.unic.ac.cy; kokkinaki.a@unic.ac.cy; chedrawi.c@unic.ac.cy
RI Osta, Alain Fouad/GLT-6249-2022
CR Abd-Alrazaq AA, 2021, J MED INTERNET RES, V23, DOI 10.2196/17828
   Abd-alrazaq AA, 2019, INT J MED INFORM, V126, P164, DOI 10.1016/j.ijmedinf.2019.03.014
   Brandtzaeg PB, 2017, LECT NOTES COMPUT SC, V10673, P377, DOI 10.1007/978-3-319-70284-1_30
   Chan FKY, 2010, J ASSOC INF SYST, V11, P519
   Chauhan S, 2016, INT J MANAG EDUC-OXF, V14, P248, DOI 10.1016/j.ijme.2016.05.005
   Cimperman M, 2016, INT J MED INFORM, V90, P22, DOI 10.1016/j.ijmedinf.2016.03.002
   Creswell J.W., 2009, RES DESIGN QUALITATI, V3rd
   de Veer AJE, 2015, BMC HEALTH SERV RES, V15, DOI 10.1186/s12913-015-0765-8
   Esmaeilzadeh P, 2015, INT J MED INFORM, V84, P548, DOI 10.1016/j.ijmedinf.2015.03.007
   Gao YW, 2015, IND MANAGE DATA SYST, V115, P1704, DOI 10.1108/IMDS-03-2015-0087
   Guo Y., 2015, INT J SMART HOME, V9, P203, DOI DOI 10.14257/IJSH.2015.9.1.22
   Hoque R, 2017, INT J MED INFORM, V101, P75, DOI 10.1016/j.ijmedinf.2017.02.002
   Hsieh PJ, 2016, COMPUT HUM BEHAV, V63, P959, DOI 10.1016/j.chb.2016.06.029
   Jabarulla MY, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9081019
   Karamitsos I., 2021, MODERN MANAGEMENT BA
   Khalilzadeh J, 2017, COMPUT HUM BEHAV, V70, P460, DOI 10.1016/j.chb.2017.01.001
   Klein HK, 1999, MIS QUART, V23, P67, DOI 10.2307/249410
   Koteluk O, 2021, J PERS MED, V11, DOI 10.3390/jpm11010032
   Lee Y., 2003, COMMUN ASSOC INF SYS, V12, P1250, DOI [10.17705/1CAIS.01250, DOI 10.17705/1CAIS.01250]
   Long M., 2020, DEEP LEARNING HEALTH
   Lu XY, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16245084
   Marrone S., 2017, CEUR WORKSHOP P
   Mesko B, 2019, J MED INTERNET RES, V21, DOI 10.2196/12490
   Okumus B, 2018, INT J HOSP MANAG, V72, P67, DOI 10.1016/j.ijhm.2018.01.001
   Orlikowski WJ, 1991, INFORM SYST RES, V2, P1, DOI 10.1287/isre.2.1.1
   Pai FY, 2011, TECHNOL FORECAST SOC, V78, P650, DOI 10.1016/j.techfore.2010.11.007
   Palanica A, 2019, J MED INTERNET RES, V21, DOI 10.2196/12887
   Papadaki M, 2021, J ENTERP INF MANAG, V34, P993, DOI 10.1108/JEIM-07-2021-554
   Park SH, 2011, INFORM TECHNOL MANAG, V12, P315, DOI 10.1007/s10799-011-0097-2
   Quaosar GMAA, 2018, TELEMED E-HEALTH, V24, P309, DOI 10.1089/tmj.2017.0111
   Reyes-Mercado Pavel, 2018, Journal of Systems and Information Technology, V20, P103, DOI 10.1108/JSIT-04-2017-0025
   Sennaar K, 2019, CHATBOTS HEALTHCARE
   Straub D, 2004, COMMUN ASS INF SYST, V13, P380
   Sumak B, 2016, COMPUT HUM BEHAV, V64, P602, DOI 10.1016/j.chb.2016.07.037
   Tavares J, 2017, BMC MED INFORM DECIS, V17, DOI 10.1186/s12911-017-0482-9
   Taylor S, 1995, MIS QUART, V19, P561, DOI 10.2307/249633
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Venkatesh V, 2008, DECISION SCI, V39, P273, DOI 10.1111/j.1540-5915.2008.00192.x
   Walsh I, 2014, EUR J INFORM SYST, V2014, P1
   Wright R., 2020, NEW YORKER 1007
   Wu B, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.9127
   Zhang Z, 2019, STUD HEALTH TECHNOL, V264, P1403, DOI [10.3233/SHTI190458, 10.3233/SHT1190458]
NR 42
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1865-1348
EI 1865-1356
BN 978-3-030-95947-0; 978-3-030-95946-3
J9 LECT NOTES BUS INF P
PY 2022
VL 437
BP 488
EP 501
DI 10.1007/978-3-030-95947-0_35
PG 14
WC Computer Science, Information Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS8EJ
UT WOS:000771721100035
DA 2022-08-02
ER

PT J
AU Elvir, M
   Gonzalez, AJ
   Walls, C
   Wilder, B
AF Elvir, Miguel
   Gonzalez, Avelino J.
   Walls, Christopher
   Wilder, Bryan
TI Remembering a Conversation - A Conversational Memory Architecture for
   Embodied Conversational Agents
SO JOURNAL OF INTELLIGENT SYSTEMS
LA English
DT Article
DE Chatbots; chatterbots; conversational agents; conversational memory;
   Embodied Conversational Agents; episodic memory; episodic memory
   architecture
ID DESIGN; MODELS
AB This paper addresses the role of conversational memory in Embodied Conversational Agents (ECAs). It describes an investigation into developing such a memory architecture and integrating it into an ECA. ECAs are virtual agents whose purpose is to engage in conversations with human users, typically through natural language speech. While several works in the literature seek to produce viable ECA dialog architectures, only a few authors have addressed the episodic memory architectures in conversational agents and their role in enhancing their intelligence. In this work, we propose, implement, and test a unified episodic memory architecture for ECAs. We describe a process that determines the prevalent contexts in the conversations obtained from the interactions. The process presented demonstrates the use of multiple techniques to extract and store relevant snippets from long conversations, most of whose contents are unremarkable and need not be remembered. The mechanisms used to store, retrieve, and recall episodes from previous conversations are presented and discussed. Finally, we test our episodic memory architecture to assess its effectiveness. The results indicate moderate success in some aspects of the memory-enhanced ECAs, as well as some work still to be done in other aspects.
C1 [Gonzalez, Avelino J.] Univ Cent Florida, Dept Comp Sci, POB 162362,4000 Cent Florida Blvd,HEC 346, Orlando, FL 32816 USA.
   [Elvir, Miguel; Walls, Christopher; Wilder, Bryan] Univ Cent Florida, Elect & Comp Engn Dept, Orlando, FL 32816 USA.
RP Gonzalez, AJ (corresponding author), Univ Cent Florida, Dept Comp Sci, POB 162362,4000 Cent Florida Blvd,HEC 346, Orlando, FL 32816 USA.
EM avelino.gonzalez@ucf.edu
FU Division of Computer and Network Systems, NSF ['CNS0703927']
FX Division of Computer and Network Systems, NSF (Grant/Award Number:
   'CNS0703927').
CR Anderson JR, 1996, AM PSYCHOL, V51, P355, DOI 10.1037/0003-066X.51.4.355
   Artstein R., 2008, P ELRA WORKSH EV MAR
   ATKINSON RC, 1971, SCI AM, V225, P82, DOI 10.1038/scientificamerican0871-82
   Banchs Rafael E., 2013, P SIGDIAL 2013, P145
   Bernsen N. O., 2004, P WORK C ADV VIS INT
   Bernsen NO, 2004, LECT NOTES COMPUT SC, V3068, P142
   Brom C., 2010, INT J MACHINE CONSCI, P227
   Brom C., 2009, P AAMAS WORKSH EMP A
   Campos J, 2010, LECT NOTES ARTIF INT, V6356, P406, DOI 10.1007/978-3-642-15892-6_44
   Church K. W., 1990, Computational Linguistics, V16, P22
   Conway MA, 2005, J MEM LANG, V53, P594, DOI 10.1016/j.jml.2005.08.005
   D'Haro L. F., 2014, CLARA MULTIFUNCTIONA
   Elvir M., 2009, THESIS
   Faltersack Z., 2011, P AAAI FALL S SER AD, P106
   Frantzi K. T., 1997, P 35 ANN M ASS COMP
   Gonzalez AJ, 2013, J INTELL SYST, V22, P365, DOI 10.1515/jisys-2013-0016
   Gorski N. A., 2009, P 9 INT C COGN MOD I
   Hassani K., 2013, INTERACT LEARN ENVIR, P1
   Hassani K, 2013, J INTELL FUZZY SYST, V25, P811, DOI 10.3233/IFS-120687
   Ho WC, 2008, CONNECT SCI, V20, P21, DOI 10.1080/09540090801889469
   JUSTESON JS, 1995, COMPUT LINGUIST, V21, P1
   Kanayama H., 2006, P 2006 C EMP METH NA
   Kim Y., 2014, MULTIMODAL ANAL ENAB, P78
   Kopp S, 2005, LECT NOTES ARTIF INT, V3661, P329
   Ku L.W., 2006, P AAAI 2006 SPRING S
   LAIRD JE, 1987, ARTIF INTELL, V33, P1, DOI 10.1016/0004-3702(87)90050-6
   LEUSKI A, 2006, P 7 SIGDIAL WORKSH D
   Levin E., 2000, P INT C SPOK LANG PR
   Lim M. Y., 2010, P INT VIRT AG
   Lim MY, 2012, STUD COMPUT INTELL, V396, P241
   Liu Y., 2005, P EUR C SPEECH COMM
   Morbini F, 2014, NATURAL INTERACTION, P313
   Niculescu Andreea I., 2014, Mobile Web Information Systems. 11th International Conference (MobiWIS 2014). Proceedings: LNCS 8640, P153, DOI 10.1007/978-3-319-10359-4_13
   Nio L., 2013, P ICE ID
   Norman KA, 2008, CAMB HANDB PSYCHOL, P189
   Nuxoll A. M., 2007, P 22 NAT C ART INT A
   PANTEL P, 2002, P 8 ACM SIGKDD INT C
   Pasca M., 2006, P 21 INT C COMP LING
   Planells J, 2013, INTERSPEECH, P1890
   Shibata T., 2014, P 5 INT WORKSH SER S, P124
   Sims C. R., 2004, P 6 INT C COGN MOD I
   Sun R, 2012, NEW IDEAS PSYCHOL, V30, P227, DOI 10.1016/j.newideapsych.2011.11.003
   Traum D., 2002, P 1 INT JOINT C AU 2
   TRAUM D, 2007, P ANN M SPEC INT GRO, P00071
   Tulving E., 1972, ORG MEMORY, P381
   Tulving E., 1983, ELEMENTS EPISODIC ME, V1
   Waikato T. U. O., 2008, WEKA 3 DATA MINING O
   Wang WW, 2012, IEEE T NEUR NET LEAR, V23, P1574, DOI 10.1109/TNNLS.2012.2208477
NR 48
TC 4
Z9 4
U1 0
U2 23
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 0334-1860
EI 2191-026X
J9 J INTELL SYST
JI J. Intell. Syst.
PD JAN
PY 2017
VL 26
IS 1
BP 1
EP 21
DI 10.1515/jisys-2015-0094
PG 21
WC Computer Science, Artificial Intelligence
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA EG5DB
UT WOS:000391062600001
DA 2022-08-02
ER

PT J
AU Car, LT
   Dhinagaran, DA
   Kyaw, BM
   Kowatsch, T
   Joty, S
   Theng, YL
   Atun, R
AF Car, Lorainne Tudor
   Dhinagaran, Dhakshenya Ardhithy
   Kyaw, Bhone Myint
   Kowatsch, Tobias
   Joty, Shafiq
   Theng, Yin-Leng
   Atun, Rifat
TI Conversational Agents in Health Care: Scoping Review and Conceptual
   Analysis
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Review
DE conversational agents; chatbots; artificial intelligence; machine
   learning; mobile phone; health care; scoping review
ID MENTAL-HEALTH; INTERVENTION; COMPUTER; SYSTEM; TRIAL; ADOLESCENTS;
   INFORMATION; TECHNOLOGY; MANAGEMENT; PATIENT
AB Background: Conversational agents, also known as chatbots, are computer programs designed to simulate human text or verbal conversations. They are increasingly used in a range of fields, including health care. By enabling better accessibility, personalization, and efficiency, conversational agents have the potential to improve patient care.
   Objective: This study aimed to review the current applications, gaps, and challenges in the literature on conversational agents in health care and provide recommendations for their future research, design, and application.
   Methods: We performed a scoping review. A broad literature search was performed in MEDLINE (Medical Literature Analysis and Retrieval System Online; Ovid), EMBASE (Excerpta Medica database; Ovid), PubMed, Scopus, and Cochrane Central with the search terms "conversational agents," "conversational AI," "chatbots," and associated synonyms. We also searched the gray literature using sources such as the OCLC (Online Computer Library Center) WorldCat database and ResearchGate in April 2019. Reference lists of relevant articles were checked for further articles. Screening and data extraction were performed in parallel by 2 reviewers. The included evidence was analyzed narratively by employing the principles of thematic analysis.
   Results: The literature search yielded 47 study reports (45 articles and 2 ongoing clinical trials) that matched the inclusion criteria. The identified conversational agents were largely delivered via smartphone apps (n=23) and used free text only as the main input (n=19) and output (n=30) modality. Case studies describing chatbot development (n=18) were the most prevalent, and only 11 randomized controlled trials were identified. The 3 most commonly reported conversational agent applications in the literature were treatment and monitoring, health care service support, and patient education.
   Conclusions: The literature on conversational agents in health care is largely descriptive and aimed at treatment and monitoring and health service support. It mostly reports on text-based, artificial intelligence-driven, and smartphone app-delivered conversational agents. There is an urgent need for a robust evaluation of diverse health care conversational agents' formats, focusing on their acceptability, safety, and effectiveness.
C1 [Car, Lorainne Tudor; Dhinagaran, Dhakshenya Ardhithy; Kyaw, Bhone Myint] Nanyang Technol Univ Singapore, Lee Kong Chian Sch Med, Family Med & Primary Care, 11 Mandalay Rd, Singapore, Singapore.
   [Car, Lorainne Tudor] Imperial Coll London, Sch Publ Hlth, Dept Primary Care & Publ Hlth, London, England.
   [Kowatsch, Tobias] Singapore ETH Ctr, Future Hlth Technol Programme, Campus Res Excellence & Technol Enterprise Create, Singapore, Singapore.
   [Kowatsch, Tobias] Swiss Fed Inst Technol, Dept Management Technol & Econ, Ctr Digital Hlth Intervent, Zurich, Switzerland.
   [Kowatsch, Tobias] Univ St Gallen, Inst Technol Management, Ctr Digital Hlth Intervent, St Gallen, Switzerland.
   [Joty, Shafiq] Nanyang Technol Univ Singapore, Sch Comp Sci & Engn, Singapore, Singapore.
   [Theng, Yin-Leng] Nanyang Technol Univ, Ctr Hlth & Sustainable Cities, Singapore, Singapore.
   [Atun, Rifat] Harvard Univ, Harvard TH Chan Sch Publ Hlth, Dept Global Hlth & Populat, Boston, MA 02115 USA.
RP Car, LT (corresponding author), Nanyang Technol Univ Singapore, Lee Kong Chian Sch Med, Family Med & Primary Care, 11 Mandalay Rd, Singapore, Singapore.
EM lorainne.tudor.car@ntu.edu.sg
RI Atun, Rifat/AAH-5537-2021; Car, Lorainne Tudor/E-1205-2017
OI Car, Lorainne Tudor/0000-0001-8414-7664; Theng,
   Yin-Leng/0000-0003-2351-8884; Kyaw, Bhone Myint/0000-0002-1750-0330;
   Dhinagaran, Dhakshenya Ardhithy/0000-0003-0629-5199; Kowatsch,
   Tobias/0000-0001-5939-4145; Atun, Rifat/0000-0002-1531-5983
FU Ageing Research Institute for Society and Education (ARISE), Nanyang
   Technological University, Singapore; National Research Foundation, Prime
   Minister's Office, Singapore under its Campus for Research Excellence
   and Technological Enterprise (CREATE) program
FX This research is supported by the Ageing Research Institute for Society
   and Education (ARISE), Nanyang Technological University, Singapore. This
   study is also supported by the National Research Foundation, Prime
   Minister's Office, Singapore under its Campus for Research Excellence
   and Technological Enterprise (CREATE) program.
CR Abashev A, 2017, BIONANOSCIENCE, V7, P403, DOI 10.1007/s12668-016-0376-9
   Ahmad NS, 2018, 2018 2018 IEEE C OP, DOI [10.1109/ICOS.2018.8632700, DOI 10.1109/ICOS.2018.8632700]
   ALEXANDER JA, 1973, AM J OPTOM PHYS OPT, V50, P730
   Allen J, 2006, J BIOMED INFORM, V39, P500, DOI 10.1016/j.jbi.2006.02.004
   Amrita, 2013, Med 2 0, V2, pe4, DOI 10.2196/med20.2720
   [Anonymous], 1992, Profiles Healthc Mark, P40
   [Anonymous], 2018, CISION PR NEWSWIRE
   [Anonymous], 2016, PERSUASIVE STRATEGIE
   [Anonymous], 2009, IEEE EXPLORE
   [Anonymous], 2018, BOTPRESS OPEN SOURCE
   [Anonymous], 2018, UNDERSTANDING BLACK
   [Anonymous], 2018, PROPOSAL DEV MOBILE
   [Anonymous], INT J ENG COMPUTER S
   [Anonymous], 2017, SMART SPEAKER SALES
   Atay C., 2016, ALZHEIMERS DEMENT, V12, P1005, DOI DOI 10.1016/j.jalz.2016.06.2070
   Azevedo Renato F L, 2018, AMIA Annu Symp Proc, V2018, P185
   Ballati F, 2018, 7 INT WORKSH REL INT
   Bhattarai P, 2017, ARCH GERONTOL GERIAT, V68, P14, DOI 10.1016/j.archger.2016.08.008
   Bickmore TW, 2018, J MED INTERNET RES, V20, DOI 10.2196/11510
   Bickmore TW, 2013, PATIENT EDUC COUNS, V92, P142, DOI 10.1016/j.pec.2013.05.011
   Bickmore TW, 2010, J HEALTH COMMUN, V15, P197, DOI 10.1080/10810730.2010.499991
   Blanson Henkemans Olivier A, 2009, Technol Health Care, V17, P253, DOI 10.3233/THC-2009-0545
   Bond R., 2017, J MED INTERNET RES, P24, DOI DOI 10.14236/EWIC/HCI2017.24
   Brixey J, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P370
   BROWN RL, 1981, AM IND HYG ASSOC J, V42, P824, DOI 10.1080/15298668191420756
   Bruner J., 2016, WHY 2016 IS SHAPING
   Callejas Z, 2014, AMBIENT ASSISTED LIV, DOI [10.1007/978-3-319-13105-4_10, DOI 10.1007/978-3-319-13105-4_10]
   Cameron G, 2018, P 32 INT BCS HUM COM, V129, P1, DOI [10.14236/ewic/HCI2018.129, DOI 10.14236/EWIC/HCI2018.129]
   Casas J, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC'18 ADJUNCT), P1676, DOI 10.1145/3267305.3274191
   Chaix B, 2019, JMIR CANCER, V5, DOI 10.2196/12856
   Cheng A, 2018, CONSUM COMM NETWORK
   Chung K, 2019, CLUSTER COMPUT, V22, P1925, DOI 10.1007/s10586-018-2334-5
   Colby K., 2013, ARTIFICIAL PARANOIA
   Comendador BE, 2015, J AUTOMATION CONTROL
   Cooper A, 2018, STUD HEALTH TECHNOL, V252, P63, DOI 10.3233/978-1-61499-890-7-63
   Crutzen Rik, 2014, BMC Res Notes, V7, P824, DOI 10.1186/1756-0500-7-824
   Crutzen R, 2011, J ADOLESCENT HEALTH, V48, P514, DOI 10.1016/j.jadohealth.2010.09.002
   D'Alfonso S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00796
   Danda P, 2015, P 13 INT C NAT LANG
   de Haan H, 2018, INFO SUPPORT RES
   Delichatsios HK, 2001, AM J HEALTH PROMOT, V15, P215, DOI 10.4278/0890-1171-15.4.215
   Denecke Kerstin, 2019, Stud Health Technol Inform, V259, P77
   Denecke K, 2018, METHOD INFORM MED, V57, P243, DOI 10.1055/s-0038-1675822
   Denecke K, 2018, DH '18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON DIGITAL HEALTH, P85, DOI 10.1145/3194658.3194670
   Deryugina OV, 2010, SCI TECH INF PROCESS, V37, P143, DOI 10.3103/S0147688210020097
   Devine KA, 2018, JCO CLIN CANCER INFO, V2, DOI 10.1200/CCI.17.00138
   Dharwadkar R, 2018, INT J COMP TRENDS TE, V60
   Divya S, 2018, J WEB DEV WEB, P1, DOI 10.46610/jowdwd
   Do HI, 2016, 2016 2016 IEEE INT C
   Dongkeon L, 2017, 2017 IEEE INT C BIG, DOI [10.1109/bigcomp.2017.7881752, DOI 10.1109/BIGCOMP.2017.7881752]
   Dowling M, 2014, ADV MENT HEALTH, V12, P216, DOI 10.1080/18374905.2014.11081899
   Dowling M, 2015, COUNS PSYCHOTHER RES, V15, P274, DOI 10.1002/capr.12037
   Dowling M, 2016, COMPUT HUM BEHAV, V55, P62, DOI 10.1016/j.chb.2015.08.009
   Dubosson F., 2017, SWISS MED INFORM, P33, DOI [10.4414/smi.33.00397, DOI 10.4414/SMI.33.00397]
   Elmasri D, 2016, BRAIN INFORM HLTH
   Fadhil A., 2017, P 11 EAI INT C PERV, P261, DOI DOI 10.1145/3154862.3154914
   Fadhil A., 2017, ADJ PUBL 25 C US MOD, P408, DOI [10.1145/3099023.3099112, DOI 10.1145/3099023.3099112]
   Fadhil A, 2017, COACHAI CONVERSATION
   Fadhil A, 2019, METHOD INFORM MED, V58, P9, DOI 10.1055/s-0039-1688757
   Ferguson G, 2010, J BIOMED INFORM, V43, pS13, DOI 10.1016/j.jbi.2010.05.014
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   FRIEDMAN E, 1981, HOSPITALS, V55, P105
   FRIEDMAN RB, 1977, JAMA-J AM MED ASSOC, V238, P1927
   Fulmer R, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/mental.9782
   Gaffney H, 2014, BEHAV COGN PSYCHOTH, V42, P731, DOI 10.1017/S135246581300060X
   Galescu L, 2009, P IEEE INT C BIBM 20, DOI [10.1109/bibmw.2009.5332111, DOI 10.1109/BIBMW.2009.5332111]
   Ghosh S, 2018, STUD HEALTH TECHNOL, V252, P51, DOI 10.3233/978-1-61499-890-7-51
   Goebel T., 2016, ASPECT BLOG
   Griol D, 2015, ART COMP BIOL MED IN
   Griol D, 2016, COGN COMPUT, V8, P336, DOI 10.1007/s12559-015-9352-x
   Hall AK, 2015, ANNU REV PUBL HEALTH, V36, P393, DOI 10.1146/annurev-publhealth-031914-122855
   Hassoon A, 2018, JMIR RES PROTOC, V7, DOI 10.2196/resprot.9096
   Heldt K, 2018, OBESITY FACTS S1, P214
   Hoermann S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7023
   Holm EA, 2019, SCIENCE, V364, P26, DOI 10.1126/science.aax0162
   Huang J, 2015, LECT NOTES COMPUT SC, V9085, P133, DOI 10.1007/978-3-319-19156-0_14
   Inkster B, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/12106
   Joerin A, 2019, CUREUS, V11, DOI 10.7759/cureus.3972
   Kamita T, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/9517321
   Kan V., 2017, P 2017 CHI C HUM FAC, P989
   Kanagarajan K, 2014, IJSC, V4, P772, DOI [10.21917/ijsc.2014.0110, DOI 10.21917/IJSC.2014.0110]
   Kazi H., 2012, INT J COMPUTER APPL, V55, P1
   Kerr D, 2018, DIABETIC MED, V35, P498, DOI 10.1111/dme.13586
   Kobori Y, 2018, J UROLOGY, V199, pE189, DOI 10.1016/j.juro.2018.02.516
   Kocaballi AB, 2019, J MED INTERNET RES, V21, DOI 10.2196/15360
   Kocielnik Rafal, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3214273
   Kowatsch T, 2017, 17 INT C INT VIRT AG
   Kowatsch T, 2017, LECT NOTES COMPUT SC, V10243, P485, DOI 10.1007/978-3-319-59144-5_36
   Kramer JN, 2019, JMIR RES PROTOC, V8, DOI 10.2196/11540
   L'Allemand D., 2018, OBES REV, V19, P102
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lee K, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0201166
   Lewis C, 2017, KDNUGGETS NEWS
   Lindenberg Katajun, 2011, Clin Pract Epidemiol Ment Health, V7, P74, DOI 10.2174/1745017901107010074
   Liu BJ, 2018, CYBERPSYCH BEH SOC N, V21, P625, DOI 10.1089/cyber.2018.0110
   Lobo J, 2017, INT J E-HEALTH MED C, V8, P21, DOI 10.4018/IJEHMC.2017100102
   Lokman Abbas Saliimi, 2010, American Journal of Applied Sciences, V7, P1406, DOI 10.3844/ajassp.2010.1406.1411
   Ly KH, 2017, INTERNET INTERV, V10, P39, DOI 10.1016/j.invent.2017.10.002
   Marciel KK, 2010, PEDIATR PULM, V45, P157, DOI 10.1002/ppul.21164
   Mascitti I, 2010, 2010 JUL 01 INT C AG, DOI [10.5220/0002589901150120, DOI 10.5220/0002589901150120]
   Mayo J., 2016, CHATBOTS LIFE
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   Middleton K, SORTING OUT SYMPTOMS
   Migneault JP, 2006, J BIOMED INFORM, V39, P468, DOI 10.1016/j.jbi.2006.02.009
   Miner AS, 2016, JAMA INTERN MED, V176, P619, DOI 10.1001/jamainternmed.2016.0400
   Morris RR, 2018, J MED INTERNET RES, V20, DOI 10.2196/10148
   Mujeeb S, 2017, INT J ADV COMPUT SC, V8, P209
   Nadarzynski T, 2019, DIGIT HEALTH, V5, DOI [10.1177/2055207619871808, 10.1177/2055207619827193]
   Neville R, 2002, BRIT MED J, V325, P600
   Ni L, 2017, KNOWLEDGE SYSTEMS SC
   Oh KJ, 2017, STUD HEALTH TECHNOL, V245, P1235, DOI 10.3233/978-1-61499-830-3-1235
   Onwumere J, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/mental.9857
   Pal K, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.8439
   Palanica A, 2019, J MED INTERNET RES, V21, DOI 10.2196/12887
   Pereira J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1237-1
   Perez Marta Garcia, 2018, P 32 INT BCS HUM COM, DOI [10.14236/ewic/HCI2018.40, DOI 10.14236/EWIC/HCI2018.40]
   Perez Sarah, 2018, TECH CRUNCH
   Perov, COMP STUDY ARTIFICIA
   Peters MDJ, 2015, INT J EVID-BASED HEA, V13, P141, DOI 10.1097/XEB.0000000000000050
   Prize L., 2019, AISB SOC STUDY ARTIF
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Rathbone AL, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7740
   Rhee H, 2014, PATIENT PREFER ADHER, V8, P63, DOI 10.2147/PPA.S53504
   Rizzoa AA, 2011, STUD HEALTH TECHNOL, V163, P503, DOI 10.3233/978-1-60750-706-2-503
   Ruggiano N, 2018, RES GERONTOL NURS, V11, P216, DOI 10.3928/19404921-20180628-04
   Saeed H., 2016, CHATBOTS LIFE
   Semaan P, 2012, J COMPUTER SCI RES, P50
   Sosale AR, 2018, DIABETES, V67, DOI 10.2337/db18-866-P
   Spinazze P, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153426
   Stasinaki A, 2018, SWISS MED WKLY, V148, p10S
   Stein Natalie, 2017, JMIR Diabetes, V2, pe28, DOI 10.2196/diabetes.8590
   Stieger Mirjam, 2018, BMC Psychol, V6, P43, DOI 10.1186/s40359-018-0257-9
   Stormon A., 2017, CHATBOTS MAGAZINE
   The History of Chatbots, 2016, FUTURISM SCI TECHNOL
   Thompson D, 2019, TRANSL BEHAV MED, V9, P448, DOI 10.1093/tbm/ibz065
   Tropea P, 2019, J MED INTERNET RES, V21, DOI 10.2196/12805
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   van Heerden A, 2017, 2017 INTERNATIONAL CONFERENCE ON THE FRONTIERS AND ADVANCES IN DATA SCIENCE (FADS), P90
   Veretskaya O., 2017, WHAT IS CHATBOT USE
   Vita S, 2018, J INT AIDS SOC S8, V21, DOI 10.1002/jia2.25187
   Wang HL, 2018, COMPUTER, V51, P26, DOI 10.1109/MC.2018.3191249
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   WILSON N, 2017, BMJ-BRIT MED J, V359, DOI DOI 10.1136/BMJ.J5635
   Xing ZP, 2019, J MED INTERNET RES, V21, DOI 10.2196/14672
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
NR 145
TC 60
Z9 60
U1 14
U2 38
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD AUG 7
PY 2020
VL 22
IS 8
AR e17158
DI 10.2196/17158
PG 21
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA NW5NM
UT WOS:000575058600004
PM 32763886
OA Green Published, gold, Green Accepted, Green Submitted
DA 2022-08-02
ER

PT C
AU Bastos, MI
   Claudio, AP
   Felix, IB
   Guerreiro, MP
   Carmo, MB
   Balsa, J
AF Bastos, Maria Ines
   Claudio, Ana Paula
   Felix, Isa Brito
   Guerreiro, Mara Pereira
   Carmo, Maria Beatriz
   Balsa, Joao
BE Rocha, AP
   Steels, L
   VandenHerik, J
TI Operationalizing Behavior Change Techniques in Conversational Agents
SO ICAART: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON AGENTS AND
   ARTIFICIAL INTELLIGENCE - VOL 1
SE ICAART
LA English
DT Proceedings Paper
CT 14th International Conference on Agents and Artificial Intelligence
   (ICAART)
CY FEB 03-05, 2022
CL ELECTR NETWORK
DE Conversational Agents; Ontologies; Behavior Change Techniques; Dialogue
   Platforms
AB Departing from previous work on the use of well-established behavior change techniques in an mHealth intervention based on a conversational agent (CA), we propose in this contribution a new architecture for the design of behavior change CAs. This novel approach combines the use of an advanced natural language platform (Dialogflow) with the explicit representation, in an ontology, of how behavior change techniques can be operationalized. The integration of these two components is explained, as well as the most challenging aspect of using the advanced features of the platform in a way that allowed the agent to lead the dialogue flow, when needed. A successful proof of concept was built, which can be the basis for the development of advanced conversational agents, combining natural language tools with ontology-based knowledge representation.
C1 [Bastos, Maria Ines; Claudio, Ana Paula; Carmo, Maria Beatriz; Balsa, Joao] Univ Lisbon, Fac Ciencias, Dept Informat, LASIGE, Lisbon, Portugal.
   [Felix, Isa Brito; Guerreiro, Mara Pereira] Nursing Sch Lisbon, Nursing Res Innovat & Dev Ctr Lisbon CIDNUR, Lisbon, Portugal.
RP Bastos, MI (corresponding author), Univ Lisbon, Fac Ciencias, Dept Informat, LASIGE, Lisbon, Portugal.
RI Félix, Isa Brito/AAZ-2624-2020; Claudio, Ana Paula/L-6809-2017; Carmo,
   Maria Beatriz/B-4003-2016
OI Félix, Isa Brito/0000-0001-8186-9506; Pereira Guerreiro,
   Mara/0000-0001-8192-6080; Claudio, Ana Paula/0000-0002-4594-8087; Carmo,
   Maria Beatriz/0000-0002-4768-9517
FU FCT through the LASIGE Research Unit [UIDB/00408/2020, UIDP/00408/2020]
FX This work was supported by FCT through the LASIGE Research Unit, ref.
   UIDB/00408/2020 and ref. UIDP/00408/2020.
CR [Anonymous], JMIR MHEALTH UHEALTH, V8
   Balsa J, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01583-w
   Baptista S, 2020, ACCEPTABILITY EMBODI
   Bhuyan SS, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0492-7
   Bickmore TW, 2005, INTERACT COMPUT, V17, P711, DOI 10.1016/j.intcom.2005.09.002
   Cane J, 2015, BRIT J HEALTH PSYCH, V20, P130, DOI 10.1111/bjhp.12102
   Zapata BC, 2015, J MED SYST, V39, DOI 10.1007/s10916-014-0182-2
   Felix IB, 2019, FRONT PHARMACOL, V10, DOI 10.3389/fphar.2019.00680
   Guerreiro M.P., 2019, GERONTECHNOLOGY COMM, P236
   Guerreiro MP, 2021, JMIR RES PROTOC, V10, DOI 10.2196/26680
   Kramer LL, 2020, J MED INTERNET RES, V22, DOI 10.2196/14058
   Michie S., 2021, WELLCOME OPEN RES, V5
   Michie S., 2014, BEHAV CHANGE WHEEL G
   Michie S, 2017, IMPLEMENT SCI, V12, DOI 10.1186/s13012-017-0641-5
   Michie S, 2013, ANN BEHAV MED, V46, P81, DOI 10.1007/s12160-013-9486-6
   Morrissey Eimear C, 2016, Am J Prev Med, V50, pe143, DOI 10.1016/j.amepre.2015.09.034
   Schachner T, 2020, J MED INTERNET RES, V22, DOI 10.2196/20701
   Teixeira M.S., 2021, P 36 ANN ACM S APPL, P611
   Wattanapisit A, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-019-1016-4
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   WHO, 2011, MHEALTH NEW HORIZONS
   World Health Organization, 2021, NONC DIS MORT
   Zhang JW, 2020, J MED INTERNET RES, V22, DOI 10.2196/22845
NR 23
TC 0
Z9 0
U1 1
U2 1
PU SCITEPRESS
PI SETUBAL
PA AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL
SN 2184-433X
BN 978-989-758-547-0
J9 ICAART
PY 2022
BP 216
EP 224
DI 10.5220/0010826800003116
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering;
   Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS8PG
UT WOS:000774749000022
OA hybrid
DA 2022-08-02
ER

PT C
AU Yang, X
   Aurisicchio, M
   Baxter, W
AF Yang, Xi
   Aurisicchio, Marco
   Baxter, Weston
GP Assoc Comp Machinery
TI Understanding Affective Experiences With Conversational Agents
SO CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN
   COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY MAY 04-09, 2019
CL Glasgow, SCOTLAND
SP Assoc Comp Machinery, ACM SIGCHI
DE Conversational Agents; User Experience; Positive Design; Affect;
   Emotional Design
ID POSITIVE EMOTIONS; ACTIVATION; AGREEMENT
AB While previous studies of Conversational Agents (e.g. Siri, Google Assistant, Alexa and Cortana) have focused on evaluating usability and exploring capabilities of these systems, little work has examined users' affective experiences. In this paper we present a survey study with 171 participants to examine CA users' affective experiences. Specifically, we present four major usage scenarios, users' affective responses in these scenarios, and the factors which influenced the affective responses. We found that users' overall experience was positive with interest being the most salient positive emotion. Affective responses differed depending on the scenarios. Both pragmatic and hedonic qualities influenced affect. The factors underlying pragmatic quality are: helpfulness, proactivity, fluidity, seamlessness and responsiveness. The factors underlying hedonic quality are: comfort in human-machine conversation, pride of using cutting-edge technology, fun during use, perception of having a human-like assistant, concern about privacy and fear of causing distraction.
C1 [Yang, Xi; Aurisicchio, Marco; Baxter, Weston] Imperial Coll London, London, England.
RP Yang, X (corresponding author), Imperial Coll London, London, England.
EM x.yang15@imperial.ac.uk; m.aurisicchio@imperial.ac.uk;
   weston.baxter@imperial.ac.uk
CR [Anonymous], 2001, P SIGCHI C HUM FACT, DOI DOI 10.1145/365024.365119
   [Anonymous], 2017, P 19 INT C HUMAN COM, DOI DOI 10.1145/3098279.3098539
   Avula S, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1375, DOI 10.1145/3077136.3084155
   Baber Christopher, 1993, DEV INTERACTIVE SPEE
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]
   Brennan Susan E., 1990, CONVERSATION DIRECT
   Cassell J, 1999, APPL ARTIF INTELL, V13, P519, DOI 10.1080/088395199117360
   Cassell J., 1994, P 21 ANN C COMP GRAP, P413, DOI DOI 10.1145/192161.192272
   Cassell J., 2000, EMBODIED CONVERSATIO
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Cohen P., 2016, P 2016 CHI C HUM FAC, V07-12, P1032
   Desmet PMA, 2012, INT J DES, V6, P1
   Egloff B, 2003, J PERS SOC PSYCHOL, V85, P528, DOI 10.1037/0022-3514.85.3.528
   Eiband M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4254, DOI 10.1145/3025453.3025636
   FLANAGAN JC, 1954, PSYCHOL BULL, V51, P327, DOI 10.1037/h0061470
   Forlizzi J., 2004, P 2004 C DES INT SYS, V261
   Fredrickson BL, 2008, J PERS SOC PSYCHOL, V95, P1045, DOI 10.1037/a0013262
   Glass James, 1999, CHALLENGES SPOKEN DI
   Graesser AC, 2017, METHOD EDUC MEAS, P65, DOI 10.1007/978-3-319-33261-1_5
   Graf Bettina, 2015, NOMBOT SIMPLIFY FOOD, P360, DOI [10.1145/2836041.2841208, DOI 10.1145/2836041.2841208]
   Hassenzahl M, 2006, BEHAV INFORM TECHNOL, V25, P91, DOI 10.1080/01449290500330331
   Hassenzahl M, 2001, IEEE SOFTWARE, V18, P70, DOI 10.1109/52.903170
   Hassenzahl M., 2003, THING I UNDERSTANDIN, P31
   Hassenzahl M., 2010, EXPERIENCE DESIGN TE
   Hassenzahl M, 2015, INT J HUM-COMPUT INT, V31, P530, DOI 10.1080/10447318.2015.1064664
   Hassenzahl M, 2010, HUM-COMPUT INTERACT, V25, P235, DOI 10.1080/07370024.2010.500139
   Hassenzahl M, 2010, INTERACT COMPUT, V22, P353, DOI 10.1016/j.intcom.2010.04.002
   HUNT RJ, 1986, J DENT RES, V65, P128, DOI 10.1177/00220345860650020701
   Jordan P. W., 2002, DESIGNING PLEASURABL
   Jung MF, 2017, ACMIEEE INT CONF HUM, P263, DOI 10.1145/2909824.3020224
   Kiseleva J, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL (CHIIR'16), P121, DOI 10.1145/2854946.2854961
   Krippendorff K., 2011, COMPUTING KRIPPENDOR
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Mekler ED, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4509, DOI 10.1145/2858036.2858225
   Moore Robert J., 2017, CONVERSATIONAL UX DE, P492, DOI [10.1145/3027063.3027077, DOI 10.1145/3027063.3027077]
   Muller LJ, 2015, P 33 ANN ACM C HUM F, P2283, DOI [10.1145/2702613.2732836, DOI 10.1145/2702613.2732836]
   Nguyen Quynh N., 2017, AI CAPABILITIES USER
   Norman D. A., 2005, EMOTIONAL DESIGN WHY
   Payr Sabine, 2013, VIRTUAL BUTLERS REAL, P146, DOI [10.1007/978-3-642-37346-6, DOI 10.1007/978-3-642-37346-6]
   Porcheron M, 2017, CSCW'17: COMPANION OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P431, DOI 10.1145/3022198.3022666
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Purington A, 2017, 2017 CHI C HUM FACT, DOI [10.1145/3027063.3053246, DOI 10.1145/3027063.3053246]
   Rammohan R, 2017, J ALLERGY CLIN IMMUN, V139, pAB250, DOI 10.1016/j.jaci.2016.12.804
   SCOTT WE, 1966, ORGAN BEHAV HUM PERF, V1, P3, DOI 10.1016/0030-5073(66)90003-1
   Sebastian J, 2017, COMPUT HUM BEHAV, V73, P479, DOI 10.1016/j.chb.2017.03.071
   Sheldon KM, 2001, J PERS SOC PSYCHOL, V80, P325, DOI 10.1037/0022-3514.80.2.325
   Tuch A. N, 2013, P CHI 2013, P2079, DOI DOI 10.1145/2470654.2481285
   Vaananen-Vainio-Mattila K., 2010, P 9 INT C MOB UB MUL, P11
   Vandenberghe Bert, 2017, P 2017 CHI C EXT ABS, P782
   Vtyurina A., 2017, P CHI C HUM FACT COM, P2187, DOI 10.1145/ 3027063
   Watson D, 1988, J PERS SOC PSYCHOL, V54, P6
   You DJ, 2012, J BIOL ENG, V6, DOI 10.1186/1754-1611-6-15
   Zamora Jennifer, 2017, RISE CHATBOTS FINDIN, P109, DOI [10.1145/3030024.3040201, DOI 10.1145/3030024.3040201]
NR 53
TC 29
Z9 31
U1 2
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5970-2
PY 2019
DI 10.1145/3290605.3300772
PG 12
WC Computer Science, Cybernetics; Computer Science, Information Systems;
   Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BN1HE
UT WOS:000474467906078
DA 2022-08-02
ER

PT C
AU Dziczkowski, G
   Doniec, A
   Lecoeuche, S
AF Dziczkowski, Grzegorz
   Doniec, Arnaud
   Lecoeuche, Stephane
BE Filipe, J
   Fred, A
TI TRIGGERING RULES FOR CONVERSATIONAL AGENTS IN TRADING SITUATIONS
SO ICAART 2011: PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON AGENTS
   AND ARTIFICIAL INTELLIGENCE, VOL 1
LA English
DT Proceedings Paper
CT 3rd International Conference on Agents and Artificial Intelligence
CY JAN 28-30, 2011
CL Rome, ITALY
SP Inst Syst & Technol Informat Control & Commun
DE Conversational agents; Data mining; Web intelligence; Behavior analysis
AB This paper describes a methodology to establish behavior rules for conversational agents on commercial web sites. Our work is a contribution to a recent research field: agent mining (Cao, 2009) which results from two interrelated research area: Agent/Multi-agent system and Data Mining. The proposed methodology is based on behavior analysis of e-commerce clients and customers' segmentation. Our proposal has been applied on a real commercial web site to construct the triggering rules of a virtual seller agent.
C1 [Dziczkowski, Grzegorz; Doniec, Arnaud; Lecoeuche, Stephane] Univ Lille Nord France, Ecole Mines Douai, IA, Douai, France.
RP Dziczkowski, G (corresponding author), Univ Lille Nord France, Ecole Mines Douai, IA, Douai, France.
EM grzegorz.dziczkowski@mines-douai.fr; arnaud.doniec@mines-douai.fr;
   stephane.lecoeuche@mines-douai.fr
RI Doniec, Arnaud/AAG-6758-2020; Lecoeuche, Stéphane/AAG-3139-2020
OI Doniec, Arnaud/0000-0002-3843-6729; Lecoeuche,
   Stéphane/0000-0002-5599-1185
CR CADEZ I, 2000, MSRTR0018
   Cao LB, 2009, DATA MINING AND MULTI-AGENT INTEGRATION, P3, DOI 10.1007/978-1-4419-0522-2_1
   Joshi A, 2000, ACM SIGMOD WORKSH RE
   Paliouras G, 2000, P INT C MACH LEARN I
   Pierrakos D, 2003, USER MODEL USER-ADAP, V13, P311, DOI 10.1023/A:1026238916441
   Srivastava J., 2000, SIGKDD EXPLORATIONS, V1, P12, DOI DOI 10.1145/846183.846188
   Yan T. W., 1997, TECHNICAL REPORT
NR 7
TC 0
Z9 0
U1 0
U2 0
PU INSTICC-INST SYST TECHNOLOGIES INFORMATION CONTROL & COMMUNICATION
PI SETUBAL
PA AVENIDA D MANUEL L, 27A 2 ESQUERDO, SETUBAL, 2910-595, PORTUGAL
BN 978-989-8425-40-9
PY 2011
BP 382
EP 387
PG 6
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BG8JP
UT WOS:000392352700052
DA 2022-08-02
ER

PT J
AU Fossa, F
   Sucameli, I
AF Fossa, Fabio
   Sucameli, Irene
TI Gender Bias and Conversational Agents: an ethical perspective on Social
   Robotics
SO SCIENCE AND ENGINEERING ETHICS
LA English
DT Article
DE Design Ethics; Conversational agents; Gender Bias; Discrimination; Moral
   Technology
ID STEREOTYPES; TECHNOLOGY; RESPONSES; COMPUTERS; MACHINES
AB The increase in the spread of conversational agents urgently requires to tackle the ethical issues linked to their design. In fact, developers frequently include in their products cues that trigger social biases in order to maximize the performance and the quality of human-machine interactions. The present paper discusses whether and to what extent it is ethically sound to intentionally trigger gender biases through the design of virtually embodied conversational agents. After outlining the complex dynamics involving social biases, social robots, and design, we evaluate the ethics of integrating gender cues in conversational agents, analysing four different approaches to the problem. Finally, we suggest which approach in our opinion might have the best chances to reduce the negative effects of biases and discriminatory visions of gender dynamics.
C1 [Fossa, Fabio] Politecn Milan, Dept Mech Engn, Milan, Italy.
   [Sucameli, Irene] Univ Pisa, Dept Comp Sci, Pisa, Italy.
RP Fossa, F (corresponding author), Politecn Milan, Dept Mech Engn, Milan, Italy.
EM fabio.fossa@polimi.it; irene.sucameli@phd.unipi.it
CR Alfano, 2013, CHARACTER MORAL FICT, DOI [10.1017/CBO9781139208536, DOI 10.1017/CBO9781139208536]
   Bernotat J, 2021, INT J SOC ROBOT, V13, P477, DOI 10.1007/s12369-019-00562-7
   Bernotat J, 2017, LECT NOTES ARTIF INT, V10652, P75, DOI 10.1007/978-3-319-70022-9_8
   Bisconti P, 2021, ADV ROBOTICS, V35, P561, DOI 10.1080/01691864.2021.1886167
   Borenstein J, 2016, SCI ENG ETHICS, V22, P31, DOI 10.1007/s11948-015-9636-2
   Brahnam Sheryl, 2015, Design, User Experience and Usability: Users and Interactions. 4th International Conference, DUXU 2015, held as part of HCI International 2015. Proceedings LNCS 9187, P172, DOI 10.1007/978-3-319-20898-5_17
   Brahnam S, 2012, INTERACT COMPUT, V24, P139, DOI 10.1016/j.intcom.2012.05.001
   Breazeal C, 2003, ROBOT AUTON SYST, V42, P167, DOI 10.1016/S0921-8890(02)00373-1
   Bryant D, 2020, ACMIEEE INT CONF HUM, P13, DOI 10.1145/3319502.3374778
   Carpenter J, 2009, INT J SOC ROBOT, V1, P261, DOI 10.1007/s12369-009-0016-4
   Coeckelbergh M, 2012, GROWING MORAL RELATIONS: CRITIQUE OF MORAL STATUS ASCRIPTION, P1, DOI 10.1057/9781137025968
   Curry A.C., 2018, P 2 ACL WORKSH ETH N, P7
   De Angeli A., 2006, P GENDER INTERACTION, P1
   Dufour F., 2016, SOCIAL SCI, V5, P27, DOI [10.3390/socsci5030027, DOI 10.3390/SOCSCI5030027]
   Eyssel F, 2012, BRIT J SOC PSYCHOL, V51, P724, DOI 10.1111/j.2044-8309.2011.02082.x
   Eyssel F, 2012, J APPL SOC PSYCHOL, V42, P2213, DOI 10.1111/j.1559-1816.2012.00937.x
   Fogg B. J, 2008, HUMAN COMPUTER INTER, P133
   Frank LE, 2020, SCI ENG ETHICS, V26, P369, DOI 10.1007/s11948-019-00099-y
   Gentzel M, 2020, SCI ENG ETHICS, V26, P931, DOI 10.1007/s11948-019-00155-7
   Gunkel DJ, 2018, ROBOT RIGHTS
   Gunkel DJ, 2012, MACHINE QUESTION: CRITICAL PERSPECTIVES ON AI, ROBOTS, AND ETHICS, P1
   IJsselsteijn W, 2006, LECT NOTES COMPUT SC, V3962, P1
   Isaac AMC., 2017, ROBOT ETHICS 20 NEW, P157
   Jung EH, 2016, CHI 16, DOI DOI 10.1145/2851581.2892428
   Klincewicz Michal., 2016, STUDIELOGIC GRAMMA, V48, P171, DOI [10.1515/slgr-2016-0061, DOI 10.1515/SLGR-2016-0061]
   Kraus M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P112
   Kuchenbrandt D, 2014, INT J SOC ROBOT, V6, P417, DOI 10.1007/s12369-014-0244-0
   Ladwig RC, 2018, PROCEEDINGS OF THE 4TH CONFERENCE ON GENDER & IT (GENDERIT '18), P67, DOI 10.1145/3196839.3196851
   Lee M, 2021, P 2021 CHI C HUM FAC
   Leonard TC, 2008, CONST POLITICAL ECON, V19, P356, DOI 10.1007/s10602-008-9056-2
   McDonnell M, 2019, INTERACT COMPUT, V31, P116, DOI 10.1093/iwc/iwz007
   Millar J, 2015, IEEE TECHNOL SOC MAG, V34, P47, DOI 10.1109/MTS.2015.2425612
   Nass C, 1996, INT J HUM-COMPUT ST, V45, P669, DOI 10.1006/ijhc.1996.0073
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Nass C, 1997, J APPL SOC PSYCHOL, V27, P864, DOI 10.1111/j.1559-1816.1997.tb00275.x
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nomura T., 2017, GEND GENOME, V1, P18, DOI [DOI 10.1089/GG.2016.29002.NOM, 10.1089/gg.2016.29002.nom]
   Powers A, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P158
   Rachels J., 2002, ELEMENTS MORAL PHILO, V4
   Reich-Stiebert N, 2017, ACMIEEE INT CONF HUM, P166, DOI 10.1145/2909824.3020242
   Robertson J, 2010, BODY SOC, V16, P1, DOI 10.1177/1357034X10364767
   Sandry E, 2015, INT J SOC ROBOT, V7, P335, DOI 10.1007/s12369-014-0278-3
   Savulescu J, 2015, ARTIF INTELL, DOI [10.1007/978-3-319-09668-1_6, DOI 10.1007/978-3-319-09668-1_6]
   Siegel M, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2563, DOI 10.1109/IROS.2009.5354116
   Silvervarg Annika, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P153, DOI 10.1007/978-3-642-33197-8_16
   Sondergaard MLJ, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P869, DOI 10.1145/3196709.3196766
   Sparrow R, 2017, INT J SOC ROBOT, V9, P465, DOI 10.1007/s12369-017-0413-z
   Sucameli I, 2021, ADV ROBOTICS, V35, P553, DOI 10.1080/01691864.2021.1884132
   Sunstein CR, 2015, YALE J REGUL, V32, P413
   Sutton S. J, 2020, CUI 20 P 2 C CONV US
   Tay B, 2014, COMPUT HUM BEHAV, V38, P75, DOI 10.1016/j.chb.2014.05.014
   Trovato G, 2018, ROBOTICS, V7, DOI 10.3390/robotics7030050
   Van den Hoven J, 2012, SCI ENG ETHICS, V18, P143, DOI 10.1007/s11948-011-9277-z
   Verbeek, 2011, MORALIZING TECHNOLOG, DOI [10.7208/chicago/9780226852904.001.0001, DOI 10.7208/CHICAGO/9780226852904.001.0001]
   Wallach W., 2009, MORAL MACHINES TEACH, DOI [10.1093/acprof.oso/9780195374049.001.0001, DOI 10.1093/ACPROF:OSO/9780195374049.001.0001, 10.1093/acprof:oso/9780195374049.001.0001]
   Wang ZX, 2021, PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2021), P1336, DOI 10.1145/3461778.3462087
   Weber J, 2007, STUD INTERDISZ GESCH, V13, P53, DOI 10.1007/978-3-531-90295-1_3
   Wessel M., 2020, CULTURALLY SUSTAINAB, P239, DOI [10.3233/FAIA200920, DOI 10.3233/FAIA200920]
   Wessel M, 2021, INT J SOC ROBOT, DOI 10.1007/s12369-021-00854-x
   West M., 2019, ID BLUSH COULD CLOSI
   Winkle K, 2021, ACMIEEE INT CONF HUM, P29, DOI 10.1145/3434074.3446910
NR 61
TC 0
Z9 0
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1353-3452
EI 1471-5546
J9 SCI ENG ETHICS
JI Sci. Eng. Ethics
PD JUN
PY 2022
VL 28
IS 3
AR 23
DI 10.1007/s11948-022-00376-3
PG 23
WC Ethics; Engineering, Multidisciplinary; History & Philosophy Of Science;
   Multidisciplinary Sciences; Philosophy
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Social Sciences - Other Topics; Engineering; History & Philosophy of
   Science; Science & Technology - Other Topics; Philosophy
GA 0Q2FN
UT WOS:000784739700001
PM 35445886
OA hybrid, Green Published
DA 2022-08-02
ER

PT C
AU Thi, DN
   The, DB
AF Thi Duyen Ngo
   The Duy Bui
BE Ghose, A
   Governatori, G
   Sadananda, R
TI When and How to Smile: Emotional Expression for 3D Conversational Agents
SO AGENT COMPUTING AND MULTI-AGENT SYSTEMS
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 10th Pacific Rim International Conference on Multi-Agent Systems
CY NOV 21-23, 2007
CL Bangkok, THAILAND
DE Human Computer Interaction; 3D Conversational Agents; Emotional Facial
   Expressions
ID MODEL
AB Conversational agents have become more and more common in the multimedia worlds of films, educative applications, e - business, computer games. Many techniques have been developed to enable these agents to behave in a human-like manner. In order to do so, conversational agents are simulated with emotion and personality as well as communicative channels such as voice, head and eye movement, manipulator and facial expression. Up to now, creating facial expression from emotions has received much attention. However, most of the work concentrates on producing static facial expressions from emotions. In this paper, we propose a scheme for displaying continuous emotional states of a conversational agent on a 3D face. The main idea behind the scheme is that an emotional facial expression happens for a few seconds only when there is a significant change in the emotional states. This makes the emotional facial expressions of the conversational agents more realistic due to the fact that a facial expression only stay on the face for a few seconds.
C1 [Thi Duyen Ngo; The Duy Bui] Vietnam Natl Univ, Coll Technol, Hanoi, Vietnam.
RP Thi, DN (corresponding author), Vietnam Natl Univ, Coll Technol, Hanoi, Vietnam.
EM duyennt@vnu.edu.vn; duybt@vnu.edu.vn
CR Albrecht I, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P77, DOI 10.1109/PCCGA.2002.1167841
   ALBRECHT I, 2005, THESIS U SAARLANDES
   [Anonymous], 2001, LNCS
   Bui TD, 2002, LECT NOTES ARTIF INT, V2479, P129
   Bui TD, 2003, COMP ANIM CONF PROC, P33, DOI 10.1109/CASA.2003.1199301
   BUI TD, 2004, P CASA 2004 COMP GRA
   BUI TD, 2004, P CGI 2004 IEEE COMP
   Cohen M. M., 1993, Models and Techniques in Computer Animation, P139
   Damasio A.R., 1994, DESCARTES ERROR EMOT
   Darwin C, 1904, EXPRESS EMOT MAN, DOI 10.1037/10001-000
   DECARLO DC, 2002, COMPUTER ANIMATION 2
   Ekman P., 1975, UNMASKING FACE GUIDE
   El-Nasr MS, 2000, AUTON AGENT MULTI-AG, V3, P219, DOI 10.1023/A:1010030809960
   FORGAS JP, 1987, PERSONALITY SOCIAL P, V13
   Galernter D. H., 1994, MUSE MACHINE
   HAGER JC, 1995, ESSENTIAL BEHAV SCI
   Hayes-Roth B., 1997, Proceedings of the First International Conference on Autonomous Agents, P1, DOI 10.1145/267658.267660
   King S., 2000, P DEF 2000 29 30 NOV, P7
   KSHIRSAGAR S, 2002, P 2 INT S SMART GRAP, P107
   KURLANDER D, 1996, SIGGRAPH 96, P225
   LATTA C, 2002, SOC ART INT SOC BEHA
   Paiva A., 1996, P 3 INT JOINT C AUT, P194
   PARKE FI, 1996, COMPUTER FACIAL ANIM
   PERLIN K, 1996, COMPUTER GRAPHICS, V30, P205
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Plutchik R., 1984, APPROACHES EMOTION
   Raouzaiou A, 2003, LECT NOTES COMPUT SC, V2849, P298
   REILLY WSN, 1996, CMUCS96138
   Stern A., 1998, Proceedings of the Second International Conference on Autonomous Agents, P334, DOI 10.1145/280765.280852
   VELASQUEZ JD, 1997, P AAAI 97, P10
NR 30
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-01638-7
J9 LECT NOTES ARTIF INT
PY 2009
VL 5044
BP 349
EP 358
PG 10
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BKG42
UT WOS:000268022400031
DA 2022-08-02
ER

PT C
AU Ahmad, R
   Siemon, D
   Gnewuch, U
   Robra-Bissantz, S
AF Ahmad, Rangina
   Siemon, Dominik
   Gnewuch, Ulrich
   Robra-Bissantz, Susanne
GP Assoc Informat Syst
TI The Benefits and Caveats of Personality-Adaptive Conversational Agents
   in Mental Health Care Completed Research
SO DIGITAL INNOVATION AND ENTREPRENEURSHIP (AMCIS 2021)
LA English
DT Proceedings Paper
CT 27th Annual Americas Conference on Information Systems (AMCIS)
CY AUG 09-13, 2021
CL ELECTR NETWORK
DE Conversational Agents; Personality-Adaptive Conversational Agents;
   Mental Health Care
ID ELIZA; CUES
AB Artificial intelligence (AI) technologies enable conversational agents (CAs) to perform highly complex tasks in a human-like manner. For example, CAs may help people cope with anxiety and thus can improve mental health and well-being. In order to achieve this and support patients in an authentic way, it is needed to imbue CAs with human-like behavior, such as personality. However, with today's powerful AI capabilities, critical voices regarding AI ethics are becoming increasingly loud to carefully consider potential consequences of designing CAs that appear too human-like. Personality adaptive conversational agents (PACAs) that automatically infer users' personality traits and adapt accordingly to their personality, fall into this category and need to be investigated regarding their benefits and caveats in mental health care. The results of our conducted qualitative study show that PACAs can be beneficial for mental health support, however it also raises concerns among participants about trust and privacy issues.
C1 [Ahmad, Rangina; Robra-Bissantz, Susanne] TU Braunschweig, Braunschweig, Germany.
   [Siemon, Dominik] LUT Univ, Lappeenranta, Finland.
   [Gnewuch, Ulrich] Karlsruhe Inst Technol, Karlsruhe, Germany.
RP Ahmad, R (corresponding author), TU Braunschweig, Braunschweig, Germany.
EM rangina.ahmad@tu-bs.de; dominik.siemon@lut.fi; ulrich.gnewuch@kit.edu;
   s.robra-bissantz@tu-bs.de
CR Ahmad R, 2021, P 54 HAW INT C SYST, P4043
   Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Babbie ER, 2013, PRACTICE SOCIAL RES, V13
   Bassett C, 2019, AI SOC, V34, P803, DOI 10.1007/s00146-018-0825-9
   Botsociety, 2020, DESIGN PREVIEW PROTO
   Boyd RL, 2017, CURR OPIN BEHAV SCI, V18, P63, DOI 10.1016/j.cobeha.2017.07.017
   Brendel AB, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13041974
   Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009
   Ferrucci DA, 2012, IBM J RES DEV, V56, DOI 10.1147/JRD.2012.2184356
   Gnewuch U., 2017, P 38 INT C INFORM SY
   Graham SA, 2020, PSYCHIAT RES, V284, DOI 10.1016/j.psychres.2019.112732
   HEISER JF, 1979, J PSYCHIAT RES, V15, P149, DOI 10.1016/0022-3956(79)90008-6
   IBM Watson PI, 2020, IBM WATS PERES INS
   Kerr IR., 2003, U OTT LAW TECHNOL J, V1, P285
   Kocaballi A. B., 2020, CONVERSATIONAL AGENT
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Luxton DD, 2020, B WORLD HEALTH ORGAN, V98, P285, DOI 10.2471/BLT.19.237636
   Luxton DD, 2014, ARTIF INTELL MED, V62, P1, DOI 10.1016/j.artmed.2014.06.004
   Mairesse F, 2010, USER MODEL USER-ADAP, V20, P227, DOI 10.1007/s11257-010-9076-2
   MAYER RC, 1995, ACAD MANAGE REV, V20, P709, DOI 10.2307/258792
   McCrae RR, 1997, AM PSYCHOL, V52, P509, DOI 10.1037/0003-066X.52.5.509
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   NASS C, 1995, INT J HUM-COMPUT ST, V43, P223, DOI 10.1006/ijhc.1995.1042
   Natale S., 2018, NEW MEDIA SOC
   Peters O., 2013, CRITICS DIGITALISATI
   Phelps J, 2000, J PUBLIC POLICY MARK, V19, P27, DOI 10.1509/jppm.19.1.27.16941
   Porra J., 2019, INFORM SYSTEMS FRONT
   Replika, 2021, REPLIKA
   Robert LP., 2020, FNT INFORM SYST, V4, P107, DOI [10.1561/2900000018, DOI 10.1561/2900000018]
   Shah H, 2016, COMPUT HUM BEHAV, V58, P278, DOI 10.1016/j.chb.2016.01.004
   Shaw G.B, 2008, PYGMALION MAJOR BARB
   Shum HY, 2018, FRONT INFORM TECH EL, V19, P10, DOI 10.1631/FITEE.1700826
   Strohmann T., 2019, AIS T HUMAN COMPUTER, V11, P54, DOI [https://doi.org/10.17705/1thci.00113, DOI 10.17705/1THCI.00113]
   Ta V., 2020, J MED INTERNET RES, V22
   Torous John, 2020, JMIR Ment Health, V7, pe18848, DOI 10.2196/18848
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Weizenbaum J., 1972, NIGHTMARE COMPUER
   WHO, 2017, DEPRESSION OTHER COM
   WHO, WHO EX BOARD STRESS
   Woebot Health, 2021, WOEB
NR 40
TC 0
Z9 0
U1 2
U2 2
PU ASSOC INFORMATION SYSTEMS
PI ATLANTA
PA P.O. BOX 2712, ATLANTA, GA 30301-2712 USA
PY 2021
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR8LY
UT WOS:000672599802051
DA 2022-08-02
ER

PT J
AU Li, CL
   Xing, WL
   Leite, W
AF Li, Chenglu
   Xing, Wanli
   Leite, Walter
TI Building socially responsible conversational agents
SO BRITISH JOURNAL OF EDUCATIONAL TECHNOLOGY
LA English
DT Article; Early Access
DE discourse safety; online discussion forums; responsible conversational
   agents; social support
ID SUPPORT; PARTICIPATION; ENGAGEMENT; ANALYTICS
AB A discussion forum is a valuable tool to support student learning in online contexts. However, interactions in online discussion forums are sparse, leading to other issues such as low engagement and dropping out. Recent educational studies have examined the affordances of conversational agents (CA) powered by artificial intelligence (AI) to automatically support student participation in discussion forums. However, few studies have paid attention to the safety of CAs. This study aimed to address the safety challenges of CAs constructed with educational big data to support learning. Specifically, we proposed a safety-aware CA model, benchmarked with two state-of-the-art (SOTA) models, to support high school student learning in an online algebra learning platform. We applied automatic text analysis to evaluate the safety and socio-emotional support levels of CA-generated and human-generated texts. A large dataset was used to train and evaluate the CA models, which consisted of all discussion post-reply pairs (n = 2,097,139) by 71,918 online math learners from 2015 to 2021. Results show that while SOTA models can generate supportive texts, their safety is compromised. Meanwhile, our proposed model can effectively enhance the safety of generated texts while providing comparable support.
C1 [Li, Chenglu; Xing, Wanli] Univ Florida, Coll Educ, Sch Teaching & Learning, Gainesville, FL 32611 USA.
   [Leite, Walter] Univ Florida, Coll Educ, Sch Human Dev & Org Studies Educ, Gainesville, FL 32611 USA.
RP Xing, WL (corresponding author), Univ Florida, Coll Educ, Sch Teaching & Learning, Gainesville, FL 32611 USA.
EM wanli.xing@coe.ufl.edu
OI Xing, Wanli/0000-0002-1446-889X; Li, Chenglu/0000-0002-1782-0457
FU Institute of Education Sciences, US Department of Education
   [R305C160004]; University of Florida AI Catalyst [P0195022]; University
   of Florida Informatics Institute Seed Funding
FX The research reported here was supported by the Institute of Education
   Sciences, US Department of Education, through Grant R305C160004 to the
   University of Florida, the University of Florida AI Catalyst
   Grant-P0195022, and the University of Florida Informatics Institute Seed
   Funding. The opinions expressed are those of the authors and do not
   represent the views of the University of Florida, Institute of Education
   Sciences, or those of the US Department of Education. We thank Dr. Kara
   Dawson from School of Teaching and Learning at the University of Florida
   for suggestions. We also thank Perspective API for allowing greater
   daily request quotas for this research.
CR Abbott BP, 2016, PHYS REV LETT, V116, DOI 10.1103/PhysRevLett.116.241102
   Almatrafi O, 2018, COMPUT EDUC, V118, P1, DOI 10.1016/j.compedu.2017.11.002
   Bae SM, 2021, CHILD YOUTH SERV REV, V123, DOI 10.1016/j.childyouth.2021.105946
   Borkan D, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P491, DOI 10.1145/3308560.3317593
   Charlevoix, 2014, P 1 ACM C LEARN SCAL, P71, DOI DOI 10.1145/2556325.2566245
   Chenglu Li, 2021, LAK21: LAK21: 11th International Learning Analytics and Knowledge Conference. Proceedings, P572, DOI 10.1145/3448139.3448200
   Chiu TKF, 2018, AUSTRALAS J EDUC TEC, V34, P16, DOI 10.14742/ajet.3240
   Cleveland-Innes M, 2012, INT REV RES OPEN DIS, V13, P269, DOI 10.19173/irrodl.v13i4.1234
   Coman C, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su122410367
   Cruz S., 2021, PUBLICATION ARIZONA
   Curry A.C., 2018, P 2 ACL WORKSH ETH N, P7
   Deetjen U, 2016, J AM MED INFORM ASSN, V23, P508, DOI 10.1093/jamia/ocv190
   Devlin J., 2018, ARXIV
   Dinan E., 2021, ARXIV
   Dixon L, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P67, DOI 10.1145/3278721.3278729
   Duggan, 2017, ONLINE HARASSMENT
   Elliott R, 2011, PSYCHOTHERAPY, V48, P43, DOI 10.1037/a0022187
   Er E, 2019, INTERACT LEARN ENVIR, V27, P685, DOI 10.1080/10494820.2019.1610455
   Essen C., 2018, INT J ED EVALUATION, V4, P1
   Ezeah C, 2014, J RES METHOD ED, V4, P8
   Fedus W., 2018, PREPRINT
   Gasevic D, 2019, COMPUT HUM BEHAV, V92, P562, DOI 10.1016/j.chb.2018.07.003
   Goggins S, 2016, COMPUT EDUC, V94, P241, DOI 10.1016/j.compedu.2015.11.002
   Grossman J., 2019, AAAI 2019 STORY ENAB
   Guo SY, 2016, PSYCHOL SCHOOLS, V53, P432, DOI 10.1002/pits.21914
   Han S, 2022, COMPUT EDUC, V179, DOI 10.1016/j.compedu.2021.104395
   Hasan R, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113894
   Hew KF, 2016, BRIT J EDUC TECHNOL, V47, P320, DOI 10.1111/bjet.12235
   Holmes W, 2019, DISTANCE EDUC, V40, P309, DOI 10.1080/01587919.2019.1637716
   Hsu JY, 2018, INTERACT LEARN ENVIR, V26, P1100, DOI 10.1080/10494820.2018.1446990
   Indurthi S, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P376
   INFANTE DA, 1986, COMMUN MONOGR, V53, P61, DOI 10.1080/03637758609376126
   Io HN, 2017, IN C IND ENG ENG MAN, P215, DOI 10.1109/IEEM.2017.8289883
   Jadhav Komal P., 2020, Computing in Engineering and Technology. Proceedings of ICCET 2019. Advances in Intelligent Systems and Computing (AISC 1025), P533, DOI 10.1007/978-981-32-9515-5_51
   Kim Hae-Young, 2017, Restor Dent Endod, V42, P152, DOI 10.5395/rde.2017.42.2.152
   Koedinger KR, 2013, SCIENCE, V342, P935, DOI 10.1126/science.1238056
   Langford CPH, 1997, J ADV NURS, V25, P95, DOI 10.1046/j.1365-2648.1997.1997025095.x
   Laurillard D, 2012, TEACHING AS A DESIGN SCIENCE, P1
   Lee N., 2019, WNLP ACL PP, P177
   Li C., P 9 ACM C LEARNING S, DOI [10.1145/3491140.3528293, DOI 10.1145/3491140.3528293]
   Li CL, 2022, DISTANCE EDUC, V43, P30, DOI 10.1080/01587919.2021.2020619
   Li CL, 2021, INT J ARTIF INTELL E, V31, P186, DOI 10.1007/s40593-020-00235-x
   Lianos H, 2018, CRIME DELINQUENCY, V64, P674, DOI 10.1177/0011128717714204
   Martinez-Maldonado R, 2019, INT J COMP-SUPP COLL, V14, P383, DOI 10.1007/s11412-019-09308-z
   Miller A., 2017, P 2017 C EMP METH NA, P79, DOI [10.18653/v1/D17-2014, DOI 10.18653/V1/D17-2014]
   Moore RL, 2019, INTERACT LEARN ENVIR, V27, P655, DOI 10.1080/10494820.2019.1610453
   Mozafari M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237861
   Nobata C, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P145, DOI 10.1145/2872427.2883062
   Obadimu A, 2019, LECT NOTES COMPUT SC, V11549, P214, DOI 10.1007/978-3-030-21741-9_22
   Ortega-Arranz A, 2019, COMPUT EDUC, V142, DOI 10.1016/j.compedu.2019.103639
   Paolacci G, 2010, JUDGM DECIS MAK, V5, P411
   Park I, 2020, INFORM MANAGE-AMSTER, V57, DOI 10.1016/j.im.2020.103372
   Paszke A, 2019, ADV NEUR IN, V32
   Pedro F., 2019, ED2019WS8 UN ED SCI
   Perkins D. N., 2013, KNOWLEDGE DESIGN
   Perspective API., 2021, US MACH LEARN RED TO
   Perspective API., 2021, CAS STUD
   Redmond P., 2006, Internet and Higher Education, V9, P267, DOI 10.1016/j.iheduc.2006.08.003
   Rieder B, 2021, BIG DATA SOC, V8, DOI 10.1177/20539517211046181
   Rizvi S, 2019, COMPUT EDUC, V137, P32, DOI 10.1016/j.compedu.2019.04.001
   Roller S., 2021, P 16 C EUROPEAN CHAP, P300
   Ruscio J, 2008, PSYCHOL METHODS, V13, P19, DOI 10.1037/1082-989X.13.1.19
   Salter NP, 2015, COMPUT HUM BEHAV, V46, P18, DOI 10.1016/j.chb.2014.12.037
   Sconfienza C, 2019, J OCCUP HEALTH, V61, P91, DOI 10.1002/1348-9585.12020
   SHUMAKER SA, 1984, J SOC ISSUES, V40, P11, DOI 10.1111/j.1540-4560.1984.tb01105.x
   Sung SH, 2021, J SCI EDUC TECHNOL, V30, P210, DOI 10.1007/s10956-020-09856-2
   Syvanen S, 2020, J COMMUN MANAG, V24, P339, DOI 10.1108/JCOM-11-2019-0145
   Tang HT, 2018, DISTANCE EDUC, V39, P353, DOI 10.1080/01587919.2018.1476841
   Tang S, 2016, PROCEEDINGS OF THE THIRD (2016) ACM CONFERENCE ON LEARNING @ SCALE (L@S 2016), P321, DOI 10.1145/2876034.2893444
   Trujillo M., 2021, P 5 WORKSHOP ONLINE, P164, DOI [10.18653/v1/2021.woah-1.18, DOI 10.18653/V1/2021.WOAH-1.18]
   van de Poel I, 2021, ETHICS INF TECHNOL, V23, P27, DOI 10.1007/s10676-018-9461-9
   Vanbrabant K, 2012, SOC NETWORKS, V34, P164, DOI 10.1016/j.socnet.2011.10.008
   Vaswani A., 2017, ARXIV
   Villasclaras-Fernandez ED, 2009, FRONT ARTIF INTEL AP, V200, P231, DOI 10.3233/978-1-60750-028-5-231
   Wang J., 2021, COMPUTERS ED ARTIFIC, V2, P1
   Wang Z, 2020, HEAT TRANSFER ENG, V41, P1856, DOI 10.1080/01457632.2019.1674554
   WELLMAN B, 1990, AM J SOCIOL, V96, P558, DOI 10.1086/229572
   Wills T. A., 1991, PROSOCIAL BEHAV, P265
   Wiyono S., 2020, IJCSAM INT J COMPUTI, V6, P50
   Wolf Thomas, 2020, Zenodo, DOI [10.5281/ZENODO.5541855, 10.5281/ZENODO.5553107, 10.5281/ZENODO.5532744, 10.5281/ZENODO.5347031, 10.5281/ZENODO.5708366, 10.5281/ZENODO.5619972, 10.5281/ZENODO.6422483, 10.5281/ZENODO.3385997, 10.5281/ZENODO.5619881, 10.5281/ZENODO.5706403, 10.5281/ZENODO.5500478, 10.5281/ZENODO.5500365, 10.5281/ZENODO.5537904, 10.5281/ZENODO.5523199, 10.5281/ZENODO.5608580]
   Wu J., 2019, OPENAI BLOG TECH REP, V1, P1
   Xing WL, 2019, INTERNET HIGH EDUC, V43, DOI 10.1016/j.iheduc.2019.100690
   Xing WL, 2018, COMPUT HUM BEHAV, V86, P227, DOI 10.1016/j.chb.2018.04.042
   Xu J., 2020, ARXIV PREPRINT ARXIV
   Zaib M., 2020, P AUSTRALASIAN COMPU, P1
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270
   Zheng LQ, 2020, INT J COMP-SUPP COLL, V15, P193, DOI 10.1007/s11412-020-09320-8
   Zou WT, 2021, COMPUT HUM BEHAV, V115, DOI 10.1016/j.chb.2020.106582
   Zumbrunn S, 2014, INSTR SCI, V42, P661, DOI 10.1007/s11251-014-9310-0
NR 89
TC 1
Z9 1
U1 2
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0007-1013
EI 1467-8535
J9 BRIT J EDUC TECHNOL
JI Br. J. Educ. Technol.
DI 10.1111/bjet.13227
EA MAY 2022
PG 28
WC Education & Educational Research
WE Social Science Citation Index (SSCI)
SC Education & Educational Research
GA 2A6ZA
UT WOS:000809646500001
DA 2022-08-02
ER

PT J
AU Bavaresco, R
   Silveira, D
   Reis, E
   Barbosa, J
   Righi, R
   Costa, C
   Antunes, R
   Gomes, M
   Gatti, C
   Vanzin, M
   Clair, S
   Silva, E
   Moreira, C
AF Bavaresco, Rodrigo
   Silveira, Diorgenes
   Reis, Eduardo
   Barbosa, Jorge
   Righi, Rodrigo
   Costa, Cristiano
   Antunes, Rodolfo
   Gomes, Marcio
   Gatti, Clauter
   Vanzin, Mariangela
   Clair Junior, Saint
   Silva, Elton
   Moreira, Carlos
TI Conversational agents in business: A systematic literature review and
   future research directions
SO COMPUTER SCIENCE REVIEW
LA English
DT Review
DE Conversational agents; Chatbots; Machine learning; Business; Industry;
   Literature review
ID CHATBOT; GAMIFICATION; SERVICE
AB The field of business shows an increasing interest in exploring conversational agents to improve service quality and market competitiveness. Furthermore, the advances in machine learning capabilities leverage the natural language processing towards natural and straightforward dialogue experiences for industries. However, in the best of our knowledge, no literature review outlines conversational agents in the business industry, primarily taking into account computational learning capabilities. This article presents a systematic literature review that encompasses these areas looking through the use of machine learning to improve the field of business. The review followed a guideline for systematic reviews to present the literature of the last decade, emphasizing business perspectives such as domains, goals, and challenges, and computational methods for self-learning, personalization, and response generation of conversational agents. As a result, the article provides the answers of three general, three focused, and two statistical questions to address the role of artificial intelligence in conversational agents applied to business domains. In this regard, the results show that no study combines self-learning, personalization, and generative-based responses for the same business solution. Additionally, the article describes the organization of the state-of-the-art, highlighting the correlation of business perspectives and machine learning methods. The contributions of this review focus on opportunities and future research directions towards human-like conversational agents for business. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Bavaresco, Rodrigo; Silveira, Diorgenes; Reis, Eduardo; Barbosa, Jorge; Righi, Rodrigo; Costa, Cristiano; Antunes, Rodolfo; Gomes, Marcio] Univ Vale Rio Sinos UNISINOS, Appl Comp Grad Program PPGCA, Software Innovat Lab SOFTWARELAB, Av Unisinos 950, Sao Leopoldo, RS, Brazil.
   [Gatti, Clauter; Vanzin, Mariangela; Clair Junior, Saint; Silva, Elton; Moreira, Carlos] Dell Inc, Av Ind Belgraf 400, Eldorado Do Sul, RS, Brazil.
RP Bavaresco, R (corresponding author), Univ Vale Rio Sinos UNISINOS, Appl Comp Grad Program PPGCA, Software Innovat Lab SOFTWARELAB, Av Unisinos 950, Sao Leopoldo, RS, Brazil.
EM rsimonb@unisinos.br
RI Barbosa, Jorge/L-9389-2013; Antunes, Rodolfo Stoffel/AAI-1742-2020; da
   Costa, Cristiano André/AAV-1894-2020
OI Barbosa, Jorge/0000-0002-0358-2056; Antunes, Rodolfo
   Stoffel/0000-0002-9388-492X; da Costa, Cristiano
   André/0000-0003-3859-6199; Bavaresco, Rodrigo/0000-0003-4188-735X
FU Dell Inc.
FX The authors would like to thank Dell Inc. for funding this work. We are
   also grateful to University of Vale do Rio dos Sinos (UNISINOS) and
   Applied Computing Graduate Program (PPGCA) for embracing this research.
CR Aalipour G, 2018, IEEE INT CONF BIG DA, P4861, DOI 10.1109/BigData.2018.8622395
   Ahmad NS, 2018, IEEE CONF OPEN SYST, P76, DOI 10.1109/ICOS.2018.8632700
   [Anonymous], 2014, SIGNAL INFORM PROCES
   [Anonymous], 2018, COMMUNICATION COMPUT, DOI DOI 10.1007/978-3-319-93408-2_10
   [Anonymous], [No title captured]
   [Anonymous], 2018, CHATBOTS WILL TRANSF
   [Anonymous], 2019, CHATBOTS MAGAZINE
   [Anonymous], [No title captured]
   [Anonymous], 2008, P 12 INT C EV ASS SO
   [Anonymous], 2017, P 9 INT C INF COMM T
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], 2014, AS PAC SIGN INF PROC
   Antares AE, 2014, INT C ADV COMP SCI I, P274, DOI 10.1109/ICACSIS.2014.7065845
   Atiyah A, 2018, INT CONF COMP SCI, P125, DOI 10.1109/CSIT.2018.8486187
   Bhadoria RS, 2018, NEURAL COMPUT APPL, V30, P3177, DOI 10.1007/s00521-017-2910-2
   Bhawiyuga A, 2017, 2017 INTERNATIONAL CONFERENCE ON SUSTAINABLE INFORMATION ENGINEERING AND TECHNOLOGY (SIET), P159, DOI 10.1109/SIET.2017.8304128
   Castro F, 2018, LECT NOTES COMPUT SC, V10954, P400, DOI 10.1007/978-3-319-95930-6_37
   Chakrabarti C, 2015, EXPERT SYST APPL, V42, P6878, DOI 10.1016/j.eswa.2015.04.067
   Chandar P, 2017, LECT NOTES COMPUT SC, V10514, P381, DOI 10.1007/978-3-319-67684-5_23
   Chen SQ, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P411, DOI 10.1145/3289600.3290971
   Chung M, 2020, J BUS RES, V117, P587, DOI 10.1016/j.jbusres.2018.10.004
   Cui L, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P97, DOI 10.18653/v1/P17-4017
   D'Haro LF, 2015, ASIAPAC SIGN INFO PR, P47, DOI 10.1109/APSIPA.2015.7415358
   D'silva GM, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P658, DOI 10.1109/I-SMAC.2017.8058261
   Dalmina L, 2019, BEHAV INFORM TECHNOL, V38, P1167, DOI 10.1080/0144929X.2019.1576768
   Deksne D, 2018, FRONT ARTIF INTEL AP, V307, P30, DOI 10.3233/978-1-61499-912-6-30
   Eichler K, 2012, KUNSTL INTELL, V26, P419, DOI 10.1007/s13218-012-0221-4
   Elsholz E, 2019, PROCEEDINGS OF THE 2019 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL (CHIIR'19), P301, DOI 10.1145/3295750.3298956
   Folstad A, 2018, LECT NOTES COMPUT SC, V11193, P194, DOI 10.1007/978-3-030-01437-7_16
   Griol D, 2016, LECT NOTES ARTIF INT, V9662, P121, DOI 10.1007/978-3-319-39324-7_11
   Handoyo E, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, COMPUTER, AND ELECTRICAL ENGINEERING (ICITACEE), P325, DOI 10.1109/ICITACEE.2018.8576921
   Hardalov M, 2019, INFORMATION, V10, DOI 10.3390/info10030082
   Hardalov M, 2018, LECT NOTES ARTIF INT, V11089, P48, DOI 10.1007/978-3-319-99344-7_5
   Hongshen Chen, 2017, ACM SIGKDD Explorations Newsletter, V19, P25, DOI 10.1145/3166054.3166058
   Horia C, 2019, COMPUT SPEECH LANG, V55, P1, DOI 10.1016/j.csl.2018.09.004
   Hussain Shafquat, 2019, Web, Artificial Intelligence and Network Applications. Proceedings of the Workshops of the 33rd International Conference on Advanced Information Networking and Applications (WAINA-2019). Advances in Intelligent Systems and Computing (927), P946, DOI 10.1007/978-3-030-15035-8_93
   Janzen S, 2009, 2009 IEEE THIRD INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING (ICSC 2009), P361, DOI 10.1109/ICSC.2009.44
   Jusoh S, 2018, INT C ELECT COMPUT
   Keshav S, 2007, ACM SIGCOMM COMP COM, V37, P83, DOI 10.1145/1273445.1273458
   Kiseleva J, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL (CHIIR'16), P121, DOI 10.1145/2854946.2854961
   Kurachi Y, 2018, FUJITSU SCI TECH J, V54, P2
   Kuramoto I, 2018, HAI'18: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT INTERACTION, P114, DOI 10.1145/3284432.3284457
   Lai ST, 2019, LECT NOTE DATA ENG, V25, P561, DOI 10.1007/978-3-030-02613-4_50
   Li Y, 2018, LECT NOTES ARTIF INT, V11108, P3, DOI 10.1007/978-3-319-99495-6_1
   Lokman AS, 2019, ADV INTELL SYST, V881, P1012, DOI 10.1007/978-3-030-02683-7_75
   Ma CH, 2018, LECT NOTES COMPUT SC, V10878, P476, DOI 10.1007/978-3-319-92537-0_55
   Ma CH, 2017, LECT NOTES COMPUT SC, V10261, P36, DOI 10.1007/978-3-319-59072-1_5
   Maedche A, 2019, BUS INFORM SYST ENG+, V61, P535, DOI 10.1007/s12599-019-00600-8
   Majumder A, 2018, LECT NOTES COMPUT SC, V10772, P604, DOI 10.1007/978-3-319-76941-7_51
   Mazumder S, 2017, SCALABLE COMPUT COMM, P1, DOI 10.1007/978-3-319-59834-5
   Morge M, 2011, LECT NOTES ARTIF INT, V6614, P141, DOI 10.1007/978-3-642-21940-5_9
   Mukherjee S, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P171, DOI 10.1145/2567948.2577021
   Niculescu Andreea I., 2014, Mobile Web Information Systems. 11th International Conference (MobiWIS 2014). Proceedings: LNCS 8640, P153, DOI 10.1007/978-3-319-10359-4_13
   Nuruzzaman M, 2018, INT CONF E BUS ENG, P54, DOI 10.1109/ICEBE.2018.00019
   Okuda T, 2018, FUJITSU SCI TECH J, V54, P4
   Petersen K, 2015, INFORM SOFTWARE TECH, V64, P1, DOI 10.1016/j.infsof.2015.03.007
   Pfeuffer N, 2019, BUS INFORM SYST ENG+, V61, P523, DOI 10.1007/s12599-019-00599-y
   Pradana Aditya, 2017, International Journal of Computer Information Systems and Industrial Management Applications, V9, P265
   Pricilla C, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATICS: CONCEPTS, THEORY AND APPLICATIONS (ICAICTA 2018), P244, DOI 10.1109/ICAICTA.2018.8541320
   Qiu MH, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P208
   Rahane W, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P601, DOI 10.1109/ICICCT.2018.8473172
   Ramesh K, 2017, COMM COM INF SC, V750, P336, DOI 10.1007/978-981-10-6544-6_31
   Dias LPS, 2018, TELEMAT INFORM, V35, P213, DOI 10.1016/j.tele.2017.11.002
   Sangroya A, 2017, 9TH INTERNATIONAL CONFERENCE ON MANAGEMENT OF EMERGENT DIGITAL ECOSYSTEMS (MEDES 2017), P128, DOI 10.1145/3167020.3167040
   Sapna, 2019, PROCEEDINGS OF THE 6TH ACM IKDD CODS AND 24TH COMAD, P256, DOI 10.1145/3297001.3297035
   Singh MP, 2018, PROC INT CONF DATA, P1423, DOI 10.1109/ICDE.2018.00161
   Singh R, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P1614, DOI 10.1109/ICICCT.2018.8472998
   Sonntag D, 2010, LECT NOTES ARTIF INT, V6392, P132
   Subramaniam S, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P597
   Sun YM, 2018, ACM/SIGIR PROCEEDINGS 2018, P235, DOI 10.1145/3209978.3210002
   Toxtli C, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173632
   Vegesna A., 2018, INT J COMPUTER APPL, V179, P51
   von Wolff RM, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P95
   Wang XJ, 2016, CAAI T INTELL TECHNO, V1, P303, DOI 10.1016/j.trit.2016.12.004
   Wazurkar P, 2017, INT CONF COMM SYST, P367, DOI [10.1109/CSNT.2017.70, 10.1109/CSNT.2017.8418568]
   Wen MH, 2018, PROCEEDINGS OF 4TH IEEE INTERNATIONAL CONFERENCE ON APPLIED SYSTEM INNOVATION 2018 ( IEEE ICASI 2018 ), P216, DOI 10.1109/ICASI.2018.8394571
   Xing XP, 2018, SIGNALS COMMUN TECHN, P109, DOI 10.1007/978-3-319-66565-8_6
   Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496
   Xue ZJ, 2018, INT CONF DAT MIN WOR, P1423, DOI 10.1109/ICDMW.2018.00202
   Yan Z, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4618
   Zhao GG, 2019, INFORMATION, V10, DOI 10.3390/info10020063
   Zhao R, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P239, DOI 10.1145/3267851.3267880
NR 83
TC 20
Z9 20
U1 15
U2 44
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1574-0137
EI 1876-7745
J9 COMPUT SCI REV
JI Comput. Sci. Rev.
PD MAY
PY 2020
VL 36
AR 100239
DI 10.1016/j.cosrev.2020.100239
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LS7SH
UT WOS:000536580800003
DA 2022-08-02
ER

PT C
AU Koetter, F
   Blohm, M
   Drawehn, J
   Kochanowski, M
   Goetzer, J
   Graziotin, D
   Wagner, S
AF Koetter, Falko
   Blohm, Matthias
   Drawehn, Jens
   Kochanowski, Monika
   Goetzer, Joscha
   Graziotin, Daniel
   Wagner, Stefan
BE VanDenHerik, J
   Rocha, AP
   Steels, L
TI Conversational Agents for Insurance Companies: From Theory to Practice
SO AGENTS AND ARTIFICIAL INTELLIGENCE, ICAART 2019
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 11th International Conference on Agents and Artificial Intelligence
   (ICAART)
CY FEB 19-21, 2019
CL Prague, CZECH REPUBLIC
DE Conversational agents; Intelligent user interfaces; Hackathon; NLP
   chatbot; Insurance
AB Advances in artificial intelligence have renewed interest in conversational agents. Additionally to software developers, today all kinds of employees show interest in new technologies and their possible applications for customers. German insurance companies generally are interested in improving their customer service and digitizing their business processes. In this work we investigate the potential use of conversational agents in insurance companies theoretically by determining which classes of agents exist which are of interest to insurance companies, finding relevant use cases and requirements. We add two practical parts: First we develop a showcase prototype for an exemplary insurance scenario in claim management. Additionally in a second step, we create a prototype focusing on customer service in a chatbot hackathon, fostering innovation in interdisciplinary teams. In this work, we describe the results of both prototypes in detail. We evaluate both chatbots defining criteria for both settings in detail and compare the results and draw conclusions for the maturity of chatbot technology for practical use, describing the opportunities and challenges companies, especially small and medium enterprises, face.
C1 [Koetter, Falko; Blohm, Matthias; Drawehn, Jens; Kochanowski, Monika] Fraunhofer Inst Ind Engn, Nobelstr 12, D-70569 Stuttgart, Germany.
   [Goetzer, Joscha; Graziotin, Daniel; Wagner, Stefan] Univ Stuttgart, Univ Str 38, D-70569 Stuttgart, Germany.
RP Blohm, M (corresponding author), Fraunhofer Inst Ind Engn, Nobelstr 12, D-70569 Stuttgart, Germany.
EM falko.koetter@iao.fraunhofer.de; matthias.blohm@iao.fraunhofer.de;
   jens.drawehn@iao.fraunhofer.de; monika.kochanowski@iao.fraunhofer.de;
   joscha.goetzer@gmail.com; daniel.graziotin@iste.uni-stuttgart.de;
   Stefan.Wagner@iste.uni-stuttgart.de
OI Graziotin, Daniel/0000-0002-9107-7681
FU Ministry of Economic Affairs, Labour and Housing Baden-Wuerttemberg
   [3-4332.62-IAO/56]
FX The work is partially based on work carried out in the project `Business
   Innovation Engineering Center', which is funded by the Ministry of
   Economic Affairs, Labour and Housing Baden-Wuerttemberg under the
   reference number 3-4332.62-IAO/56. The hackathon itself was conducted
   within the `Innovationsnetzwerk Digitalisierung fuer Versicherungen'
   [35]. The authors want to thank all participants for their contributions
   and feedback.
CR Aschenbrenner M., 2010, INFORMATIONSVERARBEI, DOI [10.1007/978-3-642-04321-5, DOI 10.1007/978-3-642-04321-5]
   Blohm M, 2019, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS (ICEIS), VOL 1, P454, DOI 10.5220/0007746204540461
   Briscoe G., 2014, DIGITAL INNOVATION H
   Cahn J., 2017, CHATBOT ARCHITECTURE
   Carpenter R., 2018, CLEVERBOT
   Chu S., 2005, P 9 INT C SPOK LANG, P865
   Cooper R.S., 2008, Patent No. [7,415,100, 7415100]
   Cotroneo U, 2014, EVOLUTION REVOLUTION
   Dale R, 2016, NAT LANG ENG, V22, P811, DOI 10.1017/S1351324916000243
   Davydova O, 2017, 25 CHATBOT PLATFORMS
   Derler R, 2017, CHATBOT VS APP VS WE
   Eeuwen M.V., 2017, THESIS U TWENTE
   Fannin T., 2017, 2017 FUTURE CLAIMS S
   Gartner, 2015, MARK TRENDS MOB APP
   GDV, 2012, VERH UMG PERS DAT DU
   Gorr D., 2018, VERSICHERUNGSWIRTSCH
   Guzman I., 2016, CHATBOTS CUSTOMER SE
   Harkous H., 2017, 12 S US PRIV SEC SOU
   Horch A., 2012, PROJEKT OPENXCHANGE
   Inc S, 2018, MOST POP MESS APPS
   Kamarinou D., 2016, 247 QUEEN MAR SCH LA
   Kasper H, 2018, HACK DEINE VERSICHER
   Kirakowski J., 2009, HUM-COMPUT INTERACT, DOI [10.5772/7741, DOI 10.5772/7741]
   Koetter F., 2012, Proceedings of the 2012 Annual SRII Global Conference (SRII), P715, DOI 10.1109/SRII.2012.84
   Koetter F, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART), VOL 1, P19, DOI 10.5220/0007252100190030
   Kowatsch T., 2017, P PERSUASIVE EMBODIE
   McTear M., 2016, CONVERSATIONAL INTER, DOI [10.1007/978-3-319-32967-3, DOI 10.1007/978-3-319-32967-3]
   Newlands M, 2017, 10 WAYS AI CHATBOTS
   Nguyen A., 2005, P 10 INT C INT US IN, P137
   Nordman E., 2017, ARTIF INTELL
   Pohl V., 2017, ZUKUNFTSSTUDIE 2027
   Power J.D., 2017, US VEHICLE DEPENDABI
   Radziwill N.M., 2017, ARXIV170404579
   Renner T., 2018, INNOVATIONSNETZWERK
   Rosell B., 2014, UNLEASHING INNOVATIO, P1, DOI [10.1109/InnoTek.2014.6877369, DOI 10.1109/INNOTEK.2014.6877369]
   Rudnicky A., 1999, IEEE AUT SPEECH REC, V13
   Schippers B, 2016, APP FATIGUE
   Schwark P., 2014, STAT TASCHENBUCH VER
   Soltani PM, 2014, PROC EUR CONF INFO, P367
   Sorensen I, 2017, EXPECTATIONS CHATBOT
   Spierling U., 2005, WORLDS PLAY INT PERS
   Stange A., 2015, CHANGE MANAGEMENT VE, P3, DOI [10.1007/978-3-658-05974-3, DOI 10.1007/978-3-658-05974-3]
   Traum DR, 2003, TEXT SPEECH LANG TEC, V22, P325
   Weindelt B, 2016, DIGITAL TRANSFORMATI
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Yacoubi A., 2018, INT C AGENTS ARTIF I
   Zimmermann G., 2015, CHANGE MANAGEMENT VE, P11, DOI [10.1007/978-3-658-05974-3, DOI 10.1007/978-3-658-05974-3]
NR 47
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-37494-5; 978-3-030-37493-8
J9 LECT NOTES ARTIF INT
PY 2019
VL 11978
BP 338
EP 362
DI 10.1007/978-3-030-37494-5_17
PG 25
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Mathematics, Applied
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Mathematics
GA BS4TY
UT WOS:000722592200017
OA Green Submitted
DA 2022-08-02
ER

PT J
AU de Araujo, JP
AF de Araujo, Jose Paulo
TI Importance of Affective States for Conversational Agents Projects
   Programmed in AIML
SO REVISTA EDUCAONLINE
LA Portuguese
DT Article
DE Artificial Intelligence; Conversational Agents; Affective States;
   Education
AB Research has shown a potential in AIML-programmed conversational agents for favoring affective factors that facilitate learning. I present a critical report on affective factors of human learning that should be considered in the design of these agents.
C1 [de Araujo, Jose Paulo] Univ Fed Rio de Janeiro, Programa Interdisciplinar Posgrad Linguist Aplica, Nucleo Pesquisas Linguagem Educ & Tecnol LingNet, Rio De Janeiro, RJ, Brazil.
RP de Araujo, JP (corresponding author), Univ Fed Rio de Janeiro, Escola Comunicacao, Lab Pesquisa Tecnol Informacao & Comunicacao, LATEC, Rio De Janeiro, RJ, Brazil.
EM josepaulo@ufrj.br
CR Abu Sawar Atwell, 2007, LDV FORUM, V22, P31
   ABUSHAWAR B., 2007, P CORP LING C CL2007
   ARAUJO J. P, 2010, PESQUISAS DISCURSO P, V4, P1
   BICKMORE T. W., 2004, P CHI VIENN APR
   Chiasson Sonia, 2005, P SIGCHI C HUM FACT, P829, DOI 10.1145/1054972.1055089
   Coniam David, 2008, ReCALL, P98, DOI 10.1017/S0958344008000815
   CONIAM D, 2008, EURO CALL REV, V13
   Doering Aaron, 2008, Journal of Interactive Learning Research, V19, P251
   FERREIRA L. P, 2006, BAZAR SOFTWARE CONHE, V1, P21
   FOGG B. J., 1997, P CHI ATL GEORG US M, P22
   Fogg BJ, 1997, INT J HUM-COMPUT ST, V46, P551, DOI 10.1006/ijhc.1996.0104
   Fryer L, 2006, LANG LEARN TECHNOL, V10, P8
   Grice Herbert Paul, 1989, STUDIES WAY WORDS
   Heller Bob Mike, 2005, EDMEDIA INNOVATE LEA, P3913
   Isen A. M., 2003, EMERGING PERSPECTIVE, P365, DOI [10.1017/CBO9780511609978.013, DOI 10.1017/CBO9780511609978.013]
   ISEN AM, 1987, J PERS SOC PSYCHOL, V52, P1122, DOI 10.1037/0022-3514.52.6.1122
   Izard C, 2008, CHILD DEV PERSPECT, V2, P156, DOI 10.1111/j.1750-8606.2008.00058.x
   Izard CE, 2009, ANNU REV PSYCHOL, V60, P1, DOI 10.1146/annurev.psych.60.110707.163539
   JAQUES P., 2005, INFORM EDUCACAO TEOR, V8
   Jia J., 2003, STUDY APPL KEYWORDS
   KERLY A., 2008, P 28 SGAI INT C INN
   Klein J, 2002, INTERACT COMPUT, V14, P119, DOI 10.1016/S0953-5438(01)00053-4
   KOWALSKI S., 2009, P 9 WORLD C COMP ED
   LEONHARDT M. D., 2003, CICLO PALESTRAS NOVA, V1
   Lu CH, 2006, LECT NOTES COMPUT SC, V4053, P575
   Fonte FAM, 2009, J UNIVERS COMPUT SCI, V15, P1486
   NASS C, 1995, INT J HUM-COMPUT ST, V43, P223, DOI 10.1006/ijhc.1995.1042
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   PRIMO A. F. T., 2008, 10 S INT INF ED
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Robison J., 2009, P 3 INT C AFF COMP I, P1
   ROTHERMEL A., 2007, AN S EXC GEST TECN S
   Scherer K. R., 2000, NEUROPSYCHOL EMOTION, V137, P137
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   SCHOPF E., UTILIZACAO CHATTERBO
   TEIXEIRA S., 2003, AN 14 S BRAS INF ED, P483
   WALLACE R. S, 2009, PARSING TURING TEST, P180
NR 37
TC 0
Z9 0
U1 0
U2 1
PU UNIV FEDERAL RIO DE JANEIRO, ESCOLA COMUNICACAO
PI RIO DE JANEIRO
PA LAB PESQUISA & TECNOLOGIAS INF COMUN, AV PASTEUR, 250, FUNDOS, RIO DE
   JANEIRO, RJ 22290-240, BRAZIL
SN 1983-2664
J9 REVIST EDUC
JI Revist. Educ.
PD JAN-JUN
PY 2011
VL 5
IS 1
BP 44
EP 62
PG 19
WC Education & Educational Research
WE Emerging Sources Citation Index (ESCI)
SC Education & Educational Research
GA VE3CE
UT WOS:000439058000003
DA 2022-08-02
ER

PT J
AU Yalcin, ON
AF Yalcin, Ozge Nilay
TI Empathy framework for embodied conversational agents
SO COGNITIVE SYSTEMS RESEARCH
LA English
DT Article
DE Empathy; Affective computing; Social interaction; Virtual agents;
   Embodied conversational agents; Human-computer interaction
ID EMOTION; APPRAISAL; BEHAVIOR
AB Empathy is a complex socio-emotional behavior that results from the interaction between affective and cognitive mechanisms. Equipping embodied conversational agents (ECAs) with empathic capacity can benefit from the integration and evaluation of these low and high level capabilities in a hierarchical manner. Following the theoretical background on empathic behavior in humans, this paper presents a framework to equip ECAs with real time multi-modal empathic interaction capabilities. We present the implementation of this framework, which includes basic dialogue capabilities as well as three levels of empathic behavior in a conversational scenario. Our approach is an inclusive stand on modeling levels of empathy and provides a baseline behavior for empathic interaction. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Yalcin, Ozge Nilay] Simon Fraser Univ, Sch Interact Arts & Technol, 250-13450 102 Ave, Surrey, BC, Canada.
RP Yalcin, ON (corresponding author), Simon Fraser Univ, Sch Interact Arts & Technol, 250-13450 102 Ave, Surrey, BC, Canada.
EM oyalcin@sfu.ca
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
   [RGPIN-2019-06767]; Social Sciences and Humanities Research Council of
   Canada (SSHRC) [435-2017-0625]
FX This work was partially supported by the Natural Sciences and
   Engineering Research Council of Canada (NSERC) [RGPIN-2019-06767] and
   the Social Sciences and Humanities Research Council of Canada (SSHRC)
   [435-2017-0625].
CR [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured], DOI 10.1109/CIG.2018.8490373
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Ball G, 2000, EMBODIED CONVERSATIONAL AGENTS, P189
   Banziger T, 2010, BLUEPRINT AFFECTIVE, P392
   BATES J, 1994, COMMUN ACM, V37, P122, DOI 10.1145/176789.176803
   Bernardet U, 2017, LECT NOTES ARTIF INT, V10498, P43, DOI 10.1007/978-3-319-67401-8_5
   Bernardet U, 2016, LECT NOTES ARTIF INT, V10011, P456, DOI 10.1007/978-3-319-47665-0_54
   Bernardet U, 2015, LECT NOTES ARTIF INT, V9238, P132, DOI 10.1007/978-3-319-21996-7_15
   Boukricha H, 2013, INT CONF AFFECT, P1, DOI 10.1109/ACII.2013.7
   Bradski G, 2000, DR DOBBS J, V25, P120
   Brave S, 2005, INT J HUM-COMPUT ST, V62, P161, DOI 10.1016/j.ijhcs.2004.11.002
   Brave S., 2002, HUM FAC ER, P81
   Broekens J, 2008, COGN SYST RES, V9, P173, DOI 10.1016/j.cogsys.2007.06.007
   Coplan A., 2011, EMPATHY PHILOS PSYCH
   DAVIS MH, 1983, J PERS SOC PSYCHOL, V44, P113, DOI 10.1037/0022-3514.44.1.113
   de Waal FBM, 2017, NAT REV NEUROSCI, V18, P498, DOI 10.1038/nrn.2017.72
   DUNCAN S, 1972, J PERS SOC PSYCHOL, V23, P283, DOI 10.1037/h0033031
   Giannakopoulos T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144610
   Gratch J, 2002, IEEE INTELL SYST, V17, P54, DOI 10.1109/MIS.2002.1024753
   Gratch J, 2007, LECT NOTES ARTIF INT, V4722, P125
   Hess U, 2014, SOC PERSONAL PSYCHOL, V8, P45, DOI 10.1111/spc3.12083
   Kopp S, 2006, LECT NOTES ARTIF INT, V4133, P205
   LAZARUS RS, 1991, AM PSYCHOL, V46, P819, DOI 10.1037/0003-066X.46.8.819
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Maatman RM, 2005, LECT NOTES ARTIF INT, V3661, P25
   McDuff Daniel, 2016, P 2016 CHI C HUM FAC, P3723, DOI DOI 10.1145/2851581.2890247
   McNeill D., 1992, HAND MIND WHAT GESTU
   Mohammad S, 2013, ARXIV13086242
   Ochs M, 2012, AUTON AGENT MULTI-AG, V24, P410, DOI 10.1007/s10458-010-9156-z
   Paiva A, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2912150
   Prendinger H, 2005, INT J HUM-COMPUT ST, V62, P231, DOI 10.1016/j.ijhcs.2004.11.009
   Rishe N, 2013, ACM TMIS, V4, P1, DOI [10.1145/2544103, DOI 10.1145/2544103]
   Rodrigues SH, 2015, INTERACT COMPUT, V27, P371, DOI 10.1093/iwc/iwu001
   Roseman IJ, 1996, COGNITION EMOTION, V10, P241, DOI 10.1080/026999396380240
   Saragih J., 2010, P 2010 IEEE COMPUTER, DOI 10.1109/CVPRW.2010.5543262
   Scherer K., 2001, APPRAISAL PROCESSES
   Schroder M, 2012, IEEE T AFFECT COMPUT, V3, P165, DOI 10.1109/T-AFFC.2011.34
   Skowron M, 2010, LECT NOTES COMPUT SC, V5967, P169
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Thiebaux M., 2008, P 7 INT C AUTONOMOUS, V1, P151
   Yalcin ON, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P546, DOI 10.1145/3242969.3264977
NR 46
TC 8
Z9 9
U1 4
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2214-4366
EI 1389-0417
J9 COGN SYST RES
JI Cogn. Syst. Res.
PD JAN
PY 2020
VL 59
BP 123
EP 132
DI 10.1016/j.cogsys.2019.09.016
PG 10
WC Computer Science, Artificial Intelligence; Neurosciences; Psychology,
   Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Neurosciences & Neurology; Psychology
GA JQ3OW
UT WOS:000498859500030
DA 2022-08-02
ER

PT J
AU Griol, D
   Carbo, J
   Molina, JM
AF Griol, David
   Carbo, Javier
   Molina, Jose M.
TI A statistical simulation technique to develop and evaluate
   conversational agents
SO AI COMMUNICATIONS
LA English
DT Article
DE Conversational agents; user simulation; statistical methodologies;
   multiagent systems
ID DIALOGUE SYSTEMS; USER SIMULATION; SPOKEN; DESIGN
AB In this paper, we present a technique for developing user simulators which are able to interact and evaluate conversational agents. Our technique is based on a statistical model that is automatically learned from a dialog corpus. This model is used by the user simulator to provide the next answer taking into account the complete history of the interaction. The main objective of our proposal is not only to evaluate the conversational agent, but also to improve this agent by employing the simulated dialogs to learn a better dialog model. We have applied this technique to design and evaluate a conversational agent which provides academic information in a multi-agent system. The results of the evaluation show that the proposed user simulation methodology can be used not only to evaluate conversational agents but also to explore new enhanced dialog strategies, thereby allowing the conversational agent to reduce the time needed to complete the dialogs and automatically detect new valid paths to achieve each of the required objectives defined for the task.
C1 [Griol, David; Carbo, Javier; Molina, Jose M.] Univ Carlos III Madrid, Dept Comp Sci, Appl Artificial Intelligence Grp GIAA, Leganes 28911, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Appl Artificial Intelligence Grp GIAA, Avda Univ 30, Leganes 28911, Spain.
EM david.griol@uc3m.es; javier.carbo@uc3m.es; josemanuel.molina@uc3m.es
RI Carbo, Javier/ABB-4694-2020; Griol, David/L-1258-2014; Molina,
   JOSE/B-1956-2008
OI Carbo, Javier/0000-0001-7794-3398; Griol, David/0000-0001-6266-5321;
   Molina, JOSE/0000-0002-7484-7357
FU [MINECO TEC2012-37832-C02-01];  [CICYT TEC 2011-28626-C02-02];  [CAM
   CONTEXTS (S2009/TIC-1485)]
FX This work was supported in part by Projects MINECO TEC2012-37832-C02-01,
   CICYT TEC 2011-28626-C02-02, CAM CONTEXTS (S2009/TIC-1485).
CR Ai H., 2007, P 8 SIGDIAL WORKSH D, P124
   Bailly G, 2010, SPEECH COMMUN, V52, P598, DOI 10.1016/j.specom.2010.02.015
   Ballinas-Hernandez AL, 2011, JASSS-J ARTIF SOC S, V14, DOI 10.18564/jasss.1789
   Balmer M, 2006, INNOVATIONS IN DESIGN & DECISION SUPPORT SYSTEMS IN ARCHITECTURE AND URBAN PLANNING, P167, DOI 10.1007/978-1-4020-5060-2_11
   Bandini S, 2006, LECT NOTES COMPUT SC, V3931, P231
   Bandini S, 2009, JASSS-J ARTIF SOC S, V12, pA51
   Bishop C.M., 1995, NEURAL NETWORKS PATT
   Bohus D., 2002, P MULT DIAL MOB ENV, P203
   Bohus D., 2007, P 7 M N AM CHAPT ASS, P9
   Bos J., 2003, P 4 SIGDIAL WORKSH D, P115
   Brahnam S, 2009, PSYCHNOLOGY J, V7, P9
   Callejas Z, 2008, SPEECH COMMUN, V50, P646, DOI 10.1016/j.specom.2008.04.004
   Chung G., 2004, P 42 ANN M ASS COMP, P63
   Cuayahuitl H, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P290
   de Alba J.F., 2010, INTEGRATED COMPUTER, V17, P243
   Eckert W, 1997, 1997 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, PROCEEDINGS, P80, DOI 10.1109/ASRU.1997.658991
   Eckert W., 1998, TR9891 ATT LAB RES
   Espana-Boquera S, 2007, LECT NOTES COMPUT SC, V4527, P327
   FIKES R, 1985, COMMUN ACM, V28, P904, DOI 10.1145/4284.4285
   Filipe Porfirio, 2010, Ambient Intelligence, P109
   Garcia F, 2003, LECT NOTES ARTIF INT, V2807, P165
   GEORGILA K, 2005, P 9 EUR C SPEECH COM, P893
   GLASS J, 1995, SPEECH COMMUN, V17, P1, DOI 10.1016/0167-6393(95)00008-C
   Griol D., 2010, P 11 SIGD M, P124
   Griol D., 2009, P 10 INT C, P2775
   Griol D, 2008, SPEECH COMMUN, V50, P666, DOI 10.1016/j.specom.2008.04.001
   Griol D, 2010, ADV INTEL SOFT COMPU, V79, P275
   Heath B., 2009, JASSS-J ARTIF SOC S, V12, P1
   Jung S, 2011, COMPUT SPEECH LANG, V25, P307, DOI 10.1016/j.csl.2010.06.002
   Klugl F, 2003, LECT NOTES ARTIF INT, V2831, P13
   Levin E, 2000, IEEE T SPEECH AUDI P, V8, P11, DOI 10.1109/89.817450
   Lin BS, 2001, IEEE T SPEECH AUDI P, V9, P534, DOI 10.1109/89.928918
   Lopez-Cozar R, 2003, SPEECH COMMUN, V40, P387, DOI 10.1016/S0167-6393(02)00126-7
   Macal CM, 2010, J SIMUL, V4, P151, DOI 10.1057/jos.2010.3
   McTear M. F., 2004, SPOKEN DIALOGUE TECH
   Melin H., 2001, TMH Q PROGR STATUS R, V1, P1
   Menezes P., 2007, HUMANOID ROBOTS HUMA, P48
   Minsky M., 1975, PSYCHOL COMPUTER VIS, P211
   Moller S, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1786
   Navarro L., 2011, P 10 INT C AUT AG MU, P701
   North MJ, 2006, ACM T MODEL COMPUT S, V16, P1, DOI 10.1145/1122012.1122013
   Paek T, 2008, SPEECH COMMUN, V50, P716, DOI 10.1016/j.specom.2008.03.010
   Pavon Juan, 2008, International Journal of Agent-Oriented Software Engineering, V2, P196, DOI 10.1504/IJAOSE.2008.017315
   Pieraccini R., 2012, VOICE MACHINE BUILID
   Pietquin O, 2006, IEEE T AUDIO SPEECH, V14, P589, DOI 10.1109/TSA.2005.855836
   Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, P319
   Sanchez-Pi N, 2007, SNPD 2007: EIGHTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, VOL 3, PROCEEDINGS, P694, DOI 10.1109/SNPD.2007.394
   Schatzmann J., 2007, P 8 SIGDIAL WORKSH D, P273
   Schatzmann J., 2007, HUMAN LANGUAGE TECHN, P149
   Schatzmann J, 2006, KNOWL ENG REV, V21, P97, DOI 10.1017/S0269888906000944
   Scheffler K., 2001, P HUM LANG TECHN HLT, P12
   Scheffler K., 2001, P NAACL WORKSH AD DI, P64
   Sharma C., 2001, VOICEXML STRATEGIES
   Torres F, 2008, COMPUT SPEECH LANG, V22, P230, DOI 10.1016/j.csl.2007.09.002
   VAQUERO C, 2006, 4 JORNADAS TECNOLOGI, P321
   Weng FL, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1061
   Weyns D., 2006, P 5 INT JOINT C AUT, P842, DOI [10.1145/1160633.1160785, DOI 10.1145/1160633.1160785]
   Wilensky U, 2009, INTRO AGENT BASED MO
   Williams JD, 2007, COMPUT SPEECH LANG, V21, P393, DOI 10.1016/j.csl.2006.06.008
   Windrum P, 2007, JASSS-J ARTIF SOC S, V10
   Young S., 2002, TECHNICAL REPORT
   Zue V, 2000, IEEE T SPEECH AUDI P, V8, P85, DOI 10.1109/89.817460
   [No title captured]
   [No title captured]
NR 64
TC 10
Z9 10
U1 1
U2 12
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 0921-7126
EI 1875-8452
J9 AI COMMUN
JI AI Commun.
PY 2013
VL 26
IS 4
BP 355
EP 371
DI 10.3233/AIC-130573
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 219ZW
UT WOS:000324551500002
OA Green Accepted
DA 2022-08-02
ER

PT C
AU Volkel, ST
   Schodel, R
   Buschek, D
   Stachl, C
   Winterhalter, V
   Buhner, M
   Hussmann, H
AF Voelkel, Sarah Theres
   Schodel, Ramona
   Buschek, Daniel
   Stachl, Clemens
   Winterhalter, Verena
   Buehner, Markus
   Hussmann, Heinrich
GP ACM
TI Developing a Personality Model for Speech-based Conversational Agents
   Using the Psycholexical Approach
SO PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING
   SYSTEMS (CHI'20)
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 25-30, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGCHI
DE Big 5; conversational agents; personality
ID ADEQUATE TAXONOMY; 5-FACTOR MODEL; EXTROVERSION; DIMENSIONS
AB We present the first systematic analysis of personality dimensions developed specifically to describe the personality of speech-based conversational agents. Following the psycholexical approach from psychology, we first report on a new multi-method approach to collect potentially descriptive adjectives from 1) a free description task in an online survey (228 unique descriptors), 2) an interaction task in the lab (176 unique descriptors), and 3) a text analysis of 30,000 online reviews of conversational agents (Alexa, Google Assistant, Cortana) (383 unique descriptors). We aggregate the results into a set of 349 adjectives, which are then rated by 744 people in an online survey. A factor analysis reveals that the commonly used Big Five model for human personality does not adequately describe agent personality. As an initial step to developing a personality model, we propose alternative dimensions and discuss implications for the design of agent personalities, personality-aware personalisation, and future research.
C1 [Voelkel, Sarah Theres; Schodel, Ramona; Winterhalter, Verena; Buehner, Markus; Hussmann, Heinrich] Ludwig Maximilians Univ Munchen, Munich, Germany.
   [Buschek, Daniel] Univ Bayreuth, Dept Comp Sci, Res Grp HCI AI, Bayreuth, Germany.
   [Stachl, Clemens] Stanford Univ, Dept Commun, Stanford, CA 94305 USA.
RP Volkel, ST (corresponding author), Ludwig Maximilians Univ Munchen, Munich, Germany.
EM sarah.voelkel@ifi.lmu.de; ramona.schoedel@psy.lmu.de;
   daniel.buschek@uni-bayreuth.de; cstachl@stanford.edu;
   verena.winterhalter@campus.lmu.de; buehner@psy.lmu.de;
   hussmann@ifi.lmu.de
RI Stachl, Clemens/ABD-9949-2021
OI Volkel, Sarah Theres/0000-0001-6940-3818
FU Bavarian State Ministry of Science and the Arts
FX This project is funded by the Bavarian State Ministry of Science and the
   Arts in the framework of the Centre Digitisation.Bavaria (ZD.B).
CR Allport GW, 1936, PSYCHOL MONOGR, V47, P1
   ANDERSON NH, 1968, J PERS SOC PSYCHOL, V9, P272, DOI 10.1037/h0025907
   Andrea E., 2000, Affective Interactions. Towards a New Generation of Computer Interfaces (Lecture Notes in Artificial Intelligence Vol.1814), P150
   Andrist S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3603, DOI 10.1145/2702123.2702592
   [Anonymous], 2008, AAAI SPRING S EM PER
   [Anonymous], 2009, BFSI BIG 5 STRUKTUR
   Bartneck C, 2008, INTERACT STUD, V9, P415, DOI 10.1075/is.9.3.04bar
   Behrend TS, 2011, BEHAV RES METHODS, V43, P800, DOI 10.3758/s13428-011-0081-0
   Berinsky AJ, 2014, AM J POLIT SCI, V58, P739, DOI 10.1111/ajps.12081
   Bouchet F., 2012, COGNITIVELY INFORM I, P177
   Braeken J, 2017, PSYCHOL METHODS, V22, P450, DOI 10.1037/met0000074
   Braun M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300270
   Buhner M., 2011, EINFUHRUNG TEST FRAG
   Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980
   BYRNE D, 1961, J ABNORM SOC PSYCH, V62, P713, DOI 10.1037/h0044721
   Cafaro A, 2016, ACM T COMPUT-HUM INT, V23, DOI 10.1145/2940325
   Cafaro Angelo, 2012, INTELLIGENT VIRTUAL, V7502
   Cattell RB, 1947, PSYCHOMETRIKA, V12, P197, DOI 10.1007/BF02289253
   Chung CK, 2008, J RES PERS, V42, P96, DOI 10.1016/j.jrp.2007.04.006
   Clark L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300705
   Costa P. T., 1992, REVISED NEO PERSONAL
   De Raad B., 2000, BIG 5 PERSONALITY FA
   DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061
   DeYoung C.G., 2015, APA HDB PERSONALITY, V4, P369, DOI [https://doi.org/10.1037/14343-017, DOI 10.1037/14343-017, 10.1037/14343-017]
   DIENER E, 1992, J RES PERS, V26, P205, DOI 10.1016/0092-6566(92)90039-7
   Doyle PR, 2019, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'19), DOI 10.1145/3338286.3340116
   Eiband M, 2019, PROCEEDINGS OF IUI 2019, P96, DOI 10.1145/3301275.3302262
   Eid M., 2014, TESTTHEORIE TESTKONS
   Gnambs T, 2015, PERS INDIV DIFFER, V84, P84, DOI 10.1016/j.paid.2014.08.019
   Goldberg L. R., 1981, REV PERSONALITY SOCI, V2, P141
   Goldberg Lewis R., 1982, ADV PERSONALITY ASSE, V1, P203
   GOLDBERG LR, 1990, J PERS SOC PSYCHOL, V59, P1216, DOI 10.1037/0022-3514.59.6.1216
   Gough Harrison G., 1980, ADJECTIVE CHECKLIST
   Guzman E, 2014, INT REQUIR ENG CONF, P153, DOI 10.1109/RE.2014.6912257
   Hara K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174023
   Isbister K, 2000, INT J HUM-COMPUT ST, V53, P251, DOI 10.1006/ijhc.2000.0368
   Jackson JJ, 2010, J RES PERS, V44, P501, DOI 10.1016/j.jrp.2010.06.005
   Jensen-Campbell LA, 2001, J PERS, V69, P323, DOI 10.1111/1467-6494.00148
   JOHN OP, 1988, EUR J PERSONALITY, V2, P171, DOI 10.1002/per.2410020302
   Kim H, 2019, PROC INT CONF PARAL, DOI 10.1145/3337821.3337886
   Kinsella B., 2018, US SMART SPEAKER CON
   Krenn B, 2014, LECT NOTES COMPUT SC, V8511, P429, DOI 10.1007/978-3-319-07230-2_41
   Kulkarni V, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0201703
   Maalej W, 2016, REQUIR ENG, V21, P311, DOI 10.1007/s00766-016-0251-9
   Matthews G., 2003, PERSONALITY TRAITS, DOI [10.1017/CBO9780511812736, DOI 10.1017/CBO9780511812736]
   McCrae RR, 2009, CAMBRIDGE HANDBOOK OF PERSONALITY PSYCHOLOGY, P148
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   MCCRAE RR, 1987, J PERS SOC PSYCHOL, V52, P81, DOI 10.1037/0022-3514.52.1.81
   MCCRAE RR, 1985, J PERS SOC PSYCHOL, V49, P710, DOI 10.1037/0022-3514.49.3.710
   McCrae RR., 2008, HDB PERSONALITY THEO, P159, DOI DOI 10.3905/JPE.2000.319978
   McNiel JM, 2006, J RES PERS, V40, P529, DOI 10.1016/j.jrp.2005.05.003
   McRorie M, 2012, IEEE T AFFECT COMPUT, V3, P311, DOI 10.1109/T-AFFC.2011.38
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Nass Clifford, 2005, WIRED SPEECH VOICE A
   Neff Michael, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P398, DOI 10.1007/978-3-642-23974-8_43
   Norman Warren T, 1967, 014738 ED U MICH DEP
   NORMAN WT, 1963, J ABNORM PSYCHOL, V66, P574, DOI 10.1037/h0040291
   Olsen Christi, 2019, VOICE REPORT ANSWERS
   Perez Marta Garcia, 2018, P 32 INT BCS HUM COM, DOI [10.14236/ewic/HCI2018.40, DOI 10.14236/EWIC/HCI2018.40]
   Pfeifer Vardoulakis Laura, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P289, DOI 10.1007/978-3-642-33197-8_30
   Porcheron M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174214
   Rao A. S., 1995, ICMAS-95 Proceedings. First International Conference on Multi-Agent Systems, P312
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Revelle W., 2016, SYCH PROCEDURES PSYC
   Rizzo P., 1997, Socially Intelligent Agents. Papers from the 1997 AAAI Fall Symposium, P109
   SCHERER KR, 1979, SOCIAL MARKERS SPEEC
   Speer Robyn, 2018, LuminosoInsight/wordfreq: v2.2, DOI 10.5281/zenodo.1443582
   Vlahos J., 2019, TALK ME VOICE COMPUT
   Welch Chris., 2018, GOOGLE JUST GAVE STU
   Zhou MX, 2019, ACM T INTERACT INTEL, V9, DOI 10.1145/3232077
   Ziegler M, 2009, EDUC PSYCHOL MEAS, V69, P548, DOI 10.1177/0013164408324469
NR 71
TC 11
Z9 11
U1 3
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6708-0
PY 2020
DI 10.1145/3313831.3376210
PG 14
WC Computer Science, Cybernetics; Computer Science, Information Systems;
   Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS1SG
UT WOS:000695432500083
OA Green Accepted, Green Submitted
DA 2022-08-02
ER

PT J
AU Patel, S
   Chiu, YT
   Khan, MS
   Bernard, JG
   Ekandjo, TAT
AF Patel, Siddharth
   Chiu, Yi-Te
   Khan, Mohammad Saud
   Bernard, Jean-Gregoire
   Ekandjo, Talitakuum A. T.
TI Conversational Agents in Organisations: Strategic Applications and
   Implementation Considerations
SO JOURNAL OF GLOBAL INFORMATION MANAGEMENT
LA English
DT Article
DE Chatbots; Conversational Agents; IT Adoption; IT Implementation; Routine
   Capability; Strategic Applications
ID INFORMATION-TECHNOLOGY; ARTIFICIAL-INTELLIGENCE; AI; OPPORTUNITIES;
   CAPABILITIES; DIRECTIONS; MANAGEMENT; CREATION; ELIZA
AB Conversational agents (CAs) promise to create significant organisational value by transforming how organisations operate and serve customers. Yet, the malleability of this technology poses challenges to both researchers and practitioners because of the wide range of strategic applications they can enable. Drawing on the lens of routine capability, this study investigates strategic applications of CAs and their associated implementation enablers and challenges. Via an exploratory case study of eight organisations that have successfully implemented CAs, this paper contributes to the literature on the value and implementation of conversational agents in particular and cognitive technologies in general by developing a typology of CA strategic applications and their implementation considerations. For practitioners, the findings highlight the interplay between technology, user, and project management factors that need to be addressed to ensure the successful delivery of the value of CAs.
C1 [Patel, Siddharth; Chiu, Yi-Te; Khan, Mohammad Saud; Bernard, Jean-Gregoire; Ekandjo, Talitakuum A. T.] Victoria Univ Wellington, Wellington, New Zealand.
RP Patel, S (corresponding author), Victoria Univ Wellington, Wellington, New Zealand.
OI Chiu, Yi-te/0000-0002-4198-9666
FU Wellington School of Business and Government, Victoria University of
   Wellington [219977]
FX This research was supported by Wellington School of Business and
   Government, Victoria University of Wellington (Funding number: 219977)
CR Abu Shawar BA and Atwell ES, 2007, J LANG TECHNOL COMPU, V22, P29
   [Anonymous], 2004, SAC 04 2004 ACM S AP
   Avison D. E., 2007, INFORM SYSTEMS DEV M, V4th
   Bank of America, 2021, MEET ER YOUR FIN DIG
   BARKI H, 1994, MIS QUART, V18, P59, DOI 10.2307/249610
   Bavaresco R, 2020, COMPUT SCI REV, V36, DOI 10.1016/j.cosrev.2020.100239
   Ben Mimoun MS, 2012, J RETAIL CONSUM SERV, V19, P605, DOI 10.1016/j.jretconser.2012.07.006
   Berry PM, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1989734.1989744
   Bittner EAC, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P227
   Bogg A, 2021, THEOR ISS ERGON SCI, V22, P488, DOI 10.1080/1463922X.2020.1827080
   Borges AFS, 2021, INT J INFORM MANAGE, V57, DOI 10.1016/j.ijinfomgt.2020.102225
   Castro F, 2018, LECT NOTES COMPUT SC, V10954, P400, DOI 10.1007/978-3-319-95930-6_37
   Chakrabarti C, 2015, EXPERT SYST APPL, V42, P6878, DOI 10.1016/j.eswa.2015.04.067
   Chowdhury GG, 2003, ANNU REV INFORM SCI, V37, P51, DOI 10.1002/aris.1440370103
   Chung M, 2020, J BUS RES, V117, P587, DOI 10.1016/j.jbusres.2018.10.004
   Ciechanowski L, 2019, FUTURE GENER COMP SY, V92, P539, DOI 10.1016/j.future.2018.01.055
   Clark L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300705
   Collier M., 2019, SPECIAL STUDY ARTIFI
   Coram A ., 2017, INVESTORS BUSINESS D
   Davenport TH, 2018, HARVARD BUS REV, V96, P108
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Devaney E ., 2016, INFOGRAPHIC RISE CHA
   El Sawy OA, 2008, MIS Q EXEC, V7, P139
   Feng S., 2020, P 53 HAW INT C SYST
   Fereday J., 2006, INT J QUAL METH, V5, P80, DOI [10.1177/160940690600500107, DOI 10.1177/160940690600500107]
   Fichman R. G., 2004, J ASSOC INF SYST, V5, P314
   Ghandeharioun A, 2019, INT CONF AFFECT
   Grand View Research Centre, 2017, CHATB MARK SIZ SHAR
   Hallam S ., 2017, 5 OUTSTANDING CHATBO
   Hao K ., 2018, AMAZON ECHOS DOMINAN
   Henfridsson O, 2018, INFORM ORGAN-UK, V28, P89, DOI 10.1016/j.infoandorg.2018.03.001
   Huang MH, 2021, J SERV RES-US, V24, P30, DOI 10.1177/1094670520902266
   Huang MH, 2019, CALIF MANAGE REV, V61, P43, DOI 10.1177/0008125619863436
   Hudson C ., 2018, CHARLOTTE BUSINESS J
   Io HN, 2017, IN C IND ENG ENG MAN, P215, DOI 10.1109/IEEM.2017.8289883
   Jain A., 2018, INT J COMPUTER SCI E, V6, P161, DOI [10.26438/ijcse/v6i1.161167, DOI 10.26438/IJCSE/V6I1.161167]
   Jang M, 2021, COMPUT HUM BEHAV, V120, DOI 10.1016/j.chb.2021.106747
   Kaplan A, 2019, BUS HORIZONS, V62, P15, DOI 10.1016/j.bushor.2018.08.004
   Kvale K., 2019, INT WORKSH CHATB RES, DOI [10.1007/978-3-030-39540-7, DOI 10.1007/978-3-030-39540-7]
   Lucas Jr H., 2008, J ASSOC INF SYST, V8, P8
   Maedche A, 2019, BUS INFORM SYST ENG+, V61, P535, DOI 10.1007/s12599-019-00600-8
   Marblestone AH, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00094
   Markus M. L., 2004, J ASSOC INF SYST, V5, P514
   Mayo Clinic, 2019, SENS MAYO CLIN ADV D
   McManus B ., 2017, MARRIOTT INT LAUNCHE
   Merchant KA, 2006, BEHAV RES ACCOUNT, V18, P117, DOI 10.2308/bria.2006.18.1.117
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Nadarzynski T, 2019, DIGIT HEALTH, V5, DOI [10.1177/2055207619871808, 10.1177/2055207619827193]
   Neff G, 2016, INT J COMMUN-US, V10, P4915
   NEXT IT, 2016, ENT CHATB US CAS ASK
   Nielsen PA, 2017, EUR J INFORM SYST, V26, P66, DOI 10.1057/s41303-016-0026-x
   Palinkas LA, 2015, ADM POLICY MENT HLTH, V42, P533, DOI 10.1007/s10488-013-0528-y
   Parker SK, 2020, APPL PSYCHOL-INT REV, DOI 10.1111/apps.12241
   Peffers K, 2013, EUR J INFORM SYST, V22, P131, DOI 10.1057/ejis.2012.60
   Power B ., 2017, AI IS STREAML MARK S
   Radziwill N.M., 2017, ARXIV170404579
   Riccardi G ., 2014, P 2014 WORKSH ROADM
   Robert LP, 2020, HUM-COMPUT INTERACT, V35, P545, DOI 10.1080/07370024.2020.1735391
   Roberts N, 2012, MIS QUART, V36, P625
   Robey D, 1999, INFORM SYST RES, V10, P167, DOI 10.1287/isre.10.2.167
   Sambamurthy V, 2003, MIS QUART, V27, P237
   Saunila M, 2019, INFORM TECHNOL PEOPL, V32, P627, DOI 10.1108/ITP-10-2016-0224
   Serban I.V., 2017, ARXIV PREPRINT ARXIV
   Sestino A, 2022, TECHNOL ANAL STRATEG, V34, P16, DOI 10.1080/09537325.2021.1883583
   Shadish W. R., 2002, EXPT QUASIEXPERIMENT
   Shankar V, 2018, J RETAILING, V94, pVI, DOI 10.1016/S0022-4359(18)30076-9
   Sharma R, 2003, MIS QUART, V27, P533
   Sheehan B, 2020, J BUS RES, V115, P14, DOI 10.1016/j.jbusres.2020.04.030
   Sheth A, 2019, IEEE INTELL SYST, V34, P24, DOI [10.1109/MIS.2019.2905748, 10.1109/mis.2019.2905748]
   Shin D, 2021, INT J HUM-COMPUT ST, V146, DOI 10.1016/j.ijhcs.2020.102551
   Shin D, 2020, COMPUT HUM BEHAV, V109, DOI 10.1016/j.chb.2020.106344
   Shin D, 2020, INT J INFORM MANAGE, V52, DOI 10.1016/j.ijinfomgt.2019.102061
   Shin D, 2019, COMPUT HUM BEHAV, V98, P277, DOI 10.1016/j.chb.2019.04.019
   Shum HY, 2018, FRONT INFORM TECH EL, V19, P10, DOI 10.1631/FITEE.1700826
   Siddike MA, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P1640
   Silva AD, 2020, EXPERT SYST APPL, V147, DOI 10.1016/j.eswa.2020.113193
   Sinatra AM, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106562
   Sjoden B, 2011, COMM COM INF SC, V126, P116
   Skjuve M, 2021, INT J HUM-COMPUT ST, V149, DOI 10.1016/j.ijhcs.2021.102601
   Swanson EB, 2019, MIS QUART, V43, P1007, DOI 10.25300/MISQ/2019/14653
   Tarafdar M, 2019, MIT SLOAN MANAGE REV, V60, P37
   Teece DJ, 1997, STRATEGIC MANAGE J, V18, P509, DOI 10.1002/(SICI)1097-0266(199708)18:7<509::AID-SMJ882>3.0.CO;2-Z
   Viswanathan V ., 2017, MAKE CHATBOT INTELLI
   von Wolff RM, 2020, PAC ASIA J ASSOC INF, V12, P64, DOI 10.17705/1pais.12203
   Wang H, 2021, ROUTL ADV TRANSL INT, P91
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Youn S, 2021, COMPUT HUM BEHAV, V119, DOI 10.1016/j.chb.2021.106721
NR 87
TC 0
Z9 0
U1 2
U2 3
PU IGI GLOBAL
PI HERSHEY
PA 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA
SN 1062-7375
EI 1533-7995
J9 J GLOB INF MANAG
JI J. Glob. Inf. Manag.
PY 2021
VL 29
IS 6
DI 10.4018/JGIM.20211101.oa53
PG 25
WC Information Science & Library Science
WE Social Science Citation Index (SSCI)
SC Information Science & Library Science
GA YC8IJ
UT WOS:000739929300013
OA gold
DA 2022-08-02
ER

PT C
AU Koetter, F
   Blohm, M
   Kochanowski, M
   Goetzer, J
   Graziotin, D
   Wagner, S
AF Koetter, Falko
   Blohm, Matthias
   Kochanowski, Monika
   Goetzer, Joscha
   Graziotin, Daniel
   Wagner, Stefan
BE Rocha, A
   Steels, L
   VanDenHerik, J
TI Motivations, Classification and Model Trial of Conversational Agents for
   Insurance Companies
SO PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND
   ARTIFICIAL INTELLIGENCE (ICAART), VOL 1
LA English
DT Proceedings Paper
CT 11th International Conference on Agents and Artificial Intelligence
   (ICAART)
CY FEB 19-21, 2019
CL Prague, CZECH REPUBLIC
DE Conversational Agents; Intelligent User Interfaces; Machine Learning;
   Nlp; Chatbots; Insurance
AB Advances in artificial intelligence have renewed interest in conversational agents. So-called chatbots have reached maturity for industrial applications. German insurance companies are interested in improving their customer service and digitizing their business processes. In this work we investigate the potential use of conversational agents in insurance companies by determining which classes of agents are of interest to insurance companies, finding relevant use cases and requirements, and developing a prototype for an exemplary insurance scenario. Based on this approach, we derive key findings for conversational agent implementation in insurance companies.
C1 [Koetter, Falko; Blohm, Matthias; Kochanowski, Monika] Fraunhofer Inst Ind Engn, Nobelstr 12, D-70569 Stuttgart, Germany.
   [Goetzer, Joscha; Graziotin, Daniel; Wagner, Stefan] Univ Stuttgart, Univ Str 38, D-70569 Stuttgart, Germany.
RP Koetter, F (corresponding author), Fraunhofer Inst Ind Engn, Nobelstr 12, D-70569 Stuttgart, Germany.
RI Wagner, Stefan/A-5200-2018
OI Wagner, Stefan/0000-0002-5256-8429; Graziotin,
   Daniel/0000-0002-9107-7681
CR [Anonymous], 2018, MOST POPULAR MESSAGI
   Aschenbrenner M, 2010, INFORMATIONSVERARBEI
   Cahn J., 2017, CHATBOT ARCHITECTURE
   Chu S., 2005, P 9 INT C SPOK LANG, P865
   Cooper R.S., 2008, Patent No. [7,415,100, 7415100]
   Cotroneo U, 2014, EVOLUTION REVOLUTION
   Dale R, 2016, NAT LANG ENG, V22, P811, DOI 10.1017/S1351324916000243
   Davydova O, 2017, 25 CHATBOT PLATFORMS
   Derler R, 2017, CHATBOT VS APP VS WE
   Eeuwen M, 2017, THESIS
   Fannin T, 2017, TECHNICAL REPORT
   Gartner, 2015, MARK TRENDS MOB APP
   GDV, 2012, VERH UMG PERS DAT DU
   Gorr D., 2018, VERSICHERUNGSWIRTSCH
   Guzmn I, 2016, TECHNICAL REPORT
   Harkous H., 2016, 12 S USABLE PRIVACY
   Horch A., 2012, PROJEKT OPENXCHANGE
   Kamarinou D, 2016, 247 QUEEN MAR SCH L
   Kirakowski J, 2009, HUMAN COMPUTER INTER
   Koetter F., 2012, Proceedings of the 2012 Annual SRII Global Conference (SRII), P715, DOI 10.1109/SRII.2012.84
   Kowatsch T., 2017, P PERSUASIVE EMBODIE
   McTear M., 2016, CONVERSATIONAL INTER, V6
   Newlands M, 2017, 10 WAYS CHATBOTS RED
   Nguyen HN, 2005, PROCEEDINGS OF THE THIRD IASTED INTERNATIONAL CONFERENCE ON CIRCUITS, SIGNALS, AND SYSTEMS, P137
   Nordman E, 2017, ARTIFICIAL INTELLIGE
   Pohl V., 2017, ZUKUNFTSSTUDIE 2027
   Power J. D, 2017, 2017 US AUTO CLAIMS
   Radziwill N.M., 2017, ARXIV170404579 ARXIV170404579
   Renner T., 2018, INNOVATIONSNETZWERK
   Rudnicky A., 1999, IEEE AUT SPEECH REC, V13
   Schippers B, 2016, APP FATIGUE
   Schwark P., 2014, STAT TASCHENBUCH VER
   Sorensen I, 2017, EXPECTATIONS CHATBOT
   Spierling U., 2005, WORLDS PLAY INT PERS
   Stange A., 2015, CHANGE MANAGEMENT VE, P3, DOI [10.1007/978-3-658-05974-3, DOI 10.1007/978-3-658-05974-3]
   Traum DR, 2003, TEXT SPEECH LANG TEC, V22, P325
   Weindelt B, 2016, TECHNICAL REPORT
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Yacoubi A., 2018, INT C AGENTS ARTIF I
   Zimmermann G., 2015, CHANGE MANAGEMENT VE, P11, DOI [10.1007/978-3-658-05974-3, DOI 10.1007/978-3-658-05974-3]
NR 40
TC 4
Z9 4
U1 1
U2 7
PU SCITEPRESS
PI SETUBAL
PA AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL
BN 978-989-758-350-6
PY 2019
BP 19
EP 30
DI 10.5220/0007252100190030
PG 12
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP9PP
UT WOS:000570385400002
OA hybrid, Green Submitted
DA 2022-08-02
ER

PT C
AU Griol, D
   Molina, JM
AF Griol, David
   Manuel Molina, Jose
BE Corchado, JM
   Perez, JB
   Hallenborg, K
   Golinska, P
   Corchuelo, R
TI Bringing Statistical Methodologies for Enterprise Integration of
   Conversational Agents
SO TRENDS IN PRACTICAL APPLICATIONS OF AGENTS AND MULTI-AGENTS SYSTEMS
SE Advances in Intelligent and Soft Computing
LA English
DT Proceedings Paper
CT 9th International Conference on Practical Applications of Agents and
   Multi-Agent Systems
CY APR 06-08, 2011
CL Univ Salamanca, Salamanca, SPAIN
HO Univ Salamanca
DE Conversational Agents; Dialog Management; Statistical Methodologies;
   User Modeling
AB In this paper we present a methodology to develop commercial conversational agents that avoids, the effort of manually defining the dialog strategy for the dialog management module. Our corpus-based methodology is based on selecting the next system answer by means of a classification process in which the complete dialog history is considered. This way, system developers can employ standards like VoiceXML to simply define system prompts and the associated grammars to recognize the users responses to the prompt, and the statistical dialog model automatically selects the next system prompt. We have applied this methodology for the development of an academic conversational agent.
C1 [Griol, David; Manuel Molina, Jose] Univ Carlos III Madrid, Grp Appl Artificial Intelligence GIAA, Dept Comp Sci, E-28903 Getafe, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Grp Appl Artificial Intelligence GIAA, Dept Comp Sci, E-28903 Getafe, Spain.
EM david.griol@uc3m.es; josemanuel.molina@uc3m.es
RI Griol, David/L-1258-2014; Golinska-Dawson, Paulina/M-6639-2014; Molina,
   JOSE/B-1956-2008
OI Griol, David/0000-0001-6266-5321; Golinska-Dawson,
   Paulina/0000-0002-5821-3805; Molina, JOSE/0000-0002-7484-7357
CR Bailly G, 2010, SPEECH COMMUN, V52, P598, DOI 10.1016/j.specom.2010.02.015
   Bohus D., 2007, P 7 M N AM CHAPT ASS, P9
   BOHUS D, 2002, P IDS 2002 KLOST IRS
   Brahnam S, 2009, PSYCHNOLOGY J, V7, P9
   Callejas Z, 2008, SPEECH COMMUN, V50, P646, DOI 10.1016/j.specom.2008.04.004
   GLASS J, 1995, SPEECH COMMUN, V17, P1, DOI 10.1016/0167-6393(95)00008-C
   Griol D., 2007, P 8 SIGDIAL WORKSH D, P39
   Griol D, 2008, SPEECH COMMUN, V50, P666, DOI 10.1016/j.specom.2008.04.001
   He Y, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU '03, P583, DOI 10.1109/ASRU.2003.1318505
   Mazuel Laurent, 2008, Web Intelligence and Agent Systems, V6, P43, DOI 10.3233/WIA-2008-0129
   Melin H., 2001, TMH Q PROGR STATUS R, V1, P1
   Menezes P., 2007, HUMANOID ROBOTS HUMA, P48
   MINKER W, 1999, STOCHASTICALLY BASED
   Rojas-Barahona L M, 2009, Int J Med Inform, V78 Suppl 1, pS56, DOI 10.1016/j.ijmedinf.2008.07.017
   Torres F, 2005, SPEECH COMMUN, V45, P211, DOI 10.1016/j.specom.2004.10.014
   VAQUERO C, 2006, 4 JORNADAS TECNOLOGI, P321
   WENG F, 2006, P INT C SPOK LANG PR, P1061
   Williams JD, 2007, COMPUT SPEECH LANG, V21, P393, DOI 10.1016/j.csl.2006.06.008
   Young S., 2002, STAT APPROACH DESIGN
   Zue V, 2000, IEEE T SPEECH AUDI P, V8, P85, DOI 10.1109/89.817460
   [No title captured]
NR 21
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 1867-5662
BN 978-3-642-19930-1
J9 ADV INTEL SOFT COMPU
PY 2011
VL 90
BP 153
EP 160
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BVN80
UT WOS:000292004800019
DA 2022-08-02
ER

PT C
AU Law, E
   Ravari, PB
   Chhibber, N
   Kulic, D
   Lin, S
   Pantasdo, KD
   Ceha, J
   Suh, S
   Dillen, N
AF Law, Edith
   Ravari, Parastoo Baghaei
   Chhibber, Nalin
   Kulic, Dana
   Lin, Stephanie
   Pantasdo, Kevin D.
   Ceha, Jessy
   Suh, Sangho
   Dillen, Nicole
GP Assoc Comp Machinery
TI Curiosity Notebook: A Platform for Learning by Teaching Conversational
   Agents
SO CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS
   IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT ACM CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 25-30, 2020
CL Honolulu, HI
SP ACM SIGCHI, Assoc Comp Machinery
DE conversational agents; learning by teaching
ID CHILDREN TEACH; PEER TUTORS; EXPLANATIONS; ROBOT
AB Learning by teaching is an established pedagogical technique; however, the exact process through which learning happens remains difficult to assess, in part due to the variability in the tutor-tutee pairing and interaction. Prior research proposed the use of teachable agents acting as students, in order to facilitate more controlled studies of the learning by teaching phenomenon. In this work, we introduce a learning by teaching platform, Curiosity Notebook, which allows students to work individually or in groups to teach a conversational agent a classification task in a variety of subject topics. We conducted a 4-week exploratory study with 12 fourth and fifth grade elementary school children, who taught a conversational robot how to classify animals, rocks/minerals and paintings. This paper outlines the architecture of our system, describes the lessons learned from the study, and contributes design considerations on how to design conversational agents and applications for learning by teaching scenarios.
C1 [Law, Edith; Ravari, Parastoo Baghaei; Chhibber, Nalin; Lin, Stephanie; Pantasdo, Kevin D.; Ceha, Jessy; Suh, Sangho; Dillen, Nicole] Univ Waterloo, Waterloo, ON, Canada.
   [Kulic, Dana] Monash Univ, Clayton, Vic, Australia.
RP Law, E (corresponding author), Univ Waterloo, Waterloo, ON, Canada.
EM edith.law@uwaterloo.ca; parastoo.baghaei.ravari@uwaterloo.ca;
   nalin.chhibber@uwaterloo.ca; dana.kulic@uwaterloo.ca;
   stephanielin78@gmail.com; kevin.pantasdo@edu.uwaterloo.ca;
   jceha@uwaterloo.ca; shsuh@uwaterloo.ca; nicole.dillen@uwaterloo.ca
CR Alaimi M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376776
   Aschner, 1963, MERRILL PALMER Q, V9, P183
   Biswas G, 2005, APPL ARTIF INTELL, V19, P363, DOI 10.1080/08839510590910200
   Biswas G, 2016, INT J ARTIF INTELL E, V26, P350, DOI 10.1007/s40593-015-0057-9
   Brophy S, 1999, FR ART INT, V50, P21
   Chaffey T, 2018, ACMIEEE INT CONF HUM, P85, DOI 10.1145/3173386.3176979
   Chandra S, 2017, AAMAS'17: PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P1490
   Chase CC, 2009, J SCI EDUC TECHNOL, V18, P334, DOI 10.1007/s10956-009-9180-4
   Chhibber Nalin, 2019, THESIS
   GALL MD, 1970, REV EDUC RES, V40, P707, DOI 10.2307/1169463
   Graesser A. C., 1999, Cognitive Systems Research, V1, P35, DOI 10.1016/S1389-0417(99)00005-4
   GRAESSER AC, 1994, AM EDUC RES J, V31, P104, DOI 10.2307/1163269
   Hood D, 2015, ACMIEEE INT CONF HUM, P83, DOI 10.1145/2696454.2696479
   Kanda T, 2004, HUM-COMPUT INTERACT, V19, P61, DOI 10.1207/s15327051hci1901&2_4
   Kulkarni C, 2013, ACM T COMPUT-HUM INT, V20, DOI 10.1145/2505057
   Lee JER, 2007, J COMMUN, V57, P183, DOI 10.1111/j.1460-2466.2007.00339.x
   Matsuda N, 2013, J EDUC PSYCHOL, V105, P1152, DOI 10.1037/a0031955
   Moreno R, 2001, COGNITION INSTRUCT, V19, P177, DOI 10.1207/S1532690XCI1902_02
   RAPHAEL TE, 1985, AM EDUC RES J, V22, P217, DOI 10.3102/00028312022002217
   Roscoe RD, 2007, REV EDUC RES, V77, P534, DOI 10.3102/0034654307309920
   Tanaka F, 2015, IEEE-RAS INT C HUMAN, P270, DOI 10.1109/HUMANOIDS.2015.7363546
   Tanaka F, 2012, J HUM-ROBOT INTERACT, V1, P78, DOI 10.5898/JHRI.1.1.Tanaka
   Wittwer J, 2008, EDUC PSYCHOL-US, V43, P49, DOI 10.1080/00461520701756420
   Yadollahi E, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P195, DOI 10.1145/3202185.3202743
NR 24
TC 1
Z9 1
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6819-3
PY 2020
AR LBW142
DI 10.1145/3334480.3382783
PG 9
WC Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ9OG
UT WOS:000626317801050
DA 2022-08-02
ER

PT J
AU Arsovski, S
   Wong, SH
   Cheok, AD
AF Arsovski, Sasa
   Wong, Sze Hui
   Cheok, Adrian David
TI Open-Domain Neural Conversational Agents: The Step Towards Artificial
   General Intelligence
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence; deep learning; neural networks; open domain
   chatbots; conversational agents
AB Development of conversational agents started half century ago and since then it has transformed into a technology that is accessible in various aspects in everyday life. This paper presents a survey current state-of-the-art in the open domain neural conversational agent research and future research directions towards Artificial General Intelligence (AGI) creation. In order to create a conversational agent which is able to pass the Turing Test, numerous research efforts are focused on open-domain dialogue system. This paper will present latest research in domain of Neural Network reasoning and logical association, sentiment analysis and real-time learning approaches applied to open domain neural conversational agents. As an effort to provide future research directions, current cutting-edge approaches applied to open domain neural conversational agents, current cutting-edge approaches in rationale generation and the state-of-the-art research directions in alternative training methods will be discussed in this paper.
C1 [Arsovski, Sasa; Wong, Sze Hui; Cheok, Adrian David] Imagineering Inst, Iskandar Puteri, Malaysia.
RP Arsovski, S (corresponding author), Imagineering Inst, Iskandar Puteri, Malaysia.
RI Cheok, Adrian David/AAT-6141-2021; Arsovski, Sasa/AAU-1605-2021
OI Cheok, Adrian David/0000-0001-6316-2339; Arsovski,
   Sasa/0000-0001-5981-9473
CR [Anonymous], 2014, P COLING 2014 25 INT
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Carpenter R., 2005, COMPUTING, V22, P2009
   Chris L., 2014, WHY CORTANA ASSISTAN
   Crist R, 2016, AMAZON ALEXA DEVICE
   Crockett K, 2011, LECT NOTES ARTIF INT, V6682, P16, DOI 10.1007/978-3-642-22000-5_3
   Das A., 2018, BUILD BETTER CHATBOT, P1
   Duan N., 2017, P 2017 C EMP METH NA, P866, DOI DOI 10.18653/V1/D17-1090
   Goertzel B., 2007, ADV ARTIFICIAL GEN I, V6, P36
   Harris J. W., 1998, HDB MATH COMPUTATION
   Heudin JC, 2017, ICAART: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 2, P34, DOI 10.5220/0006113600340041
   Kaiser Lukasz, 2017, ARXIV170605137
   Koehn P, 2005, P ACL WORKSH BUILD U
   Le Q, 2015, ARXIV150605869
   Lee L., 2011, ACL
   Lei T., 2016, ARXIV160604155
   Li J., 2016, ARXIV160601541
   Li J., 2015, ARXIV151003055
   Santoro A., 2017, ADV NEURAL INFORM PR, V30, P4967
   Serban IV, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3776
   Serban IV, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3295
   Sutskever I., 2014, ADV NEURAL INFORM PR, P3104
   Tang D, 2017, ARXIV170602027
   Wakefield Jane, 2016, MICROSOFT CHATBOT IS
   Wallace R. S., 2009, PARSING TURING TEST, P181, DOI DOI 10.1007/978-1-4020-6710-5_13
   Wang J, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P515, DOI 10.1145/3077136.3080786
   Wang T., 2017, ABS170601450 CORR
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wu Y., 2016, ARXIV160908144
   Yuan X., 2017, ARXIV170502012
NR 31
TC 5
Z9 5
U1 0
U2 13
PU SCIENCE & INFORMATION SAI ORGANIZATION LTD
PI WEST YORKSHIRE
PA 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND
SN 2158-107X
EI 2156-5570
J9 INT J ADV COMPUT SC
JI Int. J. Adv. Comput. Sci. Appl.
PD JUN
PY 2018
VL 9
IS 6
BP 402
EP 408
PG 7
WC Computer Science, Theory & Methods
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA GM3NL
UT WOS:000438011500055
DA 2022-08-02
ER

PT J
AU Tellols, D
   Lopez-Sanchez, M
   Rodriguez, I
   Almajano, P
   Puig, A
AF Tellols, Dolca
   Lopez-Sanchez, Maite
   Rodriguez, Inmaculada
   Almajano, Pablo
   Puig, Anna
TI Enhancing sentient embodied conversational agents with machine learning
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Embodied conversational agents; Machine learning; Virtual tutors
AB Within the area of intelligent User Interfaces, we propose what we call Sentient Embodied Conversational Agents (SECAs): virtual characters able to engage users in complex conversations and to incorporate sentient capabilities similar to the ones humans have. This paper introduces SECAs together with their architecture and a publicly available software library that facilitates their inclusion in applications -such as educational and elder-care- requiring proactive and sensitive agent behaviours. In fact, we illustrate our proposal with a virtual tutor embedded in an educational application for children. The evaluation was performed in two stages: firstly, we tested a version with basic textual processing capabilities; and secondly, we evaluated a SECA with Machine-Learning-enhanced user understanding capabilities. The results show a significant improvement in users' perception of the agent's understanding capability. Indeed, the Response Error Rate decreased from 22.31% to 11.46% using ML techniques. Moreover, 99.33% of the participants consider the global experience of talking with the virtual tutor with sentient capabilities to be satisfactory. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Tellols, Dolca] Tokyo Inst Technol, Sch Comp, Meguro Ookayama 2-12-1, Tokyo 1528550, Japan.
   [Lopez-Sanchez, Maite; Rodriguez, Inmaculada; Almajano, Pablo; Puig, Anna] Univ Barcelona, Gran Via Corts Catalanes 585, E-08007 Barcelona, Spain.
RP Tellols, D (corresponding author), Tokyo Inst Technol, Sch Comp, Meguro Ookayama 2-12-1, Tokyo 1528550, Japan.
EM tellols.d.aa@m.titech.ac.jp
RI Lopez-Sanchez, Maite/ABG-2682-2021; Rodriguez, Inmaculada/H-9298-2015
OI Lopez-Sanchez, Maite/0000-0002-1838-5928; Rodriguez,
   Inmaculada/0000-0001-5931-7713
FU  [2017-SGR-341];  [PGC2018-096212-B-C33]
FX This research is partly funded by research Projects 2017-SGR-341 and
   MISMIS-Language (PGC2018-096212-B-C33). We also want to thank
   Rubi-Brilla, schools Montessori, 25 de Setembre, and Escola del Mar, as
   well as the children and their families.
CR Agresti A, 2011, CATEGORICAL DATA ANA
   Almajano P, 2017, FRONT ARTIF INTEL AP, V300, P263, DOI 10.3233/978-1-61499-806-8-263
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], 2017, P 31 BRIT COMP SOC H
   [Anonymous], 2012, ORG BEHAV
   [Anonymous], 2005, P 4 INT JOINT C AUT, DOI DOI 10.1145/1082473.1082478
   [Anonymous], [No title captured]
   [Anonymous], 2018, DEEP LEARNING SPOKEN
   [Anonymous], 2014, P COLING 2014 25 INT
   Bosse T, 2015, LECT NOTES ARTIF INT, V9387, P650, DOI 10.1007/978-3-319-25524-8_48
   Cassell J, 2001, AI MAG, V22, P67
   COLBY BN, 1989, CONTEMP SOCIOL, V18, P957, DOI 10.2307/2074241
   Feshbach ND, 2009, SOCIAL NEUROSCIENCE OF EMPATHY, P85
   Garcia-Carmona A, 2013, ENSEN CIENC, V31, P87, DOI 10.5565/rev/ec/v31n3.772
   Graesser AC, 2004, BEHAV RES METH INS C, V36, P180, DOI 10.3758/BF03195563
   Haddock CK, 1998, PSYCHOL METHODS, V3, P339, DOI 10.1037/1082-989X.3.3.339
   Kshirsagar S., 2002, P 2 INT S SMART GRAP, P107, DOI DOI 10.1145/569005.569021
   Liu B., 2018, ARXIV180406512
   Maslow AH, 1943, PSYCHOL REV, V50, P370, DOI 10.1037/h0054346
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   Mikolov T., 2013, ARXIV PREPRINT ARXIV
   Pardo D, 2010, J MULTIMODAL USER IN, V3, P285, DOI 10.1007/s12193-010-0052-2
   Robertson S, 2015, LECT NOTES COMPUT SC, V9192, P427, DOI 10.1007/978-3-319-20609-7_40
   Sekhavat YA, 2017, INT J ARTIF INTELL T, V26, DOI 10.1142/S0218213017300010
   Serholt S, 2013, PROC EUR CONF GAME, P790
   Wallace, 2003, ELEMENTS AIML STYLE, DOI 10.1.1.693.3664.
   Wanner L, 2017, LECT NOTES ARTIF INT, V10349, P284, DOI 10.1007/978-3-319-59930-4_23
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
NR 30
TC 5
Z9 5
U1 4
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD JAN
PY 2020
VL 129
BP 317
EP 323
DI 10.1016/j.patrec.2019.11.035
PG 7
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA JY8EO
UT WOS:000504641500043
DA 2022-08-02
ER

PT C
AU Cho, M
   Lee, SS
   Lee, KP
AF Cho, Minji
   Lee, Sang-su
   Lee, Kun-Pyo
GP ACM
TI Once a Kind Friend is Now a Thing: Understanding How Conversational
   Agents at Home are Forgotten
SO PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE
   (DIS 2019)
LA English
DT Proceedings Paper
CT ACM Designing Interactive Systems Conference (DIS)
CY JUN 24-28, 2019
CL San Diego, CA
SP Assoc Comp Machinery, Adobe, Google, UC San Diego Design Lab, Virginia Tech, Sketch
DE Conversational agents; Amazon Echo; user experience
ID USER ACCEPTANCE; TECHNOLOGY
AB The number of households using stand-alone conversational agents is rapidly increasing. However, recent research revealed that in some of these households, use of agents decreases over time, and we know little about why. Therefore, we aim to understand how people utilize such devices in their daily lives and to explore the associated obstacles or difficulties. We conducted a long-term (12-week) user study in which we followed eight households, examining their use of Amazon Echo at home. From a series of diaries, surveys, and interviews with eight first-time users, we identified how their experiences changed over time and how conversational agents lose their presence at home. We found that voice interface, physical form, and at-home installation affect users' perceptions and expectations of smart speakers. Based on these findings, we discuss challenges and design opportunities for future at-home conversational agents.
C1 [Cho, Minji; Lee, Sang-su] Korea Adv Inst Sci & Technol, Dept Ind Design, Daejeon, South Korea.
   [Lee, Kun-Pyo] Hong Kong Polytech Univ, Sch Design, Hong Kong, Peoples R China.
RP Cho, M (corresponding author), Korea Adv Inst Sci & Technol, Dept Ind Design, Daejeon, South Korea.
EM mjcho@kaist.ac.kr; sangsu.lee@kaist.ac.kr; kunpyo.lee@polyu.edu.hk
CR Accenture, 2018, DIG CONS SURV
   Altman I., 1973, SOCIAL PENETRATION D
   Baber Christopher, 1993, DEV INTERACTIVE SPEE
   Bargh J. A., 1994, HDB SOCIAL COGNITION, V1, P1, DOI DOI 10.1007/S00572-005-0022-9
   Bentley Frank, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3264901
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Boyce S, 1996, P ISSD, V96, P65
   Brown B, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1657
   Cowan BR, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3098539
   Coyne Marty, 2017, IPROCEEDINGS, V3, pE49, DOI [10.2196/iproc.8576, DOI 10.2196/IPROC.8576]
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   de Graaf MMA, 2018, NEW MEDIA SOC, V20, P2582, DOI 10.1177/1461444817727264
   Demiris George, 2008, Technol Health Care, V16, P111
   Druga S, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P595, DOI 10.1145/3078072.3084330
   Everett M., 1995, DIFFUSION INNOVATION, V4th
   Forlizzi J., 2004, P 2004 C DES INT SYS, V261
   FURNAS GW, 1987, COMMUN ACM, V30, P964, DOI 10.1145/32206.32212
   Google, 2018, VOIC ASS IS RESH CON
   Karapanos E, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P729
   Karsenty L., 2002, International Journal of Speech Technology, V5, P147, DOI 10.1023/A:1015472130944
   Kiseleva J, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL (CHIIR'16), P121, DOI 10.1145/2854946.2854961
   Lee Y, 2011, ELECTRON COMMER R A, V10, P342, DOI 10.1016/j.elerap.2010.11.005
   Lopez G, 2018, ADV INTELL SYST, V592, P241, DOI 10.1007/978-3-319-60366-7_23
   Lovato Silvia, 2015, P 14 INT C INT DES C, P335, DOI [10.1145/2771839.2771910, DOI 10.1145/2771839.2771910]
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   McTear MF, 2002, ACM COMPUT SURV, V34, P90, DOI 10.1145/505282.505285
   Montalvan J, 2017, INT J DES, V11, P1
   Myers C, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173580
   Payr Sabine, 2013, Your Virtual Butler. The Making-of: LNCS 7407, P134, DOI 10.1007/978-3-642-37346-6_11
   Porcheron M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174214
   PriceWaterHouse Coopers, 2018, CONS INT SER PREP VO
   Purington A, 2017, 2017 CHI C HUM FACT, DOI [10.1145/3027063.3053246, DOI 10.1145/3027063.3053246]
   Rogers Y, 2007, LECT NOTES COMPUT SC, V4717, P336
   Sciuto A, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P857, DOI 10.1145/3196709.3196772
   Shedroff N., 2012, MAKE IT SO INTERACTI
   Sulleyman Aatif, 2017, NHS CYBER ATTACK WHY
   Sung J, 2010, INT J SOC ROBOT, V2, P417, DOI 10.1007/s12369-010-0065-8
   Thomson David L, 1999, ESCA TUT RES WORKSH
   voicebot.ai, 2018, SMART SPEAK CONS AD
   VoiceLabs.co, 2017, 2017 VOIC REP
   Wilamowitz-Moellendorff von, 2006, DYNAMICS USER EXPERI
   Wilks Yorick, 2010, IS COMPANION DISTINC
NR 43
TC 33
Z9 33
U1 4
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5850-7
PY 2019
BP 1557
EP 1569
DI 10.1145/3322276.3322332
PG 13
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications; Computer Science, Software Engineering; Engineering,
   Electrical & Electronic; Ergonomics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Engineering
GA BS3ZH
UT WOS:000717008300122
DA 2022-08-02
ER

PT C
AU Chen, XT
   Mi, JQ
   Jia, MH
   Han, YJ
   Zhou, ML
   Wu, T
   Guan, DS
AF Chen, Xiantao
   Mi, Jiaqi
   Jia, Menghua
   Han, Yajuan
   Zhou, Moli
   Wu, Tian
   Guan, Daisong
GP ACM
TI Chat with Smart Conversational Agents: How to Evaluate Chat Experience
   in Smart Home
SO PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER
   INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'19)
LA English
DT Proceedings Paper
CT 21st International Conference on Human-Computer Interaction with Mobile
   Devices and Services (MobileHCI)
CY OCT 01-04, 2019
CL Taipei, TAIWAN
DE Smart conversational agents; chat; experience evaluation; smart speaker;
   smart home
AB There are more and more smart devices equipped with smart conversational agents, which can engage in chat or free conversation with human. However, the human-machine chat is still in the early stage of development, and there is a lack of effective methods to evaluate chat experience. In this study we proposed an approach to evaluate chat experience with smart conversational agents in smart home. We collected evaluation metrics and applied them in user testing, and then optimized the metrics and constructed an evaluation system. We applied the evaluation system to compare chat experience of five different smart conversational agents.
C1 [Chen, Xiantao; Mi, Jiaqi; Jia, Menghua; Han, Yajuan; Zhou, Moli; Wu, Tian; Guan, Daisong] Baidu Inc, Beijing, Peoples R China.
RP Chen, XT (corresponding author), Baidu Inc, Beijing, Peoples R China.
EM chenxiantao@baidu.com; mijiaqi@baidu.com; jiamenghua@baidu.com;
   hanyajuan@baidu.com; zhoumoli@baidu.com; wutian@baidu.com;
   guandaisong@baidu.com
CR Banchs R. E., 2012, P ACL 2012 SYST DEM, P37
   Bang J, 2015, INT CONF BIG DATA, P238, DOI 10.1109/35021BIGCOMP.2015.7072837
   Dunbar RIM, 1997, HUM NATURE-INT BIOS, V8, P231, DOI 10.1007/BF02912493
   Gandhe S., 2007, INTERSPEECH, P2201
   GRICE HP, 1975, SYNTAX SEMANTICS, V3, DOI DOI 10.1111/J.1365-2664.2006.01229.X
   Leech Geoffrey, 1983, PRINCIPLES PRAGMATIC
   McTear MF, 2002, ACM COMPUT SURV, V34, P90, DOI 10.1145/505282.505285
   Naaman M, 2010, 2010 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P189
   Shawar B. A., 2007, P WORKSH BRIDG GAP A, P89, DOI [10.3115/1556328.1556341, DOI 10.3115/1556328.1556341]
   Stallard D, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, P68
   Yu ZX, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND INTELLIGENT CONTROL (ISIC 2015), P108
NR 11
TC 2
Z9 2
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6825-4
PY 2019
AR 60
DI 10.1145/3338286.3344408
PG 6
WC Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP5MZ
UT WOS:000556723600059
DA 2022-08-02
ER

PT J
AU Kocaballi, AB
   Berkovsky, S
   Quiroz, JC
   Laranjo, L
   Tong, HL
   Rezazadegan, D
   Briatore, A
   Coiera, E
AF Kocaballi, Ahmet Baki
   Berkovsky, Shlomo
   Quiroz, Juan C.
   Laranjo, Liliana
   Huong Ly Tong
   Rezazadegan, Dana
   Briatore, Agustina
   Coiera, Enrico
TI The Personalization of Conversational Agents in Health Care: Systematic
   Review
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Review
DE conversational interfaces; conversational agents; dialogue systems;
   personalization; customization; adaptive systems; health care
ID MINDFULNESS; GENERATION
AB Background: The personalization of conversational agents with natural language user interfaces is seeing increasing use in health care applications, shaping the content, structure, or purpose of the dialogue between humans and conversational agents.
   Objective: The goal of this systematic review was to understand the ways in which personalization has been used with conversational agents in health care and characterize the methods of its implementation.
   Methods: We searched on PubMed, Embase, CINAHL, PsycInfo, and ACM Digital Library using a predefined search strategy. The studies were included if they: (1) were primary research studies that focused on consumers, caregivers, or health care professionals; (2) involved a conversational agent with an unconstrained natural language interface; (3) tested the system with human subjects; and (4) implemented personalization features.
   Results: The search found 1958 publications. After abstract and full-text screening, 13 studies were included in the review. Common examples of personalized content included feedback, daily health reports, alerts, warnings, and recommendations. The personalization features were implemented without a theoretical framework of customization and with limited evaluation of its impact. While conversational agents with personalization features were reported to improve user satisfaction, user engagement and dialogue quality, the role of personalization in improving health outcomes was not assessed directly.
   Conclusions: Most of the studies in our review implemented the personalization features without theoretical or evidence-based support for them and did not leverage the recent developments in other domains of personalization. Future research could incorporate personalization as a distinct design factor with a more careful consideration of its impact on health outcomes and its implications on patient safety, privacy, and decision-making.
C1 [Kocaballi, Ahmet Baki; Berkovsky, Shlomo; Quiroz, Juan C.; Laranjo, Liliana; Huong Ly Tong; Rezazadegan, Dana; Coiera, Enrico] Macquarie Univ, Australian Inst Hlth Innovat, Fac Med & Hlth Sci, Level 6,75 Talavera Rd, Sydney, NSW 2109, Australia.
   [Briatore, Agustina] Minist Hlth, Hlth Informat Syst Off, Buenos Aires, DF, Argentina.
RP Kocaballi, AB (corresponding author), Macquarie Univ, Australian Inst Hlth Innovat, Fac Med & Hlth Sci, Level 6,75 Talavera Rd, Sydney, NSW 2109, Australia.
EM baki.kocaballi@mq.edu.au
RI Laranjo, Liliana/D-5356-2017; Quiroz, Juan/P-6215-2016; Kocaballi,
   Baki/R-3136-2019
OI Laranjo, Liliana/0000-0003-1020-3402; Quiroz, Juan/0000-0003-0241-5376;
   Kocaballi, Baki/0000-0002-8328-5317; Rezazadegan,
   Dana/0000-0002-0097-3801; Coiera, Enrico/0000-0002-6444-6584; Berkovsky,
   Shlomo/0000-0003-2638-4121; Tong, Huong Ly/0000-0002-8462-0105;
   Briatore, Agustina/0000-0002-6389-182X
FU National Health and Medical Research Council (NHMRC) [APP1134919]
FX This research was supported by the National Health and Medical Research
   Council (NHMRC) grant APP1134919 (Centre for Research Excellence in
   Digital Health). We would like to thank Catalin Tufanaru for his
   comments on the earlier drafts of this paper.
CR Aha DW, 2001, APPL INTELL, V14, P9, DOI 10.1023/A:1008346807097
   AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   Awad NF, 2006, MIS QUART, V30, P13
   Azzini Ivano, 2003, Stud Health Technol Inform, V95, P146
   Barnard KD, 2014, DIABETIC MED, V31, P522, DOI 10.1111/dme.12400
   Bickmore T, 2006, J BIOMED INFORM, V39, P556, DOI 10.1016/j.jbi.2005.12.004
   Bickmore TW, 2018, J MED INTERNET RES, V20, DOI 10.2196/11510
   Black L, 2005, 2005 18 IEEE S COMP, DOI [10.1109/cbms.2005.33, DOI 10.1109/CBMS.2005.33]
   Blom JO, 2003, HUM-COMPUT INTERACT, V18, P193, DOI 10.1207/S15327051HCI1803_1
   Brennan S. E., 1996, P INT S SPOK DIAL, V96, P41
   CARENINI G, 2001, IJCAI 2001, P01307
   Carr N, 2015, GLASS CAGE AUTOMATIO
   Cesuroglu T, 2016, BMJ OPEN, V6, DOI 10.1136/bmjopen-2015-010243
   Chen L, 2012, USER MODEL USER-ADAP, V22, P125, DOI 10.1007/s11257-011-9108-6
   CHOATE WT, 2005, SECURITY USABILITY D, P495
   Chu-Carroll J, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, pA202
   CLARK HH, 1986, COGNITION, V22, P1, DOI 10.1016/0010-0277(86)90010-7
   Coiera E, 2012, Yearb Med Inform, V7, P4
   Coiera E, 2018, J AM MED INFORM ASSN, V25, P963, DOI 10.1093/jamia/ocy028
   Demberg V, 2011, COMPUT LINGUIST, V37, P489, DOI 10.1162/COLI_a_00064
   Fan HY, 2006, J ORG COMP ELECT COM, V16, P179, DOI 10.1207/s15327744joce1603&4_2
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Fulmer R, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/mental.9782
   Giorgino T, 2005, INT J MED INFORM, V74, P159, DOI 10.1016/j.ijmedinf.2004.04.026
   Griol D, 2013, APPL ARTIF INTELL, V27, P759, DOI 10.1080/08839514.2013.835230
   Harper R, 2008, FIFTEENTH IEEE INTERNATIONAL CONFERENCE AND WORKSHOPS ON THE ENGINEERING OF COMPUTER-BASED SYSTEMS, PROCEEDINGS, P219, DOI 10.1109/ECBS.2008.31
   Hawkins RP, 2008, HEALTH EDUC RES, V23, P454, DOI 10.1093/her/cyn004
   Hong H, 2009, 2009 12 ANN INT PUBL
   Hudlicka E, 2013, PATIENT EDUC COUNS, V92, P160, DOI 10.1016/j.pec.2013.05.007
   Inkster B, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/12106
   Jameson A, 2001, PERS UBIQUIT COMPUT, V5, P29, DOI 10.1007/s007790170025
   Kember D., 2000, DEV QUESTIONNAIRE ME, V25, P381, DOI DOI 10.1080/713611442
   Kim Y, 2015, LECT NOTES ARTIF INT, V8757, P78, DOI 10.1007/978-3-319-15557-9_8
   Kocielnik Rafal, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3214273
   Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x
   Kroeze W, 2006, ANN BEHAV MED, V31, P205, DOI 10.1207/s15324796abm3103_2
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lee MK, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P743, DOI 10.1145/2750858.2807552
   Levin E, 2006, J MED INTERNET RES, V8, DOI 10.2196/jmir.8.4.e30
   Litman DJ, 2002, USER MODEL USER-ADAP, V12, P111, DOI 10.1023/A:1015036910358
   Litman DJ, 1999, CISM COUR L, P55
   Maloor P, 2000, P 1 SIGDIAL WORKSH D, V10, P94, DOI [10.3115/1117736.1117747, DOI 10.3115/1117736.1117747]
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   McTear MF, 2002, ACM COMPUT SURV, V34, P90, DOI 10.1145/505282.505285
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Noar SM, 2007, PSYCHOL BULL, V133, P673, DOI 10.1037/0033-2909.133.4.673
   Noar SM, 2011, AM J LIFESTYLE MED, V5, P112, DOI 10.1177/1559827610387255
   Oulasvirta A, 2008, INTERACT COMPUT, V20, P1, DOI 10.1016/j.intcom.2007.06.002
   Pargellis AN, 2004, SPEECH COMMUN, V42, P329, DOI 10.1016/j.specom.2003.10.003
   Pariser E., 2012, CHOICE REV ONLINE, V50, DOI 10.5860/choice.50-0926
   Pereira J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1237-1
   Perez S., 2019, TECHCRUNCH
   Pokorska-Bocci A, 2014, PERS MED, V11, P197, DOI 10.2217/pme.13.107
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Radziwill NM, 2017, EVALUATING QUALITY C, P1
   Revere D, 2001, J AM MED INFORM ASSN, V8, P62, DOI 10.1136/jamia.2001.0080062
   Rhee H, 2014, PATIENT PREFER ADHER, V8, P63, DOI 10.2147/PPA.S53504
   Rich E., 1998, READINGS INTELLIGENT, P329
   Riquelme H, 2001, J CONSUM MARK, V18, P437, DOI 10.1108/07363760110398772
   Sillice MA, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.7640
   Spalding E, 2002, TEACH COLL REC, V104, P1393, DOI 10.1111/1467-9620.00208
   Spitzer RL, 2006, ARCH INTERN MED, V166, P1092, DOI 10.1001/archinte.166.10.1092
   Tanaka H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182151
   Thompson CA, 2004, J ARTIF INTELL RES, V21, P393, DOI 10.1613/jair.1318
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   Walach H, 2006, PERS INDIV DIFFER, V40, P1543, DOI 10.1016/j.paid.2005.11.025
   Walker MA, 2004, COGNITIVE SCI, V28, P811, DOI 10.1016/j.cogsci.2004.06,002
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
NR 69
TC 45
Z9 45
U1 8
U2 31
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD NOV 7
PY 2019
VL 21
IS 11
AR e15360
DI 10.2196/15360
PG 15
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA JL3WX
UT WOS:000495464000001
PM 31697237
OA gold, Green Published
DA 2022-08-02
ER

PT J
AU DeCarlo, D
   Stone, M
   Revilla, C
   Venditti, JJ
AF DeCarlo, D
   Stone, M
   Revilla, C
   Venditti, JJ
TI Specifying and animating facial signals for discourse in embodied
   conversational agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE facial animation; embodied conversational agents
ID COMMUNICATION; EXPRESSIONS; INTONATION; MOVEMENT; LANGUAGE; SPEECH
AB People highlight the intended interpretation of their utterances within a larger discourse by a diverse set of non-verbal signals. These signals represent a key challenge for animated conversational agents because they are pervasive, variable, and need to be coordinated judiciously in an effective contribution to conversation. In this paper, we describe a freely available cross-platform real-time facial animation system, RUTH, that animates such high-level signals in synchrony with speech and lip movements. RUTH adopts an open, layered architecture in which fine-grained features of the animation can be derived by rule from inferred linguistic structure, allowing us to use RUTH, in conjunction with annotation of observed discourse, to investigate the meaningful high-level elements of conversational facial movement for American English speakers. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.
   Rutgers State Univ, Ctr Cognit Sci, Piscataway, NJ 08854 USA.
RP DeCarlo, D (corresponding author), Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.
EM decarlo@cs.rutgers.edu
OI Stone, Matthew/0000-0003-3629-2941
CR Andre E, 2000, EMBODIED CONVERSATIONAL AGENTS, P220
   [Anonymous], 1992, PARADIGMS ARTIFICIAL
   Badler N, 2002, COMP ANIM CONF PROC, P133, DOI 10.1109/CA.2002.1017521
   Ball G, 2000, EMBODIED CONVERSATIONAL AGENTS, P189
   Bavelas JB, 2000, J LANG SOC PSYCHOL, V19, P163, DOI 10.1177/0261927X00019002001
   BECKMAN M, 1997, GUIDELINSE TOBI LABE
   BLACK A, 1997, HCRCTR83
   Brand M, 1999, COMP GRAPH, P21
   BULL P, 1985, J NONVERBAL BEHAV, V9, P169, DOI 10.1007/BF01000738
   BYUN M, 2002, ACM SIGGRAPH S COMP, P65
   Cahn J.E., 1990, J AM VOICE IO SOC, V8, P1
   Cassell J, 2001, COMP GRAPH, P477
   CASSELL J, 2000, 1 INT C NAT LANG GEN, P171
   CASSELL J, 1994, P COGN SCI SOC
   CASSELL J, 1999, APPL ARTIFICIAL INTE, V13
   Cassell J., 2000, EMBODIED CONVERSATIO
   Cassell J., 1999, P SIGCHI C HUM FACT, P520, DOI DOI 10.1145/302979.303150
   Chi D, 2000, COMP GRAPH, P173
   Cohen M. M., 1993, Models and Techniques in Computer Animation, P139
   DECAROLIS B, 2001, P IJCAI
   ENGLE RA, 2000, THESIS STANFORD U
   HADAR U, 1983, LANG SPEECH, V26, P117, DOI 10.1177/002383098302600202
   Hirschberg, 1992, P INT C SPOK LANG PR, P867
   HIRSCHBERG J, 1993, ARTIF INTELL, V63, P305, DOI 10.1016/0004-3702(93)90020-C
   HIRSCHBERG J, 1996, P ACL
   Jilka M, 1999, SPEECH COMMUN, V28, P83, DOI 10.1016/S0167-6393(99)00008-4
   KING SA, 2001, THESIS OHIO STATE U
   KRAHMER E, 2002, S SPEECH PROS
   KRAHMER E, 2002, INT C SPOK LAN PROC
   LADD DR, 1985, J ACOUST SOC AM, V78, P435, DOI 10.1121/1.392466
   Lester JC, 2000, EMBODIED CONVERSATIONAL AGENTS, P123
   LOFQVIST A, 1990, NATO ADV SCI I D-BEH, V55, P289
   MACON M, 1997, CSE97007 OR GRAD I
   MARSELLA SC, 2000, P AGENTS
   Massaro D.W., 1998, PERCEIVING TALKING F
   McNeil D., 1992, HAND MIND WHAT GESTU
   MOHLER G, 2001, P 4 ISCA TUT RES WOR
   MOHLER G, 1999, P 6 EUR C SPEECH COM
   NAGAO K, 1994, P 32 ANN M ASS COMP, P102
   Nass C, 2000, EMBODIED CONVERSATIONAL AGENTS, P374
   Pelachaud C, 1996, COGNITIVE SCI, V20, P1
   Pelachaud C, 2002, J VISUAL COMP ANIMAT, V13, P301, DOI 10.1002/vis.299
   PERLIN K, 1998, TEXTURING MODELING P, P209
   PERLIN K, 1997, SIGGRAPH 1997
   PIERREHUMBERT J, 1990, SYS DEV FDN, P271
   PLATT SM, 1985, THESIS U PENNSYLVANI
   Ploog D., 1979, HUMAN ETHOLOGY CLAIM, P169, DOI DOI 10.1007/978-1-4020-2783-33
   Poggi I, 2000, AI COMMUN, V13, P169
   Poggi I, 2000, EMBODIED CONVERSATIONAL AGENTS, P155
   Smid K, 2002, COMP ANIM CONF PROC, P240, DOI 10.1109/CA.2002.1017543
   STONE M, 2003, COMPUTER ANIMATION S
   Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1, P73
   Waters, 2005, COMPUT GRAPH, V21, P17, DOI [10.1145/37402.37405, DOI 10.1145/37402.37405]
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
NR 54
TC 13
Z9 13
U1 0
U2 1
PU WILEY-BLACKWELL
PI MALDEN
PA COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2004
VL 15
IS 1
BP 27
EP 38
DI 10.1002/cav.5
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 832EF
UT WOS:000222249300004
DA 2022-08-02
ER

PT C
AU Hiniker, A
   Wang, A
   Tran, J
   Zhang, MR
   Radesky, J
   Sobel, K
   Hong, SR
AF Hiniker, Alexis
   Wang, Amelia
   Tran, Jonathan
   Zhang, Mingrui Ray
   Radesky, Jenny
   Sobel, Kiley
   Hong, Sungsoo Ray
GP ASSOC COMP MACHINERY
TI Can Conversational Agents Change the Way Children Talk to People?
SO IDC '21: PROCEEDINGS OF INTERACTION DESIGN AND CHILDREN 2021
LA English
DT Proceedings Paper
CT 20th ACM Interaction Design and Children (IDC) Conference
CY JUN 24-30, 2021
CL ELECTR NETWORK
SP Assoc Comp Machinery, Natl & Kapodistrian Univ Athens, LUMS, BRIDGES, EUGAIN, NSF
DE Conversational agents; linguistic routines
ID SOCIAL-INTERACTION; LANGUAGE; ROBOTS; TELEVISION; BEHAVIOR; SKILLS
AB Millions of children now use conversational agents (CAs), leading researchers and the public alike to ask how interactions with these devices might shape children's communication with people. We conducted a single-session observational lab study with 22 five-to-ten-year-old children as a step toward understanding whether and how children might transfer a linguistic routine they learned from a CA to a conversation with another person. We found that 68% of children spontaneously used this routine in a conversation with their parent in the lab, and 55% continued to use it at home. When addressing parents, children infused the routine with warmth and playfulness that they did not use when addressing the CA, adapting it to suit their relationship with their parent. However, only 18% of children used it in conversation with an unfamiliar researcher, where they instead were more likely to follow conventional conversational norms. These findings suggest children are quick to learn linguistic routines from CAs but use social differentiation when they apply them. Children's willingness to expand on and share the routine with their parent is consistent with the principles of the Joint Media Engagement (JME) framework and suggests CAs may be a productive medium for creating JME experiences.
C1 [Hiniker, Alexis; Zhang, Mingrui Ray; Sobel, Kiley] Univ Washington, Informat Sch, Seattle, WA 98195 USA.
   [Wang, Amelia] Univ Calif Santa Cruz, Dept Computat Media, Santa Cruz, CA USA.
   [Tran, Jonathan] Univ Washington, Dept Human Ctr Design & Engn, Seattle, WA 98195 USA.
   [Radesky, Jenny] Univ Michigan, Med Sch, Dept Pediat, Ann Arbor, MI 48109 USA.
   [Sobel, Kiley] Sesame Workshop, Joan Ganz Cooney Ctr, New York, NY USA.
   [Hong, Sungsoo Ray] George Mason Univ, Dept Informat Sci & Technol, Fairfax, VA 22030 USA.
RP Hiniker, A (corresponding author), Univ Washington, Informat Sch, Seattle, WA 98195 USA.
EM alexisr@uw.edu; amlwng@ucsc.edu; jontran7@uw.edu; mingrui@uw.edu;
   jradesky@med.umich.edu; ksobel@uw.edu; shong31@gmu.edu
OI Hong, Sungsoo Ray/0000-0001-6050-5404; Hiniker,
   Alexis/0000-0003-1607-0778
FU Jacobs Foundation Early Career Fellowship
FX Many thanks to all children and parents who participated in this study
   and to the anonymous reviewers for their feedback. We are indebted to
   Jon Froehlich, who provided excellent advice on an early draft of this
   manuscript. This work was supported in part by a Jacobs Foundation Early
   Career Fellowship to Alexis Hiniker.
CR Alaimi M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376776
   Ali MR, 2021, PHYS CHEM LIQ, V59, P537, DOI 10.1080/00319104.2020.1752690
   AMEKA F, 1987, J PRAGMATICS, V11, P299, DOI 10.1016/0378-2166(87)90135-4
   Austin John Langshaw, 1975, DO THINGS WORDS, V88
   Baig Edward C, 2019, SAY THANK YOU PLEASE
   BECKER JA, 1986, MERRILL PALMER QUART, V32, P393
   Becker Judith A., 1981, PRESCHOOLERSJUDGMENT
   Biklen Douglas, 1992, TOP LANG DISORD
   Brackett MA, 2012, LEARN INDIVID DIFFER, V22, P218, DOI 10.1016/j.lindif.2010.10.002
   Breazeal C, 2016, TOP COGN SCI, V8, P481, DOI 10.1111/tops.12192
   Burton Nathan G, 2019, THANK YOU SIRI POLIT
   Cantone KF, 2007, STUD THEOR PSYCHOLIN, V37, P1, DOI 10.1007/978-1-4020-5784-7
   Catania Fabio, 2020, INT WORKSH CHATB RES, P158
   Chalmers Matthew, 2003, WORKSH CROSSR INT HC, V8
   Chase CC, 2009, J SCI EDUC TECHNOL, V18, P334, DOI 10.1007/s10956-009-9180-4
   CHISHOLM K, 1995, DEV PSYCHOPATHOL, V7, P283, DOI 10.1017/S0954579400006507
   Clark Eve., 2009, 1 LANGUAGE ACQUISITI
   Coulmas Florian., 2011, CONVERSATIONAL ROUTI, V96
   Elgan Mike., 2018, CASE TEACHING KIDS B
   Erving Goffman., 1971, RELATIONS PUBLIC MIC
   Eyberg Sheila M, 1995, PSYCHOPHARMACOL BULL
   Garg Radhika, 2020, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V4, DOI 10.1145/3381002
   Garg Radhika, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359165
   Garg R, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376631
   GLEASON JB, 1984, DISCOURSE PROCESS, V7, P493, DOI 10.1080/01638538409544603
   Gordon G, 2015, ACMIEEE INT CONF HUM, P91, DOI 10.1145/2696454.2696469
   Gutstein SE, 2007, AUTISM, V11, P397, DOI 10.1177/1362361307079603
   Heath C., 2010, VIDEO QUALITATIVE RE
   Hourcade JP, 2012, PERS UBIQUIT COMPUT, V16, P157, DOI 10.1007/s00779-011-0383-3
   Jefferson G., 2004, CONVERSATION ANAL ST, P14, DOI 10.1075/pbns.125.02jef
   Kahn PH, 2013, CHILD DEV PERSPECT, V7, P32, DOI 10.1111/cdep.12011
   Kanda T, 2004, HUM-COMPUT INTERACT, V19, P61, DOI 10.1207/s15327051hci1901&2_4
   Kim ES, 2013, J AUTISM DEV DISORD, V43, P1038, DOI 10.1007/s10803-012-1645-2
   Kleinman Zoe, 2018, BBC NEWS JUL
   Kontogiorgos Dimosthenis, 2019, 41 ANN M COGN SCI CO
   Kose-Bagci H, 2009, ADV ROBOTICS, V23, P1951, DOI 10.1163/016918609X12518783330360
   Linebarger DL, 2005, AM BEHAV SCI, V48, P624, DOI 10.1177/0002764204271505
   Lovato SB, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P301, DOI 10.1145/3311927.3323150
   Luria M, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P633, DOI 10.1145/3322276.3322340
   Matson JL, 2011, RES DEV DISABIL, V32, P681, DOI 10.1016/j.ridd.2010.11.014
   Ogan Amy, 2012, Intelligent Tutoring Systems. Proceedings 11th International Conference (ITS 2012), P11, DOI 10.1007/978-3-642-30950-2_2
   Park HW, 2017, ACMIEEE INT CONF HUM, P137, DOI 10.1145/2909824.3020213
   Paschoal L.N., 2019, P 33 BRAZ S SOFTW EN, P57
   Pears KC, 2010, CHILD MALTREATMENT, V15, P64, DOI 10.1177/1077559509337891
   Porcheron M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174214
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   RICE M, 1983, DEV REV, V3, P211, DOI 10.1016/0273-2297(83)90030-8
   Schroeder J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173972
   Severson RL, 2010, NEURAL NETWORKS, V23, P1099, DOI 10.1016/j.neunet.2010.08.014
   SNOW CE, 1983, J CHILD LANG, V10, P551, DOI 10.1017/S0305000900005365
   Spitale M, 2019, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES: COMPANION (IUI 2019), P151, DOI 10.1145/3308557.3308722
   Takeuchi, 2011, NEW COVIEWING DESIGN
   Tanaka F, 2012, J HUM-ROBOT INTERACT, V1, P78, DOI 10.5898/JHRI.1.1.Tanaka
   Tanaka H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182151
   Tartaro A., 2008, P 8 INT C LEARN SCI, V2, P382
   Thomas R, 2007, J ABNORM CHILD PSYCH, V35, P475, DOI 10.1007/s10802-007-9104-9
   Tizard Barbara, 1977, ADOPTION 2 CHANCE
   TOMASELLO M, 1984, J SPEECH HEAR RES, V27, P359, DOI 10.1044/jshr.2703.359
   Truong A., 2016, PARENTS ARE WORRIED
   Villano M, 2011, ACMIEEE INT CONF HUM, P279, DOI 10.1145/1957656.1957770
   Werry I, 2001, LECT NOTES ARTIF INT, V2117, P57
   Winkler R, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376781
   Woolf BP, 2010, LECT NOTES COMPUT SC, V6094, P327
   Xu Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376416
   Yarosh S, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P300, DOI 10.1145/3202185.3202207
   Ying-Yu Chen, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3314392
   Yip JC, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300303
NR 67
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8452-0
PY 2021
BP 338
EP 349
DI 10.1145/3459990.3460695
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7UZ
UT WOS:000767988500034
DA 2022-08-02
ER

PT J
AU Grassi, L
   Recchiuto, CT
   Sgorbissa, A
AF Grassi, Lucrezia
   Recchiuto, Carmine Tommaso
   Sgorbissa, Antonio
TI Knowledge-Grounded Dialogue Flow Management for Social Robots and
   Conversational Agents
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Social robotics; Conversational agents; Knowledge-grounded conversation
ID ONTOLOGY; ELIZA
AB The article proposes a system for knowledge-based conversation designed for Social Robots and other conversational agents. The proposed system relies on an Ontology for the description of all concepts that may be relevant conversation topics, as well as their mutual relationships. The article focuses on the algorithm for Dialogue Management that selects the most appropriate conversation topic depending on the user input. Moreover, it discusses strategies to ensure a conversation flow that captures, as more coherently as possible, the user intention to drive the conversation in specific directions while avoiding purely reactive responses to what the user says. To measure the quality of the conversation, the article reports the tests performed with 100 recruited participants, comparing five conversational agents: (i) an agent addressing dialogue flow management based only on the detection of keywords in the speech, (ii) an agent based both on the detection of keywords and the Content Classification feature of Google Cloud Natural Language, (iii) an agent that picks conversation topics randomly, (iv) a human pretending to be a chatbot, and (v) one of the most famous chatbots worldwide: Replika. The subjective perception of the participants is measured both with the SASSI (Subjective Assessment of Speech System Interfaces) tool, as well as with a custom survey for measuring the subjective perception of coherence.
C1 [Grassi, Lucrezia; Recchiuto, Carmine Tommaso; Sgorbissa, Antonio] Univ Genoa, DIBRIS, Via AllOpera Pia 13, Genoa, Italy.
RP Grassi, L (corresponding author), Univ Genoa, DIBRIS, Via AllOpera Pia 13, Genoa, Italy.
EM lucrezia.grassi@edu.unige.it
OI Grassi, Lucrezia/0000-0001-6363-3962; Sgorbissa,
   Antonio/0000-0001-7789-4311
CR Adelman RD, 2014, JAMA-J AM MED ASSOC, V311, P1052, DOI 10.1001/jama.2014.304
   Adiwardana D., 2020, HUMAN LIKE OPENDOMAI, DOI DOI 10.3390/healthcare7020056
   Alleyne, CHAT BOTS ARE BECOMI
   Belpaeme T, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aat5954
   Broekens Joost, 2009, Gerontechnology, V8, P94
   Bruno B, 2019, INT J SOC ROBOT, V11, P515, DOI 10.1007/s12369-019-00519-w
   Bruno B, 2017, IEEE ROMAN, P553, DOI 10.1109/ROMAN.2017.8172357
   Carrithers M, 2010, CRIT ANTHROPOL, V30, P152, DOI 10.1177/0308275X09364070
   Cervone A, 2020, P 21 ANN M SPEC INT
   Colby K, 1975, ARTIFICIAL PARANOIA
   D'silva GM, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P658, DOI 10.1109/I-SMAC.2017.8058261
   Dilmegani, TOP 30 SUCCESSFUL CH
   Dinan E, 2020, EMNLP IJCNLP 2019 20, P4537, DOI DOI 10.18653/V1/D19-1461
   Dinan E, 2018, INT C LEARN REPR ICL
   Ghazvininejad M, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P5110
   Grassi L, 2021, ARXIV PREPRINT ARXIV
   Guarino N, 1998, FR ART INT, V46, P3
   HAYS RD, 1987, J PERS ASSESS, V51, P69, DOI 10.1207/s15327752jpa5101_6
   Higashinaka R, 2014, INTERSPEECH, P130
   Huang JZ, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P423
   Kim SH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103601
   Kocaballi AB, 2018, P 32 INT BCS HUM COM
   Lewis JR, 2015, INT J SPEECH TECHNOL, V18, P479, DOI 10.1007/s10772-015-9289-1
   Lewis JR, 2016, AVIXD, V1
   Mavridis N, 2015, ROBOT AUTON SYST, V63, P22, DOI 10.1016/j.robot.2014.09.031
   Miller G., 2020, SCI NEWS, DOI DOI 10.1126/SCIENCE.ABB7506
   Motik B, 2008, OWL 2 WEB ONTOLOGY L
   Niemela M, 2019, SOC ROBOT TECHNOL SO
   Nimavat K., 2017, INT J SCI RES DEV, V5, P1019
   Nomura T, 2006, AI SOC, V20, P138, DOI 10.1007/s00146-005-0012-7
   Nuruzzaman M, 2018, INT CONF E BUS ENG, P54, DOI 10.1109/ICEBE.2018.00019
   Pan YD, 2015, INT J SOC ROBOT, V7, P911, DOI 10.1007/s12369-015-0320-0
   Pandey AK, 2018, IEEE ROBOT AUTOM MAG, V25, P40, DOI 10.1109/MRA.2018.2833157
   Papadopoulos C, 2022, INT J SOC ROBOT, V14, P245, DOI 10.1007/s12369-021-00781-x
   Papadopoulos C, 2020, ARCH PUBLIC HEALTH, V78, DOI 10.1186/s13690-020-00409-y
   Pardes A, EMOTIONAL CHATBOTS A
   Recchiuto CT, 2020, IEEE ROBOT AUTOM LET, V5, P6559, DOI 10.1109/LRA.2020.3015461
   Recchuto C, 2020, INT CONF UBIQ ROBOT, P270, DOI 10.1109/UR49135.2020.9144750
   Ritter A., 2011, P C EMP METH NAT LAN, P583
   Roller S., 2020, RECIPES BUILDING OPE
   Schuetzler RM, 2020, J MANAGE INFORM SYST, V37, P875, DOI 10.1080/07421222.2020.1790204
   Shum HY, 2018, FRONT INFORM TECH EL, V19, P10, DOI 10.1631/FITEE.1700826
   Turing AM., 1950, J MIND ASS, V59, P433, DOI [10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   Venkatesh A, 2018, ARXIV PREPRINT ARXIV
   Wallace RS, 2009, PARSING TURING TEST, P181, DOI DOI 10.1007/978-1-4020-6710-5_13
   Ware JE, 1998, J CLIN EPIDEMIOL, V51, P903, DOI 10.1016/S0895-4356(98)00081-X
   Weiss B., 2008, SUBJECTIVE EVALUATIO, P285
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Weston, 2018, P 2018 EMNLP WORKSH
   Yang GZ, 2020, SCI ROBOT, V5, DOI 10.1126/scirobotics.abb5589
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270
   Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI [10.1162/coli_a_00368, 10.1162/COLI_a_00368]
   Zhu N, 2020, NEW ENGL J MED, V382, P727, DOI 10.1056/NEJMoa2001017
NR 53
TC 1
Z9 1
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD JUL
PY 2022
VL 14
IS 5
BP 1273
EP 1293
DI 10.1007/s12369-022-00868-z
EA MAR 2022
PG 21
WC Robotics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Robotics
GA 3A1KO
UT WOS:000770525700001
PM 35341063
OA Green Submitted, Green Published, hybrid
DA 2022-08-02
ER

PT J
AU Seeger, AM
   Pfeiffer, J
   Heinzl, A
AF Seeger, Anna-Maria
   Pfeiffer, Jella
   Heinzl, Armin
TI Texting with Humanlike Conversational Agents: Designing for
   Anthropomorphism
SO JOURNAL OF THE ASSOCIATION FOR INFORMATION SYSTEMS
LA English
DT Article
DE Conversational Agents; Chatbots; Anthropomorphism; Interface Design
ID INDIVIDUAL-DIFFERENCES; RECOMMENDATION AGENTS; INTERACTION STYLE;
   INCREASES TRUST; SOCIAL PRESENCE; UNCANNY VALLEY; INFORMATION; MIND;
   COMMUNICATION; CUES
AB Conversational agents (CAs) are natural language user interfaces that emulate human-to-human communication. Because of this emulation, research on CAs is inseparably linked to questions about anthropomorphism-the attribution of human qualities, including consciousness, intentions, and emotions, to nonhuman agents. Past research has demonstrated that anthropomorphism affects human perception and behavior in human-computer interactions by, for example, increasing trust and connectedness or stimulating social response behaviors. Based on the psychological theory of anthropomorphism and related research on computer interface design, we develop a theoretical framework for designing anthropomorphic CAs. We identify three groups of factors that stimulate anthropomorphism: technology design-related factors, task-related factors, and individual factors. Our findings from an online experiment support the derived framework but also reveal novel yet counterintuitive insights. In particular, we demonstrate that not all combinations of anthropomorphic technology design cues increase perceived anthropomorphism. For example, we find that using only nonverbal cues harms anthropomorphism; however, this effect becomes positive when nonverbal cues are complemented with verbal or human identity cues. We also find that CAs' disposition to complete computerlike versus humanlike tasks and individuals' disposition to anthropomorphize greatly affect perceived anthropomorphism. This work advances our understanding of anthropomorphism and contextualizes the theory of anthropomorphism within the IS discipline. We advise on the directions that research and practice should take to find the sweet spot for anthropomorphic CA design.
C1 [Seeger, Anna-Maria] Univ Mannheim, Informat Syst, Mannheim, Germany.
   [Pfeiffer, Jella] Justus Liebig Univ Giessen, Giessen, Germany.
   [Heinzl, Armin] Univ Mannheim, Business Adm & Informat Syst, Mannheim, Germany.
RP Seeger, AM (corresponding author), Univ Mannheim, Informat Syst, Mannheim, Germany.
EM seeger@uni-mannheim.de; jella.pfeiffer@wirtschaft.uni-giessen.de;
   heinzl@uni-mannheim.de
FU Federal State of Baden-Wurttemberg, Germany
FX The authors are grateful to the senior editor Radhika Santhanam and the
   team of reviewers who provided constructive feedback throughout the
   entire review process. This work was partially supported by the research
   alliance ForDigital (fordigital.org), an initiative encouraged and
   funded by the Federal State of Baden-Wurttemberg, Germany.
CR Aiken L.S., 1991, MULTIPLE REGRESSION
   Al-Natour S, 2010, P 18 EUR C INFORM SY
   Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Argyle M., 1969, SOCIAL INTERACTION
   Atzmuller C, 2010, METHODOLOGY-EUR, V6, P128, DOI 10.1027/1614-2241/a000014
   AYKIN NM, 1989, COMPUT IND ENG, V17, P614, DOI 10.1016/0360-8352(89)90135-6
   Ben Mimoun MS, 2015, J RETAIL CONSUM SERV, V26, P70, DOI 10.1016/j.jretconser.2015.05.008
   Benbasat I., 2005, J ASSOC INF SYST, V6, P72, DOI [10.17705/1jais.00065, DOI 10.17705/1JAIS.00065]
   Benbasat I, 2010, P 31 INT C INFORM SY
   Benyon D., 2014, DESIGNING INTERACTIV
   Berry DC, 2005, INT J HUM-COMPUT ST, V63, P304, DOI 10.1016/j.ijhcs.2005.03.006
   BICKMORE T, 2001, P ACM C HUM FACT COM, P396
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore T, 2005, TEXT SPEECH LANG TEC, V30, P23
   Brody N, 2004, PSYCHOL INQ, V15, P234
   Brown SA, 2016, J ASSOC INF SYST, V17, P614, DOI 10.17705/1jais.00436
   Brynjolfsson E, 2016, 2 MACHINE AGE WORK P
   Burgoon JK, 1999, J MANAGE INFORM SYST, V16, P33, DOI 10.1080/07421222.1999.11518255
   Burgoon JK, 2016, INT J HUM-COMPUT ST, V91, P24, DOI 10.1016/j.ijhcs.2016.02.002
   Burleigh TJ, 2013, COMPUT HUM BEHAV, V29, P759, DOI 10.1016/j.chb.2012.11.021
   BURLING R, 1993, CURR ANTHROPOL, V34, P25, DOI 10.1086/204132
   Caruso EM, 2010, COGNITION, V116, P149, DOI 10.1016/j.cognition.2010.04.006
   Cassell J, 2000, COMMUN ACM, V43, P50, DOI 10.1145/355112.355123
   Cassell J., 2000, EMBODIED CONVERSATIO
   Cassell J., 1999, P SIGCHI C HUM FACT, P520, DOI DOI 10.1145/302979.303150
   Chattaraman V, 2019, COMPUT HUM BEHAV, V90, P315, DOI 10.1016/j.chb.2018.08.048
   CHEEK JM, 1981, J PERS SOC PSYCHOL, V41, P330, DOI 10.1037/0022-3514.41.2.330
   Chen F, 2018, J ASS CONSUM RES, V3, P503
   Chin M.G., 2005, P HUM FACT ERG SOC A, V49, P1266, DOI [10.1177/154193120504901311, DOI 10.1177/154193120504901311]
   Chin M.G., 2004, P HUM FACT ERG SOC A, V48, P1252
   Ciechanowski L, 2019, FUTURE GENER COMP SY, V92, P539, DOI 10.1016/j.future.2018.01.055
   Cohen J., 2013, APPL MULTIPLE REGRES
   Cowell AJ, 2005, INT J HUM-COMPUT ST, V62, P281, DOI 10.1016/j.ijhcs.2004.11.008
   Crossler RE, 2017, J ASSOC INF SYST, V18, P487, DOI 10.17705/1jais.00463
   Cullen H, 2014, SOC COGN AFFECT NEUR, V9, P1276, DOI 10.1093/scan/nst109
   Culley KE, 2013, COMPUT HUM BEHAV, V29, P577, DOI 10.1016/j.chb.2012.11.023
   Cyr D, 2009, MIS QUART, V33, P539
   Davis A, 2009, J ASSOC INF SYST, V10, P90, DOI 10.17705/1jais.00183
   de Visser EJ, 2016, J EXP PSYCHOL-APPL, V22, P331, DOI 10.1037/xap0000092
   de Waal FBM, 2003, ANIM COGN, V6, P293, DOI 10.1007/s10071-003-0197-4
   Dennis, 2017, PROC HAWAII INT CONF
   Derks D, 2008, CYBERPSYCHOL BEHAV, V11, P99, DOI 10.1089/cpb.2007.9926
   Derrick DC, 2011, AIS T HUMAN COMPUTER, V3, P62, DOI DOI 10.17705/1THCI.00027
   Diederich S, 2019, P 40 INT C INFORM SY
   Egan D.E., 1988, HDB HUMAN COMPUTER I, P543
   Epley N, 2008, SOC COGNITION, V26, P143, DOI 10.1521/soco.2008.26.2.143
   Epley N, 2008, PSYCHOL SCI, V19, P114, DOI 10.1111/j.1467-9280.2008.02056.x
   Epley N, 2007, PSYCHOL REV, V114, P864, DOI 10.1037/0033-295X.114.4.864
   Eyssel F, 2013, ACMIEEE INT CONF HUM, P121, DOI 10.1109/HRI.2013.6483531
   Eyssel F, 2011, ACMIEEE INT CONF HUM, P61, DOI 10.1145/1957656.1957673
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009
   FLETCHER PC, 1995, COGNITION, V57, P109, DOI 10.1016/0010-0277(95)00692-R
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Frey CB, 2017, TECHNOL FORECAST SOC, V114, P254, DOI 10.1016/j.techfore.2016.08.019
   Gefen D, 2005, COMMUN ASSOC INF SYS, V16, P91, DOI 10.17705/1CAIS.01605
   Giger JC, 2019, HUM BEHAV EMERG TECH, V1, P111, DOI 10.1002/hbe2.147
   Gnewuch U, 2018, 26 EUR C INF SYST EC
   Gnewuch U., 2017, P 38 INT C INFORM SY
   Goasduff L., 2019, CHATBOTS WILL APPEAL
   Gong L, 2008, COMPUT HUM BEHAV, V24, P1494, DOI 10.1016/j.chb.2007.05.007
   Gray HM, 2007, SCIENCE, V315, P619, DOI 10.1126/science.1134475
   Guthrie S., 2013, ENCY SCI RELIG, P111
   Guthrie S.E., 1993, FACES CLOUDS NEW THE
   HAIR JF, 1987, MULTIVARIATE DATA AN
   Hall JA, 2013, NONVERBAL COMMUNICAT
   Hauser DJ, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00998
   Hess T, 2009, J ASSOC INF SYST, V10, P889
   Holzwarth M, 2006, J MARKETING, V70, P19, DOI 10.1509/jmkg.70.4.19
   Howell JA, 2018, COMPUT HUM BEHAV, V89, P8, DOI 10.1016/j.chb.2018.07.021
   Hsu J, 2012, LIVESCIENCE
   Isbister K, 2000, INT J HUM-COMPUT ST, V53, P251, DOI 10.1006/ijhc.2000.0368
   Kiesler S, 2008, SOC COGNITION, V26, P169, DOI 10.1521/soco.2008.26.2.169
   Kim S, 2011, J CONSUM RES, V38, P94, DOI 10.1086/658148
   Knapp ML., 2014, NONVERBAL COMMUNICAT
   Knijnenburg BP, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2963106
   Kramer NC, 2018, INT J HUM-COMPUT ST, V109, P112, DOI 10.1016/j.ijhcs.2017.09.001
   Lampe C, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P435
   Lankton NK, 2015, J ASSOC INF SYST, V16, P880, DOI 10.17705/1jais.00411
   Laurel B., 1997, Human values and the design of computer technology, P207
   Lee Y, 2011, J MANAGE INFORM SYST, V28, P269, DOI 10.2753/MIS0742-1222280308
   MacDorman KF, 2009, COMPUT HUM BEHAV, V25, P695, DOI 10.1016/j.chb.2008.12.026
   Mar RA, 2011, ANNU REV PSYCHOL, V62, P103, DOI 10.1146/annurev-psych-120709-145406
   Marketsandmarkets, 2019, CONV AI MARK COMP PL
   Mathur MB, 2016, COGNITION, V146, P22, DOI 10.1016/j.cognition.2015.09.008
   McCarthy P. X, 2019, FORBES
   McKnight DH, 2002, INFORM SYST RES, V13, P334, DOI 10.1287/isre.13.3.334.81
   Mehrabian A., 1972, NONVERBAL COMMUNICAT
   Mori M, 1970, ENERGY, V7, P33, DOI DOI 10.1109/MRA.2012.2192811
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nicolaou AI, 2006, INFORM SYST RES, V17, P332, DOI 10.1287/isre.1060.0103
   Niu DF, 2018, HUM FACTOR ERGON MAN, V28, P352, DOI 10.1002/hfm.20745
   NORMAN DA, 1994, COMMUN ACM, V37, P68, DOI 10.1145/176789.176796
   Nowak KL, 2005, J COMPUT-MEDIAT COMM, V11
   Nunamaker JE, 2011, J MANAGE INFORM SYST, V28, P17, DOI 10.2753/MIS0742-1222280102
   Pak R, 2014, ERGONOMICS, V57, P1277, DOI 10.1080/00140139.2014.928750
   PARKER EB, 1978, CONTEMP SOCIOL, V7, P32, DOI 10.2307/2065899
   Pfeiffer J, 2020, BUS INFORM SYST ENG+, V62, P249, DOI 10.1007/s12599-020-00647-y
   Pfeuffer N, 2019, BUS INFORM SYST ENG+, V61, P523, DOI 10.1007/s12599-019-00599-y
   Pickard M, 2017, ELECT J
   Qiu LY, 2010, INT J HUM-COMPUT ST, V68, P669, DOI 10.1016/j.ijhcs.2010.05.005
   Qiu LY, 2009, J MANAGE INFORM SYST, V25, P145, DOI 10.2753/MIS0742-1222250405
   Reeves B., 1997, MEDIA EQUATION PEOPL
   Riedl R, 2011, P 32 INT C INFORM SY
   Riedl R, 2014, J MANAGE INFORM SYST, V30, P83, DOI 10.2753/MIS0742-1222300404
   Rilling JK, 2008, NEUROIMAGE, V41, P1447, DOI 10.1016/j.neuroimage.2008.03.044
   Robert L. P, 2017, INT ROBOTICS AUTOMAT, V3, P1
   Robert LP, 2009, J MANAGE INFORM SYST, V26, P241, DOI 10.2753/MIS0742-1222260210
   Sah YJ, 2015, COMPUT HUM BEHAV, V45, P392, DOI 10.1016/j.chb.2014.12.055
   Salovey P., 1990, IMAG COGN PERS, V9, P185, DOI [DOI 10.2190/DUGG-P24E-52WK-6CDG, 10.2190/DUGG-P24E-52WK-6CDG]
   Saygin AP, 2012, SOC COGN AFFECT NEUR, V7, P413, DOI 10.1093/scan/nsr025
   Schroeder J, 2016, J EXP PSYCHOL GEN, V145, P1427, DOI 10.1037/xge0000214
   Schuetzler R. M, 2014, P 35 INT C INFORM SY
   Schuetzler RM, 2018, DECIS SUPPORT SYST, V114, P94, DOI 10.1016/j.dss.2018.08.011
   Seyama J, 2007, PRESENCE-TELEOP VIRT, V16, P337, DOI 10.1162/pres.16.4.337
   Skjuve M., 2019, HUMAN TECHNOLOGY, V15, P30, DOI [https://doi.org/10.17011/ht/urn.201902201607, DOI 10.17011/HT/URN.201902201607]
   Smith M. A., 1998, COMMUNITIES CYBERSPA, P29, DOI DOI 10.4324/9780203194959
   Sohn S, 2019, P 40 INT C INFORM SY
   Sproull L, 1996, HUM-COMPUT INTERACT, V11, P97, DOI 10.1207/s15327051hci1102_1
   Suh KS, 2011, MIS QUART, V35, P711
   Tam KP, 2014, SOC COGNITION, V32, P276, DOI 10.1521/soco.2014.32.3.276
   Tam KP, 2013, J EXP SOC PSYCHOL, V49, P514, DOI 10.1016/j.jesp.2013.02.001
   Tanriverdi H, 2006, MIS QUART, V30, P57
   Toure-Tillery M, 2015, J MARKETING, V79, P94, DOI 10.1509/jm.12.0166
   Tremoulet PD, 2000, PERCEPTION, V29, P943, DOI 10.1068/p3101
   Trovato G, 2015, 2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P235, DOI 10.1109/ROMAN.2015.7333573
   Vance A, 2015, MIS QUART, V39, P345, DOI 10.25300/MISQ/2015/39.2.04
   Verhagen T, 2014, J COMPUT-MEDIAT COMM, V19, P529, DOI 10.1111/jcc4.12066
   von der Putten AM, 2010, COMPUT HUM BEHAV, V26, P1641, DOI 10.1016/j.chb.2010.06.012
   Wagner K, 2019, P 40 INT C INFORM SY
   Walther J. B., 1995, Journal of Organizational Computing, V5, P355
   Walther JB, 2001, SOC SCI COMPUT REV, V19, P324, DOI 10.1177/089443930101900307
   Wang WQ, 2008, J MANAGE INFORM SYST, V24, P249, DOI 10.2753/MIS0742-1222240410
   Wang WQ, 2014, J ASSOC INF SYST, V15, P454
   Wang WH, 2017, COMPUT HUM BEHAV, V68, P334, DOI 10.1016/j.chb.2016.11.022
   Waytz A, 2014, J EXP SOC PSYCHOL, V52, P113, DOI 10.1016/j.jesp.2014.01.005
   Waytz A, 2010, J PERS SOC PSYCHOL, V99, P410, DOI 10.1037/a0020240
   Waytz A, 2010, TRENDS COGN SCI, V14, P383, DOI 10.1016/j.tics.2010.05.006
   Waytz A, 2010, PERSPECT PSYCHOL SCI, V5, P219, DOI 10.1177/1745691610369336
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   WHITE RW, 1959, PSYCHOL REV, V66, P297, DOI 10.1037/h0040934
   Wiese E, 2020, INT J HUM-COMPUT ST, V133, P1, DOI 10.1016/j.ijhcs.2019.08.002
   Willard AK, 2013, COGNITION, V129, P379, DOI 10.1016/j.cognition.2013.07.016
   Wolfl S., 2019, P 25 AM C INFORM SYS
   Yuan L, 2016, P 37 INT C INFORM SY
   Zlotowski J, 2015, INT J SOC ROBOT, V7, P347, DOI 10.1007/s12369-014-0267-6
NR 146
TC 5
Z9 5
U1 33
U2 51
PU ASSOC INFORMATION SYSTEMS
PI ATLANTA
PA GEORGIA STATE UNIV, 35 BROAD STREET, STE 916-917, ATLANTA, GA 30303 USA
SN 1536-9323
EI 1558-3457
J9 J ASSOC INF SYST
JI J. Assoc. Inf. Syst.
PY 2021
VL 22
IS 4
BP 931
EP 967
DI 10.17705/1jais.00685
PG 37
WC Computer Science, Information Systems; Information Science & Library
   Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Information Science & Library Science
GA UL5TB
UT WOS:000692712600003
DA 2022-08-02
ER

PT C
AU Ureta, J
   Brito, CI
   Dy, JB
   Santos, KA
   Villaluna, W
   Ong, E
AF Ureta, Jennifer
   Brito, Celina Iris
   Dy, Jilyan Bianca
   Santos, Kyle-Althea
   Villaluna, Winfred
   Ong, Ethel
BE Sojka, P
   Kopecek, I
   Pala, K
   Horak, A
TI At Home with Alexa: A Tale of Two Conversational Agents
SO TEXT, SPEECH, AND DIALOGUE (TSD 2020)
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 23rd Annual International Conference on Text, Speech, and Dialogue (TSD)
CY SEP 08-11, 2020
CL ELECTR NETWORK
SP Masaryk Univ, Fac Informat, Univ W Bohemia Plzen, Fac Appl Sci, Lexical Comp Ltd, IBM Ceska Republika spol s r o, Amazon Alexa
DE Conversational agents; Voice interfaces; Storytelling
AB Voice assistants in mobile devices and smart speakers offer the potential of conversational agents as storytelling peers of children, especially those who may have limited proficiency in spelling and grammar. Despite their prevalence, however, the built-in automatic speech recognition features of voice interfaces have been shown to perform poorly on children's speech, which may affect child-agent interaction. In this paper, we describe our experiments in deploying a conversational storytelling agent on two popular commercial voice interfaces Google Assistant and Amazon Alexa. Through post-validation feedback from children and analysis of the captured conversation logs, we compare the challenges encountered by children when sharing their stories with these voice assistants. We also used the Bilingual Evaluation Understudy to provide a quantitative assessment of the text-to-speech transcription quality. We found that voice assistants' short waiting time and the frequent yet misplaced interruptions during pauses disrupt the thinking process of children. Furthermore, disfluencies and grammatical errors that naturally occur in children's speech affected the transcription quality.
C1 [Ureta, Jennifer; Brito, Celina Iris; Dy, Jilyan Bianca; Santos, Kyle-Althea; Villaluna, Winfred; Ong, Ethel] De La Salle Univ, Manila, Philippines.
RP Ong, E (corresponding author), De La Salle Univ, Manila, Philippines.
EM jennifer.ureta@dlsu.edu.ph; ethel.ong@dlsu.edu.ph
OI Ong, Ethel/0000-0002-4476-6820; Ureta, Jennifer/0000-0003-0427-5311
FU DOST-PCIEERD
FX Supported by DOST-PCIEERD.
CR Blythe M, 2006, BEHAV INFORM TECHNOL, V25, P127, DOI 10.1080/01449290500331131
   Cheng Y, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P337, DOI 10.1145/3202185.3202749
   Duranti A, 1992, RETHINKING CONTEXT L
   ENGEL S., 1995, STORIES CHILDREN TEL
   Harwell D., 2018, ACCENT GAP AMAZONS G
   Hone K. S., 2000, Natural Language Engineering, P287
   Kennedy J, 2017, ACMIEEE INT CONF HUM, P82, DOI 10.1145/2909824.3020229
   Keren G, 2014, COMPUT HUM BEHAV, V35, P400, DOI 10.1016/j.chb.2014.03.009
   Lovato Silvia, 2015, P 14 INT C INT DES C, P335, DOI [10.1145/2771839.2771910, DOI 10.1145/2771839.2771910]
   Lovato SB, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P301, DOI 10.1145/3311927.3323150
   Maier A., 2011, ACM T SPEECH LANG PR, V7, P15
   Meinedo H., 2011, ACM T SPEECH LANG PR, V7, P16
   Most T, 2002, LANG SPEECH HEAR SER, V33, P112, DOI 10.1044/0161-1461(2002/009)
   Ong Ethel, 2019, 2019 22 C OR COCOSDA, P1
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   PECK J, 1989, READ TEACH, V43, P138
   Potamianos A, 2009, P 2 WORKSH CHILD COM, DOI DOI 10.1145/1640377.1640384
   Pyae A, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P548, DOI 10.1145/3292147.3292236
   Sun M, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P205, DOI 10.1145/3078072.3079714
   Tamura Y, 2017, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON HUMAN AGENT INTERACTION (HAI'17), P35, DOI 10.1145/3125739.3125750
   Ong DT, 2018, 26TH INTERNATIONAL CONFERENCE ON COMPUTERS IN EDUCATION (ICCE 2018), P205
   Ward W, 2013, J EDUC PSYCHOL, V105, P1115, DOI 10.1037/a0031589
NR 22
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-58323-1; 978-3-030-58322-4
J9 LECT NOTES ARTIF INT
PY 2020
VL 12284
BP 495
EP 503
DI 10.1007/978-3-030-58323-1_53
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Linguistics
GA BQ6GA
UT WOS:000611543200053
DA 2022-08-02
ER

PT J
AU Schachner, T
   Keller, R
   Wangenheim, FV
AF Schachner, Theresa
   Keller, Roman
   Wangenheim, Florian, V
TI Artificial Intelligence-Based Conversational Agents for Chronic
   Conditions: Systematic Literature Review
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Review
DE artificial intelligence; conversational agents; chatbots; healthcare;
   chronic diseases; systematic literature review
ID EXPERT-SYSTEM; CHILDREN; TECHNOLOGY; DIAGNOSIS; ELIZA; CARE
AB Background: A rising number of conversational agents or chatbots are equipped with artificial intelligence (AI) architecture. They are increasingly prevalent in health care applications such as those providing education and support to patients with chronic diseases, one of the leading causes of death in the 21st century. AI-based chatbots enable more effective and frequent interactions with such patients.
   Objective: The goal of this systematic literature review is to review the characteristics, health care conditions, and AI architectures of AI-based conversational agents designed specifically for chronic diseases.
   Methods: We conducted a systematic literature review using PubMed MEDLINE, EMBASE, PyscInfo, CINAHL, ACM Digital Library, ScienceDirect, and Web of Science. We applied a predefined search strategy using the terms "conversational agent," "healthcare," "artificial intelligence," and their synonyms. We updated the search results using Google alerts, and screened reference lists for other relevant articles. We included primary research studies that involved the prevention, treatment, or rehabilitation of chronic diseases, involved a conversational agent, and included any kind of AI architecture. Two independent reviewers conducted screening and data extraction, and Cohen kappa was used to measure interrater agreement.A narrative approach was applied for data synthesis.
   Results: The literature search found 2052 articles, out of which 10 papers met the inclusion criteria. The small number of identified studies together with the prevalence of quasi-experimental studies (n=7) and prevailing prototype nature of the chatbots (n=7) revealed the immaturity of the field. The reported chatbots addressed a broad variety of chronic diseases (n=6), showcasing a tendency to develop specialized conversational agents for individual chronic conditions. However, there lacks comparison of these chatbots within and between chronic diseases. In addition, the reported evaluation measures were not standardized, and the addressed health goals showed a large range. Together, these study characteristics complicated comparability and open room for future research. While natural language processing represented the most used AI technique (n=7) and the majority of conversational agents allowed for multimodal interaction (n=6), the identified studies demonstrated broad heterogeneity, lack of depth of reported AI techniques and systems, and inconsistent usage of taxonomy of the underlying AI software, further aggravating comparability and generalizability of study results.
   Conclusions: The literature on AI-based conversational agents for chronic conditions is scarce and mostly consists of quasi-experimental studies with chatbots in prototype stage that use natural language processing and allow for multimodal user interaction. Future research could profit from evidence-based evaluation of the AI-based conversational agents and comparison thereof within and between different chronic health conditions. Besides increased comparability, the quality of chatbots developed for specific chronic conditions and their subsequent impact on the target patients could be enhanced by more structured development and standardized evaluation processes.
C1 [Schachner, Theresa; Keller, Roman; Wangenheim, Florian, V] Swiss Fed Inst Technol, Dept Management Technol & Econ, WEV G 228,Weinbergstr 56-58, Zurich, Switzerland.
   [Keller, Roman; Wangenheim, Florian, V] Singapore ETH Ctr, Future Hlth Technol Programme, Campus Res Excellence & Technol Enterprise, Singapore, Singapore.
RP Schachner, T (corresponding author), Swiss Fed Inst Technol, Dept Management Technol & Econ, WEV G 228,Weinbergstr 56-58, Zurich, Switzerland.
EM tschachner@ethz.ch
OI Schachner, Theresa/0000-0002-5505-8811; Keller,
   Roman/0000-0003-4810-4944
FU National Research Foundation, Prime Minister's Office, Singapore, under
   its Campus for Research Excellence and Technological Enterprise program
FX We are grateful to Mr Julian Ventouris for his assistance with the study
   search process and Ms Grace Xiao for proofreading the document. This
   study is supported by the National Research Foundation, Prime Minister's
   Office, Singapore, under its Campus for Research Excellence and
   Technological Enterprise program.
CR Agarwal S, 2016, BMJ-BRIT MED J, V352, DOI 10.1136/bmj.i1174
   Amrita, 2013, Med 2 0, V2, pe4, DOI 10.2196/med20.2720
   Arkoudas K, 2014, CAMBRIDGE HANDBOOK OF ARTIFICIAL INTELLIGENCE, P34
   Bickmore TW, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P119, DOI 10.1145/3267851.3267908
   Bickmore TW, 2018, J MED INTERNET RES, V20, DOI 10.2196/11510
   Bodenheimer T, 2002, JAMA-J AM MED ASSOC, V288, P2469, DOI 10.1001/jama.288.19.2469
   Bostrom N, 2014, CAMBRIDGE HANDBOOK OF ARTIFICIAL INTELLIGENCE, P316
   Chaix B, 2019, JMIR CANCER, V5, DOI 10.2196/12856
   Colby KM, 1976, ARTIFICIAL PARANOIA
   Crutzen R, 2011, J ADOLESCENT HEALTH, V48, P514, DOI 10.1016/j.jadohealth.2010.09.002
   Cui L, SUPERAGENT CUSTOMER
   Davenport T, 2020, J ACAD MARKET SCI, V48, P24, DOI 10.1007/s11747-019-00696-0
   Davenport Thomas, 2019, Future Healthc J, V6, P94, DOI 10.7861/futurehosp.6-2-94
   De Bruyn A, 2020, J INTERACT MARK, V51, P91, DOI 10.1016/j.intmar.2020.04.007
   Denecke K, 2018, METHOD INFORM MED, V57, P243, DOI 10.1055/s-0038-1675822
   Des Jarlais DC, 2004, AM J PUBLIC HEALTH, V94, P361, DOI 10.2105/AJPH.94.3.361
   Easton K, 2019, J MED INTERNET RES, V21, DOI 10.2196/12996
   Epstein J, 2001, COMPUT HUM BEHAV, V17, P295, DOI 10.1016/S0747-5632(01)00004-8
   Eysenbach G, 2011, J MED INTERNET RES, V13, DOI 10.2196/jmir.1923
   Fadhil A., 2018, CONVERSATIONAL INTER
   Fadhil A., 2018, PATIENT MONITORING C
   Fadhil A, 2019, METHOD INFORM MED, V58, P9, DOI 10.1055/s-0039-1688757
   Faraj S, 2018, INFORM ORGAN-UK, V28, P62, DOI 10.1016/j.infoandorg.2018.02.005
   Ferguson G, 2010, J BIOMED INFORM, V43, pS13, DOI 10.1016/j.jbi.2010.05.014
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Fulmer R, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/mental.9782
   Gentsch P., 2019, AI MARKETING SALE SE, P11
   Griol D, 2016, COGN COMPUT, V8, P336, DOI 10.1007/s12559-015-9352-x
   Handelman GS, 2019, AM J ROENTGENOL, V212, P38, DOI 10.2214/AJR.18.20224
   Harris AD, 2006, J AM MED INFORM ASSN, V13, P16, DOI 10.1197/jamia.M1749
   Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5
   Hvidberg MF, 2016, SCAND J PUBLIC HEALT, V44, P462, DOI 10.1177/1403494816641553
   Ireland D, 2016, STUD HEALTH TECHNOL, V227, P55, DOI 10.3233/978-1-61499-666-8-55
   Ivanov S., 2017, INT SCI C CONT TOURI, P19
   Kaplan A, 2019, BUS HORIZONS, V62, P15, DOI 10.1016/j.bushor.2018.08.004
   Klok T, 2015, PEDIAT ALLERG IMM-UK, V26, P197, DOI 10.1111/pai.12362
   Kocaballi AB, 2019, J MED INTERNET RES, V21
   Kvedar JC, 2016, NAT BIOTECHNOL, V34, P239, DOI 10.1038/nbt.3495
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lenferink A, 2017, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD011682.pub2
   LEVY M, 1989, COMPUT BIOMED RES, V22, P442, DOI 10.1016/0010-4809(89)90037-2
   Maher CA, 2014, J MED INTERNET RES, V16, DOI 10.2196/jmir.2952
   Martinez-Miranda J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1387-1
   Masche J, 2018, ADV INTELL SYST, V629, P212, DOI 10.1007/978-3-319-61911-8_19
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   McTear MF, 2002, ACM COMPUT SURV, V34, P90, DOI 10.1145/505282.505285
   Moher D, 2009, BMJ-BRIT MED J, V339, DOI [10.1136/bmj.i4086, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.b2535]
   Mongan J, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200029
   Oh KJ, 2017, IEEE INT CONF MOB DA, P371, DOI 10.1109/MDM.2017.64
   OVERBY MA, 1987, COMPUT BIOL MED, V17, P383, DOI 10.1016/0010-4825(87)90056-4
   Paez KA, 2009, HEALTH AFFAIR, V28, P15, DOI 10.1377/hlthaff.28.1.15
   Park SH, 2018, RADIOLOGY, V286, P800, DOI 10.1148/radiol.2017171920
   Pereira J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1237-1
   Perski O, 2019, DIGIT HEALTH, V5, DOI 10.1177/2055207619880676
   Radziwill N.M., 2017, ARXIV170404579
   Rehman S, 2020, ANN ABBASI SHAHEED H, V25, P10
   Rhee H, 2014, PATIENT PREFER ADHER, V8, P63, DOI 10.2147/PPA.S53504
   Roca S, 2020, J BIOMED INFORM, V102, DOI 10.1016/j.jbi.2019.103305
   Rose-Davis B, 2019, STUD HEALTH TECHNOL, V264, P1337, DOI 10.3233/SHTI190444
   Russell S, 1995, ARTIF INTELL, DOI [10.1016/0925-2312(95)90020-9, DOI 10.1016/0925-2312(95)90020-9]
   Saygin AP, 2000, MIND MACH, V10, P463
   Schulz KF, 2010, J CLIN EPIDEMIOL, V63, P834, DOI [10.4103/0976-500X.72352, 10.1016/j.jclinepi.2010.02.005, 10.1016/j.ijsu.2011.09.004, 10.1186/1741-7015-8-18]
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038
   Shrestha YR, 2019, CALIF MANAGE REV, V61, P66, DOI 10.1177/0008125619862257
   STEIN REK, 1993, J PEDIATR-US, V122, P342, DOI 10.1016/S0022-3476(05)83414-6
   Suta P., 2020, INT J MECH ENG ROBOT, V9, P502, DOI [10.18178/ijmerr.9.4.502-510, DOI 10.18178/IJMERR.9.4.502-510]
   Tsai CF, 2008, EXPERT SYST APPL, V34, P2639, DOI 10.1016/j.eswa.2007.05.019
   Tullis T., 2013, MEASURING USER EXPER
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   von Krogh G, 2018, ACAD MANAG DISCOV, V4, P404, DOI 10.5465/amd.2018.0084
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Yach D, 2004, JAMA-J AM MED ASSOC, V291, P2616, DOI 10.1001/jama.291.21.2616
   Zeni Montenegro Joao Luis, 2018, 2018 5th International Conference on Computational Science and Computational Intelligence (CSCI), P756, DOI 10.1109/CSCI46756.2018.00151
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
NR 74
TC 23
Z9 23
U1 10
U2 37
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD SEP 14
PY 2020
VL 22
IS 9
AR e20701
DI 10.2196/20701
PG 16
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA PF6DS
UT WOS:000599143100001
PM 32924957
OA gold, Green Published
DA 2022-08-02
ER

PT J
AU Rosenfeld, A
   Haimovich, N
AF Rosenfeld, Ariel
   Haimovich, Nitzan
TI Designing rule-based conversational agents with behavioral programming:
   a study of human subjects
SO EUROMED JOURNAL OF BUSINESS
LA English
DT Article; Early Access
DE Behavioral programming; Conversational agents; Human study
AB Purpose In this work, the authors propose to harness the advantages of behavioral programming as a new technique for designing rule-based conversational agents. Design/methodology/approach To examine the study's hypotheses, the authors perform a first-of-its-kind user study through which the authors examine how potential designers, both expert designers, computationally-oriented designers, and otherwise, leverage behavioral programming (BP) and dialog graphs for designing conversational agents (CAs). The authors also use two standard CA settings common in the literature: designing a CA representative for a user in an online dating service and a non-character player in a role-playing game (RPG). Findings The study's results indicate that BP can be successfully utilized by computationally-oriented designers, with or without prior knowledge in CA design, and can facilitate the design of better CAs (i.e. more accurate and more robust). However, to capitalize on these potential advantages, designers may be required to devote more time to the design process and are likely to encounter higher temporal demand levels. These results suggest that BP, which was initially proposed and evaluated in the general context of software design, can constitute a valuable alternative to the classic rule-based CA design technique commonly practiced today. Research limitations/implications An important limitation of this study is the relatively small participant pool. While the authors do plan to extend this study in the future, the current coronavirus disease 2019 (COVID-19) situation makes it ever more complex to conduct formal user studies of this kind. It is, however, important to note that despite the low number of participants, many of the results are found to be statistically significant. Practical implications The authors plan to continue this line of work and conduct human studies for additional design techniques in other popular agent-based settings. Specifically, the authors seek to explore how people of different backgrounds should design agents for various tasks such as automated negotiation (e.g. how should a person design a representative agent to negotiate on her behalf?) and social choice (e.g. how should a person design a voting bot to represent her in online voting systems?). Originality/value People are increasingly interacting with conversational agents in various settings and for a variety of reasons, as the market size of those agents keeps on growing every year. Through a first-of-its-kind human study (N = 41), consisting of both expert designers, computationally-oriented designers, and otherwise, the authors demonstrate a few key advantages and limitations of BP in the realm of conversational agents and propose its consideration as an alternative to the classic dialog graph technique.
C1 [Rosenfeld, Ariel; Haimovich, Nitzan] Bar Ilan Univ, Ramat Gan, Israel.
RP Rosenfeld, A (corresponding author), Bar Ilan Univ, Ramat Gan, Israel.
EM ariel.rosenfeld@biu.ac.il
OI Rosenfeld, Ariel/0000-0002-3230-3060; Haimovich,
   Nitzan/0000-0002-6111-2423
CR Abdul-Kader SA, 2015, INT J ADV COMPUT SC, V6, P72
   Adiwardana D., 2020, HUMAN LIKE OPENDOMAI, DOI DOI 10.3390/healthcare7020056
   Alexandron G., 2012, P 12 KOL CALL INT C, P151, DOI [10.1145/2401796.2401821, DOI 10.1145/2401796.2401821]
   Alexandron G, 2014, 36TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE COMPANION 2014), P311, DOI 10.1145/2591062.2591167
   Azaria A, 2020, AUTON AGENT MULTI-AG, V34, DOI 10.1007/s10458-019-09425-x
   Banchs R. E., 2012, P ACL 2012 SYST DEM, P37
   Billard A., 2008, SPRINGER HDB ROBOTIC, P1371, DOI DOI 10.1007/978-3-540-30301-5_60
   CLANCEY WJ, 1983, ARTIF INTELL, V20, P215, DOI 10.1016/0004-3702(83)90008-5
   COLBY KM, 1971, ARTIF INTELL, V2, P1, DOI 10.1016/0004-3702(71)90002-6
   Damm W, 2001, FORM METHOD SYST DES, V19, P45, DOI 10.1023/A:1011227529550
   Dawe M., 2019, BEHAV SELECTION ALGO, P47
   Elyasaf A, 2021, INFORM SOFTWARE TECH, V133, DOI 10.1016/j.infsof.2020.106504
   Ferrucci DA, 2012, IBM J RES DEV, V56, DOI 10.1147/JRD.2012.2184356
   Fraser J, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P179, DOI 10.1145/3267851.3267896
   Gnewuch U., 2017, P 38 INT C INFORM SY
   Harel D., 2011, REV RES BEHAV PROGRA
   Harel D., 2014, P 4 SPLASH WORKSH PR P 4 SPLASH WORKSH PR, P95
   Harel D, 2012, COMMUN ACM, V55, P90, DOI 10.1145/2209249.2209270
   Harel D, 2010, LECT NOTES COMPUT SC, V6183, P250, DOI 10.1007/978-3-642-14107-2_12
   Harel David., 2003, COME LETS PLAY SCENA, V1
   HART S G, 1988, P139
   Hongshen Chen, 2017, ACM SIGKDD Explorations Newsletter, V19, P25, DOI 10.1145/3166054.3166058
   Hussain Shafquat, 2019, Web, Artificial Intelligence and Network Applications. Proceedings of the Workshops of the 33rd International Conference on Advanced Information Networking and Applications (WAINA-2019). Advances in Intelligent Systems and Computing (927), P946, DOI 10.1007/978-3-030-15035-8_93
   Kaghyan S., 2018, SOC IMAGING SCI TECH, V2018, P1, DOI 10.2352/ISSN.2470-1173.2018.06.MOBMU-117
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Luo XM, 2019, MARKET SCI, V38, P937, DOI 10.1287/mksc.2019.1192
   Masche J, 2018, ADV INTELL SYST, V629, P212, DOI 10.1007/978-3-319-61911-8_19
   Ramesh K, 2017, COMM COM INF SC, V750, P336, DOI 10.1007/978-981-10-6544-6_31
   Roller S., 2020, RECIPES BUILDING OPE
   Rosenfeld A, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3823
   Shimony B., 2011, P 2 WORKSH SOFTW ENG, P19
   Wallis P., 2010, P ACL WORKSH COMP DI, P25
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wiener G, 2010, ERLANG 2010: PROCEEDINGS OF THE 2010 ACM SIGPLAN, ERLANG WORKSHOP, P13
   Yan R, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P55, DOI 10.1145/2911451.2911542
   Yan Z, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4618
   Yan Z, 2018, KNOWL-BASED SYST, V142, P149, DOI 10.1016/j.knosys.2017.11.033
   ZUE V, 1994, SPEECH COMMUN, V15, P331, DOI 10.1016/0167-6393(94)90083-3
NR 39
TC 0
Z9 0
U1 0
U2 0
PU EMERALD GROUP PUBLISHING LTD
PI BINGLEY
PA HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN 1450-2194
EI 1758-888X
J9 EUROMED J BUS
JI EuroMed J. Bus.
DI 10.1108/EMJB-09-2021-0144
EA FEB 2022
PG 14
WC Business
WE Emerging Sources Citation Index (ESCI)
SC Business & Economics
GA YT7CY
UT WOS:000751514400001
DA 2022-08-02
ER

PT J
AU Stieglitz, S
   Hofeditz, L
   Brunker, F
   Ehnis, C
   Mirbabaie, M
   Ross, B
AF Stieglitz, Stefan
   Hofeditz, Lennart
   Bruenker, Felix
   Ehnis, Christian
   Mirbabaie, Milad
   Ross, Bjorn
TI Design principles for conversational agents to support Emergency
   Management Agencies
SO INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
LA English
DT Article
DE Conversational agents; Chatbots; Design principles; Crisis communication
ID SOCIAL MEDIA; DISASTER MANAGEMENT; INFORMATION; CRISIS; CHALLENGES;
   AGREEMENT; CHATBOT; QUALITY; NEWS
AB Widespread mis- and disinformation during the COVID-19 social media "infodemic" challenge the effective response of Emergency Management Agencies (EMAs). Conversational Agents (CAs) have the potential to amplify and distribute trustworthy information from EMAs to the general public in times of uncertainty. However, the structure and responsibilities of such EMAs are different in comparison to traditional commercial organizations. Consequently, Information Systems (IS) design approaches for CAs are not directly transferable to this different type of organization. Based on semi-structured interviews with practitioners from EMAs in Germany and Australia, twelve meta-requirements and five design principles for CAs for EMAs were developed. In contrast to the traditional view of CA design, social cues should be minimized. The study provides a basis to design robust CAs for EMAs.
C1 [Stieglitz, Stefan; Hofeditz, Lennart; Bruenker, Felix] Univ Duisburg Essen, Fac Engn, Dept Comp Sci & Appl Cognit Sci, Digital Commun & Transformat, Forsthausweg 2, D-47057 Duisburg, Germany.
   [Ehnis, Christian] Univ Sydney, Business Sch, Rm 4053,Level 4,Abercrombie Bldg H70, Sydney, NSW 2006, Australia.
   [Mirbabaie, Milad] Paderborn Univ, Warburger Str 100,Q3-128, D-33098 Paderborn, Germany.
   [Ross, Bjorn] Univ Edinburgh, Informat Forum, 10 Crichton St, Edinburgh EH8 9AB, Midlothian, Scotland.
RP Stieglitz, S (corresponding author), Univ Duisburg Essen, Fac Engn, Dept Comp Sci & Appl Cognit Sci, Digital Commun & Transformat, Forsthausweg 2, D-47057 Duisburg, Germany.
EM stefan.stieglitz@uni-due.de; Lennart.hofeditz@uni-due.de;
   felix.bruenker@uni-due.de; christian.ehnis@sydney.edu.au;
   milad.mirbabaie@uai-paderborn.de; b.ross@ed.ac.uk
OI Hofeditz, Lennart/0000-0002-5552-9599
FU European Union [823866]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   project has received funding from the European Union's Horizon 2020
   research and innovation programme under the Marie Sklodowska-Curie grant
   agreement No 823866.
CR Abedin B, 2018, INFORM SYST FRONT, V20, P729, DOI 10.1007/s10796-017-9789-4
   Ahmady SE, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2020), P177, DOI 10.1109/ICCCS49078.2020.9118510
   Aladwani AM, 2018, INT J INFORM MANAGE, V43, P261, DOI 10.1016/j.ijinfomgt.2018.08.009
   Altay N, 2014, PROD OPER MANAG, V23, P1015, DOI 10.1111/poms.12102
   Altay N, 2014, DISASTERS, V38, pS50, DOI 10.1111/disa.12052
   Balakrishnan J, 2021, ANN OPER RES, DOI 10.1007/s10479-021-04049-5
   Balakrishnan J, 2021, PSYCHOL MARKET, V38, P643, DOI 10.1002/mar.21462
   Beydoun G, 2018, INFORM SYST FRONT, V20, P649, DOI 10.1007/s10796-018-9871-6
   Brachten F, 2021, INT J INFORM MANAGE, V60, DOI 10.1016/j.ijinfomgt.2021.102375
   Brachten F, 2020, INF SYST E-BUS MANAG, V18, P187, DOI 10.1007/s10257-020-00471-7
   Braun V, 2021, QUAL RES SPORT EXERC, V13, P201, DOI 10.1080/2159676X.2019.1704846
   Bunker D, 2015, INFORM SYST FRONT, V17, P51, DOI 10.1007/s10796-014-9515-4
   Cassell J, 1999, APPL ARTIF INTELL, V13, P519, DOI 10.1080/088395199117360
   Chandra L, 2015, P ANN HICSS, P4039, DOI 10.1109/HICSS.2015.485
   Clarke R, 2020, J ASSOC INF SYST, V21, P483, DOI 10.17705/1jais.00609
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Demetis DS, 2018, J ASSOC INF SYST, V19, P929, DOI 10.17705/1jais.00514
   Denecke K, 2021, IEEE T EMERG TOP COM, V9, P1170, DOI 10.1109/TETC.2020.2974478
   Denzin N., 2009, RES ACT THEORETICAL, DOI [10.4324/9781315134543, DOI 10.4324/9781315134543]
   Diederich S, 2019, EUROPEAN C INFORM SY
   Diederich S, 2020, BUS INFORM SYST ENG+, V62, P193, DOI 10.1007/s12599-020-00639-y
   Duan YQ, 2019, INT J INFORM MANAGE, V48, P63, DOI 10.1016/j.ijinfomgt.2019.01.021
   Dubey R, 2021, INT J PROD RES, V59, P1586, DOI 10.1080/00207543.2020.1865583
   Dwivedi YK, 2020, INT J INFORM MANAGE, V55, DOI 10.1016/j.ijinfomgt.2020.102211
   Dwivedi YK, 2021, INT J INFORM MANAGE, V57, DOI 10.1016/j.ijinfomgt.2019.08.002
   Ehnis C, 2020, BEHAV INFORM TECHNOL, V39, P343, DOI 10.1080/0144929X.2019.1621934
   Elbanna A, 2019, INT J INFORM MANAGE, V47, P112, DOI 10.1016/j.ijinfomgt.2019.01.011
   Fan C, 2021, INT J INFORM MANAGE, V56, DOI 10.1016/j.ijinfomgt.2019.102049
   Feine J, 2020, P 15 INT C DESIGN SC
   Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009
   Fischer-Pressler D, 2019, COMPUT HUM BEHAV, V100, P138, DOI 10.1016/j.chb.2019.05.012
   Flick U., 2004, COMPANION QUAL RES, P178
   Gerstmann S, 2019, P 16 INT C INFORM SY
   Gnewuch U., 2017, P 38 INT C INFORM SY
   Goldkuhl G, 2012, EUR J INFORM SYST, V21, P135, DOI 10.1057/ejis.2011.54
   Graesser AC, 2014, CURR DIR PSYCHOL SCI, V23, P374, DOI 10.1177/0963721414540680
   Griol D, 2012, ADV INTEL SOFT COMPU, V153, P93
   Gupta S, 2020, PROD OPER MANAG, V29, P1789, DOI 10.1111/poms.13192
   Gupta S, 2016, PROD OPER MANAG, V25, P1611, DOI 10.1111/poms.12591
   Hofeditz L, 2019, P 27 EUROPEAN C INFO, P17
   Holderness T, 2016, SOCIAL MEDIA GOVT SE, DOI DOI 10.1007/978-3-319-27237-5_6
   Imran M, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1638
   Kamboj S, 2018, INT J INFORM MANAGE, V39, P169, DOI 10.1016/j.ijinfomgt.2017.12.001
   Kim B, 2020, DECIS SUPPORT SYST, V134, DOI 10.1016/j.dss.2020.113302
   King KK, INT J INF MANAGE, V2021, DOI [10.1016/j.ijinfomgt.2021.102390, DOI 10.1016/J.IJINFOMGT.2021.102390]
   Konicek J, 2020, DATA, V5, DOI 10.3390/data5030076
   Kwayu S, 2021, INT J INFORM MANAGE, V58, DOI 10.1016/j.ijinfomgt.2020.102280
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Laumer S, 2019, P 2019 AMERICAS C IN
   Lechler R, 2019, P 27 EUROPEAN C INFO, P18
   Lee AS, 2012, MIS QUART, V36, P749
   Lembcke T.-B., 2020, 28 EUROPEAN C INFORM
   Maniou TA, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12070109
   Mayring P, 2015, ADVNCS MTHMTCS EDUC, P365, DOI 10.1007/978-94-017-9181-6_13
   McTear M., 2016, CONVERSATIONAL INTER, P125, DOI [10.1007/978-3-319-32967-3, DOI 10.1007/978-3-319-32967-3]
   Meier P, 2020, P 40 INT C INFORM SY
   Mingers J, 2018, J INF TECHNOL-UK, V33, P85, DOI 10.1057/s41265-017-0038-6
   Mirbabaie M, 2021, DYNAMICS CONVERGENCE
   Mirbabaie M, 2021, BUS INFORM SYST ENG+, V63, P21, DOI 10.1007/s12599-020-00672-x
   Mirbabaie M, 2020, J INF TECHNOL-UK, V35, P195, DOI 10.1177/0268396220929258
   Misiura Joanna, 2019, CHATBOTS HUMANITARIA
   MOLICH R, 1990, COMMUN ACM, V33, P338, DOI 10.1145/77481.77486
   Morgan G., 1980, ACAD MANAGE REV, V5, P491, DOI DOI 10.2307/257453
   Myers M. D, 2007, INFORM ORGAN-UK, V25
   Nabity-Grover T, 2020, INT J INFORM MANAGE, V55, DOI 10.1016/j.ijinfomgt.2020.102188
   Nass C, 1997, J APPL SOC PSYCHOL, V27, P864, DOI 10.1111/j.1559-1816.1997.tb00275.x
   Nishant R, 2020, INT J INFORM MANAGE, V53, DOI 10.1016/j.ijinfomgt.2020.102104
   Norman K. L, 2018, WILEY HDB HUMAN COMP, V1
   Oh O, 2015, INFORM SYST RES, V26, P210, DOI 10.1287/isre.2015.0565
   Patton MQ, 1999, HEALTH SERV RES, V34, P1189
   Power R, 2017, PROCEEDINGS OF THE 50TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P313
   Radziwill N, 2017, ARXIV, V21
   Salem M, 2019, PROD OPER MANAG, V28, P2877, DOI 10.1111/poms.13085
   Shaheen I, 2020, PROD OPER MANAG, V29, P2828, DOI 10.1111/poms.13254
   Shareef MA, 2020, ANN OPER RES, DOI 10.1007/s10479-020-03708-3
   Shareef' MA, 2019, ANN OPER RES, V283, P1463, DOI 10.1007/s10479-018-3081-y
   Shodhi M.S., 2021, DEV DISASTER RECOVER, DOI [10.1111/poms.13489, DOI 10.1111/POMS.13489]
   Sodhi MS, 2016, J OPER MANAG, V45, P101, DOI 10.1016/j.jom.2016.05.010
   Sodhi MS, 2014, PROD OPER MANAG, V23, P938, DOI 10.1111/poms.12111
   Stieglitz S, 2019, INTERNET RES, V29, P921, DOI 10.1108/INTR-05-2018-0197
   Stieglitz S, 2018, INT J INFORM MANAGE, V39, P156, DOI 10.1016/j.ijinfomgt.2017.12.002
   Strohmann T, 2019, P 52 HAWAII INT C SY, V11, P54, DOI [10.24251/hicss.2019.580, DOI 10.24251/HICSS.2019.580]
   STRUTZEL E, 1968, NURS RES, V17, P364
   Suddaby R, 2006, ACAD MANAGE J, V49, P633, DOI 10.5465/AMJ.2006.22083020
   Tavanapour N, 2019, P EUROPEAN C INFORM
   Tim Y, 2017, INFORM SYST J, V27, P197, DOI 10.1111/isj.12114
   Tsai MH, 2019, WATER-SUI, V11, DOI 10.3390/w11020234
   Wenger C, 2017, ECOL SOC, V22, DOI 10.5751/ES-09491-220318
   Yuan FX, 2021, INT J INFORM MANAGE, V57, DOI 10.1016/j.ijinfomgt.2020.102289
   Zarocostas J, 2020, LANCET, V395, P676, DOI 10.1016/S0140-6736(20)30461-X
   Zhang C, 2019, INT J INFORM MANAGE, V49, P190, DOI 10.1016/j.ijinfomgt.2019.04.004
NR 91
TC 2
Z9 2
U1 25
U2 27
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0268-4012
EI 1873-4707
J9 INT J INFORM MANAGE
JI Int. J. Inf. Manage.
PD APR
PY 2022
VL 63
AR 102469
DI 10.1016/j.ijinfomgt.2021.102469
PG 11
WC Information Science & Library Science
WE Social Science Citation Index (SSCI)
SC Information Science & Library Science
GA 1D8HB
UT WOS:000794036000005
PM 35043026
OA Green Published, hybrid
DA 2022-08-02
ER

PT J
AU Wik, P
   Hjalmarsson, A
AF Wik, Preben
   Hjalmarsson, Anna
TI Embodied conversational agents in computer assisted language learning
SO SPEECH COMMUNICATION
LA English
DT Article
DE Second langue learning; Dialogue systems; Embodied conversational
   agents; Pronunciation training; CALL; CAPT
AB This paper describes two systems using embodied conversational agents (ECAs) for language learning. The first system, called Ville, is a virtual language teacher for vocabulary and pronunciation training. The second system, a dialogue system called DEAL, is a role-playing game for practicing conversational skills. Whereas DEAL acts as a conversational partner with the objective of creating and keeping an interesting dialogue, Ville takes the role of a teacher who guides, encourages and gives feedback to the students. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Wik, Preben; Hjalmarsson, Anna] KTH, Ctr Speech Technol, SE-10044 Stockholm, Sweden.
RP Wik, P (corresponding author), KTH, Ctr Speech Technol, Lindstedtsvagen 24, SE-10044 Stockholm, Sweden.
EM preben@speech.kth.se; annah@speech.kth.se
CR AIST G, 2006, P INT PITTSB PA US, P1922
   Bannert R., 2004, VAG MOT SVENSKT UTTA
   BESKOW J, 2003, THESIS KTH STOCKHOLM
   Bosseler A, 2003, J AUTISM DEV DISORD, V33, P653, DOI 10.1023/B:JADD.0000006002.82367.4f
   Brennan S. E., 2000, P 38 ANN M ASS COMP
   BRUSK J, 2007, P ACM FUT PLAY TOR C, P137
   BURNHAM D, 1999, AVSP, P80
   CARLSON R, 2002, P FON STOCKH SWED MA, P65
   Ellis R., 1994, UNDERSTANDING 2 LANG
   Engwall Olov, 2007, Computer Assisted Language Learning, V20, P235, DOI 10.1080/09588220701489507
   ENGWALL O, 2004, P 8 INT C SPOK LANG, P1693
   ENGWALL O, 2008, P INT 2008 BRISB AUS, P2631
   Eskenazi M., 1999, LANG LEARN TECHNOL, V2, P62
   Flege James E., 1998, STILL SPEECH TECHNOL, P1
   Gee JP, 2003, WHAT VIDEO GAMES HAVE TO TEACH US ABOUT LEARNING AND LITERACY, P1
   GRANSTROM B, 1999, P INT C PHON SCI ICP, P655
   GUSTAFSON J, 2004, P SIGDIAL
   Hjalmarsson A., 2008, P SIGDIAL 2008 COL O
   Hjalmarsson A., 2007, P SIGDIAL ANTW BELG, P132
   IUPPA N, 2007, STORY SIMULATIONS SE
   Johnson W. L., 2004, P I ITSEC
   KODA T, 1996, P HCI, P98
   Lester J. C., 1997, Proceedings of the First International Conference on Autonomous Agents, P16, DOI 10.1145/267658.269943
   Massaro DW, 2004, J SPEECH LANG HEAR R, V47, P304, DOI 10.1044/1092-4388(2004/025)
   Mateas M., 2003, FACADE EXPT BUILDING
   MCALLISTER R, 1997, 2 LANGUAGE SPEECH
   Meng H, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, VOLS 1 AND 2, P437
   Neri A., 2002, Computer Assisted Language Learning, V15, P441, DOI 10.1076/call.15.5.441.13473
   Neri A., 2002, P INT C SPOK LANG PR, P1209
   Prensky M., 2002, HORIZON, V10, P5, DOI DOI 10.1108/10748120210431349
   Prensky M., 2001, DIGITAL GAME BASED L
   Sjolander K., 2003, P FON 2003 UM U DEP, P93
   Skantze Gabriel, 2005, SIGDIAL WORKSH DISC, P178
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   van Mulken S, 1998, PEOPLE AND COMPUTER XIII, PROCEEDINGS, P53
   von Ahn L, 2006, COMPUTER, V39, P92, DOI 10.1109/MC.2006.196
   WALKER JH, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P85
   WIK P, 2007, P SLATE 2007
   Wik P., 2004, P 17 SWED PHON C FON, P136
   [No title captured]
NR 40
TC 68
Z9 68
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-6393
EI 1872-7182
J9 SPEECH COMMUN
JI Speech Commun.
PD OCT
PY 2009
VL 51
IS 10
SI SI
BP 1024
EP 1037
DI 10.1016/j.specom.2009.05.006
PG 14
WC Acoustics; Computer Science, Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Acoustics; Computer Science
GA 485AK
UT WOS:000269092500017
OA Green Submitted
DA 2022-08-02
ER

PT C
AU Fruth, A
   Neacsu, MN
   Cetina, I
   Orzan, G
AF Fruth, Andreas
   Neacsu, Monica Nicoleta
   Cetina, Iuliana
   Orzan, Gheorghe
BE Dinu, V
TI TECHNOLOGICALY ENHANCED RELATIONSHIP MARKETING BY USING MODERN
   AUTONOMOUS CONVERSATIONAL AGENTS
SO BASIQ INTERNATIONAL CONFERENCE: NEW TRENDS IN SUSTAINABLE BUSINESS AND
   CONSUMPTION 2017
SE Proceedings of BASIQ
LA English
DT Proceedings Paper
CT BASIQ International Conference on New Trends in Sustainable Business and
   Consumption
CY MAY 31-JUN 03, 2017
CL Graz, AUSTRIA
SP Assoc Innovat & Qual Sustainable Business, Padagogische Hochschule Steiermark, AE
DE relationship marketing; marketing communication; autonomous
   conversational agents; chatbot; cybermarketing; artificial intelligence;
   innovation
ID INTEGRATED COMMUNICATIONS; USER-INTERFACE; DESIGN
AB Advances in computing and internet fields brought by the digital revolution changed fundamentally the business world, companies that embraced the changes managing to reduce costs and increase innovation. In the last two years, advances in artificial intelligence (AI) together with the increased availability of commercial artificial intelligence systems resulted into a new generation of autonomous conversational agents or chatbots that engage the user directly and in a personal manner. Using these autonomous conversational agents paired with the exponentially increasing instant messaging platforms led to the creation of modern chatbots, a tool to handle two-way communication between company and customer instantly.
   This article aims at identifying and exposing the ways companies can use chatbots to empower their relationship marketing efforts and the main aspects to be considered when doing that.
C1 [Fruth, Andreas; Neacsu, Monica Nicoleta; Cetina, Iuliana; Orzan, Gheorghe] Bucharest Univ Econ Studies, Bucharest, Romania.
RP Fruth, A (corresponding author), Bucharest Univ Econ Studies, Bucharest, Romania.
RI Neacsu, Monica/Q-1109-2019; ANDREAS, FRUTH/Q-1996-2019; Orzan,
   Gheorghe/AAE-4317-2020
OI Orzan, Gheorghe/0000-0002-6410-7486
CR Berlo DK., 1960, PROCESS COMMUNICATIO
   BONSIEPE G, 1990, VISIBLE LANG, V24, P262
   Gronroos C., 2000, MARKETING REV, V1, P1, DOI DOI 10.1362/1469347002523428
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   McTear MF, 2002, ACM COMPUT SURV, V34, P90, DOI 10.1145/505282.505285
   Mehrabian A., 1972, NONVERBAL COMMUNICAT
   MUIR BM, 1987, INT J MAN MACH STUD, V27, P527, DOI 10.1016/S0020-7373(87)80013-5
   Orzan G., 2007, CYBERMARKETING
   Schultz D.E., 1992, INTEGRATED MARKETING
   Schultz DE, 1996, J BUS RES, V37, P139, DOI 10.1016/S0148-2963(96)00063-X
   Stanciulescu G., 2003, MARKETING DICT EXPLI, P158
   Statista.com, 2017, MOST POP GLOB MOB ME
   Statista.com, 2017, NUMB INT US ONL 2016
   Statista. com, 2017, NUMB MONTHL ACT FAC
   Stewart DW, 1996, J BUS RES, V37, P147, DOI 10.1016/S0148-2963(96)00064-1
   Zamora J., 2017, IUI 2017 COMPANION
   Zenith, 2017, RIS CHATB ZEN 2017 T
NR 17
TC 0
Z9 0
U1 0
U2 23
PU EDITURA ASE
PI BUCURESTI
PA PIATA ROMANA NR 6, SECTOR 1, BUCURESTI, 701631, ROMANIA
SN 2457-483X
J9 PROC BASIQ
PY 2017
BP 252
EP 260
PG 9
WC Business
WE Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Business & Economics
GA BJ6MF
UT WOS:000426833400028
DA 2022-08-02
ER

PT C
AU Kuzminykh, A
   Sun, J
   Govindaraju, N
   Avery, J
   Lank, E
AF Kuzminykh, Anastasia
   Sun, Jenny
   Govindaraju, Nivetha
   Avery, Jeff
   Lank, Edward
GP ACM
TI Genie in the Bottle: Anthropomorphized Perceptions of Conversational
   Agents
SO PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING
   SYSTEMS (CHI'20)
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 25-30, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGCHI
DE conversational agents; interaction; personification; behavioral; visual;
   anthropomorphism; user perception
ID CONSISTENCY; COMPUTERS; INCREASES; RESPONSES; MACHINES
AB This paper presents a qualitative multi-phase study seeking to identify patterns in users' anthropomorphized perceptions of conversational agents. Through a comparative analysis of behavioural perceptions and visual conceptions of three agents - Alexa, Google Assistant, and Siri - we first show that the perceptions of an agent's character are structured according to five categories: approachability, sentiment toward a user, professionalism, intelligence, and individuality. We then explore visualizations of the agents' appearance and discuss the specifics assigned to each agent. Finally, we analyze associative explanations for these perceptions. We demonstrate that the anthropomorphized behavioural and visual perceptions of agents yield structural consistency and discuss how these perceptions are linked with each other and system features.
C1 [Kuzminykh, Anastasia; Sun, Jenny; Govindaraju, Nivetha; Avery, Jeff; Lank, Edward] Univ Waterloo, Cheriton Sch Comp Sci, Waterloo, ON, Canada.
   [Lank, Edward] INRIA, Rocquencourt, France.
   [Lank, Edward] Univ Lille, UMR 9189 CRIStAL, Lille, France.
RP Kuzminykh, A (corresponding author), Univ Waterloo, Cheriton Sch Comp Sci, Waterloo, ON, Canada.
EM akuzminykh@uwaterloo.ca; jenny.sun.2@uwaterloo.ca;
   n2govind@uwaterloo.ca; jeffery.avery@uwaterloo.ca; lank@uwaterloo.ca
FU Natural Science and Engineering Research Council of Canada (NSERC)
FX We thank participants in our study. The research described in this paper
   was reviewed and approved by the Office of Research Ethics at the
   University of Waterloo. Funding for this research was provided by the
   Natural Science and Engineering Research Council of Canada (NSERC).
CR Bickmore T, 2005, TEXT SPEECH LANG TEC, V30, P23
   Bland B, 2018, ALEXA HUG ME EXPLORI
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Brahnam Sheryl, 2015, Design, User Experience and Usability: Users and Interactions. 4th International Conference, DUXU 2015, held as part of HCI International 2015. Proceedings LNCS 9187, P172, DOI 10.1007/978-3-319-20898-5_17
   Brahnam S, 2012, INTERACT COMPUT, V24, P139, DOI 10.1016/j.intcom.2012.05.001
   Breazeal C, 2003, ROBOT AUTON SYST, V42, P167, DOI 10.1016/S0921-8890(02)00373-1
   Budiu R., 2018, INTELLIGENT ASSISTAN
   Budiu Raluca, 2018, PARADOX INTELLIGENT
   Catrambone Richard, 2002, P ANN M COGN SCI SOC, V24
   Charmaz K., 2014, CONSTRUCTING GROUNDE, V2
   Cornell Social Media Lab, 2017, WHAT MAK US LOV AL
   de Visser EJ, 2016, J EXP PSYCHOL-APPL, V22, P331, DOI 10.1037/xap0000092
   Duffy BR, 2003, ROBOT AUTON SYST, V42, P177, DOI 10.1016/S0921-8890(02)00374-3
   Epley N, 2008, PSYCHOL SCI, V19, P114, DOI 10.1111/j.1467-9280.2008.02056.x
   Epley N, 2007, PSYCHOL REV, V114, P864, DOI 10.1037/0033-295X.114.4.864
   Eyssel F, 2012, J APPL SOC PSYCHOL, V42, P2213, DOI 10.1111/j.1559-1816.2012.00937.x
   Eyssel F, 2012, ACMIEEE INT CONF HUM, P125
   Fink Julia, 2012, Social Robotics. 4th International Conference (ICSR 2012). Proceedings, P199, DOI 10.1007/978-3-642-34103-8_20
   Flanagan R, 2007, PSYCHOL SCHOOLS, V44, P257, DOI 10.1002/pits.20221
   Gao Y, 2018, 2018 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI), P372, DOI 10.1109/SmartWorld.2018.00094
   Haslam N, 2006, PERS SOC PSYCHOL REV, V10, P252, DOI 10.1207/s15327957pspr1003_4
   Karjalainen KD, 2017, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON HUMAN AGENT INTERACTION (HAI'17), P89, DOI 10.1145/3125739.3125774
   Kim A, 2013, ACMIEEE INT CONF HUM, P159, DOI 10.1109/HRI.2013.6483550
   Kim B, 2016, UBICOMP'16 ADJUNCT: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P117, DOI 10.1145/2968219.2971426
   Lee SY, 2017, INT J HUM-COMPUT ST, V103, P95, DOI 10.1016/j.ijhcs.2017.02.005
   Leibowitz M., 2013, INTERPRETING PROJECT
   Lemaignan S, 2014, ACMIEEE INT CONF HUM, P226, DOI 10.1145/2559636.2559814
   Lopatovska I, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P265, DOI 10.1145/3176349.3176868
   Lopatovska I, 2019, J LIBR INF SCI, V51, P984, DOI 10.1177/0961000618759414
   MacDorman KF, 2006, INTERACT STUD, V7, P297, DOI 10.1075/is.7.3.03mac
   MacDorman KF, 2016, COGNITION, V146, P190, DOI 10.1016/j.cognition.2015.09.019
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Nass C, 1997, J APPL SOC PSYCHOL, V27, P864, DOI 10.1111/j.1559-1816.1997.tb00275.x
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nass C, 2001, J EXP PSYCHOL-APPL, V7, P171, DOI 10.1037//1076-898X.7.3.171
   Pew Research Center, 2017, NEARL HALF AM DIG VO
   Pratt JA, 2007, INTERACT COMPUT, V19, P512, DOI 10.1016/j.intcom.2007.02.003
   Purington A, 2017, 2017 CHI C HUM FACT, DOI [10.1145/3027063.3053246, DOI 10.1145/3027063.3053246]
   Qiu LY, 2009, J MANAGE INFORM SYST, V25, P145, DOI 10.2753/MIS0742-1222250405
   Riek L. D., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P245
   Sciuto A, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P857, DOI 10.1145/3196709.3196772
   Thompson JC, 2011, PERCEPTION, V40, P695, DOI 10.1068/p6900
   Venkatesh A, 1996, COMMUN ACM, V39, P47, DOI 10.1145/240483.240491
   Waytz A, 2010, PERSPECT PSYCHOL SCI, V5, P219, DOI 10.1177/1745691610369336
   Waytz A, 2010, CURR DIR PSYCHOL SCI, V19, P58, DOI 10.1177/0963721409359302
   West M., 2019, ID BLUSH COULD CLOSI
   Wiese E, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0045391
NR 47
TC 4
Z9 4
U1 1
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6708-0
PY 2020
AR 536
DI 10.1145/3313831.3376665
PG 13
WC Computer Science, Cybernetics; Computer Science, Information Systems;
   Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS1TK
UT WOS:000696109100134
DA 2022-08-02
ER

PT J
AU Kim, KM
   Hong, JH
   Cho, SB
AF Kim, Kyoung-Min
   Hong, Jin-Hyuk
   Cho, Sung-Bae
TI A semantic Bayesian network approach to retrieving information with
   intelligent conversational agents
SO INFORMATION PROCESSING & MANAGEMENT
LA English
DT Article
DE conversational agents; pattern matching; semantic Bayesian networks;
   user interface; mixed-initiative interaction
AB As access to information becomes more intensive in society, a great deal of that information is becoming available through diverse channels. Accordingly, users require effective methods for accessing this information. Conversational agents can act as effective and familiar user interfaces. Although conversational agents can analyze the queries of users based on a static process, they cannot manage expressions that are more complex. In this paper, we propose a system that uses semantic Bayesian networks to infer the intentions of the user based on Bayesian networks and their semantic information. Since conversation often contains ambiguous expressions, the managing of context and uncertainty is necessary to support flexible conversational agents. The proposed method uses mixed-initiative interaction (MII) to obtain missing information and clarify spurious concepts in order to understand the intention of users correctly. We applied this to an information retrieval service for websites to verify the usefulness of the proposed method. (c) 2006 Elsevier Ltd. All rights reserved.
C1 Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea.
RP Cho, SB (corresponding author), Yonsei Univ, Dept Comp Sci, 134 Sinchon Dong, Seoul 120749, South Korea.
EM kminkim@sclab.yonsei.ac.kr; hjinh@sclab.yonsei.ac.kr;
   sbcho@cs.yonsei.ac.kr
OI Hong, Jin-Hyuk/0000-0002-8838-5667
CR Acid S, 2003, INT J INTELL SYST, V18, P251, DOI 10.1002/int.10088
   Allen JF, 2001, AI MAG, V22, P27
   ALLEN JF, 1999, IEEE INTELL SYST APP, P14
   BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032
   Calado P, 2004, INFORM PROCESS MANAG, V40, P773, DOI 10.1016/j.ipm.2004.03.002
   Garcia-Serrano AM, 2004, EXPERT SYST APPL, V26, P413, DOI 10.1016/j.eswa.2003.09.012
   HIX D, 1993, DEV USER INTERFACE
   Hong JH, 2003, LECT NOTES COMPUT SC, V2690, P1
   HORVITZ E, 1998, P 14 C UNC ART INT U, P256
   JENNINGS NR, 1995, APPL ARTIF INTELL, V9, P351
   Macskassy S., 1996, CONVERSATIONAL AGENT
   MAES P, 1994, COMMUN ACM, V37, P31
   Meng HM, 2003, IEEE T SPEECH AUDI P, V11, P757, DOI 10.1109/TSA.2003.814380
   NUGUES P, 1996, P 11 20 WORKSH LANG, P23
   Pearl J, 1998, PROBABILISTIC REASON
   Perugini S., 2003, IT Professional, V5, P9, DOI 10.1109/MITP.2003.1191787
   Shamsfard M, 2004, INT J HUM-COMPUT ST, V60, P17, DOI 10.1016/j.ijhcs.2003.08.001
   Symeonidis AL, 2003, EXPERT SYST APPL, V25, P589, DOI 10.1016/S0957-4174(03)00099-X
   TUTLE HR, 1990, P 13 INT C RES DEV I, P1
   Yang SL, 2002, IEEE T SYST MAN CY A, V32, P419, DOI 10.1109/TSMCA.2002.803772
   Zue VW, 2000, P IEEE, V88, P1166, DOI 10.1109/5.880078
   [No title captured]
NR 22
TC 19
Z9 21
U1 0
U2 7
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0306-4573
EI 1873-5371
J9 INFORM PROCESS MANAG
JI Inf. Process. Manage.
PD JAN
PY 2007
VL 43
IS 1
BP 225
EP 236
DI 10.1016/j.ipm.2006.04.001
PG 12
WC Computer Science, Information Systems; Information Science & Library
   Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Information Science & Library Science
GA 098RC
UT WOS:000241539500015
DA 2022-08-02
ER

PT C
AU Siemon, D
   Jusmann, S
AF Siemon, Dominik
   Jusmann, Sergej
GP Assoc Informat Syst
TI Preferred Appearance of Embodied Conversational Agents in Knowledge
   Management
SO DIGITAL INNOVATION AND ENTREPRENEURSHIP (AMCIS 2021)
LA English
DT Proceedings Paper
CT 27th Annual Americas Conference on Information Systems (AMCIS)
CY AUG 09-13, 2021
CL ELECTR NETWORK
DE Conversational agents; knowledge management; appearance; design;
   artificial intelligence
ID INTELLIGENCE; CUES
AB This paper deals with the investigation of the preferred appearance of embodied conversational agents (ECA) in the context of knowledge management. ECAs are artificial intelligence-based systems that are used in different contexts and support scenarios to assist human users and jointly work with them. An important aspect is the design and especially the appearance, which influences acceptance, interaction quality, and overall work performance. An online survey was used to determine preferred appearances of ECAs that are specifically used in the context of knowledge management. With a total of 104 participants, the results yielded findings for the appearance, kinetics, proxemics, and communication of ECAs in knowledge management. Participants expressed their preferences towards a realistic and human appearance, which speaks for a desire for human-like artificial intelligence. The results contribute to the practical design of ECAs as well as to existing theories on human-AI interaction, such as anthropomorphisms.
C1 [Siemon, Dominik] LUT Univ, Lappeenranta, Finland.
   [Jusmann, Sergej] Tech Univ Carolo Wilhelmina Braunschweig, Braunschweig, Germany.
RP Siemon, D (corresponding author), LUT Univ, Lappeenranta, Finland.
EM dominik.siemon@lut.fi; s.jusmann@tu-braunschweig.de
CR Abubakar A. M., 2019, J INNOVATION KNOWLED, V4
   Ahmad R., 2020, INTRO RAFFI PERSONAL
   Ahmad R, 2021, P 54 HAW INT C SYST, P4043
   Akram MS, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10103816
   Anderson J, 2018, ARTIF INTELL
   Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Bandilla W., 2002, ONLINE SOCIAL SCI, P1
   Bee N., 2009, INTELLIGENT VIRTUAL
   Birzniece I., 2011, SCI J RIGA TU COMPUT, V43, P5, DOI DOI 10.2478/V10143-011-0001-X
   Brahnam S, 2012, INTERACT COMPUT, V24, P139, DOI 10.1016/j.intcom.2012.05.001
   Broszinsky-Schwabe E., 2016, INTERKULTURELLE KOMM
   Cassell J, 2001, AI MAG, V22, P67
   Catrambone R., 2002, P ANN M COGN SCI SOC, V24, P24
   Cowell AJ, 2005, INT J HUM-COMPUT ST, V62, P281, DOI 10.1016/j.ijhcs.2004.11.008
   Dautenhahn K., SIMULATED ORG, P267, DOI 10.1007/0-306-47373-9_33
   Davenport TH, 2001, J MANAGE INFORM SYST, V18, P3, DOI 10.1080/07421222.2001.11045674
   Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009
   Gerber A., 2020, CONCEPTUALIZATION HU, DOI 10.24251/HICSS.2020.036
   Girard J., 2015, ONLINE J APPL KNOWLE, V3, P1
   Gnewuch U., 2017, P 38 INT C INFORM SY
   Iyengar K., 2021, J ASS INFORM SYSTEMS, V22
   Lehner F., 2019, WISSENSMANAGEMENT GR
   Lhommet M., 2014, OXFORD HDB AFFECTIVE, V273
   Liebowitz J, 2001, EXPERT SYST APPL, V20, P1, DOI 10.1016/S0957-4174(00)00044-0
   Maedche A, 2016, BUS INFORM SYST ENG+, V58, P367, DOI 10.1007/s12599-016-0444-2
   McBreen H., 2002, SOCIALLY INTELLIGENT, P267, DOI 10.1007/0-306-47373-9_33
   McTear M., 2016, CONVERSATIONAL INTER, V6, P102
   Moon Y, 1996, COMMUN RES, V23, P651, DOI 10.1177/009365096023006002
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Nemati HR, 2002, DECIS SUPPORT SYST, V33, P143, DOI 10.1016/S0167-9236(01)00141-5
   Ruggles R., 2009, KNOWLEDGE MANAGEMENT
   Seeber I., 2019, INFORM MANAGE
   Shiban Y, 2015, COMPUT HUM BEHAV, V49, P5, DOI 10.1016/j.chb.2015.01.077
   Siemon D., 2020, HUMAN COLLABORATION, P105, DOI 10.4018/978-1-7998-4891-2.ch005
   Stal S. ter, 2020, 1 IMPRESSIONS EMBODI, V36, P881, DOI 10.1080/104473pu18.2019.1699744
   Stieglitz S., 2018, INT C INF SYST
   Tsui E, 2000, KNOWL-BASED SYST, V13, P235, DOI 10.1016/S0950-7051(00)00093-9
   Zelewski S., 2015, WISSENSMANAGEMENT DI
   Zhang R., 2021, P ACM HUM COMP INT
NR 39
TC 0
Z9 0
U1 1
U2 2
PU ASSOC INFORMATION SYSTEMS
PI ATLANTA
PA P.O. BOX 2712, ATLANTA, GA 30301-2712 USA
PY 2021
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR8LY
UT WOS:000672599802005
DA 2022-08-02
ER

PT C
AU Sannon, S
   Stoll, B
   DiFranzo, D
   Jung, M
   Bazarova, NN
AF Sannon, Shruti
   Stoll, Brett
   DiFranzo, Dominic
   Jung, Melte
   Bazarova, Natalya N.
GP ACM
TI How Personification and Interactivity Influence Stress-Related
   Disclosures to Conversational Agents
SO COMPANION OF THE 2018 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE
   WORK AND SOCIAL COMPUTING (CSCW'18)
LA English
DT Proceedings Paper
CT ACM Conference on Computer Supported Cooperative Work and Social
   Computing (CSCW)
CY NOV 03-07, 2018
CL Jersey City, NJ
SP Assoc Comp Machinery, ACM SIGCHI, Facebook, IBM, Underwood Inst
DE Conversational agents; disclosure; stress; personification;
   interactivity
AB In this exploratory study, we examine how personification and interactivity may influence people's disclosures around sensitive topics, such as psychological stressors. Participants (N=441) shared a recent stressful experience with one of three agent interfaces: 1) a non-interactive, non-personified survey, 2) an interactive, non-personified chatbot, and 3) an interactive, personified chatbot. We coded these responses to examine how agent type influenced the nature of the stressor disclosed, and the intimacy and amount of disclosure. Participants discussed fewer homelife related stressors, but more finance-related stressors and more chronic stressors overall with the personified chatbot than the other two agents. The personified chatbot was also twice as likely as the other agents to receive disclosures that contained very little detail. We discuss the role played by personification and interactivity in interactions with conversational agents, and implications for design.
C1 [Sannon, Shruti; Stoll, Brett; DiFranzo, Dominic; Jung, Melte; Bazarova, Natalya N.] Cornell Univ, Ithaca, NY 14853 USA.
RP Sannon, S (corresponding author), Cornell Univ, Ithaca, NY 14853 USA.
EM ss3464@cornell.edu; bas364@cornell.edu; djd274@cornell.edu;
   mfj28@cornell.edu; nnb8@cornell.edu
RI DiFranzo, Dominic/G-6683-2013
OI DiFranzo, Dominic/0000-0001-6039-1806
FU National Science Foundation [1405634]
FX We thank the National Science Foundation (award #1405634), and our
   undergraduate RAs, Brenna Garcia, Colton Zuvich, and Erin Chen, for
   their support.
CR Almeida David M., 2002, ASSESSMENT
   Hill Jennifer, 2015, COMPUTERS HUMAN BEHA
   Jiang Crystal, 2013, COMMUNICATION RES
   Jin Seung-A. A., 2010, COMPUTERS HUMAN BEHA
   Li Jingyi, 2017, P IUI
   Lucas Gale M., 2014, COMPUTERS HUMAN BEHA
   Sundar SS, 2008, MACARTHUR FDN DIGITA
NR 7
TC 7
Z9 7
U1 3
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6018-0
PY 2018
BP 285
EP 288
DI 10.1145/3272973.3274076
PG 4
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BN4KW
UT WOS:000482113000072
OA Bronze
DA 2022-08-02
ER

PT C
AU Chen, ML
   Wang, HC
AF Chen, Mei-Ling
   Wang, Hao-Chuan
GP ACM
TI How Personal Experience and Technical Knowledge Affect Using
   Conversational Agents
SO COMPANION OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER
   INTERFACES (IUI'18)
LA English
DT Proceedings Paper
CT 23rd International Conference on Intelligent User Interfaces (IUI)
CY MAR 07-11, 2018
CL Tokyo, JAPAN
SP Assoc Comp Machinery, ACM SIGAI, ACM SIGCHI
DE Conversational agents; mental models; explainable intelligent user
   interfaces
AB Conversational agents (CA) use dialogues to interact with users so as to offer an experience of naturalistic interaction. However, due to the low transparency and poor explanability of mechanism inside CA, individual's understanding of CA's capabilities may affect how the individual interacts with CA and the sustainability of CA use. To examine how users' understanding affect perceptions and experiences of using CA, we conducted a laboratory study asking 41 participants performed a set of tasks using Apple Siri. We independently manipulated two factors: (1) personal experience of using CA, and (2) technical knowledge about CA's system model. We conducted mixed-method analyses of post-task usability measures and interviews, and confirmed that use experience and technical knowledge affects perceived usability and mental models differently.
C1 [Chen, Mei-Ling] Natl Tsing Hua Univ, Inst Informat Syst & Applicat, Hsinchu, Taiwan.
   [Wang, Hao-Chuan] Natl Tsing Hua Univ, Inst Informat Syst & Applicat, Dept Comp Sci, Hsinchus, Taiwan.
RP Chen, ML (corresponding author), Natl Tsing Hua Univ, Inst Informat Syst & Applicat, Hsinchu, Taiwan.
EM cmei-ling@acm.org; haochuan@cs.nthu.edu.tw
FU Ministry of Science and Technology of Taiwan [MOST 106-2633-E-002-001,
   105-2628-E-007-004-MY2]; National Taiwan University [NTU-106R104045];
   Intel Corporation
FX This research was supported in part by the Ministry of:Science and
   Technology of Taiwan (MOST 106-2633-E-002-001, 105-2628-E-007-004-MY2),
   National Taiwan University (NTU-106R104045), and Intel Corporation.
CR Coyle David, 2017, P 19 INT C HUM C HUM
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Tullio J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P31
NR 3
TC 7
Z9 7
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5571-1
PY 2018
DI 10.1145/3180308.3180362
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BM0DZ
UT WOS:000458680100053
DA 2022-08-02
ER

PT C
AU Hayashi, Y
AF Hayashi, Yugo
BE TrausanMatu, S
   Boyer, KE
   Crosby, M
   Panourgia, K
TI Togetherness: Multiple Pedagogical Conversational Agents as Companions
   in Collaborative Learning
SO INTELLIGENT TUTORING SYSTEMS, ITS 2014
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 12th International Conference on Intelligent Tutoring Systems (ITS)
CY JUN 05-09, 2014
CL Honolulu, HI
SP Assoc Advancement Artificial Intelligence, MARi, Int Artificial Intelligence Educ Soc
DE Pedagogical Conversational Agents; Collaborative Learning; Explanation
   Activities; Social Facilitation
AB This study investigates the design of effective interaction using pedagogical conversational agents (PCAs) as companions in collaborative learning activities. Specifically, we focus on the use of embodied PCAs that evoke social awareness and engagement from human learners. In controlled experiments, paired collaborative learners were selectively accompanied by "peer-advisor" PCAs in a set of learning activities. Results show that learners who engaged with multiple PCAs gained a better understanding of target concepts than those using a single PCA. Furthermore, learners who engaged PCAs playing different collaborative roles (e. g., "mentor" and "expert") outperformed those who engaged PCAs without distinct roles. The implications of these results are explored and directions for future study are discussed.
C1 Ritsumeikan Univ, Dept Psychol, Kita Ku, Kyoto 6038577, Japan.
RP Hayashi, Y (corresponding author), Ritsumeikan Univ, Dept Psychol, Kita Ku, 56-1 Kitamachi, Kyoto 6038577, Japan.
EM y-hayashi@acm.org
CR Allport FH, 1920, J EXP PSYCHOL, V3, P159, DOI 10.1037/h0067891
   Baylor A., 2003, EDMEDIA INNOVAE LEAR, P448
   Becker-Beck U, 2005, SMALL GR RES, V36, P499, DOI 10.1177/1046496405277182
   CHI MTH, 1994, COGNITIVE SCI, V18, P439, DOI 10.1016/0364-0213(94)90016-7
   Graesser A, 2010, EDUC PSYCHOL-US, V45, P234, DOI 10.1080/00461520.2010.515933
   Gulz A, 2006, INT J HUM-COMPUT ST, V64, P322, DOI 10.1016/j.ijhcs.2005.08.006
   Hayashi Yugo, 2012, Intelligent Tutoring Systems. Proceedings 11th International Conference (ITS 2012), P22, DOI 10.1007/978-3-642-30950-2_3
   Hayashi Y, 2013, LEARNER SUPPORT AGEN
   Hayashi Y., 2006, P 28 ANN C COGN SCI, P333
   Heidig S, 2011, EDUC RES REV-NETH, V6, P27, DOI 10.1016/j.edurev.2010.07.004
   Holmes J, 2007, COMPUT EDUC, V48, P523, DOI 10.1016/j.compedu.2005.02.007
   Kim Y, 2007, J COMPUT ASSIST LEAR, V23, P220, DOI 10.1111/j.1365-2729.2006.00210.x
   Kim Y, 2005, INT J ARTIFICIAL INT, V15, P95, DOI [DOI 10.1007/BF02504991, DOI 10.1145/1067860.1067867]
   Kumar R, 2011, IEEE T LEARN TECHNOL, V4, P21, DOI 10.1109/TLT.2010.41
   Lave J., 1991, SITUATED LEARNING LE, DOI DOI 10.1017/CBO9780511815355
   Lee EJ, 2002, HUM COMMUN RES, V28, P349, DOI 10.1111/j.1468-2958.2002.tb00812.x
   LEVINE JM, 1993, ANNU REV PSYCHOL, V44, P585, DOI 10.1146/annurev.ps.44.020193.003101
   MIYAKE N, 1986, COGNITIVE SCI, V10, P151, DOI 10.1016/S0364-0213(86)80002-7
   Moreno R, 2005, J EDUC PSYCHOL, V97, P117, DOI 10.1037/0022-0663.97.1.117
   Okada T, 1997, COGNITIVE SCI, V21, P109, DOI 10.1016/S0364-0213(99)80020-2
   Salomon Gavriel, 2001, DISTRIBUTED COGNITIO
   Shirouzu H, 2002, COGNITIVE SCI, V26, P469, DOI 10.1207/s15516709cog2604_3
   Vygotsky L. S., 1978, MIND SOC DEV HIGHER
   [No title captured]
NR 24
TC 11
Z9 11
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-319-07221-0; 978-3-319-07220-3
J9 LECT NOTES COMPUT SC
PY 2014
VL 8474
BP 114
EP 123
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BB3VL
UT WOS:000343081600014
DA 2022-08-02
ER

PT C
AU Bailly, G
   Elisei, F
   Raidt, S
   Casari, A
   Picot, A
AF Bailly, Gerard
   Elisei, Frederic
   Raidt, Stephan
   Casari, Alix
   Picot, Antoine
BE Zhuang, Y
   Yang, S
   Rui, Y
   He, Q
TI Embodied conversational agents: Computing and rendering realistic gaze
   patterns
SO ADVANCES IN MULTIMEDIA INFORMATION PROCESSING - PCM 2006, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 7th Pacific Rim Conference on Multimedia
CY NOV 02-04, 2006
CL Zhejiang Univ, Hangzhou, PEOPLES R CHINA
SP Natl Nat Sci Fdn China, Insigma Technol Co Ltd, Microsoft Res, Zhejiang Univ, Y C Tang Disciplinary Dev Fund
HO Zhejiang Univ
DE embodied conversational agents; talking faces; audiovisual speech
   synthesis; face-to-face interaction
ID DIRECTION; EYES
AB We describe here our efforts for modeling multimodal signals exchanged by interlocutors when interacting face-to-face. This data is then used to control embodied conversational agents able to engage into a realistic face-to-face interaction with human partners. This paper focuses on the generation and rendering of realistic gaze patterns. The problems encountered and solutions proposed claim for a stronger coupling between research fields such as audiovisual signal processing, linguistics and psychosocial sciences for the sake of efficient and realistic human-computer interaction.
C1 [Bailly, Gerard; Elisei, Frederic; Raidt, Stephan; Casari, Alix; Picot, Antoine] Inst Commun Parlee, 46 Felix Viallet, F-38031 Grenoble, France.
RP Bailly, G (corresponding author), Inst Commun Parlee, 46 Felix Viallet, F-38031 Grenoble, France.
EM gerard.bailly@icp.inpg.fr; frederic.elisei@icp.inpg.fr;
   stephan.raidt@icp.inpg.fr; alix.casari@icp.inpg.fr;
   antoine.picot@icp.inpg.fr
RI bailly, gerard/ABI-2468-2020
OI bailly, gerard/0000-0002-6053-0818
FU GIS PEGASUS; ELESA
FX The authors want to thank Jan Cornelis, Hichem Sahli and Werner Verhelst
   for their kind invitation. The technical support from Alain Arnal and
   Christophe Savariaux was essential. This work is financed by the GIS
   PEGASUS, the ELESA research federation and the Presence project of the
   Cluster Rhones-Alpes InfoLog.
CR Argyle M., 1976, GAZE MUTUAL GAZE
   BAILLY G, 2006, INT WORKSH MULT CORP, P33
   BARONCOHEN S, 1985, COGNITION, V21, P37, DOI 10.1016/0010-0277(85)90022-8
   Benoit C, 1996, SPEECH COMMUN, V18, P381, DOI 10.1016/0167-6393(96)00026-X
   Carpenter M, 2000, COMM LANG INTERVEN, V9, P31
   Cassell J., 2000, EMBODIED CONVERSATIO
   CLODIC A, 2006, IEEE INT WORKSH ROB
   Driver J, 1999, VIS COGN, V6, P509, DOI 10.1080/135062899394920
   GEIGER G, 2003, 224AI CBCL MIT
   Grossberg Stephen, 2003, Behav Cogn Neurosci Rev, V2, P47, DOI 10.1177/1534582303002001003
   GULLBERG M, 2001, INT GEST WORKSH LOND, P206
   ITTO L, 2003, SPIE 48 ANN INT S OP, P64
   KENDON A, 1967, ACTA PSYCHOL, V26, P22, DOI 10.1016/0001-6918(67)90005-4
   Langton SRH, 1999, VIS COGN, V6, P541, DOI 10.1080/135062899394939
   Langton SRH, 2000, TRENDS COGN SCI, V4, P50, DOI 10.1016/S1364-6613(99)01436-9
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   Matsusaka Y, 2003, IEICE T INF SYST, VE86D, P26
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   Pourtois G, 2004, EUR J NEUROSCI, V20, P3507, DOI 10.1111/j.1460-9568.2004.03794.x
   PREMACK D, 1978, BEHAV BRAIN SCI, V1, P515, DOI 10.1017/S0140525X00076512
   RAIDT S, 2006, LANG RESS EV C LREC, P2544
   Riva G., 2003, BEING THERE CONCEPTS
   Scassellati B. M., 2001, FDN THEORY MIND HUMA
   Simons DJ, 1999, PERCEPTION, V28, P1059, DOI 10.1068/p2952
   Stork D. G., 1996, SPEECHREADING HUMANS
   SUN Y, 2003, THESIS EDINBURGH U E
   Thorisson KR, 2002, TEXT SPEECH LANG TEC, V19, P173
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   Xu YD, 2006, NATURE, V440, P91, DOI 10.1038/nature04262
   Yarbus A. L., 1967, EYE MOVEMENTS VISION, P171, DOI [10.1007/978-1-4899-5379-7, DOI 10.1007/978-1-4899-5379-7]
NR 30
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-48766-2
J9 LECT NOTES COMPUT SC
PY 2006
VL 4261
BP 9
EP +
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Imaging Science & Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Imaging Science & Photographic Technology
GA BFM92
UT WOS:000243129600002
OA Green Submitted
DA 2022-08-02
ER

PT C
AU Khan, S
   Camacho, A
   Novick, D
AF Khan, Sabiha
   Camacho, Adriana
   Novick, David
BE Beskow, J
   Peters, C
   Castellano, G
   OSullivan, C
   Leite, I
   Kopp, S
TI Recipe Hunt: Engaging with Cultural Food Knowledge using Multiple
   Embodied Conversational Agents
SO INTELLIGENT VIRTUAL AGENTS, IVA 2017
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 17th International Conference on Intelligent Virtual Agents (IVA)
CY AUG 27-30, 2017
CL Swedish Natl Museum Sci & Technol, Stockholm, SWEDEN
SP KTH Royal Inst Technol
HO Swedish Natl Museum Sci & Technol
DE Embodied Conversational Agents; cultural heritage; interactive
   documentary
AB The popularity in recent years of food media, particularly in the domain of documentary films, has brought the communicative potential of food to the fore. Recipe Hunt is an interactive documentary that simulates the cultural experience of connecting over food by sharing recipes. Embodied conversational agents (ECAs) are used to engage users with cultural food heritage from the U.S.-Mexico border. Recipe Hunt aims to use a distributed and participatory model of cross-cultural learning for users to engage with the culinary heritage from this region of the United States.
C1 [Khan, Sabiha] Univ Texas El Paso, Dept Commun, El Paso, TX 79968 USA.
   [Camacho, Adriana] Univ Texas El Paso, Dept Comp Sci, El Paso, TX 79968 USA.
   [Novick, David] Univ Texas El Paso, Dept Engn Educ & Leadership, El Paso, TX 79968 USA.
RP Khan, S (corresponding author), Univ Texas El Paso, Dept Commun, El Paso, TX 79968 USA.
EM skhan2@utep.edu; caro4874@gmail.com; novick@utep.edu
OI Khan, Sabiha/0000-0001-8986-9324
FU National Science Foundation [2015195909]
FX This material is based upon work supported by a National Science
   Foundation Graduate Research Fellowship under grant 2015195909. Any
   opinion, findings, and conclusions or recommendations expressed in this
   material are those of the authors and do not necessarily reflect the
   views of the National Science Foundation. We thank Inmerssion for an
   updated xml interpreter based on the UTEP AGENT system.
CR Barthes Roland, 2013, FOOD CULTURE READER, V3rd, P24
   Carson D, 2014, APPETITES ANXIETIES
   Miles Adrian., 2014, NEW DOCUMENTARY ECOL, P67
   Novick D, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P383, DOI 10.1145/2818346.2823302
NR 4
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-319-67401-8; 978-3-319-67400-1
J9 LECT NOTES ARTIF INT
PY 2017
VL 10498
BP 209
EP 212
DI 10.1007/978-3-319-67401-8_24
PG 4
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BL7SK
UT WOS:000455400000024
DA 2022-08-02
ER

PT C
AU Ahmadvand, A
AF Ahmadvand, Ali
GP ACM
TI User Intent Inference for Web Search and Conversational Agents
SO PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA
   MINING (WSDM '20)
LA English
DT Proceedings Paper
CT 13th Annual ACM International Conference on Web Search and Data Mining
   (WSDM)
CY FEB 03-07, 2020
CL Houston, TX
SP Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD, ACM SIGMOD
DE User Intent Understanding; User intent in Conversational Agents; User
   Intent in E-Commerce Search
AB User intent understanding is a crucial step in designing both conversational agents and search engines. Detecting or inferring user intent is challenging, since the user utterances or queries can be short, ambiguous, and contextually dependent. To address these research challenges, my thesis work focuses on: 1) Utterance topic and intent classification for conversational agents 2) Query intent mining and classification for Web search engines, focusing on the e-commerce domain. To address the first topic, I proposed novel models to incorporate entity information and conversation-context clues to predict both topic and intent of the user's utterances. For the second research topic, I plan to extend the existing state of the art methods in Web search intent prediction to the e-commerce domain, via: 1) Developing a joint learning model to predict search queries' intents and the product categories associated with them, 2) Discovering new hidden users' intents. All the models will be evaluated on the real queries available from a major e-commerce site search engine. The results from these studies can be leveraged to improve performance of various tasks such as natural language understanding, query scoping, query suggestion, and ranking, resulting in an enriched user experience.
C1 [Ahmadvand, Ali] Emory Univ, Dept Comp Sci, Atlanta, GA 30322 USA.
RP Ahmadvand, A (corresponding author), Emory Univ, Dept Comp Sci, Atlanta, GA 30322 USA.
EM ali.ahmadvand@emory.edu
FU Amazon Alexa team; Home Depot data science team
FX We gratefully acknowledge the financial and computing support from the
   Amazon Alexa team and The Home Depot data science team during my Ph.D.
   dissertation.
CR Ahmadvand A, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1371, DOI 10.1145/3357384.3358048
   Ahmadvand A, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1273, DOI 10.1145/3331184.3331375
   Ahmadvand Ali, 2018, 2 P AL PRIZ
   Broder A., 2002, SIGIR Forum, V36, P3, DOI 10.1145/792550.792552
   Guo Fenfei, 2018, NIPS
   Hu JA, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON ADVANCED FIBERS AND POLYMER MATERIALS, VOLS 1 AND 2, P1147
   Kim BS, 2019, PROCEEDINGS OF THE 17TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P281
   Sondhi P, 2018, ACM/SIGIR PROCEEDINGS 2018, P1245, DOI 10.1145/3209978.3210152
   Wang Zihao, 2017, 1 P AL PRIZ
   Xiong W, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5934, DOI 10.1109/ICASSP.2018.8461870
NR 10
TC 1
Z9 1
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6822-3
PY 2020
BP 911
EP 912
DI 10.1145/3336191.3372187
PG 2
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BO9KL
UT WOS:000531489300122
OA Green Submitted
DA 2022-08-02
ER

PT C
AU Smeddinck, J
   Wajda, K
   Naveed, A
   Touma, L
   Chen, YT
   Abu Hasan, M
   Latif, MW
   Porzel, R
AF Smeddinck, Jan
   Wajda, Kamila
   Naveed, Adeel
   Touma, Leen
   Chen, Yuting
   Abu Hasan, Muhammad
   Latif, Muhammad Waqas
   Porzel, Robert
GP ACM
TI QuickWoZ: A Multi-purpose Wizard-of-Oz Framework for Experiments with
   Embodied Conversational Agents
SO IUI 2010
LA English
DT Proceedings Paper
CT Proceedings of the 14th ACM International Conference on Intelligent User
   Interfaces
CY FEB 07-10, 2010
CL Hong Kong, PEOPLES R CHINA
SP ACM SIGCHI, ACM SIGART
DE HCI; embodiment; conversational agents; evaluation
AB Herein we describe the QuickWoZ system, a Wizard-of-Oz (WoZ) tool that allows for the remote control of the behavior of animated characters in a 3D environment. The complete scene, character, behaviors and sounds can be defined in simple XML documents, which are parsed at runtime, so that setting up an experiment can be done without programming expertise. Quick selection lists and buttons enable the wizard to easily control the agents' behavior and allow for fast reactions to the subjects' input. The system is tailored for experiments with embodied conversational agents (ECAs) featuring multimodal interaction and was designed as a rapid prototyping system for evaluating the impact of an agent's behavior on the user.
RP Smeddinck, J (corresponding author), Univ Bremen, FB 3, D-2800 Bremen 33, Germany.
EM confetti@informatik.uni-bremen.de; porzel@informatik.uni-bremen.de
RI Latif, Muhammad/D-1335-2018
OI Latif, Muhammad/0000-0003-4858-3324; Smeddinck, Jan
   David/0000-0003-0562-8473
CR Cassell J, 2000, COMMUN ACM, V43, P50, DOI 10.1145/355112.355123
   CASSELL J, 2001, PERSONAL UBIQUITOUS, V5
   DAHLBACK N, 1993, READINGS INTELLIGENT, P610
   FRANCONY JM, 1992, 3 C APPL NLP
   KRAEMER N, 2007, LNAI, V4722
   BASS AUDIO LIB
   MOGRE NET WRAPPER OG
NR 7
TC 1
Z9 1
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-60558-515-4
PY 2010
BP 427
EP 428
PG 2
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BRV57
UT WOS:000283748700074
DA 2022-08-02
ER

PT C
AU Gris, I
   Novick, D
   Camacho, A
   Rivera, DA
   Gutierrez, M
   Rayon, A
AF Gris, Ivan
   Novick, David
   Camacho, Adriana
   Rivera, Diego A.
   Gutierrez, Mario
   Rayon, Alex
BE Bickmore, T
   Marsella, S
   Sidner, C
TI Recorded Speech, Virtual Environments, and the Effectiveness of Embodied
   Conversational Agents
SO INTELLIGENT VIRTUAL AGENTS, IVA 2014
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 14th International Conference on Intelligent Virtual Agents (IVA)
CY AUG 27-29, 2014
CL Boston, MA
DE Embodied conversational agents; virtual environments; human-agent dialog
AB Development of embodied conversational agents (ECAs) has tended to focus on the character's dialog capabilities, with less research on the design and effect of the agent's voice and of the virtual environments in which the agent exists. For a study of human-ECA rapport, we iteratively developed three versions of a game featuring an ECA, where each version of the game had a different combination of speech generation and virtual environment. Evaluations of the users' interactions with the different versions of the game enabled us to assess the effects of changes in the agent's voice and of changes in the agent's virtual world.
C1 [Gris, Ivan; Novick, David; Camacho, Adriana; Rivera, Diego A.; Gutierrez, Mario; Rayon, Alex] Univ Texas El Paso, Dept Comp Sci, 500 W Univ Ave, El Paso, TX 79912 USA.
RP Gris, I (corresponding author), Univ Texas El Paso, Dept Comp Sci, 500 W Univ Ave, El Paso, TX 79912 USA.
EM ivangris4@gmail.com; novick@utep.edu; accamacho2@miners.utep.edu;
   darivera2@miners.utep.edu; mgutierrez19@miners.utep.edu;
   amrayon2@miners.utep.edu
CR Anderson Tim, 1985, NEW ZORK TIMES, V4
   Crowther W., 1976, COMPUTER GAME
   Newell C., 2008, INT J PERF ART DIGIT, V4, P155
   Novick D, 2014, LECT NOTES COMPUT SC, V8511, P472, DOI 10.1007/978-3-319-07230-2_45
   SCHRODER M, 2001, P 7 EUR C SPEECH COM, V1, P561
   Serrels M, 2011, REAL LIFE 1 3 PERSON
NR 6
TC 3
Z9 3
U1 1
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-319-09767-1; 978-3-319-09766-4
J9 LECT NOTES ARTIF INT
PY 2014
VL 8637
BP 182
EP 185
PG 4
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS4CK
UT WOS:000717232400022
DA 2022-08-02
ER

PT B
AU Perez-Marin, D
   Pascual-Nieto, I
AF Perez-Marin, Diana
   Pascual-Nieto, Ismael
BA PerezMarin, D
   PascualNieto, I
BF PerezMarin, D
   PascualNieto, I
TI Future Trends for Conversational Agents
SO CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND
   EFFECTIVE PRACTICES
LA English
DT Article; Book Chapter
AB In the last decades, there has been a great evolution in the field of Conversational Agents. Currently, there are agents to assist the navigation in Web pages, support elder users when interacting with some computer application to remind them which medicines they should take during the day, or to enhance the learning process by allowing students to review with systems that adapt themselves to their previous knowledge and rhythm of study. In this chapter, the goal is to provide a summary of the future trends that can be envisaged for the future of the field. It is our insight that the future of Conversational Agents are to become pervasive and natural in our daily lives.
C1 [Pascual-Nieto, Ismael] Univ Autonoma Madrid, Dept Comp Sci, E-28049 Madrid, Spain.
RI Pérez-Marín, Diana/ABF-6641-2021
OI Pérez-Marín, Diana/0000-0003-3390-0251
CR Baylor AL, 2009, PHILOS T R SOC B, V364, P3559, DOI 10.1098/rstb.2009.0148
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   Edlund J., 2007, P INT ICSLP ATW
   Fairclough SH, 2009, INTERACT COMPUT, V21, P133, DOI 10.1016/j.intcom.2008.10.011
   Gratch J, 2006, LECT NOTES ARTIF INT, V4133, P14
   Gulz A., 2004, INT J ARTIFICIAL INT, V14, P313
   Gulz A., 2010, GENDER ISSUES LEARNI, DOI [10.4018/978-1-61520-813-5.ch007, DOI 10.4018/978-1-61520-813-5.CH007]
   Kim Y., 2007, Educational Technology, V47, P23
   Klein J., 1999, CHI 99 HUM FACT COMP
   Kramer NC, 2009, SOC PSYCHOL-GERMANY, V40, P26, DOI 10.1027/1864-9335.40.1.26
   Manchon P., 2009, THESIS U SEVILLE SPA
   Morency L. -P., 2008, 10 INT C MULT INT CH
   Niles I., 2001, Formal Ontology in Information Systems. Collected Papers from the Second International Conference, P2
   Parsons TD, 2009, LECT NOTES ARTIF INT, V5639, P243, DOI 10.1007/978-3-642-02728-4_26
   Quarteroni S., 2009, SING KRAQ 09
NR 15
TC 2
Z9 2
U1 0
U2 3
PU IGI GLOBAL
PI HERSEY
PA 701 E CHOCOLATE AVE, STE 200, HERSEY, PA 17033-1240 USA
BN 978-1-60960-618-3; 978-1-60960-617-6
PY 2011
BP 395
EP 400
DI 10.4018/978-1-60960-617-6.ch018
D2 10.4018/978-1-60960-617-6
PG 6
WC Computer Science, Artificial Intelligence
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BZX29
UT WOS:000303201400019
DA 2022-08-02
ER

PT C
AU Georg, G
   Cavazza, M
   Pelachaud, C
AF Georg, Gersende
   Cavazza, Marc
   Pelachaud, Catherine
BE Prendinger, H
   Lester, J
   Ishizuka, M
TI Visualizing the Importance of Medical Recommendations with
   Conversational Agents
SO INTELLIGENT VIRTUAL AGENTS, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 8th International Conference on Intelligent Virtual Agents
CY SEP 01-03, 2008
CL Tokyo, JAPAN
SP Assoc Advancement Artificial Intelligence, European Assoc Comp Graph, ACM SIGART, ACM SIGCHI
DE Embodied Conversational Agents; Emotional Natural Language Processing;
   Medical Informatics
AB Embodied Conversational Agents (ECA) have the potential to bring to life many kinds of information, and in particular textual contents. In this paper, we present a prototype that helps visualizing the relative importance of sentences extracted from medical texts (clinical guidelines aimed at physicians). We propose to map rhetorical structures automatically recognized in the documents to a set of communicative acts controlling the expression of the ECA. As a consequence, the ECA will dramatize a sentence to reflect its perceived importance and degree of recommendation (advice, requirement, open proposal, etc). This prototype is constituted of three sub-systems: i) a text analysis module, ii) an ECA and iii) a mapping module which converts rhetorical structures produced by the text analysis module into nonverbal behaviors driving the ECA animation. This system could help authors of medical texts to reflect on the potential impact of the writing style they have adopted. The use of ECA reintroduces an affective element which won't be captured by other methods for analyzing document style.
C1 [Georg, Gersende] Ctr Cordeliers, UMRS 872, Eq 20, Paris, France.
   [Georg, Gersende] French Natl Author Hlth, La Plaine St Denis, France.
   [Cavazza, Marc] Univ Teesside, Sch Comp, Middlesbrough, Cleveland, England.
   [Pelachaud, Catherine] Univ Paris 08, F-93526 St Denis 02, France.
   [Pelachaud, Catherine] INRIA Rocquencourt, Domaine de Voluceau, France.
RP Georg, G (corresponding author), Ctr Cordeliers, UMRS 872, Eq 20, Paris, France.
EM gersende.georg@spim.jussieu.fr; m.o.cavazza@tees.ac.uk;
   catherine.pelachaud@inria.fr
OI Cavazza, Marc/0000-0001-6113-9696
FU post-doctoral fellowship from "Region Ile-de-France"
FX Gersende Georg is partly funded through a post-doctoral fellowship from
   Region Ile-de-France. We thank all the medical experts from the French
   National Health Authority (HAS) and Inserm (French National Institute of
   Health) for their participation in data collection and in evaluation
   experiments.
CR ABBATTISTA F, 2003, LNCS LNAI, V2631
   ALLBECK J, 2003, LNCS LNAI, V2631
   Bickmore TW, 2007, LECT NOTES ARTIF INT, V4722, P183
   BICKMORE TW, 2005, CHI 05 HUM FACT COMP, P1212, DOI DOI 10.1145/1056808.1056879
   BOLINGER D, 1996, INTONATION ITS PART
   Burke MJ, 2002, ORGAN RES METHODS, V5, P159, DOI 10.1177/1094428102005002002
   Cassell J, 1999, MACHINE CONVERSATION
   Charon R, 2001, JAMA-J AM MED ASSOC, V286, P1897, DOI 10.1001/jama.286.15.1897
   Chovil N., 1991, RES LANG SOC INTERAC, V25, P163, DOI [10.1080/08351819109389361, DOI 10.1080/08351819109389361]
   Darwin C, 1904, EXPRESS EMOT MAN, DOI 10.1037/10001-000
   De Carolis B, 2004, COG TECH, P65
   de Rosis F, 2004, COG TECH, P271
   de Rosis F, 2006, J BIOMED INFORM, V39, P514, DOI 10.1016/j.jbi.2006.01.001
   DECAROLIS B, 2001, INT WORKSH IPNMD VER
   Georg G, 2007, DOCENG'07: PROCEEDINGS OF THE 2007 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P69
   Hirschberg, 1992, P INT C SPOK LANG PR, P867
   HOORN J, 2003, ANN M INT COMM ASS S
   Marsella S, 2004, COG TECH, P317
   Moulin B., 1990, Proceedings. The Third International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems (IEA/AIE 90), P1112
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   PELACHAUD C, 2005, ACM MULTIMEDIA, P683
   Piwek P, 2007, LECT NOTES ARTIF INT, V4722, P161
   Ploog D., 1979, HUMAN ETHOLOGY CLAIM, P169, DOI DOI 10.1007/978-1-4020-2783-33
   Poggi I, 1998, SPEECH COMMUN, V26, P5, DOI 10.1016/S0167-6393(98)00047-8
   POGGI I, 2003, GESTURES MEANING USE, P203
   Sackett DL, 1996, BRIT MED J, V312, P71, DOI 10.1136/bmj.312.7023.71
NR 26
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-540-85482-1
J9 LECT NOTES COMPUT SC
PY 2008
VL 5208
BP 380
EP +
PG 4
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BIM69
UT WOS:000260883100039
DA 2022-08-02
ER

PT C
AU Nakano, Y
   Rehm, M
AF Nakano, Yukiko
   Rehm, Matthias
BE Kurosu, M
TI Multimodal Corpus Analysis as a Method for Ensuring Cultural Usability
   of Embodied Conversational Agents
SO HUMAN CENTERED DESIGN, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 1st International Conference on Human Centered Design held at the 13th
   International Conference on Human Computer Interaction
CY JUL 19-24, 2009
CL San Diego, CA
DE Multimodal Corpora; Embodied Conversational Agents; Cultural Usability
ID NONVERBAL BEHAVIOR
AB In this paper we propose the method of multimodal corpus analysis to collect enough empirical data for modeling the behavior of embodied conversational agents. This is a prerequisite to ensure the usability of such complex interactive systems. So far, the development of embodied agents suffers from a lack of explicit usability methods. In most cases, the consideration of usability aspects is constrained to preliminary user tests at the end of the development process.
C1 [Nakano, Yukiko] Seikei Univ Tokyo, Fac Sci & Technol, Tokyo, Japan.
   [Rehm, Matthias] Univ Augsburg, Fac Appl Informat, Augsburg, Germany.
RP Nakano, Y (corresponding author), Seikei Univ Tokyo, Fac Sci & Technol, Tokyo, Japan.
EM y.nakano@st.seikei.ac.jp; rehm@informatik.uni-augsburg.de
FU German Research Foundation (DFG) [RE2619/2-1]; Japan Society for the
   Promotion of Science (JSPS) with a grant-in-aid for scientific research
   (C) [19500104]; European Community (EC) [4-027656-STP]
FX The work described in this paper was partially supported by the German
   Research Foundation (DFG) with research grant RE2619/2-1, the Japan
   Society for the Promotion of Science (JSPS) with a grant-in-aid for
   scientific research (C) (19500104),and by the European Community (EC) in
   the eCIRCUS project IST-4-027656-STP.
CR Caridakis G, 2007, LANG RESOUR EVAL, V41, P367, DOI 10.1007/s10579-007-9057-1
   Cassell J., 2000, EMBODIED CONVERSATIO
   Efron D., 1972, GESTURE RACE CULTURE
   GALLAHER PE, 1992, J PERS SOC PSYCHOL, V63, P133, DOI 10.1037/0022-3514.63.1.133
   GERT J, 2002, PEDERSEN G HOFSTEDE
   Hall, 1966, HIDDEN DIMENSION
   Hofstede GH., 2001, CULTURES CONSEQUENCE
   Jan D, 2007, LECT NOTES ARTIF INT, V4722, P45
   JOHNSON WL, 2004, P INSTIL ICALL NLP S
   Kipp M, 2007, LECT NOTES ARTIF INT, V4722, P15
   Lacobelli F, 2007, LECT NOTES ARTIF INT, V4722, P57
   Lee J, 2006, LECT NOTES ARTIF INT, V4133, P243
   McCrae R. R., 2002, 5 FACTOR MODEL PERSO
   McNeill D., 1992, HAND MIND WHAT GESTU
   NAKANO YI, 2003, P ASS COMP LING
   PETER E, 1987, B POSTURE GESTURE
   REHM M, HUMAN CENTR IN PRESS
   Rehm M, 2007, CONVERSATIONAL INFOR, P69
   Rehm M, 2007, P ISAGA 2007
   Rehm M, 2008, LECT NOTES COMPUT SC, V5208, P223
   Rehm M, 2008, LECT NOTES ARTIF INT, V4930, P1
   Ruttkay  Z., 2008, P IUI WORKSH ENC COV
   SCHWARTZ SH, 1995, J CROSS CULT PSYCHOL, V26, P92, DOI 10.1177/0022022195261007
   Warren R, 2005, Proceedings of the 2005 Winter Simulation Conference, Vols 1-4, P1109, DOI 10.1109/WSC.2005.1574366
   [No title captured]
NR 25
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-02805-2
J9 LECT NOTES COMPUT SC
PY 2009
VL 5619
BP 521
EP +
PG 3
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BKT51
UT WOS:000269188600060
OA Green Submitted
DA 2022-08-02
ER

PT C
AU Miyamoto, T
   Katagami, D
   Usami, M
AF Miyamoto, Tomoki
   Katagami, Daisuke
   Usami, Mayumi
BE Yada, K
   Katagami, D
   Takama, Y
   Ito, T
   Abe, A
   SatoShimokawara, E
   Mori, J
   Matsumura, N
   Kashima, H
TI A Politeness Control Method for Conversational Agents Considering Social
   Relationships with Users
SO ADVANCES IN ARTIFICIAL INTELLIGENCE
SE Advances in Intelligent Systems and Computing
LA English
DT Proceedings Paper
CT 34th Annual Conference of the
   Japanese-Society-for-Artificial-Intelligence (JSAI)
CY JUN 09-12, 2020
CL ELECTR NETWORK
SP Japanese Soc Artificial Intelligence
DE Conversational agents; Politeness theory; Social relationships
AB In this paper, we propose an autonomous linguistic consideration (politeness) control method for conversational agents. As an approach to realize the proposed method, we examined input information based on politeness theory in sociolinguistics that is considered to be effective for agents to control politeness. Specifically, we adapted a questionnaire study to evaluate the politeness and comfortableness of utterances in different situations of requests. The participants evaluated stimulus utterances in terms of three social factors on the politeness theory: social distance/social status difference/conversation scene. Based on the dataset collected in this questionnaire study, a regression modelwas constructed to predict the politeness and comfortableness rated by the participants of the experiment, adapted three social factors and politeness of utterances as explanatory variables. As a result of this questionnaire study and multiple regression analysis, a valid model of politeness was obtained. The results contribute as a model to select appropriate politeness of utterance according to three social factors on the politeness theory with the user in the proposed method.
C1 [Miyamoto, Tomoki; Katagami, Daisuke] Tokyo Polytech Univ, Grad Sch, Atsugi, Kanagawa 2430297, Japan.
   [Usami, Mayumi] Natl Inst Japanese Language & Linguist, Tachikawa, Tokyo 1900014, Japan.
RP Miyamoto, T (corresponding author), Tokyo Polytech Univ, Grad Sch, Atsugi, Kanagawa 2430297, Japan.
EM d1985001@st.t-kougei.ac.jp
RI 片上, 大輔/CAG-2553-2022
FU JSPS KAKENHI [JP 18H03581, 20H05572]
FX This work was supported by JSPS KAKENHI Grant Number JP 18H03581 and
   20H05572.
CR Brown Penelope, 1987, POLITENESS SOME UNIV
   HILL B, 1986, J PRAGMATICS, V10, P347, DOI 10.1016/0378-2166(86)90006-8
   Miyamoto T, 2017, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON HUMAN AGENT INTERACTION (HAI'17), P451, DOI 10.1145/3125739.3132585
   Osawa H, 2011, ARTIF LIFE ROBOT, V16, P78, DOI 10.1007/s10015-011-0891-2
   Potts, 2013, P 51 ANN M ASS COMP, V1, P250, DOI DOI 10.1017/CBO9780511615184.011
   Usami M., 2002, DISCOURSE POLITENESS
   Zojaji S, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423917
NR 7
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2194-5357
EI 2194-5365
BN 978-3-030-73113-7; 978-3-030-73112-0
J9 ADV INTELL SYST COMP
PY 2021
VL 1357
BP 224
EP 231
DI 10.1007/978-3-030-73113-7_22
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS8EG
UT WOS:000771716000022
DA 2022-08-02
ER

PT C
AU Piccini, R
   Spanakis, G
AF Piccini, Raffaele
   Spanakis, Gerasimos
BE Rocha, AP
   Steels, L
   VanDenHerik, J
TI Exploring the Context of Recurrent Neural Network based Conversational
   Agents
SO PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND
   ARTIFICIAL INTELLIGENCE (ICAART), VOL 2
LA English
DT Proceedings Paper
CT 11th International Conference on Agents and Artificial Intelligence
   (ICAART)
CY FEB 19-21, 2019
CL Prague, CZECH REPUBLIC
DE Conversational Agents; Recurrent Neural Networks; Hierarchical Recurrent
   Encoder Decoder
AB Conversational agents have begun to rise both in the academic (in terms of research) and commercial (in terms of applications) world. This paper investigates the task of building a non-goal driven conversational agent, using neural network generative models and analyzes how the conversation context is handled. It compares a simpler Encoder-Decoder with a Hierarchical Recurrent Encoder-Decoder architecture, which includes an additional module to model the context of the conversation using previous utterances information. We found that the hierarchical model was able to extract relevant context information and include them in the generation of the output. However, it performed worse (35-40%) than the simple Encoder-Decoder model regarding both grammatically correct output and meaningful response. Despite these results, experiments demonstrate how conversations about similar topics appear close to each other in the context space due to the increased frequency of specific topic-related words, thus leaving promising directions for future research and how the context of a conversation can be exploited.
C1 [Piccini, Raffaele; Spanakis, Gerasimos] Maastricht Univ, Dept Data Sci & Knowledge Engn, Maastricht, Netherlands.
RP Piccini, R (corresponding author), Maastricht Univ, Dept Data Sci & Knowledge Engn, Maastricht, Netherlands.
RI Spanakis, Gerasimos/AAF-2024-2020
OI Spanakis, Gerasimos/0000-0002-0799-0241
CR [Anonymous], 2015, P 24 ACM INT C INF K
   [Anonymous], 2017, ARXIV170107274
   Cho K., 2015, ARXIV, P103, DOI [10.3115/v1/w14-4012, DOI 10.3115/V1/W14-4012]
   Collobert R., 2008, P 25 INT C MACHINE L, V25, P160
   Manning C. D., 1999, FDN STAT NATURAL LAN
   Mikolov T., 2013, P ADV NEUR INF PROC, V26, P3111
   Mikolov T., 2013, ARXIV, V1301, P3781
   Serban IV, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3776
   Serban IV, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3295
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
NR 10
TC 0
Z9 0
U1 0
U2 1
PU SCITEPRESS
PI SETUBAL
PA AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL
BN 978-989-758-350-6
PY 2019
BP 347
EP 356
DI 10.5220/0007574203470356
PG 10
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR8FT
UT WOS:000671841000032
OA Green Submitted, hybrid
DA 2022-08-02
ER

PT J
AU Pejsa, T
   Andrist, S
   Gleicher, M
   Mutlu, B
AF Pejsa, Tomislav
   Andrist, Sean
   Gleicher, Michael
   Mutlu, Bilge
TI Gaze and Attention Management for Embodied Conversational Agents
SO ACM TRANSACTIONS ON INTERACTIVE INTELLIGENT SYSTEMS
LA English
DT Article
DE Embodied conversational agents; gaze model; attention; body orientation;
   learning; affiliation
ID EYE-HEAD COORDINATION; VISUAL-ATTENTION; MOVEMENT KINEMATICS; VIRTUAL
   CHARACTERS; SOCIAL ATTENTION; BEHAVIOR; SHIFTS; ORIENTATION; TARGETS;
   HUMANS
AB To facilitate natural interactions between humans and embodied conversational agents (ECAs), we need to endow the latter with the same nonverbal cues that humans use to communicate. Gaze cues in particular are integral in mechanisms for communication and management of attention in social interactions, which can trigger important social and cognitive processes, such as establishment of affiliation between people or learning new information. The fundamental building blocks of gaze behaviors are gaze shifts: coordinated movements of the eyes, head, and body toward objects and information in the environment. In this article, we present a novel computational model for gaze shift synthesis for ECAs that supports parametric control over coordinated eye, head, and upper body movements. We employed the model in three studies with human participants. In the first study, we validated the model by showing that participants are able to interpret the agent's gaze direction accurately. In the second and third studies, we showed that by adjusting the participation of the head and upper body in gaze shifts, we can control the strength of the attention signals conveyed, thereby strengthening or weakening their social and cognitive effects. The second study shows that manipulation of eye-head coordination in gaze enables an agent to convey more information or establish stronger affiliation with participants in a teaching task, while the third study demonstrates how manipulation of upper body coordination enables the agent to communicate increased interest in objects in the environment.
C1 [Pejsa, Tomislav; Andrist, Sean; Gleicher, Michael; Mutlu, Bilge] Univ Wisconsin, Dept Comp Sci, 1210 W Dayton St, Madison, WI 53706 USA.
RP Pejsa, T (corresponding author), Univ Wisconsin, Dept Comp Sci, 1210 W Dayton St, Madison, WI 53706 USA.
EM tpejsa@cs.wisc.edu; sandrist@cs.wisc.edu; gleicher@cs.wisc.edu;
   bilge@cs.wisc.edu
FU National Science Foundation [1017952]; Direct For Computer & Info Scie &
   Enginr [1162037, 1208632] Funding Source: National Science Foundation
FX Parts of this work were published in Proceedings of CHI 2012 [Andrist et
   al. 2012a] and Proceedings of the 4th ICMI Workshop on Eye Gaze in
   Intelligent Human Machine Interaction [Andrist et al. 2012b]. This work
   was supported by National Science Foundation award 1017952.
CR Alkan Y, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025866
   ANDREDESHAYS C, 1988, EXP BRAIN RES, V69, P399
   Andrist Sean, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P249, DOI 10.1007/978-3-642-40415-3_22
   Andrist S., 2012, P SIGCHI C HUM FACT, P705, DOI [10.1145/2207676.2207777, DOI 10.1145/2207676.2207777]
   Andrist S., 2012, P 4 ICMI WORKSH EYE, P4
   Argyle M., 1976, GAZE MUTUAL GAZE
   BAHILL A T, 1975, Mathematical Biosciences, V24, P191, DOI 10.1016/0025-5564(75)90075-9
   Bailly G, 2010, SPEECH COMMUN, V52, P598, DOI 10.1016/j.specom.2010.02.015
   BARNES GR, 1979, J PHYSIOL-LONDON, V287, P127, DOI 10.1113/jphysiol.1979.sp012650
   Beebe Steven A, 1976, THESIS
   Bentivoglio AR, 1997, MOVEMENT DISORD, V12, P1028, DOI 10.1002/mds.870120629
   BURGOON JK, 1986, HUM COMMUN RES, V12, P495, DOI 10.1111/j.1468-2958.1986.tb00089.x
   Cafaro A, 2009, LECT NOTES ARTIF INT, V5773, P250, DOI 10.1007/978-3-642-04380-2_28
   Cassell J, 1999, SPRING INT SER ENG C, V511, P143
   D'Entremont B., 2007, GAZE FOLLOWING ITS D, P77
   EVINGER C, 1994, EXP BRAIN RES, V100, P337
   Fox J, 2009, SEX ROLES, V61, P147, DOI 10.1007/s11199-009-9599-3
   Freedman EG, 2000, EXP BRAIN RES, V131, P22, DOI 10.1007/s002219900296
   Frischen A, 2007, PSYCHOL BULL, V133, P694, DOI 10.1037/0033-2909.133.4.694
   FRY R, 1975, J SOC PSYCHOL, V96, P145, DOI 10.1080/00224545.1975.9923275
   FULLER JH, 1992, EXP BRAIN RES, V92, P152
   Fullwood C, 2006, APPL ERGON, V37, P167, DOI 10.1016/j.apergo.2005.05.003
   Garau M., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P309
   GOLDBERG GN, 1969, SOCIOMETRY, V32, P43, DOI 10.2307/2786633
   Goldring JE, 1996, EXP BRAIN RES, V111, P68
   Goossens HHLM, 1997, EXP BRAIN RES, V114, P542, DOI 10.1007/PL00005663
   Griffin ZM, 2001, COGNITION, V82, pB1, DOI 10.1016/S0010-0277(01)00138-X
   Grillon H, 2009, COMPUT ANIMAT VIRT W, V20, P111, DOI 10.1002/cav.293
   Gu E, 2006, LECT NOTES ARTIF INT, V4133, P193
   GUITTON D, 1987, J NEUROPHYSIOL, V58, P427, DOI 10.1152/jn.1987.58.3.427
   Harris MJ, 2005, CLAR SYMP, P157
   Heck R. M., 2007, THESIS
   Heylen D., 2002, P INT CLASS WORKSH N, P93
   Hietanen JK, 2002, PSYCHOL RES-PSYCH FO, V66, P174, DOI 10.1007/s00426-002-0091-8
   Hietanen JK, 1999, NEUROREPORT, V10, P3443, DOI 10.1097/00001756-199911080-00033
   Hollands MA, 2004, EXP BRAIN RES, V154, P261, DOI 10.1007/s00221-003-1718-8
   Ishiguro, 2012, ACM T INTERACT INTEL, V1, P12, DOI [10.1145/2070719.2070725, DOI 10.1145/2070719.2070725]
   Kelley D. H., 1988, COMMUNICATION ED, V37, P3
   Kendon A., 1973, SOCIAL COMMUNICATION, P29
   Kendon A, 2010, LECT NOTES COMPUT SC, V5967, P1
   Khullar SC, 2001, AUTON AGENT MULTI-AG, V4, P9, DOI 10.1023/A:1010010528443
   Kim KH, 2007, COMPUT BIOL MED, V37, P1009, DOI 10.1016/j.compbiomed.2006.08.019
   Kittur A, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P453
   Kuzuoka H, 2010, ACMIEEE INT CONF HUM, P285, DOI 10.1109/HRI.2010.5453182
   Lance BJ, 2010, IEEE COMPUT GRAPH, V30, P62, DOI 10.1109/MCG.2010.43
   Langton SRH, 2000, TRENDS COGN SCI, V4, P50, DOI 10.1016/S1364-6613(99)01436-9
   Lee J, 2007, LECT NOTES ARTIF INT, V4722, P296
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   Liu, 2009, P 2009 INT C MULT IN, P241, DOI [10.1145/1647314.1647367, DOI 10.1145/1647314.1647367]
   Liu C., 2011, P 2 WORKSH EYE GAZ I
   Lusk MM, 2007, APPL COGNITIVE PSYCH, V21, P747, DOI 10.1002/acp.1347
   McCluskey MK, 2007, J NEUROPHYSIOL, V97, P2976, DOI 10.1152/jn.00822.2006
   MEHRABIAN A, 1966, J PERS, V34, P26, DOI 10.1111/j.1467-6494.1966.tb01696.x
   Meyer AS, 1998, COGNITION, V66, pB25, DOI 10.1016/S0010-0277(98)00009-2
   Mumm J, 2011, COMPUT HUM BEHAV, V27, P1643, DOI 10.1016/j.chb.2011.02.002
   Mutlu B, 2006, IEEE-RAS INT C HUMAN, P518, DOI 10.1109/ichr.2006.321322
   Nakano YI, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P553
   OTTESON JP, 1980, PERCEPT MOTOR SKILL, V50, P35, DOI 10.2466/pms.1980.50.1.35
   Pejsa T, 2010, COMPUT GRAPH FORUM, V29, P202, DOI 10.1111/j.1467-8659.2009.01591.x
   Pejsa T, 2013, COMPUT GRAPH FORUM, V32, P143, DOI 10.1111/cgf.12034
   Pelachaud C, 2003, LECT NOTES ARTIF INT, V2792, P93
   Pelz J, 2001, EXP BRAIN RES, V139, P266, DOI 10.1007/s002210100745
   PERRETT DI, 1994, CAH PSYCHOL COGN, V13, P683
   Peters C, 2010, COMPUT GRAPH-UK, V34, P677, DOI 10.1016/j.cag.2010.09.007
   Pomianowska I., 2011, FRONTIERS INTEGRATIV, V6, P4
   SCAIFE M, 1975, NATURE, V253, P265, DOI 10.1038/253265a0
   Schegloff EA, 1998, SOC RES, V65, P535
   SHERWOOD JV, 1987, PERCEPT MOTOR SKILL, V64, P1275, DOI 10.2466/pms.1987.64.3c.1275
   Tartaro A., 2007, CHI 07 HUM FACT COMP, P1677
   Teasley S.D., 1991, PERSPECTIVES SOCIALL
   Thiebaux M., 2009, P 8 INT C AUT AG MUL, V1, P321
   UEMURA T, 1980, ACTA OTO-LARYNGOL, V90, P191, DOI 10.3109/00016488009131715
   Woodward A. L, 2005, JOINT ATTENTION COMM, P110
   ZANGEMEISTER WH, 1982, EXP NEUROL, V77, P563, DOI 10.1016/0014-4886(82)90228-X
   [No title captured]
NR 75
TC 15
Z9 15
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 2160-6455
EI 2160-6463
J9 ACM T INTERACT INTEL
JI ACM Trans. Interact. Intell. Syst.
PD MAR
PY 2015
VL 5
IS 1
DI 10.1145/2724731
PG 34
WC Computer Science, Artificial Intelligence
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA CP7SK
UT WOS:000360088100003
DA 2022-08-02
ER

PT C
AU Griol, D
   Garcia-Herrero, J
   Molina, JM
AF Griol, David
   Garcia-Herrero, Jesus
   Molina, Jose M.
BE Novais, P
   Preuveneers, D
   Corchado, JM
TI The EducAgent Platform: Intelligent Conversational Agents for E-Learning
   Applications
SO AMBIENT INTELLIGENCE: SOFTWARE AND APPLICATIONS
SE Advances in Intelligent and Soft Computing
LA English
DT Proceedings Paper
CT 2nd International Symposium on Ambient Intelligence: Software and
   Applications
CY APR 06-08, 2011
CL Salamanca, SPAIN
DE Conversational Agents; E-Learning; Oral Interaction; Intelligent Agents;
   Education and New Technologies
AB In this paper, we describe a multi-agent system developed for teaching support and student's self-learning. The main objective of the EducAgent platform is the creation of an innovative virtual space following the principles of the European Higher Education Area to make subjects and e-learning initiatives to become a more flexible, participatory and attractive space. One of the most important characteristics of the developed platform is to facilitate a more natural interaction between the system and students by means of conversational agents. We describe the main features of the EducAgent platform and its application in the new European Computer Science Degree at the Carlos III University of Madrid.
C1 [Griol, David; Garcia-Herrero, Jesus; Molina, Jose M.] Univ Carlos III Madrid, Grp Appl Artificial Intelligence GIAA, Dept Comp Sci, E-28903 Getafe, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Grp Appl Artificial Intelligence GIAA, Dept Comp Sci, E-28903 Getafe, Spain.
EM david.griol@uc3m.es; jesus.garcia@uc3m.es; josemanuel.molina@uc3m.es
RI Herrero, Jesús García/B-7135-2018; Griol, David/L-1258-2014; Molina,
   JOSE/B-1956-2008
OI Herrero, Jesús García/0000-0003-1768-2688; Griol,
   David/0000-0001-6266-5321; Molina, JOSE/0000-0002-7484-7357
CR Augusto J., 2009, ITALICS, V8, P53, DOI DOI 10.11120/ITAL.2009.08020053
   CAVAZZA M, 2010, AAMAS, P01629
   FRYER L, 2006, LANGUAGE LEARNING TE, V10, P814
   Griol D, 2008, SPEECH COMMUN, V50, P666, DOI 10.1016/j.specom.2008.04.001
   Kerly A, 2009, APPLICATIONS AND INNOVATIONS IN INTELLIGENT SYSTEMS XVI, P169
   McTear M. F., 2004, SPOKEN DIALOGUE TECH
   Pon-Barry Heather, 2006, INT J ARTIFICIAL INT, V16, P171
   RODA C, 2001, P BOTSHOW 2001 C, P17
   Wang YH, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P1023
NR 9
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 1867-5662
BN 978-3-642-19936-3
J9 ADV INTEL SOFT COMPU
PY 2011
VL 92
BP 117
EP 124
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BVF20
UT WOS:000291365300015
DA 2022-08-02
ER

PT C
AU Griol, D
   de Miguel, AS
   Molina, JM
AF Griol, David
   Sanchis de Miguel, Araceli
   Manuel Molina, Jose
BE Corchado, E
   Lozano, JA
   Quintian, H
   Yin, H
TI Giving Voice to the Internet by Means of Conversational Agents
SO INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2014
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 15th International Conference on Intelligent Data Engineering and
   Automated Learning (IDEAL)
CY SEP 10-12, 2014
CL Salamanca, SPAIN
SP IEEE Spain Sec, IEEE Syst Man & Cybernet Soc Spanish Chapter, AEPIA, Univ Salamanca, RACE Project
DE Conversational Agents; Spoken Interaction; POMDPs; Machine Learning;
   User Modeling; Neural Networks
AB In this paper we present a proposal to develop conversational agents that avoids the effort of manually defining the dialog strategy for the agent and also takes into account the benefits of using current standards. In our proposal the dialog manager is trained by means of a POMDP-based methodology using a labeled dialog corpus automatically acquired using a user modeling technique. The statistical dialog model automatically selects the next system response. Thus, system developers only need to define a set of files, each including a system prompt and the associated grammar to recognize user responses. We have applied this technique to develop a conversational agent in VoiceXML that provides information for planning a trip.
C1 [Griol, David; Sanchis de Miguel, Araceli; Manuel Molina, Jose] Univ Carlos III Madrid, Leganes 28911, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Avda Univ 30, Leganes 28911, Spain.
EM david.griol@uc3m.es; araceli.sanchis@uc3m.es; josemanuel.molina@uc3m.es
RI Griol, David/L-1258-2014; Molina, JOSE/B-1956-2008
OI Griol, David/0000-0001-6266-5321; Molina, JOSE/0000-0002-7484-7357
CR Griol D, 2013, AI COMMUN, V26, P355, DOI 10.3233/AIC-130573
   Levin E, 2000, IEEE T SPEECH AUDI P, V8, P11, DOI 10.1109/89.817450
   McTear M. F., 2004, SPOKEN DIALOGUE TECH
   Pieraccini R, 2012, VOICE IN THE MACHINE: BUILDING COMPUTERS THAT UNDERSTAND SPEECH, P1
   Pietquin O, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P545
   Rouillard Jose, 2007, Journal of Networks, V2, P27, DOI 10.4304/jnw.2.1.27-35
   Schatzmann J, 2006, KNOWL ENG REV, V21, P97, DOI 10.1017/S0269888906000944
   Thomson B., 2007, P WORKSH BRIDG GAP A, P9
   Young S, 2007, INT CONF ACOUST SPEE, P149
NR 9
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-319-10840-7; 978-3-319-10839-1
J9 LECT NOTES COMPUT SC
PY 2014
VL 8669
BP 441
EP 448
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BB7AS
UT WOS:000345286100053
OA Green Accepted
DA 2022-08-02
ER

PT C
AU Xu, Y
   Warschauer, M
AF Xu, Ying
   Warschauer, Mark
GP Assoc Comp Machinery
TI Young Children's Reading and Learning with Conversational Agents
SO CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI
   CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY MAY 04-09, 2019
CL Glasgow, SCOTLAND
SP Assoc Comp Machinery, ACM SIGCHI
DE Conversational agents; natural language processing; artificial
   intelligence; dialogic reading; young children; social interaction
AB Young children increasingly interact with voice-driven interfaces, such as conversational agents (CAs). The social nature of CAs makes them good learning partners for children. We have designed a storytelling CA to engage children in book reading activities. This case study presents the design of this CA and investigates children's interactions with and perception of the CA. Through observation, we found that children actively responded to the CA's prompts, reacted to the CA's feedback with great affect, and quickly learned the schema of interacting with a digital interlocutor. We also discovered that the availability of scaffolding appeared to facilitate child-CA conversation and learning. A brief post-reading interview suggested that children enjoyed their interaction with the CA. Design implications for dialogic systems for young children's informal learning are discussed.
C1 [Xu, Ying; Warschauer, Mark] Univ Calif Irvine, Irvine, CA 92697 USA.
RP Xu, Y (corresponding author), Univ Calif Irvine, Irvine, CA 92697 USA.
EM ying.xu@uci.edu; markw@uci.edu
CR Chen NS, 2011, COMPUT EDUC, V57, P1705, DOI 10.1016/j.compedu.2011.03.013
   Cheng Y, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P337, DOI 10.1145/3202185.3202749
   DIXONKRAUSS LA, 1995, J READING BEHAV, V27, P45, DOI 10.1080/10862969509547868
   Druga S, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P595, DOI 10.1145/3078072.3084330
   Levinson SC, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00731
   Tewari A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1807, DOI 10.1145/2556288.2557205
   Woodward Julia, 2018, P 2018 CHI C HUM FAC
   Yarosh S, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P300, DOI 10.1145/3202185.3202207
NR 8
TC 21
Z9 23
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5971-9
PY 2019
DI 10.1145/3290607.3299035
PG 8
WC Computer Science, Cybernetics; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BN4JW
UT WOS:000482042100061
DA 2022-08-02
ER

PT C
AU O'Shea, K
   Bandar, Z
   Crockett, K
AF O'Shea, Karen
   Bandar, Zuhair
   Crockett, Keeley
BE Ao, SI
   Gelman, L
   Hukins, DWL
   Hunter, A
   Korsunsky, AM
TI Novel approach for constructing conversational agents using sentence
   similarity measures
SO WORLD CONGRESS ON ENGINEERING 2008, VOLS I-II
SE Lecture Notes in Engineering and Computer Science
LA English
DT Proceedings Paper
CT World Congress on Engineering 2008
CY JUL 02-04, 2008
CL Imperial Coll London, London, ENGLAND
SP Int Assoc Engineers
HO Imperial Coll London
DE Conversational Agents; natural language processing; pattern matching;
   semantic nets; sentence similarity
AB This paper is concerned with the design of a novel approach for constructing Conversational Agents (CA) using sentence similarity measures. Most CA's scripts are organized into contexts consisting of a number of hierarchically organized rules. Each rule possesses a list of structural patterns of sentences and an associated response. User input is then matched against the patterns and the pre-determined response is sent as output. The huge overhead and maintenance of these CAs undoubtedly suggest scope for alternative approaches. In the proposed approach, sentence similarity measures are employed to examine scripts consisting of natural language sentences. This CA will be evaluated against an existing pattern-scripted CA using a set of domain-specific user utterances. Results indicate a substantial reduction of the proposed CA's knowledge-base and, thus, overall maintenance.
C1 [O'Shea, Karen; Bandar, Zuhair; Crockett, Keeley] Manchester Metropolitan Univ, Dept Comp & Math, Intelligent Syst Grp, Manchester M1 5GD, Lancs, England.
RP O'Shea, K (corresponding author), Manchester Metropolitan Univ, Dept Comp & Math, Intelligent Syst Grp, Chester St, Manchester M1 5GD, Lancs, England.
EM k.oshea@mmu.ac.uk; z.bandar@mmu.ac.uk; k.crockett@mmu.ac.uk
CR Colby K, 1975, ARTIFICIAL PARANOIA
   COLE R, 1999, NEU TOOLS INTERACTIV
   Landauer TK, 1998, ADV NEUR IN, V10, P45
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   Li YH, 2003, IEEE T KNOWL DATA EN, V15, P871, DOI 10.1109/TKDE.2003.1209005
   Li YH, 2006, IEEE T KNOWL DATA EN, V18, P1138, DOI 10.1109/TKDE.2006.130
   MASSARO DW, 1998, DEV EVALUATING CONVE
   MICHIE D, 2001, ELECT T ARTIFICIAL I
   Michie D., 2001, INFOCHAT SCRIPTERS M
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Roda C., 2001, CONVERSATIONAL AGENT
   Sammut C, 2001, ELECT T ARTIFICIAL I, V3, P1
   Sanders GA, 2000, EMBODIED CONVERSATIONAL AGENTS, P346
   Turing AM., 1950, J MIND ASS, V59, P433, DOI [10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
NR 15
TC 10
Z9 10
U1 0
U2 0
PU INT ASSOC ENGINEERS-IAENG
PI HONG KONG
PA UNIT 1, 1-F, 37-39 HUNG TO ROAD, KWUN TONG, HONG KONG, 00000, PEOPLES R
   CHINA
SN 2078-0958
BN 978-988-98671-9-5
J9 LECT NOTES ENG COMP
PY 2008
BP 321
EP 326
PG 6
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Multidisciplinary; Engineering, Electrical &
   Electronic; Mathematics, Applied
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Mathematics
GA BIH83
UT WOS:000259580600059
DA 2022-08-02
ER

PT J
AU Russo, A
   D'Onofrio, G
   Gangemi, A
   Giuliani, F
   Mongiovi, M
   Ricciardi, F
   Greco, F
   Cavallo, F
   Dario, P
   Sancarlo, D
   Presutti, V
   Greco, A
AF Russo, Alessandro
   D'Onofrio, Grazia
   Gangemi, Aldo
   Giuliani, Francesco
   Mongiovi, Misael
   Ricciardi, Francesco
   Greco, Francesca
   Cavallo, Filippo
   Dario, Paolo
   Sancarlo, Daniele
   Presutti, Valentina
   Greco, Antonio
TI Dialogue Systems and Conversational Agents for Patients with Dementia:
   The Human-Robot Interaction
SO REJUVENATION RESEARCH
LA English
DT Article
DE human-robot interaction; natural language processing; spoken dialogue
   systems; conversational agents; socially assistive robotics
ID SPEECH RECOGNITION; DISEASE
AB This study aimed to identify and describe the fundamental characteristics of spoken dialogue systems, and their role in supporting human-robot interaction and enabling the communication between socially assistive robots and patients with dementia. First, this work provides an overview of spoken dialogue systems by considering the underlying technologies, approaches, methods, and general issues. Then, the analysis focuses on studies, systems, and approaches that have investigated the role of dialogue systems and conversational agents in the interaction with elderly people with dementia by presenting the results of a literature review. While the overview of spoken dialogue systems relies on existing surveys and reviews, a research was conducted to identify existing works in the literature that have investigated the role of conversational agents and dialogue systems in the elderly and people with cognitive impairments. Inclusion criteria were as follows: (1) use of conversational agents, dialogue systems, or language processing tools for people with cognitive impairments; (2) age 60 years; (3) diagnosis of dementia according to National Institute on Aging-Alzheimer's Association (NIAAA) criteria; (4) presence of tests or experiments with qualitative or quantitative results. Initially 125 studies published between 2000 and 2017 were identified, of which 12 met the inclusion criteria. The review identifies the issues and challenges that are reported when conversational agents and speech-based interfaces have been used for interacting with people with cognitive impairments. In addition, the review led to the identification of studies that have investigated speech processing and natural language processing capabilities to assess the cognitive status of people with dementia.
C1 [Russo, Alessandro; Gangemi, Aldo; Mongiovi, Misael; Presutti, Valentina] Natl Res Council CNR, Inst Cognit Sci & Technol ISTC, Semant Technol Lab, STLab, Rome, Italy.
   [D'Onofrio, Grazia; Greco, Francesca; Sancarlo, Daniele; Greco, Antonio] IRCCS Casa Sollievo Sofferenza, Dept Med Sci, Complex Struct Geriatr, San Giovanni Rotondo, Italy.
   [D'Onofrio, Grazia; Cavallo, Filippo; Dario, Paolo] Scuola Super Sant Anna, BioRobot Inst, Pontedera, Italy.
   [Giuliani, Francesco; Ricciardi, Francesco] IRCCS Casa Sollievo Sofferenza, Innovat & Res Unit, ICT, San Giovanni Rotondo, Italy.
RP D'Onofrio, G (corresponding author), IRCCS Casa Sollievo Sofferenza, Dept Med Sci, Complex Unit Geriatr, Viale Cappuccini 1, I-71030 San Giovanni Rotondo, FG, Italy.
EM g.donofrio@operapadrepio.it
RI Mongiovì, Misael/GNP-0059-2022; Gangemi, Aldo/C-7420-2013; Greco,
   Antonio/C-1100-2017; Ricciardi, Francesco/B-2603-2017; D'Onofrio,
   Grazia/J-5619-2019; Sancarlo, Daniele/C-1056-2017
OI Mongiovì, Misael/0000-0003-0528-5490; Gangemi, Aldo/0000-0001-5568-2684;
   Greco, Antonio/0000-0001-6674-5468; Ricciardi,
   Francesco/0000-0003-0068-9912; D'Onofrio, Grazia/0000-0002-5905-6063;
   Sancarlo, Daniele/0000-0001-9541-6364; Greco, Francesca
   Romana/0000-0002-8423-1062
FU European Union Horizon 2020-the Framework Programme for Research and
   Innovation (2014-2020) under Project MARIO "Managing active and healthy
   aging with use of caring service robots'' [643808]
FX The research leading to these results has received funding from the
   European Union Horizon 2020-the Framework Programme for Research and
   Innovation (2014-2020) under grant agreement 643808 Project MARIO
   "Managing active and healthy aging with use of caring service robots.''
CR American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU, V5th ed., DOI [https://doi.org/10.1176/appi.books.9780890425596, DOI 10.1176/APPI.BOOKS.9780890425596]
   [Anonymous], 2001, AIML ARTIFICIAL INTE
   Bastianelli E, 2014, FRONT ARTIF INTEL AP, V263, P57, DOI 10.3233/978-1-61499-419-0-57
   Berg MM, 2015, LECT NOTES COMPUT SC, V9103, P144, DOI 10.1007/978-3-319-19581-0_12
   Bruno Barbara, 2013, 2013 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), P768, DOI 10.1109/ROMAN.2013.6628406
   Bunt H., 2017, MULTIMODAL INTERACT, P109
   COLBY KM, 1971, ARTIF INTELL, V2, P1, DOI 10.1016/0004-3702(71)90002-6
   Deng L, 2013, IEEE T AUDIO SPEECH, V21, P1060, DOI 10.1109/TASL.2013.2244083
   Dingli A, 2013, LECT NOTES COMPUT SC, V8082, P145, DOI 10.1007/978-3-642-40585-3_19
   FILLMORE CJ, 1976, ANN NY ACAD SCI, V280, P20, DOI 10.1111/j.1749-6632.1976.tb25467.x
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   Gales M, 2007, FOUND TRENDS SIGNAL, V1, P195, DOI 10.1561/2000000004
   Gorin AL, 1997, SPEECH COMMUN, V23, P113, DOI 10.1016/S0167-6393(97)00040-X
   Granata C, 2010, 2010 IEEE RO-MAN, P785, DOI 10.1109/ROMAN.2010.5598698
   Heerink M, 2006, IEEE INT S ROB HUM I, P521, DOI DOI 10.1109/ROMAN.2006.314442
   Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685
   Huang H, 2012, 2012 INTERNATIONAL CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (LCWAMTIP), P295, DOI 10.1109/ICWAMTIP.2012.6413497
   Huang J, 2015, LECT NOTES COMPUT SC, V9085, P133, DOI 10.1007/978-3-319-19156-0_14
   Ireland D, 2015, STUD HEALTH TECHNOL, V214, P128, DOI 10.3233/978-1-61499-558-6-128
   Kitchenham B, 2007, GUIDELINES PERFORMIN
   Kluwer T, 2011, CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND EFFECTIVE PRACTICES, P1, DOI 10.4018/978-1-60960-617-6.ch001
   Larsson S., 2000, Natural Language Engineering, P323, DOI 10.1017/S1351324900002539
   Lopez-Cozar R, 2014, LOQUENS, V1, DOI 10.3989/loquens.2014.012
   Mariani J, 2013, NATURAL INTERACTION
   MAULDIN ML, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P16
   Mavridis N, 2015, ROBOT AUTON SYST, V63, P22, DOI 10.1016/j.robot.2014.09.031
   McKhann GM, 2011, ALZHEIMERS DEMENT, V7, P263, DOI 10.1016/j.jalz.2011.03.005
   McTear M. F., 2004, SPOKEN DIALOGUE TECH
   McTear MF, 2002, ACM COMPUT SURV, V34, P90, DOI 10.1145/505282.505285
   Moller S., 2010, QUALITY TELEPHONE BA
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P587
   Nonaka Yuko, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P496, DOI 10.1007/978-3-642-33197-8_57
   Peltason J, 2010, P SIGDIAL 2010 C
   Rieser V, 2014, IEEE-ACM T AUDIO SPE, V22, P979, DOI 10.1109/TASL.2014.2315271
   Roark B, 2011, IEEE T AUDIO SPEECH, V19, P2081, DOI 10.1109/TASL.2011.2112351
   Roukos S, 2008, SPRINGER HDB SPEECH, P617
   Roy N., 2000, P WORKSH INT ROB ENT WORKSH INT ROB ENT W, VVolume 25, P184, DOI DOI 10.1007/s12369-014-0232-4
   Sadohara K., 2013, P 4 WORKSH SPEECH LA, P93
   Sakai Y, 2012, ACMIEEE INT CONF HUM, P199
   Shannon M, 2013, IEEE T AUDIO SPEECH, V21, P587, DOI 10.1109/TASL.2012.2227740
   Traum DR, 2003, TEXT SPEECH LANG TEC, V22, P325
   Vacher M, 2015, LECT NOTES COMPUT SC, V9194, P341, DOI 10.1007/978-3-319-20913-5_32
   Wallace RS, 2009, PARSING TURING TEST, P181, DOI DOI 10.1007/978-1-4020-6710-5_13
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   World Health Organization Dementia: Updated December, DEM UPD DEC 2017
   Xu W., 2000, P ANLP NAACL 2000 WO, P42, DOI DOI 10.3115/1117562.1117571
   Yaghoubzadeh Ramin, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P79, DOI 10.1007/978-3-642-40415-3_7
   Yasuda K, 2013, P 27 ANN C JSAI, VJSAI2013 3C1-IOS-1b-2
   Young S, 2013, P IEEE, V101, P1160, DOI 10.1109/JPROC.2012.2225812
   Yu D, 2015, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4471-5779-3
   Zue V, 2000, IEEE T SPEECH AUDI P, V8, P85, DOI 10.1109/89.817460
   Zue V, 2008, SPRINGER HDB SPEECH, P705
   Zue VW, 2000, P IEEE, V88, P1166, DOI 10.1109/5.880078
NR 54
TC 11
Z9 12
U1 3
U2 37
PU MARY ANN LIEBERT, INC
PI NEW ROCHELLE
PA 140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA
SN 1549-1684
EI 1557-8577
J9 REJUV RES
JI Rejuv. Res.
PD APR 1
PY 2019
VL 22
IS 2
BP 109
EP 120
DI 10.1089/rej.2018.2075
EA SEP 2018
PG 12
WC Geriatrics & Gerontology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Geriatrics & Gerontology
GA HU1QD
UT WOS:000445087400001
PM 30033861
OA Green Submitted
DA 2022-08-02
ER

PT C
AU Lipi, AA
   Nakano, Y
   Rehm, M
AF Lipi, Afia Akhter
   Nakano, Yukiko
   Rehm, Matthias
BE Stephanidis, C
TI A Parameter-Based Model for Generating Culturally Adaptive Nonverbal
   Behaviors in Embodied Conversational Agents
SO UNIVERSAL ACCESS IN HUMAN-COMPUTER INTERACTION, PT II, PROCEEDINGS:
   INTELLIGENT AND UBIQUITOUS INTERACTION ENVIRONMENTS
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 5th International Conference on Universal Access in Human-Computer
   Interaction held at the HCI International 2009
CY JUL 19-24, 2009
CL San Diego, CA
DE conversational agents; enculturate; nonverbal behaviors; Bayesian
   network
AB The goal of this paper is to integrate culture as a computational term in embodied conversational agents by employing an empirical data-driven approach as well as a theoretical model-driven approach. We propose a parameter-based model that predicts nonverbal expressions appropriate for specific cultures. First, we introduce the Hofstede theory to describe socio-cultural characteristics of each country. Then, based on the previous studies in cultural differences of nonverbal behaviors, we propose expressive parameters to characterize nonverbal behaviors. Finally, by integrating socio-cultural characteristics and nonverbal expressive characteristics, we establish a Bayesian network model that predicts posture expressiveness from a country name, and vice versa.
C1 [Lipi, Afia Akhter] Tokyo Univ Agr & Technol, Dept Comp & Informat Sci, Fuchu, Tokyo 183, Japan.
   [Nakano, Yukiko] Seikei Univ, Dept Comp & Informat Sci, Fuchu, Tokyo, Japan.
   [Rehm, Matthias] Augsburg Univ, Inst Comp Sci, Augsburg, Germany.
RP Lipi, AA (corresponding author), Tokyo Univ Agr & Technol, Dept Comp & Informat Sci, Fuchu, Tokyo 183, Japan.
EM 50007646211@st.tuat.ac.jp; y.nakano@st.seikei.ac.jp;
   rehm@informatik.uni-augsburg.de
FU German Research Foundation (DFG) [RE 2619/2-1]; Japan Society for the
   Promotion of Science (JSPS); Scientific Research [19500104]
FX This work is funded by the German Research Foundation (DFG) under
   research grant RE 2619/2-1 (CUBE-G) and the Japan Society for the
   Promotion of Science (JSPS) under a Grant-in-Aid for Scientific Research
   (C) (19500104).
CR Bull P. E, 1987, POSTURE GESTURE, V16
   Efron D., 1972, GESTURE RACE CULTURE
   GALLAHER PE, 1992, J PERS SOC PSYCHOL, P133
   Isbister K, 2004, AGENT CULTURE, P233
   JOHNSON WL, 2004, P INSTIL ICALL NLP S
   Lacobelli F, 2007, LECT NOTES ARTIF INT, V4722, P57
   LEE EJ, 1998, P WORKSH EMB CONV CH
   MANIAR N, 2007, P ACE 2007, P252
   Nass C, 2000, EMBODIED CONVERSATIONAL AGENTS, P374
   Pelachaud, 2005, P 4 INT JOINT C AUT, DOI [10.1145/1082473.1082640, DOI 10.1145/1082473.1082640]
   REHM M, 2008, P WORKSH ENC CONV IN
   REHM M, 2007, P 2 INT WORKSH HUM C
   Ting-Toomey S., 1999, COMMUNICATION CULTUR
NR 13
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-02709-3
J9 LECT NOTES COMPUT SC
PY 2009
VL 5615
BP 631
EP +
PG 3
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BME59
UT WOS:000272028100070
OA Green Submitted
DA 2022-08-02
ER

PT C
AU Liao, QV
   Shmueli-Scheuer, M
   Wen, TH
   Yu, Z
AF Liao, Q. Vera
   Shmueli-Scheuer, Michal
   Wen, Tsung-Hsien (Shawn)
   Yu, Zhou
GP ACM
TI User-Aware Conversational Agents
SO PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER
   INTERFACES: COMPANION (IUI 2019)
LA English
DT Proceedings Paper
CT 24th International Conference on Intelligent User Interfaces (IUI)
CY MAR 17-20, 2019
CL Marina Del Rey, CA
SP Assoc Comp Machinery
DE conversational agent; chatbot; dialog; user modeling; adaptation;
   personalization
AB Conversational agents are becoming increasingly popular. These systems present an extremely rich and challenging research space for addressing many aspects of user awareness and adaptation, such as user profiles, contexts, personalities, emotions, social dynamics, conversational styles, etc. Adaptive interfaces are of long-standing interest for the HCI community. Meanwhile, new machine learning approaches are introduced in the current generation of conversational agents, such as deep learning, reinforcement learning, and active learning. It is imperative to consider how various aspects of user-awareness should be handled by these new techniques. The goal of this workshop is to bring together researchers in HCI, user modeling, and the AI and NLP communities from both industry and academia, who are interested in advancing the state-of-the-art on the topic of user-aware conversational agents. Through a focused and open exchange of ideas and discussions, we will work to identify central research topics in user-aware conversational agents and develop a strong interdisciplinary foundation to address them.
C1 [Liao, Q. Vera] IBM Res AI, Yorktown Hts, NY 10598 USA.
   [Shmueli-Scheuer, Michal] IBM Res AI, Haifa, Israel.
   [Wen, Tsung-Hsien (Shawn)] PolyAI, Cambridge, England.
   [Yu, Zhou] Univ Calif Davis, Davis, CA 95616 USA.
RP Liao, QV (corresponding author), IBM Res AI, Yorktown Hts, NY 10598 USA.
EM vera.liao@ibm.com; shmueli@il.ibm.com; shawnwen@poly-ai.com;
   joyu@ucdavis.edu
NR 0
TC 2
Z9 2
U1 1
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6673-1
PY 2019
BP 133
EP 134
DI 10.1145/3308557.3313124
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP3BB
UT WOS:000546032800067
DA 2022-08-02
ER

PT C
AU Rojc, M
   Rotovnik, T
   Brus, M
   Jan, D
   Kacic, Z
AF Rojc, Matej
   Rotovnik, Tomaz
   Brus, Miso
   Jan, Dusan
   Kacic, Zdravko
BE Esposito, A
   FaundezZanuy, M
   Keller, E
   Marinaro, M
TI Embodied conversational agents in Wizard-of-Oz and multimodal
   interaction applications
SO VERBAL AND NONVERBAL COMMUNICATION BEHAVIOURS
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT International Workshop on Verbal and Nonverbal Communication Behaviours
CY MAR 29-31, 2007
CL Vietri sul Mare, ITALY
SP European COST Action 2102, Second Univ Naples, Fac Psychol, Second Univ Naples, Fac Sci, Int Inst Adv Sci Studies, Reg Campania, Provincia Salerno
DE conversational agents; speech recognition; text-to-speech synthesis;
   speech-to-speech translation
AB Embodied conversational agents employed in multimodal interaction applications have the potential to achieve similar properties as humans in face-to-face conversation. They enable the inclusion of verbal and nonverbal communication. Thus, the degree of personalization of the user interface is much higher than in other human-computer inter-faces. This, of course, greatly contributes to the naturalness and user friendliness of the interface, opening-up a wide area of possible applications. Two implementations of embodied conversational agents in human-computer interaction are presented in this paper: the first one in a Wizard-of-Oz application and the second in a dialogue system. In the Wizard-of-Oz application, the embodied conversational agent is applied in a way that it conveys the spoken information of the operator to the user with whom the operator communicates. Depending on the scenario of the application, the user may or not be aware of the operator's involvement. The operator can communicate with the user based on audio/visual, or only audio, communication. This paper describes an application setup, which enables distant communication with the user, where the user is unaware of the operator's involvement. A real-time viseme recognizer is needed to ensure a proper response from the agent. In addition, implementation of the embodied conversational agent Lili hosting an entertainment show, which is broadcast by RTV Slovenia, will be described in more detail. Employment of the embodied conversational agent as a virtual major-domo named Maja, within an intelligent ambience, using speech recognition system and TTS system PLATTOS, will be also described.
C1 [Rojc, Matej; Rotovnik, Tomaz; Kacic, Zdravko] Univ Maribor, Fac Elect Engn & Comp Sci, Maribor, Slovenia.
   [Brus, Miso; Jan, Dusan] Agito doo, Ljubljana, Slovenia.
RP Rojc, M (corresponding author), Univ Maribor, Fac Elect Engn & Comp Sci, Maribor, Slovenia.
EM matej.rojc@uni-mb.si; tomaz.rotovnik@uni-mb.si; kacic@uni-mb.si
RI Rojc, Matej/AAY-8563-2020
OI Rojc, Matej/0000-0002-2840-968X
CR Brill E., 1993, THESIS
   BULYKO I, 2001, P EUR
   Emmanuel R., 1997, FINITE STATE LANGUAG
   GAUVAIN JL, 1994, SPEECH COMMUN, V15, P21, DOI 10.1016/0167-6393(94)90038-8
   HOLZAPFEL M, 2000, THESIS
   KACIC Z, 2000, 2 INT C LANG RES EV, V2, P943
   MOHRI M, 1996, 34 M ASS COMP LING A
   MOHRI M, 1995, NATURAL LANGUAGE ENG, V1
   Ostendorf M., 2001, P ICASSP
   Rojc M., 2003, THESIS
   Rojc M, 2007, SPEECH COMMUN, V49, P230, DOI 10.1016/j.specom.2007.01.007
   SPENS KE, 2004, P IFHOH 7 WORLD C HE
   Sproat R., 1996, P 34 ANN M ASS COMP, P215
   Sproat R., 1998, MULTILINGUAL TEXT TO
   Taylor P, 2001, SPEECH COMMUN, V33, P153, DOI 10.1016/S0167-6393(00)00074-1
NR 15
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 978-3-540-76441-0
J9 LECT NOTES COMPUT SC
PY 2007
VL 4775
BP 294
EP +
PG 3
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BGZ23
UT WOS:000251471900026
DA 2022-08-02
ER

PT J
AU Lankes, M
   Bernhaupt, R
AF Lankes, Michael
   Bernhaupt, Regina
TI Using embodied conversational agents in video games to investigate
   emotional facial expressions
SO ENTERTAINMENT COMPUTING
LA English
DT Article
DE Embodied conversational agents; Emotion theory; Games; Research method
AB The perception of emotional facial expressions has been diligently studied in psychology for the last 40 years. The stimuli mainly used in these studies were photos or short film clips. Today, video games and their development frameworks allow researchers to design, model, and animate embodied conversational agents (ECAs). This research paper introduces an experimental setting to observe and measure the perception of facial expression performed by embodied conversational agents. The experimental setup is based on the research efforts of the psychologist Harald G. Wallbott and uses the CryENGINE to visualize the ECAs in various contextual settings. A new paradigm, coined "Interaction-Paradigm'', is integrated in the experimental setting, which is derived from the video-games domain. It utilizes the benefits of video games as a research tool: the setup grants participants an interactive experience of a given emotional situation, which allows the investigation of the perception process in a more realistic setting. In contrast to the traditional approaches in emotion theory research, the usage of video games ensures that situational aspects are not presented by simply showing subjects a piece of paper containing descriptions of a situation.
   Based on an extensive state of the art on using video games and games development frameworks in research, this article shows how to set up experiments using video game technology. The aim of the study is to establish a comparative experimental framework to analyze subjects' judgment on emotional stimuli in different context dimensions. The findings show that the importance of information channels changes, when people decide for the emotional quality of a situation. While in still images the majority of people bases the decision on the facial expression, rather than based on the text description, in interactive scenarios only 11.8% of the participants relied on the facial expressions, with the majority using the contextual description. We present the results of the experiment in detail and summarize how video games and games development frameworks can support research in the area of ECAs and emotion perception. (C) 2011 International Federation for Information Processing Published by Elsevier B.V. All rights reserved.
C1 [Lankes, Michael] Upper Austria Univ Appl Sci, Dept Digital Media, Softwarepk 11, A-4232 Hagenberg, Austria.
   [Bernhaupt, Regina] ICS, IRIT, F-31062 Toulouse 9, France.
RP Lankes, M (corresponding author), Upper Austria Univ Appl Sci, Dept Digital Media, Softwarepk 11, A-4232 Hagenberg, Austria.
EM michael.lankes@fh-hagenberg.at; regina.bernhaupt@irit.fr
OI Lankes, Michael/0000-0002-4098-8071
FU FH Hagenberg; ruwido; ICT&S Center Salzburg
FX This research was supported by the FH Hagenberg, ruwido, and the ICT&S
   Center Salzburg. We would like to thank the participants taking part in
   the study, the members of the ICT&S Center Salzburg, especially
   Professor Dr. Manfred Tscheligi and DI Thomas Mirlacher.
CR [Anonymous], 2008, BEEPA FRAPS REAL TIM
   Bainbridge WS, 2007, SCIENCE, V317, P472, DOI 10.1126/science.1146930
   Bartneck C., 2000, THESIS
   Bernhaupt R, 2010, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-1-84882-963-3
   Bickmore T., 2001, SIGCHI 01
   BICKMORE TW, 2005, CHI 05 HUM FACT COMP, P1212, DOI DOI 10.1145/1056808.1056879
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   Eckschlager M., 2005, ACE 05, P375
   Ellsworth P., 1972, EMOTION HUMAN FACE G, DOI DOI 10.1016/C2013-0-02458-9
   Epicgames, 2008, UNR DEV NETW
   Fagin Gary, 1990, ARTISTS COMPLETE GUI
   Fernandez-Dols J. M., 1997, STUDIES EMOTION SOCI, P275
   Fong T., 2003, SURVEY SOCIALLY INTE
   Hirsig R., 1990, SELF REFERENCING SOC, P143
   ISBISTER K, 2002, P AAMAS02 WORKSH EMB
   Kaiser S, 1996, P 9 C INT SOC RES EM, P276
   Kaiser S., 2001, PSYCHOL LEBENSQUALIT, P175
   Kriglstein S., 2005, CHI 2005, P2094, DOI DOI 10.1145/1056808.1057106
   Lankes M., 2007, P INT C ADV COMP ENT, P56
   Lankes M, 2010, HUM-COMPUT INT-SPRIN, P165, DOI 10.1007/978-1-84882-963-3_10
   Mahlke S, 2006, P CHI 06 HUM FACT CO, P1061, DOI [10.1145/1125451.1125653, DOI 10.1145/1125451.1125653]
   MANCINI M, 2004, NONVERBAL BEHAV EXPR
   Mandryk R. L., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1027
   McPherson J, 2007, BEHAV RES METHODS, V39, P876, DOI 10.3758/BF03192982
   Mcpherson J, 2008, BEHAV RES METHODS, V40, P969, DOI 10.3758/BRM.40.4.969
   Norman D. A., 2004, S FDN INT DES
   PELACHAUD C, 2005, MULTIMEDIA 05, P683
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Pruett C., 2008, EVOLUTION VIDEOGRAME
   Reeves B., 2003, CSLI LECT NOTES S
   Schiano D.J., 2004, C HUM FACT COMP SYST, P49, DOI [DOI 10.1145/985692.985699, 10.1145/985692.985699]
   Summerfield A. B., 1986, EXPERIENCING EMOTION, P50
   V. Software, 2011, VALV SOFTW WEBS
   Wallbott H. G., 1990, MIMIK IM KONTEXT
NR 34
TC 5
Z9 5
U1 0
U2 0
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1875-9521
EI 1875-953X
J9 ENTERTAIN COMPUT
JI Entertain. Comput.
PY 2011
VL 2
IS 1
SI SI
BP 29
EP 37
DI 10.1016/j.entcom.2011.03.007
PG 9
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA V19VJ
UT WOS:000214846200006
DA 2022-08-02
ER

PT J
AU Griol, D
   Callejas, Z
AF Griol, David
   Callejas, Zoraida
TI Mobile Conversational Agents for Context-Aware Care Applications
SO COGNITIVE COMPUTATION
LA English
DT Article
DE Gerontechnology; Assistive technologies and devices; Mental health;
   Multimodal conversational agents; Mobile devices; Android
ID AUTOMATIC SPEECH RECOGNITION; SPOKEN DIALOGUE MANAGEMENT; DESIGN;
   SYSTEM; DIAGNOSIS
AB Smart mobile devices have fostered new interaction scenarios that demand sophisticated interfaces. The main developers of operating systems for such devices provide APIs for developers to implement their own applications, including different solutions for graphical interfaces, sensor control, and voice interaction. Despite the usefulness of such resources, there are no strategies defined for coupling the multimodal interface with the possibilities that the devices offer to identify and adapt to the user needs, which is particularly important in domains such as Ambient Assisted Living. In this paper, we propose a framework that allows developing context-aware multimodal conversational agents that dynamically incorporate user-specific requirements and preferences as well as characteristics about the interaction environment, in order to improve and personalize the service that is provided. Our proposal integrates the facilities of the Android API in a modular architecture that emphasizes interaction management and context-awareness to build user-adapted, robust and maintainable applications. As a proof of concept, we have used the proposed framework to develop an Android app for older adults suffering from Alzheimer's. The app helps them to preserve their cognitive abilities and enhance their relationship with their environment.
C1 [Griol, David] Univ Carlos III Madrid, Dept Comp Sci, Avda Univ 30, Leganes 28911, Spain.
   [Callejas, Zoraida] Univ Granada, Dept Languages & Comp Syst, CITIC UGR, C Pdta Daniel Saucedo Aranda S-N, E-18071 Granada, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Avda Univ 30, Leganes 28911, Spain.
EM dgriol@inf.uc3m.es; zoraida@ugr.es
RI Griol, David/L-1258-2014; Callejas, Zoraida/AAX-4634-2020; Carrion,
   Zoraida Callejas/C-6851-2012
OI Griol, David/0000-0001-6266-5321; Callejas, Zoraida/0000-0001-8891-5237;
   Carrion, Zoraida Callejas/0000-0001-8891-5237
CR Abalos N, 2010, LECT NOTES ARTIF INT, V6231, P484
   Ahmad F, 2009, ANN INTERN MED, V151, P93, DOI 10.7326/0003-4819-151-2-200907210-00124
   Allen J, 2006, J BIOMED INFORM, V39, P500, DOI 10.1016/j.jbi.2006.02.004
   Andre E, 2011, COGN TECHNOL, P585, DOI 10.1007/978-3-642-15184-2_30
   Ayesh A, 2015, COGN COMPUT, V7, P285, DOI 10.1007/s12559-014-9287-7
   Becker R, 2013, COMMUN ACM, V56, P74, DOI 10.1145/2398356.2398375
   Bee N, 2010, P AAMAS 10, P1535
   Benus S, 2014, COGN COMPUT, V6, P802, DOI 10.1007/s12559-014-9261-4
   Bevacqua E, 2008, LECT NOTES COMPUT SC, V5208, P262
   Bickmore T, 2006, J BIOMED INFORM, V39, P556, DOI 10.1016/j.jbi.2005.12.004
   Bickmore TW, 2010, INTERACT COMPUT, V22, P289, DOI 10.1016/j.intcom.2009.12.001
   Bickmore TW, 2010, INTERACT COMPUT, V22, P276, DOI 10.1016/j.intcom.2010.02.001
   Black LA, 2005, COMP MED SY, P506, DOI 10.1109/CBMS.2005.33
   Blazquez G, 2011, INF FUS FUSION 2011, P1
   Bonino D, 2011, J AMB INTEL SMART EN, V3, P111, DOI 10.3233/AIS-2011-0099
   Campillo-Sanchez Pablo, 2014, Advances in Practical Applications of Heterogeneous Multi-Agent Systems. The PAAMS Collection. 12th International Conference, PAAMS 2014. Proceedings: LNCS 8473, P319, DOI 10.1007/978-3-319-07551-8_28
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   Castells M, 2009, MOBILE COMMUNICATION
   CAVAZZA M, 2010, AAMAS, P01629
   Choi J, 2013, NEUROPSYCHOL REV, V23, P48, DOI 10.1007/s11065-013-9227-4
   Corchado JM, 2008, IEEE INTELL SYST, V23, P19, DOI 10.1109/MIS.2008.27
   de Almeida DR, 2006, 20TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1, PROCEEDINGS, P205
   Delichatsios HK, 2001, AM J HEALTH PROMOT, V15, P215, DOI 10.4278/0890-1171-15.4.215
   DUTOIT T, 1996, INTRO TEXT TO SPEECH
   Evanini K, 2008, 2008 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY: SLT 2008, PROCEEDINGS, P129, DOI 10.1109/SLT.2008.4777857
   Farzanfar R, 2005, J BIOMED INFORM, V38, P220, DOI 10.1016/j.jbi.2004.11.011
   Fernandez JM, 2010, INTEGR COMPUT-AID E, V17, P243, DOI 10.3233/ICA-2010-0341
   Ghanem KG, 2005, SEX TRANSM INFECT, V81, P421, DOI 10.1136/sti.2004.013193
   Giorgino T, 2005, INT J MED INFORM, V74, P159, DOI 10.1016/j.ijmedinf.2004.04.026
   Glanz K, 2003, PATIENT EDUC COUNS, V49, P157, DOI 10.1016/S0738-3991(02)00076-9
   Gnjatovic M, 2014, COGN COMPUT, V6, P775, DOI 10.1007/s12559-014-9272-1
   Gonzalez-Velez H, 2009, APPL INTELL, V30, P191, DOI 10.1007/s10489-007-0085-8
   Griol D, 2008, SPEECH COMMUN, V50, P666, DOI 10.1016/j.specom.2008.04.001
   Griol D, 2014, LECT NOTES COMPUT SC, V8480, P25
   Griol D, 2014, COMPUT SPEECH LANG, V28, P743, DOI 10.1016/j.csl.2013.09.002
   Han B, 2004, LECT NOTES COMPUT SC, V3358, P519
   Harrington T, 2000, GERONTECHNOLOGY WHY
   Hassenzahl M., 2003, MENSCH COMPUTER 2003, P187, DOI DOI 10.1007/978-3-322-80058-9_19
   Heinroth T., 2012, INTRO SPOKEN DIALOGU
   Hofmann H., 2014, P IWSDS 14, P102
   Hone K, 1993, P EUR 01
   Hubal RC, 2006, J BIOMED INFORM, V39, P532, DOI 10.1016/j.jbi.2005.12.006
   International Data Corporation (IDC), 2015, WORLDW Q MOB PHON TR
   Jokinen Kristiina, 2003, P WORKSH ONT MULT US, P730
   Kartakis S, 2010, COMPUT IND, V61, P318, DOI 10.1016/j.compind.2009.12.002
   Kaufmann T, 2012, SPEECH COMMUN, V54, P715, DOI 10.1016/j.specom.2012.01.001
   Leite Iolanda, 2012, Advances in User Modeling. UMAP 2011 Workshops. Revised Selected Papers, P135, DOI 10.1007/978-3-642-28509-7_14
   Lemon O, 2011, COMPUT SPEECH LANG, V25, P210, DOI 10.1016/j.csl.2010.04.005
   Li S, 2007, AAAI SPRING S INT CH, P72
   Lopez-de-Ipina K, 2015, COGN COMPUT, V7, P44, DOI 10.1007/s12559-013-9229-9
   Lpez V., 2011, EXPERT SYSTEMS APPL, V39, P7330
   Maglogiannis I, 2009, APPL INTELL, V30, P24, DOI 10.1007/s10489-007-0073-z
   McTear M., 2013, VOICE APPL DEV ANDRO
   Metze F, 2009, LECT NOTES COMPUT SC, V5611, P75, DOI 10.1007/978-3-642-02577-8_9
   Miesenberger K, 2010, LECT NOTES COMPUTER, V4061
   Migneault JP, 2006, J BIOMED INFORM, V39, P468, DOI 10.1016/j.jbi.2006.02.009
   Minker W, 1999, SPEECH COMMUN, V28, P141, DOI 10.1016/S0167-6393(99)00005-9
   MOONEY K, 2004, ANN BEHAV MED ANN S, V27, P152
   O'Shaughnessy D, 2008, PATTERN RECOGN, V41, P2965, DOI 10.1016/j.patcog.2008.05.008
   Ohkawa Y, 2009, SPEECH COMMUN, V51, P875, DOI 10.1016/j.specom.2009.05.005
   Ong K, 2013, ALZHEIMERS RES THER, V5, DOI [10.1186/alzrt189, 10.1186/alzrt158]
   Oulasvirta A, 2012, PERS UBIQUIT COMPUT, V16, P105, DOI 10.1007/s00779-011-0412-2
   Paek T, 2008, SPEECH COMMUN, V50, P716, DOI 10.1016/j.specom.2008.03.010
   Payr S, 2010, 2010 IEEE RO-MAN, P476, DOI 10.1109/ROMAN.2010.5598625
   PerezMarin D, 2011, CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND EFFECTIVE PRACTICES, P1, DOI 10.4018/978-1-60960-617-6
   Petukhova V, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2556
   Pfeifer L., 2010, P INT VIRT AG, P4698
   Piau A, 2014, J NUTR HEALTH AGING, V18, P97, DOI 10.1007/s12603-013-0356-5
   Pieraccini R, 2012, VOICE IN THE MACHINE: BUILDING COMPUTERS THAT UNDERSTAND SPEECH, P1
   Pinto BM, 2002, AM J PREV MED, V23, P113, DOI 10.1016/S0749-3797(02)00441-5
   Prezerakos GN, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, PROCEEDINGS, P320
   Ramelson HZ, 1999, PATIENT EDUC COUNS, V36, P131, DOI 10.1016/S0738-3991(98)00130-X
   Rehrl T., 2013, P AAL 13, P414
   Riccardi G, 1993, P WORKSH ROADM FUT M, P53
   Rojas-Barahona L, 2009, THESIS U STUDI PAVIA
   Rouillard Jose, 2007, Journal of Networks, V2, P27, DOI 10.4304/jnw.2.1.27-35
   Saz O, 2009, SPEECH COMMUN, V51, P948, DOI 10.1016/j.specom.2009.04.006
   Schatzmann J, 2006, KNOWL ENG REV, V21, P97, DOI 10.1017/S0269888906000944
   Searle John R., 1969, SPEECH ACTS
   Seneff S., 2007, P INT WORKSH IMPR MO, P1
   Sixsmith A, 2009, LECT NOTES COMPUT SC, V5597, P233, DOI 10.1007/978-3-642-02868-7_30
   Stolcke A, 2000, COMPUT LINGUIST, V26, P339, DOI 10.1162/089120100561737
   Syrdal DS, 2014, COGN COMPUT, V6, P741, DOI 10.1007/s12559-014-9284-x
   Torres F, 2005, SPEECH COMMUN, V45, P211, DOI 10.1016/j.specom.2004.10.014
   Traum David, 2003, INFORM STATE APPROAC, P325, DOI DOI 10.1007/978-94-010-0019-2_15
   Traum DR, 1999, APPL LOG SER, V14, P169
   Tsilfidis A, 2013, COMPUT SPEECH LANG, V27, P380, DOI 10.1016/j.csl.2012.07.004
   VILLARRUBIA G, 2014, P IBER AMIA 14, V14, P767
   Wahlster W, 2001, P STAT C LEAD PROJ H, P22
   Wang YY, 2006, SPEECH COMMUN, V48, P390, DOI 10.1016/j.specom.2005.07.001
   Williams JD, 2007, COMPUT SPEECH LANG, V21, P393, DOI 10.1016/j.csl.2006.06.008
   Williams JW, 2010, EVIDENCE REPORT TECH
   Wolters M, 2009, INTERACT COMPUT, V21, P276, DOI 10.1016/j.intcom.2009.05.009
   Wu WL, 2010, COMPUT SPEECH LANG, V24, P358, DOI 10.1016/j.csl.2009.05.002
   Young S., 2002, STAT APPROACH DESIGN
   Young S, 2010, IEEE SIGNAL PROC MAG, V27, P128, DOI 10.1109/MSP.2010.935874
   [No title captured]
   [No title captured]
   [No title captured]
NR 99
TC 17
Z9 17
U1 4
U2 33
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1866-9956
EI 1866-9964
J9 COGN COMPUT
JI Cogn. Comput.
PD APR
PY 2016
VL 8
IS 2
BP 336
EP 356
DI 10.1007/s12559-015-9352-x
PG 21
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA DI9WZ
UT WOS:000373854700016
DA 2022-08-02
ER

PT C
AU Lopatovska, I
   Brown, D
   Korshakova, E
AF Lopatovska, Irene
   Brown, Diedre
   Korshakova, Elena
BE Smits, M
TI Contextual Perceptions of Feminine-, Masculine- and
   Gender-Ambiguous-Sounding Conversational Agents
SO INFORMATION FOR A BETTER WORLD: SHAPING THE GLOBAL FUTURE, PT I
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 17th International Conference on Information for a Better World -
   Shaping the Global Future (iConference)
CY FEB 28-MAR 04, 2022
CL Kyushu Univ, iSchools, ELECTR NETWORK
SP Univ Coll Dublin, Univ Texas Austin
HO Kyushu Univ, iSchools
DE Conversational agents; Intelligent personal assistants; Gendered voice
   design
ID VOICE PITCH; BIG-5 INVENTORY; SPEAKER SEX; IDENTIFICATION; STEREOTYPES;
   RESPONSES; MACHINES; SPEECH; WARMTH; BRANDS
AB The study explored whether cultural gender stereotypes are carried into the domain of conversational agents (CAs), and examined user reactions to feminine, masculine, and gender-ambiguous voices in the context of stressful and non-stressful interactions. The user's image of an ideal CA was also investigated. A fully virtual experiment guided participants through interactions with three differently voiced Amazon Alexa test apps, collected participants' demographics, ratings and comments about CAs performance, voice and personality manifestations on stressful, non-stressful and personality-revealing tasks. The masculine sounding agent was most frequently associated with extraverted, sensitive and open-minded personality, the gender-ambiguous agent was perceived as organized; and the feminine sounding agent as sympathetic. Most of the participants wanted their ideal CAs to have a highly warm and competent personality, and preferred this personality in both stressful and non-stressful contexts. Nearly half of the participants identified a preference for contextually dependent voice or stated a preference for an ideal agent with a gender-ambiguous voice, though this agent received the lowest scores during experimental interactions. The study contributes to the discussion of the cultural gender stereotypes in conversational technology and user preferences for agent's voices and personality.
C1 [Lopatovska, Irene; Brown, Diedre; Korshakova, Elena] Pratt Inst, Sch Informat, 144 W14th St, New York, NY 10011 USA.
RP Lopatovska, I (corresponding author), Pratt Inst, Sch Informat, 144 W14th St, New York, NY 10011 USA.
EM ilopatov@pratt.edu; dbrow207@pratt.edu; ekorshak@pratt.edu
OI Brown, Diedre/0000-0003-2678-837X
FU Pratt Institute
FX We are grateful to our participants and the Pratt Institute for
   supporting the study.
CR Aaker J, 2010, J CONSUM RES, V37, P224, DOI 10.1086/651566
   Aaker JL, 2012, J CONSUM PSYCHOL, V22, P191, DOI 10.1016/j.jcps.2011.11.012
   Anderson RC, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0051216
   APPLE W, 1979, J PERS SOC PSYCHOL, V37, P715, DOI 10.1037/0022-3514.37.5.715
   Audacity, 2020, AUD 2 4 1
   Banai IP, 2017, EVOL HUM BEHAV, V38, P309, DOI 10.1016/j.evolhumbehav.2016.10.012
   Belin P, 2011, BRIT J PSYCHOL, V102, P711, DOI 10.1111/j.2044-8295.2011.02041.x
   Bentley Frank, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3264901
   Benyon D., 2008, CHI 08 HUM FACT COMP, P3657
   BERRY DS, 1990, J NONVERBAL BEHAV, V14, P141, DOI 10.1007/BF00996223
   Bishop J, 2012, J ACOUST SOC AM, V132, P1100, DOI 10.1121/1.4714351
   Budiu R, MENTAL MODELS INTELL
   Burgoon J. K., 1996, NONVERBAL COMMUNICAT
   Cambre Julia, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359325
   Carpenter J., 2019, INTERACTIONS, V26, P56, DOI [10.1145/3358912, DOI 10.1145/3358912]
   Chang RCS, 2018, COMPUT HUM BEHAV, V84, P194, DOI 10.1016/j.chb.2018.02.025
   Chaves AP, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173765
   Cowan BR, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3098539
   Curry Amanda Cercas, 2020, 2 WORKSH GEND BIAS N, P72
   Danielescu A., 2018, ACM COMP HUM INT CHI
   Danielescu A., 2020, P 2 C CONV US INT CU, P1, DOI [10.1145/340 5755.3406151, DOI 10.1145/3405755.3406151]
   Danielescu A, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3174366
   ELLIS DS, 1967, SOC FORCES, V45, P431
   Emerson RW, 2016, J VISUAL IMPAIR BLIN, V110, P377
   Feine Jasper, 2020, Chatbot Research and Design. Third International Workshop, CONVERSATIONS 2019. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 11970), P79, DOI 10.1007/978-3-030-39540-7_6
   Fiske ST, 2007, TRENDS COGN SCI, V11, P77, DOI 10.1016/j.tics.2006.11.005
   Fruehholz S, 2013, NEUROSCI BIOBEHAV R, V37, P2847, DOI 10.1016/j.neubiorev.2013.10.007
   Glass RL, 2009, INFORM SYST MANAGE, V26, P209, DOI 10.1080/10580530902797631
   Honorof DN, 2010, J ACOUST SOC AM, V128, P3095, DOI 10.1121/1.3488347
   Hughes S.M., 2008, EMOTIONS HUMAN VOICE, V2, P8
   Hughes S.M., 2010, J SOC EVOL CULT PSYC, V4, P290, DOI [DOI 10.1037/H0099282, 10.1037/h0099282]
   Ivy D.K, 2012, GENDER SPEAK PERSONA, V5th
   Johnson Khari, 2018, AMAZON SAYS ALEXA IS
   Kedemey D., 2015, TIME
   Kervyn N, 2012, J CONSUM PSYCHOL, V22, P166, DOI 10.1016/j.jcps.2011.09.006
   Kinsella, 2019, VOICE ASSISTANT CONS
   Klofstad CA, 2012, P ROY SOC B-BIOL SCI, V279, P2698, DOI 10.1098/rspb.2012.0311
   Kumar P., 2011, ICCCS 11 P 2011 INT, P319, DOI [10.1145/1947940.1948007, DOI 10.1145/1947940.1948007]
   Kunst A., 2019, PREFERENCES MALE FEM
   LASS NJ, 1976, J ACOUST SOC AM, V59, P675, DOI 10.1121/1.380917
   Lindzey G., 1998, HDB SOCIAL PSYCHOL, P635
   Lopatovska Irene, 2018, Proceedings of the Association for Information Science and Technology, V55, DOI 10.1002/pra2.2018.14505501034
   Lopatovska I, 2021, CHIIR '21: PROCEEDINGS OF THE 2021 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P15, DOI 10.1145/3406522.3446018
   Lopatovska I, 2020, CHIIR'20: PROCEEDINGS OF THE 2020 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P333, DOI 10.1145/3343413.3377993
   Lopatovska I, 2020, J LIBR INF SCI, V52, P931, DOI 10.1177/0961000619891771
   Lopatovska I, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P265, DOI 10.1145/3176349.3176868
   Luria M, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P633, DOI 10.1145/3322276.3322340
   Manstead ASR, 2018, BRIT J SOC PSYCHOL, V57, P267, DOI 10.1111/bjso.12251
   Mayew WJ, 2013, EVOL HUM BEHAV, V34, P243, DOI 10.1016/j.evolhumbehav.2013.03.001
   Mays DavidV., 1982, STUDIES 2 LANGUAGE A, V5, P52
   McAleer P, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090779
   McCrae R.R., 2003, PERSONALITY ADULTHOO
   McDonnell M, 2019, INTERACT COMPUT, V31, P116, DOI 10.1093/iwc/iwz007
   Moussawi S, 2021, BEHAV INFORM TECHNOL, V40, P1603, DOI 10.1080/0144929X.2020.1772368
   Muller SL, 2018, 11TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2018), P405, DOI 10.1145/3197768.3203178
   Mulder M.P., 2002, CTIT TECHNICAL REPOR, V2, P02
   Myers I.B, 1998, INTRO TYPE GUIDE UND
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Nass C, 1997, J APPL SOC PSYCHOL, V27, P864, DOI 10.1111/j.1559-1816.1997.tb00275.x
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nass Clifford, 2005, WIRED SPEECH VOICE A
   Norgaard N, 2019, EQUAL I MEET Q 1 GEN
   NORMAN DA, 1994, COMMUN ACM, V37, P68, DOI 10.1145/176789.176796
   Obinali C., 2019, SAIS 2019 P SO ASS I, V39, P1
   Pittam J, 1994, VOICE SOCIAL INTERAC
   Porter CM, 2019, PERS RELATIONSHIP, V26, P310, DOI 10.1111/pere.12275
   Rammstedt B, 2007, EUR J PSYCHOL ASSESS, V23, P193, DOI 10.1027/1015-5759.23.3.193
   Rammstedt B, 2007, J RES PERS, V41, P203, DOI 10.1016/j.jrp.2006.02.001
   Sondergaard MLJ, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P869, DOI 10.1145/3196709.3196766
   Steele C, 2018, REAL REASON VOICE AS
   Stemler S., 2001, PRACTICAL ASSESSMENT, V7, P137, DOI DOI 10.7275/Z6FM-2E34
   Tigue CC, 2012, EVOL HUM BEHAV, V33, P210, DOI 10.1016/j.evolhumbehav.2011.09.004
   UNESCO, 2019, ID BLUSH COULD CLOSI
   Unkefer H., 2020, ACCENTURE NEWSROOM
   Voiceflow, DES PROT BUILD VOIC
   Waytz A, 2014, J EXP SOC PSYCHOL, V52, P113, DOI 10.1016/j.jesp.2014.01.005
   Waytz A, 2010, J PERS SOC PSYCHOL, V99, P410, DOI 10.1037/a0020240
   Weber R. P, 1990, BASIC CONTENT ANAL, DOI 10.4135/9781412983488
   Willis J, 2006, PSYCHOL SCI, V17, P592, DOI 10.1111/j.1467-9280.2006.01750.x
NR 79
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-96957-8; 978-3-030-96956-1
J9 LECT NOTES COMPUT SC
PY 2022
VL 13192
BP 459
EP 480
DI 10.1007/978-3-030-96957-8_38
PG 22
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS8GS
UT WOS:000772157700038
DA 2022-08-02
ER

PT J
AU Hoffman, A
   Owen, D
   Calvert, SL
AF Hoffman, Anna
   Owen, Diana
   Calvert, Sandra L.
TI Parent reports of children's parasocial relationships with
   conversational agents: Trusted voices in children's lives
SO HUMAN BEHAVIOR AND EMERGING TECHNOLOGIES
LA English
DT Article
DE artificial intelligence; children; conversational agents; parasocial
   interactions; parasocial relationships; parents; social contingency;
   trust
ID TODDLERS; CHARACTERS
AB With the rise of smart devices in the 21st century, children are increasingly engaged in socially contingent interactions with conversational agents such as Alexa, Google Assistant, and Siri. Using an online parent survey, young children's verbal interactions (parasocial interactions) and emotional relationships (parasocial relationships) with conversational agents were examined in a naturalistic study. A total of 92 parents responded to the survey, 70 of whom qualified because they had a conversational agent. Exploratory and confirmatory factor analyses of emotional parasocial relationships with conversational agents in a subset of this sample (n = 58, m(child age) = 5.54 years, age range 3-10, 33 females) revealed three dimensions: attachment, personification, and social realism. These dimensions are consistent with children's parasocial relationships with media characters. The relation between parasocial verbal interactions and emotional parasocial relationships with conversational agents was bidirectional. The results indicate that children develop close emotional ties with artificial beings, treating them as human-like entities with feelings and for whom they have feelings. Implications for interactions with artificial life as children's trusted social partners are considered.
C1 [Hoffman, Anna; Owen, Diana; Calvert, Sandra L.] Georgetown Univ, Childrens Digital Media Ctr, Washington, DC 20007 USA.
RP Hoffman, A; Owen, D; Calvert, SL (corresponding author), Georgetown Univ, Childrens Digital Media Ctr, Washington, DC 20007 USA.
EM owend@georgetown.edu; calverts@georgetown.edu
CR Aguiar N.R., 2019, IMAG COGN PERS, V38, P221, DOI [10.1177/0276236618771537, DOI 10.1177/0276236618771537]
   Airenti G, 2015, INT J SOC ROBOT, V7, P117, DOI 10.1007/s12369-014-0263-x
   Auxier B., 2019, 5 THINGS KNOW AM THE
   Bascandziev I, 2016, J EXP CHILD PSYCHOL, V152, P92, DOI 10.1016/j.jecp.2016.06.017
   Bernhold QS, 2019, J APPL COMMUN RES, DOI 10.1080/00909882.2019.1679384
   Bernstein D, 2008, J LEARN SCI, V17, P225, DOI 10.1080/10508400801986116
   Bond BJ, 2014, J CHILD MEDIA, V8, P286, DOI 10.1080/17482798.2014.890948
   Bowlby J, 1969, ATTACHMENT LOSS, V1
   Breazeal C, 2016, TOP COGN SCI, V8, P481, DOI 10.1111/tops.12192
   Browne MW, 1993, TESTING STRUCTURAL E, P136, DOI DOI 10.1177/0049124192021002005
   Calvert S. L., 2015, HDB CHILD PSYCHOL DE, P375, DOI DOI 10.1002/9781118963418.CHILDPSY410
   Calvert SL, 2021, J CHILD MEDIA, V15, P291, DOI 10.1080/17482798.2021.1896200
   Calvert SL, 2020, CHILD DEV, V91, P1491, DOI 10.1111/cdev.13341
   Calvert SL, 2017, COGNITIVE DEVELOPMENT IN DIGITAL CONTEXTS, P93, DOI 10.1016/B978-0-12-809481-5.00005-5
   Calvert SL, 2014, J APPL DEV PSYCHOL, V35, P148, DOI 10.1016/j.appdev.2014.03.004
   Common Sense Media, 2020, COMMON SENSE CENSUS
   Corriveau K, 2009, DEVELOPMENTAL SCI, V12, P426, DOI 10.1111/j.1467-7687.2008.00792.x
   Danovitch JH, 2013, J COGN DEV, V14, P499, DOI 10.1080/15248372.2012.689391
   Dibble JL, 2016, HUM COMMUN RES, V42, P21, DOI 10.1111/hcre.12063
   Druga S, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P595, DOI 10.1145/3078072.3084330
   Epley N, 2007, PSYCHOL REV, V114, P864, DOI 10.1037/0033-295X.114.4.864
   Festerling J, 2020, HUM DEV, V64, P26, DOI 10.1159/000508499
   Finkelstein, 2018, THESIS CARNEGIE MELL
   Flavell JH., 1963, DEV PSYCHOL JEAN PIA, DOI [10.1037/11449-000, DOI 10.1037/11449-000]
   Garg Radhika, 2020, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V4, DOI 10.1145/3381002
   Garzotto F., 2020, MULTI CRITERIA DECIS, P1, DOI [10.1145/3405755.3406129, DOI 10.1145/3405755.3406129]
   Gola AAH, 2013, MEDIA PSYCHOL, V16, P390, DOI 10.1080/15213269.2013.783774
   Hair J.F., 2010, MULTIVARIATE DATA AN
   Hoffner C., 2008, HDB CHILDREN MEDIA D, P309, DOI DOI 10.1002/9781444302752.CH14
   Hooper D, 2008, ELECT J BUSINESS RES, V6, P53, DOI [DOI 10.21427/D7CF7R, 10.21427/D7CF7R]
   HORTON D, 1956, PSYCHIATR, V19, P215, DOI 10.1080/00332747.1956.11023049
   Jipson, 2021, SOC RES CHILD DEV VI
   Jipson JL, 2007, CHILD DEV, V78, P1675, DOI 10.1111/j.1467-8624.2007.01095.x
   Kahn PH, 2007, INTERACT STUD, V8, P363
   Kahn PH, 2012, DEV PSYCHOL, V48, P303, DOI 10.1037/a0027033
   Kenny DA, 2003, STRUCT EQU MODELING, V10, P333, DOI 10.1207/S15328007SEM1003_1
   Kenny DA, 2015, SOCIOL METHOD RES, V44, P486, DOI 10.1177/0049124114543236
   Kuhn D, 2020, QUESTIONING CHILD: INSIGHTS FROM PSYCHOLOGY AND EDUCATION, P232
   Lauricella AR, 2011, MEDIA PSYCHOL, V14, P216, DOI 10.1080/15213269.2011.573465
   Lovato Silvia, 2015, P 14 INT C INT DES C, P335, DOI [10.1145/2771839.2771910, DOI 10.1145/2771839.2771910]
   Lovato SB, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P301, DOI 10.1145/3311927.3323150
   MacCallum RC, 1996, PSYCHOL METHODS, V1, P130, DOI 10.1037/1082-989X.1.2.130
   Mills CM, 2012, CHILD DEV, V83, P568, DOI 10.1111/j.1467-8624.2011.01725.x
   Munsch, 2018, CHILD DEV
   Nurmsoo E, 2009, DEVELOPMENTAL SCI, V12, P41, DOI 10.1111/j.1467-7687.2008.00750.x
   Porcheron M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174214
   Richards MN, 2017, J CHILD MEDIA, V11, P229, DOI 10.1080/17482798.2017.1304969
   Richards MN, 2016, J CHILD MEDIA, V10, P462, DOI 10.1080/17482798.2016.1157502
   Roseberry S, 2014, CHILD DEV, V85, P956, DOI 10.1111/cdev.12166
   Schramm H, 2008, COMMUNICATIONS-GER, V33, P385, DOI 10.1515/COMM.2008.025
   Shafto P, 2015, P 37 ANN C COGN SCI
   Tabachnick B.G, 2007, USING MULTIVARIATE S, V5th ed.
   Tomilson A., 2007, CHILDS CONCEPTION WO, V2nd
   Wellman HM, 2020, QUESTIONING CHILD: INSIGHTS FROM PSYCHOLOGY AND EDUCATION, P51
   West M., 2019, ID BLUSH COULD CLOSI
   Xu Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376416
   Yarosh S, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P300, DOI 10.1145/3202185.3202207
NR 57
TC 4
Z9 4
U1 4
U2 17
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
EI 2578-1863
J9 HUM BEHAV EMERG TECH
JI Hum. Behav. Emerg. Tech.
PD OCT
PY 2021
VL 3
IS 4
SI SI
BP 606
EP 617
DI 10.1002/hbe2.271
EA JUN 2021
PG 12
WC Psychology, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Psychology
GA WM9HL
UT WOS:000664224000001
OA gold, Green Published
DA 2022-08-02
ER

PT J
AU Aymerich-Franch, L
   Ferrer, I
AF Aymerich-Franch, Laura
   Ferrer, Iliana
TI Investigating the use of speech-based conversational agents for life
   coaching
SO INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES
LA English
DT Article
DE Conversational agents; Coaching; Psychological well-being; Positive
   technology; Goal achievement
AB Life coaching can contribute to goal attainment, quality of life, and psychological well-being enhancement. We explored the capacity of a speech-based conversational agent coach (CAC) to deliver a coaching program for goal achievement in two studies. Participants showed a significant increase in personal growth initiative (PGI) after completing the program both in the pilot and the main study. Participants in the main study additionally reported a significant increase in life satisfaction (SLS) and a significant decrease in negative affect (PANAS-N). Usability of the application, satisfaction with the coaching program, and adoption intention were rated positively in both studies. The results suggest that working on goal achievement with the CAC had a positive impact on the psychological well-being of the participants. The study provides an empirically-validated approach for automated coaching interventions and highlights the potential of conversational agents for delivering life coaching.
C1 [Aymerich-Franch, Laura; Ferrer, Iliana] Pompeu Fabra Univ, Roc Boronat 138, Barcelona 08018, Spain.
RP Aymerich-Franch, L (corresponding author), Pompeu Fabra Univ, Roc Boronat 138, Barcelona 08018, Spain.
EM laura.aymerich@gmail.com
RI Ferrer, Iliana/ACA-7055-2022; Aymerich-Franch, Laura/Q-6296-2018
OI Ferrer, Iliana/0000-0002-7326-0415; Aymerich-Franch,
   Laura/0000-0001-7627-5770
FU Ramon y Cajal Fellowship Program [RYC-2016-19770]; Agencia Estatal de
   Investigacion, Ministerio de Ciencia, Innovacion y Universidades;
   European Social Fund
FX The project has received funding from the Ramon y Cajal Fellowship
   Program (ref. RYC-2016-19770) awarded to the first author, funded by
   Agencia Estatal de Investigacion, Ministerio de Ciencia, Innovacion y
   Universidades, and the European Social Fund.
CR Albaina I.M., 2009, 2009 3 INT C PERV CO, DOI [10.4108/ICST.PERVASIVEHEALTH2009.5949, DOI 10.4108/ICST.PERVASIVEHEALTH2009.5949]
   Alberts H., 2019, GOAL VISUALIZATION
   Attkisson C C, 1982, Eval Program Plann, V5, P233, DOI 10.1016/0149-7189(82)90074-X
   Aymerich-Franch L., 2014, P INT SOC PRESENCE R
   Aymerich-Franch L., 2019, INT COMMUNICATION AS
   Ayres J., 1993, COMMUNICATION INFORM
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   BRUNSTEIN JC, 1993, J PERS SOC PSYCHOL, V65, P1061, DOI 10.1037/0022-3514.65.5.1061
   Chittaro L, 2016, INTERACT COMPUT, V28, P695, DOI 10.1093/iwc/iwv044
   Corrigan P, 2004, AM PSYCHOL, V59, P614, DOI 10.1037/0003-066X.59.7.614
   Cox E., 2010, COMPLETE HDB COACHIN
   Diederich S., 2019, P INT C WIRTSCHAFTSI, P16
   DIENER E, 1985, J PERS ASSESS, V49, P71, DOI 10.1207/s15327752jpa4901_13
   Doran GT., 1981, MANAG REV, V70, P35
   Frisch M.B., 2016, WILEY HDB POSITIVE C, DOI [10.1002/9781118468197.ch27, DOI 10.1002/9781118468197.CH27]
   Frisch M.B., 2006, QUALITY LIFE THERAPY
   Grant A.M., 2010, COMPLETE HDB COACHIN
   Grant AM, 2003, SOC BEHAV PERSONAL, V31, P253, DOI 10.2224/sbp.2003.31.3.253
   Grant AM, 2009, J POSIT PSYCHOL, V4, P396, DOI 10.1080/17439760902992456
   Green L.S., 2006, J POSIT PSYCHOL, P142, DOI DOI 10.1080/17439760600619849
   Heerink Marcel, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P528, DOI 10.1109/ROMAN.2009.5326320
   Holzinger A, 2008, LECT NOTES COMPUT SC, V5105, P98, DOI 10.1007/978-3-540-70540-6_13
   Hoy Matthew B., 2018, Medical Reference Services Quarterly, V37, P81, DOI 10.1080/02763869.2018.1404391
   Hudlicka E, 2013, PATIENT EDUC COUNS, V92, P160, DOI 10.1016/j.pec.2013.05.007
   Ives Y., 2008, INT J EVID BASED COA
   Jeong S, 2020, IEEE ROMAN, P187, DOI 10.1109/RO-MAN47096.2020.9223588
   Kamphorst BA, 2017, PERS UBIQUIT COMPUT, V21, P625, DOI 10.1007/s00779-017-1020-6
   Kreps GL, 2010, J COMPUT-MEDIAT COMM, V15, P527, DOI 10.1111/j.1083-6101.2010.01526.x
   Ly KH, 2017, INTERNET INTERV, V10, P39, DOI 10.1016/j.invent.2017.10.002
   MagyarMoe JL, 2009, PRACT RESOUR MENT, P1, DOI 10.1016/B978-0-12-374517-0.00001-2
   Merdivan E, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10030762
   Pew Research Center, 2017, NEARL HALF AM US DIG
   Radovic A, 2016, CYBERPSYCH BEH SOC N, V19, P465, DOI 10.1089/cyber.2015.0619
   Reinecke L, 2017, J MEDIA PSYCHOL-GER, V29, P111, DOI 10.1027/1864-1105/a000227
   Riva G, 2012, CYBERPSYCH BEH SOC N, V15, P69, DOI 10.1089/cyber.2011.0139
   Robitschek C, 1998, MEAS EVAL COUNS DEV, V30, P183, DOI 10.1080/07481756.1998.12068941
   RUVOLO AP, 1992, SOC COGNITION, V10, P95, DOI 10.1521/soco.1992.10.1.95
   Sareen J, 2007, PSYCHIAT SERV, V58, P357, DOI 10.1176/appi.ps.58.3.357
   Spence G. B., 2007, J POSIT PSYCHOL, V2, P185, DOI DOI 10.1080/17439760701228896
   Stoltzfus T., 2008, COACHS GUIDE POWERFU
   ter Stal S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102409
   Wang PS, 2005, ARCH GEN PSYCHIAT, V62, P603, DOI 10.1001/archpsyc.62.6.603
   Watson A, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.1629
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Whitmore J., 2010, NHRD NETWORK J, DOI [10.1177/0974173920100216, DOI 10.1177/0974173920100216]
   Whitten P., 2001, J COMPUT MED COMMUN, DOI [10.1111/j.1083-6101.2001.tb00129.x, DOI 10.1111/J.1083-6101.2001.TB00129.X]
NR 46
TC 0
Z9 0
U1 1
U2 1
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 1071-5819
EI 1095-9300
J9 INT J HUM-COMPUT ST
JI Int. J. Hum.-Comput. Stud.
PD MAR
PY 2022
VL 159
AR 102745
DI 10.1016/j.ijhcs.2021.102745
PG 8
WC Computer Science, Cybernetics; Ergonomics; Psychology, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Psychology
GA 1B8CC
UT WOS:000792658500006
OA hybrid, Green Published
DA 2022-08-02
ER

PT C
AU Jacques, R
   Folstad, A
   Gerber, E
   Grudin, J
   Luger, E
   Monroy-Hernandez, A
   Wang, DK
AF Jacques, Richard
   Folstad, Asbjorn
   Gerber, Elizabeth
   Grudin, Jonathan
   Luger, Ewa
   Monroy-Hernandez, Andres
   Wang, Dakuo
GP Assoc Comp Machinery
TI Conversational Agents: Acting on the Wave of Research and Development
SO CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI
   CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY MAY 04-09, 2019
CL Glasgow, SCOTLAND
SP Assoc Comp Machinery, ACM SIGCHI
DE Conversational agents; conversational user interfaces; intelligent
   assistants; chatbots; virtual companions; social bots
AB In the last five years, work on software that interacts with people via typed or spoken natural language, called chatbots, intelligent assistants, social bots, virtual companions, non-human players, and so on, increased dramatically. Chatbots burst into prominence in 2016. Then came a wave of research, more development, and some use.
   The time is right to assess what we have learned from endeavouring to build conversational user interfaces that simulate quasi-human partners engaged in real conversations with real people. This workshop brings together people who developed or studied various conversational agents, to explore themes that include what works (and hasn't) in home, education, healthcare, and work settings, what we have learned from this about people and their activities, and social or ethical possibilities for good or risk.
C1 [Jacques, Richard; Grudin, Jonathan] Microsoft, Redmond, WA 98052 USA.
   [Folstad, Asbjorn] SINTEF, Oslo, Norway.
   [Gerber, Elizabeth] Northwestern Univ, Evanston, IL USA.
   [Grudin, Jonathan] Univ Washington, Redmond, WA 98052 USA.
   [Luger, Ewa] Univ Edinburgh, Edinburgh, Midlothian, Scotland.
   [Monroy-Hernandez, Andres] Snap Inc, Seattle, WA 98121 USA.
   [Monroy-Hernandez, Andres] Univ Washington, Seattle, WA 98121 USA.
   [Wang, Dakuo] IBM Res, Yorktown Hts, NY 10598 USA.
RP Jacques, R (corresponding author), Microsoft, Redmond, WA 98052 USA.
EM rjacques@microsoft.com; asbjorn.folstad@sintef.no;
   egerber@northwestern.edu; jgrudin@microsoft.com; ewa.luger@ed.ac.uk;
   amh@snap.com; dakuo.wang@ibm.com
RI Gerber, Elizabeth/B-7594-2009; Singh, Munindar P/L-8500-2013; Wang,
   Dakuo/AAY-7314-2021
OI Singh, Munindar P/0000-0003-3599-3893; Wang, Dakuo/0000-0001-9371-9441
CR Abokhodair N, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P839, DOI 10.1145/2675133.2675208
   Allison F., 2017, P DIGRA
   Allison F., 2017, CHI 17
   Allison F., 2018, P DIGRA SPEC ED
   [Anonymous], 2016, CHATBOTINSIDER
   Brandtzaeg PB., 2018, INTERACTIONS, V25, P38, DOI 10.1145/3236669
   Brandtzaeg PB, 2017, LECT NOTES COMPUT SC, V10673, P377, DOI 10.1007/978-3-319-70284-1_30
   Cranshaw J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2382, DOI 10.1145/3025453.3025780
   Faraooq U, 2016, INTERACTIONS, V23, P27, DOI [DOI 10.1145/3001896, 10.1145/3001896]
   Feldman D., 2018, CHATBOTS WHAT HAPPEN
   Jain M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P895, DOI 10.1145/3196709.3196735
   Liao Q. V., 2018, P CHI 2018
   Luger E., 2017, DATA PROTECTION PRIV
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   MAES P, 1994, COMMUN ACM, V37, P31
   Savage S, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P813, DOI 10.1145/2818048.2819985
   Shamekhi A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173965
   SHUM HY, 2018, J ZHEJIANG U-SCI C, V19, P10, DOI DOI 10.1631/FITEE.1700826
   SORRENTINO A, 2016, COMMUN ACM, P96
   Toxtli C, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173632
   Turing A., 1949, LONDON TIMES
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496
NR 23
TC 6
Z9 6
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5971-9
PY 2019
DI 10.1145/3290607.3299034
PG 8
WC Computer Science, Cybernetics; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BN4JW
UT WOS:000482042103103
DA 2022-08-02
ER

PT C
AU Xu, Y
   Warschauer, M
AF Xu, Ying
   Warschauer, Mark
GP ACM
TI What Are You Talking to?: Understanding Children's Perceptions of
   Conversational Agents
SO PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING
   SYSTEMS (CHI'20)
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 25-30, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGCHI
DE Conversational agents; perceptions; animacy; children; child-agent
   interactions
ID ROBOTS; BEHAVIOR; CONCEPTIONS; BRAIN
AB Conversational agents (CAs) available in smart phones or smart speakers play an increasingly important role in young children's technological landscapes and life worlds. While a handful of studies have documented children's natural interactions with CAs, little is known about children's perceptions of CAs. To fill this gap, we examined three- to six-year-olds' perceptions of CAs' animate/artifact domain membership and properties, as well as their justifications for these perceptions. We found that children sometimes take a more nuanced position and spontaneously attribute both artifact and animate properties to CAs or view them as neither artifacts nor animate objects. This study extends current research on children's perceptions of intelligent artifacts by adding CAs as a new genre of study and provides some underlying knowledge that may guide the development of CAs to support young children's cognitive and social development.
C1 [Xu, Ying; Warschauer, Mark] Univ Calif Irvine, Irvine, CA 92717 USA.
RP Xu, Y (corresponding author), Univ Calif Irvine, Irvine, CA 92717 USA.
EM ying.xu@uci.edu; markw@uci.edu
CR Axelrod, 2015, P HUM FACTORS ERGON, V59, P801, DOI [10.1177/1541931215591245, DOI 10.1177/1541931215591245]
   Beran TN, 2011, INT J HUM-COMPUT ST, V69, P539, DOI 10.1016/j.ijhcs.2011.04.003
   Bernstein D, 2008, J LEARN SCI, V17, P225, DOI 10.1080/10508400801986116
   BORENSTEIN J, 2013, LAW INNOVATION TECHN, V5, P172
   Breazeal C, 2016, TOP COGN SCI, V8, P481, DOI 10.1111/tops.12192
   Breazeal C, 2009, PHILOS T R SOC B, V364, P3527, DOI 10.1098/rstb.2009.0157
   Brunick KL, 2016, J CHILD MEDIA, V10, P181, DOI 10.1080/17482798.2015.1127839
   Cameron D, 2015, LECT NOTES ARTIF INT, V9222, P348, DOI 10.1007/978-3-319-22979-9_34
   Caramazza A, 1998, J COGNITIVE NEUROSCI, V10, P1, DOI 10.1162/089892998563752
   Catherine Pelachaud, 2010, EXPRESSIVE GESTURES
   Chan K, 2006, QUAL MARK RES, V9, P352, DOI 10.1108/13522750610689087
   Druga S, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P595, DOI 10.1145/3078072.3084330
   Druga S, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P231, DOI 10.1145/3202185.3202741
   Edwards S, 2018, BRIT J EDUC TECHNOL, V49, P45, DOI 10.1111/bjet.12529
   Harris PL, 2011, PHILOS T R SOC B, V366, P1179, DOI 10.1098/rstb.2010.0321
   Heerink M, 2010, VIRTUAL REAL-LONDON, V14, P77, DOI 10.1007/s10055-009-0142-1
   Heintz Katharine E, 2012, COMMUNICATION RES TR, V31, P22
   Hill J, 2015, COMPUT HUM BEHAV, V49, P245, DOI 10.1016/j.chb.2015.02.026
   Jipson JL, 2007, CHILD DEV, V78, P1675, DOI 10.1111/j.1467-8624.2007.01095.x
   Jipson JL, 2016, COGNITIVE DEV, V39, P21, DOI 10.1016/j.cogdev.2016.03.001
   Johnstone T., 2000, HDB EMOTIONS, V2, P220, DOI [DOI 10.1016/S0167-6393(02)00084-5, DOI 10.1016/J.JML.2007.11.007]
   Kahn PH, 2006, INTERACT STUD, V7, P405, DOI 10.1075/is.7.3.13kah
   Kahn PH, 2013, CHILD DEV PERSPECT, V7, P32, DOI 10.1111/cdep.12011
   Kahn PH, 2012, DEV PSYCHOL, V48, P303, DOI 10.1037/a0027033
   Kahn PH, 2004, RO-MAN 2004: 13TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P545, DOI 10.1109/ROMAN.2004.1374819
   Kanero J, 2018, CHILD DEV PERSPECT, V12, P146, DOI 10.1111/cdep.12277
   Katayama N., 2010, ASIAN CULTURE HIST, V2, P111, DOI [10.5539/ach.v2n2p111, DOI 10.5539/ACH.V2N2P111]
   Kim M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216869
   Kim Y, 2007, J COMPUT ASSIST LEAR, V23, P220, DOI 10.1111/j.1365-2729.2006.00210.x
   Kory-Westlund JM, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P38, DOI 10.1145/3311927.3323143
   La Rooy D, 2007, APPL COGNITIVE PSYCH, V21, P1, DOI 10.1002/acp.1272
   Lee S, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312796
   Levy ST, 2008, INT J TECHNOL DES ED, V18, P337, DOI 10.1007/s10798-007-9032-6
   Lovato SB, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P301, DOI 10.1145/3311927.3323150
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Marshall Peter J, 2016, YOUNG CHILDRENS DEV
   Meichenbaum D., 2017, EVOLUTION COGNITIVE, P85
   Melson GF, 2009, J APPL DEV PSYCHOL, V30, P92, DOI 10.1016/j.appdev.2008.10.011
   Mertala Pekka., 2019, BRIT J EDUC TECHNOL
   Mikropoulos TASSOS A, 2003, ATTRIBUTING HUMAN PR
   Opfer JE., 2011, WILEY BLACKWELL HDB, P213
   Purington A, 2017, 2017 CHI C HUM FACT, DOI [10.1145/3027063.3053246, DOI 10.1145/3027063.3053246]
   Rakison DH, 2001, PSYCHOL BULL, V127, P209, DOI 10.1037//0033-2909.127.2.209
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Rucker MT, 2016, J SCI EDUC TECHNOL, V25, P274, DOI 10.1007/s10956-015-9592-2
   SCAIFE M, 1995, BRIT J DEV PSYCHOL, V13, P367, DOI 10.1111/j.2044-835X.1995.tb00686.x
   Sciuto A, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P857, DOI 10.1145/3196709.3196772
   Serholt S, 2016, PROCEEDINGS OF THE NORDICHI '16: THE 9TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION - GAME CHANGING DESIGN, DOI 10.1145/2971485.2971536
   Severson RL, 2010, NEURAL NETWORKS, V23, P1099, DOI 10.1016/j.neunet.2010.08.014
   Swain J., 2018, SAGE RES METHODS, DOI [10.4135/9781526435477, DOI 10.4135/9781526435477]
   Tewari A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1807, DOI 10.1145/2556288.2557205
   Tremoulet PD, 2000, PERCEPTION, V29, P943, DOI 10.1068/p3101
   vanDuuren M, 1996, EUR J PSYCHOL EDUC, V11, P365, DOI 10.1007/BF03173278
   Weiss A, 2009, INT J SOC ROBOT, V1, P243, DOI 10.1007/s12369-009-0024-4
   Woodward J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174149
   Wright K, 2015, BRIT J DEV PSYCHOL, V33, P73, DOI 10.1111/bjdp.12068
   Xu Y, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299035
NR 57
TC 21
Z9 21
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6708-0
PY 2020
DI 10.1145/3313831.3376416
PG 13
WC Computer Science, Cybernetics; Computer Science, Information Systems;
   Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS1SH
UT WOS:000695438100088
DA 2022-08-02
ER

PT C
AU Hijjawi, M
   Bandar, Z
   Crockett, K
AF Hijjawi, Mohammad
   Bandar, Zuhair
   Crockett, Keeley
GP Appl Sci Univ
TI User's Utterance Classification Using Machine Learning for Arabic
   Conversational Agents
SO 2013 5TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION
   TECHNOLOGY (CSIT)
SE International Conference on Computer Science and Information Technology
LA English
DT Proceedings Paper
CT 5th International Conference on Computer Science and Information
   Technology (CSIT)
CY MAR 27-28, 2013
CL Appl Sci Private Univ, Amman, JORDAN
SP Appl Sci Private Univ, Fac Informat Technol
HO Appl Sci Private Univ
DE Dialogue Acts; Conversational Agents; Arabic Utterances; Machine
   learning and Decision Tree
AB This paper presents a novel technique for the classification of Arabic sentences as Dialogue Acts, based on structural information contained in Arabic function words. It focuses on classifying questions and non-questions utterances as they are used in Conversational Agents. The proposed technique extracts function words features by replacing them with numeric tokens and replacing each content word with a standard numeric token. The Decision Tree has been chosen for this work to extract the classification rules. Experiments provide evidence for highly effective classification. The extracted classification rules will be embedded into a Conversational Agent called ArabChat in order to classify Arabic utterances before further processing on these utterances. This paper presents a complement work for the ArabChat to improve its performance by differentiating among question-based and non question-based utterances.
C1 [Hijjawi, Mohammad] Appl Sci Univ, Informat Technol Coll, Amman, Jordan.
   [Bandar, Zuhair; Crockett, Keeley] Manchester Metropolitan Univ, Intelligent Syst Grp, Manchester, Lancs, England.
RP Hijjawi, M (corresponding author), Appl Sci Univ, Informat Technol Coll, Amman, Jordan.
EM hijjawi@asu.edu.jo; z.bandar@mmu.ac.uk; k.crockett@mmu.ac.uk
CR Al-Jazeera, 2010, AL JAZEERA NEWS
   Al-Shammari E., 2010, GRADUATE FACULTY, P201
   Al-Shammari Eiman Tamah, 2008, P 2 ACM WORKSH IMPR
   Algazale M., 2005, 100 QUESTIONS ISLAM, VV4
   Alghad, 2004, ALGHAD NEWS
   ALKHARASHI IA, 1994, J AM SOC INFORM SCI, V45, P548, DOI 10.1002/(SICI)1097-4571(199409)45:8<548::AID-ASI3>3.0.CO;2-X
   Alrai, 2010, ALRAI NEWS
   Amayrah K., 1992, METHODS NEGATION INT, VVI
   [Anonymous], 2010, SSS
   [Anonymous], 2005, DATA MINING PRACTICA
   Atta A., 1983, 100 100 QUESTIONS AN
   Blockeel H., 2001, J MACHINE LEARNING R, V3, P9, DOI [10.1162/jmlr.2003.3.4-5.621., DOI 10.1162/JMLR.2003.3.4-5.621]
   Bouckaert R., 2010, WEKA MANUAL VESION 3, P307
   Buckley R., 2004, MODERN LIB ARABIC RE, VVI
   Buddhinath G., 2003, SIMPLE ENHANCEMENT O
   Callan R., 2003, ARTIFICIAL INTELLIGE
   Kamel M., 1996, 100 100 QUESTIONS AN, VVI
   Kamel M., 1997, QUESTIONS ANSWERS SE, VVI
   Kamel M., 1995, QUESTIONS ANSWERS SE, VVI
   KEIZER S, 2002, 3 SIGDIAL WORKSH DIS
   Khoja S, 1999, STEMMING ARABIC TEXT
   Koora, 2010, KOOOR AR SPORTS
   Kral Pavel, 2007, Journal of Multimedia, V2, P1, DOI 10.4304/jmm.2.3.1-8
   Larkey LS, 2007, TEXT SPEECH LANG TEC, V38, P221
   Luck M., 1998, J LOGIC LANGUAGE INF, V7, P103
   Mosabeh I., 1988, QUESTONS S MOHAMMAD, VV4
   Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366
   O'Shea J., 2010, P 4 KES INT C AG MUL
   PETER A, 2004, MACH LEARN, V57, P233
   Quinlan R. C, 1993, 45 PROGRAMS MACHINE
   Rashmi P., 2002, P 3 SIGDIAL WORKSH D, V2
   Sawalha M., 2009, P WORKSH MORPH AN EX
   Searle John R., 1969, SPEECH ACTS
   Stateyeh S., 1986, CONDITIONS INTERROGA
   Verbree D., 2006, IEEE SPOK LANG TECHN
   Webb N., 2005, AAAI
   WEKA, 2010, WEKA MACH LEARN DAT
   Wenliang D., 2002, P IEEE INT C PRIV SE, V14
   Witten IH, 2011, MOR KAUF D, P1
   Yo-Ping H., 2009, P 2 INT C INT SCI IN
NR 40
TC 9
Z9 9
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2381-3458
BN 978-1-4673-5825-5
J9 INT CONF COMP SCI
PY 2013
BP 223
EP 232
PG 10
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BA1RJ
UT WOS:000332960400036
DA 2022-08-02
ER

PT J
AU Kopp, S
   van Welbergen, H
   Yaghoubzadeh, R
   Buschmeier, H
AF Kopp, Stefan
   van Welbergen, Herwin
   Yaghoubzadeh, Ramin
   Buschmeier, Hendrik
TI An architecture for fluid real-time conversational agents: integrating
   incremental output generation and input processing
SO JOURNAL ON MULTIMODAL USER INTERFACES
LA English
DT Article
DE Embodied conversational agents architecture; Fluid real-time
   interaction; Generation-interpretation coordination; Incremental
   processing; ASAP; BMLA
ID TURN-TAKING; ORGANIZATION; FRAMEWORK
AB Embodied conversational agents still do not achieve the fluidity and smoothness of natural conversational interaction. One main reason is that current system often respond with big latencies and in inflexible ways. We argue that to overcome these problems, real-time conversational agents need to be based on an underlying architecture that provides two essential features for fast and fluent behavior adaptation: a close bi-directional coordination between input processing and output generation, and incrementality of processing at both stages. We propose an architectural framework for conversational agents [Artificial Social Agent Platform (ASAP)] providing these two ingredients for fluid real-time conversation. The overall architectural concept is described, along with specific means of specifying incremental behavior in BML and technical implementations of different modules. We show how phenomena of fluid real-time conversation, like adapting to user feedback or smooth turn-keeping, can be realized with ASAP and we describe in detail an example real-time interaction with the implemented system.
C1 [Kopp, Stefan; van Welbergen, Herwin; Yaghoubzadeh, Ramin; Buschmeier, Hendrik] Univ Bielefeld, CITEC, Sociable Agents Grp, D-33501 Bielefeld, Germany.
   [Kopp, Stefan; van Welbergen, Herwin; Yaghoubzadeh, Ramin; Buschmeier, Hendrik] Univ Bielefeld, Fac Technol, D-33501 Bielefeld, Germany.
RP Kopp, S (corresponding author), Univ Bielefeld, CITEC, Sociable Agents Grp, POB 100131, D-33501 Bielefeld, Germany.
EM skopp@techfak.uni-bielefeld.de; hvanwelbergen@techfak.uni-bielefeld.de;
   ryaghoubzadeh@uni-bielefeld.de; hbuschme@uni-bielefeld.de
RI Buschmeier, Hendrik/H-7719-2019; Kopp, Stefan/K-3456-2013
OI Buschmeier, Hendrik/0000-0002-9613-5713; Kopp,
   Stefan/0000-0002-4047-9277
FU Deutsche Forschungsgemeinschaft (DFG)
FX This research is supported by the Deutsche Forschungsgemeinschaft (DFG)
   in the Center of Excellence EXC 277 in "Cognitive Interaction
   Technology" (CITEC) as well as the German Federal Ministry of Education
   and Research ( BMBF) within the Leading-Edge Cluster it's OWL, managed
   by the Project Management Agency Karlsruhe (PTKA). The authors are
   responsible for the content of this publication.
CR Atterer M, P INTERSPEECH 2009 B, P1855
   Baumann T., 2012, P ACL 2012 SYST DEM, P103
   Buschmeier Hendrik, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P169, DOI 10.1007/978-3-642-23974-8_19
   Buschmeier H, P 13 ANN M SPEC INT, P295
   Buss O, 2011, SEMDIAL 2011, P47
   Cassell J, 2000, EMBODIED CONVERSATIONAL AGENTS, P29
   Clark HH, 2004, J MEM LANG, V50, P62, DOI 10.1016/j.jml.2003.08.004
   Crook N, 2012, J MULTIMODAL USER IN, V6, P13, DOI 10.1007/s12193-012-0090-z
   de Kok Iwan, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P268, DOI 10.1007/978-3-642-33197-8_28
   Eyben F., 2010, P 18 ACM INT C MULT, P1459, DOI [10.1145/1873951.1874246, DOI 10.1145/1873951.1874246]
   Garrod S, 2004, TRENDS COGN SCI, V8, P8, DOI 10.1016/j.tics.2003.10.016
   Gravano A, 2011, COMPUT SPEECH LANG, V25, P601, DOI 10.1016/j.csl.2010.10.003
   Guhe M., 2007, INCREMENTAL CONCEPTU
   Haazebroek P, 2011, COGN PROCESS, V12, P355, DOI 10.1007/s10339-011-0408-x
   Hartmann B, 2002, COMP ANIM CONF PROC, P111, DOI 10.1109/CA.2002.1017516
   HOFFMAN G, 2008, P AAAI, P01357
   Hoffmann H, 2007, NEURAL NETWORKS, V20, P22, DOI 10.1016/j.neunet.2006.07.003
   Howes C, 2011, DIALOGUE DISCOURSE, V2, P297
   Kenny PG, 2008, ANN REV CYBERTHER TE, V6, P113
   Kopp S, 2005, LECT NOTES ARTIF INT, V3661, P329
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   Kopp S, 2006, LECT NOTES ARTIF INT, V4133, P205
   Kopp S, 2010, SPEECH COMMUN, V52, P587, DOI 10.1016/j.specom.2010.02.007
   Lemon O., 2004, ACM Transactions on Computer-Human Interaction, V11, P241, DOI 10.1145/1017494.1017496
   Lison P, 2008, FRONT ARTIF INTEL AP, V178, P636, DOI 10.3233/978-1-58603-891-5-636
   Neiberg D, 2011, INT CONF ACOUST SPEE, P5836
   Nijholt A, 2008, LECT NOTES ARTIF INT, V5042, P70
   Reidsma D, 2008, COMPUT ENTERTAIN, V6, DOI [10.1145/1461999.1462005, DOI 10.1145/1461999.1462005]
   Reidsma D, 2006, LECT NOTES COMPUT SC, V4161, P1
   Reidsma  Dennis, 2011, P 4 INT WORKSH WHOL
   Ribeiro Tiago, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P189, DOI 10.1007/978-3-642-33197-8_19
   SACKS H, 1974, LANGUAGE, V50, P696, DOI 10.2307/412243
   Sadeghipour A, 2011, COGN COMPUT, V3, P419, DOI 10.1007/s12559-010-9082-z
   Schegloff EA, 2000, LANG SOC, V29, P1, DOI 10.1017/S0047404500001019
   Scherer Stefan, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P455, DOI 10.1007/978-3-642-33197-8_47
   Schlangen D., 2011, DIALOGUE DISCOURSE, V2, P83, DOI DOI 10.5087/DAD.2011.105
   Schlangen David, 2010, P SIGDIAL 2010 C 11, P51
   Schuler W, 2009, COMPUT LINGUIST, V35, P313, DOI 10.1162/coli.08-011-R2-07-021
   Seneff S, 2004, P INTERSPEECH 2004 J, P321
   Skantze G., 2010, P 11 ANN M SPEC INT, P1
   Stone M, 2003, COMPUT INTELL-US, V19, P311
   STREET RL, 1984, HUM COMMUN RES, V11, P139, DOI 10.1111/j.1468-2958.1984.tb00043.x
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Thorisson K., 1996, THESIS MIT CAMBRIDGE
   Traum David, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P275, DOI 10.1007/978-3-642-33197-8_29
   van Welbergen Herwin, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P175, DOI 10.1007/978-3-642-33197-8_18
   Vilhjalmsson HH, 2007, P 7 INT C INT VIRT A, P99
   Wykowska A, 2009, J EXP PSYCHOL HUMAN, V35, P1755, DOI 10.1037/a0016798
NR 48
TC 16
Z9 16
U1 0
U2 5
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1783-7677
EI 1783-8738
J9 J MULTIMODAL USER IN
JI J. Multimodal User Interfaces
PD MAR
PY 2014
VL 8
IS 1
SI SI
BP 97
EP 108
DI 10.1007/s12193-013-0130-3
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ5UA
UT WOS:000337753000009
OA Green Submitted
DA 2022-08-02
ER

PT C
AU Baena-Perez, R
   Ruiz-Rube, I
   Dodero, JM
   Bolivar, MA
AF Baena-Perez, Ruben
   Ruiz-Rube, Ivan
   Manuel Dodero, Juan
   Angel Bolivar, Miguel
BE Dorronsoro, B
   Ruiz, P
   DeLaTorre, JC
   Urda, D
   Talbi, EG
TI A Framework to Create Conversational Agents for the Development of Video
   Games by End-Users
SO OPTIMIZATION AND LEARNING
SE Communications in Computer and Information Science
LA English
DT Proceedings Paper
CT 3rd International Conference on Optimization and Learning (OLA)
CY FEB 17-19, 2020
CL Cadiz, SPAIN
DE Video games; End-User Development; Conversational agents; Model-Driven
   Engineering; Domain Specific Languages; Chatbots
AB Video game development is still a difficult task today, requiring strong programming skills and knowledge of multiple technologies. To tackle this problem, some visual tools such as Unity or Unreal have appeared. These tools are effective and easy to use, but they are not entirely aimed at end-users with little knowledge of software engineering. Currently, there is a resurgence in the use of chatbots thanks to the recent advances in fields such as artificial intelligence or language processing. However, there is no evidence about the use of conversational agents for developing video games with domain-specific languages (DSLs). This work states the following two hypotheses: (i) Conversational agents based on natural language can be used to work with DSL for the creation of video games; (ii) these conversational agents can be automatically created by extracting the concepts, properties and relationships from their abstract syntax. To demonstrate the hypotheses, we propose and detail the implementation of a framework to work with DSLs through a chatbot, its implementation details and a systematic method to automate its construction. This approach could be also suitable for other disciplines, in addition to video games development.
C1 [Baena-Perez, Ruben; Ruiz-Rube, Ivan; Manuel Dodero, Juan; Angel Bolivar, Miguel] Univ Cadiz, Cadiz, Spain.
RP Baena-Perez, R (corresponding author), Univ Cadiz, Cadiz, Spain.
EM ruben.baena@uca.es; ivan.ruiz@uca.es; juanma.dodero@uca.es;
   mabolivar.perez@uca.es
RI Dodero, Juan Manuel/D-4143-2009; Baena-Perez, Ruben/AAA-7985-2022;
   Ruiz-Rube, Ivan/F-5824-2016
OI Dodero, Juan Manuel/0000-0002-4105-5679; Baena-Perez,
   Ruben/0000-0001-7630-6223; Ruiz-Rube, Ivan/0000-0002-9012-700X
CR Al-Zubaide H., 2011, 2011 Fourth International Symposium on Innovation in Information & Communication Technology (ISIICT), P7, DOI 10.1109/ISIICT.2011.6149594
   [Anonymous], 2019, GAME ENGINES DO THEY GAME ENGINES DO THEY
   Bock BC, 2019, AM J PREV MED, V56, P501, DOI 10.1016/j.amepre.2018.11.026
   Bracq MS, 2019, NURS EDUC TODAY, V79, P153, DOI 10.1016/j.nedt.2019.05.026
   Brambilla M., 2017, MODEL DRIVEN SOFTWAR
   Brandtzaeg PB, 2017, LECT NOTES COMPUT SC, V10673, P377, DOI 10.1007/978-3-319-70284-1_30
   Burnett M, 2009, LECT NOTES COMPUT SC, V5435, P15
   Dorner C, 2011, INTERACT COMPUT, V23, P226, DOI 10.1016/j.intcom.2011.03.001
   Errattahi R, 2018, PROCEDIA COMPUT SCI, V128, P32, DOI 10.1016/j.procs.2018.03.005
   Fowler M., 2010, DOMAIN SPECIFIC LANG
   Gaouar Lamia, 2018, Future Computing and Informatics Journal, V3, P110, DOI 10.1016/j.fcij.2018.02.001
   Garcia CG, 2019, UNIVERSAL ACCESS INF, V18, P599, DOI 10.1007/s10209-019-00681-y
   Jain A., 2018, INT J COMPUT SCI ENG, V6, P7
   Jolak R., 2017, CIBSE 2017 CIBSE 2017, P85
   Ko AJ, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922658
   Maceli Monica G., 2017, End-User Development. 6th International Symposium, IS-EUD 2017. Proceedings: LNCS 10303, P49, DOI 10.1007/978-3-319-58735-6_4
   Mernik M, 2005, ACM COMPUT SURV, V37, P316, DOI 10.1145/1118890.1118892
   Pane JF, 2006, HUM COM INT, V9, P31
   Perez-Soler S, 2018, IEEE SOFTWARE, V35, P48, DOI 10.1109/MS.2018.290101511
   Nunez-Valdez ER, 2017, J AMB INTEL HUM COMP, V8, P435, DOI 10.1007/s12652-016-0404-1
   Rosenblatt L, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P417, DOI 10.1145/3132525.3134824
   Selic B, 2003, IEEE SOFTWARE, V20, P19, DOI 10.1109/MS.2003.1231146
   Solis-Martinez J, 2015, COMPUT STAND INTER, V42, P42, DOI 10.1016/j.csi.2015.04.009
   Vaziri M, 2017, P 2017 ACM SIGPLAN I, P44
   Whittle J, 2014, IEEE SOFTWARE, V31, P79, DOI 10.1109/MS.2013.65
   Wijman T., 2019, NEWZOOS GAMES TRENDS, P19
   Yannakakis G.N., 2018, ARTIF INTELL, DOI [10.1007/978-3-319-63519-4, DOI 10.1007/978-3-319-63519-4]
NR 27
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1865-0929
EI 1865-0937
BN 978-3-030-41913-4; 978-3-030-41912-7
J9 COMM COM INF SC
PY 2020
VL 1173
BP 216
EP 226
DI 10.1007/978-3-030-41913-4_18
PG 11
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR9NC
UT WOS:000678761600018
DA 2022-08-02
ER

PT C
AU Lovato, SB
   Piper, AM
   Wartella, EA
AF Lovato, Silvia B.
   Piper, Anne Marie
   Wartella, Ellen A.
GP ACM
TI "Hey Google, Do Unicorns Exist?": Conversational Agents as a Path to
   Answers to Children's Questions
SO PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019)
LA English
DT Proceedings Paper
CT 18th Annual ACM Interaction Design and Children (IDC)
CY JUN 12-15, 2019
CL Boise, ID
SP Boise State Univ, Stem Act Ctr, St Lukes, Osmo, Langan Barber Fdn, Discovery Ctr Idaho, StemFinity, NSF, Boise
DE Children; Question-Asking; Conversational Agents; Voice User Interfaces;
   Digital Assistants; Smart Speakers
ID INFORMATION; BEHAVIOR
AB Children are known to be curious and persistent question-askers. The pervasiveness of voice interfaces represents an opportunity for children who are not yet fluent readers to independently search the Internet by asking questions through conversational agents such as Amazon Alexa, Apple's Siri, and the Google Assistant. Through a two-week, in-home deployment study involving 18 families (children aged 5-6 and their parents), we report on which questions children choose to ask the conversational agent, the answers the agent provided, challenges in use, and their perceptions of the technology. Based on our analysis, we identify several considerations for the design of voice based conversational agents that aim to support young children's question-asking behavior and subsequent development.
C1 [Lovato, Silvia B.; Piper, Anne Marie; Wartella, Ellen A.] Northwestern Univ, Evanston, IL 60208 USA.
RP Lovato, SB (corresponding author), Northwestern Univ, Evanston, IL 60208 USA.
EM slovato@u.northwestern.edu; ampiper@northwestern.edu;
   ellen-wartella@northwestern.edu
OI Piper, Anne Marie/0000-0003-3085-3277
CR Abramovich Giselle, 2018, STUDY FINDS CONSUMER
   [Anonymous], 2012, TRUSTING WHAT YOURE
   Bilal D, 2002, J AM SOC INF SCI TEC, V53, P1170, DOI 10.1002/asi.10145
   Boyatzis R. E., 1998, TRANSFORMING QUALITA
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]
   Brennan SE, 1998, SOCIAL AND COGNITIVE APPROACHES TO INTERPERSONAL COMMUNICATION, P201
   CALLANAN MA, 1992, COGNITIVE DEV, V7, P213, DOI 10.1016/0885-2014(92)90012-G
   Chall Jeanne S., 2003, QUICK ADULT READING
   Cheng Y, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P337, DOI 10.1145/3202185.3202749
   Chouinard M. M., 2007, MONOGRAPHS SOC RES C, P129
   Clark H. H., 1991, PERSPECTIVES SOCIALL, V13, P127, DOI DOI 10.1037/10096-006
   Danovitch JH, 2013, J COGN DEV, V14, P499, DOI 10.1080/15248372.2012.689391
   Druga S, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P595, DOI 10.1145/3078072.3084330
   Druin, 2009, P 8 INT C INT DES CH, P89, DOI DOI 10.1145/1551788.1551804
   Druin, 2014, SYNTHESIS LECT INFOR, V6, P1, DOI 10.2200/S00591ED1V01Y201408ICR034
   Druin A, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P413
   Gauvain M, 2013, J CROSS CULT PSYCHOL, V44, P1148, DOI 10.1177/0022022113485430
   HENDERSON RW, 1973, AM EDUC RES J, V10, P193
   Huang Ting-Hao Kenneth, 2018, P 2018 CHI C HUM FAC, P295
   IBM, 2018, CONV CONT WILL USH A
   Kahn PH, 2012, DEV PSYCHOL, V48, P303, DOI 10.1037/a0027033
   Kennedy J, 2017, ACMIEEE INT CONF HUM, P82, DOI 10.1145/2909824.3020229
   Kurkul KE, 2018, CHILD DEV, V89, P280, DOI 10.1111/cdev.12726
   Lovato Silvia, 2015, P 14 INT C INT DES C, P335, DOI [10.1145/2771839.2771910, DOI 10.1145/2771839.2771910]
   Maier A., 2011, ACM T SPEECH LANG PR, V7, P17
   MARCHIONINI G, 1989, J AM SOC INFORM SCI, V40, P54, DOI 10.1002/(SICI)1097-4571(198901)40:1<54::AID-ASI6>3.0.CO;2-R
   Markant D, 2014, MEM COGNITION, V42, P1211, DOI 10.3758/s13421-014-0435-9
   McGregor Jay, 2017, AMAZON ECHO VS GOOGL
   McKenney S, 2010, COMPUT HUM BEHAV, V26, P656, DOI 10.1016/j.chb.2010.01.002
   Mills CM, 2011, J EXP CHILD PSYCHOL, V110, P539, DOI 10.1016/j.jecp.2011.06.003
   Nass Clifford, 2005, WIRED SPEECH VOICE A
   Nielsen, 2018, SMART SPEAK MY LANG
   NIKKEN P, 1988, J BROADCAST ELECTRON, V32, P441
   Partridge E., 2015, P 37 ANN C COGN SCI
   Purington A, 2017, 2017 CHI C HUM FACT, DOI [10.1145/3027063.3053246, DOI 10.1145/3027063.3053246]
   Pyae A., 2018, P 20 INT C HUMAN COM, P127
   Rideout V., 2017, COMMON SENSE CENSUS
   Rucker MT, 2016, J SCI EDUC TECHNOL, V25, P274, DOI 10.1007/s10956-015-9592-2
   Sciuto A, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P857, DOI 10.1145/3196709.3196772
   SOLOMON P, 1993, J AM SOC INFORM SCI, V44, P245, DOI 10.1002/(SICI)1097-4571(199306)44:5<245::AID-ASI1>3.0.CO;2-#
   Teale W.H., 1986, EMERGENT LITERACY WR
   Tizard B., 1984, YOUNG CHILDREN LEARN
   Turkle S., 1984, 2 SELF COMPUTERS HUM
   Van Duuren M, 1998, INT J BEHAV DEV, V22, P871, DOI 10.1080/016502598384207
   Vygotsky L. S., 1978, MIND SOC DEV HIGHER
   Ward W., 2011, ACM T SPEECH LANG PR, V7, P18
   Wellman HM, 2004, CHILD DEV, V75, P523, DOI 10.1111/j.1467-8624.2004.00691.x
   Woodward Julia, 2018, P 2018 CHI C HUM FAC, P575
   Yarosh S, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P300, DOI 10.1145/3202185.3202207
NR 49
TC 32
Z9 32
U1 0
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6690-8
PY 2019
BP 301
EP 313
DI 10.1145/3311927.3323150
PG 13
WC Computer Science, Interdisciplinary Applications; Education, Scientific
   Disciplines
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Education & Educational Research
GA BP6EZ
UT WOS:000559055100033
DA 2022-08-02
ER

PT S
AU Graesser, AC
   Dowell, N
   Clewley, D
AF Graesser, Arthur C.
   Dowell, Nia
   Clewley, Danielle
BE VonDavier, AA
   Zhu, M
   Kyllonen, PC
TI Assessing Collaborative Problem Solving Through Conversational Agents
SO INNOVATIVE ASSESSMENT OF COLLABORATION
SE Methodology of Educational Measurement and Assessment
LA English
DT Article; Book Chapter
DE Autotutor; Conversational agents; Cohesion; Coh-Metrix; Collaborative
   problem solving; Emotions; Feedback; Intelligent tutoring systems; PISA;
   Trialogues; Tutoring
ID NATURAL-LANGUAGE; AUTOTUTOR; DIALOGUE; TUTOR; GAME
AB Communication is a core component of collaborative problem solving and its assessment. Advances in computational linguistics and discourse science have made it possible to analyze conversation on multiple levels of language and discourse in different educational settings. Most of these advances have focused on tutoring contexts in which a student and a tutor collaboratively solve problems, but there has also been some progress in analyzing conversations in small groups. Naturalistic patterns of collaboration in one-on-one tutoring and in small groups have also been compared with theoretically ideal patterns. Conversation-based assessment is currently being applied to measure various competencies, such as literacy, mathematics, science, reasoning, and collaborative problem solving. One conversation-based assessment approach is to design computerized conversational agents that interact with the human in natural language. This chapter reports research that uses one or more agents to assess human competencies while the humans and agents collaboratively solve problems or answer difficult questions. AutoTutor holds a collaborative dialogue in natural language and concurrently assesses student performance. The agent converses through a variety of dialogue moves: questions, short feedback, pumps for information, hints, prompts for specific words, corrections, assertions, summaries, and requests for summaries. Trialogues are conversations between the human and two computer agents that play different roles (e.g., peer, tutor, expert). Trialogues are being applied in both training and assessment contexts on particular skills and competencies. Agents are currently being developed at Educational Testing Service for assessments of individuals on various competencies, including the Programme for International Student Assessment 2015 assessment of collaborative problem solving.
C1 [Graesser, Arthur C.; Dowell, Nia; Clewley, Danielle] Univ Memphis, Memphis, TN 38152 USA.
RP Graesser, AC (corresponding author), Univ Memphis, Memphis, TN 38152 USA.
EM graesser@memphis.edu; ndowell@memphis.edu; dnclwley@memphis.edu
RI Dowell, Nia/AAQ-2973-2020
OI Dowell, Nia/0000-0002-9839-8947
CR Biswas G., 2010, RES PRACT TECH ENHAN, V05, P123, DOI 10.1142/S1793206810000839
   Cade WL, 2008, LECT NOTES COMPUT SC, V5091, P470
   Cai Z., 2011, P 3 IEEE INT C INT C, P429
   Cai Z., 2015, DESIGN RECOMMENDATIO, V3, P199
   Cai Z., 2014, DESIGN RECOMMENDATIO, V2, P225
   Care E., 2014, RES PRACTICE TECHNOL, V9, P367
   Chi MTH, 2001, COGNITIVE SCI, V25, P471, DOI 10.1016/S0364-0213(01)00044-1
   COHEN PA, 1982, AM EDUC RES J, V19, P237, DOI 10.2307/1162567
   D'Mello S, 2014, LEARN INSTR, V29, P153, DOI 10.1016/j.learninstruc.2012.05.003
   D'Mello SK, 2012, IEEE T LEARN TECHNOL, V5, P304, DOI 10.1109/TLT.2012.10
   D'Mello SK, 2011, J EXP PSYCHOL-APPL, V17, P1, DOI 10.1037/a0022674
   Dede C., 2015, DATA INTENSIVE RES E
   Dowell N. M., J LEARNING IN PRESS, VXX, pXX
   Fiore SM, 2010, HUM FACTORS, V52, P203, DOI 10.1177/0018720810369807
   Graesser A. C., TEACHERS CO IN PRESS
   Graesser A. C., 2012, APA HDB RES METHODS, P307
   Graesser A. C., 2016, NATURE PROBLEM SOLVI, P275
   Graesser A. C., 1921, ASESSMENT TEACHING 2
   Graesser A. C., 2013, J ED DATA MINING, V5, P147
   Graesser A. C., 2015, EMOTIONS TECHNOLOGY, P1
   Graesser A. C., 2012, APPL NATURAL LANGUAG, P169
   Graesser AC, 2005, EDUC PSYCHOL-US, V40, P225, DOI 10.1207/s15326985ep4004_4
   Graesser AC, 2004, BEHAV RES METH INS C, V36, P180, DOI 10.3758/BF03195563
   GRAESSER AC, 1995, APPL COGNITIVE PSYCH, V9, P495, DOI 10.1002/acp.2350090604
   Graesser AC, 2008, DISCOURSE PROCESS, V45, P298, DOI 10.1080/01638530802145395
   Graesser AC, 2014, ELEM SCHOOL J, V115, P210, DOI 10.1086/678293
   Graesser AC, 2014, CURR DIR PSYCHOL SCI, V23, P374, DOI 10.1177/0963721414540680
   Graesser AC, 2011, EDUC PSYCHOL HANDB, P408
   Griffin P, 2014, ASSESSMENT FOR TEACHING, P1
   Halpern DF, 2012, THINK SKILLS CREAT, V7, P93, DOI 10.1016/j.tsc.2012.03.006
   Jackson GT, 2006, REV SIGNOS, V39, P31, DOI 10.4067/S0718-09342006000100002
   Jackson GT, 2013, J EDUC PSYCHOL, V105, P1036, DOI 10.1037/a0032580
   Jurafsky D., 2020, SPEECH LANGUAGE PROC
   Lehman B., 2013, INT J ARTIFICIAL INT, V22, P85
   McNamara DS, 2014, AUTOMATED EVALUATION
   Millis K., 2011, SERIOUS GAMES EDUTAI, P169, DOI DOI 10.1007/978-1-4471-2161-9_10
   Morgan Brent, 2012, Intelligent Tutoring Systems. Proceedings 11th International Conference (ITS 2012), P162, DOI 10.1007/978-3-642-30950-2_21
   Nye B, 2014, INT J ARTIF INTELL E, V24, P427, DOI 10.1007/s40593-014-0029-5
   OECD, 2013, PISA 2015 COLL PROBL
   Olney Andrew M., 2012, Intelligent Tutoring Systems. Proceedings 11th International Conference (ITS 2012), P256, DOI 10.1007/978-3-642-30950-2_32
   Pennebaker J. W., 2007, LIWC2007 LINGUISTIC
   Rose C, 2008, INT J COMP-SUPP COLL, V3, P237, DOI 10.1007/s11412-007-9034-0
   Rowe J., 2010, INT J ARTIFICIAL INT, V21, P166
   Rus V, 2008, INT J ARTIF INTELL T, V17, P659, DOI 10.1142/S0218213008004096
   Rus V, 2013, AI MAG, V34, P42, DOI 10.1609/aimag.v34i3.2485
   Shute V. J., 2013, MEASURING SUPPORTING
   Sottilare R., 2013, DESIGN RECOMMENDATIO, V1
   VanLehn K, 2007, COGNITIVE SCI, V31, P3, DOI 10.1080/03640210709336984
   VanLehn K, 2011, EDUC PSYCHOL-US, V46, P197, DOI 10.1080/00461520.2011.611369
   Ward W, 2013, J EDUC PSYCHOL, V105, P1115, DOI 10.1037/a0031589
   Zapata-Rivera D., 2015, DESIGN RECOMMENDATIO, V3, P169
NR 51
TC 7
Z9 7
U1 1
U2 15
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2367-170X
BN 978-3-319-33261-1; 978-3-319-33259-8
J9 METHOD EDUC MEAS
PY 2017
BP 65
EP 80
DI 10.1007/978-3-319-33261-1_5
D2 10.1007/978-3-319-33261-1
PG 16
WC Education & Educational Research
WE Book Citation Index – Social Sciences & Humanities (BKCI-SSH)
SC Education & Educational Research
GA BJ1EW
UT WOS:000417624500006
DA 2022-08-02
ER

PT C
AU Clark, L
   Pantidi, N
   Cooney, O
   Doyle, P
   Garaialde, D
   Edwards, J
   Spillane, B
   Gilmartin, E
   Murad, C
   Munteanu, C
   Wade, V
   Cowan, BR
AF Clark, Leigh
   Pantidi, Nadia
   Cooney, Orla
   Doyle, Philip
   Garaialde, Diego
   Edwards, Justin
   Spillane, Brendan
   Gilmartin, Emer
   Murad, Christine
   Munteanu, Cosmin
   Wade, Vincent
   Cowan, Benjamin R.
GP Assoc Comp Machinery
TI What Makes a Good Conversation? Challenges in Designing Truly
   Conversational Agents
SO CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN
   COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY MAY 04-09, 2019
CL Glasgow, SCOTLAND
SP Assoc Comp Machinery, ACM SIGCHI
DE Conversational Agents; Speech HCI; Spoken Dialogue Systems; Voice User
   Interface Design; Interviews
AB Conversational agents promise conversational interaction but fail to deliver. Efforts often emulate functional rules from human speech, without considering key characteristics that conversation must encapsulate. Given its potential in supporting long-term human-agent relationships, it is paramount that HCI focuses efforts on delivering this promise. We aim to understand what people value in conversation and how this should manifest in agents. Findings from a series of semi-structured interviews show people make a clear dichotomy between social and functional roles of conversation, emphasising the long-term dynamics of bond and trust along with the importance of context and relationship stage in the types of conversations they have. People fundamentally questioned the need for bond and common ground in agent communication, shifting to more utilitarian definitions of conversational qualities. Drawing on these findings we discuss key challenges for conversational agent design, most notably the need to redefine the design parameters for conversational agent interaction.
C1 [Clark, Leigh; Cooney, Orla; Garaialde, Diego; Edwards, Justin; Cowan, Benjamin R.] Univ Coll Dublin, Dublin, Ireland.
   [Pantidi, Nadia] Univ Coll Cork, Cork, Ireland.
   [Doyle, Philip] Voysis Ltd, Dublin, Ireland.
   [Spillane, Brendan; Gilmartin, Emer; Wade, Vincent] Trinity Coll Dublin, Dublin, Ireland.
   [Murad, Christine] Univ Toronto, Toronto, ON, Canada.
   [Munteanu, Cosmin] Univ Toronto Mississauga, Mississauga, ON, Canada.
RP Clark, L (corresponding author), Univ Coll Dublin, Dublin, Ireland.
EM leigh.clark@ucd.ie; konstantia.pantidi@ucc.ie;
   orla.cooney@ucdconnect.ie; pdoyle@voysis.com;
   diego.garaialde@ucdconnect.ie; justin.edwards@ucdconnect.ie;
   brendan.spillane@adaptcentre.ie; gilmare@tcd.ie; cmurad@taglab.ca;
   cosmin@taglab.ca; vincent.wade@adaptcentre.ie; benjamin.cowan@ucd.ie
RI Edwards, Justin/AAR-1691-2021
OI Edwards, Justin/0000-0003-1487-9207; Clark, Leigh/0000-0002-9237-1057;
   Cowan, Benjamin/0000-0002-8595-8132; Pantidi, Nadia/0000-0003-2703-6022;
   Spillane, Brendan/0000-0001-5893-1340
FU Irish Research Council [7516751]
FX <Irish Research
   Council>(<https://app.dimensions.ai/details/grant/grant.7516751>)
CR Abdolrahmani A, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P249, DOI 10.1145/3234695.3236344
   [Anonymous], 1987, POLITENESS SOME UNIV
   [Anonymous], 2018, BUSINESSWIRE
   [Anonymous], 2017, P 19 INT C HUMAN COM, DOI DOI 10.1145/3098279.3098539
   Bentley Frank, 2018, P ACM INT MOB WEAR U, V2
   Bickmore T., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P396
   Bickmore T., 2004, CHI 04 HUM FACT COMP, P1489, DOI DOI 10.1145/985921.986097
   Bickmore T.W., 2005, CHI 05 EXTENDED ABST, P1212, DOI [https://doi.org/10.1145/1056808.1056879, DOI 10.1145/1056808.1056879, 10.1145/1056808.1056879]
   Bickmore T, 2005, TEXT SPEECH LANG TEC, V30, P23
   Bickmore TW, 2010, INTERACT COMPUT, V22, P289, DOI 10.1016/j.intcom.2009.12.001
   Branigan HP, 2011, COGNITION, V121, P41, DOI 10.1016/j.cognition.2011.05.011
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]
   Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1
   Brown G, 1983, DISCOURSE ANAL
   Bruce A, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P4138, DOI 10.1109/ROBOT.2002.1014396
   CHEEPEN C, 1988, PREDICTABILITY INFOR
   Clark H.H., 1992, ARENAS LANGUAGE USE
   Clark H.H, 1996, USING LANGUAGE
   Clark Herbert H., 1991, PERSPECT SOC SHARED, P127, DOI DOI 10.1037/10096-006
   Clark P, 2018, TLS-TIMES LIT SUPPL, P32
   Devillers L, 2018, IEEE INT CONF AUTOMA, P697, DOI 10.1109/FG.2018.00110
   Dubberly H., 2009, INTERACTIONS, V16, P22, DOI DOI 10.1145/1551986.1551991
   Dunbar R., 1998, GROOMING GOSSIP EVOL
   Eggins S., 2005, ANAL CASUAL CONVERSA, V2nd
   Fang Hao, 2017, SOUNDING BOARD U WAS, P12
   Gilmartin E, 2018, J MULTIMODAL USER IN, V12, P297, DOI 10.1007/s12193-018-0274-2
   Gilmartin Emer, 2017, P 1 ACM SIGCHI INT W, P31, DOI DOI 10.1145/3139491.3139494
   Gockley R, 2005, IEEE RSJ INT C INT R, P1338, DOI DOI 10.1109/IROS.2005.1545303
   Goffman E., 2017, INTERACTION RITUAL E, Vfirst, DOI [10.4324/9780203788387., DOI 10.4324/9780203788387]
   Jaworski Adam, 2014, SMALL TALK, P130
   Kidwell Mardi, 2000, ISSUES APPL LINGUIST, V11
   Kuno Y, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1191
   Looije R, 2010, INT J HUM-COMPUT ST, V68, P386, DOI 10.1016/j.ijhcs.2009.08.007
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Malinowski Bronislaw, 1994, LANGUAGE LITERACY SO, P1
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   Mehrotra R, 2017, J GLOB ONCOL, V4, DOI 10.1200/JGO.17.00030
   Moore Roger K, 2017, DIALOGUES SOCIAL ROB, P281, DOI DOI 10.1007/978-981-10-2585-3_22
   Moorthy AE, 2015, INT J HUM-COMPUT INT, V31, P307, DOI 10.1080/10447318.2014.986642
   Munteanu C., 2017, CHI 17 P 2017 ACM SI, P601
   Ostrowski J, 2007, IEEE ROBOT AUTOM MAG, V14, P9, DOI 10.1109/MRA.2007.339602
   Papaioannou Ioannis, 2017, AL PRIZ P
   Pfeifer Vardoulakis Laura, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P289, DOI 10.1007/978-3-642-33197-8_30
   Porcheron M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174214
   Purington A, 2017, 2017 CHI C HUM FACT, DOI [10.1145/3027063.3053246, DOI 10.1145/3027063.3053246]
   Reeves S, 2017, TALKING CONVERSATION
   Reeves S, 2012, P SIGCHI C HUM FACT, P1573
   Rodden T.A., 2013, P SIGCHI C HUM FACT, P1173, DOI 10.1145/ 2470654.2466152
   Sabelli AM, 2011, ACMIEEE INT CONF HUM, P37, DOI 10.1145/1957656.1957669
   Sacks H., 1987, TALK SOCIAL ORG, P54
   Sacks Harvey, 1978, STUDIES ORG CONVERSA, P7, DOI DOI 10.1016/B978-0-12-623550-0.50008-2
   Saerbeck M, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1613
   SCHNEIDER R, 1988, DOMUS, P1
   Spillane B, 2017, P 1 ACM SIGCHI INT W, P43, DOI [10.1145/3139491.3139492, DOI 10.1145/3139491.3139492]
   Tsai Janice Y., 2018, WORKSH VOIC BAS CONV
   Yarosh S, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P300, DOI 10.1145/3202185.3202207
   Ziv A, 2010, SOCIETY, V47, P11, DOI 10.1007/s12115-009-9283-9
NR 57
TC 63
Z9 63
U1 3
U2 14
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5970-2
PY 2019
DI 10.1145/3290605.3300705
PG 12
WC Computer Science, Cybernetics; Computer Science, Information Systems;
   Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BN1HE
UT WOS:000474467906011
OA Green Published, Green Submitted
DA 2022-08-02
ER

PT B
AU Andrews, P
   Quarteroni, S
AF Andrews, Pierre
   Quarteroni, Silvia
BA PerezMarin, D
   PascualNieto, I
BF PerezMarin, D
   PascualNieto, I
TI Extending Conversational Agents for Task-Oriented Human-Computer
   Dialogue
SO CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND
   EFFECTIVE PRACTICES
LA English
DT Article; Book Chapter
AB We present the role of conversational agents in two task-oriented human-computer dialogue applications: Interactive Question Answering and Persuasive Dialogue. We show that conversational agents can be effectively deployed for interaction that goes beyond user entertainment and can be successfully used as a means to achieve complex tasks. Conversational agents are a winning solution in Persuasive Dialogue because, combined with a planning infrastructure, they can help manage the parts of the dialogue that cannot be planned a priori and are primordial to keep the system persuasive. In Interactive Question Answering, conversational approaches lead users to the explicit formulation of queries, allow for the submission of further queries and accomodate related queries thanks to their ability to handle context.
C1 [Andrews, Pierre] Univ Trent, Knowd Grp, I-38100 Trento, Italy.
RP Andrews, P (corresponding author), Univ Trent, Knowd Grp, I-38100 Trento, Italy.
CR Alexandersson J., 1997, INSIGHTS DIALOGUE PR
   Allen J., 2000, HDB NATURAL LANGUAGE, P347
   Allen J., 2001, IUI 01 P 6 INT C INT
   Andrews P., 2009, P AISB 09 PERS TECHN
   [Anonymous], 2003, PERSUASIVE TECHNOLOG
   Basili R., 2007, P AI IA 07
   Bickmore T., 2004, AAAI FALL S DIAL SYS
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Blum AL, 1997, ARTIF INTELL, V90, P281, DOI 10.1016/S0004-3702(96)00047-1
   Bos J., 2003, P SIGDIAL 03
   Cahn J. E., 1999, Psychological Models of Communication in Collaborative Systems. Papers from the 1999 AAAI Fall Symposium (TR FS-99-03), P25
   Cassell J., 2002, USER MODELL IN PRESS
   Churcher G. E., 1997, DIALOGUE MNAGEMENT S
   Cohen P., 1996, SURVEY STATE ART HUM, P192
   CORE MG, 1997, AAAI FALL S COMM ACT, P28
   De Boni M., 2005, NAT LANG ENG, V11
   Farzanfar R, 2005, J BIOMED INFORM, V38, P220, DOI 10.1016/j.jbi.2004.11.011
   Festinger L., 1957, THEORY COGNITIVE DIS
   Field D., 2006, P 5 WORKSH INF COMP, P27
   Freedman R, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, P52
   Galibert O., 2005, P INTERSPEECH 05
   Gilbert M. A., 2003, ARGUMENTATION MACHIN
   Ginzburg J., 1996, INTERROGATIVES QUEST
   Gorin A. L., 1999, MAY I HELP YOU COMPU
   Grosz B. J., 1986, Computational Linguistics, V12, P175
   GUERINI M, 2003, P IJCAI WORKSH COMP
   Jonsson A., 2003, AAAI SPRING S 03
   Kato T., 2006, P IQA 06
   Kirschner M., 2009, P NAACL HLT STUDENT
   Kitano H., 1991, P 29 ANN M, P25, DOI 10.3115/981344.981348
   Klein J., 1999, CHI 99 HUM FACT COMP
   Kwok C. T., 2001, P WWW 01
   LEVY D, 1997, P 1 INT WORKSH HUM C
   Lewin I., 2000, SIRIDUS SYSTEM ARCHI
   Maybury M. T., 2002, QUESTION ANSWERING R
   Mazzotta I, 2007, IEEE INTELL SYST, V22, P42, DOI 10.1109/MIS.2007.115
   Quarteroni S, 2009, NAT LANG ENG, V15, P73, DOI 10.1017/S1351324908004919
   Quarteroni S., 2009, SING KRAQ 09
   Reiter E., 1997, Natural Language Engineering, P57, DOI 10.1017/S1351324997001502
   SIMMONS RF, 1965, COMMUN ACM, V8, P53, DOI 10.1145/363707.363732
   Sinclair JM, 1975, ANAL DISCOURSE ENGLI
   Small S., 2003, P ACL 2003 WORKSH MU, P46
   Stent AJ, 2002, COMPUT SPEECH LANG, V16, P313, DOI 10.1016/S0885-2308(02)00009-8
   Sutton S., 1998, P INT C SPOK LANG PR
   TRAUM DR, 1996, P 11 TWENT WORKSH LA, P1
   Vrajitoru D., 2003, P GEN EV COMP C GECC, P315
   Walker MA, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P271
   Walton D., 1996, ARGUMENT STRUCTURE P
   Webb N., 2006, P INT QUEST ANSW WOR
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Yang F., 2006, P IQA
   Young S, 2010, COMPUT SPEECH LANG, V24, P150, DOI 10.1016/j.csl.2009.04.001
   Zhe X., 2002, INT S CSNDSP
   Zinn C, 2002, LECT NOTES COMPUT SC, V2363, P574
   [No title captured]
   [No title captured]
NR 56
TC 0
Z9 0
U1 0
U2 3
PU IGI GLOBAL
PI HERSEY
PA 701 E CHOCOLATE AVE, STE 200, HERSEY, PA 17033-1240 USA
BN 978-1-60960-618-3; 978-1-60960-617-6
PY 2011
BP 177
EP 202
DI 10.4018/978-1-60960-617-6.ch008
D2 10.4018/978-1-60960-617-6
PG 26
WC Computer Science, Artificial Intelligence
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BZX29
UT WOS:000303201400009
DA 2022-08-02
ER

PT C
AU Allela, MA
AF Allela, Melisa Achoko
BE WinschiersTheophilus, H
   VanZyl, I
   Goagoses, N
   Jat, DS
   Belay, EG
   Orji, R
   Peters, A
TI Technological Speculations for African Oral storytelling: Implication of
   creating expressive Embodied Conversational Agents
SO PROCEEDINGS OF THE SECOND AFRICAN CONFERENCE FOR HUMAN COMPUTER
   INTERACTION: THRIVING COMMUNITIES (AFRICHI)
LA English
DT Proceedings Paper
CT 2nd African Conference for Human Computer Interaction - Thriving
   Communities (AfriCHI)
CY DEC 03-07, 2018
CL Namibia Univ Sci & Technol, Windhoek, NAMIBIA
SP First Natl Bank, Mozilla, ICT4D, UEGroup, Swedish Program ICT Developing Reg, IPID, ACM SIGCHI, Namibia Univ Sci & Technol, Fac Comp & Informat, ACM Chapter
HO Namibia Univ Sci & Technol
DE Animation; Oral Storytelling; Performance; cultural digitization;
   Embodied Conversational Agents (ECAs)
ID INTELLIGENCE
AB Works of African orature, owing to their performative and participatory nature, are challenging to reproduce in written text, or as linear media in audio or video formats (animation or live action). This has created a research gap in virtual heritage research where emphasis has been placed on digitalization of tangible culture. In my dissertation, I examine the implication of bodily, expressive non-verbal characteristics of performance in traditional African oral storytelling to position their mediation in digital media formats using Embodied Conversational Agents (ECAs). Using the iconic Song of Lawino [2] as a research example for reenactment using ECAs, I illustrate that applying these performance elements and techniques can result in a new digitally embodied oral narrative that mimics the unique relationship in traditional African orature between a storyteller, the space in which the story is told and the audience.
C1 [Allela, Melisa Achoko] Tech Univ Kenya, Dept Design & Creat Media, Nairobi, Kenya.
RP Allela, MA (corresponding author), Tech Univ Kenya, Dept Design & Creat Media, Nairobi, Kenya.
EM melisallela@gmail.com
OI Achoko Allela, Melisa/0000-0002-8150-1186
CR Affiah U., 2012, IOSR J HUMANITIES SO, V5, P6
   Bitek O., 1972, SONG LAWINO SONG OCO
   Bulitko V, 2012, AI MAG, V33, P51
   Cassell J, 2001, AI MAG, V22, P67
   Castellano G, 2007, LECT NOTES COMPUT SC, V4738, P71
   Chandler T., 2017, AUST NZ J ART, V17, P182, DOI [10.1080/14434318.2017.1450063, DOI 10.1080/14434318.2017.1450063]
   CMU, 2018, CMU GRAPH LAB MOT CA CMU GRAPH LAB MOT CA
   Dirk Heylen, 2018, FACIAL EXPRESSIONS C
   Fuchs Michael, 2017, COLLECTIVE BODY MEMO
   Kenny P, 2007, BUILDING INTERACTIVE, V2007
   Kenny Patrick, 2008, P 1 INT C PERV TECHN, P1
   Ladeira I., 2007, PRESENCE 2007, P257
   Liverpool James Moore University, 2018, AN PEOPL
   Machidon OM, 2018, J CULT HERIT, V33, P249, DOI 10.1016/j.culher.2018.01.007
   Mateas M., 2001, Digital Creativity, V12, P140, DOI 10.1076/digc.12.3.140.3224
   Max Planck Institute for Intelligent Systems, 2018, MOT CAPT
   Mueller Pascal, 2007, VAST, P109, DOI DOI 10.2312/VAST/VAST07/109
   Pido Odoch, 2007, JAHAZI, V1
   Ramazani Jahan, 2001, HYBRID MUSE POSTCOLO
   Rizzo Albert, 2011, MED MEETS VIRTUAL RE
   Schnipper de Leeuw W. J. J, 1980, ORIGIN FORMS DRAMA E
   Simon Fraser University, 2018, SFU MOT CAPT DAT
   UNESCO, 2018, INTANGIBLE HERITAGE
   wa Thiongo Ngugi, 1986, DECOLONISING MIND PO
NR 24
TC 0
Z9 0
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6558-1
PY 2018
BP 251
EP 254
DI 10.1145/3283458.3283510
PG 4
WC Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BN2CA
UT WOS:000475845000043
DA 2022-08-02
ER

PT C
AU Kerly, A
   Ellis, R
   Bull, S
AF Kerly, Alice
   Ellis, Richard
   Bull, Susan
BE Allen, T
   Ellis, R
   Petridis, M
TI Conversational Agents in E-Learning
SO APPLICATIONS AND INNOVATIONS IN INTELLIGENT SYSTEMS XVI
LA English
DT Proceedings Paper
CT 28th SGAI International Conference on Innovative Techniques and
   Applications of Artificial Intelligence
CY DEC, 2008
CL Cambridge, ENGLAND
SP British Comp Soc Specialist Grp Artificial Intelligence
AB This paper discusses the use of natural language or 'conversational' agents in e-learning environments. We describe and contrast the various applications of conversational agent technology represented in the e-learning literature, including tutors, learning companions, language practice and systems to encourage reflection. We offer two more detailed examples of conversational agents, one which provides learning support, and the other Support for self-assessment. Issues and challenges for developers of conversational agent systems for e-learning are identified and discussed.
C1 [Kerly, Alice] Univ Birmingham, Birmingham B15 2TT, W Midlands, England.
   [Ellis, Richard] Elzware Ltd, Bristol BS3 4NY, Avon, England.
   [Bull, Susan] Univ Birmingham, Elect Elect & Comp Engn, Birmingham B15 2TT, W Midlands, England.
RP Kerly, A (corresponding author), Univ Birmingham, Birmingham B15 2TT, W Midlands, England.
EM alk584@bham.ac.uk; richard.ellis@elzware.com; s.bull@bham.ac.uk
OI Bull, Susan/0000-0002-1779-528X
CR Aimeur E, 1997, FR ART INT, V39, P119
   Aleven V, 2004, LECT NOTES COMPUT SC, V3220, P443
   Aleven V, 1999, FRONT ARTIF INTEL AP, V50, P199
   Beun RJ, 2003, LECT NOTES ARTIF INT, V2792, P315
   BULL S, 1995, INSTR SCI, V23, P65, DOI 10.1007/BF00890446
   CHAN TW, 1988, ITS 88 P JUN, P194
   Chou CY, 2003, COMPUT EDUC, V40, P255, DOI 10.1016/S0360-1315(02)00130-6
   *CREAT VIRT, 2004, UK LING PROV MAJ CON
   De Pietro O., 2005, Advanced Technology for Learning, V2, P29
   DILLENBOURG P, 1992, LECT NOTES COMPUT SC, V608, P651
   Dimitrova V., 2003, INT J ARTIF INTELL E, V13, P35
   Donghui Feng, 2006, 2006 International Conference on Intelligent User Interfaces, P171
   Fryer L, 2006, LANG LEARN TECHNOL, V10, P8
   Graesser A. C., 2001, INT J ARTIFICIAL INT, V12, P23
   Grigoriadou M., 2003, WORKSH LEARN MOD REF
   Heffernan NT, 2003, FR ART INT, V97, P115
   JIA J, 2002, STUDY APPL KEYWORDS
   Jones Karen Sparck, 1994, CURRENT ISSUES COMPU, P3, DOI DOI 10.1007/978-0-585-35958-8_1
   Kerly A, 2008, LECT NOTES COMPUT SC, V5091, P132
   Kerly A, 2008, KNOWL-BASED SYST, V21, P238, DOI 10.1016/j.knosys.2007.11.015
   Kerly A, 2007, KNOWL-BASED SYST, V20, P177, DOI 10.1016/j.knosys.2006.11.014
   Kim Y, 2007, INT J ARTIFICIAL INT, V17, P371, DOI DOI 10.1109/TLT.2010.41
   Kim Y, 2005, INT J ARTIFICIAL INT, V15, P95, DOI [DOI 10.1007/BF02504991, DOI 10.1145/1067860.1067867]
   Lester JC, 1999, USER MODEL USER-ADAP, V9, P1, DOI 10.1023/A:1008374607830
   LITMAN DJ, 2004, HUM LANG TECHN C N A
   Rickel J, 1999, APPL ARTIF INTELL, V13, P343, DOI 10.1080/088395199117315
   SHAW E, 1999, INT C AUT AG, P283
   SHAWAR BA, 2007, CORPUS LINGUISTICS
   TAYLOR K, 2006, AI 2006 26 SGAI INT, P193
NR 29
TC 43
Z9 43
U1 0
U2 4
PU SPRINGER-VERLAG LONDON LTD
PI GODALMING
PA SWEETAPPLE HOUSE CATTESHALL RD FARNCOMBE, GODALMING GU7 1NH, SURREY,
   ENGLAND
BN 978-1-84882-214-6
PY 2009
BP 169
EP +
PG 3
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BIR44
UT WOS:000262216100013
DA 2022-08-02
ER

PT C
AU Kubota, H
   Nishida, T
AF Kubota, H
   Nishida, T
BE Baba, N
   Jain, LC
   Howlett, RJ
TI Maintaining knowledge of conversational agents
SO KNOWLEDGE-BASED INTELLIGENT INFORMATION ENGINEERING SYSTEMS & ALLIED
   TECHNOLOGIES, PTS 1 AND 2
SE FRONTIERS IN ARTIFICIAL INTELLIGENCE AND APPLICATIONS
LA English
DT Proceedings Paper
CT 5th International Conference on Knowledge-Based Intelligent Information
   Engineering Systems and Allied Technologies (KES 2001)
CY SEP 06-08, 2001
CL OSAKA KYOIKU UNIV, OSAKA, JAPAN
SP FOST, Koei Ltd, Matsushita Elect Works Ltd
HO OSAKA KYOIKU UNIV
AB In this paper, we discuss how to maintain the knowledge of conversational agents. We have developed a human-style conversational agent called virtualized-ego that represents a real community member, Community members can exchange their knowledge by talking with virtualized-egos. The knowledge of the virtualised-ego is the corpus of past messages of human. The merit and demerit of corpus based knowledge for conversational agents are discussed.
C1 Univ Tokyo, Sch Engn, Dept Informat & Commun Engn, Tokyo, Japan.
RP Kubota, H (corresponding author), Univ Tokyo, Sch Engn, Dept Informat & Commun Engn, Tokyo, Japan.
CR Bickmore T., 2000, P SOC INT AG HUM LOO, P4
   Nishida T, 1999, NEW GENERAT COMPUT, V17, P417, DOI 10.1007/BF03037247
   NISHIDA T, 1999, HUMAN COMPUTER INTER, V2, P437
NR 3
TC 0
Z9 0
U1 0
U2 0
PU I O S PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 0922-6389
BN 1-58603-192-9
J9 FR ART INT
PY 2001
VL 69
BP 329
EP 333
PG 5
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems; Computer Science
GA BS99P
UT WOS:000171608300061
DA 2022-08-02
ER

PT C
AU Seeger, AM
   Heinzl, A
AF Seeger, Anna-Maria
   Heinzl, Armin
BE Davis, FD
   Riedl, R
   VomBrocke, J
   Leger, PM
   Randolph, AB
TI Human Versus Machine: Contingency Factors of Anthropomorphism as a
   Trust-Inducing Design Strategy for Conversational Agents
SO INFORMATION SYSTEMS AND NEUROSCIENCE, NEUROIS 2017
SE Lecture Notes in Information Systems and Organization
LA English
DT Proceedings Paper
CT Conference on Information Systems and Neuroscience - Gmunden Retreat on
   NeuroIS (NeuroIS)
CY JUN 12-14, 2017
CL Gmunden, AUSTRIA
DE Conversational agents; Trustworthiness; Anthropomorphism Eye-tracking
ID RECOMMENDATION AGENTS; SOCIAL RESPONSES; DECISION-MAKING; INCREASES
   TRUST; AUTOMATION BIAS; E-COMMERCE; TRUSTWORTHINESS; SYSTEMS; EYE
AB Conversational agents are increasingly popular in various domains of application. Due to their ability to interact with users in human language, anthropomorphizing these agents to positively influence users' trust perceptions seems justified. Indeed, conceptual and empirical arguments support the trust-inducing effect of anthropomorphic design. However, an opposing research stream that has widely been overlooked provides evidence that human-likeness reduces agents' trustworthiness. Based on a thorough analysis of psychological mechanisms related to the contradicting theoretical positions, we propose that the agent substitution type acts as a situational moderator variable on the positive relationship between anthropomorphic design and agents' trustworthiness. We argue that different agent types are related to distinct user expectations that influence the cognitive evaluation of anthropomorphic design. We further discuss how these differences translate into neurophysiological responses and propose an experimental set-up using a combination of behavioral, self-reported and eye-tracking data to empirically validate our proposed model.
C1 [Seeger, Anna-Maria; Heinzl, Armin] Univ Mannheim, Mannheim, Germany.
RP Seeger, AM (corresponding author), Univ Mannheim, Mannheim, Germany.
EM seeger@uni-mannheim.de; heinzl@uni-mannheim.de
CR Al-Natour S., 2007, SIGHCI 2007 P
   Al-Natour S., 2010, P EUR C INF SYST
   Appel J., 2012, ADV HUM-COMPUT INTER, P1, DOI DOI 10.1155/2012/324694
   Barki H, 2015, INFORM MANAGE-AMSTER, V52, P483, DOI 10.1016/j.im.2015.02.001
   Benbasat I., 2010, P INT C INF SYST
   Bickmore T., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P396
   Braun A, 2013, CHATBOTS KUNDENKOMMU
   Cassell J, 2000, COMMUN ACM, V43, P50, DOI 10.1145/355112.355123
   COMPEAU DR, 1995, MIS QUART, V19, P189, DOI 10.2307/249688
   Cyr D, 2009, MIS QUART, V33, P539
   de Visser E.J., 2012, P HUM FACT ERG SOC A
   de Visser EJ, 2016, J EXP PSYCHOL-APPL, V22, P331, DOI 10.1037/xap0000092
   Dijkstra JJ, 1999, BEHAV INFORM TECHNOL, V18, P399, DOI 10.1080/014492999118832
   Dijkstra JJ, 1998, BEHAV INFORM TECHNOL, V17, P155, DOI 10.1080/014492998119526
   Dzindolet MT, 2003, INT J HUM-COMPUT ST, V58, P697, DOI 10.1016/S1071-5819(03)00038-7
   Epley N, 2008, SOC COGNITION, V26, P143, DOI 10.1521/soco.2008.26.2.143
   Epley N, 2007, PSYCHOL REV, V114, P864, DOI 10.1037/0033-295X.114.4.864
   Fiske S., 2021, SOCIAL COGNITION BRA, V2nd
   Gefen D, 2004, OMEGA-INT J MANAGE S, V32, P407, DOI 10.1016/j.omega.2004.01.006
   Gilzenrat MS, 2010, COGN AFFECT BEHAV NE, V10, P252, DOI 10.3758/CABN.10.2.252
   Gong L, 2008, COMPUT HUM BEHAV, V24, P1494, DOI 10.1016/j.chb.2007.05.007
   JUST MA, 1976, COGNITIVE PSYCHOL, V8, P441, DOI 10.1016/0010-0285(76)90015-3
   Kassner L, 2017, PROCEEDINGS OF THE 50TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P1673
   Komiak S., 2004, E SERVICE J, V3, P49
   Krach S, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002597
   Lavin C, 2014, FRONT BEHAV NEUROSCI, V7, DOI 10.3389/fnbeh.2013.00218
   Leger PM, 2014, J ASSOC INF SYST, V15, P651
   MacDorman KF, 2009, COMPUT HUM BEHAV, V25, P695, DOI 10.1016/j.chb.2008.12.026
   Madhavan P, 2007, THEOR ISS ERGON SCI, V8, P277, DOI 10.1080/14639220500337708
   MAYER RC, 1995, ACAD MANAGE REV, V20, P709, DOI 10.2307/258792
   McKnight DH, 2002, INFORM SYST RES, V13, P334, DOI 10.1287/isre.13.3.334.81
   Merritt SM, 2013, HUM FACTORS, V55, P520, DOI 10.1177/0018720812465081
   Mosier K. L., 1996, HUM FAC TRANSP, P201
   Mosier KL, 1998, INT J AVIAT PSYCHOL, V8, P47, DOI 10.1207/s15327108ijap0801_3
   MUIR BM, 1987, INT J MAN MACH STUD, V27, P527, DOI 10.1016/S0020-7373(87)80013-5
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nunamaker JE, 2011, J MANAGE INFORM SYST, V28, P17, DOI 10.2753/MIS0742-1222280102
   Pavlou PA, 2004, INFORM SYST RES, V15, P37, DOI 10.1287/isre.1040.0015
   Poole A, 2006, ENCY HUMAN COMPUTER, P211, DOI DOI 10.4018/978-1-59140-562-7.CH034
   Preuschoff K, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00115
   Qiu LY, 2009, J MANAGE INFORM SYST, V25, P145, DOI 10.2753/MIS0742-1222250405
   Reeves B., 1997, COMPUT MATH APPL, V5, P33
   Reimer J, 2014, NEURON, V84, P355, DOI 10.1016/j.neuron.2014.09.033
   Riedl R., 2017, OXYTOCIN TRUST TRUST
   Riedl R., 2011, P 32 INT C INF SYST
   Riedl R, 2014, J ASSOC INF SYST, V15, pI
   Riedl R, 2014, J MANAGE INFORM SYST, V30, P83, DOI 10.2753/MIS0742-1222300404
   Riedl R, 2010, MIS QUART, V34, P397
   Rousseau DM, 1998, ACAD MANAGE REV, V23, P393, DOI 10.5465/AMR.1998.926617
   Satterthwaite TD, 2007, NEUROIMAGE, V37, P1017, DOI 10.1016/j.neuroimage.2007.04.066
   Schunemann Rogerio, 2014, ISRN Microbiol, V2014, P135675, DOI 10.1155/2014/135675
   Skitka LJ, 1999, INT J HUM-COMPUT ST, V51, P991, DOI 10.1006/ijhc.1999.0252
   Tomlinson EC, 2009, ACAD MANAGE REV, V34, P85, DOI 10.5465/AMR.2009.35713291
   von der Putten AM, 2010, COMPUT HUM BEHAV, V26, P1641, DOI 10.1016/j.chb.2010.06.012
   Wang WQ, 2008, J MANAGE INFORM SYST, V24, P249, DOI 10.2753/MIS0742-1222240410
   Waytz A, 2014, J EXP SOC PSYCHOL, V52, P113, DOI 10.1016/j.jesp.2014.01.005
   Waytz A, 2010, J PERS SOC PSYCHOL, V99, P410, DOI 10.1037/a0020240
   Waytz A, 2010, PERSPECT PSYCHOL SCI, V5, P219, DOI 10.1177/1745691610369336
   Xu Q, 2011, PHIL MAG LETT, V91, P724, DOI 10.1080/09500839.2011.614285
NR 60
TC 6
Z9 6
U1 4
U2 4
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2195-4968
EI 2195-4976
BN 978-3-319-67431-5; 978-3-319-67430-8
J9 L N INF SYST ORGAN
PY 2018
VL 25
BP 129
EP 139
DI 10.1007/978-3-319-67431-5_15
PG 11
WC Psychology, Biological; Behavioral Sciences; Computer Science,
   Information Systems; Neurosciences
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Psychology; Behavioral Sciences; Computer Science; Neurosciences &
   Neurology
GA BS8DO
UT WOS:000771321100015
DA 2022-08-02
ER

PT C
AU Nijholt, A
AF Nijholt, A
BE Callaos, N
   Breda, A
   Jurado, FMY
TI Issues in multimodal nonverbal communication and emotion in embodied
   (conversational) agents
SO 6TH WORLD MULTICONFERENCE ON SYSTEMICS, CYBERNETICS AND INFORMATICS, VOL
   II, PROCEEDINGS: CONCEPTS AND APPLICATIONS OF SYSTEMICS, CYBERNETICS AND
   INFORMATICS I
LA English
DT Proceedings Paper
CT 6th World Multi-Conference on Systemics, Cybernetics and Informatics
   (SCI 2002)/8th International Conference on Information Systems Analysis
   and Synthesis (ISAS 2002)
CY JUL 14-18, 2002
CL ORLANDO, FL
SP Int Inst Informat & System, World Org System & Cybernet, Ctr Syst Studies, Syst Soc Poland, Soc Appl Syst Res, Slovenian Artificial Intelligence Soc, Simon Bolivar Univ, Polish Syst Soc, Italian Soc System, Int Soc Syst Sci, Int Syst Inst, Int Federat Syst Res, Cybernet & Human Knowing, Journal Second Order Cybernet & Cybersemiot, Blaise Pascal Univ, Engineer Sci Inst, CUST, Univ Las Palmas Gran Canaria, Concurrency & Architecture Grp, Telemat Engn Dept, Tunisian Sci Soc, Acad Non Linear Sci, San Luis Natl Univ, Lab Res Computat Intelligence, Dept Informat, Amer Soc Cybernet (Canada), Wolfram Res Inc, IEEE Comp Soc, Venezuela Chapter, Steacie Inst Molec Sci, Natl Res Council Canada
DE embodied conversational agents; nonverbal communication; emotion; gaze
   behavior; turn taking; virtual reality
AB Virtual worlds are getting inhabited by virtual humans. Sometimes they act as (autonomous) embodied conversational agents; sometimes they represent human visitors and reflect (real-time) actions performed by the human visitors or users of the environment. It is not always necessary to represent a full body or any body at all. However, there are also many applications where it can be useful to have an embodied agents that does not only allow verbal interaction, but also interacts through nonverbal means, including a display of emotion. In this paper we survey the main modalities to show emotion in an embodied conversational agent. We argue that for many situations it is more important to have subtle ways of adding nonverbal cues to agent-human interaction than to be able to express some discrete full-blown emotions. We illustrate this with two of our research projects, one on gaze behavior of an embodied conversational agent and one on showing intensities and blends of emotions in facial expressions of an embodied agent.
C1 Univ Twente, CTIT, Parlevink Res Grp, NL-7500 AE Enschede, Netherlands.
RP Nijholt, A (corresponding author), Univ Twente, CTIT, Parlevink Res Grp, POB 217, NL-7500 AE Enschede, Netherlands.
EM anijholt@cs.utwente.nl
OI Nijholt, Anton/0000-0002-5669-9290
CR [Anonymous], 1988, COGNITIVE STRUCTURE, DOI DOI 10.1017/CBO9780511571299
   Cassell J., 2000, EMBODIED CONVERSATIO
   DUY BT, LNAI, V2256, P83
   EGGES A, 2001, P 2 IJCAI WORKSH KNO, P29
   EKMAN P, 1991, FUNDAMENTALS NONVERB
   ES I, 2001, THESIS U TWENTE
   EVERS M, 2001, THEMES ED, V1, P15
   GRANSTROM B, 2001, MULTIMODAL FEEDBACK
   KAPOOR A, 2001, P EM INT 2 TANGL KNO
   Kappas Arvid., 1991, FUNDAMENTALS NONVERB, P200
   KENDON A., 1980, RELATION VERBAL NONV
   KOSTOV V, P SCI 2001 ORL
   MAGNENATTHAIMAN.N, 2000, P LEARN BEH TWENT WO, V17, P1
   MARSELLA SC, P 4 INT C AUT AG 200, P301
   Nijholt A, 2000, STUD FUZZ SOFT COMP, V45, P148
   ORTONY A, 2001, EMOTIONS HUMANS ARTI
   Paradiso A., 2001, P WORKSH MULT COMM C
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   PICARD RW, 2001, 538 MIT TR MED LAB
   REILLY WS, 1992, CMUCS92143
   Reynolds C., 2001, P 9 INT C HUM COMP I
   Rime B., 1991, FUNDAMENTALS NONVERB, P239
   Russell J.A., 1997, PSYCHOL FACIAL EXPRE
   SCHLOSBERG H, 1952, J EXP PSYCH, V44
   TAN H., 1997, P WORKSH PERC US INT
   TSUKAHARA W, P CHI 2001, P77
   VANKESTEREN AJ, 2000, P TWENT WORKSH LANG
   VYZAS E, 1999, P WORKSH EM BAS ARCH
   [No title captured]
NR 29
TC 0
Z9 0
U1 1
U2 7
PU INT INST INFORMATICS & SYSTEMICS
PI ORLANDO
PA 14269 LORD BARCLAY DR, ORLANDO, FL 32837 USA
PY 2002
BP 208
EP 215
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BV62M
UT WOS:000179559400038
DA 2022-08-02
ER

PT J
AU Griol, D
   Molina, JM
   Callejas, Z
AF Griol, David
   Manuel Molina, Jose
   Callejas, Zoraida
TI Incorporating android conversational agents in m-learning apps
SO EXPERT SYSTEMS
LA English
DT Article
DE computer supported education; conversational agents; mobile learning;
   m-learning; adaptive learning; multimodal interaction; spoken
   interaction; mobile devices; android; intelligent assistants; university
   digital libraries
ID HIGHER-EDUCATION; MOBILE; LANGUAGE; GAMIFICATION; ADOPTION; TECHNOLOGY;
   MANAGEMENT; USAGE; GAME; ICT
AB Smart mobile devices have fostered new learning scenarios that demand sophisticated interfaces. Multimodal conversational agents have became a strong alternative to develop human-machine interfaces that provide a more engaging and human-like relationship between students and the system. The main developers of operating systems for such devices have provided application programming interfaces for developers to implement their own applications, including different solutions for developing graphical interfaces, sensor control and voice interaction. Despite the usefulness of such resources, there are no strategies defined for coupling the multimodal interface with the possibilities that these devices offer to enhance mobile educative apps with intelligent communicative capabilities and adaptation to the user needs. In this paper, we present a practical m-learning application that integrates features of Android application programming interfaces on a modular architecture that emphasizes interaction management and context-awareness to foster user-adaptively, robustness and maintainability.
C1 [Griol, David; Manuel Molina, Jose] Carlos III Univ Madrid, Dept Comp Sci, Avda Univ 30, Leganes 28911, Spain.
   [Callejas, Zoraida] Univ Granada, CITIC UGR, Deparment Languages & Comp Syst, C Pdta Daniel Saucedo Aranda S-N, E-18071 Granada, Spain.
RP Griol, D (corresponding author), Carlos III Univ Madrid, Dept Comp Sci, Avda Univ 30, Leganes 28911, Spain.
EM david.griol@uc3m.es; zoraida@ugr.es
RI Callejas, Zoraida/AAX-4634-2020; Molina, JOSE/B-1956-2008
OI Callejas, Zoraida/0000-0001-8891-5237; Molina, JOSE/0000-0002-7484-7357
FU MINECO [TEC2012-37832-C02-01]; CICYT [TEC2011-28626-C02-02]; CAM
   CONTEXTS [S2009/TIC-1485]
FX This work was supported in part by Projects MINECO TEC2012-37832-C02-01,
   CICYT TEC2011-28626-C02-02, CAM CONTEXTS (S2009/TIC-1485).
CR Adegbija MV, 2015, PROCD SOC BEHV, V176, P352, DOI 10.1016/j.sbspro.2015.01.482
   ALEVEN V., 2004, P 7 INT C INT TUT SY, P443, DOI DOI 10.1007/978-3-540-30139-4_42
   [Anonymous], 2014, J SOCIAL STUDIES RES, DOI DOI 10.1016/J.JSSR.2013.12.005
   Avouris N, 2012, J UNIVERS COMPUT SCI, V18, P2120
   Beun RJ, 2003, LECT NOTES ARTIF INT, V2792, P315
   Bickmore T., 2003, PHD THESIS
   Blevins B., 2014, J SOCIAL STUDIES RES, V38, P33, DOI DOI 10.1016/J.JSSR.2013.12.003
   Boe T, 2015, COMPUT HUM BEHAV, V50, P375, DOI 10.1016/j.chb.2015.03.084
   Boticki I, 2015, COMPUT EDUC, V86, P120, DOI 10.1016/j.compedu.2015.02.015
   Callahan C., 2014, J SOCIAL STUDIES RES, V38, P129
   Callejas Zoraida, 2014, Ambient Assisted Living and Daily Activities. 6th International Work-Conference, IWAAL 2014. Proceedings: LNCS 8868, P59, DOI 10.1007/978-3-319-13105-4_10
   Callejas Z, 2008, SPEECH COMMUN, V50, P646, DOI 10.1016/j.specom.2008.04.004
   Cassell J., 2012, EMBODIED DIALOG SYST
   CAVAZZA M, 2010, AAMAS, P01629
   Chen HL, 2012, LIBR INFORM SCI RES, V34, P220, DOI 10.1016/j.lisr.2011.12.001
   Churchill D, 2014, EDUC MEDIA INT, V51, P214, DOI 10.1080/09523987.2014.968444
   DE ROSIS F., 2005, P AISB 05 VIRT SOC C, P1
   Duta N, 2015, PROCD SOC BEHV, V180, P1466, DOI 10.1016/j.sbspro.2015.02.294
   Dybkjaer L, 2004, SPEECH COMMUN, V43, P33, DOI 10.1016/j.specom.2004.02.001
   Ferdousi B, 2015, PROCD SOC BEHV, V176, P307, DOI 10.1016/j.sbspro.2015.01.476
   Fryer L, 2006, LANG LEARN TECHNOL, V10, P8
   Furio D, 2015, J COMPUT ASSIST LEAR, V31, P189, DOI 10.1111/jcal.12071
   Gerger K., 2014, THESIS
   Lopez JLG, 2009, PROCD SOC BEHV, V1, P2673, DOI 10.1016/j.sbspro.2009.01.472
   Domingo MG, 2016, COMPUT HUM BEHAV, V56, P21, DOI 10.1016/j.chb.2015.11.023
   Gratch J, 2002, IEEE INTELL SYST, V17, P54, DOI 10.1109/MIS.2002.1024753
   GRIGORIADOU M., 2003, P WORKSH LEARN MOD R, P238
   Griol D, 2015, LECT NOTES COMPUT SC, V9108, P339, DOI 10.1007/978-3-319-18833-1_36
   Griol D, 2014, LECT NOTES COMPUT SC, V8480, P25
   Griol D, 2014, COMPUT SPEECH LANG, V28, P743, DOI 10.1016/j.csl.2013.09.002
   Griol D, 2012, J UNIVERS COMPUT SCI, V18, P2516
   Hassenzahl M, 2003, MENSCH COMPUTER, V2003, P187, DOI DOI 10.1007/978-3-322-80058-9_19
   Hone K., 2014, P CHI 14 WORKSH DES, P69
   Hsu Y., 2013, BRIT J EDUC TECHNOL, V44, P2120
   IDC Corporation, 2015, WORLDW Q MOB PHON Q7
   International Data Corporation (IDC), 2015, WORLDW Q MOB PHON TR
   Jeng YL, 2010, EDUC TECHNOL SOC, V13, P3
   Kanto K. J. K., 2004, P 10 ACL INT C COMP, P44
   Kartakis S, 2010, COMPUT IND, V61, P318, DOI 10.1016/j.compind.2009.12.002
   Kaufmann T, 2012, SPEECH COMMUN, V54, P715, DOI 10.1016/j.specom.2012.01.001
   Kearney M, 2015, COMPUT EDUC, V80, P48, DOI 10.1016/j.compedu.2014.08.009
   Kerly A., 2008, P AI, P169
   Kerly A, 2008, KNOWL-BASED SYST, V21, P238, DOI 10.1016/j.knosys.2007.11.015
   Kim Y, 2005, INT J ARTIFICIAL INT, V15, P95, DOI [DOI 10.1007/BF02504991, DOI 10.1145/1067860.1067867]
   Klenner M, 2015, PROCD SOC BEHV, V176, P312, DOI 10.1016/j.sbspro.2015.01.477
   Kuo MS, 2016, COMPUT HUM BEHAV, V55, P16, DOI 10.1016/j.chb.2015.08.025
   Lakkala M, 2015, COMPUT EDUC, V90, P1, DOI 10.1016/j.compedu.2015.09.001
   Latham A, 2012, COMPUT EDUC, V59, P95, DOI 10.1016/j.compedu.2011.11.001
   Lee J. K., 2014, J SOCIAL STUDIES RES, V38, P159, DOI [10.1016/j.jssr.2014.02.005, DOI 10.1016/J.JSSR.2014.02.005]
   Lu J, 2014, EDUC MEDIA INT, V51, P166, DOI 10.1080/09523987.2014.968448
   Magal-Royo T, 2010, PROCD SOC BEHV, V2, P4492, DOI 10.1016/j.sbspro.2010.03.718
   Marsella S., 2003, INTERACTIVE PEDAGOGI, P341
   McTear M., 2013, VOICE APPL DEV ANDRO
   Metze F, 2009, LECT NOTES COMPUT SC, V5611, P75, DOI 10.1007/978-3-642-02577-8_9
   Moller S, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1786
   Mouza C, 2015, COMPUT EDUC, V88, P1, DOI 10.1016/j.compedu.2015.04.009
   Murphy GD, 2011, E-J BUS EDUC SCHOLAR, V5, P18
   Nordin N, 2010, PROCD SOC BEHV, V7, P130, DOI 10.1016/j.sbspro.2010.10.019
   O'Bannon BW, 2015, COMPUT EDUC, V85, P110, DOI 10.1016/j.compedu.2015.02.010
   O'Halloran KL, 2015, J MATH BEHAV, V40, P63, DOI 10.1016/j.jmathb.2014.09.002
   Padilla-Zea N, 2014, COMPUT HUM BEHAV, V31, P461, DOI 10.1016/j.chb.2013.04.020
   Paek T, 2008, SPEECH COMMUN, V50, P716, DOI 10.1016/j.specom.2008.03.010
   Pedreira O, 2015, INFORM SOFTWARE TECH, V57, P157, DOI 10.1016/j.infsof.2014.08.007
   PerezMarin D, 2011, CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND EFFECTIVE PRACTICES, P1, DOI 10.4018/978-1-60960-617-6
   Pieraccini R, 2012, VOICE IN THE MACHINE: BUILDING COMPUTERS THAT UNDERSTAND SPEECH, P1
   Pon-Barry Heather, 2006, INT J ARTIFICIAL INT, V16, P171
   R-Moreno MD, 2014, EXPERT SYST APPL, V41, P7904, DOI 10.1016/j.eswa.2014.06.047
   Rouillard Jose, 2007, Journal of Networks, V2, P27, DOI 10.4304/jnw.2.1.27-35
   Rovira MS, 2015, PROCD SOC BEHV, V196, P190, DOI 10.1016/j.sbspro.2015.07.027
   Schmitz B, 2015, COMPUT EDUC, V81, P35, DOI 10.1016/j.compedu.2014.09.001
   Seaborn K, 2015, INT J HUM-COMPUT ST, V74, P14, DOI 10.1016/j.ijhcs.2014.09.006
   Seneff S., 2007, P INT WORKSH IMPR MO, P1
   Traum David, 2003, INFORM STATE APPROAC, P325, DOI DOI 10.1007/978-94-010-0019-2_15
   Urh M, 2015, PROCD SOC BEHV, V197, P388, DOI 10.1016/j.sbspro.2015.07.154
   Vassilakaki Evgenia, 2013, International Information and Library Review, V45, P3, DOI 10.1016/j.iilr.2013.07.002
   Wang YH, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P1023
   Wang YY, 2006, SPEECH COMMUN, V48, P390, DOI 10.1016/j.specom.2005.07.001
   Williams JD, 2007, COMPUT SPEECH LANG, V21, P393, DOI 10.1016/j.csl.2006.06.008
   Wu WL, 2010, COMPUT SPEECH LANG, V24, P358, DOI 10.1016/j.csl.2009.05.002
   Yang XM, 2015, COMPUT EDUC, V88, P292, DOI 10.1016/j.compedu.2015.06.007
   Young S., 2002, TECHNICAL REPORT
   Yue WS, 2013, PROC TECH, V11, P479, DOI 10.1016/j.protcy.2013.12.218
   Zydney JM, 2016, COMPUT EDUC, V94, P1, DOI 10.1016/j.compedu.2015.11.001
   [No title captured]
NR 84
TC 8
Z9 8
U1 0
U2 57
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD AUG
PY 2017
VL 34
IS 4
SI SI
DI 10.1111/exsy.12156
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA FD1FR
UT WOS:000407283300001
OA Green Accepted
DA 2022-08-02
ER

PT C
AU Paschoal, LN
   Krassmann, AL
   Nunes, FB
   de Oliveira, MM
   Bercht, M
   Barbosa, EF
   de Souza, SDS
AF Paschoal, Leo Natan
   Krassmann, Aliane Loureiro
   Nunes, Felipe Becker
   de Oliveira, Myke Morais
   Bercht, Magda
   Barbosa, Ellen Francine
   Senger de Souza, Simone do Rocio
GP IEEE
TI A Systematic Identification of Pedagogical Conversational Agents
SO 2020 IEEE FRONTIERS IN EDUCATION CONFERENCE (FIE 2020)
SE Frontiers in Education Conference
LA English
DT Proceedings Paper
CT IEEE Frontiers in Education Conference (FIE)
CY OCT 21-24, 2020
CL Uppsala, SWEDEN
SP IEEE, Amer Soc Engn Educ, Educ Res & Methods Div, IEEE Educ Soc, IEEE Comp Soc
DE Chatbot; Chatterbot; Pedagogical Agent
AB Conversational agents have been established to support educational practices, solving students' questions, recommending teaching materials, increasing the motivation of students who have little interest in certain content, among others. Although many studies are discussing the establishing of conversational agents, there is no global understanding of what has been investigated in this area. There are some previous secondary studies that have attempted to map the conversational agents used for educational purposes (i.e., pedagogical conversational agents). However, these studies are limited to include primary studies published in specific sets of conferences and journals. Therefore, an overview of the current state of the art associated with pedagogical conversational agents has not been produced yet. This research paper aims to contribute to the theme, through the presentation of planning, conduction, and results analysis of a systematic mapping on pedagogical conversational agents. We address the following questions: (i) in which areas have conversation agents been investigated?; (ii) at which education levels are conversational agents used?; (iii) which mechanisms do conversational agents use to interact with students?. We also present some discussions about research opportunities that can be explored in future works. This study aims to contribute to the topic of pedagogical conversational agents, helping researchers to have a deeper understanding of what has already been done and to guide their research to subjects not explored yet.
C1 [Paschoal, Leo Natan; de Oliveira, Myke Morais; Barbosa, Ellen Francine; Senger de Souza, Simone do Rocio] Univ Sao Paulo ICMC USP, Sao Carlos, SP, Brazil.
   [Krassmann, Aliane Loureiro; Bercht, Magda] Fed Univ Rio Grande do Sul CINTED UFRGS, Porto Alegre, RS, Brazil.
   [Nunes, Felipe Becker] Antonio Meneghetti Fac AMF, Santa Maria, RS, Brazil.
RP Paschoal, LN (corresponding author), Univ Sao Paulo ICMC USP, Sao Carlos, SP, Brazil.
EM paschoalln@usp.br; alkrassmann@gmail.com; nunesfb@gmail.com;
   mykeoliveira@usp.br; bercht@inf.ufrgs.br; francine@icmc.usp.br;
   srocio@icmc.usp.br
RI Paschoal, Leo Natan/S-5515-2016; Oliveira, Myke/P-9724-2018
OI Oliveira, Myke/0000-0001-8426-9127; Paschoal, Leo
   Natan/0000-0003-1076-9174
FU University of Sao Paulo; Brazilian funding agency: the State of Sao
   Paulo Research Foundation - FAPESP [2013/07375-0, 2017/10941-8,
   2018/26636-2]; Brazilian funding agency: Coordenacao de Aperfeicoamento
   de Pessoal de Nivel Superior - Brasil (CAPES) [001]; Brazilian funding
   agency: CNPq [312922/2018-3]
FX This study was financed by the University of Sao Paulo and the Brazilian
   funding agencies: the State of Sao Paulo Research Foundation - FAPESP
   (under processes no. 2013/07375-0, 2017/10941-8, and 2018/26636-2),
   Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - Brasil
   (CAPES) - Finance Code 001, and CNPq (under process no. #312922/2018-3).
CR Abdul-Kader SA, 2015, INT J ADV COMPUT SC, V6, P72
   Aguiar EVB, 2014, P ANN HICSS, P130, DOI 10.1109/HICSS.2014.24
   Basili V. R, PAN PAC COMP C
   Bergmann J., 2012, FLIP YOUR CLASSROOM
   Bernardini A.A., 2018, WORKSHOP ADV VIRTUAL, V1, P1
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   Craig SD, 2017, COMPUT EDUC, V114, P193, DOI 10.1016/j.compedu.2017.07.003
   Deryugina OV, 2010, SCI TECH INF PROCESS, V37, P143, DOI 10.3103/S0147688210020097
   Doswell JT, 2004, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P774, DOI 10.1109/ICALT.2004.1357653
   Dyba Tore, 2007, 2007 First International Symposium on Empirical Software Engineering and Measurement, P225
   Fadhil A., 2017, P 11 EAI INT C PERV, P261, DOI DOI 10.1145/3154862.3154914
   Graesser AC, 2017, COMPUT HUM BEHAV, V76, P607, DOI 10.1016/j.chb.2017.03.041
   Guo ZL, 2020, CURR EYE RES, V45, P177, DOI 10.1080/02713683.2019.1668419
   Hobert S., 2019, LECT NOTES INFORMAT, P259
   Hussain Shafquat, 2019, Web, Artificial Intelligence and Network Applications. Proceedings of the Workshops of the 33rd International Conference on Advanced Information Networking and Applications (WAINA-2019). Advances in Intelligent Systems and Computing (927), P946, DOI 10.1007/978-3-030-15035-8_93
   Io HN, 2017, IN C IND ENG ENG MAN, P215, DOI 10.1109/IEEM.2017.8289883
   ISCED, 2012, 1 UN ED SCI CULT ORG
   Kerly A, 2009, APPLICATIONS AND INNOVATIONS IN INTELLIGENT SYSTEMS XVI, P169
   Kitchenham B., 2007, 23 KEEL U U DURH
   Kuyven N. L., 2018, REV NOVAS TECNOLOGIA, V16, P123
   Langer S., 1999, AUGMENT ALTERN COMM, V15, P260
   Lin LJ, 2013, COMPUT EDUC, V67, P239, DOI 10.1016/j.compedu.2013.04.017
   Nadarzynski T, 2019, DIGIT HEALTH, V5, DOI [10.1177/2055207619871808, 10.1177/2055207619827193]
   Norvig P., 2009, ARTIFICIAL INTELLIGE
   Paschoal L. N., 2019, P 33 BRAZ S SOFTW EN, P57
   Petersen K., 2008, P 12 INT C EV ASS SO, V12, P1
   Petersen K, 2015, INFORM SOFTWARE TECH, V64, P1, DOI 10.1016/j.infsof.2015.03.007
   Quah JTS, 2019, LECT NOTES COMPUT SC, V11515, P107, DOI 10.1007/978-3-030-23554-3_8
   Roos S., THESIS UPPSALA U
   Sciuto A, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P857, DOI 10.1145/3196709.3196772
   Smutny P, 2020, COMPUT EDUC, V151, DOI 10.1016/j.compedu.2020.103862
   Wallace R. S., 2009, PARSING TURING TEST, P181, DOI DOI 10.1007/978-1-4020-6710-5_13
   Winkler R., 2018, ACAD MANAGEMENT ANN
   Wohlin C., 2012, EXPT SOFTWARE ENG
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
NR 35
TC 2
Z9 2
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 0190-5848
BN 978-1-7281-8961-1
J9 PROC FRONT EDUC CONF
PY 2020
PG 9
WC Education, Scientific Disciplines; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Education & Educational Research; Engineering
GA BR3IP
UT WOS:000646660800002
DA 2022-08-02
ER

PT C
AU Ahmadvand, A
   Sahijwani, H
   Choi, JI
   Agichtein, E
AF Ahmadvand, Ali
   Sahijwani, Harshita
   Choi, Jason Ingyu
   Agichtein, Eugene
GP ACM
TI ConCET: Entity-Aware Topic Classification for Open-Domain Conversational
   Agents
SO PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION &
   KNOWLEDGE MANAGEMENT (CIKM '19)
LA English
DT Proceedings Paper
CT 28th ACM International Conference on Information and Knowledge
   Management (CIKM)
CY NOV 03-07, 2019
CL Beijing, PEOPLES R CHINA
SP Assoc Comp Machinery, ACM SIGIR, ACM SIGWEB
DE Open-Domain Conversational Agents; Conversational Topic Classification;
   Entity-Aware conversation domain classification
AB Identifying the topic (domain) of each user's utterance in opendomain conversational systems is a crucial step for all subsequent language understanding and response tasks. In particular, for complex domains, an utterance is often routed to a single component responsible for that domain. Thus, correctly mapping a user utterance to the right domain is critical.
   To address this problem, we introduce ConCET: a Concurrent Entity-aware conversational Topic classifier, which incorporates entity-type information together with the utterance content features. Specifically, ConCET utilizes entity information to enrich the utterance representation, combining character, word, and entitytype embeddings into a single representation. However, for rich domains with millions of available entities, unrealistic amounts of labeled training data would be required. To complement our model, we propose a simple and effective method for generating synthetic training data, to augment the typically limited amounts of labeled training data, using commonly available knowledge bases as to generate additional labeled utterances. We extensively evaluate ConCET and our proposed training method first on an openly available human-human conversational dataset called Self-Dialogue, to calibrate our approach against previous state-of-the-art methods; second, we evaluate ConCET on a large dataset of human-machine conversations with real users, collected as part of the Amazon Alexa Prize. Our results show that ConCET significantly improves topic classification performance on both datasets, including 8-10% improvements over state-of-the-art deep learning methods. We complement our quantitative results with detailed analysis of system performance, which could be used for further improvements of conversational agents.
C1 [Ahmadvand, Ali; Sahijwani, Harshita; Choi, Jason Ingyu; Agichtein, Eugene] Emory Univ, Comp Sci Dept, Atlanta, GA 30322 USA.
RP Ahmadvand, A (corresponding author), Emory Univ, Comp Sci Dept, Atlanta, GA 30322 USA.
EM aahmadv@emory.edu; hsahijw@emory.edu; ichoi5@emory.edu;
   eugene.agichtein@emory.edu
FU Amazon Alexa Prize 2018
FX We gratefully acknowledge the financial and computing support from the
   Amazon Alexa Prize 2018.
CR [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2014, P C EMP METH NAT LAN
   [Anonymous], 2011, C EMP METH NAT LANG
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Bojanowski Piotr, 2017, ENRICHING WORD VECTO, P135
   Bouma G., 2009, P GSCL, P31
   Conneau Alexis, 2017, 15 C EUR CHAPT ASS C
   Cornolti M, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P567, DOI 10.1145/2872427.2883061
   Guo Fenfei, 2018, NIPS
   Kavitha KR, 2018, IEEE I C COMP INT CO, P1
   Khatri Chandra, 2018, IEEE 2018 SPOK LANG
   Krause Ben, 2017, 1 P AL PRIZ AM
   Mendes P. N., 2011, P 7 INT C SEM SYST, P1, DOI DOI 10.1145/2063518.2063519
   Mikolov T., 2013, ARXIV13013781
   Mitchell Tom M, 1997, MACH LEARN
   Mohiuddin T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P558
   Moro A., 2014, TACL, V2, P231, DOI [DOI 10.1162/tacl_a_00179, DOI 10.1162/TACL_A_00179]
   Murty BS, 2014, HIGH-ENTROPY ALLOYS, P1
   Post M., 2013, P 51 ANN M ASS COMPU, P866
   Tar C, 2018, UNIVERSAL SENTENCE E
   Venkatesh Anu, 2018, NIPS
   Wang J., 2017, IJCAI, P2915
   Wang Zhongyuan, 2016, ACL
   Xiong C., 2016, ICTIR, V2016, P181
   Yamada Ikuya, 2017, T ASS COMPUT LING, V5, P397
NR 25
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6976-3
PY 2019
BP 1371
EP 1380
DI 10.1145/3357384.3358048
PG 10
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP1KL
UT WOS:000539898201044
DA 2022-08-02
ER

PT C
AU Divekar, RR
   Lepp, H
   Chopade, P
   Albin, A
   Brenner, D
   Ramanarayanan, V
AF Divekar, Rahul R.
   Lepp, Haley
   Chopade, Pravin
   Albin, Aaron
   Brenner, Daniel
   Ramanarayanan, Vikram
BE Stephanidis, C
   Antona, M
   Ntoa, S
TI Conversational Agents in Language Education: Where They Fit and Their
   Research Challenges
SO HCI INTERNATIONAL 2021 - LATE BREAKING POSTERS, HCII 2021, PT II
SE Communications in Computer and Information Science
LA English
DT Proceedings Paper
CT 23rd International Conference on Human-Computer Interaction (HCII)
CY JUL 24-29, 2021
CL ELECTR NETWORK
DE Spoken dialogue systems; Language learning; Conversational agents;
   Conversational user interfaces; Immersion; Multimodal interfaces
AB Conversational agents (or dialogue agents or Artificial Intelligent AI agents or chatbots) can provide a foreign language learner with otherwise hard-to-find conversational exposure to a new language. Such agents that teach languages differ significantly from their general-purpose counterparts in their goals, their approach, and their users' characteristics, thereby effectively creating a new interaction paradigm for which little literature exists in the HCI of Conversational Interfaces community. The difference from general-purpose agents comes from two themes highlighted in this work: the user is not expected to know the language of interaction, and the purpose of the conversation is language education through task completion rather than task completion itself. This paper highlights the role and the research challenges of interactions with dialogue agents that allow people to learn and practice new languages.
C1 [Divekar, Rahul R.; Lepp, Haley; Chopade, Pravin; Albin, Aaron; Brenner, Daniel; Ramanarayanan, Vikram] Educ Testing Serv, Princeton, NJ 08541 USA.
RP Divekar, RR (corresponding author), Educ Testing Serv, Princeton, NJ 08541 USA.
EM rdivekar@ets.org; hlepp@ets.org; pchopade@ets.org; aalbin@ets.org;
   dsbrenner@ets.org; vramanarayanan@ets.org
OI Chopade, Dr. Pravin/0000-0003-2135-4724
CR [Anonymous], 1989, ED RES, DOI [DOI 10.3102/0013189X018001032, 10.3102/0013189X018001032]
   Bennett M. J., 1997, NEW WAYS TEACHING CU, P16
   Bibauw S, 2019, COMPUT ASSIST LANG L, V32, P827, DOI 10.1080/09588221.2018.1535508
   Biocca F., 2002, P PRESENCE, V2002, P1
   Burnham D., 1999, AVSP 1999 INT C AUD
   Divekar R.R, 2020, THESIS RENSSELAER PO
   Divekar RR, 2021, COMPUT ASSIST LANG L, DOI 10.1080/09588221.2021.1879162
   Divekar RR, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P597, DOI 10.1145/3196709.3196717
   Evanini K, 2018, INTERSPEECH, P548
   Flores JFF, 2015, DIGIT EDUC REV, P40
   Fryer L., 2020, BOTS LANGUAGE LEARNI
   Fryer LK, 2017, COMPUT HUM BEHAV, V75, P461, DOI 10.1016/j.chb.2017.05.045
   Glasser A., 2020, P 2 C CONV US INT, P1
   Grafsgaard J., 2014, ED DATA MINING 2014
   Hsu LW, 2022, COMPUT ASSIST LANG L, V35, P792, DOI 10.1080/09588221.2020.1750429
   Ismail J, 2017, ENGLISH TEACHER, P11
   Kerly A, 2009, APPLICATIONS AND INNOVATIONS IN INTELLIGENT SYSTEMS XVI, P169
   Lee JS, 2020, LANG TEACH RES, V24, P813, DOI 10.1177/1362168819831408
   Loddo I, 2017, DES J, V20, pS4076, DOI 10.1080/14606925.2017.1352909
   Long M.H., 2014, SOCIOLINGUISTICS 2 L
   LONG MH, 1983, APPL LINGUIST, V4, P126, DOI 10.1093/applin/4.2.126
   Massaro D., 2006, MULTILINGUAL EMBODIE, V2
   Mayer RE, 2017, J COMPUT ASSIST LEAR, V33, P403, DOI 10.1111/jcal.12197
   Molnar G, 2018, I S INTELL SYST INFO, P197, DOI 10.1109/SISY.2018.8524609
   Moussalli S, 2020, COMPUT ASSIST LANG L, V33, P865, DOI 10.1080/09588221.2019.1595664
   Peixoto B., 2021, IEEE ACCESS, V1
   Petrovic J., 2020, ARXIV PREPRINT ARXIV
   Pinhanez Claudio S, 2020, P 2 C CONVERSATIONAL, P1
   Qiang YH, 2019, J LOW FREQ NOISE V A, V38, P1439, DOI 10.1177/1461348419830210
   Ramanarayanan V, 2018, INTERSPEECH, P1960
   Rosell-Aguilar F, 2018, COMPUT ASSIST LANG L, V31, P854, DOI 10.1080/09588221.2018.1456465
   Si M, 2015, INT J ARTIF INTELL E, V25, P271, DOI 10.1007/s40593-014-0035-7
   Wik P, 2009, SPEECH COMMUN, V51, P1024, DOI 10.1016/j.specom.2009.05.006
   Xu Y, 2021, COMPUT EDUC, V161, DOI 10.1016/j.compedu.2020.104059
   Pham XL, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON EDUCATION AND E-LEARNING (ICEEL 2018), P16, DOI 10.1145/3291078.3291115
NR 35
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1865-0929
EI 1865-0937
BN 978-3-030-90179-0; 978-3-030-90178-3
J9 COMM COM INF SC
PY 2021
VL 1499
BP 272
EP 279
DI 10.1007/978-3-030-90179-0_35
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BT0WH
UT WOS:000793810500035
DA 2022-08-02
ER

PT C
AU Ehret, J
   Stienen, J
   Brozdowski, C
   Bonsch, A
   Mittelberg, I
   Vorlander, M
   Kuhlen, TW
AF Ehret, Jonathan
   Stienen, Jonas
   Brozdowski, Chris
   Boensch, Andrea
   Mittelberg, Irene
   Vorlaender, Michael
   Kuhlen, Torsten W.
GP ASSOC COMP MACHINERY
TI Evaluating the Influence of Phoneme-Dependent Dynamic Speaker
   Directivity of Embodied Conversational Agents' Speech
SO PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT
   VIRTUAL AGENTS (ACM IVA 2020)
LA English
DT Proceedings Paper
CT 20th ACM International Conference on Intelligent Virtual Agents (ACM
   IVA)
CY OCT 20-22, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery
DE embodied conversational agents; virtual acoustics; directional 3D sound;
   speech; phoneme-dependent directivity
AB Generating natural embodied conversational agents within virtual spaces crucially depends on speech sounds and their directionality. In this work, we simulated directional filters to not only add directionality, but also directionally adapt each phoneme. We therefore mimic reality where changing mouth shapes have an influence on the directional propagation of sound. We conducted a study (n = 32) evaluating naturalism ratings, preference and distinguishability of omnidirectional speech auralization compared to static and dynamic, phoneme-dependent directivities. The results indicated that participants cannot distinguish dynamic from static directivity. Furthermore, participants' preference ratings aligned with their naturalism ratings. There was no unanimity, however, with regards to which auralization is the most natural.
C1 [Ehret, Jonathan; Boensch, Andrea; Kuhlen, Torsten W.] Rhein Westfal TH Aachen, Visual Comp Inst, Aachen, Germany.
   [Stienen, Jonas; Vorlaender, Michael] Rhein Westfal TH Aachen, Inst Tech Acoust, Aachen, Germany.
   [Brozdowski, Chris; Mittelberg, Irene] Rhein Westfal TH Aachen, Human Technol Ctr, Aachen, Germany.
RP Ehret, J (corresponding author), Rhein Westfal TH Aachen, Visual Comp Inst, Aachen, Germany.
EM ehret@vr.rwth-aachen.de
OI Bonsch, Andrea/0000-0001-5077-3675
FU RWTH Aachen University [OPSF459]
FX Kindly funded by RWTH Aachen University as Exploratory Research Space
   Seed Fund Project OPSF459. Special thanks goes also to
   PrakaiwanVajrabhaya, Imran Muhammad, LukasAspock, Benjamin Weyers, Mark
   Muller-Giebeler and Henry Andrew.
CR Ackermann D, 2019, ACTA ACUST UNITED AC, V105, P356, DOI 10.3813/AAA.919319
   ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599
   [Anonymous], 2011, AURALIZATION FUNDAME
   Arai T., 2001, J PHONETIC SOC JPN, V5, P31, DOI DOI 10.24467/ONSEIKENKYU.5.2_31
   Bailenson JN, 2001, PRESENCE-TELEOP VIRT, V10, P583, DOI 10.1162/105474601753272844
   Behler Gottfried, 2012, P AC NANT C, P761
   Bernardet U, 2019, 2019 IEEE VIRTUAL HUMANS AND CROWDS FOR IMMERSIVE ENVIRONMENTS (VHCIE)
   Blauert J., 1997, SPATIAL HEARING PSYC
   Dicke C., 2010, P HCI 2010 24 U ABER, P309
   Gratch J, 2002, IEEE INTELL SYST, V17, P54, DOI 10.1109/MIS.2002.1024753
   Jax P, 2006, IEEE COMMUN MAG, V44, P106, DOI 10.1109/MCOM.2006.1637954
   Katz Brian F. G., 2006, J ACOUST SOC AM, V120, P3359, DOI [10.1121/1.4781486, DOI 10.1121/1.4781486]
   Kern AC, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00020
   Lentz T, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/70540
   Masiero B, 2014, IEEE-ACM T AUDIO SPE, V22, P1345, DOI 10.1109/TASLP.2014.2329184
   Mehra R, 2014, IEEE T VIS COMPUT GR, V20, P495, DOI 10.1109/TVCG.2014.38
   Pausch F, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518800871
   Postma B., 2016, GERM ANN C AC DAGA M, P352
   Postma BNJ, 2017, ACTA ACUST UNITED AC, V103, P181, DOI 10.3813/AAA.919045
   Rindel Jens H., 2004, INT S ROOM AC DES SC
   Serafin S, 2018, IEEE COMPUT GRAPH, V38, P31, DOI 10.1109/MCG.2018.193142628
   Shabtai NR, 2017, J ACOUST SOC AM, V141, P1246, DOI 10.1121/1.4976071
   StefanWeinzierl Michael Vorlander, 2017, DATABASE ANECHOIC MI, DOI [10.14279/depositonce-5861.2, DOI 10.14279/DEPOSITONCE-5861.2]
   Szekely E, 2020, INT CONF ACOUST SPEE, P7649, DOI 10.1109/ICASSP40776.2020.9054107
   Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699
   Vigeant MC, 2011, APPL ACOUST, V72, P311, DOI 10.1016/j.apacoust.2010.10.004
   Wendt J, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P130, DOI 10.1145/3308532.3329434
   Zhou Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201292
   Zibrek K, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3349609
NR 29
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-7586-3
PY 2020
AR 17
DI 10.1145/3383652.3423863
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS5CN
UT WOS:000728153600005
DA 2022-08-02
ER

PT J
AU Ben Mimoun, MS
   Poncin, I
   Garnier, M
AF Ben Mimoun, Mohammed Slim
   Poncin, Ingrid
   Garnier, Marion
TI Animated conversational agents and e-consumer productivity: The roles of
   agents and individual characteristics
SO INFORMATION & MANAGEMENT
LA English
DT Article
DE Animated conversational agents (ACA); Consumer productivity; Individual
   characteristics; Consumer profile; Eye-tracking
ID SOCIAL PRESENCE; RECOMMENDATION AGENTS; USER ACCEPTANCE; SELF-SERVICE;
   COMPUTER PLAYFULNESS; INFORMATION SEARCH; PERCEIVED EASE; E-COMMERCE;
   WEB SITE; ONLINE
AB This research presents two studies, in a lab (eye-tracking) and in a natural context, that highlight the effects of interacting with an animated conversational agents (ACA) on the objective and perceived econsumer productivity. Results from Study 1 specify that only objective e-consumer productivity depends on interaction with the ACA. Going further, Study 2 then reveals that individual characteristics affect perceived productivity, either independently from ACA use (for involvement or product familiarity) or in interaction with using the ACA (for Internet skills and need for interaction). These findings highlight the need to personalize websites that display an agent fitting user profiles. (C) 2016 Published by Elsevier B.V.
C1 [Ben Mimoun, Mohammed Slim; Garnier, Marion] Univ Lille, SKEMA, SKEMA Business Sch, Ave W Brandt, F-59777 Euralille, France.
   [Poncin, Ingrid] Catholic Univ Louvain, Louvain Sch Management, UCL Mons, Chaussee Binche 151, B-7000 Mons, Belgium.
RP Ben Mimoun, MS (corresponding author), Univ Lille, SKEMA, SKEMA Business Sch, Ave W Brandt, F-59777 Euralille, France.
EM m.slim_benmimoun@skema.edu; ingrid.poncin@uclouvain-mons.be;
   marion.garnier@skema.edu
RI Poncin, Ingrid/F-4374-2019
OI Poncin, Ingrid/0000-0002-4225-0118
CR Ahn T, 2007, INFORM MANAGE-AMSTER, V44, P263, DOI 10.1016/j.im.2006.12.008
   Aksoy L, 2011, J INTERACT MARK, V25, P110, DOI 10.1016/j.intmar.2011.01.001
   ALBA JW, 1987, J CONSUM RES, V13, P411, DOI 10.1086/209080
   ALBA JW, 1983, ADV CONSUM RES, V10, P577
   Anitsal I., 2005, THESIS
   Anitsal I, 2007, J MARKET THEORY PRAC, V15, P349, DOI 10.2753/MTP1069-6679150405
   Argo JJ, 2005, J CONSUM RES, V32, P207, DOI 10.1086/432230
   Baier D, 2010, J RETAIL CONSUM SERV, V17, P173, DOI 10.1016/j.jretconser.2010.03.005
   Baron S., EUR J MARK, V30
   Beatty SE, 1996, J RETAILING, V72, P223, DOI 10.1016/S0022-4359(96)90028-7
   Behe BK, 2015, J RETAIL CONSUM SERV, V24, P10, DOI 10.1016/j.jretconser.2015.01.002
   Ben Mimoun MS, 2014, INFORM MANAGE-AMSTER, V51, P375, DOI 10.1016/j.im.2014.02.003
   Ben Mimoun MS, 2012, J RETAIL CONSUM SERV, V19, P605, DOI 10.1016/j.jretconser.2012.07.006
   Benbasat I., 2005, J ASSOC INF SYST, V6, P72, DOI [10.17705/1jais.00065, DOI 10.17705/1JAIS.00065]
   Bettman J. R., 1979, INFORM PROCESSING TH
   BETTMAN JR, 1980, J CONSUM RES, V7, P234, DOI 10.1086/208812
   Bickmore T., 2002, P CHI 2002 WORKSHOP
   Biocca F., 1995, VISION VIRTUAL REALI, P3
   BLOCH PH, 1994, J RETAILING, V70, P23, DOI 10.1016/0022-4359(94)90026-4
   Breugelmans E, 2011, J RETAILING, V87, P75, DOI 10.1016/j.jretai.2010.09.003
   BRUCKS M, 1985, J CONSUM RES, V12, P1, DOI 10.1086/209031
   Burke RR, 2002, J ACAD MARKET SCI, V30, P411, DOI 10.1177/009207002236914
   Cassell J., 2000, EMBODIED CONVERSATIO
   Chang HH, 2010, INT J HUM-COMPUT ST, V68, P69, DOI 10.1016/j.ijhcs.2009.09.010
   Cho JS, 2004, INFORM MANAGE-AMSTER, V41, P827, DOI 10.1016/j.im.2003.08.013
   Cox R, 1948, J MARKETING, V12, P433, DOI 10.2307/1246623
   Curran J. M., 2003, J SERV RES, V5
   Curran J. M., 2005, J SERV MARK, V19, P103, DOI DOI 10.1108/08876040510591411
   Cyr D, 2007, INTERACT COMPUT, V19, P43, DOI 10.1016/j.intcom.2006.07.010
   Dabholkar PA, 2002, J ACAD MARKET SCI, V30, P184, DOI 10.1177/0092070302303001
   Dabholkar Pratibha A., 1996, INT J RES MARK, V13, P29, DOI DOI 10.1016/0167-8116(95)00027-5
   Dahl DW, 2001, J CONSUM RES, V28, P473, DOI 10.1086/323734
   Davis A, 2009, J ASSOC INF SYST, V10, P90, DOI 10.17705/1jais.00183
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   De Wulf K, 2001, J MARKETING, V65, P33, DOI 10.1509/jmkg.65.4.33.18386
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   Dholakia U.M., 2001, EUR J MARKETING, V35, P1340, DOI DOI 10.1108/EUM0000000006479
   Diesbach B. P., 2007, LECT NOTES ARTIF INT, P42
   Drossos DA, 2014, ELECTRON COMMER R A, V13, P423, DOI 10.1016/j.elerap.2014.08.003
   Felnhofer A, 2014, COMPUT HUM BEHAV, V31, P272, DOI 10.1016/j.chb.2013.10.045
   Fransen ML, 2011, J BUS RES, V64, P29, DOI 10.1016/j.jbusres.2009.09.016
   Garnier M, 2013, RECH APPL MARKET-ENG, V28, P85, DOI 10.1177/2051570713478335
   Gefen D, 2000, OMEGA-INT J MANAGE S, V28, P725, DOI 10.1016/S0305-0483(00)00021-9
   Gronroos C., J BUS RES, V57
   Groom V., 2009, INT J HUM COMPUT STU
   Gulz A, 2006, INT J HUM-COMPUT ST, V64, P322, DOI 10.1016/j.ijhcs.2005.08.006
   Hackbarth G, 2003, INFORM MANAGE-AMSTER, V40, P221, DOI 10.1016/S0378-7206(02)00006-X
   Harker P. T., 2002, J SERV RES-US, V4, P253, DOI DOI 10.1177/1094670502004004003
   Hassanein K, 2005, INT J ELECTRON COMM, V10, P31, DOI 10.2753/JEC1086-4415100202
   Hausman AV, 2009, J BUS RES, V62, P5, DOI 10.1016/j.jbusres.2008.01.018
   He Y, 2012, J BUS RES, V65, P302, DOI 10.1016/j.jbusres.2011.03.014
   HEIMBACH AE, 1989, ADV CONSUM RES, V16, P460
   Hess T, 2009, J ASSOC INF SYST, V10, P889
   Holscher C, 2000, COMPUT NETW, V33, P337, DOI 10.1016/S1389-1286(00)00031-1
   Holzwarth M, 2006, J MARKETING, V70, P19, DOI 10.1509/jmkg.70.4.19
   Homburg C, 2011, J ACAD MARKET SCI, V39, P795, DOI 10.1007/s11747-010-0220-7
   Hong IB, 2015, INT J INFORM MANAGE, V35, P322, DOI 10.1016/j.ijinfomgt.2015.01.003
   Hostler RE, 2005, DECIS SUPPORT SYST, V41, P313, DOI 10.1016/j.dss.2004.07.002
   Hsu MH, 2004, DECIS SUPPORT SYST, V38, P369, DOI 10.1016/j.dss.2003.08.001
   Huang SL, 2006, INT J ELECTRON COMM, V11, P85, DOI 10.2753/JEC1086-4415110104
   INGENE CA, 1984, J RETAILING, V60, P15
   INGENE CA, 1982, J MARKETING, V46, P75, DOI 10.2307/1251364
   Ingharn J, 2015, INFORM MANAGE-AMSTER, V52, P44, DOI 10.1016/j.im.2014.10.002
   Jeandrain A., 2008, P 37 EMAC C MAY BRIG
   Johnston R., 2004, INT J PRODUCTIVITY P, V53, P201, DOI DOI 10.1108/17410400410523756
   Kalczynski PJ, 2006, INT J ELECTRON COMM, V10, P121, DOI 10.2753/JEC1086-4415100305
   Kamis A., 2005, E SERVICE J, V4, P3
   Kamis AA, 2006, INFORM MANAGE-AMSTER, V43, P904, DOI 10.1016/j.im.2006.08.006
   Keeling KA, 2008, ADV CONSUM RES, V35, P86
   Khalifa M, 2007, EUR J INFORM SYST, V16, P780, DOI 10.1057/palgrave.ejis.3000711
   Kukar-Kinney M, 2010, J ACAD MARKET SCI, V38, P240, DOI 10.1007/s11747-009-0141-5
   Kumar N, 2006, INFORM SYST RES, V17, P425, DOI 10.1287/isre.1060.0107
   Laaksonen Pirjo, 1994, CONSUMER INVOLVEMENT
   Laroche M, 2005, J RETAILING, V81, P251, DOI 10.1016/j.jretai.2004.11.002
   Lee BK, 2011, PSYCHOL MARKET, V28, P360, DOI 10.1002/mar.20360
   Lee S, 2015, COMPUT HUM BEHAV, V51, P336, DOI 10.1016/j.chb.2015.04.049
   Lin CS, 2005, INFORM MANAGE-AMSTER, V42, P683, DOI 10.1016/j.im.2004.04.003
   Lombard M., 1997, J COMPUTER MEDIATED, V3, DOI [10.1111/j.1083-6101.1997.tb00072.x, DOI 10.1111/J.1083-6101.1997.TB00072.X]
   Mai R, 2014, J INTERACT MARK, V28, P101, DOI 10.1016/j.intmar.2013.10.001
   Artigas EM, 2015, J RETAIL CONSUM SERV, V26, P147, DOI 10.1016/j.jretconser.2015.06.005
   Markellou P., 2005, PRODUCT CATALOGUE SH
   Martin CR, 2001, INT J SERV IND MANAG, V12, P137, DOI 10.1108/09564230110387515
   McGoldrick PJ, 2008, J MARKET MANAG-UK, V24, P433, DOI 10.1362/026725708X306176
   Mimoun M. S. Ben, 2013, E MARKETING DEV DEV
   Mimoun M. S. Ben, 2013, INT BUS RES, V6, P31
   Mitchell A.A., 1979, ADV CONSUM RES, V6, P191
   Mitchell A. A., 1986, CONSUMER PSYCHOL ADV, P172
   Moon JW, 2001, INFORM MANAGE, V38, P217, DOI 10.1016/S0378-7206(00)00061-6
   Notebaert J.F., 2005, REV FRANCAISE MARKET, V205, P71
   Novak TP, 2000, MARKET SCI, V19, P22, DOI 10.1287/mksc.19.1.22.15184
   Nowak KL, 2008, COMPUT HUM BEHAV, V24, P1473, DOI 10.1016/j.chb.2007.05.005
   Nysveen H., 2005, International Journal of Internet Marketing and Advertising, V2, P288, DOI 10.1504/IJIMA.2005.008103
   O'Cass A., 2002, J RETAIL CONSUM SERV, V10, P81, DOI DOI 10.1016/S0969-6989(02)00004-8
   Ogara SO, 2014, COMPUT HUM BEHAV, V36, P453, DOI 10.1016/j.chb.2014.03.064
   Ogonowski A, 2014, J RETAIL CONSUM SERV, V21, P482, DOI 10.1016/j.jretconser.2014.03.004
   Oh H, 2013, J BUS RES, V66, P692, DOI 10.1016/j.jbusres.2011.09.005
   Ojasalo K., 1999, THESIS
   Olson E. L., 2002, J INTERACT MARK, V16, P22, DOI DOI 10.1002/DIR.10007
   Ondrusek AL, 2004, LIBR INFORM SCI RES, V26, P221, DOI 10.1016/j.lisr.2004.01.002
   Pan Y., 2005, TOW MODELS ONLINE PA
   Papadopoulou P., 2000, Virtual Reality, V5, P149, DOI 10.1007/BF01409420
   Parasuraman A, 2002, MANAG SERV QUAL, V12, P6, DOI DOI 10.1108/096045202104
   Punj G, 2009, J BUS RES, V62, P644, DOI 10.1016/j.jbusres.2007.04.013
   Qiu LY, 2010, INT J HUM-COMPUT ST, V68, P669, DOI 10.1016/j.ijhcs.2010.05.005
   Qiu LY, 2009, J MANAGE INFORM SYST, V25, P145, DOI 10.2753/MIS0742-1222250405
   Ranganathan C., 2005, CONVERTING BROWSER B
   RATCHFORD BT, 1987, J ADVERTISING RES, V27, P24
   Reynolds KE, 1999, J RETAILING, V75, P11, DOI 10.1016/S0022-4359(99)80002-5
   Russo E.J., 1980, ADV CONSUM RES, V7, P417
   Semeraro Giovanni, 2008, Universal Access in the Information Society, V7, P179, DOI 10.1007/s10209-008-0116-1
   Serenko A, 2007, INFORM MANAGE-AMSTER, V44, P657, DOI 10.1016/j.im.2007.08.002
   Shobeiri S, 2013, J RETAIL CONSUM SERV, V20, P102, DOI 10.1016/j.jretconser.2012.10.011
   Sink D. S., 1985, PRODUCTIVITY MANAGEM
   Sledgianowski D, 2009, J COMPUT INFORM SYST, V49, P74
   SMITH DC, 1992, J MARKETING RES, V29, P296, DOI 10.2307/3172741
   Spiekermann S., 2001, DRIVERS IMPEDIMENTS
   Swaminathan V, 2003, J CONSUM PSYCHOL, V13, P93, DOI 10.1207/153276603768344816
   Traphagan TW, 2010, COMPUT EDUC, V55, P923, DOI 10.1016/j.compedu.2010.04.003
   Tu CH, 2000, J NETW COMPUT APPL, V23, P27, DOI 10.1006/jnca.1999.0099
   Venkatesh V, 2000, MANAGE SCI, V46, P186, DOI 10.1287/mnsc.46.2.186.11926
   Vuorinen I, 1998, INT J SERV IND MANAG, V9, P377, DOI 10.1108/09564239810228876
   Wang LC, 2007, J MARKETING, V71, P143, DOI 10.1509/jmkg.71.3.143
   Wood N. T., 2005, International Journal of Internet Marketing and Advertising, V2, P143, DOI 10.1504/IJIMA.2005.007509
   Xiao B, 2007, MIS QUART, V31, P137
   Xue M, 2007, M&SOM-MANUF SERV OP, V9, P535, DOI 10.1287/msom.1060.0135
   Yoon VY, 2013, DECIS SUPPORT SYST, V55, P883, DOI 10.1016/j.dss.2012.12.024
   ZAICHKOWSKY JL, 1985, J CONSUM RES, V12, P341, DOI 10.1086/208520
   Zimmer JC, 2010, DECIS SUPPORT SYST, V48, P395, DOI 10.1016/j.dss.2009.10.003
   Zolkepli IA, 2015, COMPUT HUM BEHAV, V43, P189, DOI 10.1016/j.chb.2014.10.050
NR 130
TC 35
Z9 35
U1 11
U2 97
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0378-7206
EI 1872-7530
J9 INFORM MANAGE-AMSTER
JI Inf. Manage.
PD JUL
PY 2017
VL 54
IS 5
BP 545
EP 559
DI 10.1016/j.im.2016.11.008
PG 15
WC Computer Science, Information Systems; Information Science & Library
   Science; Management
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Information Science & Library Science; Business &
   Economics
GA EZ9KC
UT WOS:000405048300001
DA 2022-08-02
ER

PT J
AU Louwerse, MM
   Graesser, AC
   McNamara, DS
   Lu, SL
AF Louwerse, Max M.
   Graesser, Arthur C.
   McNamara, Danielle S.
   Lu, Shulan
TI Embodied Conversational Agents as Conversational Partners
SO APPLIED COGNITIVE PSYCHOLOGY
LA English
DT Article
ID ANIMATED PEDAGOGICAL AGENTS; COMPREHENSION; AUTOTUTOR; ATTENTION; IMPACT
AB Conversational agents are becoming more widespread in computer technologies but there has been little research in how humans interact with them. Two eye tracking studies investigated how humans distribute eye gaze towards conversational agents in complex tutoring systems. In Study 1, participants interacted with the single-agent tutoring system AutoTutor. Fixation times showed that the agent received most attention throughout the interaction, even when display size was statistically controlled. In Study 2, participants interacted with iSTART. Fixations were on the relevant agents when these agents spoke. Both studies provided evidence that humans regard animated conversational agents as conversational partners in the communication process. Copyright (C) 2008 JohnWiley & Sons, Ltd.
C1 [Louwerse, Max M.] Univ Memphis, Dept Psychol, Inst Intelligent Syst, Memphis, TN 38152 USA.
   [Lu, Shulan] Texas A&M Univ Commerce, College Stn, TX 77843 USA.
RP Louwerse, MM (corresponding author), Univ Memphis, Dept Psychol, Inst Intelligent Syst, 202 Psychol Bldg, Memphis, TN 38152 USA.
EM mlouwers@memphis.edu
CR Andre E., 1998, Proceedings of the Second International Conference on Autonomous Agents, P261, DOI 10.1145/280765.280842
   Argyle M., 1976, GAZE MUTUAL GAZE
   Atkinson RK, 2002, J EDUC PSYCHOL, V94, P416, DOI 10.1037//0022-0663.94.2.416
   Baeza-Yates R, 1999, MODERN INFORM RETRIE, V463
   Baylor A. L., 2003, Journal of Educational Computing Research, V28, P373, DOI 10.2190/V0WQ-NWGN-JB54-FAT4
   Cassell J., 2000, EMBODIED CONVERSATIO
   Clark H.H, 1996, USING LANGUAGE
   Craig SD, 2002, J EDUC PSYCHOL, V94, P428, DOI 10.1037//0022-0663.94.2.428
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   FISH RS, 1993, COMMUN ACM, V36, P48, DOI 10.1145/151233.151237
   Graesser AC, 2005, EDUC PSYCHOL-US, V40, P225, DOI 10.1207/s15326985ep4004_4
   Graesser AC, 2003, FRONT ARTIF INTEL AP, V97, P47
   Graesser AC, 2004, BEHAV RES METH INS C, V36, P180, DOI 10.3758/BF03195563
   GRAESSER AC, 2003, P AAAI SPRING S 2003, P9
   Gullberg M, 2003, MIND'S EYE: COGNITIVE AND APPLIED ASPECTS OF EYE MOVEMENT RESEARCH, P685, DOI 10.1016/B978-044451020-4/50037-2
   Hunt AR, 2003, COGNITIVE BRAIN RES, V18, P102, DOI 10.1016/j.cogbrainres.2003.08.006
   Kendon A, 1980, RELATIONSHIP VERBAL, V25, P207, DOI DOI 10.1515/9783110813098.207
   Lester JC, 1997, FR ART INT, V39, P23
   Louwerse MM, 2005, APPL COGNITIVE PSYCH, V19, P693, DOI 10.1002/acp.1117
   Lusk MM, 2007, APPL COGNITIVE PSYCH, V21, P747, DOI 10.1002/acp.1347
   MASSARO DW, 1983, J EXP PSYCHOL HUMAN, V9, P753, DOI 10.1037/0096-1523.9.5.753
   McNamara DS, 2004, BEHAV RES METH INS C, V36, P222, DOI 10.3758/BF03195567
   Moreno R, 2001, COGNITION INSTRUCT, V19, P177, DOI 10.1207/S1532690XCI1902_02
   PEZDEK K, 1983, CHILD DEV, V54, P1015, DOI 10.1111/j.1467-8624.1983.tb00522.x
   Plaisant C., 2004, DESIGNING USER INTER
   Reeves B., 1996, MEDIA EQUATION PEOPL
   REID A, 1977, SOCIAL IMPACT TELEPH, P386
   SHNEIDERMAN B, 1997, SOFTWARE AGENTS, P97
   SUMMERFIELD AQ, 1987, HEARING EYE PSYCHOL, P3
   Sweller J, 1998, EDUC PSYCHOL REV, V10, P251, DOI 10.1023/A:1022193728205
   VanLehn K, 2007, COGNITIVE SCI, V31, P3, DOI 10.1080/03640210709336984
   WAGENAAR WA, 1985, ERGONOMICS, V28, P765, DOI 10.1080/00140138508963196
   Wright R.D., 2008, ORIENTING ATTENTION
NR 33
TC 32
Z9 34
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0888-4080
EI 1099-0720
J9 APPL COGNITIVE PSYCH
JI Appl. Cogn. Psychol.
PD DEC
PY 2009
VL 23
IS 9
BP 1244
EP 1255
DI 10.1002/acp.1527
PG 12
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA 652UC
UT WOS:000282034700004
DA 2022-08-02
ER

PT C
AU Mendonca, V
   Melo, FS
   Coheur, L
   Sardinha, A
AF Mendonca, Vania
   Melo, Francisco S.
   Coheur, Luisa
   Sardinha, Alberto
BE Oliveira, E
   Gama, J
   Vale, Z
   Cardoso, HL
TI Online Learning for Conversational Agents
SO PROGRESS IN ARTIFICIAL INTELLIGENCE (EPIA 2017)
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 18th EPIA Conference on Artificial Intelligence (EPIA)
CY SEP 05-08, 2017
CL Univ Porto, Fac Engn, Porto, PORTUGAL
SP EPIA, Univ Porto, Artificial Intelligence & Comp Sci Lab, INESC TEC, Lab Artificial Intelligence & Decis Support, Inst Engn Polytechn Porto, Intelligent Engn & Comp Adv Innovat & Dev Res Grp
HO Univ Porto, Fac Engn
DE Online learning; Exponentially Weighted Average Forecaster;
   Conversational agents
AB Agents relying on large collections of interactions face the challenge of choosing an appropriate answer from such collections. Several works address this challenge by using offline learning approaches, which do not take advantage of how user-agent conversations unfold.
   In this work, we propose an alternative approach: incorporating user feedback at each interaction with the agent, in order to enhance its ability to choose an answer. We focus on the case of adjusting the weights of the features used by the agent to choose an answer, using an online learning algorithm (the Exponentially Weighted Average Forecaster) for that purpose. We validate our hypothesis with an experiment featuring a specific agent and simulating user feedback using a reference corpus. The results of our experiment suggest that the adjustment of the agent's feature weights can improve its answers, provided that an appropriate reward function is designed, as this aspect is critical in the agent's performance.
C1 [Mendonca, Vania] Inst Super Tecn, Av Prof Doutor Anibal Cavaco Silva, Porto Salvo, Portugal.
   INESC ID, Av Prof Doutor Anibal Cavaco Silva, Porto Salvo, Portugal.
RP Mendonca, V (corresponding author), Inst Super Tecn, Av Prof Doutor Anibal Cavaco Silva, Porto Salvo, Portugal.
EM vania.mendonca@tecnico.ulisboa.pt; fmelo@inesc-id.pt;
   luisa.coheur@tecnico.ulisboa.pt; alberto.sardinha@tecnico.ulisboa.pt
RI Melo, Francisco S/B-5434-2016; Melo, Francisco S./AAG-8359-2020;
   Sardinha, Alberto/L-9553-2015; Coheur, Luisa/A-7554-2012
OI Melo, Francisco S/0000-0001-5705-7372; Melo, Francisco
   S./0000-0001-5705-7372; Sardinha, Alberto/0000-0002-5782-3142; Coheur,
   Luisa/0000-0002-2456-5028
FU Fundacao para a Ciencia e a Tecnologia (FCT) [UID/CEC/50021/2013,
   CMUP-ERI/HCI/0051/2013]; FCT grant [SFRH/BD/121443/2016]
FX This work was supported by national funds through Fundacao para a
   Ciencia e a Tecnologia (FCT) with reference UID/CEC/50021/2013, and
   under project CMUP-ERI/HCI/0051/2013. Vania Mendonca is funded by an FCT
   grant with reference SFRH/BD/121443/2016.
CR Ameixa D., 2013, TECHNICAL REPORT
   Ameixa D, 2014, LECT NOTES ARTIF INT, V8637, P13, DOI 10.1007/978-3-319-09767-1_2
   Banchs R. E., 2012, P ACL 2012 SYST DEM, P37
   Banchs R. E., 2012, P 50 ANN M ASS COMP, P203
   Bessho F., 2012, P 13 ANN M SPEC INT, P227
   Cuayahuitl H., 2012, NAACL HLT WORKSH FUT, P7
   Gasic M., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P312, DOI 10.1109/ASRU.2011.6163950
   Jaccard P, 1912, NEW PHYTOL, V11, P37, DOI [DOI 10.1111/J.1469-8137.1912.TB05611.X, 10.1111/j.1469-8137.1912.tb05611.x]
   Lee L., 2011, ACL
   Levin E, 2000, IEEE T SPEECH AUDI P, V8, P11, DOI 10.1109/89.817450
   Li J., 2016, CORR
   LITTLESTONE N, 1994, INFORM COMPUT, V108, P212, DOI 10.1006/inco.1994.1009
   Lugosi G., 2006, PREDICTION LEARNING
   Magarreiro D., 2014, SEMDIAL 2014 DIALWAT
   McCandless M., 2010, LUCENE ACTION, V2nd ed.
   Nio L., 2012, INT WORKSH SPOK DIAL
   Pietquin O., 2011, INT JOINT C ART INT, P1878
   Serban I. V., 2015, AAAI 2016 SPEC TRACK
   Singh S, 2002, J ARTIF INTELL RES, V16, P105, DOI 10.1613/jair.859
   Su PH, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2431
   Xu Z., 2016, CORR
   Yao K., 2016, CORR
   Yu Z., 2016, WOCHAT WORKSH
   Yu Z., 2016, P 17 ANN M SPECIAL I, P404
NR 24
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-319-65340-2; 978-3-319-65339-6
J9 LECT NOTES ARTIF INT
PY 2017
VL 10423
BP 739
EP 750
DI 10.1007/978-3-319-65340-2_60
PG 12
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BL5QH
UT WOS:000452455800060
DA 2022-08-02
ER

PT C
AU Simonin, J
   Carbonell, N
AF Simonin, Jerome
   Carbonell, Noelle
BE Stephanidis, C
TI Enhancements to Online Help: Adaptivity and Embodied Conversational
   Agents
SO UNIVERSAL ACCESS IN HUMAN-COMPUTER INTERACTION, PT II, PROCEEDINGS:
   INTELLIGENT AND UBIQUITOUS INTERACTION ENVIRONMENTS
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 5th International Conference on Universal Access in Human-Computer
   Interaction held at the HCI International 2009
CY JUL 19-24, 2009
CL San Diego, CA
DE Adaptive user interfaces; Embodied conversational agents; Talking heads;
   Online help; Speech and graphics; Multimodal interaction; Eye tracking
AB We present and discuss the results of two empirical studies that aim at assessing the contributions, to the effectiveness and efficiency of online help of: adaptive-proactive user support (APH), multimodal (speech and graphics) messages (MH), and embodied conversational agents (ECAs). These three enhancements to online help were implemented using the Wizard of Oz technique. The first study (EH) compares MH with APH, while the second study (E2) compares MH with embodied help (EH). Half of the participants in E1 (8) used MH, and the other half used APH. Most participants who used MH, resp. APH, preferred MH, resp. APH, to standard help systems which implement text and graphics messages (like APH). In particular, proactive assistance was much appreciated. However, higher performances were achieved with MH. A majority of the 22 participants in E2 preferred EH to MH, and were of the opinion that the presence of an ECA, a talking head in this particular case, has the potential to improve help effectiveness and efficiency by increasing novice users' self confidence. However, performances with the two systems were similar, save for help consultation rate which was higher with EH. Longitudinal (usage) studies are needed to confirm the effects of these three enhancements on novice users' judgments and performances.
C1 [Simonin, Jerome; Carbonell, Noelle] Henri Poincare Univ, INRIA, Nancy Grand Est Res Ctr, LORIA, Vandoeuvre Les Nancy, France.
RP Simonin, J (corresponding author), Henri Poincare Univ, INRIA, Nancy Grand Est Res Ctr, LORIA, Campus Sci,BP 70239, Vandoeuvre Les Nancy, France.
EM Jerome.Simonin@loria.fr; Noelle.Carbonell@loria.fr
CR Axmear E, 2005, LANG SPEECH HEAR SER, V36, P244, DOI 10.1044/0161-1461(2005/024)
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   CAPOBIANCO A, 2001, P HCI INT, V2, P824
   Carroll J. M., 1987, Human-Computer Interaction, V3, P123, DOI 10.1207/s15327051hci0302_2
   Chin DN, 2001, USER MODEL USER-ADAP, V11, P181, DOI 10.1023/A:1011127315884
   DARVES C, 2004, BROWS TRUST EVALUA 4, pCH10
   Eichner T, 2007, LECT NOTES ARTIF INT, V4722, P283
   HORVITZ E, 1998, P 14 C UNC ART INT U, P256
   Jameson A, 2003, HUM FAC ER, P305
   KEHOE A, 2006, P 24 ANN C DES COMM, P157
   Ma C, 2005, P S CONV INF SUPP SO, P136
   Moreno R, 2006, CONTEMP EDUC PSYCHOL, V31, P186, DOI 10.1016/j.cedpsych.2005.05.002
   Mori J., 2003, P AAMAS 03 WORKSH W1, P58
   Payr S, 2003, APPL ARTIF INTELL, V17, P1, DOI [10.1080/713827053, 10.1080/08839510390169729]
   PICARD RW, 2005, WORKSH EV AFF INT IN
   Piwek P, 2007, LECT NOTES ARTIF INT, V4722, P161
   Poggi I, 2000, AI COMMUN, V13, P169
   Ran L, 2004, SECOND IEEE ANNUAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P23, DOI 10.1109/PERCOM.2004.1276842
   Roden TE, 2007, SCI COMPUT PROGRAM, V67, P76, DOI 10.1016/j.scico.2006.07.004
   RUTTKAY Z, 2002, WORKSH EMB CONV AG L
   van Mulken S., 1999, Human-Computer Interaction: Ergonomics and User Interfaces. Proceedings of HCI International '99 (8th International Conference on Human-Computer Interaction), P152
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Wilensky R, 2000, ARTIF INTELL REV, V14, P43, DOI 10.1023/A:1006500224529
   ZAJICEK M, 2005, P CLIHC, P31
NR 24
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-02709-3
J9 LECT NOTES COMPUT SC
PY 2009
VL 5615
BP 748
EP 757
PG 10
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BME59
UT WOS:000272028100083
OA Bronze
DA 2022-08-02
ER

PT C
AU Kocaballi, AB
   Quiroz, JC
   Laranjo, L
   Rezazadegan, D
   Kocielnik, R
   Clark, L
   Liao, QV
   Park, SY
   Moore, RJ
   Miner, A
AF Kocaballi, A. Baki
   Quiroz, Juan C.
   Laranjo, Liliana
   Rezazadegan, Dana
   Kocielnik, Rafal
   Clark, Leigh
   Liao, Q. Vera
   Park, Sun Young
   Moore, Robert J.
   Miner, Adam
GP Assoc Comp Machinery
TI Conversational Agents for Health and Wellbeing
SO CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS
   IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT ACM CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 25-30, 2020
CL Honolulu, HI
SP ACM SIGCHI, Assoc Comp Machinery
DE Conversational agent; voice interface; speech interface; chatbots;
   healthcare; health informatics
ID MENTAL-HEALTH
AB Conversational agents have increasingly been deployed in healthcare applications. However, significant challenges remain in developing this technology. Recent research in this area has highlighted that: i) patient safety was rarely evaluated; ii) health outcomes were poorly measured, and iii) no standardised evaluation methods were employed. The conversational agents in healthcare are lagging behind the developments in other domains. This one-day workshop aims to create a roadmap for healthcare conversational agents to develop standardised design and evaluation frameworks. This will prioritise health outcomes and patient safety while ensuring a high-quality user experience. In doing so, this workshop will bring together researchers and practitioners from HCI, healthcare and related speech and chatbot domains to collaborate on these key challenges.
C1 [Kocaballi, A. Baki; Quiroz, Juan C.; Laranjo, Liliana] Macquarie Univ, Ctr Hlth Informat, N Ryde, NSW, Australia.
   [Rezazadegan, Dana] Macquarie Univ, N Ryde, NSW, Australia.
   [Kocielnik, Rafal] Univ Washington, Human Ctr Design & Engn Dept, Seattle, WA 98195 USA.
   [Clark, Leigh] Swansea Univ, Comp Sci, Swansea, W Glam, Wales.
   [Liao, Q. Vera] IBM Res AI, New York, NY USA.
   [Park, Sun Young] Univ Michigan, Stamps Sch Art & Design, Ann Arbor, MI 48109 USA.
   [Park, Sun Young] Univ Michigan, Sch Informat, Ann Arbor, MI 48109 USA.
   [Moore, Robert J.] IBM Res, San Jose, CA USA.
   [Miner, Adam] Stanford Univ, Sch Med, Stanford, CA 94305 USA.
RP Kocaballi, AB (corresponding author), Macquarie Univ, Ctr Hlth Informat, N Ryde, NSW, Australia.
EM baki.kocaballi@mq.edu.au; juan.quiroz@mq.edu.au;
   liliana.laranjo@mq.edu.au; dana.rezazadegan@mq.edu.au;
   rafal.kocielnik@gmail.com; l.m.h.clark@swansea.ac.uk; vera.liao@ibm.com;
   sunypark@umich.edu; rjmoore@us.ibm.com; aminer@stanford.edu
RI Kocaballi, Baki/R-3136-2019; Laranjo, Liliana/D-5356-2017
OI Kocaballi, Baki/0000-0002-8328-5317; Laranjo,
   Liliana/0000-0003-1020-3402; Miner, Adam/0000-0002-5125-4735
FU National Health and Medical Research Council (NHMRC) [APP1134919,
   APP1054146]; National Institutes of Health, National Center for
   Advancing Translational Science, Clinical and Translational Science
   Award [KL2TR001083, UL1TR001085]; Stanford Department of Psychiatry
   Innovator Grant Program; Stanford Human-Centered AI Institute
FX This workshop is supported by the National Health and Medical Research
   Council (NHMRC) grant APP1134919 (Centre for Research Excellence in
   Digital Health) and Programme Grant APP1054146 as part of the Digital
   Scribe Project led by Professor Enrico Coiera. This work was also
   supported by grants from the National Institutes of Health, National
   Center for Advancing Translational Science, Clinical and Translational
   Science Award (KL2TR001083 and UL1TR001085), the Stanford Department of
   Psychiatry Innovator Grant Program, and the Stanford Human-Centered AI
   Institute. We would like to thank Prof Michael McTear for his comments
   on an earlier draft of this proposal.
CR Amershi Saleema, 2019, P CHI
   Bickmore T, 2006, J BIOMED INFORM, V39, P556, DOI 10.1016/j.jbi.2005.12.004
   Bickmore T, 2018, HUM-COMPUT INT-SPRIN, P33, DOI 10.1007/978-3-319-95579-7_3
   Bickmore TW, 2018, J MED INTERNET RES, V20, DOI 10.2196/11510
   Bickmore TW, 2013, J AM GERIATR SOC, V61, P1676, DOI 10.1111/jgs.12449
   Bickmore TW, 2013, PATIENT EDUC COUNS, V92, P142, DOI 10.1016/j.pec.2013.05.011
   Clark Leigh, 2019, STATE SPEECH HCI TRE
   Clark Leigh, 2019, P CHI
   Coiera E, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0066-9
   Edwards RA, 2013, MATERN CHILD HLTH J, V17, P1961, DOI 10.1007/s10995-013-1222-0
   Klann JG, 2009, BMC MED INFORM DECIS, V9, DOI 10.1186/1472-6947-9-S1-S3
   Kocaballi A. Baki, J MED INTERNET RES
   Kocaballi AB, 2019, J MED INTERNET RES, V21, DOI 10.2196/15360
   Kocielnik Rafal, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3214273
   Kocielnik Rafal, 2019, P AMIA WASH
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   Miner AS, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00746
   Miner AS, 2017, JAMA-J AM MED ASSOC, V318, P1217, DOI 10.1001/jama.2017.14151
   Miner AS, 2016, JAMA INTERN MED, V176, P619, DOI 10.1001/jamainternmed.2016.0400
   Moore R. J., 2019, CONVERSATIONAL UX DE
   Moore Robert J., 2017, P CHI
   Murad Christine, 2018, P MOB HCI 18 ADJ
   Nishida A, 2014, INT ICE CONF ENG
   Porcheron Martin, 2017, P CSCW COMP
   Pradhan A, 2018, PORTL INT CONF MANAG, DOI 10.1145/3173574.3174033
   Reeves Stuart, 2018, P CHI
   Sillice MA, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.7640
   Watson A, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.1629
   Wolters MK, 2016, HEALTH INFORM J, V22, P854, DOI 10.1177/1460458215593329
NR 31
TC 0
Z9 0
U1 1
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6819-3
PY 2020
DI 10.1145/3334480.3375154
PG 8
WC Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ9OG
UT WOS:000626317800058
OA Green Published
DA 2022-08-02
ER

PT C
AU Kaleem, M
   O'Shea, JD
   Crockett, KA
AF Kaleem, Mohammed
   O'Shea, James D.
   Crockett, Keeley A.
BE Neagu, D
   Kiran, M
   Trundle, P
TI Word Order Variation and String Similarity Algorithm to Reduce Pattern
   Scripting in Pattern Matching Conversational Agents
SO 2014 14TH UK WORKSHOP ON COMPUTATIONAL INTELLIGENCE (UKCI)
LA English
DT Proceedings Paper
CT 14th UK Annual Workshop on Computational Intelligence (UKCI)
CY SEP 08-10, 2014
CL University of Bradford, Bradford, ENGLAND
SP IEEE Computat Intelligence Soc
HO University of Bradford
DE Conversational Agents; Dialog Systems; Sentence Similarity; Urdu
ID SYSTEMS
AB This paper presents a novel sentence similarity algorithm designed to mitigate the issue of free word order in the Urdu language. Free word order in a language poses many challenges when implemented in a conversational agent, primarily due to the fact that it increases the amount of scripting time needed to script the domain knowledge. A language with free word order like Urdu means a single phrase/utterance can be expressed in many different ways using the same words and still be grammatically correct. This led to the research of a novel string similarity algorithm which was utilized in the development of an Urdu conversational agent. The algorithm was tested through a black box testing methodology which involved processing different variations of scripted patterns through the system to gauge the performance and accuracy of the algorithm with regards to recognizing word order variations of the related scripted patterns. Initial testing has highlighted that the algorithm is able to recognize legal word order variations and reduce the knowledge base scripting of conversational agents significantly. Thus saving great time and effort when scripting the knowledge base of a conversational agent.
C1 [Kaleem, Mohammed; O'Shea, James D.; Crockett, Keeley A.] Manchester Metropolitan Univ, Dept Comp Math & Digital Technol, Manchester M15 6BH, Lancs, England.
RP Kaleem, M (corresponding author), Manchester Metropolitan Univ, Dept Comp Math & Digital Technol, Manchester M15 6BH, Lancs, England.
EM mohammed.kaleem@stu.mmu.ac.uk; j.d.oshea@mmu.ac.uk; k.crockett@mmu.ac.uk
CR Abidi A., 2011, DOC AN REC ICDAR 201
   Ahmed T., 2011, P 9 INT C COMP SEM
   Ahmed T., 2011, LINGUIST LIT REV, V1, P1, DOI [10.32350/llr/11/05, DOI 10.32350/LLR/11/05]
   Alobaidi O. G., 2013, P WORLD C ENG
   Anwar W., 2006, MACH LEARN CYB 2006
   Bhagwani S., 2012, P 1 JOINT C LEX COMP
   Bickmore T, 2006, J BIOMED INFORM, V39, P556, DOI 10.1016/j.jbi.2005.12.004
   Bogel T, 2013, LING AKT, V199, P291
   Burkard R. E., 1999, LINEAR ASSIGNMENT PR
   Butt M. J., 1994, THEORETICAL PERSPECT, V50
   Butt Miriam, 1995, STRUCTURE COMPLEX PR
   Chowdhury GG, 2003, ANNU REV INFORM SCI, V37, P51, DOI 10.1002/aris.1440370103
   Crockett K, 2011, LECT NOTES ARTIF INT, V6682, P16, DOI 10.1007/978-3-642-22000-5_3
   Dasgupta D., 2008, P 2008 GECCO C COMP
   Hussain S., 2001, MULT TOP C 2001 IEEE
   Ijaz M., 2007, P C LANG TECHN CLT07
   Kaleem M., 2014, P WORLD C ENG
   Latham A. M., 2011, PERSONALITY LEARNING
   Latham A, 2014, COMPUT EDUC, V71, P97, DOI 10.1016/j.compedu.2013.09.014
   Li YH, 2006, IEEE T KNOWL DATA EN, V18, P1138, DOI 10.1109/TKDE.2006.130
   Michie D., 2001, INFOCHAT SCRIPTER MA
   Mukund S., 2010, P 23 INT C COMP LING
   Myers G.J., 2011, ART SOFTWARE TESTING, V3rd
   Naim C. M., 1999, INTRO URDU REV
   Naseem T, 2007, LANG RESOUR EVAL, V41, P117, DOI 10.1007/s10579-007-9028-6
   O'Shea J, 2008, LECT NOTES ARTIF INT, V4953, P172, DOI 10.1007/978-3-540-78582-8_18
   O'Shea J, 2011, INTEL SYST REF LIBR, V10, P201, DOI 10.1007/978-3-642-17931-0_8
   O'Shea K., 2013, APPL INTELL, P1
   O'Shea K., 2009, INT TECHN SEC T 2009
   Osathanunkul K, 2011, LECT NOTES ARTIF INT, V6682, P544, DOI 10.1007/978-3-642-22000-5_56
   Pickard M. D., 2013, J INFORM SYSTEMS
   Rashid R., 2012, AS LANG PROC LALP 20
   Raza G., 2011, SUBCATEGORIZATION AQ
   Ristad ES, 1998, IEEE T PATTERN ANAL, V20, P522, DOI 10.1109/34.682181
   Rubin VL, 2010, LIBR HI TECH, V28, P496, DOI 10.1108/07378831011096196
   Sarfraz H., 2010, TECHNOLOGY PREPAREDN
   Secer A., 2011, INT J PHYS SCI, V6, P4224
   Syed AZ, 2011, LECT NOTES ARTIF INT, V7094, P382, DOI 10.1007/978-3-642-25324-9_33
   Zafar A., 2012, P C LANG TECHN
NR 39
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-4799-5538-1
PY 2014
BP 214
EP 221
PG 8
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BC5YF
UT WOS:000353643200030
DA 2022-08-02
ER

PT C
AU Ujiro, T
   Tanaka, H
   Adachi, H
   Kazui, H
   Ikeda, M
   Kudo, T
   Nakamura, S
AF Ujiro, Tsuyoki
   Tanaka, Hiroki
   Adachi, Hiroyoshi
   Kazui, Hiroaki
   Ikeda, Manabu
   Kudo, Takashi
   Nakamura, Satoshi
GP Int Speech Commun Assoc
TI Detection of dementia from responses to atypical questions asked by
   embodied conversational agents
SO 19TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2018), VOLS 1-6: SPEECH RESEARCH FOR EMERGING
   MARKETS IN MULTILINGUAL SOCIETIES
SE Interspeech
LA English
DT Proceedings Paper
CT 19th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2018)
CY AUG 02-SEP 06, 2018
CL Hyderabad, INDIA
SP Int Speech Commun Assoc
DE Dementia; atypical questions; speech feature; language feature; embodied
   conversational agents
ID MINI-MENTAL-STATE
AB Detection of dementia requires examinations, such as blood tests and functional magnetic resonance imaging (fMRI), that can be very stressful for the patient. Previous studies proposed screenings for easy detection of dementia that utilized acoustic and language information derived from conversations between patients and medical staff. Although these studies demonstrated effectiveness in automatically detecting dementia, the tasks used were created based on neuropsychological tests. The effect of habituation on this limited variety of tasks might have a negative impact on routine dementia screening. We propose a method to detect dementia using responses to more atypical questions asked by embodied conversational agents. Through consultations with neuropsychologists, we created a total of 13 questions. The embodied conversational agent obtained answers to these questions from 24 participants (12 dementia and 12 non-dementia). We recorded their responses and extracted speech and language features. We classified the two groups (dementia/non-dementia) by a machine learning algorithm (support vector machines and logistic regression) using the extracted features. The results showed a 0.95 detection performance in the area under the curve of the receiver operating characteristic (AUROC). This result demonstrates that our system using atypical questions can detect dementia.
C1 [Ujiro, Tsuyoki; Tanaka, Hiroki; Nakamura, Satoshi] Nara Inst Sci & Technol, Grad Sch Informat Sci, Nara, Japan.
   [Adachi, Hiroyoshi; Kudo, Takashi] Osaka Univ, Hlth & Counseling Ctr, Suita, Osaka, Japan.
   [Kazui, Hiroaki] Kochi Med Sch, Dept Neuropsychiat, Nankoku, Kochi, Japan.
   [Ikeda, Manabu] Osaka Univ, Grad Sch Med, Suita, Osaka, Japan.
RP Ujiro, T (corresponding author), Nara Inst Sci & Technol, Grad Sch Informat Sci, Nara, Japan.
EM ujiro.tsuyoki.uq5@is.naist.jp
OI Tanaka, Hiroki/0000-0002-0548-6252
FU Suntory Global Innovation Center Ltd.; JSPS KAKENHI [JP17H06101,
   JP18K11437]
FX Part of this work was supported by the Collaborative Research Project
   with Suntory Global Innovation Center Ltd. as well as JSPS KAKENHI Grant
   Numbers JP17H06101 and JP18K11437.
CR American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU, V5th ed., DOI [https://doi.org/10.1176/appi.books.9780890425596, DOI 10.1176/APPI.BOOKS.9780890425596]
   American Psychiatric Association, 2000, DIAGN STAT MAN MENT, V4th, DOI [10.1176/appi.books.9780890423349, DOI 10.1176/APPI.BOOKS.9780890423349]
   Aramaki E, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155195
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   HOSOKAWA T, 1994, PERCEPT MOTOR SKILL, V79, P664, DOI 10.2466/pms.1994.79.1.664
   Hou C. E., 2005, INT J GERIATR PSYCH, V20, P809
   Roark B, 2011, IEEE T AUDIO SPEECH, V19, P2081, DOI 10.1109/TASL.2011.2112351
   SantaCruz KS, 2001, AM FAM PHYSICIAN, V63, P703
   Squire LR, 1996, P NATL ACAD SCI USA, V93, P13515, DOI 10.1073/pnas.93.24.13515
   SQUIRE LR, 1988, TRENDS NEUROSCI, V11, P170, DOI 10.1016/0166-2236(88)90144-0
   Taler V, 2008, J CLIN EXP NEUROPSYC, V30, P501, DOI 10.1080/13803390701550128
   Tanaka H, 2017, IEEE J TRANSL ENG HE, V5, DOI 10.1109/JTEHM.2017.2752152
   Wechsler D., 1997, WAIS 3 WECHSLER ADUL
   1993, SCIENCE, V262, P1747
   2015, ALZHEIMERS DEMENT, V11, P561, DOI DOI 10.1016/J.JALZ.2014.06.004
   2011, ALZHEIMERS DEMENT, V7, P263, DOI DOI 10.1016/J.JALZ.2011.03.005
   2017, PROC FIFTEENTH IAPR, P262
   2017, PROC INTERSPEECH 201, P3147, DOI DOI 10.21437/INTERSPEECH.2017-690
NR 18
TC 8
Z9 8
U1 2
U2 2
PU ISCA-INT SPEECH COMMUNICATION ASSOC
PI BAIXAS
PA C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE
SN 2308-457X
BN 978-1-5108-7221-9
J9 INTERSPEECH
PY 2018
BP 1691
EP 1695
DI 10.21437/Interspeech.2018-1514
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BM5PH
UT WOS:000465363900354
DA 2022-08-02
ER

PT J
AU Plastina, AF
AF Plastina, Anna Franca
TI THE L2 EFFECTIVENESS OF EMBODIED CONVERSATIONAL AGENTS AS
   AFFINITY-SEEKING STRATEGIES
SO RIVISTA DI PSICOLINGUISTICA APPLICATA-JOURNAL OF APPLIED
   PSYCHOLINGUISTICS
LA English
DT Article
DE Affinity-seeking strategies; Embodied Conversational Agents; ESL learner
   motivation; L2 Affective and cognitive learning; Embodied Cognition and
   Interaction
ID LANGUAGE
AB This paper advocates the need to revisit the classroom practice of affinity-seeking in view of the technology-pervasiveness of the contemporary world. Embracing a socio-psychological perspective, the study questions whether Embodied Conversational Agents (ECAs) can be effectively used as affinity-seeking strategies to enhance ESL learners' cognitive and affective outcomes. Based on the principles of embodied cognition, ECAs have the potential of engaging digital-native L2 learners in affinity-seeking, thus empowering situated language practice. A qualitative, descriptive method was adopted to analyze ECA verbal and nonverbal behaviours in simulated interactions manipulated by a validated affinity-seeking typology. Findings highlight ECA effectiveness in terms of L2 motivation, and affective and cognitive learning.
C1 [Plastina, Anna Franca] Univ Calabria, Arcavacata Di Rende, Italy.
RP Plastina, AF (corresponding author), Univ Calabria, Dept Pharm Hlth & Nutr Sci, I-87036 Arcavacata Di Rende, CS, Italy.
EM annafranca.plastina@unical.it
CR Altimari F, 2012, LECT NOTES ENG COMP, P236
   ANDERSEN JF, 1979, COMMUNICATION YB, V3, P543, DOI DOI 10.1080/23808985.1979.11923782
   [Anonymous], 2009, INT J ARTIFICIAL INT
   Argyle M, 1972, PSYCHOL INTERPERSONA
   Barsalou LW, 2003, PSYCHOL LEARN MOTIV, V43, P43, DOI 10.1016/S0079-7421(03)01011-9
   Baylor A. L., 2003, Journal of Educational Computing Research, V28, P373, DOI 10.2190/V0WQ-NWGN-JB54-FAT4
   Beebe S.A., 2009, 21 CENTURY COMMUNICA, P349
   BELL RA, 1984, COMMUN MONOGR, V51, P91, DOI 10.1080/03637758409390188
   Bennett S, 2008, BRIT J EDUC TECHNOL, V39, P775, DOI 10.1111/j.1467-8535.2007.00793.x
   Blackmore C, 2010, SOCIAL LEARNING SYSTEMS AND COMMUNITIES OF PRACTICE, P1, DOI 10.1007/978-1-84996-133-2
   BRILL J, 2001, EMERGING PERSPECTIVE
   Cassell J., 2000, EMBODIED CONVERSATIO
   Clark A, 2008, SUPERSIZING MIND EMB
   COLLEY H, 2003, INFORM FORMALITY LEA
   Collins A., 1989, KNOWING LEARNING INS, P453
   Craig SD, 2002, J EDUC PSYCHOL, V94, P428, DOI 10.1037//0022-0663.94.2.428
   Daly J. A., 1992, POWER CLASSROOM COMM, P121
   Dobransky N.D., 2004, COMMUN Q, V52, P211, DOI [DOI 10.1080/01463370409370193, https://doi.org/10.1080/01463370409370193]
   DOURISH P, 2001, ACTION IS FDN EMBODI
   Fryer L, 2006, LANG LEARN TECHNOL, V10, P8
   Frymier A. B., 2006, HDB INSTRUCTIONAL CO, P195
   FRYMIER AB, 1992, COMMUN EDUC, V41, P388, DOI 10.1080/03634529209378900
   Gasser U., 2008, BORN DIGITAL UNDERST
   Gee J. P, 2004, SITUATED LANGUAGE LE
   Gibbs RW, 2006, EMBODIMENT COGNITIVE
   Gorham J., 1989, COMMUNICATION Q, V37, P16, DOI DOI 10.1080/01463378909385522
   Grabill J.T., 2005, ENGLISH ED, V37, P301
   Hershey K., 2005, J ED MULTIMEDIA HYPE, V14, P113
   Holme R, 2012, TESOL QUART, V46, P6, DOI 10.1002/tesq.5
   JOHNSON W. L., 2009, 2009 HORIZON REPORT
   Johnson WL, 2000, INT J ARTIFICIAL INT, V11, P47
   Jones C, 2010, COMPUT EDUC, V54, P722, DOI 10.1016/j.compedu.2009.09.022
   Lankshear C., 2003, NEW LITERACIES CHANG, P3
   LENHART A, 2005, YOUTH ARE LEADING TR
   Marsick V.J., 1990, INFORMAL INCIDENTAL
   McCroskey J. C., 1986, COMMUNICATION RES RE, V3, P158, DOI DOI 10.1080/08824099509362056
   MCCROSKEY JC, 1976, INTRO HUMAN COMMUNIC
   Mehrabian A., 1971, SILENT MESSAGES
   Moreno R, 2004, INSTRUCTIONAL DESIGN, P9
   Moreno R., 2000, C P WORLD C ED MULTI, P741
   Moundridou M, 2002, J COMPUT ASSIST LEAR, V18, P253, DOI 10.1046/j.0266-4909.2001.00237.x
   Myers S.A., 1995, COMMUN RES REP, V12, DOI [https://doi.org/10.1080/08824099509362056, DOI 10.1080/08824099509362056]
   Nass C, 2004, HUM-COMPUT INT-SPRIN, V7, P161
   O'Brien DG, 2005, READ RES QUART, V40, P120, DOI 10.1598/RRQ.40.1.7
   Pelachaud C., 2005, 13th Annual ACM International Conference on Multimedia, P683
   Prensky M., 2001, HORIZON, V9, P1, DOI [10.1108/10748120110424816(, DOI 10.1108/10748120110424816]
   Rambusch J., 2005, P 27 ANN C COGNITIVE, P1803
   Reis H. T., 2009, ENCY HUMAN RELATIONS, V1
   RICHMOND V., 1986, WORLD COMMUNICATION, V15, P41
   Richmond V.P., 1992, POWER CLASSROOM COMM, P101
   ROACH K. D, 1991, SO COMMUNICATION J, V5757, P7373
   Roach KD, 2005, COMMUN Q, V53, P87, DOI 10.1080/01463370500056127
   Shapiro L, 2011, NEW PROBL PHILOS, P1
   Shum SB, 2012, EDUC TECHNOL SOC, V15, P3
   Sinha C, 2000, COGN LINGUIST, V11, P17
   SLATER D., 2012, WHAT IS INTERACTIVE
   Tapscott D., 2008, GROWN DIGITAL NET GE
   Vygotsky L. S., 1978, MIND SOC DEV HIGHER
   WANZER M. B., 2002, COMMUNICATION TEACHE, V16, P15
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   [No title captured]
NR 61
TC 0
Z9 0
U1 0
U2 0
PU FABRIZIO SERRA EDITORE
PI PISA
PA PO BOX  NO,1, SUCC NO. 8, PISA, I-56123, ITALY
SN 1592-1328
EI 1724-0646
J9 RIV PSICOLINGUIST AP
JI Riv. Psicolinguistics Appl.
PY 2014
VL 14
IS 1
BP 83
EP 96
PG 14
WC Linguistics
WE Emerging Sources Citation Index (ESCI)
SC Linguistics
GA VH4XM
UT WOS:000453261700005
DA 2022-08-02
ER

PT J
AU Montenegro, JLZ
   Da Costa, CA
AF Zeni Montenegro, Joao Luis
   da Costa, Cristiano Andre
TI The HoPE Model Architecture: a Novel Approach to Pregnancy Information
   Retrieval Based on Conversational Agents
SO JOURNAL OF HEALTHCARE INFORMATICS RESEARCH
LA English
DT Article
DE Sentence-BERT; Data augmentation; Information retrieval; Conversational
   agents; Natural language processing; Public health informatics
ID DECISION-MAKING; HEALTH; INTERNET; CHATBOT
AB Conversational agents are used to communicating with humans in a friendly manner. To achieve the highest level of performance, agents need to respond assertively and fastly. Transformer architectures are shown to produce excellent performances on recent tasks; however, for tasks involving conversational agents, they may have a lower speed performance. The main goal of this study is to evaluate and propose a HoPE (Healthcare Obstetric in PrEgnancy) model that is tailored to pregnancy data. We carried out a dataset extraction and construction process based on collections of health documents related to breastfeeding, childcare, pregnant care, nutrition, risks, vaccines, exams, and physical exercises. We evaluated two pre-trained models in the Portuguese language for the conversational agent architecture proposal and chose the one with the best performance to compose the HoPE architecture. The BERTimbau model, which has been trained on data augmentation strategies, proves to be able to retrieve information quickly and most accurately than others. For the fine-tuning process, we achieved a Spearman correlation of 95.55 on BERTimbau augmented with a few pairs (1.500 pairs). The HoPE model architecture achieved an F1-Score of 0.89, outperforming other combinations tested in this study. We will evaluate this approach for clinical studies in future studies.
C1 [Zeni Montenegro, Joao Luis; da Costa, Cristiano Andre] Univ Vale Rio dos SinosTel, SOFTWARELAB, Appl Comp Grad Program, Av Unisinos 950, Sao Leopoldo, RS, Brazil.
RP Da Costa, CA (corresponding author), Univ Vale Rio dos SinosTel, SOFTWARELAB, Appl Comp Grad Program, Av Unisinos 950, Sao Leopoldo, RS, Brazil.
EM joaomontenegro18@edu.unisinos.br; cac@unisinos.br
OI Andre da Costa, Cristiano/0000-0003-3859-6199
FU Brazilian National Council for Scientific and Technological Development
   - CNPq [303640/2017-0, 405354/2016-9]
FX The authors would like to thank the Brazilian National Council for
   Scientific and Technological Development - CNPq (Grant Numbers
   303640/2017-0 and 405354/2016-9) for supporting this work.
CR Alambo Amanuel, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12662), P20, DOI 10.1007/978-3-030-68790-8_2
   Alfeo, 2021, J INTELL MANUF, V32, P1
   ALMarwi H, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00310-z
   Alomari A, 2022, COMPUT SPEECH LANG, V71, DOI 10.1016/j.csl.2021.101276
   Altinok D, 2018, ARXIV180404838
   Amith Muhammad, 2019, Stud Health Technol Inform, V257, P17
   de Souza JVA, 2020, LECT NOTES ARTIF INT, V12037, P357, DOI 10.1007/978-3-030-41505-1_34
   [Anonymous], 2018, FARINELLI ONTONEO
   Avila, 2019, MEDIBOT ONTOLOGY BAS
   Bakouan M, 2018, INT J ADV COMPUT SC, V9, P168
   Barbosa, 2021, ARXIV211201959
   Beltagy I., 2019, P 2019 C EMP METH NA, DOI DOI 10.18653/V1/D19-1371
   Benesty J., 2009, PEARSON CORRELATION, P1, DOI DOI 10.1007/978-3-642-00296-0_5
   Bickmore TW, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5239
   Bickmore TW, 2010, J HEALTH COMMUN, V15, P197, DOI 10.1080/10810730.2010.499991
   Bickmore TW, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1265
   Bjelke M, 2016, MIDWIFERY, V40, P187, DOI 10.1016/j.midw.2016.06.020
   Boonstra, 2021, DEFINITIVE GUIDE CON, P29
   Boudjellal N, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6633213
   Cabezudo MAS, 2019, ASSIN STIL, P49
   Carlsson, 2021, INT C LEARN REPR
   Chang, 2019, ARXIV190502331
   Choi H, 2021, INT C PATT RECOG, P5482, DOI 10.1109/ICPR48806.2021.9412102
   2014, RDF 1 1 CONC ABSTR S
   Criss S, 2015, MATERN CHILD HLTH J, V19, P2536, DOI 10.1007/s10995-015-1774-2
   Croux C, 2010, STAT METHOD APPL-GER, V19, P497, DOI 10.1007/s10260-010-0142-z
   Dai Z, 2019, 2019 12 INT C IM SIG, P1, DOI DOI 10.1109/CISP-BMEI48845.2019.8965823
   Deng XY, 2016, INFORM SCIENCES, V340, P250, DOI 10.1016/j.ins.2016.01.033
   Devlin J., 2019, PRE, P4171, DOI DOI 10.48550/ARXIV.1810.04805
   Duta IC, 2016, INT WORK CONTENT MUL
   Emygdio, 2019, MULTIPLOS OLHARES CI, V9
   Engelmann D, 2021, LECT NOTES ARTIF INT, V12946, P77, DOI 10.1007/978-3-030-85739-4_7
   Esteva A, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-020-00376-2
   Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1
   Fushiki T, 2011, STAT COMPUT, V21, P137, DOI 10.1007/s11222-009-9153-8
   Ganhotra, 2020, ARXIV201002305
   Goeuriot L, 2016, INFORM RETRIEVAL, V19, P1, DOI 10.1007/s10791-015-9277-8
   Guo JF, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102067
   Han, 2019, ARXIV190402817
   Henderson, 2017, ARXIV170500652
   Hersh, 2020, INFORM RETRIEVAL BIO
   Huertas-Garcia A, 2021, INT C INT DAT ENG AU, P312
   Humeau, 2019, ARXIV190501969
   Inamdar, 2019, DEVELOPMENT, V6, P1615
   Jack B, 2015, J AM BOARD FAM MED, V28, P441, DOI 10.3122/jabfm.2015.04.140327
   Junior VODS, 2021, 2021 IEEE 21 INT C B, P1
   Kadri Y, 2006, P CHALL AR NLP MT C, P68
   Kankaria RV, 2021, 2021 12 INT C COMP C, P1
   Kasilingam DL, 2020, TECHNOL SOC, V62, DOI 10.1016/j.techsoc.2020.101280
   Khattab O, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P39, DOI 10.1145/3397271.3401075
   Kilmer, 2020, ARXIV200611467
   Kim, 2021, ARXIV210607345
   Lagan BM, 2010, BIRTH-ISS PERINAT C, V37, P106, DOI 10.1111/j.1523-536X.2010.00390.x
   Larkey L. S., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P275
   Latif G., 2017, 2017 9 IEEE GCC C EX, P1
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Li, 2020, ARXIV201105864
   Li DQ, 2018, INT J INTELL SYST, V33, P348, DOI 10.1002/int.21934
   Liang, 2016, ARXIV160605250, DOI DOI 10.18653/V1/D16-1264
   Liu, 2020, ARXIV200207972
   Lv YH, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P1103
   Malizia A, 2010, EXPERT SYST APPL, V37, P3380, DOI 10.1016/j.eswa.2009.10.010
   Maroengsit W, 2019, PROCEEDINGS OF 2019 7TH INTERNATIONAL CONFERENCE ON INFORMATION AND EDUCATION TECHNOLOGY (ICIET 2019), P111, DOI 10.1145/3323771.3323824
   Mellado-Silva R, 2020, 2020 39 INT C CHIL C, P1
   Mikolov T, 2013, P NAACL HLT 2013
   Moyer CA, 2020, ARCH WOMEN MENT HLTH, V23, P757, DOI 10.1007/s00737-020-01073-5
   Mukherjee, 2021, ARXIV211102570
   Nazir A, 2019, INT J ADV COMPUT SC, V10, P546
   Nouri SS, 2015, PATIENT EDUC COUNS, V98, P565, DOI 10.1016/j.pec.2014.12.002
   Noy N.F., 2001, KSL0105, DOI DOI 10.1016/J.ARTMED.2004.01.014
   Oliveira LES, 2017, IEEE INT C BIOINFORM, P1072, DOI 10.1109/BIBM.2017.8217805
   Padaki Ramith, 2020, Advances in Information Retrieval. 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12036), P297, DOI 10.1007/978-3-030-45442-5_37
   Palanica A, 2019, J MED INTERNET RES, V21, DOI 10.2196/12887
   Patel V, 2008, LANCET, V372, P1354, DOI 10.1016/S0140-6736(08)61556-1
   Pereira Ivan, 2020, WebMedia '20: Proceedings of the Brazilian Symposium on Multimedia and the Web, P277, DOI 10.1145/3428658.3431752
   Peters M. E., 2018, IMPROVING LANGUAGE U, P2227
   Podgorny, 2019, CHI 2019 WORKSH GLAS
   Qian YH, 2009, INT J APPROX REASON, V50, P174, DOI 10.1016/j.ijar.2008.08.004
   Quamar A, 2020, PROC VLDB ENDOW, V13, P3369, DOI 10.14778/3415478.3415557
   Ragab M, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/6241676
   Raji P, 2016, 2016 INT C RES ADV I, P1, DOI DOI 10.1109/RAINS.2016.7764416
   Rajosoa M, 2019, HYBRID QUESTION ANSW
   Reimers N., 2019, P 2019 C EMPIRICAL M, P3982
   Rodrigues R, 2019, P ASSIN 2 SHAR TASK, P39
   Rodrigues RC, 2020, LECT NOTES ARTIF INT, V12037, P239, DOI 10.1007/978-3-030-41505-1_23
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Rubinstein A, 2018, ACM S THEORY COMPUT, P1260, DOI 10.1145/3188745.3188916
   Rychalska B, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P256, DOI 10.1109/SNAMS.2018.8554770
   Safder I, 2019, SCIENTOMETRICS, V119, P257, DOI 10.1007/s11192-019-03025-y
   Samimi P, 2014, SCI WORLD J, DOI 10.1155/2014/135641
   Sankhavara J., 2020, SN COMPUT SCI, V1, P1, DOI DOI 10.1007/S42979-020-0069-X
   Sayakhot P, 2016, BMC PREGNANCY CHILDB, V16, DOI 10.1186/s12884-016-0856-5
   Senese MA, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P717
   Sheth A, 2019, IEEE INTERNET COMPUT, V23, P6, DOI 10.1109/MIC.2018.2889231
   Singh, 2021, ARXIV210103013
   Singh S, 2021, IEEE ACCESS, V9, P68675, DOI 10.1109/ACCESS.2021.3077350
   Souza Fabio, 2020, Intelligent Systems. 9th Brazilian Conference, BRACIS 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12319), P403, DOI 10.1007/978-3-030-61377-8_28
   Tahami AV, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2081, DOI 10.1145/3397271.3401296
   Tanana MJ, 2019, J MED INTERNET RES, V21, DOI 10.2196/12529
   Teixeira M.S., 2021, P 36 ANN ACM S APPL, P611
   Thakur N, 2020, ARXIV201008240
   Traylor CS, 2020, AM J OBST GYNEC MFM, V2, DOI 10.1016/j.ajogmf.2020.100229
   Trivedi S, 2020, J HEALTHC INFORM RES, V4, P395, DOI 10.1007/s41666-020-00079-z
   Vaswani A, 2017, ADV NEUR IN, V30
   Wagner JA, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P4339
   Wang A., 2018, P 2018 EMNLP WORKSH
   Wang K, 2019, LECT NOTES COMPUT SC, V11448, P49, DOI 10.1007/978-3-030-18590-9_4
   Wang Y, 2016, TREC
   Wang YX, 2020, 19TH SIGBIOMED WORKSHOP ON BIOMEDICAL LANGUAGE PROCESSING (BIONLP 2020), P105
   Whissell JS, 2011, INFORM RETRIEVAL, V14, P466, DOI 10.1007/s10791-011-9163-y
   Wu ZM, 2021, J BIOMED INFORM, V115, DOI 10.1016/j.jbi.2021.103683
   Xie YQ, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2934, DOI 10.1145/3366423.3380060
   Yang, 2019, ARXIV190201718
   Yang W, 2019, ARXIV190406652
   Yin XY, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10030958
   Yoo, 2020, J SOC E BUSINESS STU, V24
   Yoon, 2020, ARXIV201214700
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
   Zhang, 2021, ARXIV211111750
   Zhang Z, 2017, PATIENT EDUC COUNS, V100, P1730, DOI 10.1016/j.pec.2017.03.017
NR 120
TC 0
Z9 0
U1 0
U2 0
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 2509-4971
EI 2509-498X
J9 J HEALTHC INFORM RES
JI J. Healthc. Inform. Res.
PD SEP
PY 2022
VL 6
IS 3
BP 253
EP 294
DI 10.1007/s41666-022-00115-0
EA APR 2022
PG 42
WC Computer Science, Information Systems; Health Care Sciences & Services;
   Medical Informatics
WE Emerging Sources Citation Index (ESCI)
SC Computer Science; Health Care Sciences & Services; Medical Informatics
GA 3F1GK
UT WOS:000779713300001
PM 35411331
OA Green Published, Bronze
DA 2022-08-02
ER

PT S
AU Heylen, D
   van Es, I
   Nijholt, A
   van Dijk, B
AF Heylen, Dirk
   van Es, Ivo
   Nijholt, Anton
   van Dijk, Betsy
BE VanKuppevelt, JCJ
   Dybkjaer, L
   Bernsen, NO
TI CONTROLLING THE GAZE OF CONVERSATIONAL AGENTS
SO ADVANCES IN NATURAL MULTIMODAL DIALOGUE SYSTEMS
SE Text Speech and Language Technology
LA English
DT Article; Book Chapter
DE Gaze; embodied conversational agents; human computer interaction
AB We report on a pilot experiment that investigated the effects of different eye gaze behaviours of a cartoon-like talking face on the quality of human-agent dialogues. We compared a version of the talking face that roughly implements some patterns of human-like behaviour with two other versions. In one of the other versions the shifts in gaze were kept minimal and in the other version the shifts would occur randomly. The talking face has a number of restrictions. There is no speech recognition, so questions and replies have to be typed in by the users of the systems. Despite this restriction we found that participants that conversed with the agent that behaved according to the human-like patterns appreciated the agent better than participants that conversed with the other agents. Conversations with the optimal version also proceeded more efficiently. Participants needed less time to complete their task.
C1 [Heylen, Dirk; van Es, Ivo; Nijholt, Anton; van Dijk, Betsy] Univ Twente, NL-7500 AE Enschede, Netherlands.
RP Heylen, D (corresponding author), Univ Twente, NL-7500 AE Enschede, Netherlands.
EM heylen@cs.utwente.nl; es@cs.utwente.nl; anijholt@cs.utwente.nl;
   bvdijk@cs.utwente.nl
OI Nijholt, Anton/0000-0002-5669-9290
CR [Anonymous], 2001, P SIGCHI C HUM FACT, DOI DOI 10.1145/365024.365119
   ARGYLE M, 1974, EUR J SOC PSYCHOL, V4, P125, DOI 10.1002/ejsp.2420040202
   Argyle M., 1976, GAZE MUTUAL GAZE
   ARGYLE M, 1972, COMMUNICATION FACE F, P155
   ARGYLE M, 1993, BODILY COMMUNICATION
   Cassell J, 1999, SPRING INT SER ENG C, V511, P143
   CASSELL J, 2000, CONVERSATIONAL AGENT
   Cassell J., 1994, P 21 ANN C COMP GRAP, P413, DOI DOI 10.1145/192161.192272
   CHOPRAKULLAR S, 1999, P 3 ANN C AUT AG, P9
   COLBURN RA, 2000, MSRTR200081 MICR
   FUKAYAMA A, 2002, P SIGCHI C HUM FACT, P41
   Garau M, 2001, P SIGCHI C HUM FACT, P309
   HEYLEN D, 2001, P EUR S INT TECHN HY, P110
   KENDON A, 1990, CONDUCTING INTERACTI, P51
   KLEINKE CL, 1986, PSYCHOL BULL, V100, P78, DOI 10.1037/0033-2909.100.1.78
   Nijholt A, 2000, STUD FUZZ SOFT COMP, V45, P148
   Novick DG, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1888, DOI 10.1109/ICSLP.1996.608001
   Poggi I, 2000, AI COMMUN, V13, P169
   Thornton K., 1996, Proceedings of the 8th Workshop on Nuclear Astrophysics, P44
   VERTEGAAL R, 1999, P CHI 99, P294
NR 20
TC 8
Z9 8
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS
SN 1386-291X
BN 978-1-4020-3933-1
J9 TEXT SPEECH LANG TEC
PY 2005
VL 30
BP 245
EP 262
D2 10.1007/1-4020-3933-6
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Language & Linguistics
WE Book Citation Index – Social Sciences & Humanities (BKCI-SSH); Book Citation Index – Science (BKCI-S)
SC Computer Science; Linguistics
GA BLA38
UT WOS:000269751500012
DA 2022-08-02
ER

PT J
AU Rubin, VL
   Chen, YM
   Thorimbert, LM
AF Rubin, Victoria L.
   Chen, Yimin
   Thorimbert, Lynne Marie
TI Artificially intelligent conversational agents in libraries
SO LIBRARY HI TECH
LA English
DT Article
DE Academic libraries; Public libraries; Canada; Intelligent agents; User
   interfaces; Information retrieval
AB Purpose - Conversational agents are natural language interaction interfaces designed to simulate conversation with a real person. This paper seeks to investigate current development and applications of these systems worldwide, while focusing on their availability in Canadian libraries. It aims to argue that it is both timely and conceivable for Canadian libraries to consider adopting conversational agents to enhance not replace face-to-face human interaction. Potential users include library web site tour guides, automated virtual reference and readers' advisory librarians, and virtual story-tellers. To provide background and justification for this argument, the paper seeks to review agents from classic implementations to state-of-the-art prototypes: how they interact with users, produce language, and control conversational behaviors.
   Design/methodology/approach - The web sites of the 20 largest Canadian libraries were surveyed to assess the extent to which specific language-related technologies are offered in Canada, including conversational agents. An exemplified taxonomy of four pragmatic purposes that conversational agents currently serve outside libraries educational, informational, assistive, and socially interactive is proposed and translated into library settings.
   Findings - As of early 2010, artificially intelligent conversational systems have been found to be virtually non-existent in Canadian libraries, while other innovative technologies proliferate (e.g. social media tools). These findings motivate the need for a broader awareness and discussion within the US community of these systems' applicability and potential for library purposes.
   Originality/value - This paper is intended for reflective information professionals who seek a greater understanding of the issues related to adopting conversational agents in libraries, as this topic is scarcely covered in the LIS literature. The pros and cons are discussed, and insights offered into perceptions of intelligence (artificial or not) as well as the fundamentally social nature of human-computer interaction.
C1 [Rubin, Victoria L.; Chen, Yimin] Univ Western Ontario, Fac Informat & Media Studies, London, ON, Canada.
   [Thorimbert, Lynne Marie] Marigold Lib Syst, Strathmore, AB, Canada.
RP Rubin, VL (corresponding author), Univ Western Ontario, Fac Informat & Media Studies, London, ON, Canada.
EM vrubin@uwo.ca
RI ; Rubin, Victoria/N-7341-2015
OI Chen, Yimin/0000-0002-0924-3661; Rubin, Victoria/0000-0003-3610-9967
CR Active History, 2009, HEAD2HEAD INT
   Andre E., 2000, COOPERATIVE INFORM A, P51
   Artstein R, 2009, LECT NOTES COMPUT SC, V5533, P22, DOI 10.1007/978-3-642-01748-3_2
   Barr A., 1982, HDB ARTIFICIAL INTEL, V1
   Berner U, 2003, LECT NOTES COMPUT SC, V2615, P350
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   CARTE, 2009, ADV DIST ED ADE
   Cassell J, 2001, AI MAG, V22, P67
   Chatbots.org, 2006, CHATB DIR LILL
   Christensen A., 2007, TREND GERMANY LIB CH
   Cycorp, 2009, WHATS CYC
   Daden Limited, 2010, INTR LILL VIRT LIB L
   ELLIOTT C, 1998, AI MAGAZINE, V19
   Epstein R., 2007, SCI AM MIND     1016
   Eve, 2009, EV EGAIN CHATB
   Figa E, 2004, P ASIST ANNU, V41, P403, DOI 10.1002/meet.1450410147
   Foster ME, 2007, LECT NOTES COMPUT SC, V4555, P828
   Goh OS, 2003, LECT NOTES COMPUT SC, V2690, P10
   Hafner K., 2001, GAME SIMULATIONS MIL
   Heudin JC, 2008, LECT NOTES COMPUT SC, V4820, P154
   Hofstadter DR., 1995, FLUID CONCEPTS CREAT
   HSIEH CC, 1989, INFORM TECHNOL LIBR, V8, P209
   IntelliResponse, 2009, INST ANSW AG HIGH ED
   Jia JY, 2009, KNOWL-BASED SYST, V22, P249, DOI 10.1016/j.knosys.2008.09.001
   Kerly A, 2008, KNOWL-BASED SYST, V21, P238, DOI 10.1016/j.knosys.2007.11.015
   Kopp S, 2005, LECT NOTES ARTIF INT, V3661, P329
   Lester J., 2001, AI MAGAZINE, V22
   Maclean's, 2009, CAN BEST SCH OUR 19
   Nardi BA, 1996, LIBRI, V46, P59, DOI 10.1515/libr.1996.46.2.59
   NASS C, 1994, P SIGCHI C HUM FACT
   NextIT, 2009, NEWS ARM SERG STAR R
   Ottawa Public Library, 2010, MISS STAT OTT PUBL L
   Public Library Statistics, 2008, STAT PART CAN PUBL L
   Rao K.N., 2001, INFORM SCI, V4, P25
   San-Segundo R, 2008, SPEECH COMMUN, V50, P1009, DOI 10.1016/j.specom.2008.02.001
   Shawar B.A., 2003, PROCESAMIENTO LENGUA, V31, P309
   SitePal.com, 2009, SITEPAL ED
   Skov-Nielson H., 2008, PARTNERSHIP CANADIAN, V3
   Speech and Language Processing for Assistive Technologies, 2010, P 11 ANN C N AM CHAP
   Staab S., 1999, P 3 INT WORKSH COOP
   Toronto Public Library, 2010, TOR PUBL LIB OUR VIS
   Turing AM., 1950, J MIND ASS, V59, P433, DOI [10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   Uhler L., 2010, VOYA, V32, P472
   University of British Columbia, 2010, U BRIT COL LIB
   University of Saskatchewan, 2010, U SASK LIB STRAT PLA
   US Army, 2009, SGT STAR ARM VIRT GU
   Wallace R.S., 2009, PARSING TURING TEST
   Weizenbaum J., 1966, CACM, V9, P35
   Zick L., 2000, First Monday, V5
   [No title captured]
NR 50
TC 28
Z9 28
U1 4
U2 56
PU EMERALD GROUP PUBLISHING LIMITED
PI BINGLEY
PA HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN 0737-8831
J9 LIBR HI TECH
JI Libr. Hi Tech
PY 2010
VL 28
IS 4
BP 496
EP 522
DI 10.1108/07378831011096196
PG 27
WC Information Science & Library Science
WE Social Science Citation Index (SSCI)
SC Information Science & Library Science
GA 733YR
UT WOS:000288300900002
DA 2022-08-02
ER

PT J
AU Wienrich, C
   Carolus, A
AF Wienrich, Carolin
   Carolus, Astrid
TI Development of an Instrument to Measure Conceptualizations and
   Competencies About Conversational Agents on the Example of Smart
   Speakers
SO FRONTIERS IN COMPUTER SCIENCE
LA English
DT Article
DE artificial intelligence literacy; artificial intelligence education;
   voice-based artificial intelligence; conversational agents; measurement
ID VALIDATION; LITERACY; BELIEFS
AB The concept of digital literacy has been introduced as a new cultural technique, which is regarded as essential for successful participation in a (future) digitized world. Regarding the increasing importance of AI, literacy concepts need to be extended to account for AI-related specifics. The easy handling of the systems results in increased usage, contrasting limited conceptualizations (e.g., imagination of future importance) and competencies (e.g., knowledge about functional principles). In reference to voice-based conversational agents as a concrete application of AI, the present paper aims for the development of a measurement to assess the conceptualizations and competencies about conversational agents. In a first step, a theoretical framework of "AI literacy" is transferred to the context of conversational agent literacy. Second, the "conversational agent literacy scale" (short CALS) is developed, constituting the first attempt to measure interindividual differences in the "(il) literate" usage of conversational agents. 29 items were derived, of which 170 participants answered. An explanatory factor analysis identified five factors leading to five subscales to assess CAL: storage and transfer of the smart speaker's data input; smart speaker's functional principles; smart speaker's intelligent functions, learning abilities; smart speaker's reach and potential; smart speaker's technological (surrounding) infrastructure. Preliminary insights into construct validity and reliability of CALS showed satisfying results. Third, using the newly developed instrument, a student sample's CAL was assessed, revealing intermediated values. Remarkably, owning a smart speaker did not lead to higher CAL scores, confirming our basic assumption that usage of systems does not guarantee enlightened conceptualizations and competencies. In sum, the paper contributes to the first insights into the operationalization and understanding of CAL as a specific subdomain of AI-related competencies.
C1 [Wienrich, Carolin] Julius Maximilian Univ, Inst Human Comp Media, Human Tech Syst, Wurzburg, Germany.
   [Carolus, Astrid] Julius Maximilians Univ, Media Psychol, Inst Human Comp Media, Wurzburg, Germany.
RP Wienrich, C (corresponding author), Julius Maximilian Univ, Inst Human Comp Media, Human Tech Syst, Wurzburg, Germany.
EM carolin.wienrich@uni-wuerzburg.de
CR Baacke D., 1999, HDB MEDIEN MEDIENKOM, DOI [10.17192/ep2000.2.2792, DOI 10.17192/EP2000.2.2792]
   Baumeister J., 2019, SYSTEMATIC VIEW SPEE, DOI [10.1136/bmjspcare-2019-huknc.228, DOI 10.1136/BMJSPCARE-2019-HUKNC.228]
   Belshaw D.A.J., 2011, THESIS U DURHAM DURH
   Berg MM, 2015, LECT NOTES COMPUT SC, V9103, P144, DOI 10.1007/978-3-319-19581-0_12
   Buhner M., 2011, EINFUHRUNG TEST UND
   Burrell J, 2016, BIG DATA SOC, V3, P1, DOI 10.1177/2053951715622512
   Chetty K, 2018, ECONOMICS-KIEL, V12, DOI 10.5018/economics-ejournal.ja.2018-23
   Cohen J., 1988, STAT POWER ANAL JBR, V2nd, DOI DOI 10.4324/9780203771587
   Covello S., 2010, REV DIGITAL LITERACY, P1
   CRONBACH LJ, 1955, PSYCHOL BULL, V52, P281, DOI 10.1037/h0040957
   Doran D., 2018, CEUR WORKSHOP PROC, V2071
   Eurobarometer, 2017, SPECIAL EUROBAROMETE
   Fast E, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P963
   Field A. P., 2013, DISCOVERING STAT USI, V4th
   Franke T, 2019, INT J HUM-COMPUT INT, V35, P456, DOI 10.1080/10447318.2018.1456150
   Gallardo-Echenique E.E., 2015, MERLOT J ONLINE LEAR, V11, P1
   Goebel R, 2018, LECT NOTES COMPUT SC, V11015, P295, DOI 10.1007/978-3-319-99740-7_21
   Groeben N., 2002, MEDIENKOMPETENZ VORA
   Gunes E, 2018, COMPUT EDUC, V118, P96, DOI 10.1016/j.compedu.2017.11.012
   Hadan H, 2020, LECT NOTES COMPUT SC, V12063, P102, DOI 10.1007/978-3-030-54455-3_8
   Hernandez A., 2021, BEST 7 FREE OPEN SOU
   Howard MC, 2016, INT J HUM-COMPUT INT, V32, P51, DOI 10.1080/10447318.2015.1087664
   Janssen J, 2013, COMPUT EDUC, V68, P473, DOI 10.1016/j.compedu.2013.06.008
   JENKINS H., 2006, CONFRONTING CHALLENG
   KAISER HF, 1974, EDUC PSYCHOL MEAS, V34, P111, DOI 10.1177/001316447403400115
   Kelley PG, 2019, HAPPY ASSURED LIFE W
   Kluwer T, 2011, CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND EFFECTIVE PRACTICES, P1, DOI 10.4018/978-1-60960-617-6.ch001
   Kraus M., 2020, HDB KUNSTLICHEN INTE, P859, DOI [10.1515/9783110659948-020, DOI 10.1515/9783110659948-020]
   Lau Josephine, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274371
   Literat I., 2014, J MEDIA LITERACY ED, V6, P15, DOI DOI 10.23860/JMLE-6-1-2
   Long DR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376727
   Lyons A.C., 2019, FUTURE WORD ED DIGIT
   McTear M., 2016, CONVERSATIONAL INTER, DOI [10.1007/978-3-319-32967-3_17, DOI 10.1007/978-3-319-32967-3_17]
   Meticulous, 2021, NO TIT
   Neyer FJ, 2012, DIAGNOSTICA, V58, P87, DOI 10.1026/0012-1924/a000067
   Ng W, 2012, COMPUT EDUC, V59, P1065, DOI 10.1016/j.compedu.2012.04.016
   Nomura T, 2006, INTERACT STUD, V7, P437, DOI 10.1075/is.7.3.14nom
   Nunnally J. C, 1967, PSYCHOMETRIC THEORY, DOI [10.2307/1161962, DOI 10.2307/1161962]
   Oxbrow N, 1998, ELECTRON LIBR, V16, P359, DOI 10.1108/eb045661
   Perdana R., 2019, INT J ED RES REV, V4, DOI [10.24331/ijere.628309, DOI 10.24331/IJERE.628309]
   Porat E, 2018, COMPUT EDUC, V126, P23, DOI 10.1016/j.compedu.2018.06.030
   Putten A.R-V.D.E.R., 2018, DEV VALIDATION SELF, V7, P1, DOI [10.1145/3139352, DOI 10.1145/3139352]
   Schwarzer R, 1997, APPL PSYCHOL-INT REV, V46, P69, DOI 10.1111/j.1464-0597.1997.tb01096.x
   Shapiro J. J., 1996, EDUCOM Review, V31, P31
   Siegert I, 2014, J MULTIMODAL USER IN, V8, P17, DOI 10.1007/s12193-013-0129-9
   Van Den Brande, 2016, DIGCOMP 20 DIGITAL C
   Wardrip-Fruin N., 2001, DIGITAL HUMANITIES, P1
   Wienrich C., 2021, EXTENDED ARTIFICIAL
   Zeng Eric, 2017, END USER SECURITY PR, P65
NR 50
TC 0
Z9 0
U1 8
U2 11
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2624-9898
J9 FRONT COMP SCI-SWITZ
JI Front. Comput. Sci.-Switz
PD AUG 2
PY 2021
VL 3
AR 685277
DI 10.3389/fcomp.2021.685277
PG 14
WC Computer Science, Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA UD9EU
UT WOS:000687504700001
OA Green Published, gold
DA 2022-08-02
ER

PT C
AU Dingier, T
   Kostakos, V
   Choudhury, A
AF Dingier, Tilman
   Kostakos, Vassilis
   Choudhury, Ashris
GP ACM
TI Biased Bots: Conversational Agents to Overcome Polarization
SO PROCEEDINGS OF THE 2018 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE
   AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2018 ACM INTERNATIONAL
   SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC'18 ADJUNCT)
LA English
DT Proceedings Paper
CT ACM International Joint Conference on Pervasive and Ubiquitous Computing
   / ACM International Symposium on Wearable Computers (UbiComp/ISWC)
CY OCT 08-12, 2018
CL Google, Singapore, SINGAPORE
SP Assoc Comp Machinery, ACM SIGCHI, ACM SIGMOBILE, NOKIA Bell Labs, Intel, Microsoft, NAVER Labs, HUAWEI, Singapore Tourism Board, Singapore Pass Made Possible
HO Google
DE Critical Media; Depolarization; Chatbots; Conversational Agents
AB In today's media landscape, emotionally charged topics including issues related to politics, religion, or gender can lead to the formation of filter bubbles, echo chambers, and subsequently to strong polarization. An effective way to help people break out of their bubble is engaging with other perspectives. When caught in a filter bubble, however, it can be hard to find an opposed conversation partner in one's social surroundings to discuss a particular topic with. Also, such conversations can be socially awkward and are, therefore, rather avoided. In this project, we aim to train different chat-bots to become highly opinionated on specific topics (e.g., pro/against gun laws) and provide the opportunity to discuss political views with a highly biased opponent.
C1 [Dingier, Tilman; Kostakos, Vassilis] Univ Melbourne, Melbourne, Vic, Australia.
   [Choudhury, Ashris] Indian Inst Technol, Kharagpur, W Bengal, India.
RP Dingier, T (corresponding author), Univ Melbourne, Melbourne, Vic, Australia.
EM tilman.dingler@unimelb.edu.au; vassilis.kostakos@unimelb.edu.au;
   ashris@iitkgp.ac.in
RI Kostakos, Vassilis/G-8997-2011
OI Kostakos, Vassilis/0000-0003-2804-6038; Dingler,
   Tilman/0000-0001-6180-7033
FU Samsung GRO [IO170924-04695-01]
FX This work is partially funded by the Samsung GRO Grant number
   IO170924-04695-01.
CR Anderson R., 1994, CONVERSATION JOURNAL
   Billig Michael, 1996, ARGUING THINKING RHE
   Blankenhorn David, 2015, AM INTEREST
   Flaherty DK, 2011, ANN PHARMACOTHER, V45, P1302, DOI 10.1345/aph.1Q318
   Flaxman S, 2016, PUBLIC OPIN QUART, V80, P298, DOI 10.1093/poq/nfw006
   Gillani Nabeel, 2018, ARXIV180301731
   Haller E, 2013, I C CONTR SYS COMP S, P582, DOI 10.1109/CSCS.2013.85
   Klopfenstein LC, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P555, DOI 10.1145/3064663.3064672
   Nguyen TT, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P677, DOI 10.1145/2566486.2568012
   Pariser E., 2011, FILTER BUBBLE NEW PE
   Schudson M, 1997, CRIT STUD MASS COMM, V14, P297, DOI 10.1080/15295039709367020
   Schwind C, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P349
   Zaller John R, 1992, NATURE ORIGINS MASS
NR 13
TC 4
Z9 4
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5966-5
PY 2018
BP 1664
EP 1668
DI 10.1145/3267305.3274189
PG 5
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BM2UN
UT WOS:000461550100296
DA 2022-08-02
ER

PT B
AU Lopez-Cozar, R
   Callejas, Z
   Espejo, G
   Griol, D
AF Lopez-Cozar, Ramon
   Callejas, Zoraida
   Espejo, Gonzalo
   Griol, David
BA PerezMarin, D
   PascualNieto, I
BF PerezMarin, D
   PascualNieto, I
TI Enhancement of Conversational Agents by Means of Multimodal Interaction
SO CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND
   EFFECTIVE PRACTICES
LA English
DT Article; Book Chapter
ID SPOKEN DIALOGUE; LANGUAGE; SYSTEMS
AB The main objective of multimodal conversational agents is to provide a more engaged and participative communication by allowing users to employ more than one input methodologies and providing output channels that are different to exclusively using voice. This chapter presents a detailed study on the benefits, disadvantages, and implications of incorporating multimodal interaction in conversational agents. Initially, it focuses on implementation techniques. Next, it explains the fusion and fission of multimodal information and focuses on the core module of these agents: the dialogue manager. Later on, the chapter addresses architectures, tools to develop some typical components of the agents, and evaluation methodologies. As a case of study, it describes the multimodal conversational agent in which we are working at the moment to provide assistance to professors and students in some of their daily activities in an academic centre, for example, a University's Faculty.
C1 [Lopez-Cozar, Ramon; Callejas, Zoraida] Univ Granada, Fac Comp Sci & Telecommun, Dept Languages & Comp Syst, E-18071 Granada, Spain.
   [Griol, David] Univ Carlos III Madrid, Dept Comp Sci, E-28903 Getafe, Spain.
   [Griol, David] Motorola Inc, Schaumburg, IL 60196 USA.
RP Lopez-Cozar, R (corresponding author), Univ Granada, Fac Comp Sci & Telecommun, Dept Languages & Comp Syst, E-18071 Granada, Spain.
RI Carrion, Zoraida Callejas/C-6851-2012; Callejas, Zoraida/AAX-4634-2020
OI Carrion, Zoraida Callejas/0000-0001-8891-5237; Callejas,
   Zoraida/0000-0001-8891-5237
CR Alaman X., 2001, C INT PERS INT 2001, P72
   Allen J, 1995, NATURAL LANGUAGE UND
   Allen J., 2007, P 22 NAT C ART INT A, P22
   Allen JF, 2001, AI MAG, V22, P27
   Andernach T., 1996, P NLP IND APPL, P41
   [Anonymous], 2007, P NIPS
   BALCI K, 2005, P 7 INT C MULT INT X, P208
   Batliner A, 2003, SPEECH COMMUN, V40, P117, DOI 10.1016/S0167-6393(02)00079-1
   Bernsen N. O., 1998, P 1 INT C LANG RES E, P185
   Bernsen NO, 2002, TEXT SPEECH LANG TEC, V19, P93
   Beveridge M, 2006, J BIOMED INFORM, V39, P482, DOI 10.1016/j.jbi.2005.12.008
   Bird S, 2008, P 3 WORKSH ISS TEACH, P62
   Bohus D., 2007, P HLT NAACL
   Boisen S., 1989, P WORKSH SPEECH NAT, P135
   BOS J, 2003, P 10 C EUR ASS COMP, P71
   Carpenter R., 1992, LOGIC TYPED FEATURES, DOI [10.1017/CBO9780511530098, DOI 10.1017/CBO9780511530098]
   Cassell J., 2000, EMBODIED CONVERSATIO
   Cassell J., 1999, P SIGCHI C HUM FACT, P520, DOI DOI 10.1145/302979.303150
   Catizone R, 2003, P EACL 03 WORKSH DIA, P25
   Cavazza M., 2008, P AAMAS
   CLARK RAJ, 2004, P 5 ISCA WORKSH SPEE, P173
   Cole R, 2003, P IEEE, V91, P1391, DOI 10.1109/JPROC.2003.817143
   COLE RA, 1997, SURVEY STATE ART HUM
   Corradini A, 2008, LECT NOTES ARTIF INT, V5078, P2, DOI 10.1007/978-3-540-69369-7_2
   Cuayahuitl H, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P290
   De Carolis B., 2002, P AAMAS
   Degerstedt L, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P489
   DENOS E, 1999, P EUR C SPEECH TECHN, P1527
   Doherty P., 1998, P 14 EUR C ART INT E, P747
   Dybkjaer L, 2004, SPEECH COMMUN, V43, P33, DOI 10.1016/j.specom.2004.02.001
   Dybkjaer L., 2000, NAT LANG ENG, V6, P243, DOI DOI 10.1017/S1351324900002461
   Ekman Paul, 1978, FACIAL ACTION CODING
   Eliasson K, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1600
   Emele Martin C., 1994, P INT WORKSH SHAR NA
   Fabbrizio G.D., 2004, P INT C SPOK LANG PR, P3065
   Faure C., 1993, P INT C REAL VIRT WO, P171
   Forbes-Riley K, 2011, COMPUT SPEECH LANG, V25, P105, DOI 10.1016/j.csl.2009.12.002
   Fraikin F., 2002, REQUIREMENTS ANAL CA
   Fraser N. M., 1991, Computer Speech and Language, V5, P81, DOI 10.1016/0885-2308(91)90019-M
   GLASS J, 1995, SPEECH COMMUN, V17, P1, DOI 10.1016/0167-6393(95)00008-C
   Goddeau D, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P701, DOI 10.1109/ICSLP.1996.607458
   Graesser AC, 2001, AI MAG, V22, P39
   Griol D., 2006, P INT C SPEECH COMP, P131
   Griol D., 2009, P 9 SIGDIAL WORKSH D, P326
   Griol D, 2008, SPEECH COMMUN, V50, P666, DOI 10.1016/j.specom.2008.04.001
   Huang H, 2008, P 7 INT C AUT AG MUL, P128
   Huang HH, 2007, LECT NOTES ARTIF INT, V4722, P381
   Hubal RC, 2008, COMPUT HUM BEHAV, V24, P1104, DOI 10.1016/j.chb.2007.03.010
   Ibrahim A, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P117, DOI 10.1109/ICMI.2002.1166979
   Ieronutti L, 2007, COMPUT EDUC, V49, P93, DOI 10.1016/j.compedu.2005.06.007
   Jianyi Liu, 2006, 2006 4th IEEE International Conference on Industrial Informatics, P1042
   Johnson L. W., 2008, P 20 NAT C INN APPL, P1632
   Johnston M, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P376
   King M., 1996, EAGEWGPR2
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   Kopp S, 2006, LECT NOTES ARTIF INT, V4133, P205
   Kuppevelt J., 2005, ADV NATURAL MULTIMOD, DOI [10.1007/1-4020-3933-6, DOI 10.1007/1-4020-3933-6]
   Larsson S., 1999, MODEL DIALOGUE MOVES
   Lee A., 2009, P AS PAC SIGN INF PR
   Lee K.-F., 1990, READINGS SPEECH RECO, P600
   LEMON O, 2006, P EACL
   Lemon O, 2006, IEEE W SP LANG TECH, P178, DOI 10.1109/SLT.2006.326774
   Levin E., 1997, EUROSPEECH, V97, P1883
   Li L, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P497, DOI 10.1109/MMSP.2006.285359
   Lopez-Cozar R, 2003, SPEECH COMMUN, V40, P387, DOI 10.1016/S0167-6393(02)00126-7
   Lopez-Cozar R., 2011, J AMBIENT INTELLIGEN
   Maatman RM, 2005, LECT NOTES ARTIF INT, V3661, P25
   Mairesse F, 2009, INT CONF ACOUST SPEE, P4749, DOI 10.1109/ICASSP.2009.4960692
   Malaka R., 2004, P 9 INT C INT US INT, P310
   Malatesta L, 2009, APPL INTELL, V30, P58, DOI 10.1007/s10489-007-0076-9
   Maragoudakis M, 2007, IEEE INTELL SYST, V22, P67, DOI 10.1109/MIS.2007.14
   Mayfield L., 1999, P ACL IALL
   MCTEAR M, 1998, P INT C SPOK LANG PR, P1223
   McTear M. F., 2004, SPOKEN DIALOGUE TECH
   MEZARUIZ IV, 2008, P ICASSP
   Minker W, 1998, SPEECH COMMUN, V25, P223, DOI 10.1016/S0167-6393(98)00038-7
   Mohri M, 1997, COMPUT LINGUIST, V23, P269
   Moran D. R., 1997, IUI97. 1997 International Conference on Intelligent User Interfaces, P61, DOI 10.1145/238218.238290
   Morency L.-P., 2005, P 7 INT C MULTIMODAL, P18, DOI DOI 10.1145/1088463.1088470
   Muller J, 2003, LECT NOTES ARTIF INT, V2821, P633
   Nielsen P. B., 1992, P INT C SPOK LANG PR, P719
   Nigay L., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P98
   NIGAY L, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P172
   Oh A. H., 2000, P 2000 ANLP NAACL WO, V3, P27
   Paek T, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P41
   PANDZIC IS, 2002, P 7 INT C 3D WEB TEC, P27
   Paroubek P., 1999, BLUEPRINT GEN INFRAS
   Patel M., 1991, FACES FACIAL ANIMATI, P33
   Pelachaud C., 2004, P WORKSH BAL PERC AC
   PELLOM B, 2003, P ICASSP
   Pfleger N., 2002, P KONVENS
   Pietquin O, 2006, IEEE T AUDIO SPEECH, V14, P589, DOI 10.1109/TSA.2005.855836
   Potamianos A, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU '03, P192, DOI 10.1109/ASRU.2003.1318427
   Rabiner L., 1993, FUNDAMENTALS SPEECH
   Raux A., 2007, P ASRU
   Reithinger N., 2005, P INTERSPEECH LISB P, P841
   Rosenfeld R, 1995, P ARPA SPOK LANG SYS
   Runge F., 1993, P EUR, P943
   Salber D., 1993, Human-Computer Interaction. Third International Conference, EWHCI '93. Selected Papers, P219
   San Segundo R., 2004, P CURS TECN LING
   Schatzmann J, 2006, KNOWL ENG REV, V21, P97, DOI 10.1017/S0269888906000944
   Schatzmann J, 2009, IEEE T AUDIO SPEECH, V17, P733, DOI 10.1109/TASL.2008.2012071
   Seneff S., 1989, Speech and Natural Language. Proceedings of a Workshop, P168
   Seneff S., 1998, P ICSLP 98, V98, P931
   Seron F., 2006, P 2 INT WORKSH UB CO, P241
   Steininger S, 2002, P 3 INT C LANG RES E
   Stent A., 1999, P 37 ANN M ASS COMP, P183
   Takeuchi A., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P450
   TEKALP MA, 2000, IMAGE COMMUNICATION
   Tian Y., 2003, HDB FACE RECOGNITION
   Tryphonas, 2004, VOICE EXTENSIBLE MAR
   Tsutsui T., 2000, P WORLD C WWW INT WE, P537
   Turunen M., 2004, THESIS U TAMPERE
   Wachsmuth I, 2003, P INT C COMP MISS, P277
   Wahlster W., 2001, P CYB ASS INT S, P33
   Wahlster W., 2006, SMARTKOM FDN MULTIMO, DOI [https://doi.org/10.1007/3-540-36678-4, DOI 10.1007/3-540-36678-4]
   Wahlster Wolfgang, 2003, P HUM COMP INT STAT, P47
   WALKER JH, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P85
   Walker MA, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P515
   Walker MA, 1998, COMPUT SPEECH LANG, V12, P317, DOI 10.1006/csla.1998.0110
   Walker Willie, 2002, FREETTS PERFORMANCE
   Walsh P, 2003, 3RD IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P17, DOI 10.1109/ICALT.2003.1215018
   Ward W., 1994, P ARPA HUM LANG TECH, P213
   Wasinger R., 2003, P EUR, P1049
   Webb N., 2010, P INT C LANG RES EV
   Wei X., 2000, P ANLP NAACL WORKSH, P42
   Williams JD, 2007, COMPUT SPEECH LANG, V21, P393, DOI 10.1016/j.csl.2006.06.008
   WOODLAND P., 2000, HTK BOOK
   Young SJ, 1997, COMPUT SPEECH LANG, V11, P73, DOI 10.1006/csla.1996.0023
   Zapata CM, 2007, DYNA-COLOMBIA, V74, P125
   ZHANG T, 2005, P AAAI WORKSH SPOK L, P60
   Zue V, 2000, IEEE T SPEECH AUDI P, V8, P85, DOI 10.1109/89.817460
   Zukerman I, 2001, USER MODEL USER-ADAP, V11, P129, DOI 10.1023/A:1011174108613
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 138
TC 5
Z9 5
U1 0
U2 9
PU IGI GLOBAL
PI HERSEY
PA 701 E CHOCOLATE AVE, STE 200, HERSEY, PA 17033-1240 USA
BN 978-1-60960-618-3; 978-1-60960-617-6
PY 2011
BP 223
EP 252
DI 10.4018/978-1-60960-617-6.ch010
D2 10.4018/978-1-60960-617-6
PG 30
WC Computer Science, Artificial Intelligence
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BZX29
UT WOS:000303201400011
DA 2022-08-02
ER

PT C
AU Lins, LF
   Melo, G
   Oliveira, T
   Alencar, P
   Cowan, D
AF Lins, Luis Fernando
   Melo, Glaucia
   Oliveira, Toacy
   Alencar, Paulo
   Cowan, Donald
BE Marrella, A
   Weber, B
TI PACAs: Process-Aware Conversational Agents
SO BUSINESS PROCESS MANAGEMENT WORKSHOPS, BPM 2021
SE Lecture Notes in Business Information Processing
LA English
DT Proceedings Paper
CT International Conference on Business Process Management (BPM)
CY SEP 06-10, 2021
CL ELECTR NETWORK
DE Business process; Conversational agent; Workflow; Chatbot; Camunda; Rasa
AB Processes are an essential concept in modern society, promoting the standardization, documentation, and control of complex interactions between businesses, governments, and individuals. Therefore, it is essential to provide approaches and tools that support the participants during the execution of these processes. However, current solutions for process guidance are usually proprietary, difficult to follow, and not effective in supporting these participants in their daily processes. In this paper, we present an approach for building a novel type of conversational agents - which we call PACAs - that can communicate with workflow management systems, using the BPMN standard, to support the execution of a process. We also describe a use case in which a PACA is implemented by using Rasa - a chatbot framework - and Camunda Engine - a workflow management system. We believe that promoting the integration of processes and conversational agents is key to simplifying process execution and, thus, making business processes more widespread and prevalent in the academy and industry.
C1 [Lins, Luis Fernando; Oliveira, Toacy] Univ Fed Rio de Janeiro, Rio De Janeiro, Brazil.
   [Melo, Glaucia; Alencar, Paulo; Cowan, Donald] Univ Waterloo, Comp Syst Grp, Waterloo, ON, Canada.
RP Lins, LF (corresponding author), Univ Fed Rio de Janeiro, Rio De Janeiro, Brazil.
EM luisfernandolins@poli.ufrj.br; gmelo@uwaterloo.ca; toacy@cos.ufrj.br;
   palencar@uwaterloo.ca; dcowan@uwaterloo.ca
RI Oliveira, Toacy/AAG-2789-2019
OI Oliveira, Toacy/0000-0001-8184-2442
CR Cranshaw J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2382, DOI 10.1145/3025453.3025780
   Dijkman R, 2012, COMPUT IND, V63, P91, DOI 10.1016/j.compind.2011.12.003
   Dumas M., 2018, FUNDAMENTALS BUSINES, DOI [10.1007/978-3-662-56509-4, DOI 10.1007/978-3-662-56509-4]
   Gnewuch U., 2017, P 38 INT C INFORM SY
   Helander M.G., 2014, HDB HUMAN COMPUTER I
   Jiangbo Dang, 2008, 2008 International MCETECH Conference on e-Technologies, P25, DOI 10.1109/MCETECH.2008.15
   Polyvyanyy A, 2012, LECT NOTES COMPUT SC, V7481, P335, DOI 10.1007/978-3-642-32885-5_26
   Toxtli C, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173632
NR 8
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1865-1348
EI 1865-1356
BN 978-3-030-94343-1; 978-3-030-94342-4
J9 LECT NOTES BUS INF P
PY 2022
VL 436
BP 312
EP 318
DI 10.1007/978-3-030-94343-1_24
PG 7
WC Business; Computer Science, Artificial Intelligence; Computer Science,
   Information Systems; Computer Science, Theory & Methods; Management;
   Operations Research & Management Science
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Business & Economics; Computer Science; Operations Research & Management
   Science
GA BS6XX
UT WOS:000754564600024
DA 2022-08-02
ER

PT C
AU van Turnhout, K
   Terken, J
   Eggen, B
AF van Turnhout, Koen
   Terken, Jacques
   Eggen, Berry
BE Andre, E
   Dybkjaer, L
   Minker, W
   Neumann, H
   Pieraccini, R
   Weber, M
TI Designing socially aware conversational agents
SO PERCEPTION IN MULTIMODAL DIALOGUE SYSTEMS, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 4th IEEE Tutorial and Research Workshop on Perception and Interactive
   Technologies for Speech-Based Systems
CY JUN 16-18, 2008
CL Kloster Irsee, GERMANY
SP IEEE, IEEE Signal Proc Soc, ACL Sigmedia, ACL/ISCA Sigdial
AB In this paper we address the problem of how to make conversational agents socially aware. State-of-the-art conversational agents cannot deal with multi-user situations where the user-system dialog is interleaved with discussions between users. We describe the development of an algorithm for determining addressee-hood of user utterances. The algorithm makes errors; in determining addressee-hood for individual utterances, classifying utterances intended for the system as utterances intended for the other user and the other way around, creating unexpected situations in the agent's behaviour. This raises the question of how to design the conversational agent so that the users understand why the agent behaves in particular ways. We describe a study aimed at obtaining guidelines for the design of a socially aware conversational agent. We conclude that principles for modelling the behaviour of the agent are to be derived from theories about human communication rather than from theories about human-computer interaction.
C1 [van Turnhout, Koen; Terken, Jacques; Eggen, Berry] Tech Univ Eindhoven, Fac Ind Design, NL-5600 MB Eindhoven, Netherlands.
RP van Turnhout, K (corresponding author), Tech Univ Eindhoven, Fac Ind Design, Postbus 513, NL-5600 MB Eindhoven, Netherlands.
EM k.g.v.turnhout@tue.nl; j.m.b.terken@tue.nl; j.h.eggen@tue.nl
OI Terken, Jacques/0000-0002-6494-3230
CR [Anonymous], 2001, P SIGCHI C HUM FACT, DOI DOI 10.1145/365024.365119
   Argyle Michael, 1977, J ENV PSYCHOL NONVER, V1, P6, DOI [10.1007/BF01115461, DOI 10.1007/BF01115461]
   Bakx I., 2003, P 9 IFIP TC13 INT C, P701
   Cassell J, 1999, SPRING INT SER ENG C, V511, P143
   CLARK HH, 1996, MACHINE CONVERSATION
   Katzenmaier M., 2004, P 6 INT C MULT INT, P144, DOI DOI 10.1145/1027933.1027959
   Nielsen J., 1994, USABILITY INSPECTION, P25, DOI DOI 10.1089/TMJ.2010.0114
   Shneiderman B., 1992, DESIGNING USER INTER
   STURM JA, 2002, C LANG RES EV MAY 29
   Sturm J, 2005, TEXT SPEECH LANG TEC, V28, P329
   Takemae Yoshinao, 2003, P 11 ACM INT C MULT, P303
   Terken J, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P94
   Thorisson KR, 2002, TEXT SPEECH LANG TEC, V19, P173
   van Turnhout Koen, 2005, P 7 INT C MULT INT, P175
   VANTURNHOUT KG, 2007, THESIS TU EINDHOVEN
NR 15
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-540-69368-0
J9 LECT NOTES ARTIF INT
PY 2008
VL 5078
BP 256
EP 267
PG 12
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BHW89
UT WOS:000257111900029
DA 2022-08-02
ER

PT C
AU Mallinar, N
   Shah, A
   Ugrani, R
   Gupta, A
   Gurusankar, M
   Ho, TK
   Liao, QV
   Zhang, YF
   Bellamy, RKE
   Yates, R
   Desmarais, C
   McGregor, B
AF Mallinar, Neil
   Shah, Abhishek
   Ugrani, Rajendra
   Gupta, Ayush
   Gurusankar, Manikandan
   Ho, Tin Kam
   Liao, Q. Vera
   Zhang, Yunfeng
   Bellamy, Rachel K. E.
   Yates, Robert
   Desmarais, Chris
   McGregor, Blake
GP AAAI
TI Bootstrapping Conversational Agents with Weak Supervision
SO THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST
   INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH
   AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
LA English
DT Proceedings Paper
CT 33rd AAAI Conference on Artificial Intelligence / 31st Innovative
   Applications of Artificial Intelligence Conference / 9th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY JAN 27-FEB 01, 2019
CL Honolulu, HI
SP Assoc Advancement Artificial Intelligence
AB Many conversational agents in the market today follow a standard bot development framework which requires training intent classifiers to recognize user input. The need to create a proper set of training examples is often the bottleneck in the development process. In many occasions agent developers have access to historical chat logs that can provide a good quantity as well as coverage of training examples. However, the cost of labeling them with tens to hundreds of intents often prohibits taking full advantage of these chat logs. In this paper, we present a framework called search, label, and propagate (SLP) for bootstrapping intents from existing chat logs using weak supervision. The framework reduces hours to days of labeling effort down to minutes of work by using a search engine to find examples, then relies on a data programming approach to automatically expand the labels. We report on a user study that shows positive user feedback for this new approach to build conversational agents, and demonstrates the effectiveness of using data programming for auto-labeling. While the system is developed for training conversational agents, the framework has broader application in significantly reducing labeling effort for training text classifiers.
C1 [Mallinar, Neil; Shah, Abhishek; Ugrani, Rajendra; Gupta, Ayush; Gurusankar, Manikandan; Ho, Tin Kam; Yates, Robert; Desmarais, Chris; McGregor, Blake] IBM Watson, New York, NY 10003 USA.
   [Liao, Q. Vera; Zhang, Yunfeng; Bellamy, Rachel K. E.] IBM Res AI, Yorktown Hts, NY 10598 USA.
RP Mallinar, N (corresponding author), IBM Watson, New York, NY 10003 USA.
CR [Anonymous], 2010, P 16 ACM SIGKDD, DOI DOI 10.1145/1835804.1835859
   [Anonymous], 2009, IEEE T NEURAL NETW, DOI DOI 10.1109/TNN.2009.2015974
   Bach S. H., 2017, ABS170300854 CORR
   Fujino A., 2005, P 20 NAT C ART INT A, P764
   Goyal Anuj, 2018, ARXIV180501542
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Ratner A, 2017, PROC VLDB ENDOW, V11, P269, DOI 10.14778/3157794.3157797
   Ratner Alexander, 2016, Adv Neural Inf Process Syst, V29, P3567
   Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019
   Settles B., 2012, SYNTH LECT ARTIF INT, DOI [10.2200/s00429ed1v01y201207aim018, DOI 10.2200/S00429ED1V01Y201207AIM018, 10.1007/978-3-031-01560-1]
   Willis J, 2015, ST ANDR STUD REFORM, P1
   Yan Y, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2244
NR 12
TC 1
Z9 1
U1 0
U2 0
PU ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE
PI PALO ALTO
PA 2275 E BAYSHORE RD, STE 160, PALO ALTO, CA 94303 USA
BN 978-1-57735-809-1
PY 2019
BP 9528
EP 9533
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BN6ZH
UT WOS:000486572504012
DA 2022-08-02
ER

PT C
AU Demetriadis, S
   Karakostas, A
   Tsiatsos, T
   Caballe, S
   Dimitriadis, Y
   Weinberger, A
   Papadopoulos, PM
   Palaigeorgiou, G
   Tsimpanis, C
   Hodges, M
AF Demetriadis, Stavros
   Karakostas, Anastasios
   Tsiatsos, Thrasyvoulos
   Caballe, Santi
   Dimitriadis, Yannis
   Weinberger, Armin
   Papadopoulos, Pantelis M.
   Palaigeorgiou, George
   Tsimpanis, Costas
   Hodges, Matthew
BE Barolli, L
   Xhafa, F
   Javaid, N
   Spaho, E
   Kolici, V
TI Towards Integrating Conversational Agents and Learning Analytics in
   MOOCs
SO ADVANCES IN INTERNET, DATA & WEB TECHNOLOGIES
SE Lecture Notes on Data Engineering and Communications Technologies
LA English
DT Proceedings Paper
CT 6th International Conference on Emerging Internet, Data and Web
   Technologies (EIDWT)
CY MAR 15-17, 2018
CL Polytechn Univ Tirana, Tirana, ALBANIA
HO Polytechn Univ Tirana
AB Higher Education Massive Open Online Courses (MOOCs) introduce a way of transcending formal higher education by realizing technology-enhanced formats of learning and instruction and by granting access to an audience way beyond students enrolled in any one Higher Education Institution. However, although MOOCs have been reported as an efficient and important educational tool, there is a number of issues and problems related to their educational impact. More specifically, there is an important number of drop outs during a course, little participation, and lack of students' motivation and engagement overall. This may be due to one-size-fits-all instructional approaches and very limited commitment to student-student and teacher-student collaboration. This paper introduces the development agenda of a newly started European project called "colMOOC" that aims to enhance the MOOCs experience by integrating collaborative settings based on Conversational Agents and screening methods based on Learning Analytics, to support both students and teachers during a MOOC course. Conversational pedagogical agents guide and support student dialogue using natural language both in individual and collaborative settings. Integrating this type of conversational agents into MOOCs to trigger peer interaction in discussion groups can considerably increase the engagement and the commitment of online students and, consequently, reduce MOOCs dropout rate. Moreover, Learning Analytics techniques can support teachers' orchestration and students' learning during MOOCs by evaluating students' interaction and participation. The research reported in this paper is currently undertaken within the research project colMOOC funded by the European Commission.
C1 [Demetriadis, Stavros; Tsiatsos, Thrasyvoulos] Aristotle Univ Thessaloniki, Thessaloniki, Greece.
   [Karakostas, Anastasios] Ctr Res & Technol Hellas, Thermi, Greece.
   [Caballe, Santi] Univ Oberta Catalunya, Barcelona, Spain.
   [Dimitriadis, Yannis] Univ Valladolid, Valladolid, Spain.
   [Weinberger, Armin] Univ Saarland, Saarbrucken, Germany.
   [Papadopoulos, Pantelis M.] Aarhus Univ, Aarhus, Denmark.
   [Palaigeorgiou, George] Learnworlds, London, England.
   [Tsimpanis, Costas] Greek Univ Network, Athens, Greece.
   [Hodges, Matthew] Telefonica, Madrid, Spain.
RP Caballe, S (corresponding author), Univ Oberta Catalunya, Barcelona, Spain.
EM scaballe@uoc.edu
RI Demetriadis, Stavros/Z-3200-2019; Tsiatsos, Thrasyvoulos/W-5386-2019;
   Dimitriadis, Yannis/K-6846-2014
OI Demetriadis, Stavros/0000-0002-1561-6372; Tsiatsos,
   Thrasyvoulos/0000-0002-4946-9585; Dimitriadis,
   Yannis/0000-0001-7275-2242; Papadopoulos, Pantelis/0000-0002-1527-5483;
   Karakostas, Anastasios/0000-0002-8508-3903
FU European Commission [588438-EPP-1-2017-1-EL-EPPKA2-KA]
FX This research was funded by the European Commission through the project
   "colMOOC: Integrating Conversational Agents and Learning Analytics in
   MOOCs" (588438-EPP-1-2017-1-EL-EPPKA2-KA).
CR Barak M, 2016, COMPUT EDUC, V94, P49, DOI 10.1016/j.compedu.2015.11.010
   Bassi R, 2014, 2014 INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKING AND COLLABORATIVE SYSTEMS (INCOS), P184, DOI 10.1109/INCoS.2014.15
   Capuano N, 2016, INT J EMERG TECHNOL, V11, P24, DOI 10.3991/ijet.v11i07.5878
   Capuano N, 2015, 2015 10TH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND INTERNET COMPUTING (3PGCIC), P64, DOI 10.1109/3PGCIC.2015.7
   Daradoumis T, 2013, 2013 EIGHTH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND INTERNET COMPUTING (3PGCIC 2013), P208, DOI 10.1109/3PGCIC.2013.37
   Ganan D, 2017, INT J WEB INF SYST, V13, P25, DOI 10.1108/IJWIS-12-2016-0074
   Karakostas A, 2014, EDUC TECHNOL SOC, V17, P206
   Kumar R, 2011, IEEE T LEARN TECHNOL, V4, P21, DOI 10.1109/TLT.2010.41
   Lankshear C, 2008, DIGITAL LITERACIES C
   Michaels S., 2010, ACCOUNTABLE TALK SOU
   Miguel Jorge, 2013, 2013 5th International Conference on Intelligent Networking and Collaborative Systems, P289, DOI 10.1109/INCoS.2013.52
   Noroozi O, 2013, COMPUT EDUC, V61, P59, DOI 10.1016/j.compedu.2012.08.013
   Schuwer R, 2015, INT REV RES OPEN DIS, V16, P20
   Siemens G., 2013, OPEN ED RESOURCES IN, P5
   Tegos S, 2017, EDUC TECHNOL SOC, V20, P99
   Tegos S, 2015, COMPUT EDUC, V87, P309, DOI 10.1016/j.compedu.2015.07.014
   Tegos S, 2014, 2014 INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKING AND COLLABORATIVE SYSTEMS (INCOS), P176, DOI 10.1109/INCoS.2014.66
   Tegos S, 2014, INT J ARTIF INTELL E, V24, P62, DOI 10.1007/s40593-013-0007-3
NR 18
TC 13
Z9 13
U1 0
U2 10
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2367-4512
BN 978-3-319-75928-9; 978-3-319-75927-2
J9 LECT NOTE DATA ENG
PY 2018
VL 17
BP 1061
EP 1072
DI 10.1007/978-3-319-75928-9_98
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA BL6AH
UT WOS:000453042300098
DA 2022-08-02
ER

PT J
AU Laranjo, L
   Dunn, AG
   Tong, HL
   Kocaballi, AB
   Chen, J
   Bashir, R
   Surian, D
   Gallego, B
   Magrabi, F
   Lau, AYS
   Coiera, E
AF Laranjo, Liliana
   Dunn, Adam G.
   Tong, Huong Ly
   Kocaballi, Ahmet Baki
   Chen, Jessica
   Bashir, Rabia
   Surian, Didi
   Gallego, Blanca
   Magrabi, Farah
   Lau, Annie Y. S.
   Coiera, Enrico
TI Conversational agents in healthcare: a systematic review
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
LA English
DT Review
DE artificial intelligence [Mesh]; medical informatics [Mesh];
   conversational agent; dialogue system
ID SPOKEN DIALOGUE; UNINTENDED CONSEQUENCES; VIRTUAL HUMAN; INTERVENTIONS;
   RECOGNITION; TECHNOLOGY; LANGUAGE; QUALITY
AB Objective: Our objective was to review the characteristics, current applications, and evaluation measures of conversational agents with unconstrained natural language input capabilities used for health-related purposes.
   Methods: We searched PubMed, Embase, CINAHL, PsycInfo, and ACM Digital using a predefined search strategy. Studies were included if they focused on consumers or healthcare professionals; involved a conversational agent using any unconstrained natural language input; and reported evaluation measures resulting from user interaction with the system. Studies were screened by independent reviewers and Cohen's kappa measured inter-coder agreement.
   Results: The database search retrieved 1513 citations; 17 articles (14 different conversational agents) met the inclusion criteria. Dialogue management strategies were mostly finite-state and frame-based (6 and 7 conversational agents, respectively); agent-based strategies were present in one type of system. Two studies were randomized controlled trials (RCTs), 1 was cross-sectional, and the remaining were quasi-experimental. Half of the conversational agents supported consumers with health tasks such as self-care. The only RCT evaluating the efficacy of a conversational agent found a significant effect in reducing depression symptoms (effect size d 1/4 0.44, p 1/4 .04). Patient safety was rarely evaluated in the included studies.
   Conclusions: The use of conversational agents with unconstrained natural language input capabilities for health-related purposes is an emerging field of research, where the few published studies were mainly quasiexperimental, and rarely evaluated efficacy or safety. Future studies would benefit from more robust experimental designs and standardized reporting.
C1 [Laranjo, Liliana; Dunn, Adam G.; Tong, Huong Ly; Kocaballi, Ahmet Baki; Chen, Jessica; Bashir, Rabia; Surian, Didi; Gallego, Blanca; Magrabi, Farah; Lau, Annie Y. S.; Coiera, Enrico] Macquarie Univ, Australian Inst Hlth Innovat, Ctr Hlth Informat, Level 6,75 Talavera Rd, Sydney, NSW 2113, Australia.
RP Laranjo, L (corresponding author), Macquarie Univ, Australian Inst Hlth Innovat, Ctr Hlth Informat, Level 6,75 Talavera Rd, Sydney, NSW 2113, Australia.
EM liliana.laranjo@mq.edu.au
RI Bashir, Rabia/Q-3225-2019; Surian, Didi/M-3244-2019; Kocaballi,
   Baki/R-3136-2019; Laranjo, Liliana/D-5356-2017; Dunn, Adam/E-6828-2011
OI Bashir, Rabia/0000-0002-9613-8957; Surian, Didi/0000-0003-2299-2971;
   Kocaballi, Baki/0000-0002-8328-5317; Laranjo,
   Liliana/0000-0003-1020-3402; Lau, Annie Y.S./0000-0002-3028-4222; Dunn,
   Adam/0000-0002-1720-8209; Tong, Huong Ly/0000-0002-8462-0105; Coiera,
   Enrico/0000-0002-6444-6584
FU National Health and Medical Research Council (NHMRC) [APP1134919]; 
   [APP1054146]
FX This research was supported by the National Health and Medical Research
   Council (NHMRC) grant APP1134919 (Centre for Research Excellence in
   Digital Health) and Program Grant APP1054146.
CR Ash JS, 2004, J AM MED INFORM ASSN, V11, P104, DOI 10.1197/jamia.M1471
   Azzini Ivano, 2003, Stud Health Technol Inform, V95, P146
   Bernsen NO, 2007, TEXT SPEECH LANG TEC, V37, P187
   Beveridge M, 2006, J BIOMED INFORM, V39, P482, DOI 10.1016/j.jbi.2005.12.008
   Bickmore T, 2006, J BIOMED INFORM, V39, P556, DOI 10.1016/j.jbi.2005.12.004
   Bickmore TW, 2013, J AM GERIATR SOC, V61, P1676, DOI 10.1111/jgs.12449
   Bickmore TW, 2013, PATIENT EDUC COUNS, V92, P142, DOI 10.1016/j.pec.2013.05.011
   Black LA, 2005, COMP MED SY, P506, DOI 10.1109/CBMS.2005.33
   Bossuyt PM, 2015, BMJ-BRIT MED J, V351, DOI [10.1148/radiol.2015151516, 10.1136/bmj.h5527, 10.1373/clinchem.2015.246280]
   Cabitza F, 2017, JAMA-J AM MED ASSOC, V318, P517, DOI 10.1001/jama.2017.7797
   Chu-Carroll J, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P262
   Coiera E, 2016, Yearb Med Inform, P163
   Coiera E, 2017, BMJ OPIN
   Coiera E, 2018, J AM MED INFORM ASSN, P1
   Crawford K, 2016, NATURE, V538, P311, DOI 10.1038/538311a
   Crutzen R, 2011, J ADOLESCENT HEALTH, V48, P514, DOI 10.1016/j.jadohealth.2010.09.002
   Des Jarlais DC, 2004, AM J PUBLIC HEALTH, V94, P361, DOI 10.2105/AJPH.94.3.361
   DONABEDIAN A, 1966, MILBANK FUND Q, V44, P166, DOI 10.2307/3348969
   Edwards RA, 2013, MATERN CHILD HLTH J, V17, P1961, DOI 10.1007/s10995-013-1222-0
   Eysenbach G, 2011, J MED INTERNET RES, V13, DOI 10.2196/jmir.1923
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Giorgino T, 2005, INT J MED INFORM, V74, P159, DOI 10.1016/j.ijmedinf.2004.04.026
   Griol D, 2013, APPL ARTIF INTELL, V27, P759, DOI 10.1080/08839514.2013.835230
   Harper R, 2008, FIFTEENTH IEEE INTERNATIONAL CONFERENCE AND WORKSHOPS ON THE ENGINEERING OF COMPUTER-BASED SYSTEMS, PROCEEDINGS, P219, DOI 10.1109/ECBS.2008.31
   Hartling L., 2013, ASSESSING RISK BIAS
   Higgins JT., 2008, ASSESSING RISK BIAS, P187, DOI DOI 10.1002/9780470712184
   Hodgson T, 2017, J AM MED INFORM ASSN, V24, P1127, DOI 10.1093/jamia/ocx073
   Hoffmann TC, 2014, BMJ-BRIT MED J, V348, DOI [10.1136/bmj.g1687, 10.1055/s-0041-111066]
   Hudlicka E, 2013, PATIENT EDUC COUNS, V92, P160, DOI 10.1016/j.pec.2013.05.007
   Ireland D, 2016, STUD HEALTH TECHNOL, V227, P55, DOI 10.3233/978-1-61499-666-8-55
   Juang BH, 2000, P IEEE, V88, P1142, DOI 10.1109/5.880077
   Kim MO, 2016, J AM MED INFORM ASSN, V24
   Lamel L, 2000, 6 INT C SPOK LANG PR
   Levin E, 2006, J MED INTERNET RES, V8, DOI 10.2196/jmir.8.4.e30
   Liberati A, 2009, ANN INTERN MED, V151, pW65, DOI [10.1371/journal.pmed.1000100, 10.7326/0003-4819-151-4-200908180-00136, 10.1136/bmj.b2700]
   Lopez-Cozar R, 2011, CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND EFFECTIVE PRACTICES, P223, DOI 10.4018/978-1-60960-617-6.ch010
   Lucas GM, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00051
   Mallios S., 2016, 2016 JUL PRESENTED 2, P1, DOI [10.1109/IISA.2016.7785371, DOI 10.1109/IISA.2016.7785371]
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   McTear MF, 2002, ACM COMPUT SURV, V34, P90, DOI 10.1145/505282.505285
   Miner AS, 2016, JAMA INTERN MED, V176, P619, DOI 10.1001/jamainternmed.2016.0400
   Moher D, 2009, PLOS MED, V6, DOI 10.1371/journal.pmed.1000097
   Nishida A, 2014, INT ICE CONF ENG
   Parasuraman R, 2000, IEEE T SYST MAN CY A, V30, P286, DOI 10.1109/3468.844354
   Philip P, 2017, SCI REP-UK, V7, DOI 10.1038/srep42656
   Philip P, 2015, PRESENCE-TELEOP VIRT, V23, P369, DOI 10.1162/PRES_a_00197
   POSADZKI P, 2016, COCHRANE DB SYST REV, V12, DOI DOI 10.1002/14651858.CD009921.PUB2
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Radziwill N, 2017, ARXIV1704
   Rhee H, 2014, PATIENT PREFER ADHER, V8, P63, DOI 10.2147/PPA.S53504
   Serban I.V., 2015, ARXIV151205742
   Stone P, 2016, ARTIF INTELL
   Streiner D. L., 2008, HLTH MEASUREMENT SCA
   Tanaka H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182151
   Walker MA, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P271
   Watson A, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.1629
   Weiss B., 2015, COMPUTATIONAL COMPUT, V1, P1
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wolters MK, 2016, HEALTH INFORM J, V22, P854, DOI 10.1177/1460458215593329
   Young S, 2013, P IEEE, V101, P1160, DOI 10.1109/JPROC.2012.2225812
NR 60
TC 250
Z9 251
U1 23
U2 85
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1067-5027
EI 1527-974X
J9 J AM MED INFORM ASSN
JI J. Am. Med. Inf. Assoc.
PD SEP
PY 2018
VL 25
IS 9
BP 1248
EP 1258
DI 10.1093/jamia/ocy072
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Health Care Sciences & Services;
   Information Science & Library Science; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Health Care Sciences & Services; Information Science &
   Library Science; Medical Informatics
GA GS3SS
UT WOS:000443542400020
PM 30010941
OA Green Published, hybrid
DA 2022-08-02
ER

PT C
AU Ventura, J
   Ventura, M
   Olabe, JC
AF Ventura, J
   Ventura, M
   Olabe, JC
BE Levy, Y
TI Embodied conversational agents: Developing usable agents
SO PROCEEDINGS OF THE IEEE SOUTHEASTCON 2004: EXCELLENCE IN ENGINEERING,
   SCIENCE, AND TECHNOLOGY
LA English
DT Proceedings Paper
CT IEEE SoutheastCon 2005
CY APR 08-10, 2005
CL Ft Lauderdale, FL
SP IEEE, Reg 3, IEEE Broward Sect, Nova SE Univ
AB Improvements in computer hardware and software have governed the design of embodied conversational agents, and there has been little empirical research related to the development of full-body agents that exhibit visual and auditory properties to convey instructional information in engineering programs. The purpose of this study is to utilize recently developed software to formulate agents specifically developed to function in a knowledge-based learning environment and provide non-verbal expressions through gaze, gesture, and locomotion.
   Embodied conversational agents are computer-generated images with lifelike facial features and body movements, capable of performing a collaborating role as instructors. Agents generally resemble human-like forms with auditory qualities that range from human to cartoon. This study focuses on the development of agents that are functional in a variety of educational environments and learning domains.
C1 Christian Bros Univ, Dept Elect & Comp Engn, Memphis, TN USA.
RP Ventura, J (corresponding author), Christian Bros Univ, Dept Elect & Comp Engn, Memphis, TN USA.
EM jventura@cbu.edu; mventura@memphis.edu; jolabe@cbu.edu
CR ANDERSON LW, 2001, TAXONOMY LEARNING AS
   ANDRE E, 2000, P 5 INT C INT US INT
   Atkinson RK, 2002, J EDUC PSYCHOL, V94, P416, DOI 10.1037//0022-0663.94.2.416
   BARTNECK C, 2003, P 2003 INT C DES PLE
   Cassell J., 2000, P 5 INT C INT US INT, P52, DOI [10.1145/325737.325781, DOI 10.1145/325737.325781]
   Cassell J., 2001, P 41 ANN M ASS COMP
   Clarebout G., 2002, Journal of Educational Multimedia and Hypermedia, V11, P267
   Craig SD, 2002, J EDUC PSYCHOL, V94, P428, DOI 10.1037//0022-0663.94.2.428
   FROKJAER E, 2002, C HUM FACT COMP SYST
   GRAESSER AC, 2003, 25 ANN M CONG SCI SO
   Johnson WL, 2000, INT J ARTIFICIAL INT, V11, P47
   JOHNSON WL, 2003, P 2003 INT C INT US
   McBreen HM, 2001, IEEE T SYST MAN CY A, V31, P394, DOI 10.1109/3468.952714
   MCBREEN HM, 2001, P WORKSH MULT COMM C
   MORENO R, 2001, ERIC, P1
   Preece J., 2002, INTERACTION DESIGN H
   RIST T, 2003, P 2003 INT C INT US
   Shneiderman B, 1998, DESIGNING USER INTER
   VENTURA J, 2004, P IEEE SE CON 2004 G
   YOON SY, 2000, P 5 INT C AUT AG BAR
   2003, VOX PROXY
NR 21
TC 1
Z9 1
U1 0
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 0-7803-8865-8
PY 2005
BP 663
EP 669
DI 10.1109/SECON.2005.1423322
PG 7
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BCE86
UT WOS:000228954600107
DA 2022-08-02
ER

PT C
AU Hahaianu, F
   Manasia, L
AF Hahaianu, Florentina
   Manasia, Loredana
BE Roceanu, I
   Stanescu, I
   Barbieru, D
TI LEARNING ARCHITECTURE TO SUPPORT THE DEVELOPMENT OF SOCIO-EMOTIONAL
   INTELLIGENCE IN A COLLABORATIVE LEARNING ENVIRONMENT THROUGH THE USE OF
   CONVERSATIONAL AGENTS
SO QUALITY AND EFFICIENCY IN E-LEARNING, VOL 2
SE eLearning and Software for Education
LA English
DT Proceedings Paper
CT 9th International Conference eLearning and Software for Education
CY APR 25-26, 2013
CL Bucharest, ROMANIA
SP Games & Learn Alliance, intuitext Grup SOFTWIN, ASCENDIA DESIGN, SAP, INSOFT Dev & Consult, MAGUAY, Adv Technol Syst, PLAGIAT
DE socio-emotional intelligence; collaborative learning environments;
   conversational agents
AB Achieving goals in everyday life is also related to emotional intelligence. If traditional education brings us the practice of training of regular intelligence, we assume that digital communities of learning could better focus on socio-emotional intelligence. However, experts in the field of educational sciences postulate an evolution from the century of individual to the county of community. Our approach is to build learning environments where participants can socially interact, build and manage declarative and procedural knowledge, but also develop their competencies in socio-emotional intelligence field by interacting with a Conversational Agent (CA).
   Learning architectures that propose one-to-one interaction (Learner (L) - Agent Systems) to learn foreign languages solve complex problems or situations have been shown to he effective. Researchers can identify substantial learning gains associated with the involvement of conversational agents. Our work aims to enrich the learning architecture proposed by E. Wenger in social learning theory with the presence and pedagogical roles of a Conversational Agent. In the context of this learning architecture, participants in the learning community become and act as learning agencies. Learner agency is feasible in educational settings, both formal and informal. This paper assumes that the size effect of the immersion of a conversational agent is augmented by the context of a collaborative multi-users digital environment. Additionally, we describe specific roles of the conversational agents derived from the core structure of the socio-emotional intelligence: self-awareness, self regulation, motivation, empathy, and social skills in order to illustrate the desirable properties of this new architecture.
C1 [Hahaianu, Florentina] Natl Intelligence Acad Mihai Viteazul, Bucharest, Romania.
EM flori.hahaianu@gmail.com; loredanamanasia@yahoo.com
RI MANASIA, Loredana/F-6330-2016
OI MANASIA, Loredana/0000-0002-1628-8171
CR [Anonymous], 2009, BUILDING INTELLIGENT
   Bandura A, 2006, PERSPECT PSYCHOL SCI, V1, P164, DOI 10.1111/j.1745-6916.2006.00011.x
   CASSEL J, 2000, EMBODIED CONVERSATIO
   Gardner H., 1993, FRAMES MIND THEORY M
   Goleman D., 2007, INTELIGENTA SOCIALA
   Goleman D., 2008, INTELIGENTA EMOTIONA
   Kim Y, 2006, ETR&D-EDUC TECH RES, V54, P569, DOI 10.1007/s11423-006-0637-3
   Mayer J, 1997, EMOTIONAL DEV EMOTIO
   Mayer J. D., 1990, IMAGINATION COGNITIO, V9, P185
   McLoughlin C., 2008, EM TECHN C U WOLL
   Neacsu I., 2010, INTRO PSIHOLOGIA EDU
   ROCO M, 2001, CREATIVITATE INTELIG
   Wenger E., 2002, COMMUNITIES PRACTICE
   Wenger E.C., 1998, COMMUNITIES PRACTICE
NR 14
TC 1
Z9 1
U1 0
U2 8
PU CAROL I NATL DEFENCE UNIV PUBLISHING HOUSE
PI BUCHAREST
PA PANDURI ST, 68-72, BUCHAREST, 00000, ROMANIA
SN 2066-026X
J9 ELEARN SOFTW EDUC
PY 2013
BP 392
EP 397
PG 6
WC Education & Educational Research
WE Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Education & Educational Research
GA BJG73
UT WOS:000328100100063
DA 2022-08-02
ER

PT J
AU Hubal, RC
   Fishbein, DH
   Sheppard, MS
   Paschall, MJ
   Eldreth, DL
   Hyde, CT
AF Hubal, Robert C.
   Fishbein, Diana H.
   Sheppard, Monica S.
   Paschall, Mallie J.
   Eldreth, Diana L.
   Hyde, Christopher T.
TI How do varied populations interact with embodied conversational agents?
   Findings from inner-city adolescents and prisoners
SO COMPUTERS IN HUMAN BEHAVIOR
LA English
DT Article
DE embodied conversational agents; adolescent participants; prison inmates;
   user acceptance
ID SUBSTANCE USE DISORDER; VIRTUAL-REALITY; PSYCHOMETRIC PROPERTIES;
   COGNITIVE MEDIATORS; AGGRESSIVE-BEHAVIOR; COMPETENCE; VIOLENCE;
   REHABILITATION; OFFENDERS; CHARACTER
AB Two studies were conducted to identify individual characteristics that predict behavioral responses to violence prevention interventions. These studies used embodied conversational agents (ECAs) to create hypothetical social situations (called virtual vignettes) to assess interpersonal competency skills. One study was of male inner-city African-American adolescents, and the second was of male prisoners in a state correctional system. In pre- and post-intervention sessions, participants interacted with an ECA that tried to entice them into making risky decisions. The virtual vignette sessions tested participants' negotiation and conflict resolution skills. Results showed differing tendencies for participants to be engaged by the virtual vignettes. The vignettes were sufficiently realistic to elicit differences in behavior among the adolescents, but generally not for the prisoners. Prior acceptance, accessibility, and usability data suggest that most users readily accept ECAs as valid conversational partners. The evidence presented here suggests that the technology - or the setting in which the technology is used is not by itself sufficient to actively engage users. The usefulness of virtual vignettes to adequately predict future behavior may be at least partially influenced by participant characteristics. (c) 2007 Elsevier Ltd. All rights reserved.
C1 [Hubal, Robert C.] RTI Int, Ctr Distributed Learning, Res Triangle Pk, NC 27709 USA.
   [Fishbein, Diana H.; Sheppard, Monica S.; Eldreth, Diana L.] RTI Int, Transdisciplinary Behav Sci Program, Baltimore, MD USA.
   [Hyde, Christopher T.] BioAssessments Inc, Elkton, MD USA.
RP Hubal, RC (corresponding author), RTI Int, Ctr Distributed Learning, 3040 Cornwallis Rd, Res Triangle Pk, NC 27709 USA.
EM rhubai@rti.org
OI fishbein, diana/0000-0003-1644-2762; Hubal, Robert/0000-0003-2637-0918
FU NIDA NIH HHS [R01 DA014813-02, R01 DA014813] Funding Source: Medline;
   NATIONAL INSTITUTE ON DRUG ABUSE [R01DA014813] Funding Source: NIH
   RePORTER
CR Aharonovich E, 2003, DRUG ALCOHOL DEPEN, V71, P207, DOI 10.1016/S0376-8716(03)00092-9
   Andre E, 1999, APPL ARTIF INTELL, V13, P415, DOI 10.1080/088395199117333
   [Anonymous], 2003, KUNSTLICHE INTELLIGE, DOI DOI 10.1002/J.2162-6057.20041B01234.X
   [Anonymous], 1988, COGNITIVE STRUCTURE, DOI DOI 10.1017/CBO9780511571299
   AYLETT R, 2001, 20 WORKSH UK PLANN S
   BARTNECK C, 2002, WORKSH VIRT CONV CHA
   BATES J, 1994, COMMUN ACM, V37, P122, DOI 10.1145/176789.176803
   Bickmore T., 2000, P AAAI FALL S SOC IN
   Bosworth K, 2000, AM J HEALTH BEHAV, V24, P268, DOI 10.5993/AJHB.24.4.3
   BOTVIN GJ, 1995, JAMA-J AM MED ASSOC, V273, P1106, DOI 10.1001/jama.273.14.1106
   CAMBURN DP, 1999, P INT C SURV NONR PO
   Cassell J., 2000, P 5 INT C INT US INT, P52, DOI [10.1145/325737.325781, DOI 10.1145/325737.325781]
   CERRATO L, 2002, P AAMAS02 WORKSH BOL
   CHO H, 2000, P ANN M AM PUBL HLTH
   CHRISTOPH N, 2004, EVALUATING ECAS
   Conati C, 2002, APPL ARTIF INTELL, V16, P555, DOI 10.1080/08839510290030390
   Cowell AJ, 2005, INT J HUM-COMPUT ST, V62, P281, DOI 10.1016/j.ijhcs.2004.11.008
   DAHLBACK N, 1993, KNOWL-BASED SYST, V6, P258, DOI 10.1016/0950-7051(93)90017-N
   Dawes MA, 2000, DRUG ALCOHOL DEPEN, V61, P3, DOI 10.1016/S0376-8716(00)00120-4
   DETERDING R, 2005, MAGICAL NEXT BECOMES
   ELLIOTT C, 1993, P 13 INT JOINT C ART, P194
   Fishbein D, 2000, CRIM JUSTICE BEHAV, V27, P139, DOI 10.1177/0093854800027002001
   FISHBEIN D, 2006, UNPUB NEUROPSYCHOLOG
   Fishbein DH, 2006, DRUG ALCOHOL DEPEN, V82, P47, DOI 10.1016/j.drugalcdep.2005.08.008
   FRANK G, 2002, P INT TRAIN SIM ED C
   Frankfort-Nachmias C., 2000, SOCIAL STAT DIVERSE, VSecond
   Funge J, 1999, COMP GRAPH, P29
   Giancola PR, 1996, ALCOHOL CLIN EXP RES, V20, P740, DOI 10.1111/j.1530-0277.1996.tb01680.x
   Giancola PR, 1998, J STUD ALCOHOL, V59, P560, DOI 10.15288/jsa.1998.59.560
   GODEREAUX C, 1996, HUMANKYBERNETIK, V37, P39
   Gottfredson Denise C, 2003, Prev Sci, V4, P27, DOI 10.1023/A:1021782710278
   Gratch J, 2005, APPL ARTIF INTELL, V19, P215, DOI 10.1080/08839510590910156
   GUERRA NG, 1990, DEV PSYCHOL, V26, P269, DOI 10.1037/0012-1649.26.2.269
   Guinn C., 2003, P WORKSH ASS AD US A
   GUINN C, 2004, P INT C MULT INT NEW
   GUINN CI, 1998, MODERN SIMULATION TR, V6, P44
   HAMMOND R, 1991, J HEALTH CARE POOR U, V2, P359
   HAYESROTH B, 2004, ANN REV CYBERTHERAPY, P85
   Hermann D., 1996, RETRAINING COGNITION
   Hill CD, 1996, J FORENSIC SCI, V41, P56
   Holbrook MI, 1997, PSYCHOL REP, V81, P623
   HUBAL RC, 2001, P INT TRAIN SYST ED
   HUBAL RC, 2003, P INT US INT C MIAM
   Hubal RC, 2006, J BIOMED INFORM, V39, P532, DOI 10.1016/j.jbi.2005.12.006
   ISBISTER K, 2002, P JOINT C AUT AG MUL
   Jessor R., 1998, NEW PERSPECTIVES ADO
   JOHNSEN K, 2005, P IEEE VIRT REAL C B
   Kellam SG, 1998, DEV PSYCHOPATHOL, V10, P165, DOI 10.1017/S0954579498001564
   Kim Y, 2006, ETR&D-EDUC TECH RES, V54, P223, DOI 10.1007/s11423-006-8805-z
   Kizakevich PN, 2003, STUD HEALTH TECHNOL, V94, P165
   KIZAKEVICH PN, 1993, BIOL PSYCHOL, V36, P51, DOI 10.1016/0301-0511(93)90080-R
   Kizakevich PN, 1998, ST HEAL T, V50, P309
   Klinger E, 2005, CYBERPSYCHOL BEHAV, V8, P76, DOI 10.1089/cpb.2005.8.76
   Koda Tomoko, 1996, 5 IEEE INT WORKSH RO
   Lester J. C., 1997, P ACM SIGCHI C HUM F, P359, DOI DOI 10.1145/258549.258797
   Link MW, 2006, COMPUT HUM BEHAV, V22, P412, DOI 10.1016/j.chb.2004.09.008
   Louwerse MM, 2005, APPL COGNITIVE PSYCH, V19, P693, DOI 10.1002/acp.1117
   Lutzker J., 1998, HDB CHILD ABUSE RES, P319, DOI 10.1007/978-1-4757-2909-2_13
   MAGNENATTHALMAN.N, 2000, P 17 20 WORKSH LANG, P1
   Manchester D, 1997, BRAIN INJURY, V11, P605, DOI 10.1080/026990597123296
   MARGALIT M, 1989, J LEARN DISABIL, V22, P41, DOI 10.1177/002221948902200108
   MCCOLLUM C, 2004, P INT TRAIN SIM ED C
   Moreno R, 2001, COGNITION INSTRUCT, V19, P177, DOI 10.1207/S1532690XCI1902_02
   Moundridou M, 2002, J COMPUT ASSIST LEAR, V18, P253, DOI 10.1046/j.0266-4909.2001.00237.x
   Nicholaichuk T, 2000, Sex Abuse, V12, P139, DOI 10.1023/A:1009542208305
   NORLING E, 2004, AAMAS, P758
   OLSEN DE, 2001, P OFF NAT DRUG CONTR
   Paschall MJ, 2005, HEALTH EDUC RES, V20, P61, DOI 10.1093/her/cyg103
   Paschall MJ, 1997, HEALTH EDUC RES, V12, P117, DOI 10.1093/her/12.1.117
   Paschall MJ, 1998, J CONSULT CLIN PSYCH, V66, P825, DOI 10.1037/0022-006X.66.5.825
   PASCHALL MJ, 2001, REV J, V6, P1
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Prendinger H., 2001, Proceedings of the Fifth International Conference on Autonomous Agents, P270, DOI 10.1145/375735.376307
   Raine A, 1993, PSYCHOPATHOLOGY CRIM, DOI DOI 10.1016/B978-0-08-057148-5.50005-8
   RAYBOURN E, 2005, P INT TRAIN SIM ED C
   REISS AJ, 1994, UNDERSTANDING PREVEN, V2
   RICE MF, 1997, AM PSYCHOL       APR, P418
   Rickel J, 1999, APPL ARTIF INTELL, V13, P343, DOI 10.1080/088395199117315
   Rogers RD, 1999, J NEUROSCI, V19, P9029, DOI 10.1523/JNEUROSCI.19-20-09029.1999
   Rogers RD, 2001, CURR OPIN NEUROBIOL, V11, P250, DOI 10.1016/S0959-4388(00)00204-X
   Rothwell NA, 1999, BRAIN INJURY, V13, P521
   ROUSSEAU D, 1997, 9710 KSL STANF U
   Ruttkay Z., 2004, BROWS TRUST EVALUATI
   Ryu J., 2003, TECHNOLOGY INSTRUCTI, V2, P291
   Shine J, 2000, MED SCI LAW, V40, P327, DOI 10.1177/002580240004000408
   SLABY RG, 1988, DEV PSYCHOL, V24, P580, DOI 10.1037/0012-1649.24.4.580
   Slaby RG., 1992, VIGNETTES DEV EVALUA
   Slater M, 1999, IEEE COMPUT GRAPH, V19, P6, DOI 10.1109/38.749116
   STOKES J, 2001, P 10 C COMP GEN FORC, P467
   TAKACS B, 2005, IEEE COMPUTER GR SEP
   Tarter R, 1999, DEV PSYCHOPATHOL, V11, P657, DOI 10.1017/S0954579499002266
   WETTER T, 1992, IBM J RES DEV, V36, P435, DOI 10.1147/rd.363.0435
   Wilson BA, 1997, J INT NEUROPSYCH SOC, V3, P487, DOI 10.1017/S1355617797004876
   Woods S, 2007, COMPUT HUM BEHAV, V23, P770, DOI 10.1016/j.chb.2004.11.018
   WRAY RE, 2004, INNOVATIVE APPL ARTI
   XIAO J, 2002, EMB CONV AG LETS SPE
   YUNG B, 1995, POSITIVE ADOLESCENT
   ZIMMER J, 2003, MED MEETS VIRT REAL
   [No title captured]
NR 99
TC 20
Z9 20
U1 1
U2 13
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0747-5632
EI 1873-7692
J9 COMPUT HUM BEHAV
JI Comput. Hum. Behav.
PD MAY
PY 2008
VL 24
IS 3
BP 1104
EP 1138
DI 10.1016/j.chb.2007.03.010
PG 35
WC Psychology, Multidisciplinary; Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA 283UV
UT WOS:000254662900032
PM 19412316
OA Green Accepted
DA 2022-08-02
ER

PT J
AU Liu, CX
   Ham, J
   Postma, E
   Midden, C
   Joosten, B
   Goudbeek, M
AF Liu, Caixia
   Ham, Jaap
   Postma, Eric
   Midden, Cees
   Joosten, Bart
   Goudbeek, Martijn
TI Representing Affective Facial Expressions for Robots and Embodied
   Conversational Agents by Facial Landmarks
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Article
DE Robots; Embodied conversational agents; Emotion; Facial expression;
   Facial landmarks; FaceTracker
ID PERCEPTION; EMOTION; RECOGNITION; MOTION
AB Affective robots and embodied conversational agents require convincing facial expressions to make them socially acceptable. To be able to virtually generate facial expressions, we need to investigate the relationship between technology and human perception of affective and social signals. Facial landmarks, the locations of the crucial parts of a face, are important for perception of the affective and social signals conveyed by facial expressions. Earlier research did not use that kind of technology, but rather used analogue technology to generate point-light faces. The goal of our study is to investigate whether digitally extracted facial landmarks contain sufficient information to enable the facial expressions to be recognized by humans. This study presented participants with facial expressions encoded in moving landmarks, while these facial landmarks correspond to the facial-landmark videos that were extracted by face analysis software from full-face videos of acted emotions. The facial-landmark videos were presented to 16 participants who were instructed to classify the sequences according to the emotion represented. Results revealed that for three out of five facial-landmark videos (happiness, sadness and anger), participants were able to recognize emotions accurately, but for the other two facial-landmark videos (fear and disgust), their recognition accuracy was below chance, suggesting that landmarks contain information about the expressed emotions. Results also show that emotions with high levels of arousal and valence are better recognized than those with low levels of arousal and valence. We argue that the question of whether these digitally extracted facial landmarks are a basis for representing facial expressions of emotions is crucial for the development of successful humanrobot interaction in the future. We conclude by stating that landmarks provide a basis for the virtual generation of emotions in humanoid agents, and discuss how additional facial information might be included to provide a sufficient basis for faithful emotion identification.
C1 [Liu, Caixia; Ham, Jaap; Midden, Cees] Eindhoven Univ Technol, Dept Ind Engn & Innovat Sci, Human Technol Interact Grp, NL-5600 MB Eindhoven, Netherlands.
   [Liu, Caixia; Postma, Eric; Joosten, Bart; Goudbeek, Martijn] Tilburg Univ, Tilburg Ctr Cognit & Commun, NL-5000 LE Tilburg, Netherlands.
RP Liu, CX (corresponding author), Eindhoven Univ Technol, Dept Ind Engn & Innovat Sci, Human Technol Interact Grp, POB 513, NL-5600 MB Eindhoven, Netherlands.
EM c.liu@tue.nl; j.r.c.ham@tue.nl; e.o.postma@tilburguniversity.edu;
   c.j.h.midden@tue.nl; b.joosten@tilburguniversity.edu;
   m.b.goudbeek@tilburguniversity.edu
RI Goudbeek, Martijn/J-4442-2019
OI Goudbeek, Martijn/0000-0002-7787-4123
FU China Scholarship Council
FX The authors acknowledge anonymous reviewers for their constructive and
   detailed comments to an earlier version of this paper. We wish to
   express our gratitude to Ruud Mattheij, and Peter Ruijten, and the
   Persuasive Technology Lab Group at TU/e for the fruitful discussions
   about this work. The first author also appreciates the scholarship for
   her Ph.D. project from China Scholarship Council.
CR Alexander O, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P176, DOI 10.1109/CVMP.2009.29
   Aviezer H., 2008, 1 IMPRESSIONS PP, P255
   Banziger T., 2010, BLUEPRINT AFFECTIVE, P271
   Banziger T, 2011, EMOTION, DOI 10.137/a0025827
   BASSILI JN, 1978, J EXP PSYCHOL HUMAN, V4, P373, DOI 10.1037/0096-1523.4.3.373
   Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1
   Breazeal CL, DESIGNING SOCIAL ROB
   Breazeal CL, 2000, THESIS MIT, P178
   Cheng LC, 2013, INT J SOC ROBOT, V5, P423, DOI 10.1007/s12369-012-0168-5
   JOHANSSON G, 1975, SCI AM, V232, P76, DOI 10.1038/scientificamerican0675-76
   Kedzierski J, 2013, INT J SOC ROBOT, V5, P237, DOI 10.1007/s12369-013-0183-1
   Lucey P, 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P255, DOI 10.1109/DICTA.2010.53
   Mondloch CJ, 2012, J EXP CHILD PSYCHOL, V111, P180, DOI 10.1016/j.jecp.2011.08.003
   Russell J. A., 1997, STUDIES EMOTION SOCI, P295, DOI [10.1017/CBO9780511659911.015, DOI 10.1017/CBO9780511659911.015]
   Saragih J. M., 2011, AUTOMATIC FACE GESTU
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093
   Tomlinson EK, 2006, SCHIZOPHR RES, V85, P96, DOI 10.1016/j.schres.2006.03.018
   Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007
   Yang C, 2007, INTERACTIVE FACIAL E
NR 20
TC 5
Z9 5
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD NOV
PY 2013
VL 5
IS 4
BP 619
EP 626
DI 10.1007/s12369-013-0208-9
PG 8
WC Robotics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Robotics
GA AE1VW
UT WOS:000333760400014
DA 2022-08-02
ER

PT J
AU Bennion, MR
   Hardy, GE
   Moore, RK
   Kellett, S
   Millings, A
AF Bennion, Matthew Russell
   Hardy, Gillian E.
   Moore, Roger K.
   Kellett, Stephen
   Millings, Abigail
TI Usability, Acceptability, and Effectiveness of Web-Based Conversational
   Agents to Facilitate Problem Solving in Older Adults: Controlled Study
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Article
DE transdiagnostic; method of levels; system usability; acceptability;
   effectiveness; mental health; conversational agents; older adults;
   chatbots; web-based
ID COGNITIVE-BEHAVIORAL THERAPY; SUBTHRESHOLD DEPRESSION;
   COST-EFFECTIVENESS; PEOPLE; TRIAL; SYMPTOMS; ANXIETY; SYSTEM; LIFE
AB Background: The usability and effectiveness of conversational agents (chatbots) that deliver psychological therapies is under-researched.
   Objective: This study aimed to compare the system usability, acceptability, and effectiveness in older adults of 2 Web-based conversational agents that differ in theoretical orientation and approach.
   Methods: In a randomized study, 112 older adults were allocated to 1 of the following 2 fully automated interventions: Manage Your Life Online (MYLO; ie, a chatbot that mimics a therapist using a method of levels approach) and ELIZA (a chatbot that mimics a therapist using a humanistic counseling approach). The primary outcome was problem distress and resolution, with secondary outcome measures of system usability and clinical outcome.
   Results: MYLO participants spent significantly longer interacting with the conversational agent. Posthoc tests indicated that MYLO participants had significantly lower problem distress at follow-up. There were no differences between MYLO and ELIZA in terms of problem resolution. MYLO was rated as significantly more helpful and likely to be used again. System usability of both the conversational agents was associated with helpfulness of the agents and the willingness of the participants to reuse. Adherence was high. A total of 12% (7/59) of the MYLO group did not carry out their conversation with the chatbot.
   Conclusions: Controlled studies of chatbots need to be conducted in clinical populations across different age groups. The potential integration of chatbots into psychological care in routine services is discussed.
C1 [Bennion, Matthew Russell; Hardy, Gillian E.; Kellett, Stephen; Millings, Abigail] Univ Sheffield, Dept Psychol, 1 Vicar Lane, Sheffield, S Yorkshire, England.
   [Moore, Roger K.] Univ Sheffield, Dept Comp Sci, Sheffield, S Yorkshire, England.
RP Bennion, MR (corresponding author), Univ Sheffield, Dept Psychol, 1 Vicar Lane, Sheffield, S Yorkshire, England.
EM m.bennion@sheffield.ac.uk
RI bennion, matthew r/P-2368-2016; Moore, Roger K/B-1985-2016
OI bennion, matthew r/0000-0003-2318-1468; Millings,
   Abigail/0000-0002-7849-6048; Hardy, Gillian/0000-0002-9637-815X;
   Kellett, Stephen/0000-0001-6034-4495; Moore, Roger K/0000-0003-0065-3311
FU University of Sheffield; Economic and Social Research Council
   [ES/L001365/1]
FX This work was supported by a Doctor of Philosophy studentship awarded by
   the University of Sheffield to the first author MB and an Economic and
   Social Research Council grant (number ES/L001365/1).
CR Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Bennion MR, 2019, BMJ HEALTH CARE INFO, V26, DOI 10.1136/bmjhci-2019-100027
   Bird T, 2018, BEHAV COGN PSYCHOTH, V46, P570, DOI 10.1017/S1352465817000820
   Botella C, 2009, CYBERPSYCHOL BEHAV, V12, P255, DOI 10.1089/cpb.2008.0325
   Broglia E, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/14318
   Brooke J., 1996, SUS A QUICK DIRTY US
   Brooke J, 2013, J USABILITY STUD, V8, P29
   CAREY TA, 2006, METHOD LEVELS DO PSY
   Carlbring P, 2018, COGN BEHAV THERAPY, V47, P1, DOI 10.1080/16506073.2017.1401115
   Cavanagh K., 2010, OXFORD GUIDE LOW INT, V227, P232
   Cavanagh Kate, 2009, Cognitive Behaviour Therapy, V38, P235, DOI 10.1080/16506070802561256
   Christensen H, 2009, J MED INTERNET RES, V11, DOI 10.2196/jmir.1194
   Crabb RM, 2012, BRIT J CLIN PSYCHOL, V51, P459, DOI 10.1111/j.2044-8260.2012.02038.x
   CyberPsych, 2008, EL COMP THER
   de Wit Jessica, 2015, Internet Interventions, V2, P161, DOI 10.1016/j.invent.2015.02.007
   Dear BF, 2015, BEHAV THER, V46, P206, DOI 10.1016/j.beth.2014.09.007
   Dear BF, 2013, AUST NZ J PSYCHIAT, V47, P169, DOI 10.1177/0004867412466154
   Elsegood K, 2008, COUNS PSYCHOTHER RES, V8, P189, DOI 10.1080/14733140802163914
   Etzelmueller A, 2018, INTERNET INTERV, V12, P165, DOI 10.1016/j.invent.2018.01.003
   Fisk A. D., 2009, DESIGNING OLDER ADUL
   Fluckiger C, 2018, PSYCHOTHERAPY, V55, P316, DOI 10.1037/pst0000172
   Gaffney H, 2014, BEHAV COGN PSYCHOTH, V42, P731, DOI 10.1017/S135246581300060X
   Helgadottir FD, 2009, BEHAV CHANGE, V26, P245, DOI 10.1375/bech.26.4.245
   Iso, 2018, 9241112018 ISO
   Kessler D, 2009, LANCET, V374, P628, DOI 10.1016/S0140-6736(09)61257-5
   Kleiboer A, 2016, TRIALS, V17, DOI 10.1186/s13063-016-1511-1
   Lovibond S. H., 1995, MANUAL DEPRESSION AN, V2nd
   Murray E, 2016, AM J PREV MED, V51, P843, DOI 10.1016/j.amepre.2016.06.008
   Pinquart M, 2001, BASIC APPL SOC PSYCH, V23, P245, DOI 10.1207/S15324834BASP2304_2
   Powers W.T., 1973, BEHAV CONTROL PERCEP
   Richards D, 2014, BMC PSYCHIATRY, V14, DOI 10.1186/1471-244X-14-147
   Rogers CR., 1995, WAY BEING
   Sauro J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1599
   Spek V, 2008, PSYCHOL MED, V38, P635, DOI 10.1017/S0033291707002590
   Spek V, 2007, PSYCHOL MED, V37, P1797, DOI 10.1017/S0033291707000542
   Titov N, 2015, BEHAV THER, V46, P193, DOI 10.1016/j.beth.2014.09.008
   Turkle, 1997, LIFE SCREEN IDENTITY
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   van Ballegooijen W, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100674
   Vis Christiaan, 2015, Internet Interventions, V2, P399, DOI 10.1016/j.invent.2015.10.002
   Zou JB, 2012, J ANXIETY DISORD, V26, P650, DOI 10.1016/j.janxdis.2012.04.002
NR 41
TC 6
Z9 6
U1 5
U2 26
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD MAY 27
PY 2020
VL 22
IS 5
AR e16794
DI 10.2196/16794
PG 12
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA LR4IH
UT WOS:000535659700001
PM 32384055
OA Green Accepted, gold, Green Published
DA 2022-08-02
ER

PT C
AU Choi, D
   Kwak, D
   Cho, M
   Lee, S
AF Choi, Dasom
   Kwak, Daehyun
   Cho, Minji
   Lee, Sangsu
GP ACM
TI "Nobody Speaks that Fast!" An Empirical Study of Speech Rate in
   Conversational Agents for People with Vision Impairments
SO PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING
   SYSTEMS (CHI'20)
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 25-30, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGCHI
DE Conversational agents; Accessibility; People with vision impairments;
   Speech rate
ID STUDENTS
AB The number of people with vision impairments using Conversational Agents (CAs) has increased because of the potential of this technology to support them. As many visually impaired people are accustomed to understanding fast speech, most screen readers or voice assistant systems offer speech rate settings. However, current CAs are designed to interact at a human-like speech rate without considering their accessibility. In this study, we tried to understand how people with vision impairments use CA at a fast speech rate. We conducted a 20-day in-home study that examined the CA use of 10 visually impaired people at default and fast speech rates. We investigated the difference in visually impaired people's CA use with different speech rates and their perception toward CA at each rate. Based on these findings, we suggest considerations for the future design of CA speech rate for those with visual impairments.
C1 [Choi, Dasom; Kwak, Daehyun; Cho, Minji; Lee, Sangsu] Korea Adv Inst Sci & Technol, Dept Ind Design, Daejeon, South Korea.
RP Choi, D (corresponding author), Korea Adv Inst Sci & Technol, Dept Ind Design, Daejeon, South Korea.
EM dasomchoi@kaist.ac.kr; nubdigi7@kaist.ac.kr; mjcho@kaist.ac.kr;
   sangsu.lee@kaist.ac.kr
CR Abdolrahmani A, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P249, DOI 10.1145/3234695.3236344
   Abdolrahmani A, 2016, 13TH WEB FOR ALL CONFERENCE MONTREAL, CANADA 2016, DOI 10.1145/2899475.2899482
   Ahmed F., 2013, P 2013 INT C INT US, P435, DOI DOI 10.1145/2449396.2449452
   Ahmed Faisal, P 25 ANN ACM S US IN, P367, DOI [10.1145/2380116.2380164, DOI 10.1145/2380116.2380164]
   Ahmed Faisal, P INT CROSS DISC C W, DOI [10.1145/2207016.2207052, DOI 10.1145/2207016.2207052]
   [Anonymous], 2018, ANDROID GOOGLE ASSIS
   Asakawa Chieko, 2003, MAXIMUM LISTENING SP
   Azenkot S, 2013, P 15 INT ACM SIGACCE, P1, DOI DOI 10.1145/2513383.2513440
   Bentley Frank, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3264901
   Bhalla A, 2018, INDIAHCI'18: PROCEEDINGS OF THE 9TH INDIAN CONFERENCE ON HUMAN COMPUTER INTERACTION, P90, DOI 10.1145/3297121.3297136
   Bigham JP, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P101, DOI 10.1145/3132525.3132533
   Bouck EC, 2011, J SPEC EDUC TECHNOL, V26, P1
   Bragg D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174018
   Branham SM, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P446, DOI 10.1145/3308561.3353797
   Branham SM, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P260, DOI 10.1145/3132525.3132534
   Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1
   Bruce A, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P4138, DOI 10.1109/ROBOT.2002.1014396
   Cafaro A, 2016, AAMAS'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P911
   Cho M, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P1557, DOI 10.1145/3322276.3322332
   Clark L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300705
   Cohen M. H., 2004, VOICE USER INTERFACE
   Cowan BR, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3098539
   Druga S, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P595, DOI 10.1145/3078072.3084330
   Feng JJ, 2011, UNIVERSAL ACCESS INF, V10, P17, DOI 10.1007/s10209-010-0185-9
   Freedom Scientific, JAWS
   Gadde Prathik, 2013, P ADJ PUBL 26 ANN AC, P85
   Gibbs G. R., 2007, ANAL QUALITATIVE DAT, DOI 10.4135/9781849208574
   Gilpin LH, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188557
   Guerreiro J, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P3, DOI 10.1145/2700648.2809840
   Guo ZX, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3313075
   Kane SK, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P413
   Kane Shaun K., 2013, P SIGCHI C HUM FACT, P347
   Karapanos E, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P729
   Kim H, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312887
   Kuno Y, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1191
   Lazar J, 2007, INT J HUM-COMPUT INT, V22, P247, DOI 10.1080/10447310709336964
   Lee S, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312796
   Leobas G.V., 2018, SBLP, P27, DOI [10.1145/3264637.3264641, DOI 10.1145/3264637.3264641]
   Leporini B, 2012, P 24 AUSTR COMP HUM, P339, DOI DOI 10.1145/2414536.2414591
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Luria M, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P633, DOI 10.1145/3322276.3322340
   McCarthy T, 2013, ASSIST TECHNOL, V25, P222, DOI 10.1080/10400435.2013.768719
   Mennicken S, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P120, DOI 10.1145/2971648.2971757
   Moorthy AE, 2015, INT J HUM-COMPUT INT, V31, P307, DOI 10.1080/10447318.2014.986642
   Murphy Emma, 2008, Universal Access in the Information Society, V7, P79, DOI 10.1007/s10209-007-0098-4
   Nass Clifford, 2005, WIRED SPEECH VOICE A
   Pearl C., 2016, DESIGNING VOICE USER
   Porcheron M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174214
   Portet F, 2013, PERS UBIQUIT COMPUT, V17, P127, DOI 10.1007/s00779-011-0470-5
   Pradhan A, 2018, PORTL INT CONF MANAG, DOI 10.1145/3173574.3174033
   Purington A, 2017, 2017 CHI C HUM FACT, DOI [10.1145/3027063.3053246, DOI 10.1145/3027063.3053246]
   Pyae A., 2018, P 20 INT C HUMAN COM, P127
   Saffarizadeh Kambiz, 2017, CONVERSATIONAL ASSIS
   Sciuto A, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P857, DOI 10.1145/3196709.3196772
   Sheikh W, 2018, INT J LEARN TECHNOL, V13, P3, DOI 10.1504/IJLT.2018.091609
   이나라, 2017, [Phonetics and Speech Sciences, 말소리와 음성과학], V9, P27, DOI 10.13064/KSSS.2017.9.1.027
   Smith DW, 2014, INT REV RES DEV DISA, V46, P23, DOI 10.1016/B978-0-12-420039-5.00003-4
   Song J, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312865
   Stent A, 2011, ASSETS 11: PROCEEDINGS OF THE 13TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P211
   The Amazon Blog, 2019, ALEXA SPEAK SLOWER C
   Wang I, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300511
   Westlund JMK, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P207, DOI 10.1145/3202185.3202732
   Wulf L., 2014, P 8 NORD C HUM COMP P 8 NORD C HUM COMP, P203
   Yuasa Masahide, 2010, CHI 10 EXTENDED ABST, P3919, DOI [10.1145/1753846.1754079, DOI 10.1145/1753846.1754079]
   Zhong Y., 2014, P 11 WEB ALL C SEOUL, P1, DOI DOI 10.1145/2596695.2596720
   Ziman R, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188575
NR 66
TC 9
Z9 9
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6708-0
PY 2020
AR 442
DI 10.1145/3313831.3376569
PG 13
WC Computer Science, Cybernetics; Computer Science, Information Systems;
   Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS1TK
UT WOS:000696109100040
DA 2022-08-02
ER

PT J
AU Morrow, DG
   Lane, HC
   Rogers, WA
AF Morrow, Daniel G.
   Lane, H. Chad
   Rogers, Wendy A.
TI A Framework for Design of Conversational Agents to Support Health
   Self-Care for Older Adults
SO HUMAN FACTORS
LA English
DT Article
DE conversational agents; pedagogical agents; learning; motivation; aging;
   self-care
AB Objective
   We examined the potential of conversational agents (CAs) to support older adults' self-care related to chronic illness in light of lessons learned from decades of pedagogical agent research, which investigates the impact and efficacy of CAs for a wide range of learners.
   Background
   The role of CAs in education (i.e., pedagogical agents) has been long studied, but their potential for supporting self-care has received less attention, especially for older adults.
   Methods
   We reviewed work on pedagogical agents and considered how it informs the design of CAs for older adults. We propose a framework for designing CAs to support older adult self-care, which organizes a review of work in this area and integration with the pedagogical agent literature.
   Results
   Our review of the pedagogical agent literature revealed an evolution from teaching machines to interactive, social systems that influence student motivational as well as learning outcomes. To integrate this review with work on CAs and self-care, we developed a framework that specifies how self-care goals evolve with stages of an illness, communication goals that support self-care at each stage, patient needs, and requirements for CAs to support these needs. The review identified an agenda for future research on CA functions and features that help older adults accept need for self-care, establish self-care, and sustain self-care over time.
   Conclusions
   Integrating insights from the pedagogical agent literature with research on developing CAs for self-care defines an agenda for developing and evaluating CAs to help older adults manage illness.
C1 [Morrow, Daniel G.; Lane, H. Chad; Rogers, Wendy A.] Univ Illinois, Champaign, IL USA.
RP Morrow, DG (corresponding author), Univ Illinois, Dept Educ Psychol, Champaign, IL 61820 USA.
EM dgm@illinois.edu
OI Rogers, Wendy/0000-0002-0787-2130
FU Jump Applied Research for Community Health through Engineering and
   Simulation (ARCHES) program, UIUC/OSF Hospital, Peoria, IL; National
   Institutes of Health (National Institute on Aging) Grant through the
   Center for Research and Education on Aging and Technology Enhancement
   (CREATE) [P01 AG17211]; National Institute on Disability, Independent
   Living, and Rehabilitation Research (NIDILRR Grant) through the
   Rehabilitation and Engineering Research Center on Technologies to
   Support Aging-in-Place for People with Long-Term Disabilities (TechSAge)
   [90REGE0006-01-00]
FX Our thanks to Kenny Blocker for help with Figure 1. Support for writing
   this paper was provided to Dan Morrow by the Jump Applied Research for
   Community Health through Engineering and Simulation (ARCHES) program,
   UIUC/OSF Hospital, Peoria, IL. Support to Wendy Rogers was provided from
   National Institutes of Health (National Institute on Aging) Grant P01
   AG17211 through the Center for Research and Education on Aging and
   Technology Enhancement (CREATE; www.create-center.org) and from the
   National Institute on Disability, Independent Living, and Rehabilitation
   Research (NIDILRR Grant 90REGE0006-01-00) through the Rehabilitation and
   Engineering Research Center on Technologies to Support Aging-in-Place
   for People with Long-Term Disabilities (TechSAge;
   www.rerctechsage.org).The content is solely the responsibility of the
   authors and does not necessarily reflect the official views of these
   institutions.
CR Anderson JR, 1995, J LEARN SCI, V4, P167, DOI 10.1207/s15327809jls0402_2
   Anderson M, 2017, TECH ADOPTION CLIMBS
   Atkinson RK, 2005, CONTEMP EDUC PSYCHOL, V30, P117, DOI 10.1016/j.cedpsych.2004.07.001
   Azevedo Renato F L, 2018, AMIA Annu Symp Proc, V2018, P185
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T, 2010, APPL ARTIF INTELL, V24, P648, DOI 10.1080/08839514.2010.492259
   Bickmore TW, 2010, J HEALTH COMMUN, V15, P197, DOI 10.1080/10810730.2010.499991
   Bickmore TW, 2009, PATIENT EDUC COUNS, V75, P315, DOI 10.1016/j.pec.2009.02.007
   BLOOM BS, 1984, EDUC LEADERSHIP, V41, P4
   Charles ST, 2010, ANNU REV PSYCHOL, V61, P383, DOI 10.1146/annurev.psych.093008.100448
   Chattaraman V, 2012, COMPUT HUM BEHAV, V28, P2055, DOI 10.1016/j.chb.2012.06.009
   Chi MTH, 2001, COGNITIVE SCI, V25, P471, DOI 10.1016/S0364-0213(01)00044-1
   de Graaf A, 2016, REV COMMUN RES, V4, P88, DOI 10.12840/issn.2255-4165.2016.04.01.011
   Duwe EAG, 2018, HEALTH EDUC J, V77, P412, DOI 10.1177/0017896917751553
   Fabbri E, 2015, J AM MED DIR ASSOC, V16, P640, DOI 10.1016/j.jamda.2015.03.013
   Federman AD, 2010, J ASTHMA, V47, P620, DOI 10.3109/02770901003702816
   Goldin-Meadow S., 2005, HEARING GESTURE OUR
   Graesser AC, 2001, AI MAG, V22, P39
   Gratch J., 2006, 6 INT C INT VIRT AG
   Gulz A, 2006, INT J HUM-COMPUT ST, V64, P322, DOI 10.1016/j.ijhcs.2005.08.006
   Hagger MS, 2010, HEALTH PSYCHOL REV, V4, P57, DOI 10.1080/17437199.2010.503594
   Hartholt A., 2013, P 2013 INT C INT VIR
   Hoffman DL, 2018, J CONSUM RES, V44, P1178, DOI 10.1093/jcr/ucx105
   Hosseinpanah A, 2018, HAI'18: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT INTERACTION, P184, DOI 10.1145/3284432.3284442
   Johnson WL, 2016, INT J ARTIF INTELL E, V26, P25, DOI 10.1007/s40593-015-0065-9
   Kim Y, 2016, INT J ARTIF INTELL E, V26, P160, DOI 10.1007/s40593-015-0055-y
   Koon LM, 2020, ERGON DES, V28, P16, DOI 10.1177/1064804619842501
   Kopp S, 2018, P AAMAS WORKSH INT C, V2338
   Kramer NC, 2012, STUD COMPUT INTELL, V396, P215
   Kramer NC, 2010, EDUC PSYCHOL REV, V22, P71, DOI 10.1007/s10648-010-9123-x
   Kulik JA, 2016, REV EDUC RES, V86, P42, DOI 10.3102/0034654315581420
   Lane H. Chad, 2013, Artificial Intelligence in Education. Proceedings of 16th International Conference (AIED 2013): LNCS 7926, P309, DOI 10.1007/978-3-642-39112-5_32
   Medlock S, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.3749
   MEYER D, 1985, HEALTH PSYCHOL, V4, P115, DOI 10.1037/0278-6133.4.2.115
   Mitzner T., 2013, REV HUM FACTORS ERGO, V8, P277, DOI [DOI 10.1177/1557234X13492979, 10.1177/1557234X13492979]
   Moraes M., 2002, P IMAGINA 2002 MONT, P207
   Moreno R., 2005, CAMBRIDGE HDB MULTIM, P507, DOI DOI 10.1017/CBO9780511816819.032
   Mori M, 1970, ENERGY, V7, P33, DOI DOI 10.1109/MRA.2012.2192811
   Morrow D., 2020, P HUM FACT ERG SOC 6
   National Public Radio, 2018, SMART AUD REP SPRING
   Pak R, 2012, ERGONOMICS, V55, P1059, DOI 10.1080/00140139.2012.691554
   Pfeifer Vardoulakis Laura, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P289, DOI 10.1007/978-3-642-33197-8_30
   Phillips E, 2018, ACMIEEE INT CONF HUM, P105, DOI 10.1145/3171221.3171268
   Prakash A, 2015, INT J SOC ROBOT, V7, P309, DOI 10.1007/s12369-014-0269-4
   Pressey SL, 1926, SCHOOL SOC, V23, P373
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Rigaud A., 2013, ACHI 2013 6 INT C AD
   Ring L, 2015, J MULTIMODAL USER IN, V9, P79, DOI 10.1007/s12193-014-0157-0
   Schroeder NL, 2014, J RES TECHNOL EDUC, V46, P229, DOI 10.1080/15391523.2014.888265
   Schroeder NL, 2013, J EDUC COMPUT RES, V49, P1, DOI 10.2190/EC.49.1.a
   Schulman D., 2009, P 4 INT C PERS TECHN, P1
   Schwarzer R, 2008, APPL PSYCHOL-INT REV, V57, P1, DOI 10.1111/j.1464-0597.2007.00325.x
   Shute VJ., 1996, HDB RES ED COMMUNICA, P570
   Sidner CL, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3213050
   Strassmann C, 2017, LECT NOTES ARTIF INT, V10498, P413, DOI 10.1007/978-3-319-67401-8_51
   Veletsianos G., 2014, HDB RES ED COMMUNICA, P759, DOI [DOI 10.1007/978-1-4614-3185-5_61, 10.1007/978-1-4614-3185-5_61]
   Ward BW, 2014, PREV CHRONIC DIS, V11, DOI 10.5888/pcd11.130389
NR 58
TC 3
Z9 3
U1 2
U2 10
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0018-7208
EI 1547-8181
J9 HUM FACTORS
JI Hum. Factors
PD MAY
PY 2021
VL 63
IS 3
BP 369
EP 378
AR 0018720820964085
DI 10.1177/0018720820964085
EA OCT 2020
PG 10
WC Behavioral Sciences; Engineering, Industrial; Ergonomics; Psychology,
   Applied; Psychology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Behavioral Sciences; Engineering; Psychology
GA RP0HI
UT WOS:000633612200001
PM 33090054
DA 2022-08-02
ER

PT C
AU Luria, M
   Reig, S
   Tan, XZ
   Steinfeld, A
   Forlizzi, J
   Zimmerman, J
AF Luria, Michal
   Reig, Samantha
   Tan, Xiang Zhi
   Steinfeld, Aaron
   Forlizzi, Jodi
   Zimmerman, John
GP ACM
TI Re-Embodiment and Co-Embodiment: Exploration of social presence for
   robots and conversational agents
SO PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE
   (DIS 2019)
LA English
DT Proceedings Paper
CT ACM Designing Interactive Systems Conference (DIS)
CY JUN 24-28, 2019
CL San Diego, CA
SP Assoc Comp Machinery, Adobe, Google, UC San Diego Design Lab, Virginia Tech, Sketch
DE interaction design; user enactments; social robots; conversational
   agents; re-embodiment; co-embodiment; embodied agents
ID METAANALYSIS; TRUST
AB Interactions with multiple conversational agents and social robots are becoming increasingly common. This raises new design challenges: Should agents and robots be modeled after humans, presenting their entity (i.e., social presence) as bound to a single body, or should they take advantage of non-human capabilities, such as moving their social presence from body to body across service touchpoints and contexts? We conducted a User Enactments study in which participants interacted with agents that had one social presence per body, that could re-embody (move their social presence from body to body), and that could co-embody (move their social presence into a body that already contains another). Reactions showed that participants felt comfortable with re-embodying agents, who created more seamless and efficient experiences. Yet situations that required expertise or concentration raised concerns about non-human behaviors. We report on our insights regarding collaboration and coordination with several agents in multi-step interactions.
C1 [Luria, Michal; Reig, Samantha; Forlizzi, Jodi; Zimmerman, John] Carnegie Mellon Univ, Human Comp Interact Inst, Pittsburgh, PA 15213 USA.
   [Tan, Xiang Zhi; Steinfeld, Aaron] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
RP Luria, M (corresponding author), Carnegie Mellon Univ, Human Comp Interact Inst, Pittsburgh, PA 15213 USA.
EM mluria@cs.cmu.edu; sreig@cs.cmu.edu; zhi.tan@ri.cmu.edu;
   steinfeld@cmu.edu; forlizzi@cs.cmu.edu; johnz@cs.cmu.edu
OI Steinfeld, Aaron/0000-0003-2274-0053
FU National Science Foundation [SES 1734456]
FX We would like to thank the students who helped set-up and pilot the
   study: Xu Zeng, Thomas Von Davier, Ashvik Awasti, Benjamin Stone and
   Monica Huang. We would also like to thank our participants. This work is
   supported by the National Science Foundation under Grant Numbers SES
   1734456. Any findings, conclusions or recommendations expressed in this
   material are those of the authors and do not necessarily reflect the
   views of the National Science Foundation.
CR Bainbridge WA, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P701, DOI 10.1109/ROMAN.2008.4600749
   Benbasat I., 2005, J ASSOC INF SYST, V6, P72, DOI [10.17705/1jais.00065, DOI 10.17705/1JAIS.00065]
   Beyer H., 1997, CONTEXTUAL DESIGN CU
   Breazeal C, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P383, DOI 10.1109/IROS.2005.1545011
   Burns C., 1994, C COMP HUM FACT COMP, P119
   Business Insider Leanna Garfield, 2016, COMP AR REPL HUM JOB
   Cassell J., 2000, EMBODIED CONVERSATIO
   Chaves AP, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173765
   Cooper A, 2007, FACE 3 ESSENTIALS IN
   Davidoff S, 2007, LECT NOTES COMPUT SC, V4717, P429
   Desai M., 2009, P S AISB 2009 CONVEN
   Duffy BR, 2003, COMP ANIM CONF PROC, P118, DOI 10.1109/CASA.2003.1199312
   Golembewski M., 2010, P 8 ACM C DES INT SY, P89, DOI DOI 10.1145/1858171.1858189
   Hancock PA, 2011, HUM FACTORS, V53, P517, DOI 10.1177/0018720811417254
   Hekkert P, 2003, BRIT J PSYCHOL, V94, P111, DOI 10.1348/000712603762842147
   Hinds PJ, 2004, HUM-COMPUT INTERACT, V19, P151, DOI 10.1207/s15327051hci1901&2_7
   Hoffman G, 2015, ACMIEEE INT CONF HUM, P181, DOI 10.1145/2696454.2696487
   Jibo, JIBO
   Kiesler S, 2008, SOC COGNITION, V26, P169, DOI 10.1521/soco.2008.26.2.169
   Kim CH, 2013, ACMIEEE INT CONF HUM, P161, DOI 10.1109/HRI.2013.6483551
   Koay KL, 2016, IEEE ROMAN, P809, DOI 10.1109/ROMAN.2016.7745212
   Koay Kheng Lee, 2009, USER STUDY VISUALIZA
   Lockton Dan, NEW METAPHORS WORKSH
   Luria M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P580, DOI 10.1145/3025453.3025786
   Martin A, 2005, LECT NOTES ARTIF INT, V3661, P454
   Murnane Kevin, 2018, REPORT CLAIMS 16 ADU
   Mutlu B., 2009, P 4 ACM IEEE INT C H, P69, DOI [10.1145/1514095.1514110, DOI 10.1145/1514095.1514110]
   Nass Clifford, 2005, WIRED SPEECH VOICE A
   Ogawa K, 2008, LECT NOTES COMPUT SC, V5208, P296
   Porcheron M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174214
   Powers A., 2007, 2007 2nd Annual Conference on Human-Robot Interaction (HRI), P145
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Reig S, 2019, ACMIEEE INT CONF HUM, P742, DOI 10.1109/HRI.2019.8673226
   Riek LD, 2012, J HUM-ROBOT INTERACT, V1, P119, DOI 10.5898/JHRI.1.1.Riek
   Schaefer KE, 2016, HUM FACTORS, V58, P377, DOI 10.1177/0018720816634228
   Sciuto A, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P857, DOI 10.1145/3196709.3196772
   Seeger Anna-Maria, 2017, DO WE NEED HUMAN ANT
   Syrdal D. S., 2009, NEGATIVE ATTITUDES R
   Tan XZ, 2019, ACMIEEE INT CONF HUM, P114, DOI 10.1109/HRI.2019.8673304
   Williams T, 2015, J HUM-ROBOT INTERACT, V4, P24, DOI 10.5898/JHRI.4.2.Williams
   Zimmerman John, 2017, She Ji: The Journal of Design, Economics, and Innovation, V3, P30, DOI 10.1016/j.sheji.2017.08.003
NR 41
TC 27
Z9 27
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5850-7
PY 2019
BP 633
EP 644
DI 10.1145/3322276.3322340
PG 12
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications; Computer Science, Software Engineering; Engineering,
   Electrical & Electronic; Ergonomics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Engineering
GA BS3ZH
UT WOS:000717008300052
OA Bronze
DA 2022-08-02
ER

PT C
AU Figa, E
   Tarau, P
AF Figa, E
   Tarau, P
BE Arabnia, HR
   Droegehorn, O
TI Conversational agents as Web services
SO IC'04: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTERNET
   COMPUTING, VOLS 1 AND 2
LA English
DT Proceedings Paper
CT International Conference on Internet Computing/International Symposium
   on Web Services and Applications
CY JUN 21-24, 2004
CL Las Vegas, NV
SP Comp Sci Res, Educ & Applicat Press, Int Technol Inst, Korean Soc Internet Informat, World Acad Sci Informat Technol
DE conversational agents; agent-based Web services; natural language
   processing; WordNet; logic programming
AB We describe a Web-services based conversational agent architecture that combines logical inferences from the WordNet knowledge base and Web content extraction using Google's Web-search API. Our agents interact with users over the Web, as voice-enabled animated characters and can reach wireless devices through Instant Messenger protocol adapters.
C1 Univ N Texas, Sch Lib & Informat Sci, Denton, TX 76203 USA.
RP Figa, E (corresponding author), Univ N Texas, Sch Lib & Informat Sci, POB 311068, Denton, TX 76203 USA.
CR Baker C.F., 1998, P 17 INT C COMPUTATI, P86
   CAVASSA M, 2001, P INT C VIRT STOR AV
   Felbaum C., 1998, WORDNET ELECT LEXICA
   FIGA E, 2003, TISE 2003 DARMSTADT
   Fokkinga M., 1992, LECT NOTES STOP 1992, P1
   Mateas Michael, 2003, P TECHN INT DIG STOR
   Miller G., 1990, 43 CSL PRINC U
   Searle John R., 1969, SPEECH ACTS
   SINGH P, 2002, P AAAI SPRING S ACQU
   SINGH P, 2003, OPEN MIND COMMON SEN
   TARAU P, 2003, JINNI 2004 PROLOG CO
   TARAU P, 2004, BINPROLOG 10 X PROFE
   TARAU P., 1999, LOGIC PROGRAMMING PA, P33
   TARAU P, 2000, P CL 2000 LOND JUL 2
   WALLACE R, 2002, AIML PATTERN MATCHIN
   WERNER E, 1988, P COLING 88, P744
   ZANCANARO M, 2001, P INT C VIRT STOR AV
NR 17
TC 0
Z9 0
U1 0
U2 0
PU C S R E A PRESS
PI ATHENS
PA 115 AVALON DR, ATHENS, GA 30606 USA
BN 1-932415-46-7
PY 2004
BP 773
EP 782
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BBK73
UT WOS:000225901700118
DA 2022-08-02
ER

PT C
AU Shmueli-Scheuer, M
   Artstein, R
   Khazaeni, Y
   Fang, H
   Liao, QV
AF Shmueli-Scheuer, Michal
   Artstein, Ron
   Khazaeni, Yasaman
   Fang, Hao
   Liao, Q. Vera
GP ACM
TI user2agent: 2nd Workshop on User-Aware Conversational Agents
SO PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER
   INTERFACES COMPANION (IUI'20)
LA English
DT Proceedings Paper
CT 25th ACM International Conference on Intelligent User Interfaces (IUI)
CY MAR 17-20, 2020
CL Cagliari, ITALY
SP ACM
AB Conversational agents are becoming increasingly popular. These systems present an extremely rich and challenging research space for addressing many aspects of user awareness and adaptation, such as user profiles, contexts, personalities, emotions, social dynamics, conversational styles, etc. Adaptive interfaces are of long-standing interest for the HCI community. Meanwhile, new machine learning approaches are introduced in the current generation of conversational agents, such as deep learning, reinforcement learning, and active learning. It is imperative to consider how various aspects of user-awareness should be handled by these new techniques. The goal of this workshop is to bring together researchers in HCI, user modeling, and the AI and NLP communities from both industry and academia, who are interested in advancing the state-of-the-art on the topic of user-aware conversational agents. Through a focused and open exchange of ideas and discussions, we will work to identify central research topics in user-aware conversational agents and develop a strong interdisciplinary foundation to address them.
C1 [Shmueli-Scheuer, Michal] IBM Res AI, Haifa, Israel.
   [Artstein, Ron] USC Inst Creat Technol, Playa Vista, CA USA.
   [Khazaeni, Yasaman] IBM Res AI, Cambridge, MA USA.
   [Fang, Hao] Microsoft Semant Machines, Redmond, WA USA.
   [Liao, Q. Vera] IBM Res AI, Yorktown Hts, NY USA.
RP Shmueli-Scheuer, M (corresponding author), IBM Res AI, Haifa, Israel.
EM shmueli@il.ibm.com; artstein@ict.usc.edu; yasaman.khazaeni@us.ibm.com;
   hao.fang@microsoft.com; vera.liao@ibm.com
CR Han Xu, 2020, COMP P 25 INT C INT
   Iovine Andrea, 2020, COMP P 25 INT C INT
   Liao QV, 2019, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES: COMPANION (IUI 2019), P133, DOI 10.1145/3308557.3313124
   Mahmood Riyadh, 2020, P 25 INT C INT US IN
   Rizk Yara, 2020, COMP P 25 INT C INT
   Tellols DolAga, 2020, COMP P 25 INT C INT
   Xie Yubo, 2020, COMP P 25 INT C INT
NR 7
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-7513-9
PY 2020
BP 9
EP 10
DI 10.1145/3379336.3379356
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR0KP
UT WOS:000629492200005
DA 2022-08-02
ER

PT J
AU Loveys, K
   Sebaratnam, G
   Sagar, M
   Broadbent, E
AF Loveys, Kate
   Sebaratnam, Gabrielle
   Sagar, Mark
   Broadbent, Elizabeth
TI The Effect of Design Features on Relationship Quality with Embodied
   Conversational Agents: A Systematic Review
SO INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS
LA English
DT Review
DE Human-computer interaction; Embodied conversational agents; Relationship
   quality; Design features; Healthcare
ID PHYSICIAN-PATIENT COMMUNICATION; TEACHER-STUDENT RELATIONSHIPS; SOCIAL
   SUPPORT; PHYSIOLOGICAL PROCESSES; VIRTUAL COUNSELORS; HEALTH;
   INTERVENTIONS; CONSEQUENCES; INFORMATION; PERSPECTIVE
AB Embodied conversational agents (ECAs) are increasingly used in healthcare and other settings to improve self-management and provide companionship. Their ability to form close relationships with people is important for enhancing effectiveness and engagement. Several studies have looked at enhancing relationships with ECAs through design features focused on behaviours, appearance, or language. However, this evidence is yet to be systematically synthesized. This systematic review evaluates the effect of different design features on relationship quality with ECAs. A systematic search was conducted on electronic databases EMBASE, PsychInfo, PubMed, MEDLINE, Cochrane Library, SCOPUS, and Web of Science in January-February 2019. 43 studies were included for review that evaluated the effect of a design feature on relationship quality and social perceptions or behaviours towards an ECA. Results synthesize effective design features and lay a scientific framework for improving relationships with ECAs in healthcare and other applications. Risk of bias for included studies was generally low, however there were some limitations in the research quality pertaining to outcome measurement and the reporting of statistics. Further research is needed to understand how to make ECAs effective and engaging for all consumers.
C1 [Loveys, Kate; Sebaratnam, Gabrielle; Broadbent, Elizabeth] Univ Auckland, Sch Med, Dept Psychol Med, Bldg 507,Level 3,22-30 Pk Ave, Auckland 1023, New Zealand.
   [Sagar, Mark] Univ Auckland, Auckland Bioengn Inst, Auckland, New Zealand.
RP Loveys, K (corresponding author), Univ Auckland, Sch Med, Dept Psychol Med, Bldg 507,Level 3,22-30 Pk Ave, Auckland 1023, New Zealand.
EM k.loveys@auckland.ac.nz; e.broadbent@auckland.ac.nz
OI Loveys, Kate/0000-0003-0694-4830; Sebaratnam,
   Gabrielle/0000-0002-9946-9815; Broadbent, Elizabeth/0000-0003-3626-9100
CR Alexander JA, 2012, HEALTH SERV RES, V47, P1201, DOI 10.1111/j.1475-6773.2011.01354.x
   Allison T, 2000, TRENDS COGN SCI, V4, P267, DOI 10.1016/S1364-6613(00)01501-1
   Alotaibi M. B., 2012, Proceedings of the 2012 Ninth International Conference on Information Technology: New Generations (ITNG), P796, DOI 10.1109/ITNG.2012.158
   Andrist Sean, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P249, DOI 10.1007/978-3-642-40415-3_22
   [Anonymous], 2015, ACM T INTERACTIVE IN
   Arafa Y, 2000, IEEE SYS MAN CYBERN, P792, DOI 10.1109/ICSMC.2000.885946
   Beldad A, 2016, COMPUT HUM BEHAV, V60, P62, DOI 10.1016/j.chb.2016.02.046
   Bergmann Kirsten, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P126, DOI 10.1007/978-3-642-33197-8_13
   Bickmore Timothy, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P55, DOI 10.1007/978-3-642-23974-8_7
   Bickmore T., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P396
   Bickmore T., 2009, P 8 INT C AUT AG MUL, V1, P297
   Bickmore T, 2008, CHI 08 WORKSH TECHN
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore TW, 2013, J AM GERIATR SOC, V61, P1676, DOI 10.1111/jgs.12449
   Bickmore TW, 2013, PATIENT EDUC COUNS, V92, P142, DOI 10.1016/j.pec.2013.05.011
   Bickmore TW, 2013, AUTON AGENT MULTI-AG, V27, P254, DOI 10.1007/s10458-012-9216-7
   Bickmore TW, 2009, PERVASIVE MOB COMPUT, V5, P226, DOI 10.1016/j.pmcj.2008.05.004
   Brave S, 2005, INT J HUM-COMPUT ST, V62, P161, DOI 10.1016/j.ijhcs.2004.11.002
   Broadbent E, 2018, LECT NOTES ARTIF INT, V11357, P308, DOI 10.1007/978-3-030-05204-1_30
   Broadbent E, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.8640
   Cassell J., 2000, EMBODIED CONVERSATIO
   Cassell J., 1999, P SIGCHI C HUM FACT, P520, DOI DOI 10.1145/302979.303150
   Cerekovic A, 2017, IEEE T AFFECT COMPUT, V8, P382, DOI 10.1109/TAFFC.2016.2545650
   Cerekovic A, 2014, LECT NOTES COMPUT SC, V8749, P1, DOI 10.1007/978-3-319-11839-0_1
   Chattaraman V, 2019, COMPUT HUM BEHAV, V90, P315, DOI 10.1016/j.chb.2018.08.048
   Chipidza FE, 2015, PRIMARY CARE COMPANI, V17
   Cornelius-White J, 2007, REV EDUC RES, V77, P113, DOI 10.3102/003465430298563
   Creed C, 2012, INTERACT COMPUT, V24, P339, DOI 10.1016/j.intcom.2012.05.004
   Cyr D, 2007, INTERACT COMPUT, V19, P43, DOI 10.1016/j.intcom.2006.07.010
   Dobrian F, 2013, COMMUN ACM, V56, P91, DOI 10.1145/2428556.2428577
   Doherty K, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234149
   Dush CMK, 2005, J SOC PERS RELAT, V22, P607, DOI 10.1177/0265407505056438
   Edwards RA, 2013, MATERN CHILD HLTH J, V17, P1961, DOI 10.1007/s10995-013-1222-0
   Gardiner PM, 2017, PATIENT EDUC COUNS, V100, P1720, DOI 10.1016/j.pec.2017.04.015
   Gilani SN, 2016, LECT NOTES ARTIF INT, V10011, P128, DOI 10.1007/978-3-319-47665-0_12
   Griffiths S., 2015, P 4 INT S NEW FRONT
   Hawkley LC, 2010, ANN BEHAV MED, V40, P218, DOI 10.1007/s12160-010-9210-8
   Hayashi Y., 2015, HAI 2015 P 3 INT C H, P135, DOI [10.1145/2814940.2814946, DOI 10.1145/2814940.2814946]
   Heinrichs M, 2003, BIOL PSYCHIAT, V54, P1389, DOI 10.1016/S0006-3223(03)00465-7
   Hoegen R, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P275, DOI 10.1145/3267851.3267911
   Hogan BE, 2002, CLIN PSYCHOL REV, V22, P381, DOI 10.1016/S0272-7358(01)00102-7
   House J.S., 1985, SOCIAL SUPPORT HLTH
   Jeong S, 2018, 2018 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC), P74
   Joranson N, 2015, J AM MED DIR ASSOC, V16, P867, DOI 10.1016/j.jamda.2015.05.002
   Kang SH, 2016, INT C HUM COMP INT, P107
   Kang SH, 2014, COMPUT HUM BEHAV, V34, P120, DOI 10.1016/j.chb.2014.01.006
   Kang SH, 2012, STUD HEALTH TECHNOL, V181, P202, DOI 10.3233/978-1-61499-121-2-202
   Kang SH, 2011, STUD HEALTH TECHNOL, V167, P143, DOI 10.3233/978-1-60750-766-6-143
   KAPLAN SH, 1989, MED CARE, V27, pS110, DOI 10.1097/00005650-198903001-00010
   Kessler R.C., 1985, SOCIAL SUPPORT MENTA
   Kiecolt-Glaser JK, 2010, NEUROSCI BIOBEHAV R, V35, P33, DOI 10.1016/j.neubiorev.2009.09.003
   Kramer NC, 2018, INT J HUM-COMPUT ST, V109, P112, DOI 10.1016/j.ijhcs.2017.09.001
   Kulms Philipp, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P80, DOI 10.1007/978-3-642-23974-8_9
   Kulms P, 2014, LECT NOTES ARTIF INT, V8637, P250, DOI 10.1007/978-3-319-09767-1_32
   Liew TW, 2016, EDUC TECHNOL SOC, V19, P104
   Lopez V, 2008, PROC INT C TOOLS ART, P194, DOI 10.1109/ICTAI.2008.50
   Matthews A, 2008, LECT NOTES COMPUT SC, V5208, P516
   McBreen H., 2000, Proceedings of the Fourth International Conference on Autonomous Agents, P39, DOI 10.1145/336595.336968
   McPherson M, 2001, ANNU REV SOCIOL, V27, P415, DOI 10.1146/annurev.soc.27.1.415
   Morry MM, 2010, J SOC PSYCHOL, V150, P369, DOI 10.1080/00224540903365471
   Novick D, 2017, INT C HUM COMP INT, P609, DOI DOI 10.1007/978-3-319-58071-5_46
   Novick D, 2014, LECT NOTES COMPUT SC, V8511, P472, DOI 10.1007/978-3-319-07230-2_45
   Ochs M, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2925993
   Partala T, 2004, P NORDCHI, P353, DOI DOI 10.1145/1028014.1028070
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Qiu LY, 2009, J MANAGE INFORM SYST, V25, P145, DOI 10.2753/MIS0742-1222250405
   Qiu LY, 2005, INT J HUM-COMPUT INT, V19, P75, DOI 10.1207/s15327590ijhc1901_6
   Ranjbartabar Hedieh, 2019, IEEE T AFFECTIVE COM
   Richards D, 2014, INT J HUM-COMPUT ST, V72, P460, DOI 10.1016/j.ijhcs.2014.01.005
   Ring L, 2015, J MULTIMODAL USER IN, V9, P79, DOI 10.1007/s12193-014-0157-0
   Ring L, 2013, INT CONF AFFECT, P61, DOI 10.1109/ACII.2013.17
   Rishe N, 2013, ACM TMIS, V4, P1, DOI [10.1145/2544103, DOI 10.1145/2544103]
   ROBERTS CS, 1994, CANCER, V74, P336, DOI 10.1002/cncr.2820741319
   Robinson H, 2017, HEALTH PSYCHOL, V36, P619, DOI 10.1037/hea0000492
   Romero O.J, 2017, P 26 INT JOINT C ART, P3807, DOI [10.24963/ijcai.2017/532, DOI 10.24963/IJCAI.2017/532]
   Roorda DL, 2011, REV EDUC RES, V81, P493, DOI 10.3102/0034654311421793
   Ryokai K, 2003, J COMPUT ASSIST LEAR, V19, P195, DOI 10.1046/j.0266-4909.2003.00020.x
   Sagar M, 2014, P SA 14 SIGGRAPH AS
   Schillinger D, 2004, PATIENT EDUC COUNS, V52, P315, DOI 10.1016/S0738-3991(03)00107-1
   Shamekhi A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173965
   Sidner CL, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3213050
   Stevens Catherine J, 2016, Comput Cogn Sci, V2, P1
   STEWART MA, 1995, CAN MED ASSOC J, V152, P1423
   Takashima K., 2008, GRAPH INTERFACE, P169, DOI [10.1145/1375714.1375744, DOI 10.1145/1375714.1375744]
   Tamayo S, 2012, 2012 INT S COMP ED S, P1
   Thompson L, 2012, BMC PSYCHIATRY, V12, DOI 10.1186/1471-244X-12-87
   Tickle-Degnen L, 1990, PSYCHOL INQ, V1, P285, DOI DOI 10.1207/S15327965PLI0104_
   Uchino BN, 2006, J BEHAV MED, V29, P377, DOI 10.1007/s10865-006-9056-5
   Uchino BN, 1996, PSYCHOL BULL, V119, P488, DOI 10.1037/0033-2909.119.3.488
   Valtorta NK, 2016, HEART, V102, P1009, DOI 10.1136/heartjnl-2015-308790
   Vasiljevs A, 2017, NEW CHALLENGES EC BU, P667
   Veritas Health Innovation, COV SYST REV SOFTW
   von der Piitten Astrid M., 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P183, DOI 10.1007/978-3-642-23974-8_20
   von der Putten AM, 2010, COMPUT HUM BEHAV, V26, P1641, DOI 10.1016/j.chb.2010.06.012
   Watson A, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.1629
NR 95
TC 10
Z9 10
U1 7
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1875-4791
EI 1875-4805
J9 INT J SOC ROBOT
JI Int. J. Soc. Robot.
PD DEC
PY 2020
VL 12
IS 6
SI SI
BP 1293
EP 1312
DI 10.1007/s12369-020-00680-7
EA SEP 2020
PG 20
WC Robotics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Robotics
GA PM7GX
UT WOS:000572613400002
DA 2022-08-02
ER

PT J
AU Sebastian, J
   Richards, D
AF Sebastian, Joel
   Richards, Deborah
TI Changing stigmatizing attitudes to mental health via education and
   contact with embodied conversational agents
SO COMPUTERS IN HUMAN BEHAVIOR
LA English
DT Article
DE Embodied conversational agents; Stigmatizing attitudes; Anorexia
   nervosa; Traditional stigma; Volitional stigma
ID EATING-DISORDER SYMPTOMS; ANOREXIA-NERVOSA; TREATMENT-SEEKING;
   MORTALITY-RATES; SOCIAL DISTANCE; ILLNESS STIGMA; PREVALENCE; COMMUNITY;
   INTERVENTIONS; LITERACY
AB Educating society concerning stigmatized conditions, such as the eating disorder Anorexia Nervosa (AN), aims to change attitudes that will encourage individuals with AN to recognize their condition and decide to seek help. Embodied Conversational Agents (ECAs) may play an important role in bringing about changes in attitude and behavior because they potentially allow tailored but anonymous, free and convenient access and can deliver the information in a conversational way that overcomes health literacy barriers. In this first study we compare the use of an ECA with a video to deliver two strategies (education and contact) to address stigma around the mental health condition of Anorexia Nervosa (AN). Our results with 245 participants show that both media (ECA and video) aided recognition of AN and produced significant changes in positive volitional stigma and negative volitional stigma but not in traditional stigma (desire for social distance), with some notable differences based on gender. Baseline data was used in place of a control group and the sample population was undergraduate Psychology students due to higher incidences of AN in this population. Further validation is needed involving a control group and testing on populations other than Psychology students. Nevertheless, these initial results encourage our future work to build tailored ECAs to challenge particular beliefs to support a wide range of educational interventions to change behaviors and improve decision-making relating to health and wellbeing. (C) 2017 Elsevier Ltd. All rights reserved.
C1 [Sebastian, Joel] Macquarie Univ, Dept Psychol, N Ryde, NSW 2109, Australia.
   [Richards, Deborah] Macquarie Univ, Dept Comp, N Ryde, NSW 2109, Australia.
RP Richards, D (corresponding author), Macquarie Univ, Dept Comp, N Ryde, NSW 2109, Australia.
EM joel.sebastion@students.mq.edu.au; deborah.richards@mq.edu.au
OI Richards, Deborah/0000-0002-7363-1511
CR Allport G. W., 1979, NATURE PREJUDICE BAS
   Andre E., 1998, P 2 INT C AUT AG
   Angermeyer MC, 2013, BRIT J PSYCHIAT, V203, P146, DOI 10.1192/bjp.bp.112.122978
   Arcelus J, 2011, ARCH GEN PSYCHIAT, V68, P724, DOI 10.1001/archgenpsychiatry.2011.74
   Association A. P., 2013, APA DICT CLIN PSYCH
   Aylett R., 2009, P 8 INT C AUT AG MUL, V1
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T, 2010, INT VIRT AG
   Bickmore T., 2015, INT VIRT AG
   Bickmore TW, 2013, PATIENT EDUC COUNS, V92, P142, DOI 10.1016/j.pec.2013.05.011
   Bickmore Timothy W., 2009, P SIGCHI C HUM FACT
   Carnell S., 2015, INT VIRT AG
   Cordar A., 2015, INT VIRT AG
   Corrigan PW, 2007, COMMUNITY MENT HLT J, V43, P171, DOI 10.1007/s10597-006-9061-8
   Corrigan PW, 2012, PSYCHIAT SERV, V63, P963, DOI 10.1176/appi.ps.201100529
   Corrigan PW, 2001, SCHIZOPHRENIA BULL, V27, P187, DOI 10.1093/oxfordjournals.schbul.a006865
   Corrigan PW, 2001, PSYCHIAT SERV, V52, P953, DOI 10.1176/appi.ps.52.7.953
   Crisafulli MA, 2008, INT J EAT DISORDER, V41, P333, DOI 10.1002/eat.20507
   Crisafulli MA, 2010, J SOC CLIN PSYCHOL, V29, P756, DOI 10.1521/jscp.2010.29.7.756
   Crisp AH, 2000, BRIT J PSYCHIAT, V177, P4, DOI 10.1192/bjp.177.1.4
   Darby AM, 2012, INT J EAT DISORDER, V45, P120, DOI 10.1002/eat.20886
   Dias J., 2007, I KNOW WHAT I DID LA
   Easter MM, 2012, SOC SCI MED, V75, P1408, DOI 10.1016/j.socscimed.2012.05.042
   Eisenberg D, 2011, J AM COLL HEALTH, V59, P700, DOI 10.1080/07448481.2010.546461
   Fernando R., 2009, AUTOMATED EXPLANATIO
   Fox J, 2009, MEDIA PSYCHOL, V12, P1, DOI 10.1080/15213260802669474
   Gratwick-Sarll K, 2014, EAT DISORD, V22, P405, DOI 10.1080/10640266.2014.925764
   Griffiths S, 2014, INT J EAT DISORDER, V47, P189, DOI 10.1002/eat.22220
   Halan S., 2015, INT VIRT AG
   Hart LM, 2011, CLIN PSYCHOL REV, V31, P727, DOI 10.1016/j.cpr.2011.03.004
   Hawkins RP, 2010, COMPUT HUM BEHAV, V26, P1081, DOI 10.1016/j.chb.2010.03.011
   Hinshaw SP, 2008, ANNU REV CLIN PSYCHO, V4, P367, DOI 10.1146/annurev.clinpsy.4.022007.141245
   Holmes EP, 1999, SCHIZOPHRENIA BULL, V25, P447, DOI 10.1093/oxfordjournals.schbul.a033392
   Jin SAA, 2010, COMPUT HUM BEHAV, V26, P443, DOI 10.1016/j.chb.2009.12.003
   Jorm AF, 1997, MED J AUSTRALIA, V166, P182, DOI 10.5694/j.1326-5377.1997.tb140071.x
   Jorm AF, 2012, AM PSYCHOL, V67, P231, DOI 10.1037/a0025957
   Li J, 2016, COMPUT HUM BEHAV, V55, P1222, DOI 10.1016/j.chb.2015.04.005
   Link BG, 2004, SCHIZOPHRENIA BULL, V30, P511, DOI 10.1093/oxfordjournals.schbul.a007098
   LINK BG, 1987, AM J SOCIOL, V92, P1461, DOI 10.1086/228672
   Magerko B, 2005, INT IND TRAIN SIM ED
   Martinez-Miranda J., 2014, INT VIRT AG
   Mast MS, 2007, PATIENT EDUC COUNS, V68, P16, DOI 10.1016/j.pec.2007.03.020
   Mond J., 2006, J MENTAL HLTH, V15, P519, DOI [10.1080/09638230600902559, DOI 10.1080/09638230600902559]
   Mond JM, 2012, AUST J PSYCHOL, V64, P108, DOI 10.1111/j.1742-9536.2011.00033.x
   Paiva A., 2004, P 3 INT JOINT C AUT, V1
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Person N.K., 2001, ARTIFICIAL INTELLIGE
   Pettigrew TF, 2008, EUR J SOC PSYCHOL, V38, P922, DOI 10.1002/ejsp.504
   Roehrig JP, 2010, INT J EAT DISORDER, V43, P671, DOI 10.1002/eat.20760
   Sapouna M, 2010, J CHILD PSYCHOL PSYC, V51, P104, DOI 10.1111/j.1469-7610.2009.02137.x
   Shi L., 2015, INT VIRT AG
   Smink FRE, 2012, CURR PSYCHIAT REP, V14, P406, DOI 10.1007/s11920-012-0282-y
   Stice E, 2013, J ABNORM PSYCHOL, V122, P445, DOI 10.1037/a0030679
   Vandereycken W, 2006, EUR EAT DISORD REV, V14, P341, DOI 10.1002/erv.721
   von dem Knesebeck O, 2013, PSYCHIAT RES, V209, P670, DOI 10.1016/j.psychres.2013.04.001
   von Holle A, 2008, AUST NZ J PSYCHIAT, V42, P108, DOI 10.1080/00048670701787610
   WEINER B, 1988, J PERS SOC PSYCHOL, V55, P738, DOI 10.1037/0022-3514.55.5.738
   Wingfield N, 2011, INT J EAT DISORDER, V44, P369, DOI 10.1002/eat.20824
   Yee Nick, 2006, P PRES, V24, P26
   Zwidkert K., 2013, J EATING DISORDERS, V1
NR 60
TC 22
Z9 23
U1 6
U2 30
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0747-5632
EI 1873-7692
J9 COMPUT HUM BEHAV
JI Comput. Hum. Behav.
PD AUG
PY 2017
VL 73
BP 479
EP 488
DI 10.1016/j.chb.2017.03.071
PG 10
WC Psychology, Multidisciplinary; Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA EY0CI
UT WOS:000403625400051
DA 2022-08-02
ER

PT J
AU Lee, S
   Jeon, J
AF Lee, Seongyong
   Jeon, Jaeho
TI Visualizing a disembodied agent: young EFL learners' perceptions of
   voice-controlled conversational agents as language partners
SO COMPUTER ASSISTED LANGUAGE LEARNING
LA English
DT Article; Early Access
DE Conversational agents; chatbots; anthropomorphism; EFL learners; learner
   perception
ID IDENTITIES; TEACHERS
AB Artificial agents, such as voice-controlled conversational agents (VCAs) built into smart devices, are becoming more prevalent in daily and educational contexts, enhancing the possibility of using them as language partners. However, research has primarily focused on the cognitive or affective outcomes of using these agents, overlooking questions about language learners' perceptions of agents as human-like conversational partners and about what aspects of agents generate the social interaction schema required for language learning. To address these gaps, this exploratory study examined to what extent EFL students perceived a VCA as a human-like language partner and what knowledge regarding language partners these students used to justify their perceptions. Sixty-seven Korean EFL students, all of them being nine years old, completed three interactional tasks with a VCA designed to act as a language partner. They then participated in a drawing task and in-depth interview implemented to explore students' perceptions toward the VCA as a language partner. Thematic analysis of students' drawings and interview transcripts found that the majority of students identified human elements in the VCA, perceiving it either as a human-like partner or as something between artifact and human. This strong tendency toward anthropomorphism indicates VCAs' great potential as interactive language partners in EFL contexts. Additionally, this study discusses the reasons for and implications of students' strong anthropomorphism tendency and how students used their knowledge regarding language partners to justify their VCA perceptions. Future recommendations for the use of VCAs were suggested from both pedagogical and technological standpoints.
C1 [Lee, Seongyong] Hannam Univ, English Educ, Daejeon, South Korea.
   [Jeon, Jaeho] Seoul Natl Univ Educ, English Educ, Seoul, South Korea.
RP Jeon, J (corresponding author), Seoul Natl Univ Educ, Seoul 06639, South Korea.
EM jaehojeon21@gmail.com
OI Lee, Seongyong/0000-0002-9436-4272; Jeon, Jaeho/0000-0002-1161-3676
CR ACTFL, 2012, ACTFL PROF
   Ahmadi A, 2017, COMPUT ASSIST LANG L, V30, P149, DOI 10.1080/09588221.2017.1284132
   Ahn SY, 2021, SYSTEM, V102, DOI 10.1016/j.system.2021.102598
   Ahn SY, 2018, APPL LINGUIST REV, V9, P225, DOI 10.1515/applirev-2016-1064
   Alemi M, 2020, LANG LEARN TECHNOL, V24, P86
   Atkinson RK, 2005, CONTEMP EDUC PSYCHOL, V30, P117, DOI 10.1016/j.cedpsych.2004.07.001
   Barnes BD, 2013, AUST J TEACH EDUC, V38, P19, DOI 10.14221/ajte.2013v38n2.2
   Baylor A. L., 2003, Journal of Educational Computing Research, V28, P373, DOI 10.2190/V0WQ-NWGN-JB54-FAT4
   Bibauw S, 2019, COMPUT ASSIST LANG L, V32, P827, DOI 10.1080/09588221.2018.1535508
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]
   Chen HHJ, 2020, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2020.1833043
   Chiou EK, 2020, COMPUT EDUC, V146, DOI 10.1016/j.compedu.2019.103756
   Craig SD, 2017, COMPUT EDUC, V114, P193, DOI 10.1016/j.compedu.2017.07.003
   Darvin R, 2015, ANNU REV APPL LINGUI, V35, P36, DOI 10.1017/S0267190514000191
   Davis RO, 2021, J RES TECHNOL EDUC, V53, P89, DOI 10.1080/15391523.2020.1830894
   Davis RO, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103605
   Divekar RR, 2021, COMPUT ASSIST LANG L, DOI 10.1080/09588221.2021.1879162
   Dizon G, 2021, RELC J, DOI 10.1177/00336882211020548
   Dizon G, 2020, LANG LEARN TECHNOL, V24, P16
   Druga S, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P595, DOI 10.1145/3078072.3084330
   Ellis R., 2003, TASK BASED LANGUAGE
   Epley N, 2007, PSYCHOL REV, V114, P864, DOI 10.1037/0033-295X.114.4.864
   Faranda W.T, 2004, J MARKETING ED, V26, P271, DOI DOI 10.1177/0273475304268782
   Fryer L, 2006, LANG LEARN TECHNOL, V10, P8
   Fryer LK, 2019, COMPUT HUM BEHAV, V93, P279, DOI 10.1016/j.chb.2018.12.023
   Girouard-Hallam LN, 2021, HUM BEHAV EMERG TECH, V3, P1118, DOI 10.1002/hbe2.321
   Heider F, 1944, AM J PSYCHOL, V57, P243, DOI 10.2307/1416950
   Hsu HL, 2021, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2021.2016864
   Jeon J, 2021, COMPUT ASSIST LANG L, DOI 10.1080/09588221.2021.2021241
   Jeon J, 2021, COMPUT ASSIST LANG L, DOI 10.1080/09588221.2021.1987272
   Kory-Westlund JM, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00081
   Lee S. W., 2019, 2019 IEEE INT C CONS, P1, DOI [DOI 10.1109/ICCE.2019.8662072, DOI 10.4271/2019-01-0253]
   Lee S, 2020, INT J HUM-COMPUT INT, V36, P930, DOI 10.1080/10447318.2019.1699748
   Mayer RE, 2003, J EDUC PSYCHOL, V95, P419, DOI 10.1037/0022-0663.95.2.419
   Mertala Pekka, 2019, International Journal of Child-Computer Interaction, V19, P56, DOI 10.1016/j.ijcci.2018.11.003
   Moussalli S, 2020, COMPUT ASSIST LANG L, V33, P865, DOI 10.1080/09588221.2019.1595664
   Park GP, 2006, ASIA PAC EDUC REV, V7, P236, DOI 10.1007/BF03031547
   RIPS LJ, 1975, J VERB LEARN VERB BE, V14, P665, DOI 10.1016/S0022-5371(75)80055-7
   Seneff S, 2004, 2004 INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, P341
   Sinatra AM, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106562
   Tai TY, 2020, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2020.1841801
   Tai TY, 2022, COMPUT ASSIST LANG L, DOI 10.1080/09588221.2022.2040536
   Vailshery L.S., 2021, NUMBER DIGITAL VOICE
   van den Berghe R, 2021, J COMPUT ASSIST LEAR, V37, P396, DOI 10.1111/jcal.12497
   Xu W, 2020, INT J QUAL METH, V19, DOI 10.1177/1609406920918810
   Xu Y, 2020, PROCEEDINGS OF IDC 2020, P216, DOI 10.1145/3392063.3394417
   Xu Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376416
NR 47
TC 0
Z9 0
U1 5
U2 5
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0958-8221
EI 1744-3210
J9 COMPUT ASSIST LANG L
JI Comput. Assist. Lang. Learn.
DI 10.1080/09588221.2022.2067182
EA APR 2022
PG 26
WC Education & Educational Research; Linguistics; Language & Linguistics
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Education & Educational Research; Linguistics
GA 1A9BZ
UT WOS:000792044000001
DA 2022-08-02
ER

PT C
AU Raju, A
   Hedayatnia, B
   Liu, L
   Gandhe, A
   Khatri, C
   Metallinou, A
   Venkatesh, A
   Rastrow, A
AF Raju, Anirudh
   Hedayatnia, Behnam
   Liu, Linda
   Gandhe, Ankur
   Khatri, Chandra
   Metallinou, Angeliki
   Venkatesh, Anu
   Rastrow, Ariya
GP Int Speech Commun Assoc
TI Contextual Language Model Adaptation for Conversational Agents
SO 19TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2018), VOLS 1-6: SPEECH RESEARCH FOR EMERGING
   MARKETS IN MULTILINGUAL SOCIETIES
SE Interspeech
LA English
DT Proceedings Paper
CT 19th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2018)
CY AUG 02-SEP 06, 2018
CL Hyderabad, INDIA
SP Int Speech Commun Assoc
DE speech recognition; language modeling; deep learning; weighted finite
   state transducers
AB Statistical language models (LM) play a key role in Automatic Speech Recognition (ASR) systems used by conversational agents. These ASR systems should provide a high accuracy under a variety of speaking styles, domains, vocabulary and argots. In this paper, we present a DNN-based method to adapt the LM to each user-agent interaction based on generalized contextual information, by predicting an optimal, context-dependent set of LM interpolation weights. We show that this framework for contextual adaptation provides accuracy improvements under different possible mixture LM partitions that are relevant for both (1) Goal-oriented conversational agents where it's natural to partition the data by the requested application and for (2) Non-goal oriented conversational agents where the data can be partitioned using topic labels that come from predictions of a topic classifier. We obtain a relative WER improvement of 3% with a 1-pass decoding strategy and 6% in a 2-pass decoding framework, over an unadapted model. We also show up to a 15% relative improvement in recognizing named entities which is of significant value for conversational ASR systems.
C1 [Raju, Anirudh; Hedayatnia, Behnam; Gandhe, Ankur; Khatri, Chandra; Metallinou, Angeliki; Venkatesh, Anu; Rastrow, Ariya] Amazon Alexa Machine Learning, Seattle, WA 98121 USA.
   [Liu, Linda] Univ Rochester, Rochester, NY 14627 USA.
RP Raju, A (corresponding author), Amazon Alexa Machine Learning, Seattle, WA 98121 USA.
EM ranirudh@amazon.com; behnam@amazon.com; aggandhe@amazon.com;
   ckhatri@amazon.com; ametalli@amazon.com; anuvenk@amazon.com;
   arastrow@amazon.com
CR Aleksic P, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P468
   Axelrod A., 2011, P 2011 C EMP METH NA, P355
   Ballinger B, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1812
   Bellegarda JR, 2000, P IEEE, V88, P1279, DOI 10.1109/5.880084
   Chen L., 2001, LANGUAGE MODEL ADAPT
   Clarkson PR, 1997, INT CONF ACOUST SPEE, P799, DOI 10.1109/ICASSP.1997.596049
   Gao J., 2006, COMP STUDY LANGUAGE, V5, P207
   Guo F., 2017, NIPS WORKSH CONV AI
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   Kneser R., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P586, DOI 10.1109/ICASSP.1993.319375
   Kneser R., 1997, EUROSPEECH
   Mikolov T., 2012, 2012 IEEE SPOK LANG
   Mohri M, 2002, COMPUT SPEECH LANG, V16, P69, DOI 10.1006/csla.2001.0184
   Pennington J, 2014, P EMNLP C, V2014, P1532
   Tam Y. C., 2005, P INTERSPEECH, P5
   Thadani K, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P210
   Visweswariah K., 2001, INTERSPEECH, P251
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wessel F., 1999, P ESCA WORKSH INT DI, P93
   Xu W., 2000, P ICSLP, P118
NR 20
TC 10
Z9 10
U1 0
U2 2
PU ISCA-INT SPEECH COMMUNICATION ASSOC
PI BAIXAS
PA C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE
SN 2308-457X
BN 978-1-5108-7221-9
J9 INTERSPEECH
PY 2018
BP 3333
EP 3337
DI 10.21437/Interspeech.2018-1122
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BM5PH
UT WOS:000465363900696
OA Green Submitted
DA 2022-08-02
ER

PT C
AU Morveli-Espinoza, M
   Puyol-Gruart, J
AF Morveli-Espinoza, Mariela
   Puyol-Gruart, Josep
BE Alsinet, T
   PuyolGruart, J
   Torras, C
TI On Partial Deduction and Conversational Agents
SO ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT
SE Frontiers in Artificial Intelligence and Applications
LA English
DT Proceedings Paper
CT 11th International Conference of the
   Catalan-Association-for-Artificial-Intelligence
CY OCT 22-24, 2008
CL St Marti Empuries, SPAIN
SP Catalan Assoc Artificial Intelligence, CSIC, iSOCO, Caixa Girona, Univ Empresa, Dept Innovacio, Strands, Empuries
DE Conversational agents; multi-agent systems; partial deduction;
   multiple-valued logic
ID SPECIALIZATION; COMMUNICATION
AB Agents are situated autonomous entities that perceive and act in their environment, and communicate with other agents. An agent usually starts a conversation by querying another agent because it needs to satisfy a specific goal. This process allocates a new goal to the agent receiving the initial query, starting new dialogs with other agents, generating a recursive interaction. The generation of this kind of dialog is interesting when the system has the possibility of generating conditional answers with imprecise and uncertain values. We consider simple deliberative rule-based agents that proactively try to satisfy their goals. The mechanism to achieve this dialogs is based in the specialization of the mental state of agents, by means of the partial deduction of rule bases.
C1 [Morveli-Espinoza, Mariela; Puyol-Gruart, Josep] Spanish Sci Res Council CSIC, Artificial Intelligence Res Inst IIIA, Campus UAB, Bellaterra 08193, Spain.
RP Puyol-Gruart, J (corresponding author), Spanish Sci Res Council CSIC, Artificial Intelligence Res Inst IIIA, Campus UAB, Bellaterra 08193, Spain.
EM puyol@iiia.csic.es
RI Puyol-Gruart, Josep/H-2474-2015
OI Puyol-Gruart, Josep/0000-0002-7264-8645; Morveli Espinoza,
   Mariela/0000-0002-7376-2271
FU Spanish projects IEA [TIN2006-15662-C02-01]; MULOG2
   [TIN2007-68005-C04-01]; Agreement Technologies [CON- SOLIDER
   CSD2007-0022, INGENIO 2010]; Programme Al an; European Union Programme
   of High Level Scholarships [E06D101440PE]
FX Authors acknowledge partial support by the Spanish projects IEA
   (TIN2006-15662-C02-01), MULOG2 (TIN2007-68005-C04-01) and Agreement
   Technologies (CON- SOLIDER CSD2007-0022, INGENIO 2010). Mariela
   Morveli-Espinoza is supported by the Programme Al an, the European Union
   Programme of High Level Scholarships for Latin America, scholarship
   No.(E06D101440PE). We would like to thank the referees for their
   valuable suggestions and comments.
CR Arcos JL, 2005, ENG APPL ARTIF INTEL, V18, P191, DOI 10.1016/j.engappai.2004.11.019
   Austin J. L., 1975, DO THINGS WORDS, VSecond
   Barbuceanu M, 2000, LECT NOTES ARTIF INT, V1916, P220
   Bentahar J, 2003, LECT NOTES ARTIF INT, V2922, P146
   BRENNAN SE, 1995, KNOWL-BASED SYST, V8, P143, DOI 10.1016/0950-7051(95)98376-H
   COLOMBETTI M, 2000, 4 INT C AUT AG, P21
   ENDRISS U, 2003, P IJCAI 2003
   *FIPA, 2002, COMM ACT LIB SPEC
   FLORES RA, 2001, AOSE, P50
   Fruhwirth T, 2005, LECT NOTES COMPUT SC, V3573, P133, DOI 10.1007/11506676_9
   Greaves M, 2000, LECT NOTES ARTIF INT, V1916, P118
   Iwanuma K, 2002, LECT NOTES ARTIF INT, V2424, P245, DOI 10.1007/3-540-45757-7_21
   LLOYD JW, 1991, J LOGIC PROGRAM, V11, P217, DOI 10.1016/0743-1066(91)90027-M
   PUYOL J, 1992, P 10 EUR C ART INT E, P144
   Puyol-Gruart J, 1998, INT J APPROX REASON, V18, P107, DOI 10.1016/S0888-613X(97)10006-8
   PUYOLGRUART J, 1997, MATHWARE SOFT COMPUT, V4, P299
   Rago F, 2006, LECT NOTES ARTIF INT, V2955, P46
   Russell S., 2010, ARTIF INTELL, V3
   SHOHAM Y, 1993, ARTIF INTELL, V60, P51, DOI 10.1016/0004-3702(93)90034-9
   [No title captured]
NR 20
TC 2
Z9 2
U1 0
U2 1
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 0922-6389
EI 1879-8314
BN 978-1-58603-925-7
J9 FRONT ARTIF INTEL AP
PY 2008
VL 184
BP 60
EP +
DI 10.3233/978-1-58603-925-7-60
PG 2
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BMP68
UT WOS:000273295000007
DA 2022-08-02
ER

PT C
AU Caballe, S
   Conesa, J
AF Caballe, Santi
   Conesa, Jordi
BE Xhafa, F
   Barolli, L
   Gregus, M
TI Conversational Agents in Support for Collaborative Learning in MOOCs: An
   Analytical Review
SO ADVANCES IN INTELLIGENT NETWORKING AND COLLABORATIVE SYSTEMS
SE Lecture Notes on Data Engineering and Communications Technologies
LA English
DT Proceedings Paper
CT 10th International Conference on Intelligent Networking and
   Collaborative Systems (INCoS)
CY SEP 05-07, 2018
CL Comenius Univ, Bratislava, SLOVAKIA
HO Comenius Univ
AB Massive Open Online Courses (MOOCs) arose as a way of transcending formal higher education by realizing technology-enhanced formats of learning and instruction and by granting access to a wide audience way beyond students enrolled in any one Higher Education Institution. However, while MOOCs have been reported as an efficient and important educational tool, yet there is a number of issues and problems related to their educational impact. More specifically, there is an important number of drop outs during a course, little participation, and lack of students' motivation and engagement overall. To overcome these limitations, Conversational pedagogical agents have arisen to guide and support student dialogue using natural language both in individual and collaborative settings. Conversational agents have been produced to meet a wide variety of applications and studies exploring the usage of such agents have led to positive results. Integrating this type of artificial agents into MOOCs is expected to trigger productive peer interaction in discussion groups. In this paper, we present a state-of-the-art study of the use of conversational agents to support collaborative learning in the context of MOOCs. The ultimate goal of this study is to analyze the potential of conversational agents to considerably increase the engagement and the commitment of MOOC students, reducing consequently, the overall MOOCs dropout rate. The research reported in this paper is currently undertaken within the research project colMOOC funded by the European Commission.
C1 [Caballe, Santi; Conesa, Jordi] Univ Oberta Catalunya, Fac Comp Sci Multimedia & Telecommun, Barcelona 08018, Spain.
RP Caballe, S (corresponding author), Univ Oberta Catalunya, Fac Comp Sci Multimedia & Telecommun, Barcelona 08018, Spain.
EM scaballe@uoc.edu; jconesac@uoc.edu
RI Caballé, Santi/F-7255-2010
OI Caballé, Santi/0000-0002-2490-6830
FU European Commission [588438-EPP-1-2017-1-EL-EPPKA2-KA]
FX This research was funded by the European Commission through the project
   "colMOOC: Integrating Conversational Agents and Learning Analytics in
   MOOCs" (588438-EPP-1-2017-1-EL-EPPKA2-KA).
CR Adamson D., 2014, INT J AI ED, V24, P91
   Aleven V, 2016, LECT NOTES COMPUT SC, V9684, P409, DOI 10.1007/978-3-319-39583-8_49
   Baneres D., 2016, 10 INT C COMPL INT S, P87
   Bassi R., 2014, OPEN ED RESOURCES IN, P5
   Baxter JA, 2014, INT REV RES OPEN DIS, V15
   Caballe S, 2014, J COMPUT ASSIST LEAR, V30, P51, DOI 10.1111/jcal.12021
   Caballe S, 2011, COMPUT HUM BEHAV, V27, P1372, DOI 10.1016/j.chb.2010.07.032
   Daradoumis T, 2013, 2013 EIGHTH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND INTERNET COMPUTING (3PGCIC 2013), P208, DOI 10.1109/3PGCIC.2013.37
   Demetriadis S, 2018, LECT NOTE DATA ENG, V17, P1061, DOI 10.1007/978-3-319-75928-9_98
   Dyke G., 2013, PRODUCTIVE MULTIVOCA, P459, DOI 10.1007/978-1-4614-8960-3_25
   Ferschke O., 2015, P 11 INT C COMP SUPP, P459
   Ferschke O, 2015, LECT NOTES ARTIF INT, V9112, P115, DOI 10.1007/978-3-319-19773-9_12
   Ganan D, 2015, INT J AP MAT COM-POL, V25, P361, DOI 10.1515/amcs-2015-0028
   Guardia L., 2013, ELEARN PAPERS, V33, P1
   JAQUES PA, 2002, P COMP SUPP COLL LEA, P546
   Kucirkova N, 2017, LEARN MEDIA TECHNOL, V42, P324, DOI 10.1080/17439884.2015.1054835
   Kumar R, 2011, IEEE T LEARN TECHNOL, V4, P21, DOI 10.1109/TLT.2010.41
   Mackness J., 2010, P 7 INT C NETWORKED, P266
   Oates BJ., 2006, RES INFORM SYSTEMS C
   Pane JF, 2014, EDUC EVAL POLICY AN, V36, P127, DOI 10.3102/0162373713507480
   Papazoglou MP, 2001, COMMUN ACM, V44, P71, DOI 10.1145/367211.367268
   Razmerita L., 2018, 51 HAW INT C SYST SC, P727
   Sanz A, 2013, 2013 17TH IEEE INTERNATIONAL SYMPOSIUM ON POWER LINE COMMUNICATIONS AND ITS APPLICATIONS (ISPLC), P285, DOI 10.1109/ISPLC.2013.6525865
   Shah D., 2018, CLASSCENTRAL
   Siemens G., 2013, OPEN ED RESOURCES IN, P5
   Tegos S, 2017, EDUC TECHNOL SOC, V20, P99
   Tegos S, 2015, COMPUT EDUC, V87, P309, DOI 10.1016/j.compedu.2015.07.014
   Tomar G. S., 2017, TRANSFORMING LEARNIN, V1, P607
NR 28
TC 9
Z9 9
U1 0
U2 5
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2367-4512
BN 978-3-319-98557-2
J9 LECT NOTE DATA ENG
PY 2019
VL 23
BP 384
EP 394
DI 10.1007/978-3-319-98557-2_35
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Engineering, Electrical & Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BN4JJ
UT WOS:000481989000035
DA 2022-08-02
ER

PT J
AU Hepenstal, S
   Zhang, LS
   Kodagoda, N
   Wong, BLW
AF Hepenstal, Sam
   Zhang, Leishi
   Kodagoda, Neesha
   Wong, B. L. William
TI Developing Conversational Agents for Use in Criminal Investigations
SO ACM TRANSACTIONS ON INTERACTIVE INTELLIGENT SYSTEMS
LA English
DT Article
DE Explainability; criminal intelligence analysis; conversational agents;
   transparency
ID MODEL; TRUST
AB The adoption of artificial intelligence (AI) systems in environments that involve high risk and high consequence decision-making is severely hampered by critical design issues. These issues include system transparency and brittleness, where transparency relates to (i) the explainability of results and (ii) the ability of a user to inspect and verify system goals and constraints; and brittleness, (iii) the ability of a system to adapt to new user demands. Transparency is a particular concern for criminal intelligence analysis, where there are significant ethical and trust issues that arise when algorithmic and system processes are not adequately understood by a user. This prevents adoption of potentially useful technologies in policing environments. In this article, we present a novel approach to designing a conversational agent (CA) AI system for intelligence analysis that tackles these issues. We discuss the results and implications of three different studies; a Cognitive Task Analysis to understand analyst thinking when retrieving information in an investigation, Emergent Themes Analysis to understand the explanation needs of different system components, and an interactive experiment with a prototype conversational agent. Our prototype conversational agent, named Pan, demonstrates transparency provision and mitigates brittleness by evolving new CA intentions. We encode interactions with the CA with human factors principles for situation recognition and use interactive visual analytics to support analyst reasoning. Our approach enables complex AI systems, such as Pan, to be used in sensitive environments, and our research has broader application than the use case discussed.
C1 [Hepenstal, Sam] Def Sci Technol Lab, Salisbury, Wilts, England.
   [Zhang, Leishi; Kodagoda, Neesha; Wong, B. L. William] Middlesex Univ London, London, England.
   [Hepenstal, Sam] Def Sci & Technol Lab, Salisbury SP4 0JQ, Wilts, England.
   [Zhang, Leishi; Kodagoda, Neesha; Wong, B. L. William] Middlesex Univ, London NW4 4BT, England.
RP Hepenstal, S (corresponding author), Def Sci Technol Lab, Salisbury, Wilts, England.; Hepenstal, S (corresponding author), Def Sci & Technol Lab, Salisbury SP4 0JQ, Wilts, England.
EM sh1966@live.mdx.ac.uk; L.X.Zhang@mdx.ac.uk; N.Kodagoda@mdx.ac.uk;
   w.wong@mdx.ac.uk
CR Andrews Simon, 2014, LECT NOTES COMPUT SC, V8132, DOI [10.1007/978-3-642-40769- 7_11, DOI 10.1007/978-3-642-40769-7_11]
   Ashby W. R., 1958, CYBERNETICA, V1, P83, DOI DOI 10.1007/978-1-4899-0718-9_28
   Bhattacharya R, 1998, ACAD MANAGE REV, V23, P459, DOI 10.2307/259289
   Blandford A, 2004, INT J HUM-COMPUT ST, V61, P421, DOI 10.1016/j.ijhcs.2003.12.012
   Card S. K., 1983, PSYCHOL HUMAN COMPUT
   Conneau A., 2017, P 2017 C EMPIRICAL M, P670, DOI DOI 10.18653/V1/D17-1070
   Ezer Neta, 2019, P HUM FACT ERG SOC M
   Garriga Gemma C., 2017, FORMAL CONCEPT ANAL, P522, DOI [10.1007/978-1-4899-7687-1_316, DOI 10.1007/978-1-4899-7687-1_316]
   Gerber M.., 2016, P HUMAN FACTORS ERGO, V60, P173, DOI [10.1177/1541931213601039, DOI 10.1177/1541931213601039]
   Gilpin L.H., 2018, EXPLAINING EXPLANATI
   Hepenstal S, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES COMPANION (IUI'20), P134, DOI 10.1145/3379336.3381463
   Hepenstal Sam, 2020, P 64 HUM FACT ERG SO
   Hepenstal Sam, 2019, P WORKSH ALG TRANSP
   Hepenstal Sam, 2020, CEUR WORKSHOP P
   Hepenstal Sam, 2019, P 63 HUM FACT ERG SO
   Hoffman Robert R., 2018, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V62, P197, DOI 10.1177/1541931218621047
   Jabin Suraiya, 2015, INT J NEW TECHNOL SC, V2, P3
   Kinsella Bret, 2019, NPR STUDY SAYS 118 M
   Kinsella Bret, 2018, AMAZON ECHO DEVICE S
   KLEIN GA, 1989, IEEE T SYST MAN CYB, V19, P462, DOI 10.1109/21.31053
   Klein G, 2006, IEEE INTELL SYST, V21, P88, DOI 10.1109/MIS.2006.100
   Klein Gary, 1993, DECISION MAK ACTION
   Klein Gary, 2017, SEEING WHAT OTHERS D
   Kodagoda Neesha, 2009, P HUM FACT ERG SOC M, V53, P319, DOI [10.1518/107118109X12524441080821, DOI 10.1518/107118109X12524441080821]
   Leslie David, 2019, ABS190605684 CORR
   Leventakis G, 2018, SPRINGERBRIEF CRIM, P1, DOI 10.1007/978-3-319-89297-9
   Liburmulu, 2019, INFORMASI RUTE T SEM
   Lipton Z.C., 2016, ARXIV160603490
   Marr Bernard, 2014, DEAR IKEA YOUR CUSTO
   McTear MF, 2002, ACM COMPUT SURV, V34, P90, DOI 10.1145/505282.505285
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P52
   Molnar C., 2019, INTERPRETABLE MACHIN, DOI 10.1007/s10290-014-0202-9
   NORMAN DA, 1983, COMMUN ACM, V26, P254, DOI 10.1145/2163.358092
   PENNINGTON N, 1992, J PERS SOC PSYCHOL, V62, P189, DOI 10.1037/0022-3514.62.2.189
   Preece A, 2017, IEEE T HUM-MACH SYST, V47, P1017, DOI 10.1109/THMS.2017.2700625
   Qazi N, 2016, IEEE SYS MAN CYBERN, P1917, DOI 10.1109/SMC.2016.7844519
   Radziwill Nicole M., 2017, ABS170404579 CORR
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Schaefer KE, 2016, HUM FACTORS, V58, P377, DOI 10.1177/0018720816634228
   Schuetzler RM, 2019, COMPUT HUM BEHAV, V97, P250, DOI 10.1016/j.chb.2019.03.033
   Seaborne A, 2007, SPARQL QUERY LANGUAG
   Shaw Danny, 2019, BBC
   Springer A, 2019, PROCEEDINGS OF IUI 2019, P107, DOI 10.1145/3301275.3302322
   Thomas J. J., 2005, ILLUMINATING PATH RE, P184, DOI [10.3389/fmicb.2011.00006, DOI 10.3389/FMICB.2011.00006]
   Toulmin S., 1958, USES ARGUMENT
   Wakefield J., 2016, BBC NEWS
   Weston J., 2019, ABS190208654 CORR
   Wolf CT, 2019, PROCEEDINGS OF IUI 2019, P252, DOI 10.1145/3301275.3302317
   Wong B.L.W., 2016, P HUMAN FACTORS ERGO, V60, P178, DOI [10.1177/1541931213601040, DOI 10.1177/1541931213601040]
   Wong B. L. William, 2003, CRITICAL DECISION ME, P327
   Wong BL, 2002, P HF2002 HUM FACT C
   Yang Y, 2006, ASMC PROC, P7
   Yevtushenko SA, 2000, P 7 NAT C ART INT, P127
   Yin Xiaoyu, 2019, NEURAL MACHINE TRANS
   Zhou Michelle X., 2019, P 24 INT C INT US IN, pi, DOI DOI 10.1145/3301275.3308445
NR 55
TC 0
Z9 0
U1 6
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 2160-6455
EI 2160-6463
J9 ACM T INTERACT INTEL
JI ACM Trans. Interact. Intell. Syst.
PD AUG
PY 2021
VL 11
IS 3-4
AR 25
DI 10.1145/3444369
PG 35
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA YY3EL
UT WOS:000754674100009
OA Green Accepted
DA 2022-08-02
ER

PT C
AU Iovine, A
AF Iovine, Andrea
GP ASSOC COMP MACHINERY
TI Conversational Agents for Recommender Systems
SO RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS
LA English
DT Proceedings Paper
CT 14th ACM Conference on Recommender Systems (RECSYS)
CY SEP 22-26, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery
DE conversational recommender systems; conversational agents; review-based
   recommender systems; interactive explanation; natural language
   processing
ID EXPLANATIONS; SUPPORT
AB In my Ph.D. work, my objective is to improve the state of the art in Conversational Recommender Systems, by proposing a model that closely follows the process that people enact when searching for products and services. Rich user profiles are elicited using natural language dialogue. Item descriptions will be extracted from a combination of structured and unstructured data such as user reviews. Natural language explanations will ensure that users can quickly understand the reasoning behind the recommendations. Interactive explanation will then allow them to further compare several alternatives. This extended abstract presents the motivations of my work, it details the research plan, and the research questions. Finally, it shows some preliminary results, and outlines the next steps for my Ph.D. program.
C1 [Iovine, Andrea] Univ Bari Aldo Moro, Bari, Italy.
RP Iovine, A (corresponding author), Univ Bari Aldo Moro, Bari, Italy.
EM andrea.iovine@uniba.it
CR Bogers T, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P238, DOI 10.1145/3109859.3109893
   Bostandjiev Svetlin, 2012, RECSYS 12 P 6 ACM C, P35
   Catherine R, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P288, DOI 10.1145/3109859.3109878
   Chen, 2020, ARXIV200400646
   Chen L, 2015, USER MODEL USER-ADAP, V25, P99, DOI 10.1007/s11257-015-9155-5
   Chen L, 2012, USER MODEL USER-ADAP, V22, P125, DOI 10.1007/s11257-011-9108-6
   Christakopoulou K, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P815, DOI 10.1145/2939672.2939746
   Ding Y, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3436
   DWeld Gagan, 2018, CHALLENGE CRAFTING I
   Elahi M, 2016, COMPUT SCI REV, V20, P29, DOI 10.1016/j.cosrev.2016.05.002
   Giannakopoulos A., 2017, P 8 WORKSH COMP APPR, P180
   Goodman B, 2017, AI MAG, V38, P50, DOI 10.1609/aimag.v38i3.2741
   He C, 2016, EXPERT SYST APPL, V56, P9, DOI 10.1016/j.eswa.2016.02.013
   Hone K. S., 2000, Natural Language Engineering, P287
   Iovine A, 2020, DECIS SUPPORT SYST, V131, DOI 10.1016/j.dss.2020.113250
   Jannach D, 2007, J WEB ENG, V6, P165
   Jannach Dietmar, 2016, INT C EL COMM WEB TE, P21
   Jugovac M, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/3001837
   Kang J, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P229, DOI 10.1145/3109859.3109873
   Kelly D, 2009, COMPUTER, V42, P60, DOI 10.1109/MC.2009.82
   Konstan JA, 2012, USER MODEL USER-ADAP, V22, P101, DOI 10.1007/s11257-011-9112-x
   Lamche B, 2014, JOINT WORKSH INT HUM, V14
   Lei WQ, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P304, DOI 10.1145/3336191.3371769
   Li P, 2019, RECSYS 2019: 13TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P428, DOI 10.1145/3298689.3347068
   Li X., 2017, P 2017 C EMP METH NA, P2886
   Li X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4194
   Liu Hanxiao, 2018, DARTS DIFFERENTIABLE
   Luo HS, 2019, IEEE-ACM T AUDIO SPE, V27, P1201, DOI 10.1109/TASLP.2019.2913094
   Musto C, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P321, DOI 10.1145/3109859.3109905
   Nunes I, 2017, USER MODEL USER-ADAP, V27, P393, DOI 10.1007/s11257-017-9195-0
   Ouyang S., 2018, ARXIV PREPRINT ARXIV
   Pu Pearl, 2010, USER CENTRIC EVALUAT, V612, P8
   Rafailidis D, 2019, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, MINING AND SEMANTICS (WIMS 2019), DOI 10.1145/3326467.3326468
   Ricci F, 2007, IEEE INTELL SYST, V22, P22, DOI 10.1109/MIS.2007.43
   Shalom OS, 2019, RECSYS 2019: 13TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P353, DOI 10.1145/3298689.3347061
   Smyth Barry, 2003, 14 IR ART INT COGN S
   Sun YM, 2018, ACM/SIGIR PROCEEDINGS 2018, P235, DOI 10.1145/3209978.3210002
   Suzuki T, 2018, IEEE INT CONF BIG DA, P3549, DOI 10.1109/BigData.2018.8622439
   Tintarev N, 2011, RECOMMENDER SYSTEMS HANDBOOK, P479, DOI 10.1007/978-0-387-85820-3_15
   Tintarev N, 2007, I C DATA ENGIN WORKS, P801, DOI 10.1109/ICDEW.2007.4401070
   Tong S., 2001, ACTIVE LEARNING THEO, V1
   Warnestal Pontus, 2005, P 4 IJCAI WORKSH KNO, P32
   Worndl Wolfgang, 2015, i-com: A Journal of Interactive and Cooperative Media, V14, P19, DOI 10.1515/icom-2015-0007
   Ye H, 2017, LECT NOTES ARTIF INT, V10235, P350, DOI 10.1007/978-3-319-57529-2_28
   Zhang YF, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P177, DOI 10.1145/3269206.3271776
   Zheng L, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P425, DOI 10.1145/3018661.3018665
NR 46
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-7583-2
PY 2020
BP 758
EP 763
DI 10.1145/3383313.3411453
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS6JF
UT WOS:000748895000126
DA 2022-08-02
ER

PT J
AU Hayashi, Y
AF Hayashi, Yugo
TI Multiple pedagogical conversational agents to support learner-learner
   collaborative learning: Effects of splitting suggestion types
SO COGNITIVE SYSTEMS RESEARCH
LA English
DT Article
DE Pedagogical conversational agents; Collaborative learning;
   Communication; Explanation Activities; Role-playing
AB This study experimentally investigated the design of effective interactions using pedagogical conversational agents (PCAs) in a learner-learner collaborative learning activity. While dyads engaged in a concept explanation task (explaining the mechanism of computer processing), PCAs served as facilitators and provided metacognitive suggestions to better improve learning performance. Previous studies have shown that learners who received several types of suggestions from multiple PCAs were motivated to produce effective explanations; this study then further explored the effects of using multiple PCAs in different roles, providing different types of facilitation. It was predicted that by using two different PCAs to offer suggestions with a delay, learners may be able to process information more efficiently, for example by paying closer attention to each type of suggestion. To investigate this possibility, two types of facilitating content, namely provision of metacognitive suggestions and advice on effective coordination, were each implemented into two role-playing PCAs, named the "explanation adviser" and the "communication adviser" respectively. The results show that when learners used PCAs playing different roles and offering suggestions corresponding to these roles, learners generated explanations related to the suggestions and improved performance (efficacy of explanations) in several areas, including learning performance, for example better understanding the concept and becoming able to explain it using a greater range of technical words. This study shows empirically how multiple PCAs can be effectively designed to implement roles yielding different types of suggestions. The advantages of using such methods and implementing such functions of PCAs are further discussed. (C) 2018 Published by Elsevier B.V.
C1 [Hayashi, Yugo] Ritsumeikan Univ, Coll Comprehens Psychol, 2-150 Iwakura Cho, Ibaraki, Osaka 5678570, Japan.
RP Hayashi, Y (corresponding author), Ritsumeikan Univ, Coll Comprehens Psychol, 2-150 Iwakura Cho, Ibaraki, Osaka 5678570, Japan.
EM yhayashi@fc.ritsumei.ac.jp
OI Hayashi, Yugo/0000-0003-2438-3109
FU JSPS KAKENHI [16K00219]
FX This work was supported by JSPS KAKENHI Grant No. 16K00219.
CR Aleven V, 2009, IEEE T LEARN TECHNOL, V2, P64, DOI 10.1109/TLT.2009.22
   Anderson JR, 1995, J LEARN SCI, V4, P167, DOI 10.1207/s15327809jls0402_2
   Beal CR, 2007, J INTERACT ONLINE LE, V6, P43
   Beck JE, 1998, LECT NOTES COMPUT SC, V1452, P6
   Becker-Beck U, 2005, SMALL GR RES, V36, P499, DOI 10.1177/1046496405277182
   Biswas G, 2005, APPL ARTIF INTELL, V19, P363, DOI 10.1080/08839510590910200
   CHI MTH, 1994, COGNITIVE SCI, V18, P439, DOI 10.1016/0364-0213(94)90016-7
   Craig SD, 2006, COGNITION INSTRUCT, V24, P565, DOI 10.1207/s1532690xci2404_4
   D'Mello SK, 2008, USER MODEL USER-ADAP, V18, P45, DOI 10.1007/s11257-007-9037-6
   Fiore SM, 2010, HUM FACTORS, V52, P203, DOI 10.1177/0018720810369807
   Graesser A., 2013, ACM T INTERACT INTEL, V2, P1, DOI DOI 10.1145/2395123.2395128
   Graesser A., 2017, OECD SERIES, P245
   Graesser A. C, 2017, GRANTEE SUBMISSION, V119, P1
   Graesser AC, 2005, IEEE T EDUC, V48, P612, DOI 10.1109/TE.2005.856149
   Hayashi Yugo, 2012, Intelligent Tutoring Systems. Proceedings 11th International Conference (ITS 2012), P22, DOI 10.1007/978-3-642-30950-2_3
   Hayashi Y., 2015, IEICE T FUND ELECTR, V98, P76
   Hayashi Y, 2013, LEARNER SUPPORT AGEN
   Hayashi Y., 2006, P 28 ANN C COGN SCI, P333
   Hayashi Y, 2018, COGNITIVE SCI, V42, P69, DOI 10.1111/cogs.12587
   Hayashi Y, 2016, IEICE T INF SYST, VE99D, P1455, DOI 10.1587/transinf.2015CBP0005
   Hayashi Y, 2014, LECT NOTES COMPUT SC, V8474, P114, DOI 10.1007/978-3-319-07221-0_14
   Hesse F., 2015, ASSESSMENT TEACHING, P37
   Holmes J, 2007, COMPUT EDUC, V48, P523, DOI 10.1016/j.compedu.2005.02.007
   JOHNSTON WA, 1976, J EXP PSYCHOL-HUM L, V2, P153
   Kim Y, 2005, INT J ARTIFICIAL INT, V15, P95, DOI [DOI 10.1007/BF02504991, DOI 10.1145/1067860.1067867]
   King P. E., 2000, COMMUNICATION ED, V49
   Koedinger K. R., 1997, INT J ARTIFICIAL INT, V8, P30, DOI DOI 10.1007/s40593-015-0082-8
   Kumar R, 2011, IEEE T LEARN TECHNOL, V4, P21, DOI 10.1109/TLT.2010.41
   Lave J., 1991, SITUATED LEARNING LE, DOI DOI 10.1017/CBO9780511815355
   Lee EJ, 2002, HUM COMMUN RES, V28, P349, DOI 10.1111/j.1468-2958.2002.tb00812.x
   Leelawong Krittaya, 2008, INT J ARTIFICIAL INT, V18, P181
   MADIGAN SA, 1969, J VERB LEARN VERB BE, V8, P828, DOI 10.1016/S0022-5371(69)80050-2
   Matsuda N, 2013, INT J ARTIF INTELL E, V23, P1, DOI 10.1007/s40593-013-0009-1
   Mayer E. R., 2010, APPL SCI LEARNING
   Mcnamara D. S., 2007, ISTART WEB BASED TUT
   Millis K., 2011, SERIOUS GAMES EDUTAI, P169, DOI DOI 10.1007/978-1-4471-2161-9_10
   MIYAKE N, 1986, COGNITIVE SCI, V10, P151, DOI 10.1016/S0364-0213(86)80002-7
   O'Neil HF, 2010, COMPUTER-BASED DIAGNOSTICS AND SYSTEMATIC ANALYSIS OF KNOWLEDGE, P261, DOI 10.1007/978-1-4419-5662-0_14
   Organisation For Economic Co-Operation Development, 2017, PISA 2015 RES STUD W
   Roberge ME, 2010, HUM RESOUR MANAGE R, V20, P295, DOI 10.1016/j.hrmr.2009.09.002
   Rose C, 2008, INT J COMP-SUPP COLL, V3, P237, DOI 10.1007/s11412-007-9034-0
   Rummel N, 2005, J LEARN SCI, V14, P201, DOI 10.1207/s15327809jls1402_2
   SWELLER J, 1990, J EXP PSYCHOL GEN, V119, P176, DOI 10.1037/0096-3445.119.2.176
   van Dick R, 2008, HUM RELAT, V61, P1463, DOI 10.1177/0018726708095711
   van Knippenberg D, 2007, ANNU REV PSYCHOL, V58, P515, DOI 10.1146/annurev.psych.58.110405.085546
   Vygotsky L. S., 1980, DEV HIGHER PSYCHOL P
NR 46
TC 4
Z9 4
U1 0
U2 18
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1389-0417
J9 COGN SYST RES
JI Cogn. Syst. Res.
PD MAY
PY 2019
VL 54
BP 246
EP 257
DI 10.1016/j.cogsys.2018.04.005
PG 12
WC Computer Science, Artificial Intelligence; Neurosciences; Psychology,
   Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Neurosciences & Neurology; Psychology
GA HH5BM
UT WOS:000455740800019
DA 2022-08-02
ER

PT J
AU Diederich, S
   Brendel, AB
   Kolbe, LM
AF Diederich, Stephan
   Brendel, Alfred Benedikt
   Kolbe, Lutz M.
TI Designing Anthropomorphic Enterprise Conversational Agents
SO BUSINESS & INFORMATION SYSTEMS ENGINEERING
LA English
DT Article
DE Conversational agent; Anthropomorphism; Social response theory; Theory
   of uncanny valley; Design science research
ID SOCIAL RESPONSES; SCIENCE RESEARCH; TECHNOLOGY; SYSTEMS; ACCEPTANCE;
   TRUST; PERSONALIZATION; PERCEPTION; POLITENESS; CUES
AB The increasing capabilities of conversational agents (CAs) offer manifold opportunities to assist users in a variety of tasks. In an organizational context, particularly their potential to simulate a human-like interaction via natural language currently attracts attention both at the customer interface as well as for internal purposes, often in the form of chatbots. Emerging experimental studies on CAs look into the impact of anthropomorphic design elements, so-called social cues, on user perception. However, while these studies provide valuable prescriptive knowledge of selected social cues, they neglect the potential detrimental influence of the limited responsiveness of present-day conversational agents. In practice, many CAs fail to continuously provide meaningful responses in a conversation due to the open nature of natural language interaction, which negatively influences user perception and often led to CAs being discontinued in the past. Thus, designing a CA that provides a human-like interaction experience while minimizing the risks associated with limited conversational capabilities represents a substantial design problem. This study addresses the aforementioned problem by proposing and evaluating a design for a CA that offers a human-like interaction experience while mitigating negative effects due to limited responsiveness. Through the presentation of the artifact and the synthesis of prescriptive knowledge in the form of a nascent design theory for anthropomorphic enterprise CAs, this research adds to the growing knowledge base for designing human-like assistants and supports practitioners seeking to introduce them into their organizations.
C1 [Diederich, Stephan; Brendel, Alfred Benedikt; Kolbe, Lutz M.] Univ Gottingen, Chair Informat Management, Pl Gottinger Sieben 5, D-37073 Gottingen, Germany.
RP Diederich, S (corresponding author), Univ Gottingen, Chair Informat Management, Pl Gottinger Sieben 5, D-37073 Gottingen, Germany.
EM stephan.diederich@stud.uni-goettingen.de; abrendel@uni-goettingen.de;
   lkolbe@uni-goettingen.de
CR Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Bartneck C, 2009, INT J SOC ROBOT, V1, P71, DOI 10.1007/s12369-008-0001-3
   Baskerville R, 2010, BUS INFORM SYST ENG+, V2, P271, DOI 10.1007/s12599-010-0118-4
   Ben Mimoun MS, 2012, J RETAIL CONSUM SERV, V19, P605, DOI 10.1016/j.jretconser.2012.07.006
   Boudreau MC, 2001, MIS QUART, V25, P1, DOI 10.2307/3250956
   Brynjolfsson E, 2016, 2 MACHINE AGE WORK P
   Burmester M., 2019, P ACM CHI C HUM FACT, P1
   Cafaro A, 2016, ACM T COMPUT INTERAC, V24, P1
   Chandra L, 2015, P ANN HICSS, P4039, DOI 10.1109/HICSS.2015.485
   Chattaraman V, 2019, COMPUT HUM BEHAV, V90, P315, DOI 10.1016/j.chb.2018.08.048
   Cowell AJ, 2005, INT J HUM-COMPUT ST, V62, P281, DOI 10.1016/j.ijhcs.2004.11.008
   Cyr D, 2009, MIS QUART, V33, P539
   Davenport TH, 2016, MIT SLOAN MANAGE REV, V57, P21
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   de Visser EJ, 2016, J EXP PSYCHOL-APPL, V22, P331, DOI 10.1037/xap0000092
   Diederich S., 2019, 14 INT C WIRTSCH, P1550
   Diederich S, 2019, P EUROPEAN C INFORM
   Diederich S., 2019, P INT C INF SYST ICI
   Dzindolet MT, 2003, INT J HUM-COMPUT ST, V58, P697, DOI 10.1016/S1071-5819(03)00038-7
   Elson JS, 2018, P HAW INT C SYST SCI, P430
   Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009
   Folstad A., 2017, INTERACTIONS, V24, P38, DOI [10.1145/3085558, DOI 10.1145/3085558]
   Gefen D, 1997, MIS QUART, V21, P389, DOI 10.2307/249720
   Gefen D., 2003, E SERVICE, V2, P7, DOI [DOI 10.2979/ESJ.2003.2.2.7, https://doi.org/10.2979/esj.2003.2.2.7]
   Gefen D, 2005, COMMUN ASSOC INF SYS, V16, P91, DOI 10.17705/1CAIS.01605
   Gnewuch U., 2018, P EUROPEAN C INFORM
   Gnewuch U., 2017, P 38 INT C INF SYST
   Go E, 2019, COMPUT HUM BEHAV, V97, P304, DOI 10.1016/j.chb.2019.01.020
   Gong L, 2008, COMPUT HUM BEHAV, V24, P1494, DOI 10.1016/j.chb.2007.05.007
   Gregor S, 2007, J ASSOC INF SYST, V8, P312, DOI 10.17705/1jais.00129
   Gregor S, 2013, MIS QUART, V37, P337, DOI 10.25300/MISQ/2013/37.2.01
   Gregory RW, 2014, INFORM SYST RES, V25, P639, DOI 10.1287/isre.2014.0533
   Hevner A. R., 2007, SCANDINAVIAN J INFOR, V19, P87
   Hevner A, 2019, BUS INFORM SYST ENG+, V61, P3, DOI 10.1007/s12599-018-0571-z
   Hevner AR, 2004, MIS QUART, V28, P75, DOI 10.2307/25148625
   Holtgraves T, 2007, BEHAV RES METHODS, V39, P156, DOI 10.3758/BF03192855
   Iivari J, 2015, EUR J INFORM SYST, V24, P107, DOI 10.1057/ejis.2013.35
   Junglas I, 2013, J ASSOC INF SYST, V14, P585
   Knijnenburg BP, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2963106
   Komiak SYX, 2006, MIS QUART, V30, P941
   Koufaris M, 2002, INFORM SYST RES, V13, P205, DOI 10.1287/isre.13.2.205.83
   Kuechler William, 2008, Journal of Design Research, V7, P1, DOI 10.1504/JDR.2008.019897
   Kumar R, 2018, P ACM CHI C HUM FACT
   Lee SY, 2017, INT J HUM-COMPUT ST, V103, P95, DOI 10.1016/j.ijhcs.2017.02.005
   Liao QV, 2018, P ACM CHI C HUM FACT
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   MacDorman K.F., 2006, P ICCS COGSCI 2006 L
   MacDorman KF, 2009, COMPUT HUM BEHAV, V25, P695, DOI 10.1016/j.chb.2008.12.026
   Maedche A, 2016, BUS INFORM SYST ENG+, V58, P367, DOI 10.1007/s12599-016-0444-2
   Mayer RE, 2006, INT J HUM-COMPUT ST, V64, P36, DOI 10.1016/j.ijhcs.2005.07.001
   McQuiggan SW, 2007, INT J HUM-COMPUT ST, V65, P348, DOI 10.1016/j.ijhcs.2006.11.015
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   Morana S., 2017, BUS INFORM SYST ENG+, V9, P42, DOI [https://doi.org/10.1007/s35764-017-0101-7, DOI 10.1007/S35764-017-0101-7]
   Mori M., 1970, ENERGY
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Mosier KL, 1996, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY - 40TH ANNUAL MEETING, VOLS 1 AND 2, P204
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nunamaker JE, 2011, J MANAGE INFORM SYST, V28, P17, DOI 10.2753/MIS0742-1222280102
   Peffers K, 2018, EUR J INFORM SYST, V27, P129, DOI 10.1080/0960085X.2018.1458066
   Pfeuffer N., 2019, BUSINESS INFORM SYST, P1
   Powers A, 2006, P 2006 ACM C HUM ROB
   Qiu LY, 2010, INT J HUM-COMPUT ST, V68, P669, DOI 10.1016/j.ijhcs.2010.05.005
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Saffarizadeh K., 2017, P INT C INF SYST ICI
   Schroeder J, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P472
   Schuetzler RM, 2018, P AM C INF SYST AMIC
   Schuetzler RM, 2014, P INT C INF SYST ICI
   Seeger A.-M., 2018, ICIS 2018 P
   Seeger A-M, 2017, SPECIAL INTEREST GRO
   Seidel S, 2018, EUR J INFORM SYST, V27, P221, DOI 10.1057/s41303-017-0039-0
   Seymour M, 2018, J ASSOC INF SYST, V19, P953, DOI 10.17705/1jais.00515
   Stock RM, 2018, P INT C INF SYST ICI
   Tinwell A, 2014, COMPUT HUM BEHAV, V36, P286, DOI 10.1016/j.chb.2014.03.073
   Toxtli C, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173632
   Urbach N., 2010, J INF TECHNOL THEORY, V11, P5, DOI DOI 10.1037/0021-9010.90.4.710
   Venable J, 2016, EUR J INFORM SYST, V25, P77, DOI 10.1057/ejis.2014.36
   Verhagen T, 2014, J COMPUT-MEDIAT COMM, V19, P529, DOI 10.1111/jcc4.12066
   Walls JG, 1992, INFORM SYST RES, V3, P36, DOI 10.1287/isre.3.1.36
   Wang N, 2008, INT J HUM-COMPUT ST, V66, P98, DOI 10.1016/j.ijhcs.2007.09.003
   Wiese E, 2020, INT J HUM-COMPUT ST, V133, P1, DOI 10.1016/j.ijhcs.2019.08.002
   Wunderlich NV, 2017, P INT C INF SYST ICI
   Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496
NR 83
TC 21
Z9 21
U1 12
U2 31
PU SPRINGER VIEWEG-SPRINGER FACHMEDIEN WIESBADEN GMBH
PI WIESBADEN
PA ABRAHAM-LINCOLN STASSE 46, WIESBADEN, 65189, GERMANY
SN 2363-7005
EI 1867-0202
J9 BUS INFORM SYST ENG+
JI Bus. Inf. Syst. Eng.
PD JUN
PY 2020
VL 62
IS 3
BP 193
EP 209
DI 10.1007/s12599-020-00639-y
PG 17
WC Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA LV2DM
UT WOS:000538250200002
OA hybrid, Green Published
DA 2022-08-02
ER

PT J
AU Bailly, G
   Raidt, S
   Elisei, F
AF Bailly, Gerard
   Raidt, Stephan
   Elisei, Frederic
TI Gaze, conversational agents and face-to-face communication
SO SPEECH COMMUNICATION
LA English
DT Article
DE Conversational agents; Face-to-face communication; Gaze
ID PERCEPTION; ATTENTION; DIRECTION; EYES
AB In this paper, we describe two series of experiments that examine audiovisual face-to-face interaction between naive human viewers and either a human interlocutor or a virtual conversational agent. The main objective is to analyze the interplay between speech activity and mutual gaze patterns during mediated face-to-face interactions. We first quantify the impact of deictic gaze patterns of our agent. We further aim at refining our experimental knowledge on mutual gaze patterns during human face-to-face interaction by using new technological devices such as non-invasive eye trackers and pinhole cameras, and at quantifying the impact of a selection of cognitive states and communicative functions on recorded gaze patterns. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Bailly, Gerard; Raidt, Stephan; Elisei, Frederic] Univ Grenoble, Speech & Cognit Dept, GIPSA Lab, CNRS,UMR 5216, Grenoble, France.
RP Bailly, G (corresponding author), Univ Grenoble, Speech & Cognit Dept, GIPSA Lab, CNRS,UMR 5216, Grenoble, France.
EM gerard.bailly@gipsa-lab.grenoble-inp.fr
RI bailly, gerard/ABI-2468-2020
OI bailly, gerard/0000-0002-6053-0818
FU Rhone-Alpes region
FX We thank our colleague and target speaker Helene Loevenbruck for her
   incredible patience and complicity. We also thank all of our subjects -
   the ones whose data have been used here and the others whose data have
   been corrupted by deficiencies of recording devices. Edouard Gentaz has
   helped us in statistical processing. This paper benefited from the
   pertinent suggestions of the two anonymous reviewers. We thank Peter F.
   Dominey and Marion Dohen for the proofreading. This project has been
   financed by the project Presence of the cluster ISLE of the Rhone-Alpes
   region.
CR [Anonymous], 2000, P EYE TRACKING RES A, DOI [DOI 10.1145/355017.355028, 10.1145/355017.355028]
   Argyle M., 1976, GAZE MUTUAL GAZE
   Bailly G., 2003, International Journal of Speech Technology, V6, P331, DOI 10.1023/A:1025700715107
   BAILLY G, 2005, HUMAN COMPUTER INTER
   BARONCOHEN S, 1985, COGNITION, V21, P37, DOI 10.1016/0010-0277(85)90022-8
   Benoit C, 1996, SPEECH COMMUN, V18, P381, DOI 10.1016/0167-6393(96)00026-X
   Blais C, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003022
   BREAZEAL C, 2000, THESIS MIT BOSTON
   Buchan JN, 2007, SOC NEUROSCI-UK, V2, P1, DOI 10.1080/17470910601043644
   Buchan JN, 2008, BRAIN RES, V1242, P162, DOI 10.1016/j.brainres.2008.06.083
   Carpenter M, 2000, COMM LANG INTERVEN, V9, P31
   Cassell J., 2000, EMBODIED CONVERSATIO
   CASTIELLO U, 1991, BRAIN, V114, P2639, DOI 10.1093/brain/114.6.2639
   Chen M., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P49
   Driver J, 1999, VIS COGN, V6, P509, DOI 10.1080/135062899394920
   DUNCAN S, 1972, J PERS SOC PSYCHOL, V23, P283, DOI 10.1037/h0033031
   ELISEI F, 2007, EYEGAZE AWARE ANAL S, P120
   EVINGER C, 1994, EXP BRAIN RES, V100, P337
   FUJIE S, 2005, BACK CHANNEL FEEDBAC, P889
   GEIGER G, 2003, PERCEPTUAL EVALUATIO, P224
   Giles H., 1979, LANGUAGE SOCIAL PSYC
   GOODWIN C, 1980, SOCIOL INQ, V50, P272, DOI 10.1111/j.1475-682X.1980.tb00023.x
   HADDINGTON P, 2002, STUDIA LINGUSITICA L, P107
   Itti L, 2003, PROC SPIE, V5200, P64, DOI 10.1117/12.512618
   Kaur M., 2003, P 5 INT C MULT INT I, P151
   KENDON A, 1967, ACTA PSYCHOL, V26, P22, DOI 10.1016/0001-6918(67)90005-4
   Langton SRH, 1999, VIS COGN, V6, P541, DOI 10.1080/135062899394939
   Langton SRH, 2000, TRENDS COGN SCI, V4, P50, DOI 10.1016/S1364-6613(99)01436-9
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   Leslie, 1994, MAPPING MIND DOMAIN, P119, DOI DOI 10.1017/CBO9780511752902.006
   Lewkowicz DJ, 1996, J EXP PSYCHOL HUMAN, V22, P1094, DOI 10.1037/0096-1523.22.5.1094
   Matsusaka Y, 2003, IEICE T INF SYST, VE86D, P26
   Miller LM, 2005, J NEUROSCI, V25, P5884, DOI 10.1523/JNEUROSCI.0896-05.2005
   MORGAN JL, 1996, SIGNAL SYNTAX OVERVI
   NOVICK DG, 1996, COORDINATING TURN TA
   OS ED, 2005, SPEECH COMMUN, V47, P194
   Peters C, 2005, LECT NOTES ARTIF INT, V3661, P229
   Peters C, 2003, ATTENTION DRIVEN EYE
   Picot A, 2007, LECT NOTES ARTIF INT, V4722, P272
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   POSNER MI, 1990, ANNU REV NEUROSCI, V13, P25, DOI 10.1146/annurev.ne.13.030190.000325
   Pourtois G, 2004, EUR J NEUROSCI, V20, P3507, DOI 10.1111/j.1460-9568.2004.03794.x
   Povinelli RJ, 2003, IEEE T KNOWL DATA EN, V15, P339, DOI 10.1109/TKDE.2003.1185838
   PREMACK D, 1978, BEHAV BRAIN SCI, V1, P515, DOI 10.1017/S0140525X00076512
   RAIDT S, 2008, THESIS I NATL POLYTE, P175
   RAIDT S, 2006, LANG RESS EV C LREC, P2544
   REVERET L, 2000, INT C SPEECH LANG PR, P755
   Riva G., 2003, BEING THERE CONCEPTS
   Rochet-Capellan A, 2008, J SPEECH LANG HEAR R, V51, P1507, DOI 10.1044/1092-4388(2008/07-0173)
   RUTTER DR, 1987, DEV PSYCHOL, V23, P54, DOI 10.1037/0012-1649.23.1.54
   Scassellati B. M., 2001, FDN THEORY MIND HUMA
   Thorisson KR, 2002, TEXT SPEECH LANG TEC, V19, P173
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   WALLBOTT HG, 1991, J PERS SOC PSYCHOL, V61, P147, DOI 10.1037/0022-3514.61.1.147
   Yarbus A. L., 1967, EYE MOVEMENTS VISION, P171, DOI [10.1007/978-1-4899-5379-7, DOI 10.1007/978-1-4899-5379-7]
NR 55
TC 51
Z9 51
U1 2
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-6393
EI 1872-7182
J9 SPEECH COMMUN
JI Speech Commun.
PD JUN
PY 2010
VL 52
IS 6
SI SI
BP 598
EP 612
DI 10.1016/j.specom.2010.02.015
PG 15
WC Acoustics; Computer Science, Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Acoustics; Computer Science
GA 604MB
UT WOS:000278282000013
OA Green Submitted
DA 2022-08-02
ER

PT C
AU Lacobelli, F
   Cassell, J
AF Lacobelli, Francisco
   Cassell, Justine
BE Pelachaud, C
   Martin, JC
   Andre, E
   Chollet, G
   Karpouzis, K
   Pele, D
TI Ethnic identity and engagement in embodied conversational agents
SO INTELLIGENT VIRTUAL AGENTS, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 7th International Conference on Intelligent Virtual Agents
CY SEP 17-19, 2007
CL Paris, FRANCE
SP &ftgroup France Telecom, European Project IST FP6 Callas, Springer, Assoc Advancement Artificial Intelligence, Eurograph, FP6 IST Humaine Network Excellence, ACM SIGCHI, ACM SIGART, Univ Paris 8, LIMSI-CNRS, Univ Augsburg, ENST, Natl Tech Univ Athens, France Telecom
DE virtual peers; embodied conversational agents; culture; ethnicity
AB In this paper we present the design, development and initial evaluation of a virtual peer that models ethnicity through culturally authentic verbal and non-verbal behaviors. The behaviors chosen for the implementation come from an ethnographic study with African-American and Caucasian children and the evaluation of the virtual peer consists of a study in which children interacted with an African American or a Caucasian virtual peer and then assessed its ethnicity. Results suggest that it may be possible to tip the ethnicity of a embodied conversational agent by changing verbal and nonverbal behaviors instead of surface attributes, and that children engage with those virtual peers in ways that have promise for educational applications.
C1 [Lacobelli, Francisco; Cassell, Justine] Northwestern Univ, Frances Searle Bldg 2-343-2240 Campus Dr, Evanston, IL 60208 USA.
RP Lacobelli, F (corresponding author), Northwestern Univ, Frances Searle Bldg 2-343-2240 Campus Dr, Evanston, IL 60208 USA.
EM f-iacobelli@northwestern.edu; justine@northwestern.edu
RI Cassell, Justine/B-7123-2009
FU National Science Foundation
FX We thank Andrea Tartaro, Joris Janssen, Nathan Cantelmo, Deb Zutty and
   the other members of the Articulab for their help. This study was made
   possible by grants from the National Science Foundation.
CR BAYLOR A, 2003, P EL WORLD C EL CORP
   BIGLER RS, 1993, CHILD DEV, V64, P1507, DOI 10.2307/1131549
   Cassell J, 2004, J APPL DEV PSYCHOL, V25, P75, DOI 10.1016/j.appdev.2003.11.003
   CASSELL J, 2007, VIRTUAL PEERS LITERA, P39
   Cassell J., 2001, PERSONAL TECHNOLOGIE, V5, P203
   Craig H. K., 2005, MALIK GOES SCH EXAMI
   ECKERT P, 2005, VARIATIONS CONVENTIO
   Gould S. J., 1981, MISMEASURE MAN
   HAYESROTH B, 2002, P IMAGINA 2002 M CAR
   Maldonado H, 2004, AGENT CULTURE, P143
   Nass C, 2000, EMBODIED CONVERSATIONAL AGENTS, P374
   WANG A, 2003, VIENN WORKSH 03 ED A
NR 12
TC 30
Z9 31
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-540-74996-7
J9 LECT NOTES ARTIF INT
PY 2007
VL 4722
BP 57
EP +
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BGR56
UT WOS:000250108100006
DA 2022-08-02
ER

PT J
AU Martinez-Miranda, J
AF Martinez-Miranda, Juan
TI Embodied Conversational Agents for the Detection and Prevention of
   Suicidal Behaviour: Current Applications and Open Challenges
SO JOURNAL OF MEDICAL SYSTEMS
LA English
DT Article
DE Suicide prevention; Embodied conversational agents; Mental healthcare;
   Literature review
ID RISK-ASSESSMENT; VIRTUAL AGENT; DEPRESSION; INTERVENTIONS; PROGRAMS;
   SYSTEM
AB Embodied conversational agents (ECAs) are advanced computational interactive interfaces designed with the aim to engage users in the continuous and long-term use of a background application. The advantages and benefits of these agents have been exploited in several e-health systems. One of the medical domains where ECAs are recently applied is to support the detection of symptoms, prevention and treatment of mental health disorders. As ECAs based applications are increasingly used in clinical psychology, and due that one fatal consequence of mental health problems is the commitment of suicide, it is necessary to analyse how current ECAs in this clinical domain support the early detection and prevention of risk situations associated with suicidality. The present work provides and overview of the main features implemented in the ECAs to detect and prevent suicidal behaviours through two scenarios: ECAs acting as virtual counsellors to offer immediate help to individuals in risk; and ECAs acting as virtual patients for learning/training in the identification of suicide behaviours. A literature review was performed to identify relevant studies in this domain during the last decade, describing the main characteristics of the implemented ECAs and how they have been evaluated. A total of six studies were included in the review fulfilling the defined search criteria. Most of the experimental studies indicate promising results, though these types of ECAs are not yet commonly used in routine practice. The identification of some open challenges for the further development of ECAs within this domain is also discussed.
C1 [Martinez-Miranda, Juan] CONACYT Ctr Invest Cient & Educ Super Ensenada, Unidad Transferencia Tecnol, Tepic, Mexico.
RP Martinez-Miranda, J (corresponding author), CONACYT Ctr Invest Cient & Educ Super Ensenada, Unidad Transferencia Tecnol, Tepic, Mexico.
EM jmiranda@cicese.mx
RI Martínez-Miranda, Juan/ABB-7942-2020
OI Martínez-Miranda, Juan/0000-0001-5081-8212
FU Mexican National Research Council (CONACyT) [2016-1-273,163]
FX This study was funded by the Mexican National Research Council (CONACyT
   grant number 2016-1-273,163).
CR Albright Glenn, 2016, Mhealth, V2, P44, DOI 10.21037/mhealth.2016.11.02
   Bagley SC, 2010, SUICIDE LIFE-THREAT, V40, P257, DOI 10.1521/suli.2010.40.3.257
   Bartgis J, 2016, AM INDIAN ALASKA NAT, V23, P1, DOI 10.5820/aian.2302.2016.1
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T, 2010, HARVARD REV PSYCHIAT, V18, P119, DOI 10.3109/10673221003707538
   Bickmore TW, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5239
   Breso A, 2016, EXPERT SYST, V33, P297, DOI 10.1111/exsy.12151
   Breso A, 2016, INT J HUM-COMPUT ST, V87, P80, DOI 10.1016/j.ijhcs.2015.11.003
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Burton C, 2016, J TELEMED TELECARE, V22, P348, DOI 10.1177/1357633X15609793
   Core M, 2006, SIMUL-T SOC MOD SIM, V82, P685, DOI 10.1177/0037549706075542
   Cummins N, 2015, SPEECH COMMUN, V71, P10, DOI 10.1016/j.specom.2015.03.004
   DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061
   Fleming TM, 2017, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00215
   Foster A, 2015, ACAD PSYCHIATR, V39, P620, DOI 10.1007/s40596-014-0185-9
   Gebhard P, 2008, LECT NOTES COMPUT SC, V5208, P426
   Isern D, 2016, J MED SYST, V40, DOI 10.1007/s10916-015-0376-2
   Kavakli M, 2012, J INTEGR DES PROCESS, V16, P5, DOI 10.3233/jid-2012-0004
   Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x
   Lisetti C, 2008, P CHI 2008 C WORKSH, P1
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   Luxton D.D., 2015, CURR TREAT OPT PSYCH, V2, P349, DOI DOI 10.1007/S40501-015-0057-2
   Manning L, 2012, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND EVALUATION, P185
   Martinez-Miranda Juan, 2014, Emotion Modeling. Towards Pragmatic Computational Models of Affective Processes. LNCS 8750, P115, DOI 10.1007/978-3-319-12973-0_7
   Martinez-Miranda J., 2008, P 7 C AUT AG MULT SY, V3, P1277
   Martinez-Miranda J, 2017, LECT NOTES ARTIF INT, V10233, P361, DOI 10.1007/978-3-319-57351-9_41
   Mateas M, 2003, GAM DEV C GDC 03
   May A, 2011, ASSESSMENT, V18, P379, DOI 10.1177/1073191110374285
   Micoulaud-Franchi JA, 2016, LECT NOTES ARTIF INT, V10011, P416, DOI 10.1007/978-3-319-47665-0_45
   MILLER WR, 1983, BEHAV PSYCHOTHER, V11, P147, DOI 10.1017/S0141347300006583
   Milner A, 2015, HEALTH PROMOT INT, V30, P29, DOI 10.1093/heapro/dau085
   O'Dea Bridianne, 2015, Internet Interventions, V2, P183, DOI 10.1016/j.invent.2015.03.005
   Perry Y, 2016, J CAN ACAD CHILD ADO, V25, P73
   Perry Y, 2015, TRIALS, V16, DOI 10.1186/s13063-015-0929-1
   Pontier M, 2008, LECT NOTES COMPUT SC, V5208, P417
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Ring L, 2016, P ACM SIGCHI C HUM F
   Rizzoa AA, 2011, STUD HEALTH TECHNOL, V163, P503, DOI 10.3233/978-1-60750-706-2-503
   Robinson J, 2016, EARLY INTERV PSYCHIA, V10, P28, DOI 10.1111/eip.12137
   Robinson J, 2013, CRISIS, V34, P164, DOI 10.1027/0227-5910/a000168
   Savage JM, 2015, COMM COM INF SC, V529, P703, DOI 10.1007/978-3-319-21383-5_119
   Scherer K. R., 2001, APPRAISAL PROCESSES
   Scherer S, 2013, INT CONF ACOUST SPEE, P709, DOI 10.1109/ICASSP.2013.6637740
   Silverman B G, 2001, Health Care Manag Sci, V4, P213, DOI 10.1023/A:1011448916375
   van Merrienboer JJG, 2005, EDUC PSYCHOL REV, V17, P147, DOI 10.1007/s10648-005-3951-0
   Witt K, 2017, AM J IND MED, V60, P394, DOI 10.1002/ajim.22676
   WOOLDRIDGE M, 1995, KNOWL ENG REV, V10, P115, DOI 10.1017/S0269888900008122
   World Health Organization, 2017, WORLD HLTH STAT 2017
   Yellowlees PM, 2012, TELEMED E-HEALTH, V18, P558, DOI 10.1089/tmj.2011.0195
   Zhang LY, 2014, IEEE INFOCOM SER, P549, DOI 10.1109/INFOCOM.2014.6847979
   Zhang Z, 2014, LECT NOTES ARTIF INT, V8637, P504, DOI 10.1007/978-3-319-09767-1_61
   [No title captured]
NR 52
TC 17
Z9 17
U1 0
U2 22
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0148-5598
EI 1573-689X
J9 J MED SYST
JI J. Med. Syst.
PD SEP
PY 2017
VL 41
IS 9
AR 135
DI 10.1007/s10916-017-0784-6
PG 14
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA FD6XA
UT WOS:000407670000007
PM 28755270
DA 2022-08-02
ER

PT C
AU Akahori, W
   Miyake, A
   Sugiyama, H
   Watanabe, M
   Minami, H
AF Akahori, Wataru
   Miyake, Asuka
   Sugiyama, Hiroaki
   Watanabe, Masahiro
   Minami, Hiroya
GP Assoc Comp Machinery
TI Paired Conversational Agents for Easy-to-Understand Instruction
SO CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI
   CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY MAY 04-09, 2019
CL Glasgow, SCOTLAND
SP Assoc Comp Machinery, ACM SIGCHI
DE conversational agent; paired agents; instruction; smart speaker
AB Conversational agents such as those hosted by the 'smart speakers' have become popular over the last few years. Although users can accomplish tasks as if they were asking a person, users still have problems in utilizing conversational agents effectively. To address this problem, some proposals explain how to input agent requests by using visual information such as instruction manuals and displays. However, such instructions create problems such as occupying the hands and eyes. The purpose of this study is to effectively enhance request entry by issuing instructions for use in an easy-to-understand manner without using visual information. Our proposal uses a pair of conversational agents, one is called the main agent, and the other is called the sub-agent, that have different voice types. Experiments show that agent pairing yields easier to understand instructions than using just the main agent. Furthermore, experiments also show that use instructions are easier to understand if the sub-agent reads aloud specific examples of use.
C1 [Akahori, Wataru; Miyake, Asuka; Watanabe, Masahiro; Minami, Hiroya] NTT Serv Evolut Labs, Tokyo, Japan.
   [Sugiyama, Hiroaki] NTT Commun Sci Labs, Tokyo, Japan.
RP Akahori, W (corresponding author), NTT Serv Evolut Labs, Tokyo, Japan.
EM wataru.akahori.cd@hco.ntt.co.jp; asuka.miyake.zw@hco.ntt.co.jp;
   hiroaki.sugiyama.kf@hco.ntt.co.jp; masahiro.watanabe.xd@hco.ntt.co.jp;
   hiroya.minami.gs@hco.ntt.co.jp
CR Baylor AL, 2003, FR ART INT, V97, P377
   HART S G, 1988, P139
   Hojo N, 2018, IEICE T INF SYST, VE101D, P462, DOI 10.1587/transinf.2017EDP7165
   Kubota H, 2002, T JAPANESE SOC ARTIF, V17, P313
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/0033-295X.101.2.343
   Porcheron M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174214
   Swartout W, 2010, LECT NOTES ARTIF INT, V6356, P286, DOI 10.1007/978-3-642-15892-6_30
NR 8
TC 0
Z9 0
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5971-9
PY 2019
DI 10.1145/3290607.3312794
PG 6
WC Computer Science, Cybernetics; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BN4JW
UT WOS:000482042102146
DA 2022-08-02
ER

PT S
AU Kronlid, F
AF Kronlid, Fredrik
BE Klusch, M
   Rovatsos, M
   Payne, TR
TI Turn taking for artificial conversational agents
SO COOPERATIVE INFORMATION AGENTS X, PROCEEDINGS
SE LECTURE NOTES IN COMPUTER SCIENCE
LA English
DT Article; Proceedings Paper
CT 10th International Workshop on Cooperative Information Agents
CY SEP 11-13, 2006
CL Edinburgh, SCOTLAND
SP Natl eSci Ctr, Univ Edinburgh, Ctr Intelligent Syst & Their Applicat, Whitestein Technol, British Soc Study Artificial Intelligence & Simulat Behav, IEEE Comp Soc Standards Org Comm FIPA Intelligent & Phys Agents
ID ORGANIZATION
AB In this paper we describe the design of a turn manager for deployment in artificial conversational agents, using the Harel statechart formalism. We show that the formalism's support for concurrent interrelated processes allows a modular design, producing three smaller statecharts responsible for the turn taking logic. The logic of the turn manager is inspired by a well-known. turn management model for human-human conversation.
C1 Univ Gothenburg, Grad Sch Language Technol, S-40530 Gothenburg, Sweden.
   Univ Gothenburg, Dept Linguist, S-40530 Gothenburg, Sweden.
RP Kronlid, F (corresponding author), Univ Gothenburg, Grad Sch Language Technol, Box 200, S-40530 Gothenburg, Sweden.
EM kronlid@ling.gu.se
CR Barnett J., STATE CHART XML SCXM
   Cassell J., 2000, IUI 2000. 2000 International Conference on Intelligent User Interfaces, P52
   EDLUND J, 2005, COMPUTER STUDIES LAN, V8, P576
   HAREL D, 1987, SCI COMPUT PROGRAM, V8, P231, DOI 10.1016/0167-6423(87)90035-9
   HULSTIJN J, 2003, TURNTAKING CASE AGEN
   KRONLID F, THESIS GOTEBORG U
   Ricordel P.-M., 1999, 1 INT WORKSH CENTR E, P203
   SACKS H, 1974, LANGUAGE, V50, P696, DOI 10.2307/412243
   Schegloff EA, 2000, LANG SOC, V29, P1, DOI 10.1017/S0047404500001019
   Tryphonas, 2004, VOICE EXTENSIBLE MAR
NR 10
TC 6
Z9 6
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-38569-X
J9 LECT NOTES COMPUT SC
PY 2006
VL 4149
BP 81
EP 95
PG 15
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BFB83
UT WOS:000240907300007
DA 2022-08-02
ER

PT J
AU Hadfi, R
   Haqbeen, J
   Sahab, S
   Ito, T
AF Hadfi, Rafik
   Haqbeen, Jawad
   Sahab, Sofia
   Ito, Takayuki
TI Argumentative Conversational Agents for Online Discussions
SO JOURNAL OF SYSTEMS SCIENCE AND SYSTEMS ENGINEERING
LA English
DT Article
DE Artificial intelligence; conversational agents; natural language
   processing; online discussion; computational social science
AB Artificial Intelligence is revolutionising our communication practices and the ways in which we interact with each other. This revolution does not only impact how we communicate, but it affects the nature of the partners with whom we communicate. Online discussion platforms now allow humans to communicate with artificial agents in the form of socialbots. Such agents have the potential to moderate online discussions and even manipulate and alter public opinions. In this paper, we propose to study this phenomenon using a constructed large-scale agent platform. At the heart of the platform lies an artificial agent that can moderate online discussions using argumentative messages. We investigate the influence of the agent on the evolution of an online debate involving human participants. The agent will dynamically react to their messages by moderating, supporting, or attacking their stances. We conducted two experiments to evaluate the platform while looking at the effects of the conversational agent. The first experiment is a large-scale discussion with 1076 citizens from Afghanistan discussing urban policy-making in the city of Kabul. The goal of the experiment was to increase the citizen involvement in implementing Sustainable Development Goals. The second experiment is a small-scale debate between a group of 16 students about globalisation and taxation in Myanmar. In the first experiment, we found that the agent improved the responsiveness of the participants and increased the number of identified ideas and issues. In the second experiment, we found that the agent polarised the debate by reinforcing the initial stances of the participant.
C1 [Hadfi, Rafik; Sahab, Sofia; Ito, Takayuki] Kyoto Univ, Dept Social Informat, Sakyo Ward, Yoshidahonmachi, Kyoto 6068501, Japan.
   [Haqbeen, Jawad] Nagoya Inst Technol, Showa Ku, Gokiso Cho, Nagoya, Aichi 4668555, Japan.
RP Hadfi, R (corresponding author), Kyoto Univ, Dept Social Informat, Sakyo Ward, Yoshidahonmachi, Kyoto 6068501, Japan.
EM rafik.hadfi@i.kyoto-u.ac.jp; jawad.haqbeen@itolab.nitech.ac.jp;
   sahab.sofia.4h@kyoto-u.ac.jp; ito@i.kyoto-u.ac.jp
RI Haqbeen, Jawad/R-6205-2019
OI Hadfi, Rafik/0000-0003-2352-1936; Sahab, Sofia/0000-0002-5822-5021;
   Haqbeen, Jawad/0000-0002-0481-0196
FU JST CREST [JPMJCR15E1]
FX The authors would like to thank the anonymous reviewers for their
   helpful comments. This work was supported by JST CREST Grant Number
   JPMJCR15E1, Japan.
CR Al-Zubaide H., 2011, INT S INN INF COMM T
   Amgoud L, 2008, INT J INTELL SYST, V23, P1062, DOI 10.1002/int.20307
   Amgoud L., 2000, EUR C ART INT ECAI20
   Bail CA, 2018, P NATL ACAD SCI USA, V115, P9216, DOI 10.1073/pnas.1804840115
   Baroni P, 2007, ARTIF INTELL, V171, P675, DOI 10.1016/j.artint.2007.04.004
   Bistarelli S, 2017, 2017 AEIT INTERNATIONAL ANNUAL CONFERENCE
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacl_a_00051]
   Csaky R., 2019, ARXIV PREPRINT ARXIV, V1908, P08835
   DUNG PM, 1995, ARTIF INTELL, V77, P321, DOI 10.1016/0004-3702(94)00041-X
   Ferrara Emilio, 2018, First Monday, V22, DOI 10.5210/fm.v22i18.8005
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Haqbeen J., 2020, P 8 ACM COLL INT C
   Hongshen Chen, 2017, ACM SIGKDD Explorations Newsletter, V19, P25, DOI 10.1145/3166054.3166058
   Iandoli L., 2007, MIT SLOAN RES PAPER
   Ito T., 2014, COLLECTIVE INTELLIGE
   Ito T., 2019, 7 ACM COLLECTIVE INT
   Ito T, 2015, COLLECTIVE INTELLIGE
   Keuschnigg M, 2018, J COMPUT SOC SCI, V1, P3, DOI 10.1007/s42001-017-0006-5
   Kolko J., 2012, WICKED PROBLEMS PROB
   Kunz W., 1970, ISSUES ELEMENTS INFO, V131
   Lagasquie-Schiex, 2005, C SYMB QUANT APPR RE
   Malone TW, 2018, SUPERMINDS SURPRISIN
   Malone TW., 2007, INNOVATIONS TECHNOLO, V2, P15, DOI DOI 10.1162/ITGG.2007.2.3.15
   Nofal S., 2019, 11 INT C KNOWL ENG O
   Nuez Ezquerra A, 2018, THESIS U POLITECNICA
   Ozer M., 2019, P ACM C C 17
   Parsons, 1997, P AAAI SPRING S QUAL
   Rao MK, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON ADVANCED INFORMATICS FOR COMPUTING RESEARCH (ICAICR '19), DOI 10.1145/3339311.3339335
   Savaget P, 2019, SCI PUBL POLICY, V46, P369, DOI 10.1093/scipol/scy064
   Shao CC, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06930-7
   Stella M, 2018, P NATL ACAD SCI USA, V115, P12435, DOI 10.1073/pnas.1803470115
   Sunstein CR., 2001, ECHOCHAMBERS BUSH GO
   Suzuki S., 2019, ANN C JAP SOC ART IN
   Varol Onur, 2017, ARXIV170303107
   Wallace R.S., 2009, PARSING TURING TEST
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wittig M., 2016, AMAZON WEB SERVICES
   Woolley AW, 2010, SCIENCE, V330, P686, DOI 10.1126/science.1193147
   Yan Z, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4618
NR 39
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1004-3756
EI 1861-9576
J9 J SYST SCI SYST ENG
JI J. Syst. Sci. Syst. Eng.
PD AUG
PY 2021
VL 30
IS 4
BP 450
EP 464
DI 10.1007/s11518-021-5497-1
EA MAY 2021
PG 15
WC Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Operations Research & Management Science
GA TZ1BL
UT WOS:000653624800002
PM 34054250
OA Bronze, Green Published
DA 2022-08-02
ER

PT C
AU Scotti, V
   Tedesco, R
   Sbattella, L
AF Scotti, Vincenzo
   Tedesco, Roberto
   Sbattella, Licia
BE Unger, H
   Kim, J
   Kang, U
   SoIn, C
   Du, J
   Saad, W
   Ha, YG
   Wagner, C
   Bourgeois, J
   Sathitwiriyawong, C
   Kwon, HY
   Leung, C
TI A Modular Data-Driven Architecture for Empathetic Conversational Agents
SO 2021 IEEE INTERNATIONAL CONFERENCE ON BIG DATA AND SMART COMPUTING
   (BIGCOMP 2021)
SE International Conference on Big Data and Smart Computing
LA English
DT Proceedings Paper
CT IEEE International Conference on Big Data and Smart Computing (BigComp)
CY JAN 17-20, 2021
CL SOUTH KOREA
SP IEEE, IEEE Comp Soc, Korean Inst Informat Scientists & Engineers
DE Empathetic Computing; Conversational Agents; Deep Learning
AB Empathy is a fundamental mechanism of human interactions. As such, it should he an integral part of Human Computer Interaction systems to make them more relatable. With this work, we focused on conversational scenarios where integrating empathy is crucial to perceive the computer like a human. As a result, we derived the high-level architecture of an Empathetic Conversational Agent we are willing to implement. We relied on theories about artificial empathy to derive the function approximating this mechanism and selected the conversational aspects to control for an empathetic interaction. In particular, we designed a core empathetic controller manages the empathetic responses, predicting, at each turn, the high-level content of the response. The derived architecture integrates empathy in a task-agnostic manner; hence we can employ it in multiple scenarios by changing the objective of the controller.
C1 [Scotti, Vincenzo; Tedesco, Roberto; Sbattella, Licia] Politecn Milan, DEIB, Milan, Italy.
RP Scotti, V (corresponding author), Politecn Milan, DEIB, Milan, Italy.
EM vincenzo.scotti@polimi.it; roberto.tedesco@polimi.it;
   licia.sbattella@polimi.it
RI Tedesco, Roberto/GMW-8169-2022
OI TEDESCO, ROBERTO/0000-0002-2830-4247; Scotti,
   Vincenzo/0000-0002-8765-604X
FU European Union's Horizon 2020 project "WorkingAge" [826232]
FX Partially supported by the European Union's Horizon 2020 project
   "WorkingAge" (grant agreement No. 826232).
CR Asada M, 2015, INT J SOC ROBOT, V7, P19, DOI 10.1007/s12369-014-0253-z
   Aytar Y., 2016, ADV NEURAL INFORM PR, P892, DOI DOI 10.1109/CVPR.2016.18
   Baevski A., 2020, WAV2VEC 2 0 FRAMEWOR
   Dathathri S., 2020, PLUG PLAY LANGUAGE M
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Huang M., ACM T INF SYST, V38
   Jurafsky D., 2009, SPEECH LANGUAGE PROC
   Lin Z., 2020, CAIRE EMPATHETIC NEU
   Liu Q., 2020, A SURVEY CONTEXTUAL
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Oord A.V. D., 2016, ARXIV
   Paiva A, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2912150
   Picard R.W., 2000, AFFECTIVE COMPUTING
   Rae J. W., 2019, COMPRESSIVE TRANSFOR
   Sankar C, 2019, 20TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2019), P1
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   Shuster K., 2020, DIALOGUE DODECATHLON
   Suni A., 2020, 10 INT C SPEECH PROS
   Sutskever I., 2014, ADV NEURAL INFORM PR, P3104
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Wang A, 2019, P NEURIPS, P3266
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Xue LM, 2018, PROCEEDINGS OF THE JOINT WORKSHOP OF THE 4TH WORKSHOP ON AFFECTIVE SOCIAL MULTIMEDIA COMPUTING AND FIRST MULTI-MODAL AFFECTIVE COMPUTING OF LARGE-SCALE MULTIMEDIA DATA (ASMMC-MMAC'18), P15, DOI 10.1145/3267935.3267947
   Yalcin O. N, 2018, SER ICMI 18, P546
   Zhou H, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P730
NR 25
TC 0
Z9 0
U1 4
U2 4
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2375-933X
BN 978-1-7281-8924-6
J9 INT CONF BIG DATA
PY 2021
BP 365
EP 368
DI 10.1109/BigComp51126.2021.00080
PG 4
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR6NJ
UT WOS:000662199000071
OA Green Submitted
DA 2022-08-02
ER

PT C
AU Heudin, JC
AF Heudin, Jean-Claude
BE Filipe, J
   Fred, A
TI A SCHIZOPHRENIC APPROACH FOR INTELLIGENT CONVERSATIONAL AGENTS
SO ICAART 2011: PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON AGENTS
   AND ARTIFICIAL INTELLIGENCE, VOL 2
LA English
DT Proceedings Paper
CT 3rd International Conference on Agents and Artificial Intelligence
CY JAN 28-30, 2011
CL Rome, ITALY
SP Inst Syst & Technol Informat Control & Commun
DE Conversational agent; Intelligent agent; Multi-agent; Schizophrenic
   model
AB We present a novel approach for creating intelligent conversational agents based on a "schizophrenic" model implemented using the EVA (Evolutionary Virtual Agent) nano-agent architecture. The Ms House experiment developed using this approach is compared with Eliza and the Alice chatterbot.
C1 [Heudin, Jean-Claude] Int Inst Multimedia Leonard de Vinci, Imedialab, Paris, France.
RP Heudin, JC (corresponding author), Int Inst Multimedia Leonard de Vinci, Imedialab, Paris, France.
EM Jean-claude.heudin@devinci.fr
CR Allen J., 2001, AI MAGAZINE, V22
   [Anonymous], 2005, P 4 INT JOINT C AUT, DOI DOI 10.1145/1082473.1082478
   Baker J. E., 1987, Genetic Algorithms and their Applications: Proceedings of the Second International Conference on Genetic Algorithms, P14
   CASSEL J, 2000, EMBODIED CONVERSATIO
   CLINGER W, 1991, REVISED 4 REPORT ALG
   DIGMAN JM, 1990, ANNU REV PSYCHOL, V41, P417, DOI 10.1146/annurev.psych.41.1.417
   Heudin Jean-Claude, 2010, Web Intelligence and Intelligent Agents, P1
   Heudin J.-C., 2009, P 14 INT S ART LIF R
   Heudin J.-C., 1992, RISC ARCHITECTURES
   Heudin J.-C., 2007, P 6 INT WORKSH DAT A
   Heudin JC, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON INTELLIGENT AGENT TECHNOLOGY, PROCEEDINGS, P93, DOI 10.1109/IAT.2004.1342929
   Langton C. G, 1989, P 1 ART LIF C, VVI
   McCutcheon M, 1996, WRITERS DIGEST SOURC
   Millet P., 2007, P INT AG TECHN C ACM
   Ray T. S, 1992, ARTIF LIFE, P371, DOI DOI 10.1016/S0040-4039(01)97473-8
   Sussman J. G., 1975, AIM349 MIT AI LAB
   Vala M., 2002, AISB J, V1
   Wallace R.S., 2002, THE ANATOMY OF ALICE
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
NR 19
TC 2
Z9 2
U1 0
U2 3
PU INSTICC-INST SYST TECHNOLOGIES INFORMATION CONTROL & COMMUNICATION
PI SETUBAL
PA AVENIDA D MANUEL L, 27A 2 ESQUERDO, SETUBAL, 2910-595, PORTUGAL
BN 978-989-8425-41-6
PY 2011
BP 251
EP 256
PG 6
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BG8JQ
UT WOS:000392353500034
DA 2022-08-02
ER

PT C
AU Ayedoun, E
   Hayashi, Y
   Seta, K
AF Ayedoun, Emmanuel
   Hayashi, Yuki
   Seta, Kazuhisa
BE Andre, E
   Baker, R
   Hu, X
   Rodrigo, MMT
   DuBoulay, B
TI Communication Strategies and Affective Backchannels for Conversational
   Agents to Enhance Learners' Willingness to Communicate in a Second
   Language
SO ARTIFICIAL INTELLIGENCE IN EDUCATION, AIED 2017
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 18th International Conference on Artificial Intelligence in Education
   (AIED)
CY JUN 28-JUL 01, 2017
CL Cent China Normal Univ, Wuhan, PEOPLES R CHINA
HO Cent China Normal Univ
DE Willingness to communicate in L2; Conversational agents; Communication
   strategies; Affective backchannels; Intelligent tutoring
AB Willingness to Communicate (WTC) in a second language (L2) is believed to have a direct and sustained influence on learners' actual usage frequency of the targeted language. To help overcome the lack of suitable environments to increase L2 learners WTC, our approach is to implement a WTC model based conversational agent. In this paper, we propose a dialogue management model based on set of communication strategies and affective backchannels in order to foster the agent's ability to carry on natural and WTC friendly conversations with L2 learners. We expect that combining communication strategies with affective backchannels can empower conversational agents to the extent to effectively help L2 learners recover from eventual communication pitfalls and create a warm conversation atmosphere.
C1 [Ayedoun, Emmanuel; Hayashi, Yuki; Seta, Kazuhisa] Osaka Prefecture Univ, Grad Sch Humanities & Sustainable Syst Sci, Osaka, Japan.
RP Ayedoun, E (corresponding author), Osaka Prefecture Univ, Grad Sch Humanities & Sustainable Syst Sci, Osaka, Japan.
EM eayedoun@ksm.kis.osakafu-u.ac.jp
CR Ayedoun E., 2016, J INF SYST ED, V15, P5, DOI [10.12937/ejsise.15.15, DOI 10.12937/EJSISE.15.15]
   Dornyei Z, 1997, LANG LEARN, V47, P173, DOI 10.1111/0023-8333.51997005
   Macintyre PD, 1998, MOD LANG J, V82, P545, DOI 10.2307/330224
   McCroskey J., 1997, AVOIDING COMMUNICATI, P75
   Smith C, 2011, PRESENCE-VIRTUAL AUG, V20, P395, DOI 10.1162/PRES_a_00063
NR 5
TC 2
Z9 2
U1 2
U2 9
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-319-61425-0; 978-3-319-61424-3
J9 LECT NOTES ARTIF INT
PY 2017
VL 10331
BP 459
EP 462
DI 10.1007/978-3-319-61425-0_40
PG 4
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BK3AD
UT WOS:000434475300040
DA 2022-08-02
ER

PT J
AU Rodriguez, JA
   Santana, MG
   Perera, MVA
   Pulido, JR
AF Artiles Rodriguez, Josue
   Guerra Santana, Monica
   Aguiar Perera, Ma Victoria
   Rodriguez Pulido, Josefa
TI Embodied conversational agents: artificial intelligence for autonomous
   learning
SO PIXEL-BIT- REVISTA DE MEDIOS Y EDUCACION
LA Spanish
DT Article
DE Artificial intelligence; tutoring; University education; embodied
   conversational agents
AB This paper delves into the possibilities of conversational virtual agents as a tool to tutor university students' work. A quantitative methodology with a descriptive, correlational and differential design was used to evaluate the usability of the conversational agent in a sample of 303 university students. For this, a virtual conversational agent was designed and evaluated to support the End-of-Degree Project tutorials with the SUS Scale (System Usability Scale). The results indicate that the scale has a satisfactory metric quality and good model goodness, aspects that are verified in the empirical structure and in the favorable internal consistency of the questionnaire. The data also show that there are significant differences (99.95% CI) in the variables gender, grade, level of knowledge, and the grade of chatbot use. It was completed with the record of the actual use of the agent, within a period of six months, by 589 students from three different degrees, answering 3025 questions in six months. In conclusion, the results allow to establish explanatory criteria on the use of chatbots. It is necessary to continue deepening in this type of tools for the monitoring and evaluation of students.
C1 [Artiles Rodriguez, Josue; Guerra Santana, Monica; Aguiar Perera, Ma Victoria; Rodriguez Pulido, Josefa] Univ Las Palmas Gran Canaria, Fac Ciencias Educ, Las Palmas Gran Canaria, Spain.
RP Rodriguez, JA (corresponding author), Univ Las Palmas Gran Canaria, Fac Ciencias Educ, Las Palmas Gran Canaria, Spain.
RI Artiles-Rodríguez, Josue/F-8527-2016
OI Artiles Rodriguez, Josue/0000-0002-2492-2486
CR Aguilar-Ibanez C., 2018, P 2018 15 INT C ELEC, P1
   [Anonymous], 2005, MULTIVARIATE DATA AN
   [Anonymous], 2010, METODOLOGIA INVESTIG
   [Anonymous], 2019, P 31 INT C SOFTW ENG, DOI DOI 10.18293/SEKE2019-029
   Babul Sabarish V., 2011, International Journal of Virtual Reality, V10, P25
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Brooke J, 1996, SUS A QUICK DIRTY US
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Bunge M, 2010, PSEUDOCIENCIAS
   Cochran W. G., 1980, TECNICAS DE MUESTREO
   Colace Francesco, 2018, INT J MECH ENG ROBOT, V7, P528
   Coperich K, 2017, P 2017 IND SYST ENG
   Dale R, 2016, NAT LANG ENG, V22, P811, DOI 10.1017/S1351324916000243
   Fadhil A., 2017, P 11 EAI INT C PERV, P261, DOI DOI 10.1145/3154862.3154914
   Fast E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174047
   Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009
   Finstad K, 2010, INTERACT COMPUT, V22, P323, DOI 10.1016/j.intcom.2010.04.004
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Ghosh D, 2018, PROCEEDINGS OF CHINESE CHI 2018: SIXTH INTERNATIONAL SYMPOSIUM OF CHINESE CHI (CHINESE CHI 2018), P11, DOI 10.1145/3202667.3204844
   Hair F.Joseph, 1998, MULTIVARIATE DATA AN, V5th
   Herbert D, 2018, EXPERT SYST APPL, V112, P342, DOI 10.1016/j.eswa.2018.06.049
   Hobert S., 2019, P 14 INT C WIRTSCH, P301
   Jung S, 2013, BEHAV PROCESS, V97, P90, DOI 10.1016/j.beproc.2012.11.016
   Kaplan R., 2009, PSYCHOL TESTING PRIN
   Kerlinger F.N., 1979, ENFOQUE CONCEPTUAL I
   Kerly A, 2009, APPLICATIONS AND INNOVATIONS IN INTELLIGENT SYSTEMS XVI, P169
   Kirakowski J., 1994, USE QUESTIONNAIRE ME
   Landauer T.K., 1997, HDB HUMAN COMPUTER I, P203, DOI DOI 10.1016/B978-044481862-1.50075-3
   Lewis JR, 2018, INT J HUM-COMPUT INT, V34, P577, DOI 10.1080/10447318.2018.1455307
   Lewis JR, 2009, LECT NOTES COMPUT SC, V5619, P94, DOI 10.1007/978-3-642-02806-9_12
   Lucey N. M, 1991, THESIS U COLL CORK
   Neumann AT, 2019, 2019 IEEE 5TH INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2019), P11, DOI 10.1109/CIC48465.2019.00011
   Nunnally J., 1978, AM EDUC RES J
   Saenz J., 2017, IIE ANN C P, P1357
   Salvador L., 2019, INT J MANAG INFORM T, V14, P3338, DOI [10.24297/ijmit.v14i0.7921, DOI 10.24297/IJMIT.V14I0.7921]
   Sauro J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1609
   Schroeder J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173972
   Sinoo C, 2018, PATIENT EDUC COUNS, V101, P1248, DOI 10.1016/j.pec.2018.02.008
   Sollner M, 2020, P 53 HAW INT C SYST, P22, DOI [10.24251/hicss.2020.005, DOI 10.24251/HICSS.2020.005]
   Sumikawa Yasunobu, 2020, Intelligent Decision Technologies 2019. Proceedings of the 11th KES International Conference on Intelligent Decision Technologies (KES-IDT 2019). Smart Innovation, Systems and Technologies (SIST 142), P3, DOI 10.1007/978-981-13-8311-3_1
   Tabachnik B. G., 1989, USING MULTIVARIATE S
   Tegos S, 2017, EDUC TECHNOL SOC, V20, P99
   Tegos S, 2014, INT J ARTIF INTELL E, V24, P62, DOI 10.1007/s40593-013-0007-3
   Tielman ML, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0771-y
   Tullis T. S., 2004, UPA ANN C UNPUB
   Wargnier P, 2015, 2015 3RD IEEE VR INTERNATIONAL WORKSHOP ON VIRTUAL AND AUGMENTED ASSISTIVE TECHNOLOGY (VAAT), P23, DOI 10.1109/VAAT.2015.7155406
   Wellnhammer N., 2020, P 53 HAW INT C SYST, P146, DOI [10.24251/hicss.2020.019, DOI 10.24251/HICSS.2020.019]
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
NR 49
TC 0
Z9 0
U1 7
U2 7
PU UNIV SEVILLA, EDITORIAL
PI SEVILLE
PA SECRETARIADO PUBLICACIONES, C/ PORVENIR, NO 27, SEVILLE, 41013, SPAIN
SN 1133-8482
EI 2171-7966
J9 PIXEL-BIT
JI Pixel-Bit
PD AUG
PY 2021
IS 62
BP 107
EP 144
DI 10.12795/pixelbit.86171
PG 38
WC Education & Educational Research
WE Emerging Sources Citation Index (ESCI)
SC Education & Educational Research
GA YV4QB
UT WOS:000752713300006
OA Green Submitted, gold
DA 2022-08-02
ER

PT J
AU Ehret, J
   Bonsch, A
   Aspock, L
   Rohr, CT
   Baumann, S
   Grice, M
   Fels, J
   Kuhlen, TW
AF Ehret, Jonathan
   Boensch, Andrea
   Aspoeck, Lukas
   Roehr, Christine T.
   Baumann, Stefan
   Grice, Martine
   Fels, Janina
   Kuhlen, Torsten W.
TI Do Prosody and Embodiment Influence the Perceived Naturalness of
   Conversational Agents' Speech?
SO ACM TRANSACTIONS ON APPLIED PERCEPTION
LA English
DT Article
DE Embodied conversational agents (ECAs); virtual acoustics; prosody;
   accentuation; speech; text-to-speech; audio; embodiment
AB For conversational agents' speech, either all possible sentences have to be prerecorded by voice actors or the required utterances can be synthesized. While synthesizing speech is more flexible and economic in production, it also potentially reduces the perceived naturalness of the agents among others due to mistakes at various linguistic levels. In our article, we are interested in the impact of adequate and inadequate prosody, here particularly in terms of accent placement, on the perceived naturalness and aliveness of the agents. We compare (1) inadequate prosody, as generated by off-the-shelf text-to-speech (TTS) engines with synthetic output; (2) the same inadequate prosody imitated by trained human speakers; and (3) adequate prosody produced by those speakers. The speech was presented either as audio-only or by embodied, anthropomorphic agents, to investigate the potential masking effect by a simultaneous visual representation of those virtual agents. To this end, we conducted an online study with 40 participants listening to four different dialogues each presented in the three Speech levels and the two Embodiment levels. Results confirmed that adequate prosody in human speech is perceived as more natural (and the agents are perceived as more alive) than inadequate prosody in both human (2) and synthetic speech (1). Thus, it is not sufficient to just use a human voice for an agents' speech to be perceived as natural-it is decisive whether the prosodic realisation is adequate or not. Furthermore, and surprisingly, we found no masking effect by speaker embodiment, since neither a human voice with inadequate prosody nor a synthetic voice was judged as more natural, when a virtual agent was visible compared to the audio-only condition. On the contrary, the human voice was even judged as less "alive" when accompanied by a virtual agent. In sum, our results emphasize, on the one hand, the importance of adequate prosody for perceived naturalness, especially in terms of accents being placed on important words in the phrase, while showing, on the other hand, that the embodiment of virtual agents plays a minor role in the naturalness ratings of voices.
C1 [Ehret, Jonathan; Boensch, Andrea; Kuhlen, Torsten W.] Rhein Westfal TH Aachen, Visual Comp Inst, Kopernikusstr 6, D-52074 Aachen, Germany.
   [Aspoeck, Lukas; Fels, Janina] Rhein Westfal TH Aachen, Inst Hearing Technol & Acoust, Kopernikusstr 5, D-52074 Aachen, Germany.
   [Roehr, Christine T.; Baumann, Stefan; Grice, Martine] Univ Cologne, IfL Phonet, Herbert Lewin Str 6, D-50931 Cologne, Germany.
RP Ehret, J (corresponding author), Rhein Westfal TH Aachen, Visual Comp Inst, Kopernikusstr 6, D-52074 Aachen, Germany.
EM ehret@vr.rwth-aachen.de; boensch@vr.rwth-aachen.de;
   lukas.aspoeck@akustik.rwth-aachen.de; christine.roehr@uni-koeln.de;
   stefan.baumann@uni-koeln.de; martine.grice@uni-koeln.de;
   janina.fels@akustik.rwth-aachen.de; kuhlen@vr.rwth-aachen.de
CR Al Moubayed Samer, 2012, Cognitive Behavioural Systems (COST 2012). International Training School. Revised Selected Papers, P114, DOI 10.1007/978-3-642-34584-5_9
   Anderson Keith, 2013, Advances in Computer Entertainment. 10th International Conference, ACE 2013. Proceedings: LNCS 8253, P476, DOI 10.1007/978-3-319-03161-3_35
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Bailenson JN, 2001, PRESENCE-TELEOP VIRT, V10, P583, DOI 10.1162/105474601753272844
   Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Baur T, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P220, DOI 10.1109/SocialCom.2013.39
   Cabral JP, 2017, INTERSPEECH, P229, DOI 10.21437/Interspeech.2017-325
   Cambre Julia, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359325
   Cassell J., 2000, EMBODIED CONVERSATIO
   Chateau N, 2005, LECT NOTES COMPUT SC, V3784, P652
   Cherif E, 2019, RECH APPL MARKET-ENG, V34, P28, DOI 10.1177/2051570719829432
   Chini JJ, 2016, PHYS REV PHYS EDUC R, V12, DOI 10.1103/PhysRevPhysEducRes.12.010117
   Chollet M, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P1143, DOI 10.1145/2750858.2806060
   Cohn Michelle, 2020, COGSCI
   Cutler Anne, 1980, ERRORS LINGUISTIC PE, P67
   Davis RO, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103605
   de Borst AW, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00576
   Galvez RH, 2020, SPEECH COMMUN, V124, P46, DOI 10.1016/j.specom.2020.07.007
   Georgila K, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3519
   Gong L, 2007, HUM COMMUN RES, V33, P163, DOI 10.1111/j.1468-2958.2007.00295.x
   Gratch J, 2016, LECT NOTES ARTIF INT, V10011, P283, DOI 10.1007/978-3-319-47665-0_25
   Hiyakumoto Laurie, 1997, CONCEPT SPEECH GENER, V21, P15
   Kang N, 2016, COMPUT HUM BEHAV, V55, P680, DOI 10.1016/j.chb.2015.10.008
   Katsyri J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00390
   Krenn B, 2017, AI SOC, V32, P65, DOI 10.1007/s00146-014-0569-0
   Kuhne K, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.593732
   Leiner D.J., 2021, SOSCI SURVEY VERSION
   Lugrin J.-L., 2016, FRONTIERS ICT, V3, DOI [10.3389/fict.2016.00026, DOI 10.3389/FICT.2016.00026]
   Malisz Zofia, 2019, 10 ISCA SPEECH SYNTH, P257, DOI [10.21437/SSW.2019-46, DOI 10.21437/SSW.2019-46]
   Marsella S., 2013, P 12 ACM SIGGRAPH EU, P25, DOI DOI 10.1145/2485895.2485900
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Peeters D, 2019, PSYCHON B REV, V26, P894, DOI 10.3758/s13423-019-01571-3
   R Development Core Team, 2011, R LANG ENV STAT COMP
   Rosenthal-von der Putten AM, 2016, LECT NOTES ARTIF INT, V10011, P256, DOI 10.1007/978-3-319-47665-0_23
   Schroder M, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P3260
   Seaborn K, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3386867
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   van der Struijk S, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P159, DOI 10.1145/3267851.3267918
   Wang I, 2021, INT J HUM-COMPUT INT, V37, P1648, DOI 10.1080/10447318.2021.1898851
   West M., 2019, ID BLUSH COULD CLOSI
NR 41
TC 0
Z9 0
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1544-3558
EI 1544-3965
J9 ACM T APPL PERCEPT
JI ACM Trans. Appl. Percept.
PD OCT
PY 2021
VL 18
IS 4
AR 21
DI 10.1145/3486580
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YY1DS
UT WOS:000754533100005
DA 2022-08-02
ER

PT C
AU Nass, C
   Robles, E
   Wang, QY
AF Nass, C
   Robles, E
   Wang, QY
BE Ruttkay, Z
   Pelachaud, C
TI 'user as assessor' approach to embodied conversational agents - The case
   of apparent attention in ECAs
SO FROM BROWS TO TRUST: EVALUATING EMBODIED CONVERSATIONAL AGENTS
SE Human-Computer Interaction Series
LA English
DT Proceedings Paper
CT Workshop on Embodied Conversational Agents held at the 2002 AAMAS
   Conference
CY MAR, 2003
CL Montreal, CANADA
DE user as assessor approach; apparent attention; selectivity; breadth;
   evaluation methodology; design principle
ID PERSONALITY; RESPONSES; CONSISTENCY; PERCEPTION; MACHINES; FORM
AB Traditionally, an optimal embodied conversational agent (ECA) has the same capabilities and appearance as an actual person. This chapter proposes a 'user as assessor' approach to evaluating ECAs that focuses on how ECAs manifest human capabilities independent of actual capabilities that an ECA may possess. Literatures on humans as producers of behavior and humans as interpreters of behavior are lever-aged to draw implications for how ECAs should behave to seem most realistic to their human assessors. To illustrate the approach, we answer the question, "what will convince a user that an ECA is paying attention to him or her, whether the ECA truly is paying attention or not?"' 'Apparent attention' is conceptualized in terms of two basic dimensions - selectivity and breadth - and their indicators and impacts. Using the proposed approach, the chapter provides guidelines for how agents, conversational agents, and ECAs can effectively exhibit attention.
EM wangqy@stanford.edu
CR ANDRE E, 1999, P WORKSH AFF INT NEW, P136
   [Anonymous], 2001, P SIGCHI C HUM FACT, DOI DOI 10.1145/365024.365119
   Argyle M., 1976, GAZE MUTUAL GAZE
   Bailenson JN, 2001, PRESENCE-TELEOP VIRT, V10, P583, DOI 10.1162/105474601753272844
   BAILENSON JN, IN PRESS INTERPERSON
   BAVELAS JB, 1988, HUM COMMUN RES, V14, P275, DOI 10.1111/j.1468-2958.1988.tb00158.x
   BEAUMOND JG, 1983, INTRO NEUROPSYCHOLOG
   BENIGER JR, 1987, COMMUN RES, V14, P325
   BIERNAT M, 1993, J EXP SOC PSYCHOL, V29, P166, DOI 10.1006/jesp.1993.1008
   Bishop DVM, 1998, APPL PSYCHOLINGUIST, V19, P415, DOI 10.1017/S0142716400010249
   BORKENAU P, 1993, J PERS SOC PSYCHOL, V65, P546, DOI 10.1037/0022-3514.65.3.546
   Branigan HP, 2000, COGNITION, V75, pB13, DOI 10.1016/S0010-0277(99)00081-5
   BRAVE S, 2002, HDB HUMAN COMPUTER I, P00251
   BRAVE S, 2003, THESIS STANFORD U
   Brennan SE, 1996, J EXP PSYCHOL LEARN, V22, P1482, DOI 10.1037/0278-7393.22.6.1482
   Cassell J, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P106
   Cassell J., 1999, Psychological Models of Communication in Collaborative Systems. Papers from the 1999 AAAI Fall Symposium (TR FS-99-03), P34
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893
   Chopra-Khullar S., 1999, Proceedings of the Third International Conference on Autonomous Agents, P16, DOI 10.1145/301136.301152
   Clark H.H, 1996, USING LANGUAGE
   Coen MH, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P547
   COKER DA, 1987, HUM COMMUN RES, V13, P463, DOI 10.1111/j.1468-2958.1987.tb00115.x
   EYSENCK MW, 1997, PRINCIPLES COGNITIVE
   FRIEDMAN B, 1997, HUMAN VALUES DESIGN
   GIGES B, 1975, TRANSACTIONAL ANAL J, V5, P264, DOI 10.1177/036215377500500313
   Grayson D., 1998, SIGCHI Bulletin, V30, P30
   Grice H. Paul, 1975, SYNTAX SEMANTICS, V3, P44
   Grosz B. J., 1986, Computational Linguistics, V12, P175
   GROSZ BJ, 1995, COMPUT LINGUIST, V21, P203
   HALLER SM, 1997, AAAI SPRING S COMP M, P78
   Hochschild Arlie., 1985, MANAGED HEART
   HOEKS B, 1993, BEHAV RES METH INSTR, V25, P16, DOI 10.3758/BF03204445
   Hook K, 2000, AI COMMUN, V13, P195
   Isbister K, 2000, INT J HUM-COMPUT ST, V53, P251, DOI 10.1006/ijhc.2000.0368
   James W., 1890, PRINCIPLES PSYCHOL, V2
   Kahnemann D, 1973, ATTENTION EFFORT
   Kant I., 1929, CRITIQUE PURE REASON
   Kendon A., 1967, ACTA PSYCHOL, V26, P1
   Kettebekov S, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P161, DOI 10.1109/ICMI.2002.1166986
   Krause M. A., 1997, INT J COMP PSYCHOL, V10, P137
   Lakoff Robin, 1975, LANGUAGE WOMANS PLAC
   LASHKARI Y, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P444
   LATORELLA KA, 1999, NASATM1999209707
   Lester J., 1997, IJCAI 97 WORKSH AN I, P61
   LEUNG EHL, 1981, DEV PSYCHOL, V17, P215, DOI 10.1037/0012-1649.17.2.215
   LIEBERMAN H, 1995, P 14 INT JOINT C ART, P457
   Maglio PP, 2003, COMMUN ACM, V46, P47, DOI 10.1145/636772.636797
   MAGLIO PP, 2000, P 5 INT C INT US INT, P169
   MANN WC, 1987, RS87190 INT COMP SCI
   McNeill David., 1992, HAND MIND WHAT GESTU
   METRAL M, 1993, DESIGN GENERIC LEARN
   Minsky M, 1986, THE SOCIETY OF MIND
   Mirsky AF, 1989, INTEGRATING THEORY P, P75
   Moon Y, 1996, COMMUN RES, V23, P651, DOI 10.1177/009365096023006002
   Moon Y, 1998, PUBLIC OPIN QUART, V62, P610, DOI 10.1086/297862
   Moore C, 2001, J COGN DEV, V2, P109, DOI 10.1207/S15327647JCD0202_1
   MURRAY JH, 1991, COMPUT HUMANITIES, V25, P1, DOI 10.1007/BF00054285
   Nass C, 2000, COMMUN ACM, V43, P36, DOI 10.1145/348941.348976
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Nass C, 1997, J APPL SOC PSYCHOL, V27, P864, DOI 10.1111/j.1559-1816.1997.tb00275.x
   Nass C, 2000, EMBODIED CONVERSATIONAL AGENTS, P374
   Nass C, 2001, J EXP PSYCHOL-APPL, V7, P171, DOI 10.1037//1076-898X.7.3.171
   NORMAN DA, 1997, SOFTWARE AGENTS, P49
   OH A, 2002, P C HUM FACT COMP SY, P650
   PERSSON P, 2000, AAAI FALL S 2000 TEC, P131
   POESIO M, 1992, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE (KR 92), P369
   REED CA, 2002, P 15 EUR C ART INT L, P440
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Rich C, 1998, USER MODEL USER-ADAP, V8, P315, DOI 10.1023/A:1008204020038
   Rickel J, 2002, LECT NOTES COMPUT SC, V2363, P542
   Rickel J, 1999, APPL ARTIF INTELL, V13, P343, DOI 10.1080/088395199117315
   Rizzo P., 1997, Socially Intelligent Agents. Papers from the 1997 AAAI Fall Symposium, P109
   ROSENKRANTZ P, 1968, J CONSULT CLIN PSYCH, V32, P287, DOI 10.1037/h0025909
   Schmidt CL, 1999, ECOL PSYCHOL, V11, P139, DOI 10.1207/s15326969eco1102_2
   SCHNEIDERMAWN B, 1997, DESIGNING USER INTER
   SHANKAR TR, 2000, P 33 HAW INT C SYST, P3035
   SHERMAN E, 1973, GRADUATE RES ED RELA, V7, P5
   SHETH B, 1993, P 9 C ART INT APPL, P1
   Spence C, 2001, Q J EXP PSYCHOL-A, V54, P775, DOI 10.1080/02724980042000480
   Steinfield, 1990, ORG COMMUNICATION TE, P46, DOI 10.4135/9781483325385.n3
   Tajfel Henri, 1981, SOCIAL IDENTITY INTE
   Tannen D., 1990, YOU JUST DONT UNDERS
   Traum D., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P766
   VERTEGAAL R, 2003, P COMP SUPP COOP WOR, P41
   VERTEGAAL R, 2002, P GRAPH INT MONTR CA, P95
   Vilhjalmsson H. H., 1998, Proceedings of the Second International Conference on Autonomous Agents, P269, DOI 10.1145/280765.280843
   Walker WA, 1996, J PEDIATR GASTR NUTR, V22, P2, DOI 10.1097/00005176-199601000-00002
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P23
   Wickens C., 1984, VARIETIES ATTENTION
   [No title captured]
   [No title captured]
NR 92
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS
SN 1571-5035
EI 2524-4477
BN 1-4020-2729-X
J9 HUM-COMPUT INT-SPRIN
PY 2004
VL 7
BP 161
EP 188
PG 28
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BBP07
UT WOS:000226830500006
DA 2022-08-02
ER

PT S
AU Bickmore, T
   Cassell, J
AF Bickmore, Timothy
   Cassell, Justine
BE VanKuppevelt, JCJ
   Dybkjaer, L
   Bernsen, NO
TI SOCIAL DIALOGUE WITH EMBODIED CONVERSATIONAL AGENTS
SO ADVANCES IN NATURAL MULTIMODAL DIALOGUE SYSTEMS
SE Text Speech and Language Technology
LA English
DT Article; Book Chapter
DE Embodied conversational agent; social dialogue; trust
ID RESPONSES
AB The functions of social dialogue between people in the context of performing a task is discussed, as well as approaches to modelling such dialogue in embodied conversational agents. A study of an agent's use of social dialogue is presented, comparing embodied interactions with similar interactions conducted over the phone, assessing the impact these media have on a wide range of behavioural, task and subjective measures. Results indicate that subjects' perceptions of the agent are sensitive to both interaction style (social vs. task-only dialogue) and medium.
C1 [Bickmore, Timothy] Northeastern Univ, Boston, MA 02115 USA.
   [Cassell, Justine] Northwestern Univ, Evanston, IL 60208 USA.
RP Bickmore, T (corresponding author), Northeastern Univ, Boston, MA 02115 USA.
EM bickmore@ccs.neu.edu; justine@northwestern.edu
CR Altman I., 1973, SOCIAL PENETRATION D
   Andersen P.A., 1998, HDB COMMUNICATION EM, P303, DOI https://doi.org/10.1016/B978-012057770-5/50013-8
   Andre E., 1998, Proceedings of the Second International Conference on Autonomous Agents, P261, DOI 10.1145/280765.280842
   ANDRE E, 1996, P WORKSH ADV VIS INT, P245
   Argyle M., 1990, PSYCHOL INQ, V1, P297, DOI [10.1207/s15327965pli0104_3, DOI 10.1207/S15327965PLI0104_3]
   Argyle M., 1988, BODILY COMMUNICATION
   BESKOW J, 1997, P IJCAI 1997 WORKSH
   BICKMORE T, 2001, P ACM C HUM FACT COM, P396
   BICKMORE T, 2002, P AAAI FALL S ET HUM, P9
   Bos N., 2002, P CHI 2002, P135, DOI DOI 10.1145/503376.503401
   BOYLE EA, 1994, LANG SPEECH, V37, P1, DOI 10.1177/002383099403700101
   Brown Penelope, 1978, QUESTIONS POLITENESS, P56
   BROWN R, 1989, LANG SOC, V18, P159, DOI 10.1017/S0047404500013464
   Brown Roger, 1972, LANGUAGE SOCIAL CONT, P252
   Cassell J, 2003, USER MODEL USER-ADAP, V13, P89, DOI 10.1023/A:1024026532471
   Cassell J, 2000, EMBODIED CONVERSATIONAL AGENTS, P29
   Cassell J., 2000, P 5 INT C INT US INT, P52, DOI [10.1145/325737.325781, DOI 10.1145/325737.325781]
   Cassell J., 2000, EMBODIED CONVERSATIO
   Cassell J., 1999, P SIGCHI C HUM FACT, P520, DOI DOI 10.1145/302979.303150
   CHEEPEN C, 1988, PREDICTABILITY INFOR
   Chovil N., 1991, RES LANG SOC INTERAC, V25, P163, DOI [10.1080/08351819109389361, DOI 10.1080/08351819109389361]
   Clark H.H, 1996, USING LANGUAGE
   COUPLAND J, 1992, LANG SOC, V21, P207, DOI 10.1017/S0047404500015268
   Daly-Jones O, 1998, INT J HUM-COMPUT ST, V49, P21, DOI 10.1006/ijhc.1998.0195
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   Dunbar Robin, 1996, GROOMING GOSSIP EVOL
   Duncan S., 1974, LANG SOC, V3, P161, DOI [https://doi.org/10.1017/S0047404500004322, DOI 10.1016/j.tics.2009.04.005]
   Garros D., 1999, COMMUNICATION
   Goffman Irving, 1967, INTERACTION RITUAL E, P5
   GUSTAFSON J, 1999, P EUROSPEECH, P1151
   HAUPTMANN AG, 1988, INT J MAN MACH STUD, V28, P583, DOI 10.1016/S0020-7373(88)80062-2
   Jakobson R., 1960, STYLE LANGUAGE, P351
   KENDON A, 1980, CONDUCTING INTERACTI, V7
   Kiesler S., 1997, Human values and the design of computer technology, P191
   Koda T, 1996, RO-MAN '96 - 5TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P189, DOI 10.1109/ROMAN.1996.568812
   Laver John, 1981, CONVERSATIONAL ROUTI, P289
   Laver John, 1975, ORG BEHAV FACE TO FA, P215
   Lester JC, 1999, USER MODEL USER-ADAP, V9, P1, DOI 10.1023/A:1008374607830
   Maes P., 1989, Connection Science, V1, P291, DOI 10.1080/09540098908915643
   Malinowski Bronislaw, 1923, MEANING MEANING, P296
   McNeill D., 1992, HAND MIND WHAT GESTU
   Moon Y, 1996, COMMUN RES, V23, P651, DOI 10.1177/009365096023006002
   Nass C, 2000, COMMUN ACM, V43, P36, DOI 10.1145/348941.348976
   Oviatt S, 2000, EMBODIED CONVERSATIONAL AGENTS, P319
   OVIATT S, 1995, COMPUT SPEECH LANG, V9, P19, DOI 10.1006/csla.1995.0002
   OVIATT S, 1998, READINGS INTELLIGENT, P620
   Petty Richard E., 1998, HDB SOCIAL PSYCHOL, P323
   Prus, 1989, MAKING SALES INFLUEN
   Reeves B., 1996, MEDIA EQUATION PEOPL
   RESNIK PV, 1985, J SOC PSYCHOL, V125, P761, DOI 10.1080/00224545.1985.9713550
   RICHMOND V, 1995, IMMEDIACY NONVERBAL
   RICKEL J, 1998, P 3 WORKSH EMB CONV, P39
   Rickenberg Raoul, 2000, P SIGCHI C HUM FACT, P49
   Rutter D., 1987, COMMUNICATING TELEPH
   Schneider K. P., 1988, SMALL TALK ANAL PHAT
   Shaw J.J., 1994, CONSUMER BEHAV STRAT
   SIDNER CL, 2005, ADV NATURAL MULTIMOD
   Sproull L., 1997, Human values and the design of computer technology, P163
   Stone M, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P198
   Svennevig Jan., 2000, GETTING ACQUAINTED C
   Takeuchi A., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P450
   van Mulken S., 1999, Human-Computer Interaction: Ergonomics and User Interfaces. Proceedings of HCI International '99 (8th International Conference on Human-Computer Interaction), P152
   Wheeless L.R., 1977, HUM COMMUN RES, V3, P250, DOI DOI 10.1111/J.1468-2958.1977.TB00523.X
   Whittaker S., 1997, ROLE VISION FACE TO, P23
   WHITTAKER S, 1993, P HUM FACT COMP SYST, P73
   WIGGINS JS, 1979, J PERS SOC PSYCHOL, V37, P395, DOI 10.1037/0022-3514.37.3.395
   WILSON G, 1977, PERSONALITY VARIABLE, P179
   ZHENG J, 2002, P SIGCHI C HUM FACT, P141
NR 68
TC 84
Z9 84
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS
SN 1386-291X
BN 978-1-4020-3933-1
J9 TEXT SPEECH LANG TEC
PY 2005
VL 30
BP 23
EP 54
D2 10.1007/1-4020-3933-6
PG 32
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Language & Linguistics
WE Book Citation Index – Social Sciences & Humanities (BKCI-SSH); Book Citation Index – Science (BKCI-S)
SC Computer Science; Linguistics
GA BLA38
UT WOS:000269751500003
DA 2022-08-02
ER

PT C
AU Porcheron, M
   Fischer, JE
   Luger, E
   McGregor, M
   Brown, B
   Candello, H
   O'Hara, K
AF Porcheron, Martin
   Fischer, Joel E.
   Luger, Ewa
   McGregor, Moira
   Brown, Barry
   Candello, Heloisa
   O'Hara, Kenton
GP Assoc Comp Machinery
TI Talking with Conversational Agents in Collaborative Action
SO CSCW'17: COMPANION OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED
   COOPERATIVE WORK AND SOCIAL COMPUTING
LA English
DT Proceedings Paper
CT ACM Conference on Computer Supported Cooperative Work and Social
   Computing (CSCW)
CY FEB 25-MAR 01, 2017
CL Portland, OR
SP Assoc Comp Machinery, ACM SIGCHI, Facebook, IBM Res, Microsoft Res, HP, Mozilla
DE conversational agents; intelligent personal assistants; multi-party
   conversation; collocated interaction; CSCW
AB This one-day workshop intends to bring together both academics and industry practitioners to explore collaborative challenges in speech interaction. Recent improvements in speech recognition and computing power has led to conversational interfaces being introduced to many of the devices we use every day, such as smartphones, watches, and even televisions. These interfaces allow us to get things done, often by just speaking commands, relying on a reasonably well understood single-user model. While research on speech recognition is well established, the social implications of these interfaces remain underexplored, such as how we socialise, work, and play around such technologies, and how these might be better designed to support collaborative collocated talk-in-action. Moreover, the advent of new products such as the Amazon Echo and Google Home, which are positioned as supporting multi-user interaction in collocated environments such as the home, makes exploring the social and collaborative challenges around these products, a timely topic. In the workshop, we will review current practices and reflect upon prior work on studying talk-in-action and collocated interaction. We wish to begin a dialogue that takes on the renewed interest in research on spoken interaction with devices, grounded in the existing practices of the CSCW community.
C1 [Porcheron, Martin; Fischer, Joel E.] Univ Nottingham, Mixed Real Lab, Nottingham, England.
   [Luger, Ewa] Univ Edinburgh, Design Informat, Edinburgh, Midlothian, Scotland.
   [McGregor, Moira; Brown, Barry] Stockholm Univ, Mobile Life Ctr, Stockholm, Sweden.
   [Candello, Heloisa] IBM Res Lab, Social Data Analyt Grp, Sao Paulo, Brazil.
   [O'Hara, Kenton] Microsoft Res, Cambridge, England.
RP Porcheron, M (corresponding author), Univ Nottingham, Mixed Real Lab, Nottingham, England.
EM porcheron@acm.org; joel.fischer@nottingham.ac.uk;
   eluger@exseed.ed.ac.uk; moira@mobilelifecentre.org;
   barry@mobilelifecentre.org; heloisacandello@br.ibm.com;
   keohar@microsoft.com
RI Porcheron, Martin/AAB-8774-2021; Candello, Heloisa/S-1840-2019
OI Porcheron, Martin/0000-0003-3814-7174; Fischer, Joel/0000-0001-8878-2454
FU EPSRC [EP/G037574/1, EP/G065802/1, EP/N014243/1]; EPSRC [EP/M02315X/1]
   Funding Source: UKRI
FX Martin Porcheron is supported by EPSRC grants EP/G037574/1 and
   EP/G065802/1. Joel E. Fischer is supported by EPSRC grant EP/N014243/1.
CR Ben Shneiderman, 2000, COMMUN ACM, V43, P63, DOI [10.1145/348941.348990, DOI 10.1145/348941.348990]
   Clawson James, 2008, P 10 INT C HUM COMP, P187
   Ferdous HS, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P132, DOI 10.1145/2971648.2971715
   Fischer JE, 2016, PROCEEDINGS OF THE 19TH ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING COMPANION, P465, DOI 10.1145/2818052.2855522
   Gilbert Nigel, 1990, COMPUTERS CONVERSATI, P235, DOI DOI 10.1016/B978-0-08-050264-9.50016-6
   Jones A, 2014, IEEE SYS MAN CYBERN, P1107, DOI 10.1109/SMC.2014.6974062
   Lucero A, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI 2016), P1117, DOI 10.1145/2957265.2962651
   Lucero Andres, 2010, P 12 INT C HUM COMP, P337, DOI [10.1145/1851600.1851659, DOI 10.1145/1851600.1851659]
   Lucero Andres, 2015, P 33 ANN ACM C HUM F, P2437, DOI [10.1145/2702613.2702649, DOI 10.1145/2702613.2702649]
   Lucero Andres, 2015, P 17 INT C HUM COMP, P1138, DOI DOI 10.1145/2786567.2795401
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   McGregor M, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P2208, DOI 10.1145/2998181.2998335
   Moser C, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1881, DOI 10.1145/2858036.2858357
   Payr Sabine, 2013, Your Virtual Butler. The Making-of: LNCS 7407, P134, DOI 10.1007/978-3-642-37346-6_11
   Pilato G., 2010, SEMANTIC COMPUTING, P357
   Porcheron M, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P207, DOI 10.1145/2998181.2998298
   Porcheron M, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1649, DOI 10.1145/2818048.2820014
   Porcheron Martin, 2016, P 2016 CHI C HUM FAC, P3309, DOI DOI 10.1145/2851581.2856471
   Porcheron Martin, 2016, P 20 INT AC MINDTR C, P226, DOI [10.1145/2994318.2994358, DOI 10.1145/2994310.2994350]
   Rooksby J., 2015, P 14 EUR C COMP SUPP, P243, DOI DOI 10.1007/978-3-319-20499-4_13
   [No title captured]
NR 21
TC 18
Z9 18
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-4688-7
PY 2017
BP 431
EP 436
DI 10.1145/3022198.3022666
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Social Sciences, Interdisciplinary
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Social Sciences - Other Topics
GA BL7JF
UT WOS:000455085000100
OA Green Accepted
DA 2022-08-02
ER

PT J
AU Graesser, AC
   Li, HY
   Forsyth, C
AF Graesser, Arthur C.
   Li, Haiying
   Forsyth, Carol
TI Learning by Communicating in Natural Language With Conversational Agents
SO CURRENT DIRECTIONS IN PSYCHOLOGICAL SCIENCE
LA English
DT Article
DE conversational agents; intelligent tutoring systems; learning
   technologies
ID INTELLIGENT TUTORING SYSTEM; DIALOGUE; AUTOTUTOR
AB Learning is facilitated by conversational interactions both with human tutors and with computer agents that simulate human tutoring and ideal pedagogical strategies. In this article, we describe some intelligent tutoring systems (e.g., AutoTutor) in which agents interact with students in natural language while being sensitive to their cognitive and emotional states. These systems include one-on-one tutorial dialogues, conversational trialogues in which two agents (a tutor and a peer) interact with a human student, and other conversational ensembles in which agents take on different roles. Tutorial conversations with agents have also been incorporated into educational games. These learning environments have been developed for different populations (elementary through high school students, college students, adults with reading difficulties) and different subjects spanning science, technology, engineering, mathematics, reading, writing, and reasoning. This article identifies some of the conversation patterns that are implemented in the dialogues and trialogues.
C1 [Graesser, Arthur C.; Li, Haiying; Forsyth, Carol] Memphis State Univ, Memphis, TN 38152 USA.
RP Graesser, AC (corresponding author), Memphis State Univ, Dept Psychol, Psychol Bldg Room 202, Memphis, TN 38152 USA.
EM graesser@memphis.edu
CR Biswas G., 2010, RES PRACT TECH ENHAN, V05, P123, DOI 10.1142/S1793206810000839
   Chi MTH, 2001, COGNITIVE SCI, V25, P471, DOI 10.1016/S0364-0213(01)00044-1
   Clark H.H, 1996, USING LANGUAGE
   COHEN PA, 1982, AM EDUC RES J, V19, P237, DOI 10.2307/1162567
   D'mello S., 2013, ACM T INTERACT INTEL, V2, P1
   D'Mello SK, 2011, J EXP PSYCHOL-APPL, V17, P1, DOI 10.1037/a0022674
   Forsyth C., 2012, LEARNING GAINS CORE
   Gholson B, 2009, INSTR SCI, V37, P487, DOI 10.1007/s11251-008-9069-2
   Graesser A. C., 2012, APA ED PSYCHOL HDB, V3, P451, DOI [10.1037/13275-018, DOI 10.1037/13275-018]
   Graesser A. C., 2012, APPL NATURAL LANGUAG, P169
   Graesser AC, 2005, IEEE T EDUC, V48, P612, DOI 10.1109/TE.2005.856149
   Graesser AC, 2004, BEHAV RES METH INS C, V36, P180, DOI 10.3758/BF03195563
   GRAESSER AC, 1995, APPL COGNITIVE PSYCH, V9, P495, DOI 10.1002/acp.2350090604
   Graesser AC, 2008, DISCOURSE PROCESS, V45, P298, DOI 10.1080/01638530802145395
   Graesser AC, 2012, PSYCHOL LEARN MOTIV, V57, P183, DOI 10.1016/B978-0-12-394293-7.00005-4
   Graesser AC, 2011, AM PSYCHOL, V66, P743, DOI 10.1037/a0024573
   Graesser AC, 2011, EDUC PSYCHOL HANDB, P408
   Halpern DF, 2012, THINK SKILLS CREAT, V7, P93, DOI 10.1016/j.tsc.2012.03.006
   Hu XG, 2004, BEHAV RES METH INS C, V36, P241, DOI 10.3758/BF03195569
   Jackson G. T., 2006, P 28 ANN M COGN SCI, P1557
   Jurafsky D., 2020, SPEECH LANGUAGE PROC
   Kopp KJ, 2012, LEARN INSTR, V22, P320, DOI 10.1016/j.learninstruc.2011.12.002
   Kumar R, 2011, IEEE T LEARN TECHNOL, V4, P21, DOI 10.1109/TLT.2010.41
   LANDAUER TK, 2007, HDB LATENT SEMANTIC
   Lehman B., 2013, INT J ARTIFICIAL INT, V22, P85
   McNamara D. S., 2006, Journal of Educational Computing Research, V34, P147, DOI 10.2190/1RU5-HDTJ-A5C8-JVWE
   Millis K., 2011, SERIOUS GAMES EDUTAI, P169, DOI DOI 10.1007/978-1-4471-2161-9_10
   Olney Andrew M., 2012, Intelligent Tutoring Systems. Proceedings 11th International Conference (ITS 2012), P256, DOI 10.1007/978-3-642-30950-2_32
   Rus V, 2013, AI MAG, V34, P42, DOI 10.1609/aimag.v34i3.2485
   VanLehn K, 2007, COGNITIVE SCI, V31, P3, DOI 10.1080/03640210709336984
   VanLehn K, 2011, EDUC PSYCHOL-US, V46, P197, DOI 10.1080/00461520.2011.611369
   Ward W, 2013, J EDUC PSYCHOL, V105, P1115, DOI 10.1037/a0031589
NR 32
TC 43
Z9 43
U1 0
U2 38
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0963-7214
EI 1467-8721
J9 CURR DIR PSYCHOL SCI
JI Curr. Dir. Psychol.
PD OCT
PY 2014
VL 23
IS 5
BP 374
EP 380
DI 10.1177/0963721414540680
PG 7
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA AS0UJ
UT WOS:000343993700011
DA 2022-08-02
ER

PT J
AU Pernencar, C
   Saboia, I
   Dias, JC
AF Pernencar, Claudia
   Saboia, Inga
   Dias, Joana Carmo
TI How Far Can Conversational Agents Contribute to IBD Patient Health
   Care-A Review of the Literature
SO FRONTIERS IN PUBLIC HEALTH
LA English
DT Review
DE artificial intelligence; chatbot; conversational agents; digital health;
   IBD; machine learning
ID INFLAMMATORY-BOWEL-DISEASE; CROHNS-DISEASE
AB Modern societies are facing health and healthcare challenges as never seen before. The digital world in which we are living today considers digital health interventions such as "internet-delivered " therapy (e-Therapy) or mobile apps as an integrated part of healthcare systems. Digital transformation in health care requires the active involvement of patients as the central part of healthcare interventions. In the case of chronic health conditions, such as inflammatory bowel disease (IBD), it is believed that the adoption of new digital tools helps to maintain and extend the health and care of patients, optimizing the course of the treatment of the disease. The study goal was to undertake a literature review associating the use of chatbot technology with IBD patients' health care. This study intends to support digital product developments, mainly chatbot for IBD or other chronic diseases. The work was carried out through two literature review phases. The first one was based on a systematic approach and the second was a scoping review focused only on Frontiers Journals. This review followed a planned protocol for search and selection strategy that was created by a research team discussion. Chatbot technology for chronic disease self-management can have high acceptance and usability levels. The more interaction with a chatbot, the more patients are able to increase their self-care practice, but there is a challenge. The chatbot ontology to personalize the communication still needed to have strong guidelines helping other researchers to define which Electronic Medical Records (EMRs) should be used in the chatbots to improve the user satisfaction, engagement, and dialog quality. The literature review showed us both evidence and success of these tools in other health disorders. Some of them revealed a huge potential for conversational agents as a part of digital health interventions.
C1 [Pernencar, Claudia] Univ NOVA Lisboa, NOVA Inst Commun, NOVA Sch Social Sci & Humanities, ICNOVA, Lisbon, Portugal.
   [Pernencar, Claudia] Polytech Inst Leiria, Arts & Design Res Lab, LIDA, Leiria, Portugal.
   [Saboia, Inga] Univ Fed Ceara, UFC Virtual, Fortaleza, Brazil.
   [Saboia, Inga] Univ Aveiro, DigiMedia Dept Commun & Art, Aveiro, Portugal.
   [Dias, Joana Carmo] Res Ctr Org, COMEGI, Markets & Ind Management, Lisbon, Portugal.
   [Dias, Joana Carmo] UNIDCOM IADE Design & Commun Res Ctr, Lisbon, Portugal.
RP Pernencar, C (corresponding author), Univ NOVA Lisboa, NOVA Inst Commun, NOVA Sch Social Sci & Humanities, ICNOVA, Lisbon, Portugal.; Pernencar, C (corresponding author), Polytech Inst Leiria, Arts & Design Res Lab, LIDA, Leiria, Portugal.
EM claudiapernencar@fcsh.unl.pt
RI Pernencar, Claudia/H-9361-2016
OI Pernencar, Claudia/0000-0001-8981-2133
FU National Funds through FCT -Fundacao para a Ciencia e a Tecnologia
   [UIDB/05021/2020, UIDB/04005/2020]
FX This work was funded by the National Funds through FCT -Fundacao para a
   Ciencia e a Tecnologia under project Refa: UIDB/05021/2020 and Refa:
   UIDB/04005/2020.
CR Afzali A, 2018, INFLAMM BOWEL DIS, V24, P2, DOI 10.1093/ibd/izx015
   Ashton JJ, 2019, LANCET, V393, P1672, DOI 10.1016/S0140-6736(18)33125-8
   Ashton JJ, 2019, TRANSL PEDIATR, V8, P56, DOI 10.21037/tp.2018.12.03
   Borland D, 2019, APPL CLIN INFORM, V10, P377, DOI 10.1055/s-0039-1688938
   Cohn HM, 2016, GASTROENTEROLOGY, V150, pS992, DOI 10.1016/S0016-5085(16)33359-5
   Comendador Benilda Eleonor V., 2015, Journal of Automation and Control Engineering, V3, P137, DOI 10.12720/joace.3.2.137-140
   Dardzinska A, 2018, ACTA MECH AUTOMATICA, V12, P227, DOI 10.2478/ama-2018-0035
   Dosovitsky Gilly, 2021, Front Digit Health, V3, P735053, DOI 10.3389/fdgth.2021.735053
   Dosovitsky Gilly, 2021, Front Digit Health, V3, P645805, DOI 10.3389/fdgth.2021.645805
   Frontiers Journal, 2022, FRONTIERS
   Gratzer D, 2020, ACAD PSYCHIATR, V44, P231, DOI 10.1007/s40596-019-01170-3
   Grove C, 2021, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.606041
   Hernandez D, 2018, WALL STREET J, V9
   Huckvale K, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.2542
   Isakov O, 2017, INFLAMM BOWEL DIS, V23, P1516, DOI 10.1097/MIB.0000000000001222
   Jandoo T, 2020, DIGIT HEALTH, V6, DOI 10.1177/2055207619898984
   Koci O, 2018, PEERJ, V6, DOI 10.7717/peerj.5047
   Maenhout L, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.724779
   Mossotto E, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-02606-2
   Organization WH, 2019, WHO DIRECTOR GEN OPE
   Roccetti M, 2017, NETW MODEL ANAL HLTH, V6, DOI 10.1007/s13721-017-0152-y
   Ruggiano Nicole, 2021, J Med Internet Res, V23, pe25006, DOI 10.2196/25006
   Sandborn WJ, 2014, ALIMENT PHARM THER, V40, P903, DOI 10.1111/apt.12930
   Sels L, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.554811
   Torous J, 2018, EVID-BASED MENT HEAL, V21, P116, DOI 10.1136/eb-2018-102891
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   Vilaza Giovanna Nunes, 2021, Front Digit Health, V3, P689736, DOI 10.3389/fdgth.2021.689736
   WIRED, 2020, VIRT THER HELP VET O
   World Health Organization, 2021, GLOB STRAT DIG HLTH
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
   Yin AL, 2019, J MED INTERNET RES, V21, DOI 10.2196/14630
   Zand A, 2019, J CROHNS COLITIS, V13, pS244, DOI 10.1093/ecco-jcc/jjy222.413
   Zand A, 2020, J MED INTERNET RES, V22, DOI 10.2196/15589
NR 33
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2296-2565
J9 FRONT PUBLIC HEALTH
JI Front. Public Health
PD JUN 30
PY 2022
VL 10
AR 862432
DI 10.3389/fpubh.2022.862432
PG 13
WC Public, Environmental & Occupational Health
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Public, Environmental & Occupational Health
GA 3A5RZ
UT WOS:000827318300001
PM 35844879
OA Green Published, gold
DA 2022-08-02
ER

PT C
AU Kim, H
   Koh, DY
   Lee, G
   Park, JM
   Lim, YK
AF Kim, Hankyung
   Koh, Dong Yoon
   Lee, Gaeun
   Park, Jung-Mi
   Lim, Youn-kyung
GP Assoc Comp Machinery
TI Designing Personalities of Conversational Agents
SO CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI
   CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY MAY 04-09, 2019
CL Glasgow, SCOTLAND
SP Assoc Comp Machinery, ACM SIGCHI
DE Conversational Agent; Personality; Voice User interface; Interaction
   Design
AB Recent years have seen numerous attempts to imbue conversational agents with marked identities by crafting their personalities. However, the question remains as to how such personalities can be systematically designed. To address this problem, this paper proposes a conceptual framework for designing and communicating agent personalities. We conducted two design workshops with 12 designers, discovering three dimensions of an agent personality and three channels to express it. The study results revealed that an agent personality can be crafted by designing common traits shared within a service domain, distinctive traits added for a unique identity, and neutral traits left intentionally undecided or user-driven. Also, such a personality can be expressed through how an agent performs services, what contents it provides, and how it speaks and appears to be. Our results suggest a renewed view of the dimensions of conversational agent personalities.
C1 [Kim, Hankyung; Koh, Dong Yoon; Lim, Youn-kyung] Korea Adv Inst Sci & Technol, Dept Ind Design, Daejeon, South Korea.
   [Lee, Gaeun; Park, Jung-Mi] Samsung Res, Seoul, South Korea.
RP Kim, H (corresponding author), Korea Adv Inst Sci & Technol, Dept Ind Design, Daejeon, South Korea.
EM hkkim31@kaist.ac.kr; topdavid@kaist.ac.kr; gganni.lee@samsung.com;
   jungmi.park@samsung.com; younlim@kaist.ac.kr
FU Samsung Research Project "Humane AI: Implementation and Evaluation for
   HRI Adaptation"; Institute of Information & Communications Technology
   Planning & Evaluation (IITP) - Korea government (MSIT) [2016-0-00564]
FX This work was primarily supported by Samsung Research Project "Humane
   AI: Implementation and Evaluation for HRI Adaptation" and partially
   supported by Institute of Information & Communications Technology
   Planning & Evaluation (IITP) grant funded by the Korea government (MSIT)
   (No.2016-0-00564).
CR [Anonymous], HDB PERSONALITY THEO
   Callejas Z, 2011, CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND EFFECTIVE PRACTICES, P203, DOI 10.4018/978-1-60960-617-6.ch009
   Cohen M. H, 2004, VOICE USER INTERFACE, P75
   Danielescu A, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3174366
   Dryer DC, 1999, APPL ARTIF INTELL, V13, P273, DOI 10.1080/088395199117423
   Dwoskin E., 2016, NEXT HOT JOB SILICON
   Goetz J, 2003, RO-MAN 2003: 12TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P55
   Google Developers, 2018, CREAT PERS WHAT DOES
   Kshirsagar S., 2002, P 2 INT S SMART GRAP, P107, DOI DOI 10.1145/569005.569021
   McKenzie S, 2017, ARTIST WHO WORKED PI
   Nass C, 2012, P CHI 2012, P329
   Tapus A, 2008, INTEL SERV ROBOT, V1, P169, DOI 10.1007/s11370-008-0017-4
NR 12
TC 2
Z9 2
U1 1
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5971-9
PY 2019
DI 10.1145/3290607.3312887
PG 6
WC Computer Science, Cybernetics; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BN4JW
UT WOS:000482042102006
DA 2022-08-02
ER

PT J
AU Luo, TC
   Aguilera, A
   Lyles, CR
   Figueroa, CA
AF Luo, Tiffany Christina
   Aguilera, Adrian
   Lyles, Courtney Rees
   Figueroa, Caroline Astrid
TI Promoting Physical Activity Through Conversational Agents: Mixed Methods
   Systematic Review
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Review
DE physical activity; health behavior; behavior change; conversational
   agent; virtual agent; chatbot; digital health; eHealth; mHealth; mobile
   health; mobile phone
ID HEALTH; INTERVENTIONS; BEHAVIORS; TALK
AB Background: Regular physical activity (PA) is crucial for well-being; however, healthy habits are difficult to create and maintain. Interventions delivered via conversational agents (eg, chatbots or virtual agents) are a novel and potentially accessible way to promote PA. Thus, it is important to understand the evolving landscape of research that uses conversational agents.
   Objective: This mixed methods systematic review aims to summarize the usability and effectiveness of conversational agents in promoting PA, describe common theories and intervention components used, and identify areas for further development.
   Methods: We conducted a mixed methods systematic review. We searched seven electronic databases (PsycINFO, PubMed, Embase, CINAHL, ACM Digital Library, Scopus, and Web of Science) for quantitative, qualitative, and mixed methods studies that conveyed primary research on automated conversational agents designed to increase PA. The studies were independently screened, and their methodological quality was assessed using the Mixed Methods Appraisal Tool by 2 reviewers. Data on intervention impact and effectiveness, treatment characteristics, and challenges were extracted and analyzed using parallel-results convergent synthesis and narrative summary.
   Results: In total, 255 studies were identified, 7.8% (20) of which met our inclusion criteria. The methodological quality of the studies was varied. Overall, conversational agents had moderate usability and feasibility. Those that were evaluated through randomized controlled trials were found to be effective in promoting PA. Common challenges facing interventions were repetitive program content, high attrition, technical issues, and safety and privacy concerns.
   Conclusions: Conversational agents hold promise for PA interventions. However, there is a lack of rigorous research on long-term intervention effectiveness and patient safety. Future interventions should be based on evidence-informed theories and treatment approaches and should address users' desires for program variety, natural language processing, delivery via mobile devices, and safety and privacy concerns.
C1 [Luo, Tiffany Christina; Aguilera, Adrian; Figueroa, Caroline Astrid] Univ Calif Berkeley, Sch Social Welf, Haviland Hall, Berkeley, CA 94720 USA.
   [Aguilera, Adrian] Univ Calif San Francisco, Dept Psychiat, Zuckerberg San Francisco Gen Hosp, San Francisco, CA USA.
   [Aguilera, Adrian; Lyles, Courtney Rees] Univ Calif San Francisco, Zuckerberg San Francisco Gen Hosp, Ctr Vulnerable Populat, San Francisco, CA 94143 USA.
   [Lyles, Courtney Rees] Univ Calif San Francisco, Dept Epidemiol & Biostat, San Francisco, CA USA.
   [Lyles, Courtney Rees] Univ Calif San Francisco, Dept Med, San Francisco, CA 94143 USA.
   [Lyles, Courtney Rees] Univ Calif Berkeley, Sch Publ Hlth, Berkeley, CA 94720 USA.
RP Luo, TC (corresponding author), Univ Calif Berkeley, Sch Social Welf, Haviland Hall, Berkeley, CA 94720 USA.
EM tiffany.luo@berkeley.edu
OI Aguilera, Adrian/0000-0003-1773-8768; Luo, Tiffany/0000-0003-4461-8585;
   Figueroa, Caroline/0000-0003-0692-2244
CR [Anonymous], 1977, SOCIAL LEARNING THEO
   [Anonymous], 2020, ADULT PHYS IN PREV M
   [Anonymous], 2018, GLOB HLTH OBS DAT RE
   Bandura A, 2001, ANNU REV PSYCHOL, V52, P1, DOI 10.1146/annurev.psych.52.1.1
   Bendig E., 2019, VERHALTENSTHERAPIE, P1, DOI [10.1159/000501812, DOI 10.1159/000501812]
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore TW, 2013, J AM GERIATR SOC, V61, P1676, DOI 10.1111/jgs.12449
   Bickmore TW, 2013, PATIENT EDUC COUNS, V92, P142, DOI 10.1016/j.pec.2013.05.011
   Bickmore TW, 2011, J BIOMED INFORM, V44, P183, DOI 10.1016/j.jbi.2010.12.006
   Bickmore TW, 2010, INTERACT COMPUT, V22, P276, DOI 10.1016/j.intcom.2010.02.001
   Bickmore TW, 2005, INTERACT COMPUT, V17, P711, DOI 10.1016/j.intcom.2005.09.002
   Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158
   Direito A, 2017, ANN BEHAV MED, V51, P226, DOI 10.1007/s12160-016-9846-0
   Fadhil A, 2019, P RECENT ADV NATURAL, P295, DOI [10.26615/978-954-452-056-4_034, DOI 10.26615/978-954-452-056-4_034]
   Fadhil A, 2019, METHOD INFORM MED, V58, P9, DOI 10.1055/s-0039-1688757
   Festinger L., 1957, THEORY COGNITIVE DIS
   Friederichs S, 2014, J MED INTERNET RES, V16, DOI 10.2196/jmir.2974
   Gardiner PM, 2017, PATIENT EDUC COUNS, V100, P1720, DOI 10.1016/j.pec.2017.04.015
   Gardner B, 2012, BRIT J GEN PRACT, V62, P664, DOI 10.3399/bjgp12X659466
   Glanz K., 2008, HLTH BEHAV HLTH ED, V4th
   Harasim L., 2017, LEARNING THEORY ONLI
   Hofstede G., 2001, ONLINE READINGS PSYC, DOI 10.9707/2307-0919.1014
   Hong Q., 2018, MCGILL, P1
   Hong QN, 2018, EDUC INFORM, V34, P285, DOI 10.3233/EFI-180221
   Kocaballi AB, 2019, J MED INTERNET RES, V21, DOI 10.2196/15360
   Kocielnik Rafal, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3214273
   Kramer JN, 2020, ANN BEHAV MED, V54, P518, DOI 10.1093/abm/kaaa002
   Kramer JN, 2019, JMIR RES PROTOC, V8, DOI 10.2196/11540
   Kramer LL, 2020, J MED INTERNET RES, V22, DOI 10.2196/14058
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Luo TC, 2020, OSF HOME
   Maher CA, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/17558
   MARCUS BH, 1994, MED SCI SPORT EXER, V26, P1400
   Martin K., 2020, ARXIV PREPRINT ARXIV
   Moher David, 2009, Ann Intern Med, V151, P264, DOI 10.1136/bmj.b2535
   Muellmann S, 2018, PREV MED, V108, P93, DOI 10.1016/j.ypmed.2017.12.026
   Murray E, 2016, AM J PREV MED, V51, P843, DOI 10.1016/j.amepre.2016.06.008
   Noyes J, 2019, BMJ GLOB HEALTH, V4, DOI 10.1136/bmjgh-2018-000893
   O'Shea J, 2011, INTEL SYST REF LIBR, V10, P201, DOI 10.1007/978-3-642-17931-0_8
   Olafsson S, 2019, INT CONF PER COMP, P31, DOI 10.1145/3329189.3329202
   Pace R, 2012, INT J NURS STUD, V49, P47, DOI 10.1016/j.ijnurstu.2011.07.002
   Piao M, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/15085
   Hong QN, 2017, SYST REV-LONDON, V6, DOI 10.1186/s13643-017-0454-2
   Romeo A, 2019, J MED INTERNET RES, V21, DOI 10.2196/12053
   Salwen-Deremer JK, 2019, J TECHNOL BEHAV SCI, V5, P51, DOI [10.1007/s41347-019-00118-6, DOI 10.1007/S41347-019-00118-6]
   Schoeppe S, 2016, INT J BEHAV NUTR PHY, V13, DOI 10.1186/s12966-016-0454-y
   Schwarzer R, 2008, EUR PSYCHOL, V13, P141, DOI 10.1027/1016-9040.13.2.141
   Sillice MA, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.7640
   Simila H, 2014, 13 MED C MED BIOL EN, P1197
   Tacconelli E., 2010, LANCET INFECT DIS, V10, P226, DOI [DOI 10.1016/S1473-3099(10)70065-7, 10.1016/S1473-3099(10)70065-7]
   Taylor-Pashow KML, 2019, SOLVENT EXTR ION EXC, V37, P1, DOI 10.1080/07366299.2019.1592924
   Vainio J, 2014, P 8 INT C PERV COMP, DOI [10.4108/icst.pervasivehealth.2014.254951, DOI 10.4108/ICST.PERVASIVEHEALTH.2014.254951]
   Watson A, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.1629
   World Health Organization, 2018, GLOB ACT PLAN PHYS A
   Zhou S, 2017, 2017 INTERNATIONAL CONFERENCE ON CULTURE AND COMPUTING (CULTURE AND COMPUTING), P89, DOI 10.1109/Culture.and.Computing.2017.42
NR 56
TC 2
Z9 2
U1 5
U2 10
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD SEP 14
PY 2021
VL 23
IS 9
AR e25486
DI 10.2196/25486
PG 17
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA UR2YF
UT WOS:000696619000001
PM 34519653
OA Green Published, gold
DA 2022-08-02
ER

PT J
AU Adikari, A
   de Silva, D
   Moraliyage, H
   Alahakoon, D
   Wong, JH
   Gancarz, M
   Chackochan, S
   Park, B
   Heo, R
   Leung, Y
AF Adikari, Achini
   de Silva, Daswin
   Moraliyage, Harsha
   Alahakoon, Damminda
   Wong, Jiahui
   Gancarz, Mathew
   Chackochan, Suja
   Park, Bomi
   Heo, Rachel
   Leung, Yvonne
TI Empathic conversational agents for real-time monitoring and
   co-facilitation of patient-centered healthcare
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
LA English
DT Article
DE Chatbots; Conversational agents; Patient-centered care; Cancer care;
   Empathic AI; Human-centric AI; Patient emotions; Group emotions;
   Real-time monitoring; Co-facilitation; Markov models; Artificial
   intelligence
ID EMOTIONS; SUPPORT
AB Healthcare systems across the world are transitioning into patient-centered healthcare models to ensure improved health outcomes, increased operational efficiencies and respectful patient engagement. Digital health technologies are at the forefront of this transition in facilitating a role for the patient in the clinical dimensions of the healthcare trajectory, from diagnosis and interventions to treatment and recovery. Despite this prevalence in the clinical space, the non-clinical needs of patient mental health and wellbeing are frequently overlooked by contemporary patient-centered healthcare models. Conversational agents (or chatbots) are digital dialogue systems that are widespread and widely used in sequential information provision and information acquisition tasks. Given the intimate nature of this human-machine interaction, conversational agents can be effectively utilized to support and sustain patient mental health and wellbeing. In this paper, we propose an empathic conversational agent framework based on an ensemble of natural language processing techniques and artificial intelligence algorithms for real-time monitoring and co-facilitation of patient-centered healthcare for improved mental health and wellbeing outcomes. The technical contributions of this framework are; detection of patient emotions, prediction of patient emotion transitions, detection of group emotions, formulation of patient behavioral metrics, and resource recommendations based on patient concerns. The architectural contributions of the framework are intelligent communication channels that stream empathic conversational elements and resource recommendations for the multi-user conversations and co-facilitation updates for the human healthcare provider interface. The framework was empirically evaluated on a benchmark dataset and further validated based on a clinical protocol designed for its application in an online support group setting for cancer patients and caregivers in Canada. The results of these experiments confirm the effectiveness of this framework, its contributory role and practical value in realizing a patient-centered healthcare model for improved mental health and wellbeing outcomes. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Adikari, Achini; de Silva, Daswin; Moraliyage, Harsha; Alahakoon, Damminda] La Trobe Univ, Ctr Data Analyt & Cognit, Bundoora, Vic 3083, Australia.
   [Wong, Jiahui; Gancarz, Mathew; Chackochan, Suja; Leung, Yvonne] De Souza Inst, Toronto, ON, Canada.
   [Park, Bomi; Heo, Rachel; Leung, Yvonne] Univ Toronto, Fac Med, Dept Psychiat, Toronto, ON, Canada.
RP Adikari, A (corresponding author), La Trobe Univ, Ctr Data Analyt & Cognit, Bundoora, Vic 3083, Australia.
EM a.adikari@latrobe.edu.au
OI Moraliyage, Harsha/0000-0002-6212-8312; Adikari,
   Achini/0000-0001-5112-5063
FU Ontario Institute for Cancer Research, Cancer Care Ontario Health
   Services Research Network [P.HSR.147]
FX This research was supported by a grant from Ontario Insti-tute for
   Cancer Research, Cancer Care Ontario Health Services Research Network.
   Grant P.HSR.147.
CR Adikari A, 2021, IEEE T IND INFORM, V17, P2743, DOI 10.1109/TII.2020.3009277
   Adikari A, 2021, FUTURE GENER COMP SY, V116, P302, DOI 10.1016/j.future.2020.10.028
   Adikari A, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229361
   Adikari A, 2019, IEEE INTL CONF IND I, P183, DOI 10.1109/INDIN41052.2019.8972196
   Agarwal A., 2021, ARXIV210101334CS, V2021
   Aizawa A, 2003, INFORM PROCESS MANAG, V39, P45, DOI 10.1016/S0306-4573(02)00021-3
   Almansor EH, 2020, ADV INTELL SYST, V993, P534, DOI 10.1007/978-3-030-22354-0_47
   Altebarmakian M, 2019, INT J COMP-SUPP COLL, V14, P443, DOI 10.1007/s11412-019-09309-y
   [Anonymous], 2021, GLOVE GLOBAL VECTORS
   [Anonymous], 2021, STATE OF THE ART OPE
   [Anonymous], 2019, CUSTOMER SUPPORT TWI
   [Anonymous], 2021, CONVERSATIONAL AGENT
   Antheunis ML, 2013, PATIENT EDUC COUNS, V92, P426, DOI 10.1016/j.pec.2013.06.020
   Atzeni M, 2020, FUTURE GENER COMP SY, V110, P984, DOI 10.1016/j.future.2019.10.012
   Balint E, 1969, J R Coll Gen Pract, V17, P269
   Banchs RE, 2017, ASIAPAC SIGN INFO PR, P1364, DOI 10.1109/APSIPA.2017.8282245
   Bandaragoda T, 2018, ANN SURG ONCOL, V25, P1737, DOI 10.1245/s10434-018-6372-2
   Bar-Lev S, 2008, QUAL HEALTH RES, V18, P509, DOI 10.1177/1049732307311680
   Barak A, 2008, COMPUT HUM BEHAV, V24, P1867, DOI 10.1016/j.chb.2008.02.004
   Bendig E., 2019, VERHALTENSTHERAPIE, P1, DOI [10.1159/000501812, DOI 10.1159/000501812]
   Bertero Dario, 2016, P 2016 C EMPIRICAL M, P1042, DOI 10.18653/v1/D16-1110
   Bone Daniel, 2017, IEEE Signal Processing Magazine, V34, p196, 189, 190, DOI 10.1109/MSP.2017.2718581
   Borek AJ, 2019, BRIT J HEALTH PSYCH, V24, P787, DOI 10.1111/bjhp.12379
   Cancer chat Canada at de souza institute, 2020, CANC CHAT CAN
   Dale R, 2016, NAT LANG ENG, V22, P811, DOI 10.1017/S1351324916000243
   Daniel F, 2018, 2018 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON SOFTWARE ENGINEERING FOR COGNITIVE SERVICES (SE4COG), P31, DOI 10.1145/3195555.3195563
   De Silva D, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0205855
   Demiris G, 2008, J AM MED INFORM ASSN, V15, P8, DOI 10.1197/jamia.M2492
   Eikelboom J, 2001, BRIT MED J, V322, P1192, DOI 10.1136/bmj.322.7296.1192
   Folstad A., 2017, INTERACTIONS, V24, P38, DOI [10.1145/3085558, DOI 10.1145/3085558]
   Hoy Matthew B., 2018, Medical Reference Services Quarterly, V37, P81, DOI 10.1080/02763869.2018.1404391
   I. of M. (US) C. on the N.Q.R. on H.C. Delivery U.S.a. for H. Research, 2001, ENV NAT HLTH CAR QUA
   Kretzschmar K, 2019, BIOMED INFORM INSIGH, V11, DOI 10.1177/1178222619829083
   Lee D, 2017, INT CONF BIG DATA, P437, DOI 10.1109/BIGCOMP.2017.7881752
   Leung Y., 2020, JMIR RES PROTOC ACCE
   Lin ZJ, 2020, AAAI CONF ARTIF INTE, V34, P13622
   Mikolov T., 2013, ARXIV, V1301, P3781
   Millenson M.L., 2015, ROAD MAKING PATIENT
   Mohr DC, 2017, ANNU REV CLIN PSYCHO, V13, P23, DOI 10.1146/annurev-clinpsy-032816-044949
   Oh KJ, 2017, IEEE INT CONF MOB DA, P371, DOI 10.1109/MDM.2017.64
   Pennington J., 2014, P 2014 C EMPIRICAL M, P1532
   PLUTCHIK R, 1982, SOC SCI INFORM, V21, P529, DOI 10.1177/053901882021004003
   Ranasinghe W, 2018, UROL ONCOL-SEMIN ORI, V36, DOI 10.1016/j.urolonc.2018.08.012
   Recupero DR, 2019, IEEE COMPUT INTELL M, V14, P77, DOI 10.1109/MCI.2019.2937614
   Reyes A, 2012, DATA KNOWL ENG, V74, P1, DOI 10.1016/j.datak.2012.02.005
   Shen GY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3838
   Shumanov M, 2021, COMPUT HUM BEHAV, V117, DOI 10.1016/j.chb.2020.106627
   Tatai G, 2003, LECT NOTES ARTIF INT, V2792, P5
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   Wang, 2014, P 2014 INT C MULT FU, P1
   Westerman D, 2019, COMMUN STUD, V70, P295, DOI 10.1080/10510974.2018.1557233
   Yu DM, 2008, 10TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, P265
   Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI [10.1162/coli_a_00368, 10.1162/COLI_a_00368]
NR 53
TC 3
Z9 3
U1 7
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-739X
EI 1872-7115
J9 FUTURE GENER COMP SY
JI Futur. Gener. Comp. Syst.
PD JAN
PY 2022
VL 126
BP 318
EP 329
DI 10.1016/j.future.2021.08.015
EA SEP 2021
PG 12
WC Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA UZ0HB
UT WOS:000701892900008
DA 2022-08-02
ER

PT S
AU O'Shea, J
   Bandar, Z
   Crockett, K
AF O'Shea, James
   Bandar, Zuhair
   Crockett, Keeley
BE Tolk, A
   Jain, LC
TI Systems Engineering and Conversational Agents
SO INTELLIGENCE-BASED SYSTEMS ENGINEERING
SE Intelligent Systems Reference Library
LA English
DT Article; Book Chapter
DE Conversational agent; systems engineering; dialogue; evaluation;
   methodology; semantic similarity; short text
ID SEMANTIC SIMILARITY; INFORMATION; LANGUAGE; DESIGN; GUIDE
AB This chapter describes Conversational Agents (CAs) in the context of Systems Engineering. A CA is a computer program which interacts with a user through natural language dialogue and provides some form of service. CA technology has two points of interest to systems engineers: the use of systems engineering techniques in CA research and the application of CAs in project development. CAs offer the opportunity to automate more complex applications than are feasible with conventional web interfaces. Currently such applications require a human expert in the domain to mediate between the user and the application. The CA effectively replaces the human expert. This chapter reviews the current capabilities of various CA technologies, outlines a development methodology for systems engineering practitioners interested in developing real world applications and suggests a number of directions for systems engineers who wish to participate in CA research.
C1 [O'Shea, James; Bandar, Zuhair; Crockett, Keeley] Manchester Metropolitan Univ, Sch Comp Math & Digital Technol, Manchester M1 5GD, Lancs, England.
RP O'Shea, J (corresponding author), Manchester Metropolitan Univ, Sch Comp Math & Digital Technol, Chester St, Manchester M1 5GD, Lancs, England.
EM j.d.oshea@mmu.ac.uk; z.bandar@mmu.ac.uk; k.crockett@mmu.ac.uk
CR Achananuparp P, 2008, LECT NOTES COMPUT SC, V5182, P305, DOI 10.1007/978-3-540-85836-2_29
   ANDERNACH T, 1995, 15 INT C LANG ENG AI, P351
   Andersen V, 2003, APPL ARTIF INTELL, V17, P745, DOI [10.1080/713827257, 10.1080/08839510390225140]
   [Anonymous], 1990, COGNITIVE STRUCTURE
   Austin, 1975, THINGS WORDS W JAMES
   Babu S, 2006, LECT NOTES ARTIF INT, V4133, P169
   *BBC, 2009, TOR CRIT FLU ADV LIN
   BEVACQUA E, 2007, AISB 2007 ARTIFICIAL
   BICKMORE T, 2000, AM ASS ARTIFICIAL IN, P4
   Bickmore T, 2006, J BIOMED INFORM, V39, P556, DOI 10.1016/j.jbi.2005.12.004
   BLOCK N, 1981, PHILOS REV, V90, P5, DOI 10.2307/2184371
   BOHUS D, 2009, SIGDIAL 2009 C 10 AN
   Bohus D., 2009, SIGDIAL 09 P SIGDIAL, P225, DOI [10.3115/1708376.1708409, DOI 10.3115/1708376.1708409]
   Bouwman G, 1999, INT CONF ACOUST SPEE, P493, DOI 10.1109/ICASSP.1999.758170
   BOUWMAN G, 1998, 1 INT C LANG RES EV, P191
   Brent J, 2008, P 7 INT JOINT C AUT, P199
   Capuano N, 2009, ICALT: 2009 IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, P484, DOI 10.1109/ICALT.2009.53
   Cassell J., 1999, Autonomous Agents and Multi-Agent Systems, V2, P45, DOI 10.1023/A:1010027123541
   Cassell J, 2003, USER MODEL USER-ADAP, V13, P89, DOI 10.1023/A:1024026532471
   Cassell J, 2001, KNOWL-BASED SYST, V14, P55, DOI 10.1016/S0950-7051(00)00102-7
   CASSELL J, 2000, EMBODIED CAS
   Cheongjae Lee, 2010, Journal of Computing Science and Engineering, V4, P1
   CROCKETT K, 2009, KNOWLEDGE REASONING, P1
   De Angeli A, 2009, PSYCHNOLOGY J, V7, P49
   Deerwester SC, 1989, COMPUTER INFORM RETR
   Dehaene S, 2001, COGNITION, V79, P1, DOI 10.1016/S0010-0277(00)00123-2
   DETHLEFS N, 2010, SEMDIAL 2010 14 WORK
   DeVault David, 2009, P SIGDIAL LOND UK, P11
   Farquhar A, 1997, INT J HUM-COMPUT ST, V46, P707, DOI 10.1006/ijhc.1996.0121
   Fenton N., 2014, SOFTWARE METRICS RIG, V3rd
   FERRI F, 2007, 19 INT C SOFTW ENG K, P664
   Forbes-Riley K, 2011, COMPUT SPEECH LANG, V25, P105, DOI 10.1016/j.csl.2009.12.002
   Foster ME, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1818
   Gacitua-Decar V, 2009, 2009 WORLD CONFERENCE ON SERVICES PART, P111, DOI 10.1109/SERVICES-2.2009.28
   Gergle D, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1543
   GIRAUDO E, 2009, EVALUATION NLP SPEEC
   GLASS J, 2004, 4 INT C COMP AID DES, P347
   Gorin AL, 1997, SPEECH COMMUN, V23, P113, DOI 10.1016/S0167-6393(97)00040-X
   Graesser AC, 2005, IEEE T EDUC, V48, P612, DOI 10.1109/TE.2005.856149
   GUNDERSON K, 1964, MIND, V73, P234
   HILLARD DL, 2008, ELECT ENG
   HOSOM JP, 2003, AUTOMATIC SPEECH REC, P20
   Huang JJ, 2008, CONSUM COMM NETWORK, P289, DOI 10.1109/ccnc08.2007.71
   HULSTIJN H, 1996, TWENT WORKSH LANG TE, V11
   HUNT A, 1997, COMP SPEECH FAQ 6
   Hunt M. J., 1990, SPEECH COMMUN, V9, P239
   Inkpen D., 2007, STUD U BABES BOLYAI, VLII, P11
   Jackson P., 2007, NATURAL LANGUAGE PRO, V2nd
   KATO T, 2010, SIGIR 2010 33 ANN IN, P3
   KEGEL, 2010, KEGEL OLDEST HARLEY
   Kopp S, 2005, LECT NOTES ARTIF INT, V3661, P329
   Laham D., 1998, LATENT SEMANTIC ANAL
   Lamel L, 2002, SPEECH COMMUN, V38, P131, DOI 10.1016/S0167-6393(01)00048-6
   Lamel LF, 1997, SPEECH COMMUN, V23, P67, DOI 10.1016/S0167-6393(97)00037-X
   LANCE B, 2008, 7 INT C AUT AG MULT, P199
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   Le Bigot L, 2004, APPL ERGON, V35, P557, DOI 10.1016/j.apergo.2004.06.001
   LEFEVRE F, 2009, SIGDIAL 2009 C 10 AN, P272
   Li YH, 2003, IEEE T KNOWL DATA EN, V15, P871, DOI 10.1109/TKDE.2003.1209005
   Li YH, 2006, IEEE T KNOWL DATA EN, V18, P1138, DOI 10.1109/TKDE.2006.130
   Litman DJ, 2002, USER MODEL USER-ADAP, V12, P111, DOI 10.1023/A:1015036910358
   Liu XY, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P250, DOI 10.1109/ICSC.2007.48
   Massaro DW, 2000, EMBODIED CONVERSATIONAL AGENTS, P287
   MCGEARY Z, 2005, CUSTOMER RELATIONSHI
   McKevitt P, 1999, INT J HUM-COMPUT ST, V51, P947, DOI 10.1006/ijhc.1999.0271
   MICHIE D, 2001, RETURN IMITATION GAM, V6, P205
   MIN F, 2006, 2 INT C SEM KNOWL GR, P41
   MINKER W, 1996, 4 INT C SPOK LANG IC, P1013
   MORGE M, 2010, 9 INT C AUT AG MULT, P127
   O'Shea K., 2009, LECT NOTES ELECT ENG, V39, P505
   O'Shea K, 2008, LECT NOTES ENG COMP, P321
   OPDENAKKER H, 2009, SIGDIAL 2009 C 10 AN, P21
   OSHEA J, 2010, COMPUTING MATH MANCH
   OWDA M, 2007, IEEE WIC ACM INT C W
   PLANTEC P, 1998, ZEN SCRIPTING VERBOT
   RAUT CK, 2009, EMMANUEL COLL
   Resnik P, 1999, J ARTIF INTELL RES, V11, P95, DOI 10.1613/jair.514
   RIGO S, 2009, EVALUATION NLP SPEEC
   Robinson S, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P1125
   SAGAE K, 2009, NAACL HLT 2009, P53
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   SAMMUT C, 2001, ELECT T ARTIFICIAL I, V5, P191
   SANDERS GA, 2000, EMBODIED CAS
   Searle J. R., 1999, MIND LANGUAGE SOC
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038
   Semeraro G, 2003, LECT NOTES COMPUT SC, V2615, P360
   SKANTZE G, 2009, SIGDIAL 2009 C 10 AN, P310
   SPARCKJONES K, 1972, J DOC, V28, P11, DOI 10.1108/eb026526
   Tsatsaronis G, 2010, J ARTIF INTELL RES, V37, P1, DOI 10.1613/jair.2880
   Turing AM., 1950, J MIND ASS, V59, P433, DOI [10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   Walker MA, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P271
   Walker MA, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P515
   WALKER MA, 2000, LANGUAGE RESOURCES E
   WALKER MA, 2002, INT C NAT LANG GEN, P73
   Webb N, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Young S, 2010, COMPUT SPEECH LANG, V24, P150, DOI 10.1016/j.csl.2009.04.001
   Yuan X, 2005, COMPUT ANIMAT VIRT W, V16, P109, DOI 10.1002/cav.65
   Zdenek S, 2001, MIND MACH, V11, P53, DOI 10.1023/A:1011214808628
   ZDRAVKOVA K, 2000, 22 INT C INF TECHN I, P189
   [No title captured]
NR 100
TC 13
Z9 13
U1 0
U2 2
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 1868-4394
EI 1868-4408
BN 978-3-642-17930-3
J9 INTEL SYST REF LIBR
PY 2011
VL 10
BP 201
EP 232
DI 10.1007/978-3-642-17931-0_8
D2 10.1007/978-3-642-17931-0
PG 32
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Software Engineering
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BWA74
UT WOS:000293318100008
DA 2022-08-02
ER

PT C
AU Noori, Z
   Crockett, K
   Bandar, Z
   Al-Mousa, M
AF Noori, Zaid
   Crockett, Keeley
   Bandar, Zuhair
   Al-Mousa, Mohammed
GP IEEE
TI An Arabic Word Similarity Measure for Semantic Conversational Agents
SO 2018 IEEE 2ND INTERNATIONAL WORKSHOP ON ARABIC AND DERIVED SCRIPT
   ANALYSIS AND RECOGNITION (ASAR)
LA English
DT Proceedings Paper
CT 2nd IEEE International Workshop on Arabic and Derived Script Analysis
   and Recognition (IEEE ASAR)
CY MAR 12-14, 2018
CL Alan Turing Inst, London, ENGLAND
SP IEEE, British Lib, Lab Lorrain Rech Informatique Ses Applicat, Res Grp Intelligent Machines Lab, a2ia
HO Alan Turing Inst
DE word similarity; semantics; lexical tree; conversational agents
AB Word similarity measures are used to measure the semantic relatedness between two words. Whereas traditional English measures exist, relatively little research has been undertaken in developing such measures for Modern Standard Arabic largely due to the linguistic challenges of the language. Domain coverage is also an issue when looking to select the best measure for incorporation into a semantic conversational agent. The information source used within the measure should be general yet capable of dealing with domain specific language to ensure robust and appropriate responses. This paper proposes a word similarity measure that utilises the length, and depth of the words from within a domain specific lexical tree that is used as the information source. The measure is compared with an existing Arabic word similarity measure through evaluation on a generic published dataset and the results show the new measure gives high correlation with human ratings.
C1 [Noori, Zaid] Minist Foreign Affairs, Iraqi Ambassador, Baghdad, Iraq.
   [Crockett, Keeley] Manchester Metropolitan Univ, Sch Comp Math & Digital Technol, Manchester M1 5GD, Lancs, England.
   [Bandar, Zuhair] Silen Talker Ltd, Manchester, Lancs, England.
   [Al-Mousa, Mohammed] Neaimy LLC, Washington, DC USA.
RP Noori, Z (corresponding author), Minist Foreign Affairs, Iraqi Ambassador, Baghdad, Iraq.
EM zaidnori@yahoo.co.uk; K.Crockett@mmu.ac.uk;
   zuhair.bandar@silent-talker.com; m.moses@neaimy.com
CR Almarsoomi FA, 2013, IEEE SYS MAN CYBERN, P504, DOI 10.1109/SMC.2013.92
   Alobaidi Omar G., 2015, 7th International Conference on Agents and Artificial Intelligence (ICAART 2015). Proceedings, P361
   Buckwalter Tim, 2002, ARABIC MORPHOLOGY AN
   Hijjawi M, 2016, INT J ADV COMPUT SC, V7, P332
   Hongzhe Liu, 2013, Journal of Software, V8, P1451, DOI 10.4304/jsw.8.6.1451-1458
   Li YH, 2006, IEEE T KNOWL DATA EN, V18, P1138, DOI 10.1109/TKDE.2006.130
   MILLER GA, 1991, LANG COGNITIVE PROC, V6, P1, DOI 10.1080/01690969108406936
   Noori Z, 2014, IEANG 2014, V2014, P5
   O'Shea J., 2010, INTELLIGENCE BASED S, V10
   O'shea James, 2013, ACM T SPEECH LANGUAG, V10
   O'Shea K., 2010, INT J INTELLIGENT CO, V1, P23
   Pease A, 2011, ONTOLOGYPORTAL
   Reed SK, 2015, COGN SYST RES, V33, P122, DOI 10.1016/j.cogsys.2014.06.001
NR 13
TC 0
Z9 0
U1 0
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-5386-1459-4
PY 2018
BP 119
EP 123
PG 5
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Linguistics
GA BL1RK
UT WOS:000448176500022
DA 2022-08-02
ER

PT C
AU Jain, A
   Pecune, F
   Matsuyama, Y
   Cassell, J
AF Jain, Alankar
   Pecune, Florian
   Matsuyama, Yoichi
   Cassell, Justine
GP ACM
TI A User Simulator Architecture for Socially-Aware Conversational Agents
SO 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18)
LA English
DT Proceedings Paper
CT 18th ACM International Conference on Intelligent Virtual Agents (IVA)
CY NOV 05-08, 2018
CL Western Sydney Univ, New Parramatta City Campus, Sydney, AUSTRALIA
SP ACM, ACM SigAI, Wargaming, DXC, Macquarie Univ, MARCS Inst
HO Western Sydney Univ, New Parramatta City Campus
DE User simulator; dialog system; conversational agent; rapport
AB Over the last two decades, Reinforcement Learning (RL) has emerged the method of choice for data-driven dialog management. However, one of the limitations of RL methods for the optimization of dialog managers in the context of virtual conversational agents, is that they require a large amount of data, which is often unavailable, particularly when the dialog deals with complex discourse phenomena. User simulators help address this problem by generating synthetic data to train RL agents in an online fashion. In this work, we extend user simulators to the case of socially-aware conversational agents, that combine task and social functions. We propose a novel architecture that takes into consideration the user's conversational goals and generates both task and social behaviour. Our proposed architecture is general enough to be useful for training socially-aware conversational agents in any domain. As a proof of concept, we construct a user simulator for training a conversational recommendation agent and provide evidence towards the effectiveness of the approach.
C1 [Jain, Alankar; Pecune, Florian; Matsuyama, Yoichi; Cassell, Justine] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.
RP Jain, A (corresponding author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.
EM alankarj@cs.cmu.edu; fpecune@cs.cmu.edu; yoichim@cs.cmu.edu;
   justine@cs.cmu.edu
OI Pecune, Florian/0000-0002-3235-2575
FU Microsoft; LivePerson; Google; IT R&D program of MSIP/IITP
   [2017-0-00255]
FX This work was supported in part by generous funding from Microsoft,
   LivePerson, Google, and the IT R&D program of MSIP/IITP [2017-0-00255,
   Autonomous Digital Companion Development]. We would also like to thank
   all the members of Articulab in Carnegie Mellon University for their
   useful feedback.
CR AMBADY N, 1992, PSYCHOL BULL, V111, P256, DOI 10.1037/0033-2909.111.2.256
   [Anonymous], 2013, P ICML
   Bickmore TW, 2013, AUTON AGENT MULTI-AG, V27, P254, DOI 10.1007/s10458-012-9216-7
   Cassell J, 2003, USER MODEL USER-ADAP, V13, P89, DOI 10.1023/A:1024026532471
   Chandramohan Senthilkumar, 2011, C INT SPEECH COMM AS
   COLLINS NL, 1994, PSYCHOL BULL, V116, P457, DOI 10.1037/0033-2909.116.3.457
   DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061
   Drolet AL, 2000, J EXP SOC PSYCHOL, V36, P26, DOI 10.1006/jesp.1999.1395
   Ferreira E, 2015, COMPUT SPEECH LANG, V34, P256, DOI 10.1016/j.csl.2015.03.007
   Fraser N. M., 1991, Computer Speech and Language, V5, P81, DOI 10.1016/0885-2308(91)90019-M
   Georgila Kallirroi, 2010, P 11 ANN M SPEC INT, P103
   Gordon G, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3951
   Keizer Simon, 2012, DATA DRIVEN METHODS, P39
   Leite I., 2011, P INT C US MOD AD PE, P135
   Lemon O., 2012, DATA DRIVEN METHODS
   Li X., 2016, ARXIV161205688
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Mandal G, 2015, J HIGH ENERGY PHYS, DOI 10.1007/JHEP08(2015)013
   Matsuyama Y., 2016, P 17 ANN M SPEC INT, P224
   Pecune F, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P1241
   Pietquin O, 2013, KNOWL ENG REV, V28, P59, DOI 10.1017/S0269888912000343
   Pynadath DV, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1181
   Rich Charles, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P327, DOI 10.1007/978-3-642-33197-8_34
   Rieser V, 2011, THEOR APPL NAT LANG, P1, DOI 10.1007/978-3-642-24942-6
   Ritschel Hannes, 2017, ADAPTING ROBOTS LING
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Schatzmann J., 2007, HUMAN LANGUAGE TECHN, P149
   Schatzmann Jost, 2007, P SIGDIAL ANTW, P9
   Singh S, 2000, ADV NEUR IN, V12, P956
   Spencer-Oatey H, 2005, POLITENESS FACE PERC
   Steve Matt Stuttle, 2006, KNOWL ENG REV, V1, P24
   Tracy, 1990, J LANG SOC PSYCHOL, V9, P1, DOI DOI 10.1177/0261927X9091001
   WELCH BL, 1947, BIOMETRIKA, V34, P28, DOI 10.1093/biomet/34.1-2.28
   Wilks Yorick, 2010, CLOSE ENGAGEMENTS AR, V8
   Williams JD, 2008, SPEECH COMMUN, V50, P829, DOI 10.1016/j.specom.2008.05.007
   Young Steve, 2010, 11 ANN C INT SPEECH
   Yu Zhou, 2017, INT JOINT C ART INT
   Zhao R, 2016, LECT NOTES ARTIF INT, V10011, P218, DOI 10.1007/978-3-319-47665-0_20
   Zhao R, 2014, LECT NOTES ARTIF INT, V8637, P514, DOI 10.1007/978-3-319-09767-1_62
NR 40
TC 6
Z9 6
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6013-5
PY 2018
BP 133
EP 140
DI 10.1145/3267851.3267916
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BO3RU
UT WOS:000511376500020
DA 2022-08-02
ER

PT C
AU Luger, E
   Sellen, A
AF Luger, Ewa
   Sellen, Abigail
GP ACM
TI "Like Having a Really bad PA": The Gulf between User Expection and
   Experience of Conversational Agents
SO 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI
   2016
LA English
DT Proceedings Paper
CT 34th Annual CHI Conference on Human Factors in Computing Systems
   (CHI4GOOD)
CY MAY 07-12, 2016
CL San Jose, CA
SP Assoc Comp Machinery, SIG CHI
DE Conversational Agents; mental models; evaluation; H.5.m. Information
   interfaces and presentation (e.g., HCI): Miscellaneous
AB The past four years have seen the rise of conversational agents (CAs) in everyday life. Apple, Microsoft, Amazon, Google and Facebook have all embedded proprietary CAs within their software and, increasingly, conversation is becoming a key mode of human-computer interaction. Whilst we have long been familiar with the notion of computers that speak, the investigative concern within HCI has been upon multimodality rather than dialogue alone, and there is no sense of how such interfaces are used in everyday life. This paper reports the findings of interviews with 14 users of CAs in an effort to understand the current interactional factors affecting everyday use. We find user expectations dramatically out of step with the operation of the systems, particularly in terms of known machine intelligence, system capability and goals. Using Norman's 'gulfs of execution and evaluation' [30] we consider the implications of these findings for the design of future systems.
C1 [Luger, Ewa; Sellen, Abigail] Microsoft Res, Cambridge, England.
RP Luger, E (corresponding author), Microsoft Res, Cambridge, England.
EM ewluge@microsoft.com; asellen@microsoft.com
CR [Anonymous], 2010, CLOSE ENGAGEMENTS AR
   [Anonymous], 2014, AS PAC SIGN INF PROC
   Attride-Stirling J., 2001, QUALITATIVE RES, V1, P385, DOI DOI 10.1177/146879410100100307
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Boden Margaret A, 2007, P ART COMP SOC PERS
   Bolt R. A., 1980, Computer Graphics, V14, P262
   Brennan S., 1990, ART HUMAN COMPUTER I
   Bryman A, 2016, SOCIAL RES METHODS
   Cassell J, 2001, AI MAG, V22, P67
   Cassell J, 2000, EMBODIED CONVERSATIONAL AGENTS, P29
   D'Onfro Jilian, 2015, MICROSOFT CREATED CH
   Davis Martin, 2000, ENGINES LOGIC MATH O
   Dey A. K., 2005, ACM Transactions on Computer-Human Interaction, V12, P53, DOI 10.1145/1057237.1057241
   Don A., 1992, P SIGCHI C HUM FACT, V2, P67
   Dragone M, 2005, LECT NOTES ARTIF INT, V3661, P166
   Glass J. R., 1999, P IEEE WORKSH AUT SP
   Goffman Erving., 1967, INTERACTION RITUAL E
   Graesser AC, 2014, CURR DIR PSYCHOL SCI, V23, P374, DOI 10.1177/0963721414540680
   Guest G, 2006, FIELD METHOD, V18, P59, DOI 10.1177/1525822X05279903
   Gustafson J, 2005, LECT NOTES ARTIF INT, V3661, P37
   Habermas Jurgen., 1998, PRAGMATICS COMMUNICA, P403
   Harper R., 2010, TEXTURE HUMAN EXPRES
   Heuwinkel  Kerstin, 2012, YOUR VIRTUAL BUTLER, P16, DOI [10.1007/978-3-642-37346-6_3, DOI 10.1007/978-3-642-37346-6_3]
   Iurgel IA, 2005, LECT NOTES ARTIF INT, V3661, P15
   Kopp S, 2005, LECT NOTES ARTIF INT, V3661, P329
   Licklider J.C.R., 1960, Institute of Radio Engineers Transactions on Human Factors in Electronics, VHFE-1, P4, DOI 10.1109/THFE2.1960.4503259
   Maglio PP, 2003, COMMUN ACM, V46, P47, DOI 10.1145/636772.636797
   Metz C., 2015, WIRED
   Moore Roger, 2012, YOUR VIRTUAL BUTLER, P119, DOI [10.1007/978-3-642-37346-6_10, DOI 10.1007/978-3-642-37346-6_10]
   Norman Don., 2013, DESIGN EVERYDAY THIN
   O'Hara K, 2013, ACM T COMPUT-HUM INT, V20, DOI 10.1145/2442106.2442111
   Payr Sabine, 2013, Your Virtual Butler. The Making-of: LNCS 7407, P134, DOI 10.1007/978-3-642-37346-6_11
   Pilato G., 2010, SEMANTIC COMPUTING, P357
   Preece J., 2015, INTERACTION DESIGN H
   Pulman S. G., 2010, P 2010 WORKSH COMP D, P37
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Richards Deborah, 2012, P 8 AUSTR C INT ENT, DOI [10.1145/2336727.2336742, DOI 10.1145/2336727.2336742]
   Rojas-Barahona LM, 2014, LECT NOTES COMPUT SC, V8403, P503, DOI 10.1007/978-3-642-54906-9_41
   Shechtman N., 2003, P SIGCHI C HUM FACT, P281, DOI [DOI 10.1145/642611.642661, 10.1145/642611.642661]
   Shedroff N., 2012, MAKE IT SO INTERACTI
   Sturm Janienke, 1999, P ESCA WORKSH INT DI
   Tegos S., 2012, 2012 4th International Conference on Intelligent Networking and Collaborative Systems (INCoS 2012), P162, DOI 10.1109/iNCoS.2012.105
   Trappl Robert, 2012, YOUR VIRTUAL BUTLER, P1, DOI [10.1007/978-3-642-37346-6_1, DOI 10.1007/978-3-642-37346-6_1]
   von der Putten AM, 2010, COMPUT HUM BEHAV, V26, P1641, DOI 10.1016/j.chb.2010.06.012
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Weizenbaum J., 1976, COMPUTER POWER HUMAN
   Wilks Yorick, 2010, P 2010 WORKSH COMP D, P13
NR 47
TC 288
Z9 289
U1 4
U2 21
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-3362-7
PY 2016
BP 5286
EP 5297
DI 10.1145/2858036.2858288
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BF3EQ
UT WOS:000380532905025
DA 2022-08-02
ER

PT C
AU Jeong, Y
   Lee, J
   Kang, Y
AF Jeong, Yuin
   Lee, Juho
   Kang, Younah
GP Assoc Comp Machinery
TI Exploring Effects of Conversational Fillers on User Perception of
   Conversational Agents
SO CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI
   CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY MAY 04-09, 2019
CL Glasgow, SCOTLAND
SP Assoc Comp Machinery, ACM SIGCHI
DE Conversational Agent; Voice User Interface; Conversational Fillers; User
   Perception; Perceived Intelligence; Human-likeness; Likability
ID UH; UM
AB Through technological advancements in various areas of our lives, Conversational Agents progressed in their human-likeness. In the field of HCI, however, the use of conversational fillers (e.g., "um," "uh," etc.) by Conversational Agents have not been fully explored in an experimental setting. We observed the effects on user perceptions of Intelligence, Human-likeness and Likability of Conversational Agents by a 2 x 2 experimental design. From the results of 26 total participants, we concluded that 1) the use of fillers by Conversational Agents are perceived as less intelligent and less likable in task-oriented conversations, 2) and the fillers did not have any statistically significant change in perception of human-likeness. However, further examination showed that users reported filler-speaking agents as more entertaining for social-oriented conversations. With these findings, we discuss design implications for voice-based Conversational Agents.
C1 [Jeong, Yuin; Lee, Juho; Kang, Younah] Yonsei Univ, Seoul 03722, South Korea.
RP Jeong, Y (corresponding author), Yonsei Univ, Seoul 03722, South Korea.
EM youin.jeong@gmail.com; juho@yonsei.ac.kr; kang.younah@gmail.com
FU Korea Institute for Advancement of Technology (KIAT) - Korea Government
   (MOTIE) [N0001436]
FX This research was supported by Korea Institute for Advancement of
   Technology (KIAT) grant funded by the Korea Government (MOTIE)
   (N0001436, The Competency Development Program for Industry Specialist).
CR Araki K, 2009, AAMAS 09 P 8 INT C A, V2, P1171
   Arnold JE, 2007, J EXP PSYCHOL LEARN, V33, P914, DOI 10.1037/0278-7393.33.5.914
   Bartneck C., 2008, TECHNICAL REPORT, P37
   Burnard P, 1991, Nurse Educ Today, V11, P461, DOI 10.1016/0260-6917(91)90009-Y
   Clark HH, 2002, COGNITION, V84, P73, DOI 10.1016/S0010-0277(02)00017-3
   Fox Tree J.E., 1993, COMPREHENSION SPEECH
   Iqbal ST, 2004, CHI 04 EXT ABSTR HUM, P1477, DOI 10.1145/985921.986094
   KASL SV, 1965, J PERS SOC PSYCHOL, V1, P425, DOI 10.1037/h0021918
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Ohshima N, 2015, 2015 24TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P325, DOI 10.1109/ROMAN.2015.7333677
   Pfeifer LM, 2009, LECT NOTES ARTIF INT, V5773, P460
   Pytko J. L, 2013, COLL STELIZABETH J B
   Rose R. L, 1998, THESIS
   Westerman D, 2018, COMMUNICATION STUDIE, P1
   Wigdor N, 2016, IEEE ROMAN, P219, DOI 10.1109/ROMAN.2016.7745134
   Zagermann J, 2018, 2018 CHI C HUM FACT
NR 17
TC 7
Z9 7
U1 1
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5971-9
PY 2019
DI 10.1145/3290607.3312913
PG 6
WC Computer Science, Cybernetics; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BN4JW
UT WOS:000482042102154
DA 2022-08-02
ER

PT S
AU Moreno, KN
   Klettke, B
   Nibbaragandla, K
   Graesser, AC
AF Moreno, KN
   Klettke, B
   Nibbaragandla, K
   Graesser, AC
BE Cerri, SA
   Gouarderes, G
   Paraguacu, F
TI Perceived characteristics and pedagogical efficacy of animated
   conversational agents
SO INTELLIGENT TUTORING SYSTEMS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 6th International Conference on Intelligent Tutoring Systems
CY JUN 02-07, 2002
CL SAN SEBASTIAN, SPAIN
SP Assoc Comp Machinery, Int Federat Informat Proc, Artificial Intelligence Educ Soc, IEEE CS Learning Technol Task Force, French Direct Gen Armement, Asociac Espanola Inteligencia Artificial
AB We investigated college students' perceptions of a diverse sample of animated conversational agents. We also examined the pedagogical efficacy of those agents. We found that people perceive differences among the agents on several dimensions, such as likeability, and that the agents differ in pedagogical efficacy. However, none of the characteristics that we measured accounted for differences in pedagogical efficacy across the agents. We discuss implications for the field of agent studies with particular emphasis on the creation of pedagogically effective conversational agents and suggest directions for future research.
C1 Univ Memphis, Dept Psychol, Memphis, TN 38152 USA.
RP Moreno, KN (corresponding author), Univ Memphis, Dept Psychol, Memphis, TN 38152 USA.
EM kmoreno@memphis.edu; bklettke@memphis.edu; kiran_bhai@hotmail.com;
   a-graesser@memphis.edu
OI Klettke, Bianca/0000-0003-4602-2435
CR Andre E., 1998, Proceedings of the Second International Conference on Autonomous Agents, P261, DOI 10.1145/280765.280842
   Andre E, 2001, AI MAG, V22, P53
   ATKINSON RK, IN PRESS J ED PSYCHO
   BAYLOR AL, 2001, P ART INT ED AIED IN
   Cassell J., 1994, P 21 ANN C COMP GRAP, P413, DOI DOI 10.1145/192161.192272
   Elliott C., 1999, Artificial intelligence today. Recent trends and developments, P195
   Frasson C, 1998, LECT NOTES COMPUT SC, V1452, P594
   Graesser AC, 2001, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P460, DOI 10.1109/ICALT.2001.943979
   Graesser AC, 2001, AI MAG, V22, P39
   GRAESSER AC, IN PRESS INT J ARTIF
   HU X, 1998, XTRAIN 1 0 COMPUTER
   Johnson W. L., 1997, SIGART Bulletin, V8, P16
   Johnson WL, 2001, AI MAG, V22, P85
   Johnson WL, 2000, INT J ARTIFICIAL INT, V11, P47
   Lester J. C., 1997, P ACM SIGCHI C HUM F, P359, DOI DOI 10.1145/258549.258797
   Lester JC, 1999, USER MODEL USER-ADAP, V9, P1, DOI 10.1023/A:1008374607830
   Loyall A. B., 1997, P 1 INT C AUT AG MAR
   *MICR, 1998, MICR AG 2 0 COMP SOF
   MORENO KN, 2002, UNPUB PEOPLE STEREOT
   Moreno R, 2001, COGNITION INSTRUCT, V19, P177, DOI 10.1207/S1532690XCI1902_02
   PERSON N. K., 2000, AG 2000 P WORKSH ACH, P85
   Person N. K., 2001, INT J ARTIFICIAL INT, V12, P23
   PERSON NK, IN PRESS ENCY ED
   PERSON NK, 2001, P 2001 IEEE C COMM I
   PERSON NK, 1999, P INT WORKSH AFF INT, P167
   Rickel J, 1999, APPL ARTIF INTELL, V13, P343, DOI 10.1080/088395199117315
   Shaw E., 1999, Proceedings of the Third International Conference on Autonomous Agents, P283, DOI 10.1145/301136.301210
   Towns S. G., 1998, IUI '98. 1998 International Conference on Intelligent User Interfaces, P13
   WHITTAKER S, IN PRESS HDB DISCOUR
NR 29
TC 9
Z9 9
U1 0
U2 4
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-43750-9
J9 LECT NOTES COMPUT SC
PY 2002
VL 2363
BP 963
EP 971
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BV79M
UT WOS:000180067900096
DA 2022-08-02
ER

PT C
AU Bosse, T
   Provoost, S
AF Bosse, Tibor
   Provoost, Simon
BE Brinkman, WP
   Broekens, J
   Heylen, D
TI On Conversational Agents with Mental States
SO INTELLIGENT VIRTUAL AGENTS, IVA 2015
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 15th International Conference on Intelligent Virtual Agents (IVA)
CY AUG 26-28, 2015
CL Delft, NETHERLANDS
SP UnivTwente, Delft Univ Technol
DE Virtual training; Aggression de-escalation; Cognitive modelling
AB Embodied conversational agents (ECAs) have been put forward as a promising means for the training of social skills. The traditional approach to drive the behaviour of ECAs during human-agent dialogues is to use conversation trees. Although this approach is easy to use and very transparent, an important limitation of conversation trees is that the resulting behaviour of the ECAs is often perceived as predictable. To provide ECAs with more sophisticated behaviour, the current paper proposes an approach to endow them with mental states. The approach is illustrated by a motivational example in the domain of aggression de-escalation training.
C1 [Bosse, Tibor; Provoost, Simon] Vrije Univ Amsterdam, Dept Comp Sci, NL-1081 HV Amsterdam, Netherlands.
   [Bosse, Tibor] TNO, Dept Training & Performance Innovat, NL-3769 DE Soesterberg, Netherlands.
RP Bosse, T (corresponding author), Vrije Univ Amsterdam, Dept Comp Sci, Boelelaan 1081, NL-1081 HV Amsterdam, Netherlands.
EM t.bosse@vu.nl; s.j.provoost@vu.nl
CR Anderson L N, 1996, Nurse Pract, V21, P101, DOI 10.1097/00006205-199610000-00007
   BATES J, 1994, COMMUN ACM, V37, P122, DOI 10.1145/176789.176803
   Bosse T, 2014, LECT NOTES COMPUT SC, V8524, P375, DOI 10.1007/978-3-319-07485-6_37
   Cassell J., 2000, EMBODIED CONVERSATIO
   Dodge K. A., 1990, DEV TREATMENT CHILDH, P201
   Gebhard P, 2003, LECT NOTES ARTIF INT, V2792, P48
   Julia M Kim, 2009, INT J ARTIF INTELL E, V19, P289
   Kenny P., 2007, P 2007 INT IND TRAIN
   Ministry of the Interior and Kingdom Relations, 2008, TECHNICAL REPORT
   Van den Bosch K., 2012, LNCS, V7502, P426
NR 10
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 978-3-319-21996-7; 978-3-319-21995-0
J9 LECT NOTES ARTIF INT
PY 2015
VL 9238
BP 60
EP 64
DI 10.1007/978-3-319-21996-7_6
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BD7RG
UT WOS:000363485400006
DA 2022-08-02
ER

PT J
AU Kocaballi, AB
   Quiroz, JC
   Rezazadegan, D
   Berkovsky, S
   Magrabi, F
   Coiera, E
   Laranjo, L
AF Kocaballi, Ahmet Baki
   Quiroz, Juan C.
   Rezazadegan, Dana
   Berkovsky, Shlomo
   Magrabi, Farah
   Coiera, Enrico
   Laranjo, Liliana
TI Responses of Conversational Agents to Health and Lifestyle Prompts:
   Investigation of Appropriateness and Presentation Structures
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Article
DE conversational agents; chatbots; patient safety; health literacy; public
   health; design principles; evaluation
ID BEHAVIOR
AB Background: Conversational agents (CAs) are systems that mimic human conversations using text or spoken language. Their widely used examples include voice-activated systems such as Apple Siri, Google Assistant, Amazon Alexa, and Microsoft Cortana. The use of CAs in health care has been on the rise, but concerns about their potential safety risks often remain understudied.
   Objective: This study aimed to analyze how commonly available, general-purpose CAs on smartphones and smart speakers respond to health and lifestyle prompts (questions and open-ended statements) by examining their responses in terms of content and structure alike.
   Methods: We followed a piloted script to present health- and lifestyle-related prompts to 8 CAs. The CAs' responses were assessed for their appropriateness on the basis of the prompt type: responses to safety-critical prompts were deemed appropriate if they included a referral to a health professional or service, whereas responses to lifestyle prompts were deemed appropriate if they provided relevant information to address the problem prompted. The response structure was also examined according to information sources (Web search-based or precoded), response content style (informative and/or directive), confirmation of prompt recognition, and empathy.
   Results: The 8 studied CAs provided in total 240 responses to 30 prompts. They collectively responded appropriately to 41% (46/112) of the safety-critical and 39% (37/96) of the lifestyle prompts. The ratio of appropriate responses deteriorated when safety-critical prompts were rephrased or when the agent used a voice-only interface. The appropriate responses included mostly directive content and empathy statements for the safety-critical prompts and a mix of informative and directive content for the lifestyle prompts.
   Conclusions: Our results suggest that the commonly available, general-purpose CAs on smartphones and smart speakers with unconstrained natural language interfaces are limited in their ability to advise on both the safety-critical health prompts and lifestyle prompts. Our study also identified some response structures the CAs employed to present their appropriate responses. Further investigation is needed to establish guidelines for designing suitable response structures for different prompt types.
C1 [Kocaballi, Ahmet Baki; Quiroz, Juan C.; Rezazadegan, Dana; Berkovsky, Shlomo; Magrabi, Farah; Coiera, Enrico; Laranjo, Liliana] Macquarie Univ, Australian Inst Hlth Innovat, Level 6,75 Talavera Rd, Sydney, NSW 2109, Australia.
   [Laranjo, Liliana] Univ Nova Lisboa, NOVA Natl Sch Publ Hlth, Publ Hlth Res Ctr, Lisbon, Portugal.
   [Laranjo, Liliana] Univ Nova Lisboa, NOVA Med Sch, Comprehens Hlth Res Ctr, Lisbon, Portugal.
RP Kocaballi, AB (corresponding author), Macquarie Univ, Australian Inst Hlth Innovat, Level 6,75 Talavera Rd, Sydney, NSW 2109, Australia.
EM abakik@gmail.com
RI Laranjo, Liliana/D-5356-2017; Kocaballi, Baki/R-3136-2019; Quiroz,
   Juan/P-6215-2016
OI Laranjo, Liliana/0000-0003-1020-3402; Kocaballi,
   Baki/0000-0002-8328-5317; Magrabi, Farah/0000-0002-8426-5588;
   Rezazadegan, Dana/0000-0002-0097-3801; Berkovsky,
   Shlomo/0000-0003-2638-4121; Quiroz, Juan/0000-0003-0241-5376; Coiera,
   Enrico/0000-0002-6444-6584
CR Amazon, 2019, FALL BACK UNM UTT
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T, 2018, HUM-COMPUT INT-SPRIN, P33, DOI 10.1007/978-3-319-95579-7_3
   Bickmore TW, 2018, J MED INTERNET RES, V20, DOI 10.2196/11510
   Boyd M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194811
   Burleson B., 2002, HDB INTERPERSONAL CO, V3rd, P374, DOI DOI 10.4135/9781483326368.N2
   Cocco AM, 2018, MED J AUSTRALIA, V209, P342, DOI 10.5694/mja17.00889
   Coiera E, 2000, J AM MED INFORM ASSN, V7, P277, DOI 10.1136/jamia.2000.0070277
   Coiera E, 2018, J AM MED INFORM ASSN, V25, P963, DOI 10.1093/jamia/ocy028
   Edu J, 2019, SMART HOME PERSONAL, P1
   Fulmer R, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/mental.9782
   Hone KS, 2001, INT J HUM-COMPUT ST, V54, P637, DOI 10.1006/ijhc.2000.0456
   JIH HJ, 1992, ETR&D-EDUC TECH RES, V40, P39, DOI 10.1007/BF02296841
   Krippendorff K., 2018, CONTENT ANAL INTRO I
   Kumar A, 2018, J FOOD PROD MARK, V24, P196, DOI 10.1080/10454446.2017.1266553
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Liu BJ, 2018, CYBERPSYCH BEH SOC N, V21, P625, DOI 10.1089/cyber.2018.0110
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   MacGeorge E. L., 2016, COMMUNICATION YB, V40, P213, DOI DOI 10.1080/23808985.2015.11735261
   MacGeorge EL, 2009, J SOC PERS RELAT, VMay 26, DOI [10.4135/9781412990301, DOI 10.4135/9781412990301]
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   Miner AS, 2016, JAMA INTERN MED, V176, P619, DOI 10.1001/jamainternmed.2016.0400
   Mishara BL, 2007, SUICIDE LIFE-THREAT, V37, P308, DOI 10.1521/suli.2007.37.3.308
   Moon Y, 2002, J CONSUM PSYCHOL, V12, P313, DOI 10.1207/15327660260382351
   Myers C, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173580
   Nielsen J, 1994, USABILITY ENG
   Norman Don., 2013, DESIGN EVERYDAY THIN
   Norman DonaldA., 1987, HUMAN COMPUTER INTER, P241, DOI [10.5555/58076.58097, DOI 10.5555/58076.58097]
   Ogden W, 1997, HDB HUMAN COMPUTER I
   Pereira J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1237-1
   Pradhan A, 2018, PORTL INT CONF MANAG, DOI 10.1145/3173574.3174033
   Russi CS., 2018, ROSENS EMERGENCY MED, V9, P153
   Sezgin Emre, 2019, TRANSLATION BEHAV ME, V10, P3, DOI [10.2139/ssrn.3381183, DOI 10.2139/SSRN.3381183]
   Taib IA, 2011, SAFETY SCI, V49, P607, DOI 10.1016/j.ssci.2010.12.014
   Teasley S.D., 1991, PERSPECTIVES SOCIALL
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   Wolters MK, 2016, HEALTH INFORM J, V22, P854, DOI 10.1177/1460458215593329
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
   Zhang JJ, 2004, J BIOMED INFORM, V37, P193, DOI 10.1016/j.jbi.2004.04.004
NR 39
TC 20
Z9 20
U1 1
U2 9
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD FEB 10
PY 2020
VL 22
IS 2
AR e15823
DI 10.2196/15823
PG 15
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA KK4ZL
UT WOS:000512751900001
PM 32039810
OA Green Published, gold, Green Submitted
DA 2022-08-02
ER

PT C
AU Ayedoun, E
   Hayashi, Y
   Seta, K
AF Ayedoun, Emmanuel
   Hayashi, Yuki
   Seta, Kazuhisa
BE Chen, W
   Yang, JC
   Ayub, AFM
   Wong, SL
   Mitrovic, A
TI Can Conversational Agents Foster Learners' Willingness To Communicate in
   a Second Language? : Effects of Communication Strategies and Affective
   Backchannels
SO 25TH INTERNATIONAL CONFERENCE ON COMPUTERS IN EDUCATION (ICCE 2017):
   TECHNOLOGY AND INNOVATION: COMPUTER-BASED EDUCATIONAL SYSTEMS FOR THE
   21ST CENTURY
LA English
DT Proceedings Paper
CT 25th International Conference on Computers in Education (ICCE) -
   Technology and Innovation - Computer-Based Educational Systems for the
   21st Century
CY DEC 04-08, 2017
CL Christchurch, NEW ZEALAND
DE Willingness to communicate in L2; conversational agents; communication
   strategies; affective backchannels; intelligent tutoring
ID EFL LEARNERS; CONTEXT; ATTITUDES
AB Willingness to communicate (WTC) in a second language (L2) is believed to have a direct and sustained influence on learners' actual usage frequency of the targeted language. To help overcome the lack of suitable environments to increase L2 learners' WTC, our approach is to build conversational agents that can help L2 learners overcome their apprehension towards communication in L2. In this paper, we focus on the dialogue management aspects of our approach and propose a model based on set of communication strategies (CS) and affective backchannels (AB) in order to foster agents' ability to carry on natural and WTC friendly conversations with L2 learners. An evaluation of the proposed method led to two main findings. First, combining CS and AB empowers the conversational agent, making possible highly significant WTC gains among L2 learners in English as a foreign language context. Secondly, even a single implementation of AB proved to have the potential to enhance L2 learners' WTC to some extent.
C1 [Ayedoun, Emmanuel; Hayashi, Yuki; Seta, Kazuhisa] Osaka Prefecture Univ, Grad Sch Humanities & Sustainable Syst Sci, Sakai, Osaka, Japan.
RP Ayedoun, E (corresponding author), Osaka Prefecture Univ, Grad Sch Humanities & Sustainable Syst Sci, Sakai, Osaka, Japan.
EM eayedoun@ksm.kis.osakafu-u.ac.jp
CR Ayedoun E., 2016, J INF SYST ED, V15, P5, DOI [10.12937/ejsise.15.15, DOI 10.12937/EJSISE.15.15]
   Canale M, 1980, APPL LINGUIST, V1, P1, DOI DOI 10.1093/APPLIN/1.1.1
   Clement R, 2003, J LANG SOC PSYCHOL, V22, P190, DOI 10.1177/0261927X03022002003
   Compton L., 2004, COMPUTER ASSISTED LA, P123
   Derwing TM, 2008, APPL LINGUIST, V29, P359, DOI 10.1093/applin/amm041
   Dornyei Z, 1997, LANG LEARN, V47, P173, DOI 10.1111/0023-8333.51997005
   Dornyei Z., 1991, ELT J, V45, P16
   Howitt D., 2011, INTRO RES METHODS PS, V164, P179
   Kopp S, 2008, LECT NOTES ARTIF INT, V4930, P18
   MacIntyre PD, 1996, J LANG SOC PSYCHOL, V15, P3, DOI 10.1177/0261927X960151001
   Macintyre PD, 1998, MOD LANG J, V82, P545, DOI 10.2307/330224
   Matsuoka R, 2006, P 9 C PAN PAC ASS AP, P165
   McCroskey J., 1997, AVOIDING COMMUNICATI, P75
   Mesgarshahr A, 2014, STUD SECOND LANG LE, V4, P51, DOI 10.14746/ssllt.2014.4.1.4
   Morency LP, 2010, AUTON AGENT MULTI-AG, V20, P70, DOI 10.1007/s10458-009-9092-y
   Nakaya Kae, 2013, RES PRACT TECH ENHAN, V8, P65
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Oz H, 2015, LEARN INDIVID DIFFER, V37, P269, DOI 10.1016/j.lindif.2014.12.009
   Peng J. E., 2007, U SYDNEY PAPERS TESO, V2, P33
   Reinders H, 2014, LANG LEARN TECHNOL, V18, P101
   Sick J. R., 2000, TEST YOUR WILLINGNES
   Smith C., TELEOPERATORS VIRTUA, V20, P395
   Thornbury S., 2005, SENTENCE
   Yashima T, 2004, LANG LEARN, V54, P119, DOI 10.1111/j.1467-9922.2004.00250.x
   Yashima T, 2002, MOD LANG J, V86, P54, DOI 10.1111/1540-4781.00136
NR 25
TC 0
Z9 0
U1 1
U2 6
PU ASIA PACIFIC SOC COMPUTERS IN EDUCATION
PI TAOYUAN CITY
PA NO 300, JUNGDA RD, JHONGLI DISTRICT, TAOYUAN CITY, 320, TAIWAN
BN 978-986-94012-6-5
PY 2017
BP 835
EP 844
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods;
   Education & Educational Research
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Education & Educational Research
GA BK1KC
UT WOS:000431848700142
DA 2022-08-02
ER

PT J
AU Thomaz, F
   Salge, C
   Karahanna, E
   Hulland, J
AF Thomaz, Felipe
   Salge, Carolina
   Karahanna, Elena
   Hulland, John
TI Learning from the Dark Web: leveraging conversational agents in the era
   of hyper-privacy to enhance marketing
SO JOURNAL OF THE ACADEMY OF MARKETING SCIENCE
LA English
DT Article
DE Web; Dark Web; Consumer privacy; Marketing strategy; Chatbots;
   Conversational agents; Personalization; Anthropomorphism
ID SELF-DISCLOSURE; RECOMMENDATION AGENTS; INFORMATION PRIVACY; SOCIAL
   PRESENCE; VIRTUAL AGENTS; MUSIC PIRACY; PERSONALIZATION; SERVICE;
   IMPACT; FUTURE
AB The Web is a constantly evolving, complex system, with important implications for both marketers and consumers. In this paper, we contend that over the next five to ten years society will see a shift in the nature of the Web, as consumers, firms and regulators become increasingly concerned about privacy. In particular, we predict that, as a result of this privacy-focus, various information sharing and protection practices currently found on the Dark Web will be increasingly adapted in the overall Web, and in the process, firms will lose much of their ability to fuel a modern marketing machinery that relies on abundant, rich, and timely consumer data. In this type of controlled information-sharing environment, we foresee the emersion of two distinct types of consumers: (1) those generally willing to share their information with marketers (Buffs), and (2) those who generally deny access to their personal information (Ghosts). We argue that one way marketers can navigate this new environment is by effectively designing and deploying conversational agents (CAs), often referred to as "chatbots." In particular, we propose that CAs may be used to understand and engage both types of consumers, while providing personalization, and serving both as a form of differentiation and as an important strategic asset for the firm-one capable of eliciting self-disclosure of otherwise private consumer information.
C1 [Thomaz, Felipe] Univ Oxford, Said Business Sch, Oxford OX1 1HP, England.
   [Salge, Carolina] Wake Forest Univ, Sch Business, Winston Salem, NC 27106 USA.
   [Karahanna, Elena; Hulland, John] Univ Georgia, Terry Coll Business, Athens, GA 30601 USA.
RP Thomaz, F (corresponding author), Univ Oxford, Said Business Sch, Oxford OX1 1HP, England.
EM felipe.thomaz@sbs.ox.ac.uk; salgeca@wfu.edu; ekarah@uga.edu;
   jhulland@uga.edu
RI Hulland, John/ABI-7715-2020
OI Thomaz, Felipe/0000-0002-2223-3791
CR Acquisti A, 2015, SCIENCE, V347, P509, DOI 10.1126/science.aaa1465
   Adjerid I, 2019, MANAGE SCI, V65, P2267, DOI 10.1287/mnsc.2018.3028
   Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Adomavicius G, 2005, COMMUN ACM, V48, P83, DOI 10.1145/1089107.1089109
   Adomavicius G, 2001, COMPUTER, V34, P74, DOI 10.1109/2.901170
   Adomavicius G., 2008, STATE OF THE ART DEC, P55, DOI DOI 10.1287/EDUC.1080.0044
   Adomavicius G., 2009, BUSINESS COMPUTING
   Aggarwal P, 2007, J CONSUM RES, V34, P468, DOI 10.1086/518544
   Aguirre E, 2016, J CONSUM MARK, V33, P98, DOI 10.1108/JCM-06-2015-1458
   Al-Natour S, 2006, J ASSOC INF SYST, V7, P821, DOI 10.17705/1jais.00110
   Al-Natour S, 2011, J ASSOC INF SYST, V12, P347
   Altman Irwin, 1975, ENV SOCIAL BEHAV PRI
   Anderson CL, 2011, INFORM SYST RES, V22, P469, DOI 10.1287/isre.1100.0335
   [Anonymous], 2001, MARK INTELL PLAN, DOI DOI 10.1108/EUM0000000006109
   Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Arazy O., 2010, J ASS INFORM SYSTEMS, V11
   Arora N, 2008, MARKET LETT, V19, P305, DOI 10.1007/s11002-008-9056-z
   Bakken SA, 2018, EUR J CRIMINOL, V15, P442, DOI 10.1177/1477370817749177
   Barratt MJ, 2016, INT J DRUG POLICY, V35, P24, DOI 10.1016/j.drugpo.2016.04.019
   Ben Mimoun MS, 2017, INFORM MANAGE-AMSTER, V54, P545, DOI 10.1016/j.im.2016.11.008
   Ben Mimoun MS, 2012, J RETAIL CONSUM SERV, V19, P605, DOI 10.1016/j.jretconser.2012.07.006
   Ben Mimoun MS, 2015, J RETAIL CONSUM SERV, V26, P70, DOI 10.1016/j.jretconser.2015.05.008
   Benjamin V, 2019, MIS QUART, V43, P1, DOI 10.25300/MISQ/2019/13808
   BENNETT CJ, 2006, GOVERNANCE PRIVACY P
   Bleier A, 2019, J MARKETING, V83, P98, DOI 10.1177/0022242918809930
   Bleier A, 2015, J RETAILING, V91, P390, DOI 10.1016/j.jretai.2015.04.001
   Bojei J, 2013, J CONSUM BEHAV, V12, P171, DOI 10.1002/cb.1408
   Brandtzaeg PB., 2018, INTERACTIONS, V25, P38, DOI 10.1145/3236669
   Brandtzaeg PB, 2017, LECT NOTES COMPUT SC, V10673, P377, DOI 10.1007/978-3-319-70284-1_30
   Bucklin RE, 2003, J MARKETING RES, V40, P249, DOI 10.1509/jmkr.40.3.249.19241
   Burke RR, 1997, J ACAD MARKET SCI, V25, P352, DOI 10.1177/0092070397254007
   Bursztein E., 2017, UNDERSTANDING PEOPLE
   Caudevilla F, 2016, INT J DRUG POLICY, V35, P38, DOI 10.1016/j.drugpo.2016.04.017
   Caudill EM, 2000, J PUBLIC POLICY MARK, V19, P7, DOI 10.1509/jppm.19.1.7.16951
   Chakrabarti C, 2015, EXPERT SYST APPL, V42, P6878, DOI 10.1016/j.eswa.2015.04.067
   Chattaraman V, 2012, COMPUT HUM BEHAV, V28, P2055, DOI 10.1016/j.chb.2012.06.009
   Chatterjee P, 2003, MARKET SCI, V22, P520, DOI 10.1287/mksc.22.4.520.24906
   Chung TS, 2016, J ACAD MARKET SCI, V44, P66, DOI 10.1007/s11747-015-0441-x
   Cortes C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P9, DOI 10.1145/347090.347094
   Danaher B, 2010, MARKET SCI, V29, P1138, DOI 10.1287/mksc.1100.0600
   Daugherty PR, 2018, HUMAN MACHINE REIMAG
   Deighton J, 1997, J ACAD MARKET SCI, V25, P347, DOI 10.1177/0092070397254006
   Dholakia Nikhilesh, 2001, J RES CONSUMERS, V1, P1
   Dinev T, 2006, INFORM SYST RES, V17, P61, DOI 10.1287/isre.1060.0080
   Duxbury SW, 2019, CRIMINOLOGY, V57, P314, DOI 10.1111/1745-9125.12203
   Edvardsson B, 2011, J ACAD MARKET SCI, V39, P327, DOI 10.1007/s11747-010-0200-y
   Elkins AC, 2013, GROUP DECIS NEGOT, V22, P897, DOI 10.1007/s10726-012-9339-x
   Gao M, 2010, INFORM SYST FRONT, V12, P607, DOI 10.1007/s10796-009-9199-3
   Garfinkel S, 2017, COMMUN ACM, V60, P5, DOI 10.1145/3125780
   Ghose A, 2012, MARKET SCI, V31, P493, DOI 10.1287/mksc.1110.0700
   GIVON M, 1995, J MARKETING, V59, P29, DOI 10.2307/1252012
   Gnewuch U., 2017, DESIGNING COOPERATIV, P15
   Hann H, 2008, MANAGE SCI, V54, P1094, DOI 10.1287/mnsc.1070.0837
   He X., 2015, C ASS ADV ART INT AA
   Holt TJ, 2016, DEVIANT BEHAV, V37, P353, DOI 10.1080/01639625.2015.1026766
   Hosanagar K., 2019, HUMANS GUIDE MACHINE
   Huang MH, 2017, J ACAD MARKET SCI, V45, P906, DOI 10.1007/s11747-017-0545-6
   Huang TL, 2016, FUNDAMENTAL RESEARCH IN STRUCTURAL ENGINEERING: RETROSPECTIVE AND PROSPECTIVE, VOLS 1 AND 2, P1650
   Jain S, 2008, MARKET SCI, V27, P610, DOI 10.1287/mksc.1070.0313
   Jardine E, 2018, NEW MEDIA SOC, V20, P435, DOI 10.1177/1461444816639976
   Jenkins MC, 2007, LECT NOTES COMPUT SC, V4552, P76
   Johar M, 2014, INFORM SYST RES, V25, P285, DOI 10.1287/isre.2014.0518
   Kehr F, 2015, INFORM SYST J, V25, P607, DOI 10.1111/isj.12062
   Knijnenburg BP, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2963106
   Kumar N, 2006, INFORM SYST RES, V17, P425, DOI 10.1287/isre.1060.0107
   Ladegaard I, 2019, INT J DRUG POLICY, V63, P113, DOI 10.1016/j.drugpo.2018.09.013
   Lamberton C, 2016, J MARKETING, V80, P146, DOI 10.1509/jm.15.0415
   Lambrecht A, 2013, J MARKETING RES, V50, P561, DOI 10.1509/jmr.11.0503
   LANGER EJ, 1992, CONSCIOUS COGN, V1, P289, DOI 10.1016/1053-8100(92)90066-J
   Lariviere B, 2017, J BUS RES, V79, P238, DOI 10.1016/j.jbusres.2017.03.008
   Le Q, 2015, ARXIV150605869
   Leong B, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P299, DOI 10.1145/3287560.3287591
   Li H, 2011, DECIS SUPPORT SYST, V51, P434, DOI 10.1016/j.dss.2011.01.017
   Li SSY, 2015, J ASSOC INF SYST, V16, P72, DOI 10.17705/1jais.00389
   Li WF, 2016, J MANAGE INFORM SYST, V33, P1059, DOI 10.1080/07421222.2016.1267528
   Louwerse MM, 2005, APPL COGNITIVE PSYCH, V19, P693, DOI 10.1002/acp.1117
   Mannila H., 1997, DISCOVERY FREQUENT E, P31
   Martin KD, 2017, J ACAD MARKET SCI, V45, P135, DOI 10.1007/s11747-016-0495-4
   McAfee A., 2012, HARVARD BUSINESS REV
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   Mende M, 2019, J MARKETING RES, V56, P535, DOI 10.1177/0022243718822827
   Mobasher B, 2000, COMMUN ACM, V43, P142, DOI 10.1145/345124.345169
   Mobasher B., 2007, ADAPTIVE WEB
   Montgomery AL, 2004, MARKET SCI, V23, P579, DOI 10.1287/mksc.1040.0073
   Moon Y, 2000, J CONSUM RES, V26, P323, DOI 10.1086/209566
   Moon Y, 2003, J CONSUM PSYCHOL, V13, P125, DOI 10.1207/153276603768344843
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Murthi BPS, 2003, MANAGE SCI, V49, P1344, DOI 10.1287/mnsc.49.10.1344.17313
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Neff G., 2016, INT J COMMUNICATION, V10, P17
   Niu L, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P1075, DOI 10.1109/ICMLC.2002.1174549
   Padmanabhan B., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P154
   Peterson RA, 1997, J ACAD MARKET SCI, V25, P329, DOI 10.1177/0092070397254005
   Phelps J, 2000, J PUBLIC POLICY MARK, V19, P27, DOI 10.1509/jppm.19.1.27.16941
   Picard R. W, 1997, MIT MEDIA LAB PERCEP, P16
   Qiu LY, 2009, J MANAGE INFORM SYST, V25, P145, DOI 10.2753/MIS0742-1222250405
   Sahni NS, 2018, MARKET SCI, V37, P236, DOI 10.1287/mksc.2017.1066
   Schuetzler R. M., 2014, HUMAN COMPUTER INTER, P17
   Schumann JH, 2014, J MARKETING, V78, P59, DOI 10.1509/jm.11.0316
   Shechtman N., 2003, P SIGCHI C HUM FACT, P281, DOI [DOI 10.1145/642611.642661, 10.1145/642611.642661]
   Short J. A., 1976, SOCIAL PSYCHOL TELEC
   Shum HY, 2018, FRONT INFORM TECH EL, V19, P10, DOI 10.1631/FITEE.1700826
   Singh MN, 2016, INFECT GENET EVOL, V41, P100, DOI 10.1016/j.meegid.2016.03.025
   Sinha RK, 2008, J MARKETING, V72, P1, DOI 10.1509/jmkg.72.1.1
   Sinha RK, 2010, J MARKETING, V74, P40, DOI 10.1509/jmkg.74.2.40
   Smith HJ, 2011, MIS QUART, V35, P989
   Smith HJ, 2001, CALIF MANAGE REV, V43, P8, DOI 10.2307/41166073
   Spangler WE, 2006, COMMUN ACM, V49, P119, DOI 10.1145/1125944.1125951
   Staff F. M., 2016, TRY HELLO HIPMUNKTM
   Stewart DW, 2017, J ACAD MARKET SCI, V45, P156, DOI 10.1007/s11747-016-0504-7
   Summers CA, 2016, J CONSUM RES, V43, P156, DOI 10.1093/jcr/ucw012
   Tam KY, 2006, MIS QUART, V30, P865
   Trusov M, 2016, MARKET SCI, V35, P405, DOI 10.1287/mksc.2015.0956
   Tur G., 2011, SPOKEN LANGUAGE UNDE, P93
   Turkle S., 2017, ALONE TOGETHER WHY W
   Tuzhilin A, 2008, BUSINESS COMPUTING
   Urban GL, 2014, MARKET SCI, V33, P27, DOI 10.1287/mksc.2013.0803
   Van Buskirk J, 2016, INT J DRUG POLICY, V35, P32, DOI 10.1016/j.drugpo.2016.01.010
   van Doorn J, 2017, J SERV RES-US, V20, P43, DOI 10.1177/1094670516679272
   Verhagen T, 2014, J COMPUT-MEDIAT COMM, V19, P529, DOI 10.1111/jcc4.12066
   Vlahos J., 2018, NY TIMES
   Wang WQ, 2008, J MANAGE INFORM SYST, V24, P249, DOI 10.2753/MIS0742-1222240410
   Warren S.D., 1890, HARVARD LAW REV, P193, DOI DOI 10.2307/1321160
   Westin Alan F., 1967, PRIVACY FREEDOM
   Xu H, 2009, J MANAGE INFORM SYST, V26, P135, DOI 10.2753/MIS0742-1222260305
   Yang CF, 2016, IEEE IC COMP COM NET
   Yu J, 2015, J MANAGE INFORM SYST, V32, P239, DOI 10.1080/07421222.2015.1063305
   Yue WT, 2019, MIS QUART, V43, P73, DOI 10.25300/MISQ/2019/13042
NR 129
TC 39
Z9 39
U1 9
U2 56
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0092-0703
EI 1552-7824
J9 J ACAD MARKET SCI
JI J. Acad. Mark. Sci.
PD JAN
PY 2020
VL 48
IS 1
SI SI
BP 43
EP 63
DI 10.1007/s11747-019-00704-3
EA NOV 2019
PG 21
WC Business
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA KQ2KE
UT WOS:000495716200002
OA Green Published, hybrid
DA 2022-08-02
ER

PT C
AU Mancini, M
   Pelachaud, C
AF Mancini, Maurizio
   Pelachaud, Catherine
BE Dias, MS
   Gibet, S
   Wanserley, MM
   Bastos, R
TI Implementing Distinctive Behavior for Conversational Agents
SO GESTURE-BASED HUMAN-COMPUTER INTERACTION AND SIMULATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 7th International Gesture Workshop
CY MAY 23-25, 2007
CL Lisbon, PORTUGAL
ID CUES
AB We aim to define conversational agents exhibiting distinctive behavior. To this aim we provide a small set of parameters to allow one to define behavior profiles and then leave to the system the task of animating the agents. Our approach is to manipulate. the behavior tendency of the agents depending on their communicative intention and emotional state. In this paper we define the concepts of Baseline and Dynamicline. The Baseline of an agent is defined as a set of fixed parameters that represent the personalized agent behavior, while the Dynamicline is a set of parameters that derive both from the Baseline and the current communicative. intention and emotional state,
C1 [Mancini, Maurizio] Univ Paris 08, F-93526 St Denis 02, France.
   [Pelachaud, Catherine] CNRS, Telecom Paris Tech, Paris, France.
RP Mancini, M (corresponding author), Univ Paris 08, F-93526 St Denis 02, France.
RI Mancini, Maurizio/D-9776-2015
OI Mancini, Maurizio/0000-0002-9933-8583
CR ALLBECK J, 2002, WORKSH EMB COUV AG L
   Andre E., 1998, 2 INT C AUT AG, P261
   Ball G, 2000, EMBODIED CONVERSATIONAL AGENTS, P189
   Chi D, 2000, COMP GRAPH, P173
   De Carolis B, 2004, COG TECH, P65
   GALLAHER PE, 1992, J PERS SOC PSYCHOL, V63, P133, DOI 10.1037/0022-3514.63.1.133
   HARTMANN B, 2005, INT C INT US INT WOR
   HARTMANN B, 2005, 3 INT JOINT C AUT AG
   Kipp M., 2005, GESTURE GENERATION I
   Kipp M, 2006, LECT NOTES ARTIF INT, V4133, P230
   Mancini M, 2006, LECT NOTES ARTIF INT, V3881, P280
   MAYA V, 2004, P ART INT SIM BEH LE
   McNeill D., 1992, HAND MIND WHAT GESTU
   Neff M., 2005, P 2005 ACM SIGGRAPH, P161, DOI DOI 10.1145/1073368.1073391
   Noot H, 2003, LECT NOTES ARTIF INT, V2915, P324
   PELACHAUD C, 2005, MULTIMEDIA 05, P683
   Poggi I., 2003, GESTURES MEANING USE
   RUTTKAY Z, ANIMATING E IN PRESS
   Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W
   WALLBOTT HG, 1986, J PERS SOC PSYCHOL, V51, P690, DOI 10.1037/0022-3514.51.4.690
NR 20
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-540-92864-5
J9 LECT NOTES ARTIF INT
PY 2009
VL 5085
BP 163
EP +
PG 3
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BIX03
UT WOS:000263514500017
DA 2022-08-02
ER

PT J
AU Kumar, R
   Rose, CP
AF Kumar, Rohit
   Rose, Carolyn P.
TI Architecture for Building Conversational Agents that Support
   Collaborative Learning
SO IEEE TRANSACTIONS ON LEARNING TECHNOLOGIES
LA English
DT Article
DE Collaborative learning; intelligent agents; natural language interfaces;
   software architectures
ID TUTORING SYSTEM; FRAMEWORK
AB Tutorial Dialog Systems that employ Conversational Agents (CAs) to deliver instructional content to learners in one-on-one tutoring settings have been shown to be effective in multiple learning domains by multiple research groups. Our work focuses on extending this successful learning technology to collaborative learning settings involving two or more learners interacting with one or more agents. Experience from extending existing techniques for developing conversational agents into multiple-learner settings highlights two underlying assumptions from the one-learner setting that do not generalize well to the multiuser setting, and thus cause difficulties. These assumptions include what we refer to as the near-even participation assumption and the known addressee assumption. A new software architecture called Basilica that allows us to address and overcome these limitations is a major contribution of this article. The Basilica architecture adopts an object-oriented approach to represent agents as a network composed of what we refer to as behavioral components because they enable the agents to engage in rich conversational behaviors. Additionally, we describe three specific conversational agents built using Basilica in order to illustrate the desirable properties of this new architecture.
C1 [Kumar, Rohit; Rose, Carolyn P.] Carnegie Mellon Univ, Language Technol Inst, Gates Hilman Ctr, Pittsburgh, PA 15213 USA.
   [Rose, Carolyn P.] Carnegie Mellon Univ, Human Comp Interact Inst, Gates Hilman Ctr, Pittsburgh, PA 15213 USA.
RP Kumar, R (corresponding author), Carnegie Mellon Univ, Language Technol Inst, Gates Hilman Ctr, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
EM rohitk@cs.cmu.edu; cprose@cs.cmu.edu
FU  [NSF SBE 0836012];  [NSF DRC 0835426];  [NSF EEC 0935145]
FX This work was supported in part by the following grants: NSF SBE
   0836012, NSF DRC 0835426, and NSF EEC 0935145.
CR AI H, 2010, P INT C INT TUT SYST
   ALEVEN V, 2000, AAAI FALL S BUILD DI, P65
   Arnott E, 2008, BEHAV RES METHODS, V40, P694, DOI 10.3758/BRM.40.3.694
   Baker M, 1997, J COMPUT ASSIST LEAR, V13, P175, DOI 10.1046/j.1365-2729.1997.00019.x
   BALES RF, 1950, INTERACTION PROCESS
   BENUS S, 2009, P INT
   BOHUS D, 2007, THESIS CARNEGIE MELL
   Bohus D, 2009, COMPUT SPEECH LANG, V23, P332, DOI 10.1016/j.csl.2008.10.001
   Chaudhuri S., 2009, P ART INT ED AIED 09
   CHAUDHURI S, 2008, P INT TUT SYST ITS 0
   Chen WQ, 2003, LECT NOTES ARTIF INT, V2774, P238
   Chou CY, 2003, COMPUT EDUC, V40, P255, DOI 10.1016/S0360-1315(02)00130-6
   Diziol D, 2010, EDUC PSYCHOL REV, V22, P89, DOI 10.1007/s10648-009-9116-9
   Forbus KD, 1999, ARTIF INTELL, V114, P297, DOI 10.1016/S0004-3702(99)00080-6
   Freedman R, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, P52
   Graesser AC, 2005, IEEE T EDUC, V48, P612, DOI 10.1109/TE.2005.856149
   Graesser AC, 2008, DISCOURSE PROCESS, V45, P298, DOI 10.1080/01638530802145395
   Gweon G, 2011, COMPUT-SUPP COLLAB L, P293, DOI 10.1007/978-1-4419-7710-6_14
   JORDAN P, 2006, P ITS WORKSH TEACH R
   JORDAN P, 2007, P ART INT ED AIED 07
   KOLLAR I, 2006, ED PSYCHOL REV
   Kreijns K, 2003, COMPUT HUM BEHAV, V19, P335, DOI 10.1016/S0747-5632(02)00057-2
   KUMAR R, 2007, P ART INT ED AIED 07
   KUMAR R, 2010, P INT C INT TUT SYST
   Kumar R., 2007, P WORKSH SPEECH LANG
   LARSON S, 2006, DIALOGUE SYSTEMS PRO
   LOLL F, 2009, P 9 IEEE INT C ADV L
   Muhlpfordt M., 2005, P COMP SUPP COLL LEA
   O'Donnell AM, 1999, RUTG INV SYMP EDUC S, P179
   ONEILL I, 2003, P 8 EUR C SPEECH COM, P593
   Raux A., 2008, THESIS CARNEGIE MELL
   Renkl A, 1998, CONTEMP EDUC PSYCHOL, V23, P90, DOI 10.1006/ceps.1997.0959
   Rose C, 2008, INT J COMP-SUPP COLL, V3, P237, DOI 10.1007/s11412-007-9034-0
   ROSE CP, 2003, P ART INT ED AIED 03
   STEGMANN K, 2004, P 1 JOINT M EARLI SI, P320
   Weusijana B. K., 2008, 2 LIF ED COMM CONV P
   2007, VOICEXML
   [No title captured]
NR 38
TC 61
Z9 62
U1 2
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1939-1382
J9 IEEE T LEARN TECHNOL
JI IEEE Trans. Learn. Technol.
PD JAN-MAR
PY 2011
VL 4
IS 1
BP 21
EP 34
DI 10.1109/TLT.2010.41
PG 14
WC Computer Science, Interdisciplinary Applications; Education &
   Educational Research
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Education & Educational Research
GA 789UP
UT WOS:000292542200003
OA hybrid
DA 2022-08-02
ER

PT C
AU Angelini, L
   Caon, M
   Casas, J
   Cena, F
   Rapp, A
   Abou Khaled, O
   Mugellini, E
AF Angelini, Leonardo
   Caon, Maurizio
   Casas, Jacky
   Cena, Federica
   Rapp, Amon
   Abou Khaled, Omar
   Mugellini, Elena
GP ACM
TI Ubiquitous Chatbots: Workshop on Wearable and Embodied Conversational
   Agents
SO PROCEEDINGS OF THE 2018 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE
   AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2018 ACM INTERNATIONAL
   SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC'18 ADJUNCT)
LA English
DT Proceedings Paper
CT ACM International Joint Conference on Pervasive and Ubiquitous Computing
   / ACM International Symposium on Wearable Computers (UbiComp/ISWC)
CY OCT 08-12, 2018
CL Google, Singapore, SINGAPORE
SP Assoc Comp Machinery, ACM SIGCHI, ACM SIGMOBILE, NOKIA Bell Labs, Intel, Microsoft, NAVER Labs, HUAWEI, Singapore Tourism Board, Singapore Pass Made Possible
HO Google
DE Conversational agent; chatbot; ubiquitous computing; human-computer
   interaction; coaching
AB Human-computer interaction is progressively shifting towards natural language communication, determining the rise of conversational agents. In the context of ubiquitous computing, the opportunities for interacting with new services and systems in a conversational manner are increasing and, nowadays, it is common to talk to home assistants to interact with a smart environment or to write to chatbots to access an online service. This workshop aims at bringing together researchers from academia and industry in order to establish a multidisciplinary community interested in discovering and exploring the challenges and opportunities coming from the ubiquity of conversational agents.
C1 [Angelini, Leonardo; Caon, Maurizio; Casas, Jacky; Abou Khaled, Omar; Mugellini, Elena] HES SO Univ Appl Sci Western Switzerland, Fribourg, Switzerland.
   [Cena, Federica; Rapp, Amon] Univ Torino, Turin, Italy.
RP Angelini, L (corresponding author), HES SO Univ Appl Sci Western Switzerland, Fribourg, Switzerland.
EM leonardo.angelini@hes-so.ch; maurizio.caon@hes-so.ch;
   jacky.casas@hes-so.ch; cena@di.unito; amon.rapp@gmail.com;
   omar.aboukhaled@hes-so.ch; elena.mugellini@hes-so.ch
RI Rapp, Amon/P-8663-2016; Cena, Federica/ABD-5287-2020; KHALED, Omar
   ABOU/O-6389-2019; Angelini, Leonardo/AAI-4217-2021
OI Rapp, Amon/0000-0003-3855-9961; KHALED, Omar ABOU/0000-0002-0178-9037; 
CR Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Chaves AP, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173765
   Johnson K., 2017, FACEBOOK MESSENGER H
   Larsen J.E., 2015, ADJ P 2015 ACM INT J, P969, DOI [10.1145/2800835.2807947, DOI 10.1145/2800835.2807947]
   Orlowski, 2017, FACEBOOK SCALES BACK
   Rapp A, 2018, BEHAV INFORM TECHNOL, V37, P335, DOI 10.1080/0144929X.2018.1436592
   Schmitz Michael, 2010, P TEI 11, P157, DOI [10.1145/1935701.1935732, DOI 10.1145/1935701.1935732]
NR 7
TC 2
Z9 2
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5966-5
PY 2018
BP 1652
EP 1655
DI 10.1145/3267305.3274146
PG 4
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BM2UN
UT WOS:000461550100294
DA 2022-08-02
ER

PT J
AU Louwerse, MM
   Graesser, AC
   Lu, SL
   Mitchell, HH
AF Louwerse, MM
   Graesser, AC
   Lu, SL
   Mitchell, HH
TI Social cues in animated conversational agents
SO APPLIED COGNITIVE PSYCHOLOGY
LA English
DT Article
ID LIFELIKE PEDAGOGICAL AGENTS; ENVIRONMENTS; DIALOGUE
AB In human-computer interaction people often interpret the interaction with the computer as interactions with humans. The social agency theory suggests that social cues like the face and voice of the agent motivate this interpretation. In two off-line experiments in which comprehension scores and liking ratings were collected, we found that participants preferred natural agents with natural voices, as predicted by the social-cue hypothesis. Although female agents with male voices formed an exception, this was explained by a stereotype effect. These findings support the social-cue hypothesis and the social agency theory that human characteristics are applied in the perception of computational animated conversational agents. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Univ Memphis, Inst Intelligent Syst, Dept Psychol, Memphis, TN 38152 USA.
RP Louwerse, MM (corresponding author), Univ Memphis, Inst Intelligent Syst, Dept Psychol, 202 Psychol Bldg, Memphis, TN 38152 USA.
EM mlouwers@memphis.edu
CR ALLEN JF, 1995, J EXP THEOR ARTIF IN, V7, P7, DOI 10.1080/09528139508953799
   Andre E., 1998, Proceedings of the Second International Conference on Autonomous Agents, P261, DOI 10.1145/280765.280842
   Atkinson RK, 2002, J EDUC PSYCHOL, V94, P416, DOI 10.1037//0022-0663.94.2.416
   Baylor A. L., 2003, Journal of Educational Computing Research, V28, P373, DOI 10.2190/V0WQ-NWGN-JB54-FAT4
   Cassell J, 1999, APPL ARTIF INTELL, V13, P519, DOI 10.1080/088395199117360
   CASSELL J, 1994, COMPUTER GRAPHICS, V28, P413
   Cassell J., 2000, EMBODIED CONVERSATIO
   Craig SD, 2002, J EDUC PSYCHOL, V94, P428, DOI 10.1037//0022-0663.94.2.428
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   Eagly A. H, 1987, SEX DIFFERENCES SOCI
   GERTNER A, 2000, INTELLIGENT TUTORING, P131
   Graesser A. C., 2001, INT J ARTIFICIAL INT, V12, P257
   Graesser AC, 2004, BEHAV RES METH INS C, V36, P180, DOI 10.3758/BF03195563
   Graesser AC, 2002, LECT NOTES COMPUT SC, V2363, P972
   Graesser AC, 2001, AI MAG, V22, P39
   GRAESSER AC, 2003, P AAAI SPRING S 2003, P9
   Lesgold A., 1992, COMPUTER ASSISTED IN, P201
   Lester JC, 1999, APPL ARTIF INTELL, V13, P383, DOI 10.1080/088395199117324
   Lester JC, 1999, USER MODEL USER-ADAP, V9, P1, DOI 10.1023/A:1008374607830
   LOUWERSE MM, 2002, ETIQUETTE HUMAN COMP, P71
   MASSARO DW, 1994, J EXP PSYCHOL HUMAN, V20, P1107, DOI 10.1037/0096-1523.20.6.1107
   Mayer RE, 2003, J EDUC PSYCHOL, V95, P419, DOI 10.1037/0022-0663.95.2.419
   McNamara DS, 2004, BEHAV RES METH INS C, V36, P222, DOI 10.3758/BF03195567
   Minstrell, 1996, ISSUES ED CONTRIBUTI, V2, P123
   Moreno KN, 2002, LECT NOTES COMPUT SC, V2363, P963
   Moreno R, 2001, COGNITION INSTRUCT, V19, P177, DOI 10.1207/S1532690XCI1902_02
   Nass C, 1997, J APPL SOC PSYCHOL, V27, P864, DOI 10.1111/j.1559-1816.1997.tb00275.x
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Rickel J, 1999, APPL ARTIF INTELL, V13, P343, DOI 10.1080/088395199117315
   Rudnicky A., 1999, P EUR, P1531
   SHNEIDERMAN B, 1997, SOFTWARE AGENTS, P97
   Shneiderman B., 1992, DESIGNING USER INTER
   Syrdal AK, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P438, DOI 10.1109/ICSLP.1996.607148
   Trautner H., 2000, DEV SOCIAL PSYCHOL G
   [No title captured]
   [No title captured]
NR 37
TC 44
Z9 45
U1 2
U2 9
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0888-4080
EI 1099-0720
J9 APPL COGNITIVE PSYCH
JI Appl. Cogn. Psychol.
PD SEP
PY 2005
VL 19
IS 6
BP 693
EP 704
DI 10.1002/acp.1117
PG 12
WC Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA 971LD
UT WOS:000232384600002
DA 2022-08-02
ER

PT C
AU Khan, R
   De Angeli, A
AF Khan, Rabia
   De Angeli, Antonella
BE Gross, T
   Gulliksen, J
   Kotze, P
   Oestreicher, L
   Palanque, P
   Prates, RO
TI The Attractiveness Stereotype in the Evaluation of Embodied
   Conversational Agents
SO HUMAN-COMPUTER INTERACTION - INTERACT 2009, PT I
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 12th IFIP International Conference on Human-Computer Interaction
CY AUG 24-28, 2009
CL Uppsala, SWEDEN
SP IFIP TC13, Swedish Interdisciplinary Interest Grp Human Comp Interact, Uppsala Univ, Dept Informat Technol
DE Embodied conversational agents; user evaluation; virtual bodies
ID BEAUTIFUL; AVATARS
AB Physical attractiveness is an important cue for social interaction. Psychology studies have long shown that physical attractiveness can elicit positive personality attributions Lis well Lis positive behaviour towards other people. This effect is explained by the attractiveness stereotype. In this paper, we investigate whether this stereotype apply to the interaction with virtual agents. We report the results of two experiments where the attractiveness stereotype was tested with and without interaction with the agent. Results indicate a strong effect of the attractiveness stereotype, showing that users tend to form and maintain a better evaluation of attractive agents than Of unattractive ones independent of actual interaction with the agent or the agents' ethnicity. Implications for design are discussed.
C1 [Khan, Rabia; De Angeli, Antonella] Univ Manchester, Manchester Business Sch, Manchester M15 6PB, Lancs, England.
RP Khan, R (corresponding author), Univ Manchester, Manchester Business Sch, Booth St W, Manchester M15 6PB, Lancs, England.
EM Rabia.Khan@postgrad.manchester.ac.uk; Antonella.De-Angeli@mbs.ac.uk
RI De Angeli, Antonella/AAN-6245-2021
CR [Anonymous], 2007, SPSS SURVIVAL MANUAL
   BAYLOR AL, 2005, COGNITION LEARNING, V2, P291
   BAYLOR AL, 2005, P WORKSH AFF INT INT
   Brace N, 2006, SPSS PSYCHOL GUIDE D
   De Angeli A, 2008, INTERACT COMPUT, V20, P302, DOI 10.1016/j.intcom.2008.02.004
   DION K, 1972, J PERS SOC PSYCHOL, V24, P285, DOI 10.1037/h0033731
   EAGLY AH, 1991, PSYCHOL BULL, V110, P109, DOI 10.1037/0033-2909.110.1.109
   FEINGOLD A, 1992, PSYCHOL BULL, V111, P304, DOI 10.1037/0033-2909.111.2.304
   FISKE ST, 1993, ANNU REV PSYCHOL, V44, P155, DOI 10.1146/annurev.ps.44.020193.001103
   Holzwarth M, 2006, J MARKETING, V70, P19, DOI 10.1509/jmkg.70.4.19
   KHAN R, 2007, P 21 BRIT HCI GROUP
   Langlois JH, 2000, PSYCHOL BULL, V126, P390, DOI 10.1037/0033-2909.126.3.390
   MCCROSKEY JC, 1972, ANN CONV W SPEECH CO
   Messinger P.R., 2008, J VIRTUAL WORLDS RES, V1, P1, DOI DOI 10.4101/JVWR.V1I2.352
   Moon Y, 1996, COMMUN RES, V23, P651, DOI 10.1177/009365096023006002
   Nass C, 2000, EMBODIED CONVERSATIONAL AGENTS, P374
   Nowak KL, 2008, COMPUT HUM BEHAV, V24, P1473, DOI 10.1016/j.chb.2007.05.005
   Nowak Kristine L., 2005, J COMPUT-MEDIAT COMM, V11, P153, DOI [DOI 10.1111/J.1083-6101.2006.TB00308.X, 10.1111/j.1083-6101.2006.tb00308]
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Rhodes G, 2006, ANNU REV PSYCHOL, V57, P199, DOI 10.1146/annurev.psych.57.102904.190208
   Vasalou A, 2008, INT J HUM-COMPUT ST, V66, P801, DOI 10.1016/j.ijhcs.2008.08.002
   Vasalou A, 2009, COMPUT HUM BEHAV, V25, P510, DOI 10.1016/j.chb.2008.11.007
   WHEELER L, 1997, WHAT IS BEAUTIFUL IS, P795
   ZANBAKA C, 2006, P SIGCHI C HUM FACT
NR 24
TC 11
Z9 11
U1 0
U2 3
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-03654-5
J9 LECT NOTES COMPUT SC
PY 2009
VL 5726
BP 85
EP 97
PN I
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BLR80
UT WOS:000270899000010
OA Bronze
DA 2022-08-02
ER

PT C
AU Keller, R
   Yao, JL
   Teepe, GW
   Hartmann, S
   Lohse, KM
   von Wangenheim, F
   Muller-Riemenschneider, F
   Mair, JL
   Kowatsch, T
AF Keller, Roman
   Yao, Jiali
   Teepe, Gisbert Wilhelm
   Hartmann, Sven
   Lohse, Kim-Morgaine
   von Wangenheim, Florian
   Muller-Riemenschneider, Falk
   Mair, Jacqueline Louise
   Kowatsch, Tobias
BE Pesquita, C
   Fred, A
   Gamboa, H
TI Are Conversational Agents Used at Scale by Companies Offering Digital
   Health Services for the Management and Prevention of Diabetes?
SO HEALTHINF: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON
   BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES - VOL. 5: HEALTHINF
LA English
DT Proceedings Paper
CT 14th International Joint Conference on Biomedical Engineering Systems
   and Technologies (BIOSTEC) / 14th Int Conf on Bio-inspired Systems and
   Signal Processing (BIOSIGNALS) / 14th Int Conf on Biomedical Electronics
   and Devices (BIODEVICES)
CY FEB 11-13, 2021
CL ELECTR NETWORK
DE Digital Health Companies; Healthcare; Type 2 Diabetes; Prevention;
   Management; Funding; Conversational Agents
AB Successful interventions to prevent and manage type 2 diabetes rely on long-term, day-to-day decisions which take place outside of clinical settings. In this context, human resources are difficult to scale up, and leveraging Conversational agents (CAs) could be one way to scale up healthcare to tackle the emerging epidemic of type 2 diabetes. The objective of this paper is to assess the degree to which CAs are employed by top-funded digital health companies that target the prevention and management of type 2 diabetes. Companies were identified via two venture capital databases, i.e. Crunchbase Pro and Pitchbook. Two independent reviewers screened results and the final list of companies was validated and revised by three independent digital health experts. The companies' digital services (usually mobile applications) were accessed and reviewed for the utilisation of CAs. To better understand the purpose of identified CAs, relevant publications were identified via PubMed, Google Scholar, ACM Digital Library and on the companies' website. Nine out of 15 companies' digital services were accessible to the authors and only in one case a CA was employed. The uptake of CAs by topfunded digital health companies targeting type-2 diabetes is still low.
C1 [Keller, Roman; Yao, Jiali; von Wangenheim, Florian; Muller-Riemenschneider, Falk; Mair, Jacqueline Louise; Kowatsch, Tobias] Campus Res Excellence & Technol Enterprise CREATE, Future Hlth Technol Singapore ETH Ctr, Singapore, Singapore.
   [Teepe, Gisbert Wilhelm; Lohse, Kim-Morgaine; von Wangenheim, Florian; Mair, Jacqueline Louise; Kowatsch, Tobias] Swiss Fed Inst Technol, Dept Management Technol & Econ, Ctr Digital Hlth Intervent, Zurich, Switzerland.
   [Muller-Riemenschneider, Falk] Natl Univ Singapore, Saw Swee Hock Sch Publ Hlth, Singapore, Singapore.
   [Muller-Riemenschneider, Falk] Natl Univ Singapore, Yong Loo Lin Sch Med, Singapore, Singapore.
   [Hartmann, Sven; Kowatsch, Tobias] Univ St Gallen, Inst Technol Management, Ctr Digital Hlth Intervent, St Gallen, Switzerland.
RP Mair, JL; Kowatsch, T (corresponding author), Campus Res Excellence & Technol Enterprise CREATE, Future Hlth Technol Singapore ETH Ctr, Singapore, Singapore.; Mair, JL; Kowatsch, T (corresponding author), Swiss Fed Inst Technol, Dept Management Technol & Econ, Ctr Digital Hlth Intervent, Zurich, Switzerland.; Kowatsch, T (corresponding author), Univ St Gallen, Inst Technol Management, Ctr Digital Hlth Intervent, St Gallen, Switzerland.
RI Mair, Jacqueline Louise/D-3829-2013
OI Mair, Jacqueline Louise/0000-0002-1466-8680
FU National Research Foundation, Prime Minister's Office, Singapore under
   its Campus for Research Excellence and Technological Enterprise (CREATE)
   programme
FX This research is supported by the National Research Foundation, Prime
   Minister's Office, Singapore under its Campus for Research Excellence
   and Technological Enterprise (CREATE) programme.
CR Berube C., 2020, JMIR PREPRINTS
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore TW, 2018, J MED INTERNET RES, V20, DOI 10.2196/11510
   Bickmore TW, 2010, INTERACT COMPUT, V22, P289, DOI 10.1016/j.intcom.2009.12.001
   Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158
   Fleming GA, 2020, DIABETES CARE, V43, P250, DOI 10.2337/dci19-0062
   Garg SK, 2019, DIABETES TECHNOL THE, V21, pS1, DOI 10.1089/dia.2019.0090
   Hauser-Ulrich S, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/15806
   IDC, 2020, INTR WHO GUID REC DI
   International Diabetes Federation, 2019, IDF DIABETES ATLAS 9
   King AC, 2020, JAMA INTERN MED, V180, P1481, DOI 10.1001/jamainternmed.2020.4143
   Kowatsch T., 2020, JMIR PREPRINTS
   Kvedar JC, 2016, NAT BIOTECHNOL, V34, P239, DOI 10.1038/nbt.3495
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Ma TT, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312853
   Obrien J. D., 2017, CHATBOTS DIABETES SE
   Ramchandani N, 2019, DIABETES TECHNOL THE, V21, pS48, DOI 10.1089/dia.2019.0016
   Retterath A., 2020, BENCHMARKING VENTURE
   Rui P, 2014, NATL AMBULATORY MED
   Schachner T, 2020, J MED INTERNET RES, V22, DOI 10.2196/20701
   Sosale AR, 2018, DIABETES, V67, DOI 10.2337/db18-866-P
   Stein N., 2020, ONE YEAR CLIN OUTCOM
   Stein N., 2019, CLIN OUTCOMES OLDER, DOI [10.2337/dci18-0007, DOI 10.2337/DCI18-0007]
   WHO, 2018, CLASS DIG HLTH INT V
   World Health Organization, 2016, GLOB REP PSOR
   Wu XH, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/12297
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
NR 28
TC 0
Z9 0
U1 3
U2 4
PU SCITEPRESS
PI SETUBAL
PA AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL
BN 978-989-758-490-9
PY 2021
BP 811
EP 816
DI 10.5220/0010412708110816
PG 6
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR6TR
UT WOS:000664063000091
OA Green Published, hybrid
DA 2022-08-02
ER

PT B
AU Callejas, Z
   Lopez-Cozar, R
   Abalos, N
   Griol, D
AF Callejas, Zoraida
   Lopez-Cozar, Ramon
   Abalos, Nieves
   Griol, David
BA PerezMarin, D
   PascualNieto, I
BF PerezMarin, D
   PascualNieto, I
TI Affective Conversational Agents: The Role of Personality and Emotion in
   Spoken Interactions
SO CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND
   EFFECTIVE PRACTICES
LA English
DT Article; Book Chapter
ID RECOGNITION; DIALOGUE; SPEECH; ANNOTATION; CHARACTER
AB In this chapter, we revisit the main theories of human emotion and personality and their implications for the development of affective conversational agents. We focus on the role that emotion plays for adapting the agents' behaviour and how this emotional responsivity can be conveniently modified by rendering a consistent artificial personality. The multiple applications of affective CAs are addressed by describing recent experiences in domains such as pedagogy, computer games, and computer-mediated therapy.
C1 [Callejas, Zoraida] Univ Granada, Fac Comp Sci & Telecommun, Dept Languages & Comp Syst, E-18071 Granada, Spain.
   [Griol, David] Univ Carlos III Madrid, Dept Comp Sci, E-28903 Getafe, Spain.
   [Griol, David] Motorola Inc, Schaumburg, IL 60196 USA.
RP Callejas, Z (corresponding author), Univ Ulster, Belfast, Antrim, North Ireland.
RI Carrion, Zoraida Callejas/C-6851-2012; Callejas, Zoraida/AAX-4634-2020
OI Carrion, Zoraida Callejas/0000-0001-8891-5237; Callejas,
   Zoraida/0000-0001-8891-5237
CR Abu Maria K, 2007, INFORM SOFTWARE TECH, V49, P695, DOI 10.1016/j.infsof.2006.08.002
   Aleman A, 2008, BIOL PSYCHOL, V79, P58, DOI 10.1016/j.biopsycho.2008.01.009
   Allport GW, 1936, PSYCHOL MONOGR, V47, P1
   [Anonymous], 1988, COGNITIVE STRUCTURE, DOI DOI 10.1017/CBO9780511571299
   Ball E, 2002, EMOTIONS IN HUMANS AND ARTIFACTS, P303
   Batliner A, 2004, LECT NOTES COMPUT SC, V3068, P1
   Batliner A., COMPUTER SP IN PRESS
   Beale R, 2009, INT J HUM-COMPUT ST, V67, P755, DOI 10.1016/j.ijhcs.2009.05.001
   Becker C., 2007, CONVERSATIONAL INFOR, P49
   Bee N, 2009, LECT NOTES ARTIF INT, V5773, P229
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore TW, 2010, INTERACT COMPUT, V22, P289, DOI 10.1016/j.intcom.2009.12.001
   Bickmore TW, 2005, INTERACT COMPUT, V17, P711, DOI 10.1016/j.intcom.2005.09.002
   Boehner K, 2007, INT J HUM-COMPUT ST, V65, P275, DOI 10.1016/j.ijhcs.2006.11.016
   Boersma P, 1993, ACCURATE SHORT TERM
   Brahnam S., 2005, ABUSE DARKER SIDE HU, P62
   Brahnam S, 2009, PSYCHNOLOGY J, V7, P9
   Bui T., 2002, P 25 GERM C ART INT, P1
   Burleson W, 2007, IEEE INTELL SYST, V22, P62, DOI 10.1109/MIS.2007.69
   Callejas Z., 2009, P 10 ANN C INT SPEEC, P2863
   Callejas Z, 2008, SPEECH COMMUN, V50, P416, DOI 10.1016/j.specom.2008.01.001
   Cannon W. B., 1929, BODILY CHANGES PAIN
   Cattell RB, 1943, J ABNORM SOC PSYCH, V38, P476, DOI 10.1037/h0054116
   Cavazza M., 2009, P 8 INT C AUT AG MUL, V1, P313
   Cavicchio F, 2008, LECT NOTES ARTIF INT, V5078, P233, DOI 10.1007/978-3-540-69369-7_26
   Chibelushi C. C., 2003, FACIAL EXPRESSION RE
   Conati C., 2009, P 17 INT C US MOD AD
   Conte H. R., 1981, J PERS SOC PSYCHOL, V2, P823
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Creed C, 2008, INTERACT COMPUT, V20, P225, DOI 10.1016/j.intcom.2007.11.004
   D'Mello SK, 2008, USER MODEL USER-ADAP, V18, P45, DOI 10.1007/s11257-007-9037-6
   Darwin C., 1872, ORIGIN SPECIES MEANS, V3rd ed, DOI 10.1037/10001-000
   de Rosis F, 2007, LECT NOTES COMPUT SC, V4738, P179
   de Sevin Etienne, 2009, P 8 INT C AUT AG MUL, P1131
   EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037/0033-2909.115.2.268
   Endrass B., 2009, P 8 INT C AUT AG MUL, V1, P281
   EYSENCK HJ, 1991, PERS INDIV DIFFER, V12, P773, DOI 10.1016/0191-8869(91)90144-Z
   EYSENCK SBG, 1963, BRIT J PSYCHOL, V54, P51, DOI 10.1111/j.2044-8295.1963.tb00861.x
   Fok HK, 2008, J RES PERS, V42, P133, DOI 10.1016/j.jrp.2007.04.005
   Forbes-Riley K, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P201
   Fox E., 2008, EMOTION SCI COGNITIV, DOI DOI 10.1007/978-1-137-07946-6
   Fragopanagos N, 2005, NEURAL NETWORKS, V18, P389, DOI 10.1016/j.neunet.2005.03.006
   Hansen JHL, 1996, SPEECH COMMUN, V20, P151, DOI 10.1016/S0167-6393(96)00050-7
   Harmon-Jones E., 2001, AFFECT SOCIAL COGNIT, P212
   HEATH RG, 1974, AM J PSYCHIAT, V131, P858
   Hook K, 2008, LECT NOTES COMPUT SC, V5033, P1, DOI 10.1007/978-3-540-68504-3_1
   Hook K, 2009, PHILOS T R SOC B, V364, P3585, DOI 10.1098/rstb.2009.0202
   Hooker CI, 2008, NEUROPSYCHOLOGIA, V46, P2709, DOI 10.1016/j.neuropsychologia.2008.05.005
   Imholz S, 2008, THINK SKILLS CREAT, V3, P47, DOI 10.1016/j.tsc.2008.02.001
   James W., 1884, MIND, V9, P185
   Johnstone T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1985, DOI 10.1109/ICSLP.1996.608026
   Kapoor A., 2005, P MM, V05, P1985
   KENTRIDGE RW, 1990, COGNITION EMOTION, V4, P191, DOI 10.1080/02699939008410796
   KRENN B, 2003, P WORKSH EM RICH VIR
   Kumano S., 2009, P 11 INT C MULT INT, P99
   LARSEN RJ, 1991, J PERS SOC PSYCHOL, V61, P132, DOI 10.1037/0022-3514.61.1.132
   Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534
   Lepri B, 2009, LECT NOTES COMPUT SC, V5535, P114, DOI 10.1007/978-3-642-02247-0_13
   Lester J. C., 1997, P SP INT GROUP COMP
   Lim S, 2010, INT J HUM-COMPUT ST, V68, P57, DOI 10.1016/j.ijhcs.2009.09.008
   Lopez-Cozar R, 2008, LECT NOTES ARTIF INT, V5246, P617, DOI 10.1007/978-3-540-87391-4_78
   Mairesse F., 2008, P 30 ANN M COGN SCI
   Marriot A., 2003, MPEG 4 FACIAL ANIMAT, P219
   McCrae RR, 2005, J PERS SOC PSYCHOL, V89, P407, DOI 10.1037/0022-3514.89.3.407
   MCCRAE RR, 1987, J PERS SOC PSYCHOL, V52, P81, DOI 10.1037/0022-3514.52.1.81
   McQuiggan SW, 2007, INT J HUM-COMPUT ST, V65, P348, DOI 10.1016/j.ijhcs.2006.11.015
   Morency L. P., 2006, P 7 INT C MULT INT I, P18
   Morrison D, 2007, SPEECH COMMUN, V49, P98, DOI 10.1016/j.specom.2006.11.004
   NIJHOLT A, 2007, CONVERSATIONAL INFOR, P21
   Nomura T., 2005, P INTERACT 2005 WORK, P58
   Ortony A, 2002, EMOTIONS IN HUMANS AND ARTIFACTS, P189
   Osgood C. E., 1957, MEASUREMENT MEANING
   Paiva A., 2001, P C ART CULT SCI ASP
   Peper M, 2006, J PHYSIOLOGY-PARIS, V99, P293, DOI 10.1016/j.jphysparis.2006.03.009
   Picard RW, 2002, EMOTIONS IN HUMANS AND ARTIFACTS, P213
   Pitterman A., 2006, P 2 IEEE INT C INT E, P213
   Plutchik Robert, 2003, EMOTIONS LIFE PERSPE
   Pratt JA, 2007, INTERACT COMPUT, V19, P512, DOI 10.1016/j.intcom.2007.02.003
   Prendinger H, 2003, LECT NOTES ARTIF INT, V2792, P283
   Read S, 2007, LECT NOTES COMPUT SC, V4738, P735
   Reithinger Norbert, 2006, ICMI 06, P51
   Rindermann H, 2001, PERS INDIV DIFFER, V30, P829, DOI 10.1016/S0191-8869(00)00076-3
   Rolls ET, 2007, EMOTION EXPLAINED
   ROSEMAN IJ, 1990, J PERS SOC PSYCHOL, V59, P899, DOI 10.1037/0022-3514.59.5.899
   Rousseau D, 1996, PROCEEDINGS OF THE 1, P38
   RUSSELL JA, 1994, PSYCHOL BULL, V115, P102, DOI 10.1037/0033-2909.115.1.102
   Scheibe S, 2010, J GERONTOL B-PSYCHOL, V65, P135, DOI 10.1093/geronb/gbp132
   SCHEUTZ M, 2001, P AAAI FALL S, P123
   Schuller B, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P552, DOI 10.1109/ASRU.2009.5372886
   Schulman D., 2009, P 4 INT C PERS TECHN, P1
   Sebe N, 2004, IEEE SYS MAN CYBERN, P623
   Shan C., 2007, P BRIT MACH VIS C BM
   Stern A, 2002, EMOTIONS IN HUMANS AND ARTIFACTS, P333
   STIBBARD R, 2000, P ISCA WORKSH SPEECH, P60
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Xiao H, 2005, LECT NOTES COMPUT SC, V3784, P637
   Yildirim S., COMPUTER SP IN PRESS
   Zeng ZH, 2007, LECT NOTES COMPUT SC, V4451, P72
   Zhu ZG, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM AND KNOWLEDGE ENGINEERING, VOLS 1 AND 2, P695, DOI 10.1109/ISKE.2008.4731019
   [No title captured]
   [No title captured]
NR 101
TC 7
Z9 7
U1 0
U2 10
PU IGI GLOBAL
PI HERSEY
PA 701 E CHOCOLATE AVE, STE 200, HERSEY, PA 17033-1240 USA
BN 978-1-60960-618-3; 978-1-60960-617-6
PY 2011
BP 203
EP 222
DI 10.4018/978-1-60960-617-6.ch009
D2 10.4018/978-1-60960-617-6
PG 20
WC Computer Science, Artificial Intelligence
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BZX29
UT WOS:000303201400010
DA 2022-08-02
ER

PT J
AU Hassani, M
   Young, SD
AF Hassani, Maryam
   Young, Sean D.
TI Potential Role of Conversational Agents in Encouraging PrEP Uptake
SO JOURNAL OF BEHAVIORAL HEALTH SERVICES & RESEARCH
LA English
DT Article; Early Access
ID HIV PREEXPOSURE PROPHYLAXIS; PREVENTION; PEOPLE
AB Approximately 1.2 million people are living with HIV, with many of them unaware of their infection. Pre-exposure prophylaxis (PrEP) is available to minimize transmission among those at high risk for infection, including men who have sex with men, people who inject drugs, and female sex workers. Despite its availability, there is low usage of PrEP. To address this problem, various digital tools have been examined in HIV research. Among those, conversational agents are still underused and their capacity warrants examination to reach at-risk populations. In this paper, we discuss the potential of conversational agents in increasing uptake of PrEP by addressing barriers experienced among those at high risk for infection.
C1 [Hassani, Maryam; Young, Sean D.] Univ Calif Irvine, Dept Informat, Irvine, CA USA.
RP Young, SD (corresponding author), Univ Calif Irvine, Dept Emergency Med, Orange, CA 92668 USA.
EM Syoung5@hs.uci.edu
OI Young, Sean D./0000-0001-6052-4875
FU National Institute of Mental Health [MH106415]; National Institute on
   Drug Abuse (NIDA); National Center of Complementary and Integrative
   Health (NCCIH); National Institute of Allergy and Infectious Diseases
   (NIAID)
FX This work was supported by the National Institute of Mental Health under
   Grant MH106415, National Institute on Drug Abuse (NIDA), National Center
   of Complementary and Integrative Health (NCCIH), and National Institute
   of Allergy and Infectious Diseases (NIAID).
CR Allen ST, 2020, AIDS BEHAV, V24, P1942, DOI 10.1007/s10461-019-02767-3
   [Anonymous], 2020, NEARLY 90 MILLION US
   [Anonymous], 2020, WHO LAUNCH CHATB FAC
   [Anonymous], FORBES WEBSITE
   [Anonymous], 2020, FUT IS NOW 37 FASC C
   [Anonymous], 2020, PREP US US COUNT LEV
   [Anonymous], 2018, FUTURE COMPUTED ARTI
   Auerbach JD, 2015, AIDS PATIENT CARE ST, V29, P102, DOI 10.1089/apc.2014.0142
   Biello KB, 2018, HARM REDUCT J, V15, DOI 10.1186/s12954-018-0263-5
   Brixey J, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P370
   Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158
   Chou R, 2019, JAMA-J AM MED ASSOC, V321, P2214, DOI 10.1001/jama.2019.2591
   Coalition GAP, 1996, AIDS WORLD 2 GLOB DI
   Darien K., 2021, INTERNET DERIVED HLT
   Dubov A, 2018, AM J MENS HEALTH, V12, P1843, DOI 10.1177/1557988318797437
   Footer KHA, 2019, AIDS CARE, V31, P1207, DOI 10.1080/09540121.2019.1587352
   Garett R, 2022, J PUBLIC HEALTH-UK, DOI 10.1093/pubmed/fdac020
   Garett R, 2021, HEALTH TECHNOL-GER, V11, P1305, DOI 10.1007/s12553-021-00611-0
   Garett R, 2021, AIDS BEHAV, V25, P333, DOI 10.1007/s10461-021-03221-z
   Gopalappa C, 2017, MED DECIS MAKING, V37, P224, DOI 10.1177/0272989X16668509
   Hoagland B, 2020, BRAZ J INFECT DIS, V24, P360, DOI 10.1016/j.bjid.2020.05.004
   Hosek S, 2016, J INT AIDS SOC, V19, DOI 10.7448/IAS.19.7.21107
   Kambutse I, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0207650
   Liu AY, 2021, AIDS BEHAV, V25, P1001, DOI 10.1007/s10461-020-03054-2
   Maeng W, 2021, 5TH ASIAN CHI SYMPOSIUM PROCEEDINGS, P160, DOI 10.1145/3429360.3468203
   Mayer KH, 2020, ADV THER, V37, P1778, DOI 10.1007/s12325-020-01295-0
   Mississippi State Department of Health, 2021, NEWS RELEASE
   Nilsson N. J., 1980, PRINCIPLES ARTIFICIA
   Ortblad KF, 2019, LANCET HIV, V6, pE644, DOI 10.1016/S2352-3018(19)30194-8
   Peitzmeier SM, 2017, AIDS CARE, V29, P1453, DOI 10.1080/09540121.2017.1300628
   Prakash AV, 2020, PAC ASIA J ASSOC INF, V12, P1, DOI 10.17705/1pais.12201
   Riddell J, 2018, JAMA-J AM MED ASSOC, V319, P1261, DOI 10.1001/jama.2018.1917
   Romero RA, 2021, CURR HIV-AIDS REP, V18, P391, DOI 10.1007/s11904-021-00565-y
   Rosengren-Hovee AL, 2021, AIDS BEHAV, V25, P2054, DOI 10.1007/s10461-020-03135-2
   Sarikaya R, 2017, IEEE SIGNAL PROC MAG, V34, P67, DOI 10.1109/MSP.2016.2617341
   Tomko C, 2019, AIDS PATIENT CARE ST, V33, P49, DOI 10.1089/apc.2018.0182
   van Heerden Alastair, 2017, 2017 International Conference on the Frontiers and Advances in Data Science (FADS). Proceedings, P80, DOI 10.1109/FADS.2017.8253198
   Vermey K, 2019, SEX TRANSM INFECT, V95, pA99, DOI 10.1136/sextrans-2019-sti.251
   Yi-Chieh Lee, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3392836
NR 39
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1094-3412
EI 1556-3308
J9 J BEHAV HEALTH SER R
JI J. Behav. Health Serv. Res.
DI 10.1007/s11414-022-09798-0
EA MAY 2022
PG 7
WC Health Care Sciences & Services; Health Policy & Services; Public,
   Environmental & Occupational Health
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Public, Environmental & Occupational
   Health
GA 0Z4SA
UT WOS:000791068500001
PM 35513743
OA Bronze, Green Published
DA 2022-08-02
ER

PT J
AU Lee, SY
   Lee, G
   Kim, S
   Lee, J
AF Lee, Seo-young
   Lee, Gyuho
   Kim, Soomin
   Lee, Joonhwan
TI Expressing Personalities of Conversational Agents through Visual and
   Verbal Feedback
SO ELECTRONICS
LA English
DT Article
DE personality expression; conversational agent; visual feedback; verbal
   cues; artificial intelligent speakers
ID COMPUTER PERSONALITIES; SOCIAL RESPONSES; COLOR; ROBOT
AB As the uses of conversational agents increase, the affective and social abilities of agents become important with their functional abilities. Agents that lack affective abilities could frustrate users during interaction. This study applied personality to implement the natural feedback of conversational agents referring to the concept of affective computing. Two types of feedback were used to express conversational agents' personality: (1) visual feedback and (2) verbal cues. For visual feedback, participants (N = 45) watched visual feedback with different colors and motions. For verbal cues, participants (N = 60) heard different conditions of agents' voices with different scripts. The results indicated that the motions of visual feedback were more significant than colors. Fast motions could express distinct and positive personalities. Different verbal cues were perceived as different personalities. The perceptions of personalities differed according to the vocal gender. This study provided design implications for personality expressions applicable to diverse interfaces.
C1 [Lee, Seo-young; Lee, Gyuho; Kim, Soomin; Lee, Joonhwan] Seoul Natl Univ, Dept Commun, Seoul 08826, South Korea.
RP Lee, J (corresponding author), Seoul Natl Univ, Dept Commun, Seoul 08826, South Korea.
EM joonhwan@snu.ac.kr
RI Kim, Soomin/ABD-4898-2021
OI Kim, Soomin/0000-0003-2523-7808
FU National Research Foundation of Korea (NRF) - Korean National Police
   Agency [NRF-2018M3E2A1081492]; Ministry of Science and ICT for Police
   field customized research and development project [NRF-2018M3E2A1081492]
FX This research was supported by the National Research Foundation of Korea
   (NRF) Grant funded by the Korean National Police Agency and the Ministry
   of Science and ICT for Police field customized research and development
   project. (NRF-2018M3E2A1081492).
CR Aly A, 2013, ACMIEEE INT CONF HUM, P325, DOI 10.1109/HRI.2013.6483606
   Andrist S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3603, DOI 10.1145/2702123.2702592
   APPLE W, 1979, J PERS SOC PSYCHOL, V37, P715, DOI 10.1037/0022-3514.37.5.715
   Bailenson JN, 2007, HUM-COMPUT INTERACT, V22, P325
   BARRICK MR, 1991, PERS PSYCHOL, V44, P1, DOI 10.1111/j.1744-6570.1991.tb00688.x
   Bickmore T., 2018, P SIGCHI C HUM FACT, P396
   Brave S., 2002, HUM FAC ER, P81
   Breazeal C, 2004, IEEE T SYST MAN CY C, V34, P181, DOI 10.1109/TSMCC.2004.826268
   Brebner J., 1985, INDIVIDUAL DIFFERENC, P27
   Brick M, 1944, AM J ORTHOPSYCHIAT, V14, P136, DOI 10.1111/j.1939-0025.1944.tb04858.x
   Byrne A, 2003, BEHAV BRAIN SCI, V26, P3, DOI 10.1017/S0140525X03000013
   Chang RCS, 2018, COMPUT HUM BEHAV, V84, P194, DOI 10.1016/j.chb.2018.02.025
   Costa G, 2008, ACTA HORTIC, P179, DOI 10.17660/ActaHortic.2008.774.22
   Dewaele JM, 1999, LANG LEARN, V49, P509, DOI 10.1111/0023-8333.00098
   DIGMAN JM, 1990, ANNU REV PSYCHOL, V41, P417, DOI 10.1146/annurev.psych.41.1.417
   Dryer DC, 1999, APPL ARTIF INTELL, V13, P273, DOI 10.1080/088395199117423
   F"unakoshi K., 2008, P 10 INT C MULT INT, P293, DOI [10.1145/1452392.1452452, DOI 10.1145/1452392.1452452]
   Hancock JT, 2001, COMMUN RES, V28, P325, DOI 10.1177/009365001028003004
   Heylighen F., 2002, FOUND SCI, V7, P293, DOI DOI 10.1023/A:1019661126744
   Hyde J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1719, DOI 10.1145/2702123.2702465
   Isbister K, 2000, INT J HUM-COMPUT ST, V53, P251, DOI 10.1006/ijhc.2000.0368
   Joosse M, 2013, IEEE INT CONF ROBOT, P2134, DOI 10.1109/ICRA.2013.6630863
   Karwoski TF, 1938, PSYCHOL MONOGR, V50, P1
   Lee KM, 2006, J COMMUN, V56, P754, DOI 10.1111/j.1460-2466.2006.00318.x
   Lee S., 2019, THESIS, P1
   Lee S., 2013, P 2018 ACM IEEE INT, P169
   Lenclos JP, 2004, COLORS WORLD GEOGRAP
   Loffler D, 2018, ACMIEEE INT CONF HUM, P334, DOI 10.1145/3171221.3171261
   Mairesse F., 2009, CAMB SHEFFIELD, P1
   McCrae RR, 1997, AM PSYCHOL, V52, P509, DOI 10.1037/0003-066X.52.5.509
   Moon Y, 1996, COMMUN RES, V23, P651, DOI 10.1177/009365096023006002
   MURRAY DC, 1957, J APPL PSYCHOL, V41, P279, DOI 10.1037/h0041425
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   NASS C, 1995, INT J HUM-COMPUT ST, V43, P223, DOI 10.1006/ijhc.1995.1042
   Naz K., 2004, P AIC COL PAINTS INT, P31
   Neff M, 2010, LECT NOTES ARTIF INT, V6356, P222, DOI 10.1007/978-3-642-15892-6_24
   Niculescu A., 2011, Proceedings of the 2011 International Conference on User Science and Engineering (i-USEr 2011), P18, DOI 10.1109/iUSEr.2011.6150529
   Oliveira R, 2018, ACMIEEE INT CONF HUM, P279, DOI 10.1145/3171221.3171272
   Picard R. W., 1999, Human-Computer Interaction: Ergonomics and User Interfaces. Proceedings of HCI International '99 (8th International Conference on Human-Computer Interaction), P829
   Picard R.W., 2000, AFFECTIVE COMPUTING
   Rammstedt B, 2007, J RES PERS, V41, P203, DOI 10.1016/j.jrp.2006.02.001
   SCHAIE KW, 1963, PSYCHOL BULL, V60, P530, DOI 10.1037/h0047902
   Seo YS, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020164
   Sokolova MV, 2015, APPL SCI-BASEL, V5, P275, DOI 10.3390/app5030275
   Song SC, 2017, ACMIEEE INT CONF HUM, P2, DOI 10.1145/2909824.3020239
   Tapus A, 2008, SPRINGER TRAC ADV RO, V39, P165
   Terada K., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P314, DOI 10.1109/ROMAN.2012.6343772
   TORRES O, 1997, P 1 INT WORKSH HUM C
   Wang R, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P295, DOI 10.1145/2750858.2804251
   Warner S., 1966, J PROJ TECH PERS ASS, V30, P512
   [No title captured]
NR 51
TC 3
Z9 3
U1 2
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2079-9292
J9 ELECTRONICS-SWITZ
JI Electronics
PD JUL
PY 2019
VL 8
IS 7
AR 794
DI 10.3390/electronics8070794
PG 19
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Physics
GA IS3OQ
UT WOS:000482063200081
OA gold, Green Published
DA 2022-08-02
ER

PT C
AU Mancini, M
   Pelachaud, C
AF Mancini, Maurizio
   Pelachaud, Catherine
BE Pelachaud, C
   Martin, JC
   Andre, E
   Chollet, G
   Karpouzis, K
   Pele, D
TI Dynamic behavior qualifiers for conversational agents
SO INTELLIGENT VIRTUAL AGENTS, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 7th International Conference on Intelligent Virtual Agents
CY SEP 17-19, 2007
CL Paris, FRANCE
SP &ftgroup France Telecom, European Project IST FP6 Callas, Springer, Assoc Advancement Artificial Intelligence, Eurograph, FP6 IST Humaine Network Excellence, ACM SIGCHI, ACM SIGART, Univ Paris 8, LIMSI-CNRS, Univ Augsburg, ENST, Natl Tech Univ Athens, France Telecom
ID CUES
AB We aim at defining conversational agents that exhibit qualitatively distinctive behaviors. To this aim we provide a small set of parameters to allow one to define behavior profiles and then leave to the system the task of animating the agent. Our approach is to manipulate the behavior tendency of the agent depending on its communicative intention and emotional state.
   In this paper we will define the concepts of Baseline and Dynamicline. The Baseline of an agent is defined as a set of fixed parameters that represent the personalized agent behavior, while the Dynamicline, is a set of parameters values that derive both from the Baseline and the current communicative goals and emotional state.
C1 [Mancini, Maurizio; Pelachaud, Catherine] Univ Paris 08, F-93526 St Denis 02, France.
RP Mancini, M (corresponding author), Univ Paris 08, F-93526 St Denis 02, France.
RI Mancini, Maurizio/D-9776-2015
OI Mancini, Maurizio/0000-0002-9933-8583
FU EU FP6 Network of Excellence HUMAINE [IST-2002-2.3.1.6]; EU FP6
   Integrated Project Callas [FP6-2005-IST-5]
FX Part of this research is supported by the EU FP6 Network of Excellence
   HUMAINE (IST-2002-2.3.1.6) and by the EU FP6 Integrated Project Callas
   (FP6-2005-IST-5).
CR ALLBECK J, 2002, WORKSH EMB CONV AG L
   Andre E., 1998, 2 INT C AUT AG, P261
   Ball G, 2000, EMBODIED CONVERSATIONAL AGENTS, P189
   Chi D, 2000, COMP GRAPH, P173
   GALLAHER PE, 1992, J PERS SOC PSYCHOL, V63, P133, DOI 10.1037/0022-3514.63.1.133
   HARTMANN B, 2005, INT C INT US INT WOR
   HARTMANN B, 2005, 3 INT JOINT C AUT AG
   Kipp M., 2005, GESTURE GENERATION I
   Kipp M, 2006, LECT NOTES ARTIF INT, V4133, P230
   Mancini M, 2006, LECT NOTES ARTIF INT, V3881, P280
   MAYA V, 2004, P ART INT SIM BEH LE
   MCNEILL D, 1992, HAND MIND GESTURES R, P423
   Neff M., 2005, P 2005 ACM SIGGRAPH, P161, DOI DOI 10.1145/1073368.1073391
   Noot H, 2003, LECT NOTES ARTIF INT, V2915, P324
   RUTTKAY Z, ANIMATING EXPRESSIVE
   Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W
   WALLBOTT HG, 1986, J PERS SOC PSYCHOL, V51, P690, DOI 10.1037/0022-3514.51.4.690
NR 17
TC 10
Z9 10
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-540-74996-7
J9 LECT NOTES ARTIF INT
PY 2007
VL 4722
BP 112
EP +
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BGR56
UT WOS:000250108100011
DA 2022-08-02
ER

PT C
AU Motalebi, N
   Abdullah, S
AF Motalebi, Nasim
   Abdullah, Saeed
GP ACM
TI Conversational Agents to Provide Couple Therapy for Patients with PTSD
SO PROCEEDINGS OF THE 12TH EAI INTERNATIONAL CONFERENCE ON PERVASIVE
   COMPUTING TECHNOLOGIES FOR HEALTHCARE (PERVASIVEHEALTH 2018)
SE International Conference on Pervasive Computing Technologies for
   Healthcare
LA English
DT Proceedings Paper
CT 12th EAI International Conference on Pervasive Computing Technologies
   for Healthcare (PervasiveHealth)
CY MAY 21-24, 2018
CL New York, NY
SP EAI
DE Conversation Voice Agents; Mental Health; PTSD; HCI; CSCW
ID BEHAVIORAL CONJOINT THERAPY
AB Conversational agents (CAs) like Amazon Alexa can potentially enable a new way to deliver therapy to patients with serious mental illnesses. Specifically, they can be used to provide support for real-time family therapy and interventions in a scalable way. However, this requires significant changes in traditional therapeutic content since interaction with CAs is fundamentally different than reading or using eHealth applications. In this work, we aim to identify challenges in adapting a clinically validated therapy for Post-Traumatic Stress Disorder (PTSD) to conversational agents. Specifically, we describe our initial design and development process to use Amazon Alexa to deliver Cognitive-Behavioral Conjoint Therapy (CBCT) for PTSD. Our initial design process resulted in an interaction model that emphasizes short dialogues and interactivity. This design process and interaction model can potentially be useful for future studies focusing on using conversational agents for therapeutic content delivery.
C1 [Motalebi, Nasim; Abdullah, Saeed] Penn State Univ, University Pk, PA 16802 USA.
RP Motalebi, N (corresponding author), Penn State Univ, University Pk, PA 16802 USA.
EM nfm5140@psu.edu; saeed@psu.edu
OI Abdullah, Saeed/0000-0002-4371-8173
CR Anders G., 2017, AMAZONS ALEXA IS BET
   Anderson M., 2015, TECHNOLOGY DEVICE OW
   Brunette M. F., 2016, COORDINATED TECHNOLO
   Choe EK, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P61
   Churchill E., 2014, FDN DESIGNING USER C
   Dabbs AD, 2009, CIN-COMPUT INFORM NU, V27, P175, DOI 10.1097/NCN.0b013e31819f7c7c
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Kazdin AE, 2013, CLIN PSYCHOL SCI, V1, P170, DOI 10.1177/2167702612463566
   Kessler RC, 2005, ARCH GEN PSYCHIAT, V62, P593, DOI 10.1001/archpsyc.62.6.593
   Kuhn E, 2017, J CONSULT CLIN PSYCH, V85, P267, DOI 10.1037/ccp0000163
   Ma MX, 2017, 2017 IEEE/ACM SECOND INTERNATIONAL CONFERENCE ON CONNECTED HEALTH - APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P258, DOI 10.1109/CHASE.2017.91
   Macdonald A, 2016, J FAM PSYCHOL, V30, P157, DOI 10.1037/fam0000177
   McCurdie Tara, 2012, Biomed Instrum Technol, VSuppl, P49, DOI 10.2345/0899-8205-46.s2.49
   Mohr D. C., 2017, J MED INTERNET RES, V19
   Monson CM, 2012, JAMA-J AM MED ASSOC, V308, P700, DOI 10.1001/jama.2012.9307
   Price M, 2013, PSYCHOL TRAUMA-US, V5, P93, DOI 10.1037/a0026244
   Schlosser D, 2016, JMIR RES PROTOC, V5, DOI 10.2196/resprot.5450
   Schwartz S. W., 2009, ADOLESCENT MENTAL HL
   Shnaider P, 2014, J TRAUMA STRESS, V27, P129, DOI 10.1002/jts.21893
   Tarrier N, 1999, PSYCHOL MED, V29, P801, DOI 10.1017/S0033291799008569
NR 20
TC 1
Z9 1
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
SN 2153-1633
BN 978-1-4503-6450-8
J9 INT CONF PER COMP
PY 2018
BP 347
EP 351
DI 10.1145/3240925.3240933
PG 5
WC Computer Science, Interdisciplinary Applications; Health Care Sciences &
   Services; Medical Informatics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Health Care Sciences & Services; Medical Informatics
GA BQ7AM
UT WOS:000614057600045
DA 2022-08-02
ER

PT S
AU Lee, J
   Marsella, S
AF Lee, Jina
   Marsella, Stacy
BE Gratch, J
   Young, M
   Aylett, R
   Ballin, D
   Olivier, P
TI Nonverbal behavior generator for embodied conversational agents
SO INTELLIGENT VIRTUAL AGENTS, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 6th International Conference on Intelligent Virtual Agents
CY AUG 21-23, 2006
CL Marina del Rey, CA
SP Univ SE Calif, Inst Creat Technol, HUMAINE Network, Boston Dynam Inc, Soar Technol Inc, Elect Arts, AAAI, European Assoc Com Graph, ACM SIGART, ACM SIGGRAPH, ACM SIGCHI
AB Believable nonverbal behaviors for embodied conversational agents (ECA) can create a more immersive experience for users and improve the effectiveness of communication. This paper describes a nonverbal behavior generator that analyzes the syntactic and semantic structure of the surface text as well as the affective state of the ECA and annotates the surface text with appropriate nonverbal behaviors. A number of video clips of people conversing were analyzed to extract the nonverbal behavior generation rules. The system works in real-time and is user-extensible so that users can easily modify or extend the current behavior generation rules.
C1 Univ So Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
RP Lee, J (corresponding author), Univ So Calif, Inst Informat Sci, 4676 Admiralty Way,Suite 1001, Marina Del Rey, CA 90292 USA.
EM jinal@isi.edu; marsella@isi.edu
CR BECHEIRAZ P, 1998, P 1 WORKSH EMB CONV, P57
   Cassell J, 1999, SPRING COMP SCI, P109
   Cassell J., 2001, P SIGGRAPH 2001, P477, DOI 10. 1145/383259. 383315
   CHARIANK E, 2000, P N AM CHAPT ASS COM
   De Carolis B, 2004, COG TECH, P65
   DURLACH N, 1998, BT WORKSH PRES SHAR
   FABRI M, 2002, P AUT AG MULT AG SYS
   HADAR U, 1983, HUM MOVEMENT SCI, V2, P35, DOI 10.1016/0167-9457(83)90004-0
   HEYLEN D, IN PRESS P AISB S SO
   Kallmann M., 2005, P 5 INT WORK C INT V, V3661, P243
   KENDON A, 2003, GESTURE, P147
   Knapp M.L., 1997, NONVERBAL COMMUNICAT, V4th ed
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   KOPP S, 2006, UNPUB INT C VIRT AG
   McClave EZ, 2000, J PRAGMATICS, V32, P855, DOI 10.1016/S0378-2166(99)00079-X
   Ploog D., 1979, HUMAN ETHOLOGY CLAIM, P169, DOI DOI 10.1007/978-1-4020-2783-33
   STRIEGNITZ K, 2005, P WORKSH SPAT LANG D
   SWARTOUT W, 2001, P 5 INT C AUT AG MON
   VILHJALMSSON H, 2005, WORKSH MOD CONSTR HU
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
NR 20
TC 84
Z9 84
U1 0
U2 9
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-37593-7
J9 LECT NOTES ARTIF INT
PY 2006
VL 4133
BP 243
EP 255
PG 13
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BEZ35
UT WOS:000240268400020
DA 2022-08-02
ER

PT C
AU Ciupe, A
   Militia, DF
   Meza, S
   Orza, B
AF Ciupe, Aurelia
   Militia, Doru Florin
   Meza, Serban
   Orza, Bogdan
BE Ashmawy, AK
   Schreiter, S
TI Learning Agile with Intelligent Conversational Agents
SO PROCEEDINGS OF 2019 IEEE GLOBAL ENGINEERING EDUCATION CONFERENCE
   (EDUCON)
SE IEEE Global Engineering Education Conference
LA English
DT Proceedings Paper
CT 10th IEEE Global Engineering Education Conference (EDUCON)
CY APR 09-11, 2019
CL Dubai, U ARAB EMIRATES
SP IEEE, Amer Univ Dubai, Sch Engn, IEEE Educ Soc, MathWorks, EdNex, Quanser
DE conversational agent; learning analytics; Agile Scrum training; higher
   education; educational design
AB Conversational agents assist traditional teaching-learning instruments in proposing new designs for knowledge creation and learning analysis, across organizational environments. Means of building common educative background in both industry and academic fields become of interest for ensuring educational effectiveness and consistency. Such a context requires transferable practices and becomes the basis for the Agile adoption into Higher Education, at both curriculum and operational levels. The current work proposes a model for delivering Agile Scrum training through an assistive web-based conversational service, where analytics are collected to provide an overview on learners' knowledge path. Besides its specific applicability into Software Engineering (SE) industry, the model is to assist the academic SE curriculum. A user-acceptance test has been carried out among 200 undergraduate students and patterns of interaction have been depicted for 2 conversational strategies.
C1 [Ciupe, Aurelia; Militia, Doru Florin; Meza, Serban; Orza, Bogdan] Tech Univ Cluj Napoca, Multimedia Syst & Applicat Lab, Cluj Napoca, Romania.
RP Ciupe, A (corresponding author), Tech Univ Cluj Napoca, Multimedia Syst & Applicat Lab, Cluj Napoca, Romania.
EM aurelia.ciupe@com.utcluj.ro; mititica.doru.florin@utcluj.didatec.ro;
   serban.meza@com.utcluj.ro; bogdan.orza@com.utcluj.ro
RI MEZA, Serban Nicolae/ABH-2578-2021; MEZA, Serban Nicolae/ABH-2623-2021;
   ORZA, Bogdan/S-8746-2019
OI MEZA, Serban Nicolae/0000-0002-9109-0659; MEZA, Serban
   Nicolae/0000-0002-9109-0659; 
CR Bogatu A., 2015, ROCHI, P81
   Chatti MA, 2012, INT J TECHNOL ENHANC, V4, P318, DOI 10.1504/IJTEL.2012.051815
   Demetriadis S, 2018, LECT NOTE DATA ENG, V17, P1061, DOI 10.1007/978-3-319-75928-9_98
   Ferrucci D, 2010, AI MAG, V31, P59, DOI 10.1609/aimag.v31i3.2303
   Gary K. A., 2015, P FRONT ED C FIE, V2014
   Heberle A, 2018, IEEE GLOB ENG EDUC C, P1723, DOI 10.1109/EDUCON.2018.8363442
   High R, 2012, ERA COGNITIVE SYSTEM, P1
   Kropp M, 2014, CONF SOFTW ENG EDUC, P139, DOI 10.1109/CSEET.2014.6816791
   Kropp M, 2013, CONF SOFTW ENG EDUC, P179, DOI 10.1109/CSEET.2013.6595249
   Martin A, 2017, LECT NOTES BUS INF P, V283, P151, DOI 10.1007/978-3-319-57633-6_10
   Massaro DW, 2000, EMBODIED CONVERSATIONAL AGENTS, P287
   Radziwill N.M., 2017, ARXIV170404579 ARXIV170404579
   Ravi R, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2193, DOI 10.1109/ICACCI.2018.8554577
   Rico DF, 2009, AGILE 2009 CONFERENCE, P174, DOI 10.1109/AGILE.2009.13
   RODA C., 2001, P BOTSHOW 2001, P1
   Schafer U, 2017, IEEE GLOB ENG EDUC C, P754
   Scharlau B.A., 2013, P 18 ACM C INN TECHN, P303
   Smart Paul, 2017, Philos Technol, V30, P357, DOI 10.1007/s13347-016-0250-2
   Vinyals O., 2015, NEURAL CONVERSATIONA, V37
NR 19
TC 0
Z9 0
U1 1
U2 7
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2165-9567
BN 978-1-5386-9506-7
J9 IEEE GLOB ENG EDUC C
PY 2019
BP 1100
EP 1107
PG 8
WC Education, Scientific Disciplines; Engineering, Multidisciplinary
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Education & Educational Research; Engineering
GA BN1XY
UT WOS:000475690400164
DA 2022-08-02
ER

PT C
AU Das, KSJ
   Beinema, T
   den Akker, HO
   Hermens, H
AF Das, Kuthethur Sneha Jagannath
   Beinema, Tessa
   den Akker, Harm Op
   Hermens, Hermie
BE Ziefle, M
   Maciaszek, L
TI Generation of Multi-Party Dialogues among Embodied Conversational Agents
   to Promote Active Living and Healthy Diet for Subjects Suffering from
   Type 2 Diabetes
SO ICT4AWE 2019: PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON
   INFORMATION AND COMMUNICATION TECHNOLOGIES FOR AGEING WELL AND E-HEALTH
LA English
DT Proceedings Paper
CT 5th International Conference on Information and Communication
   Technologies for Ageing Well and e-Health (ICT4AWE)
CY MAY 02-04, 2019
CL Heraklion, GREECE
DE Virtual Coaching; Embodied Conversational Agents; Behaviour Change; Type
   2 Diabetes Mellitus
ID PHYSICAL-ACTIVITY; VIRTUAL AGENTS; MOTIVATION; AVATARS
AB Diabetes Mellitus is a chronic condition that is highly prevalent in the geriatric population. Self-management plays a key role in the management of this condition. Leading an active lifestyle and having a healthy meal are cornerstones in managing this condition. Now with the advancement in Information and Communication Technology (ICT), continuous and proactive care from the affected individual's side is possible. A change in the individual's behaviour would be beneficial in pursuing physical activity and adopting a healthy diet. This paper focuses on providing a dialogue based virtual health coaching through multiple Embodied Conversational Agents (ECAs), using strategies such as Motivational Interviewing (MI), Theories of Behaviour Change and Behaviour Change Techniques (BCTs). The dialogues are constructed to induce a behaviour change and promote motivation in the affected subjects to work on improving their physical activity and diet plan.
C1 [Das, Kuthethur Sneha Jagannath; Hermens, Hermie] Univ Twente, Biomed Signals & Syst, NL-7522 NB Enschede, Netherlands.
   [Das, Kuthethur Sneha Jagannath; Beinema, Tessa; den Akker, Harm Op] Roessingh Res & Dev, Telemed Grp, NL-7522 AH Enschede, Netherlands.
RP Das, KSJ (corresponding author), Univ Twente, Biomed Signals & Syst, NL-7522 NB Enschede, Netherlands.; Das, KSJ (corresponding author), Roessingh Res & Dev, Telemed Grp, NL-7522 AH Enschede, Netherlands.
RI Beinema, Tessa/AAH-8905-2021; Beinema, Tessa/AGD-2961-2022
OI Beinema, Tessa/0000-0003-3513-0641; op den Akker,
   Harm/0000-0001-6312-6063
CR Al-Taee M.A., 2013, IEEE JORD C APPL EL, P1
   Albaina I. M., 2009, INT C PERV COMP TECH, P1, DOI DOI 10.4108/ICST.PERVASIVEHEALTH2009.5949
   Amini R, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI 2013), P46, DOI 10.1109/ICHI.2013.13
   Aujoulat I, 2007, PATIENT EDUC COUNS, V66, P13, DOI 10.1016/j.pec.2006.09.008
   Backholer K, 2012, PATHOLOGY, V44, P110, DOI 10.1097/PAT.0b013e32834e8e12
   Backman C, 2018, JMIR RES PROTOC, V7, DOI 10.2196/11031
   BANDURA A, 1991, ORGAN BEHAV HUM DEC, V50, P248, DOI 10.1016/0749-5978(91)90022-L
   Baylor AL, 2009, PHILOS T R SOC B, V364, P3559, DOI 10.1098/rstb.2009.0148
   Di Loreto C, 2003, DIABETES CARE, V26, P404, DOI 10.2337/diacare.26.2.404
   Fioravanti A, 2011, IEEE ENG MED BIO, P3550, DOI 10.1109/IEMBS.2011.6090591
   FISHER JD, 1992, PSYCHOL BULL, V111, P455, DOI 10.1037/0033-2909.111.3.455
   Gokalp H, 2013, TELEMED E-HEALTH, V19, P910, DOI 10.1089/tmj.2013.0109
   Gupta Itika, 2018, 2018 IEEE International Conference on Healthcare Informatics (ICHI). Proceedings, P419, DOI 10.1109/ICHI.2018.00081
   Hankonen N, 2015, ANN BEHAV MED, V49, P7, DOI 10.1007/s12160-014-9624-9
   Inzucchi S. E, 2011, CECIL MED
   JANZ NK, 1984, HEALTH EDUC QUART, V11, P1, DOI 10.1177/109019818401100101
   Kantharaju RB, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P255, DOI 10.1145/3267851.3267890
   Karageorgos G., 2018, IEEE REV BIOMEDICAL
   Lagerros YT, 2013, THER ADV GASTROENTER, V6, P77, DOI 10.1177/1756283X12459413
   LeRouge C, 2013, INT J MED INFORM, V82, pE251, DOI 10.1016/j.ijmedinf.2011.03.006
   Lisetti C. L., 2011, 2011 5th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth 2011), P246, DOI 10.4108/icst.pervasivehealth.2011.246078
   Locke EA, 2002, AM PSYCHOL, V57, P705, DOI 10.1037//0003-066X.57.9.705
   Maresca G., 2018, J TELEMED TELECARE
   Michie S, 2013, ANN BEHAV MED, V46, P81, DOI 10.1007/s12160-013-9486-6
   Miller W. R., 1995, MOTIVATIONAL ENHANCE
   Nieto-Chaupis H., 2017, EL EL ENG INF COMM T, P1
   Op den Akker H, 2018, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES FOR AGEING WELL AND E-HEALTH (ICT4AWE), P219, DOI 10.5220/0006787702190226
   Pardhan S, 2020, ETHNIC HEALTH, V25, P843, DOI 10.1080/13557858.2018.1455809
   PROCHASKA JO, 1994, HEALTH PSYCHOL, V13, P39, DOI 10.1037/0278-6133.13.1.39
   Ravenet B, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01144
   Rogers R.W, 1983, SOCIAL PSYCHOPHYSIOL, P153, DOI DOI 10.1093/DEAFED/ENT031
   Seifert CM, 2012, AM J HEALTH PROMOT, V26, pTAHP1, DOI [10.4278/ajhp.26.4.tahp, 10.4278/ajhp.26.3.tahp]
   Shaked NA, 2017, HEALTHC TECHNOL LETT, V4, P83, DOI 10.1049/htl.2017.0009
   Sherifali D, 2017, J DIABETES, V9, P547, DOI 10.1111/1753-0407.12528
   Silva S, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041285
   Sina M, 2018, DIABETES RES CLIN PR, V141, P126, DOI 10.1016/j.diabres.2018.04.031
   Snaith M., 2018, P 7 INT C COMP MOD A
   Tanaka H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182151
   Thent ZC, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080436
   van Doorn-van Atten M, 2018, NUTRIENTS, V10, P1062
   Wargnier P, 2015, 2015 3RD IEEE VR INTERNATIONAL WORKSHOP ON VIRTUAL AND AUGMENTED ASSISTIVE TECHNOLOGY (VAAT), P23, DOI 10.1109/VAAT.2015.7155406
NR 41
TC 6
Z9 6
U1 1
U2 3
PU SCITEPRESS
PI SETUBAL
PA AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL
BN 978-989-758-368-1
PY 2019
BP 297
EP 304
DI 10.5220/0007750602970304
PG 8
WC Computer Science, Interdisciplinary Applications; Health Care Sciences &
   Services; Geriatrics & Gerontology; Medical Informatics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Health Care Sciences & Services; Geriatrics &
   Gerontology; Medical Informatics
GA BP9QT
UT WOS:000570596400033
OA Green Published, hybrid, Green Submitted
DA 2022-08-02
ER

PT C
AU Pesty, S
   Duhaut, D
AF Pesty, Sylvie
   Duhaut, Dominique
BE Richard, P
   Braz, J
TI ACCEPTABILITY IN INTERACTION From Robots to Embodied Conversational
   Agents
SO GRAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER
   GRAPHICS THEORY AND APPLICATIONS
LA English
DT Proceedings Paper
CT International Conference on Computer Graphics Theory and Applications
   (GRAPP 2011)
CY MAR 05-07, 2011
CL Vilamoura, PORTUGAL
SP Inst Syst & Technol Informat Control & Commun
DE Embodied Conversational Agents; Acceptability; Companion robot;
   Emotions; and personality
ID INFORMATION-TECHNOLOGY; USER ACCEPTANCE
AB This paper will propose to increase the traditional definition of system acceptability to take into account the heavy interaction between a man and a real or virtual system. We introduce the notion of "socially credible" which describes the need of emotions and personality in intelligent environment. This notion is measured by experiments using a plush robot Emi and a virtual embodied conversational agent.
C1 [Pesty, Sylvie] Univ Grenoble, UMR 5217, Lab LIG, Grenoble, France.
   [Duhaut, Dominique] Univ South Britanny, Valoria, Vannes, France.
RP Pesty, S (corresponding author), Univ Grenoble, UMR 5217, Lab LIG, Grenoble, France.
EM sylvie.pesty@imag.fr; dominique.duhaut@univ-ubs.fr
FU French ANR agency under the Psirob project; CECIL project
FX A part of this work has been realized with the support of the French ANR
   agency under the Psirob project and the CECIL project.
CR Ajzen I., 1985, ACTION CONTROL COGNI, P11, DOI DOI 10.1007/978-3-642-69746-3_2
   BATES J, 1994, COMMUN ACM, V37, P122, DOI 10.1145/176789.176803
   Berger A., 2005, 4 INT CENTR E EUR C, P31
   Dang T.-H.-H., 2008, 10 INT C CONTR AUT R
   Davis F.D., 1986, TECHNOLOGY ACCEPTANC
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Guiraud N., 2011, P 10 INT C AUT AG MU
   Le Tallec M., 2010, P TEXT SPEECH DIAL T
   Leidner D, 2006, MIS Q, V30, P2
   Nielsen J, 1994, USABILITY ENG
   Ortony A., 2003, EMOTIONS HUMANS ARTI
   Poggi I, 2005, TEXT SPEECH LANG TEC, V27, P3, DOI 10.1007/1-4020-3051-7_1
   Saint-Aime S., 2010, CONCEPTION REALISATI
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
NR 14
TC 0
Z9 0
U1 1
U2 5
PU SCITEPRESS
PI SETUBAL
PA AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL
BN 978-989-8425-45-4
PY 2011
BP 365
EP 370
PG 6
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BG8ZU
UT WOS:000392902600047
DA 2022-08-02
ER

PT S
AU Balata, J
   Mikovec, Z
   Slavik, P
AF Balata, Jan
   Mikovec, Zdenek
   Slavik, Pavel
BE Moore, RJ
   Szymanski, MH
   Arar, R
   Ren, GJ
TI Conversational Agents for Physical World Navigation
SO STUDIES IN CONVERSATIONAL UX DESIGN
SE Human-Computer Interaction Series
LA English
DT Article; Book Chapter
AB This chapter presents a design process for developing a conversational navigation agent for visually impaired pedestrians where communication runs in natural language. This approach brings a lot of new problems with opportunity to solve them in nontraditional ways. The conversation with the agent is an example of a problem-solving process with several complex parts of the solution needed to be executed by the user. The user can ask additional questions about each part of the solution, thus adaptively changing the level of detail of information acquired, or to alternate the whole process to fit user preferences. In this way, the agent can replace a human navigator. Using this design process exemplar, we provide guidance on creating similar conversational agents, which utilize a natural language user interface. The guidance is supported by the results of several experiments conducted with participants with visual impairments.
C1 [Balata, Jan; Mikovec, Zdenek; Slavik, Pavel] Czech Tech Univ, Fac Elect Engn, Prague, Czech Republic.
RP Balata, J (corresponding author), Czech Tech Univ, Fac Elect Engn, Prague, Czech Republic.
EM balatjan@fel.cvut.cz; xmikovec@fel.cvut.cz; slavik@fel.cvut.cz
RI Míkovec, Zdeněk/AAE-9906-2022; Míkovec, Zdeněk/AFF-6102-2022
OI Míkovec, Zdeněk/0000-0001-5569-6066; Míkovec, Zdeněk/0000-0001-5569-6066
CR Allen JF, 2001, AI MAG, V22, P27
   Baecker Ronald M, 2008, Interactions, V15, P22, DOI 10.1145/1340961.1340968
   Balata J, 2016, ACSIS-ANN COMPUT SCI, V8, P1605, DOI 10.15439/2016F135
   Balata J, 2015, LECT NOTES COMPUT SC, V9296, P89, DOI 10.1007/978-3-319-22701-6_8
   Bradley NA, 2005, PERS UBIQUIT COMPUT, V9, P395, DOI 10.1007/s00779-005-0350-y
   Bujacz M, 2008, 2008 Conference on Human System Interactions, P888, DOI 10.1109/HSI.2008.4581561
   Chu-Carroll J, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P262
   Chung G., 2004, P 42 ANN M ASS COMP, P63
   CLARKCARTER DD, 1986, ERGONOMICS, V29, P779, DOI 10.1080/00140138608968314
   Frohlich D.M., 1990, COMPUTERS CONVERSATI, P187
   Golledge R. G., 1996, CONSTRUCTION COGNITI, P215, DOI DOI 10.1007/978-0-585-33485-1_10
   HAMMOND K, 1995, PR CONF ART INT APPL, P80, DOI 10.1109/CAIA.1995.378787
   Hearst M, 1999, IEEE INTELL SYST APP, V14, P14, DOI 10.1109/5254.796083
   Jurafsky D., 2000, SPEECH LANGUAGE PROC
   Leshed Gilly, 1675, P 26 ANN CHI C HUM F, DOI [10.1145/1357054.1357316, DOI 10.1145/1357054.1357316]
   Loomis J. M., 1994, ASSETS '94. The First Annual ACM Conference on Assistive Technologies, P85
   Lovett MC, 2002, HDB EXPT PSYCHOL
   May AJ, 2003, PERS UBIQUIT COMPUT, V7, P331, DOI 10.1007/s00779-003-0248-5
   Newell A., 1972, HUMAN PROBLEM SOLVIN
   NIELSEN J, 1993, COMMUN ACM, V36, P83, DOI 10.1145/255950.153582
   Parush A, 2007, LECT NOTES COMPUT SC, V4736, P238
   Pasotti P, 2016, P 10 INT WORKSH NORM
   Rosen S., 2010, FDN ORIENTATION MOBI, V1, P138
   ROSS T, 2004, MOB HUM COMP INT, V3160, P300
   Sacks Harwey, 1979, EVERYDAY LANGUAGE ST, P15, DOI DOI 10.2307/2066919
   Strothotte T, 1996, P 2 ANN ACM C ASS TE, P139, DOI DOI 10.1145/228347.228369
   V?lkel T., 2008, P 10 INT ACM SIGACCE, P185, DOI [DOI 10.1145/1414471.1414506, 10.1145/1414471.1414506]
   vanDam A, 1997, COMMUN ACM, V40, P63, DOI 10.1145/253671.253708
   Vystrcil J, 2014, EACL 2014, P58
   White R.W., 2009, P 2009 INT C INCL DE
   Wilcock Graham, 2012, P COLING 2012 WORKSH, P57
   Wobbrock J.O, 2011, ACM TRANS ACCESS COM, V3, P1, DOI [DOI 10.1145/1952383.1952384, 10.1145/1952383.1952384]
NR 32
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1571-5035
EI 2524-4477
BN 978-3-319-95579-7; 978-3-319-95578-0
J9 HUM-COMPUT INT-SPRIN
PY 2018
BP 61
EP 83
DI 10.1007/978-3-319-95579-7_4
D2 10.1007/978-3-319-95579-7
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Software Engineering
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BM0BU
UT WOS:000458606800004
DA 2022-08-02
ER

PT C
AU Ireland, D
   Hassanzadeh, H
   Tran, SN
AF Ireland, David
   Hassanzadeh, Hamed
   Tran, Son N.
BE Cheng, L
   Leung, ACS
   Ozawa, S
TI Sentimental Analysis for AIML-Based E-Health Conversational Agents
SO NEURAL INFORMATION PROCESSING (ICONIP 2018), PT II
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 25th International Conference on Neural Information Processing (ICONIP)
CY DEC 13-16, 2018
CL Siem Reap, CAMBODIA
SP Asia Pacific Neural Network Soc, Springer
DE Sentiment analysis; E-health chatbots
AB Conversational agents or chat-bots are emerging in various applications including finance, education and e-health. Recent research has highlighted the importance of the consistency between the response of the chat-bot and the sentiment of the input utterance. This is quite challenging as detecting the sentiment of an utterance often depends on the context and timing of the conversation. Moreover, whereas humans have complex repair strategies, encoding these for human-computer interaction is problematic. This paper presents five sentiment prediction models for conversational agents that are trained on a large corpus of smart-phone application reviews and their sentiment ranks obtained from the Google playstore. These models are tested on collected, real-life conversations between a human and a machine. It is found that positive utterances are classified with a high accuracy but classifying negative utterances is still challenging.
C1 [Ireland, David; Hassanzadeh, Hamed; Tran, Son N.] CSIRO, Australian E Hlth Res Ctr, Brisbane, Qld 4026, Australia.
RP Tran, SN (corresponding author), CSIRO, Australian E Hlth Res Ctr, Brisbane, Qld 4026, Australia.
EM d.ireland@csiro.au; hamed.hassanzadeh@csiro.au; son.tran@csiro.au
RI Hassanzadeh, Hamed/K-9151-2016
OI Hassanzadeh, Hamed/0000-0003-2315-1963
CR Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Crutzen R, 2011, J ADOLESCENT HEALTH, V48, P514, DOI 10.1016/j.jadohealth.2010.09.002
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Huang JZ, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P423
   Ireland D, 2016, DRIVING REFORM DIGIT, V227
   Ireland D, 2016, CLASSIFIED UTTERANCE
   Ireland D, 2015, HARLIE DIALOG DATA
   Ireland D, 2015, STUD HEALTH TECHNOL, V214, P128, DOI 10.3233/978-1-61499-558-6-128
   Kim Y, 2014, P 2014 C EMP METH NA, P1746, DOI 10.3115/v1/D14-1181
   Milne M, 2011, CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND EFFECTIVE PRACTICES, P23, DOI 10.4018/978-1-60960-617-6.ch002
   Moraes R, 2013, EXPERT SYST APPL, V40, P621, DOI 10.1016/j.eswa.2012.07.059
   Mullen T., 2004, P 2004 C EMP METH NA, P412, DOI [DOI 10.3115/1219044.1219069, 10.3115/1219044.1219069]
   RATNADEEP R, 2013, ASIAN J COMPUT SCI I, V2, P104
   Saldert C, 2014, INT J LANG COMM DIS, V49, P710, DOI 10.1111/1460-6984.12105
   Suk HI, 2017, ELS MIC SOC BOOK SER, P3, DOI 10.1016/B978-0-12-810408-8.00002-X
   Wallace, 2003, ELEMENTS AIML STYLE, DOI 10.1.1.693.3664.
   Watson A, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.1629
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
NR 19
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-04179-3; 978-3-030-04178-6
J9 LECT NOTES COMPUT SC
PY 2018
VL 11302
BP 41
EP 51
DI 10.1007/978-3-030-04179-3_4
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ6OX
UT WOS:000612947100004
DA 2022-08-02
ER

PT C
AU Truong, HP
   Parthasarathi, P
   Pineau, J
AF Hoai Phuoc Truong
   Parthasarathi, Prasanna
   Pineau, Joelle
GP Assoc Computat Linguist
TI MACA: A Modular Architecture for Conversational Agents
SO 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND
   DIALOGUE (SIGDIAL 2017)
LA English
DT Proceedings Paper
CT 18th Annual Meeting of the
   Special-Interest-Group-on-Discourse-and-Dialogue (SIGdial)
CY AUG 15-17, 2017
CL Saarbrucken, GERMANY
SP Special Interest Grp Discourse & Dialogue, Interactions, Adobe Res, Facebook, ETS, Univ Saarlandes, Univ Saarlandes, Spoken Languages Syst Grp, Microsoft, Amazon, Honda Res Inst, Charamel GmbH, Maluuba, DFKI, PARC, SemVox
AB We propose a software architecture designed to ease the implementation of dialogue systems. The Modular Architecture for Conversational Agents (MACA) uses a plug-n-play style that allows quick prototyping, thereby facilitating the development of new techniques and the reproduction of previous work. The architecture separates the domain of the conversation from the agent's dialogue strategy, and as such can be easily extended to multiple domains. MACA provides tools to host dialogue agents on Amazon Mechanical Turk (mTurk) for data collection and allows processing of other sources of training data. The current version of the framework already incorporates several domains and existing dialogue strategies from the recent literature.
C1 [Hoai Phuoc Truong; Parthasarathi, Prasanna; Pineau, Joelle] McGill Univ, Sch Comp Sci, Montreal, PQ, Canada.
RP Truong, HP (corresponding author), McGill Univ, Sch Comp Sci, Montreal, PQ, Canada.
EM phuoc.truong2@mail.mcgill.ca; prasanna.p@cs.mcgill.ca;
   jpineau@cs.mcgill.ca
FU Samsung Advanced Institute of Technology (SAIT); Natural Sciences and
   Engineering Research Council of Canada (NSERC)
FX The authors gratefully acknowledge financial support for this work by
   the Samsung Advanced Institute of Technology (SAIT) and the Natural
   Sciences and Engineering Research Council of Canada (NSERC).
CR Abadi M., 2016, ARXIV PREPRINT ARXIV
   Allen JF, 2001, AI MAG, V22, P27
   Bird S., 2006, P COLING ACL INT PRE, DOI [10.3115/1225403.1225421, DOI 10.3115/1225403.1225421]
   Bohus D, 2003, RAVENCLAW DIALOG MAN
   Crook PA, 2016, NAACL HLT
   Eskenazi M, 2016, ARXIV160602562
   Gage P., 1994, C USERS J, V12, P23
   Gureckis TM, 2016, BEHAV RES METHODS, V48, P829, DOI 10.3758/s13428-015-0642-8
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Kim S, 2014, ASIAPAC SIGN INFO PR
   Le Q.V., 2014, INT C MACH LEARN, V32, P1188
   Lowe Ryan, 2015, P SIGDIAL 2015 C 16, P285, DOI DOI 10.18653/V1/W15-4640
   Mikolov T, 2013, EFFICIENT ESTIMATION, P1
   Png SW, 2011, INT CONF ACOUST SPEE, P2156
   Ritter A., 2011, P C EMP METH NAT LAN, P583
   Schatzmann J., 2005, P 6 SIGDIAL WORKSH D, P45
   Seide F, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P242
   Serban I. V., 2016, ARXIV160506069
   Serban IV, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3776
   Theano Development Team, 2016, ARXIV E PRINTS
   Young S, 2006, IEEE W SP LANG TECH, P8, DOI 10.1109/SLT.2006.326785
NR 21
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-945626-82-1
PY 2017
BP 93
EP 102
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Linguistics
GA BS2XU
UT WOS:000708086400014
DA 2022-08-02
ER

PT C
AU Jonell, P
AF Jonell, Patrik
GP Assoc Comp Machinery
TI Using Social and Physiological Signals for User Adaptation in
   Conversational Agents
SO AAMAS '19: PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON
   AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS
LA English
DT Proceedings Paper
CT 18th International Conference on Autonomous Agents and MultiAgent
   Systems (AAMAS)
CY MAY 13-17, 2019
CL Montreal, CANADA
SP Assoc Comp Machinery, Int Fdn Autonomous Agents & MultiAgent Syst, NSF, Artificial Intelligence Journal, Tourisme Montreal, J P Morgan, DeepMind, ACM SIGAI, Concordia Univ
DE Learning agent capabilities (agent models, communication, observation);
   Deep learning; Single and multi-agent planning and scheduling
AB In face-to-face communication, humans subconsciously emit social signals which are picked up and used by their interlocutors as feedback for how well the previously communicated messages have been received. The feedback is then used in order to adapt the way the coming messages are being produced and sent to the interlocutor, leading to the communication to become as efficient and enjoyable as possible. Currently however, it is rare to find conversational agents utilizing this feedback channel for altering how the multimodal output is produced during interactions with users, largely due to the complex nature of the problem. In most regards, humans have a significant advantage over conversational agents in interpreting and acting on social signals. Humans are however restricted to a limited set of sensors, "the five senses", which conversational agents are not. This makes it possible for conversational agents to use specialized sensors to pick up physiological signals, such as skin temperature, respiratory rate or pupil dilation, which carry valuable information about the user with respect to the conversation. This thesis work aims at developing methods for utilizing both social and physiological signals emitted by humans in order to adapt the output of the conversational agent, allowing for an increase in conversation quality. These methods will primarily be based on automatically learning adaptive behavior from examples of real human interactions using machine learning methods.
C1 [Jonell, Patrik] KTH Royal Inst Technol, Stockholm, Sweden.
RP Jonell, P (corresponding author), KTH Royal Inst Technol, Stockholm, Sweden.
EM pjjonell@kth.se
FU Swedish Foundation for Strategic Research Grant [RIT15-0107]
FX I would like to extend a special thanks to Jonas Beskow, Joakim
   Gustafson, and Andre Pereira. This project is supported by Swedish
   Foundation for Strategic Research Grant No.: RIT15-0107.
CR Abdelrahman Yomna, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3130898
   Ahmad MI, 2017, INT J HUM-COMPUT INT, V33, P943, DOI 10.1080/10447318.2017.1300750
   Alam MR, 2012, IEEE T SYST MAN CY C, V42, P1190, DOI 10.1109/TSMCC.2012.2189204
   [Anonymous], 2018, ARXIV180309017
   Bailenson JN, 2005, PSYCHOL SCI, V16, P814, DOI 10.1111/j.1467-9280.2005.01619.x
   Boccanfuso L, 2016, IEEE ROMAN, P718, DOI 10.1109/ROMAN.2016.7745198
   Broekens Joost, 2009, Gerontechnology, V8, P94
   Churamani N, 2018, IEEE IJCNN
   Greenwood D, 2017, LECT NOTES ARTIF INT, V10498, P160, DOI 10.1007/978-3-319-67401-8_18
   Heerink M, 2009, ADV ROBOTICS, V23, P1909, DOI [10.1163/01691860918609N12518783330289, 10.1163/016918609X12518783330289]
   Hemminghaus J, 2017, ACMIEEE INT CONF HUM, P332, DOI 10.1145/2909824.3020217
   Hirshfield L, 2016, MCPMD'18: PROCEEDINGS OF THE WORKSHOP ON MODELING COGNITIVE PROCESSES FROM MULTIMODAL DATA, DOI 10.1145/3279810.3279848
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Jeong H, 2017, STUD HEALTH TECHNOL, V245, P417, DOI 10.3233/978-1-61499-830-3-417
   Jonell  Patrik, 2017, ARXIV170901613
   Jones A, 2018, INT J SOC ROBOT, V10, P357, DOI 10.1007/s12369-017-0458-z
   Karras T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073658
   Khawaja MA, 2009, LECT NOTES COMPUT SC, V5726, P485, DOI 10.1007/978-3-642-03655-2_54
   Kistler F, 2012, J MULTIMODAL USER IN, V6, P39, DOI 10.1007/s12193-011-0087-z
   Leite I., 2011, P INT C US MOD AD PE, P135
   Lopes J, 2016, MCPMD'18: PROCEEDINGS OF THE WORKSHOP ON MODELING COGNITIVE PROCESSES FROM MULTIMODAL DATA, DOI 10.1145/3279810.3279851
   Lubold N, 2016, ACMIEEE INT CONF HUM, P255, DOI 10.1109/HRI.2016.7451760
   Martins GS, 2019, INT J SOC ROBOT, V11, P185, DOI 10.1007/s12369-018-0485-4
   Patrik Jonell, 2018, LREC
   Pham HX, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P361, DOI 10.1145/3242969.3243017
   Picard R, 2001, PATTERN ANAL MACHINE, V23, P10
   Sadoughi N, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6169, DOI 10.1109/ICASSP.2018.8461967
   Torrey C., 2006, 1st Annual Conference on Human-Robot Interaction, P126
   Verberne Frank M. F., 2013, Persuasive Technology. 8th International Conference, PERSUASIVE 2013. Proceedings, P234, DOI 10.1007/978-3-642-37157-8_28
   Verkruysse W, 2008, OPT EXPRESS, V16, P21434, DOI 10.1364/OE.16.021434
   Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007
   Weber K, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P154, DOI 10.1145/3242969.3242976
   Wolf Elena, 2018, P WORKSH MOD COGN PR, P6
   Zhang LS, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P428, DOI 10.1145/3242969.3242998
NR 34
TC 0
Z9 0
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6309-9
PY 2019
BP 2420
EP 2422
PG 3
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BN1GG
UT WOS:000474345000426
DA 2022-08-02
ER

PT C
AU van Straalen, B
   Heylen, D
   Theune, M
   Nijholt, A
AF van Straalen, Bart
   Heylen, Dirk
   Theune, Mariet
   Nijholt, Anton
BE Dignum, F
   Bradshaw, J
   Silverman, B
   VanDoesburg, W
TI Enhancing Embodied Conversational Agents with Social and Emotional
   Capabilities
SO AGENTS FOR GAMES AND SIMULATIONS: TRENDS IN TECHNIQUES, CONCEPTS AND
   DESIGN
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 1st International Workshop on Agents for Games and Simulation
CY MAY 11, 2009
CL Budapest, HUNGARY
DE Embodied Conversational Agents; Social Agents; Bad News Conversations;
   Tutoring; Empathy
ID INTENTION
AB In this paper we present our current work on an embodied conversational agent for training medical bad news conversations and discuss the inspiration gained from previous work of our own and others. Central in this research is the influence of emotional and social features on the selection and realization of conversational behavior.
C1 [van Straalen, Bart; Heylen, Dirk; Theune, Mariet; Nijholt, Anton] Univ Twente, NL-7500 AE Enschede, Netherlands.
RP van Straalen, B (corresponding author), Univ Twente, POB 217, NL-7500 AE Enschede, Netherlands.
EM straalenb@ewi.utwente.nl; d.k.j.heylen@ewi.utwente.nl;
   m.theune@ewi.utwente.nl; a.nijholt@ewi.utwente.nl
OI Nijholt, Anton/0000-0002-5669-9290; Theune, Mariet/0000-0002-8258-2029
CR [Anonymous], 1988, COGNITIVE STRUCTURE, DOI DOI 10.1017/CBO9780511571299
   Aylett RS, 2005, LECT NOTES ARTIF INT, V3661, P305
   Baile W F, 2000, Oncologist, V5, P302, DOI 10.1634/theoncologist.5-4-302
   Bickmore T.W, 2003, THESIS MIT CAMBRIDGE
   Bickmore T, 2009, LECT NOTES ARTIF INT, V5773, P6
   CARVER CS, 1989, J PERS SOC PSYCHOL, V56, P267, DOI 10.1037/0022-3514.56.2.267
   Cassell J., 1999, P SIGCHI C HUM FACT, P520, DOI DOI 10.1145/302979.303150
   COHEN PR, 1990, ARTIF INTELL, V42, P213, DOI 10.1016/0004-3702(90)90055-5
   Elliott C, 1992, THESIS NW U
   FOLKMAN S, 1980, J HEALTH SOC BEHAV, V21, P219, DOI 10.2307/2136617
   Friedrichsen Maria J, 2003, J Palliat Med, V6, P565, DOI 10.1089/109662103768253678
   Garg A, 1997, CAN MED ASSOC J, V156, P1159
   Georgeff M, 1999, LECT NOTES ARTIF INT, V1555, P1
   GRATCH J, 2001, AGENTS 01, P278
   Heylen D, 2005, APPL ARTIF INTELL, V19, P287, DOI 10.1080/08839510590910183
   HEYLEN D, 2009, P INT C AFF COMP INT
   HOSPERS M, 2003, APPL INTELLIGENT AGE, P143
   Johnson WL, 2004, LECT NOTES COMPUT SC, V3068, P254
   Kubler-Ross E., 1969, DEATH DYING
   MARSELLA S, 2000, AGENTS 2000, P301
   MARSELLA S, 2006, AGENT CONSTRUCTION E, P601
   Marsella SC, 1998, LECT NOTES COMPUT SC, V1452, P464
   Orlander JD, 2002, J GEN INTERN MED, V17, P825, DOI 10.1046/j.1525-1497.2002.10915.x
   POEL M, 2004, CYBERNET SYST, P663
   RAO AS, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P473
   RICKEL J, 1998, AGENTS 98 P 2 INT C, P332
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Varni JW, 1999, J PSYCHOSOC ONCOL, V16, P41, DOI 10.1300/J077v16n03_04
   Wooldridge M, 2000, REASONING RATIONAL A
NR 29
TC 6
Z9 6
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-11197-6
J9 LECT NOTES ARTIF INT
PY 2009
VL 5920
BP 95
EP 106
PG 12
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BPJ36
UT WOS:000278990700007
DA 2022-08-02
ER

PT S
AU Pelachaud, C
   Bilvi, M
AF Pelachaud, C
   Bilvi, M
BE Huget, MP
TI Computational model of believable conversational agents
SO COMMUNICATION IN MULTIAGENT SYSTEMS: AGENT COMMUNICATION LANGUAGES AND
   CONVERSATION POLICIES
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT Workshop on Agent Communication Languages and Conversation Policies
CY JUL 15, 2002
CL BOLOGNA, ITALY
ID FACIAL EXPRESSIONS
AB In this chapter we present the issues and problems involved in the creation of Embodied Conversational Agents (ECAs). These agents may have a humanoid aspect and may be embedded in a user interface with the capacity to interact with the user; that is they axe able to perceive and understand what the user is saying, but also to answer verbally and nonverbally to the user. ECAs axe expected to interact with users as in human-human conversation. They should smile, raise their brows, nod, and even gesticulate, not in a random manner but in co-occurrence with their speech. Results from research in human-human communication are applied to human-ECA communication, or ECA-ECA communication. The creation of such agents requires several steps ranging from the creation of the geometry of the body and facial models to the modeling of their mind, emotion, and personality, but also to the computation of the facial expression, body gesture, gaze that accompany their speech. In this chapter we will present our work toward the computation of nonverbal behaviors accompanying speech.
C1 Univ Paris 08, IUT Montreuil, LINC Paragraphe, F-93526 St Denis 02, France.
   Univ Roma La Sapienza, Dept Comp Sci & Syst, Rome, Italy.
RP Pelachaud, C (corresponding author), Univ Paris 08, IUT Montreuil, LINC Paragraphe, F-93526 St Denis 02, France.
EM c.pelachaud@iut.univ-paris8.fr; bilvi@dis.uniroma1.it
CR Andre E, 2000, EMBODIED CONVERSATIONAL AGENTS, P220
   Ball G, 2000, EMBODIED CONVERSATIONAL AGENTS, P189
   Bartlett MS, 1999, PSYCHOPHYSIOLOGY, V36, P253, DOI 10.1017/S0048577299971664
   BLACK AW, FESTIVAL
   Cassell J., 1994, P 21 ANN C COMP GRAP, P413, DOI DOI 10.1145/192161.192272
   CASSELL J, 1999, AAAI99 FALL S PSYCH
   CASSELL J, 2001, COMP GRAPH P ANN C S
   Cassell J., 1999, P SIGCHI C HUM FACT, P520, DOI DOI 10.1145/302979.303150
   DECAROLIS N, 2002, INT NAT LANG GEN C N
   Doenges PK, 1997, SIGNAL PROCESS-IMAGE, V9, P433, DOI 10.1016/S0923-5965(97)00007-6
   ELLIOTT C, 1992, THESIS NW U
   ESSA IA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P76, DOI 10.1109/CVPR.1994.323813
   Jenkins, 1971, PERCEPTION LANGUAGE, P150
   JOHNSON W, 2000, IN PRESS INT J ARTIF
   KENDON A, 1974, NONVERBAL COMMUNICAT
   Lester JC, 2000, EMBODIED CONVERSATIONAL AGENTS, P123
   LUNDEBERG M, 1999, P ESCA WORKSH AUD VI
   Marsella S. C., 2000, Proceedings of the Fourth International Conference on Autonomous Agents, P301, DOI 10.1145/336595.337507
   ORTONY A, IN PRESS EMOTIONS HU
   Ostermann J, 1998, COMP ANIM CONF PROC, P49, DOI 10.1109/CA.1998.681907
   PARADISO A, 2001, MULTIMODAL COMMUNICA
   Pelachaud C, 1996, COGNITIVE SCI, V20, P1
   PELACHAUD C, 2002, 1 INT JOINT C AUT AG
   Ploog D., 1979, HUMAN ETHOLOGY CLAIM, P169, DOI DOI 10.1007/978-1-4020-2783-33
   Poggi I, 2000, AI COMMUN, V13, P169
   Poggi I, 2000, EMBODIED CONVERSATIONAL AGENTS, P155
   Poggi I., 2002, GESTURES MEANING USE
   RIST T, 2002, ANIMATING EXPRESSIVE
   SCHEFLEN AE, 1964, PSYCHIATRY, P27
NR 29
TC 30
Z9 30
U1 0
U2 6
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-40385-X
J9 LECT NOTES ARTIF INT
PY 2003
VL 2650
BP 300
EP 317
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BX36M
UT WOS:000185072700017
DA 2022-08-02
ER

PT C
AU Morton, H
   McBreen, H
   Jack, M
AF Morton, H
   McBreen, H
   Jack, M
BE Ruttkay, Z
   Pelachaud, C
TI Experimental evaluation of the use of ECAs in ecommerce applications -
   Three studies
SO FROM BROWS TO TRUST: EVALUATING EMBODIED CONVERSATIONAL AGENTS
SE HUMAN-COMPUTER INTERACTION SERIES
LA English
DT Proceedings Paper
CT Workshop on Embodied Conversational Agents held at the 2002 AAMAS
   Conference
CY MAR, 2003
CL Montreal, CANADA
DE conversational agents; evaluation; eCommerce.
AB This chapter describes an experimental approach to the evaluation of embodied conversational agents (ECAs) within eCommerce contexts and exemplifies the approach with three case studies. Results are presented from three experiments into the usability of eCommerce applications employing 3D ECAs within the, domain of eRetail and eBanking.
   The findings described here confirm user preferences for applications in Which the agent acts as a conversational partner compared with A non-visual telephone application using speech recognition. Further, data in this chapter confirm the positive role of ECAs in interfaces and the benefits to that role of adding other modalities such as text output.
C1 Univ Edinburgh, Ctr Commun Interface Res, Edinburgh EH8 9YL, Midlothian, Scotland.
RP Morton, H (corresponding author), Univ Edinburgh, Ctr Commun Interface Res, Edinburgh EH8 9YL, Midlothian, Scotland.
CR [Anonymous], 1998, ISO9241
   BERSEN N, 1998, DESIGNING INTERACTIV
   Bickmore T., 2000, P SOC INT AG HUM LOO, P4
   Brown Penelope, 1987, POLITENESS SOME UNIV
   CASSELL J, 1994, PROCEEDINGS OF THE SIXTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P153
   Coolican H., 1994, RES METHODS STAT PSY, V2nd
   Costa P.T., 1995, NEO PERSONALITY INVE
   CRYSTAL D, 1997, DICT LINGUSITICS PHO
   Dix A, 1993, HUMAN COMPUTER INTER
   FOSTER JC, 1993, INTERACTIVE SPEECH T, P167
   Halliday M.A.K., 1970, NEW HORIZON LINGUIST, P140
   KNIGHT H, 1996, WORKING PAPER, V9604
   Likert RA, 1932, ARCH PSYCHOL, V140, P5
   LOVE S, 1992, P I AC SPEECH HEAR W, V14, P553
   LOVE S, 1997, THESIS U EDINBURGH
   MCBREEN H, 2001, P INT C AUT AG WORKS, P83
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Nass C, 2000, EMBODIED CONVERSATIONAL AGENTS, P374
   TRUDGILL P, 2000, SOCIOLINGUSTICS
   Van Mulken S., 1999, P 8 INT C HUM COMP I, P152
   [No title captured]
NR 21
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS
BN 1-4020-2729-X
J9 HUM COM INT
PY 2004
VL 7
BP 293
EP 321
PG 29
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BBP07
UT WOS:000226830500011
DA 2022-08-02
ER

PT J
AU Mancini, M
   Pelachaud, C
AF Mancini, Maurizio
   Pelachaud, Catherine
TI Generating distinctive behavior for Embodied Conversational Agents
SO JOURNAL ON MULTIMODAL USER INTERFACES
LA English
DT Article
DE ECA; Behavior; Multimodal; Distinctive; Expressive
ID MODEL; PERSONALITY; DIMENSIONS; EXPRESSION
AB In this paper we describe an algorithm for generating distinctive behavior for Embodied Conversational Agents. To this aim, we introduce the concepts of agent's general behavior tendency, named Baseline, and local behavior tendency, called in turn Dynamicline. Depending on the communicative intentions of the agent, the Baseline is modulated. The obtained behavior tendency corresponds to the Dynamicline which is then used to determine the nonverbal signals and their expressivity the agent will produce to communicate its intentions. We also propose a system to extract the movement expressivity of a human user standing in front of a camera. The extracted characteristics are then used to characterize the agent's Baseline. We end the paper by presenting an evaluation study of our model.
C1 [Mancini, Maurizio] Univ Genoa, InfoMus Lab, DIST, I-16145 Genoa, Italy.
   [Pelachaud, Catherine] TELECOM ParisTech, CNRS LTCI, F-75014 Paris, France.
RP Mancini, M (corresponding author), Univ Genoa, InfoMus Lab, DIST, Viale Causa 13, I-16145 Genoa, Italy.
EM maurizio.mancini@dist.unige.it; catherine.pelachaud@telecom-paristech.fr
RI Mancini, Maurizio/D-9776-2015
OI Mancini, Maurizio/0000-0002-9933-8583
CR ALLBECK J, 2003, LIFE LIKE CHARACTERS
   Allwood J, 2002, TEXT SPEECH LANG TEC, V19, P7
   Argyle M., 1988, BODILY COMMUNICATION
   Ball G, 2000, EMBODIED CONVERSATIONAL AGENTS, P189
   Byun M, 2002, P 2002 ACM SIGGRAPH, P71
   Caldognetto EM, 2000, 4 C GFS GRUPP FONCT
   CAMURRI A, 2004, LNAI, V2915
   Cassell J., 2000, EMBODIED CONVERSATIO
   CASSELL J, 2001, WORKSH REPR ANN EV N
   De Carolis B, 2004, COG TECH, P65
   DeCarolis B, 2000, WORKSH ACH HUM LIK B
   DiPaola S, 2004, ELECT IMAGING VISUAL
   Egges A, 2003, LECT NOTES ARTIF INT, V2773, P453
   EKMAN P, 1980, J PERS SOC PSYCHOL, V38, P270, DOI 10.1037/0022-3514.38.2.270
   GALLAHER PE, 1992, J PERS SOC PSYCHOL, V63, P133, DOI 10.1037/0022-3514.63.1.133
   HARTMANN B, 2005, 3 INT JOINT C AUT AG
   Kallmann M, 2005, LECT NOTES ARTIF INT, V3661, P253
   Kendon A., 2004, GESTURE VISIBLE ACTI
   Kipp M, 2007, LECT NOTES ARTIF INT, V4722, P15
   Kipp M, 2006, LECT NOTES ARTIF INT, V4133, P230
   Kopp S, 2002, COMP ANIM CONF PROC, P252, DOI 10.1109/CA.2002.1017547
   Laban R.V., 1971, MASTERY MOVEMENT
   Lebourque T, 1999, P COMP AN, V99
   Lester J, 1997, COSMO LIFE ANIMATED, P61
   Mancini M., 2008, P INT JOINT C AUT AG, P159
   Mancini M, 2007, LECT NOTES ARTIF INT, V4722, P112
   McNeill D., 1992, HAND MIND WHAT GESTU
   Neff M., 2004, AISB 2004 Convention: Motion, Emotion and Cognition. Symposium on Language, Speech and Gesture for Expressive Characters, P29
   Neff M., 2005, P 2005 ACM SIGGRAPH, P161, DOI DOI 10.1145/1073368.1073391
   Neff M., 2009, P ACM SIGGRAPH EUR S, P103
   Neff M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330516
   Niewiadomski R, 2007, LECT NOTES COMPUT SC, V4738, P12
   Pelachaud C., 2005, 13th Annual ACM International Conference on Multimedia, P683
   Poggi I, 2000, EMBODIED CONVERSATIONAL AGENTS, P155
   Poggi I, 2003, P 2 INT JOINT C AUT, P1098
   Poggi Isabella, 2007, MIND HANDS FACE BODY
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Ruttkay Z, 2008, ANIMATING EXPRESSIVE
   Scherer K. R., 1985, HDB DISCOURSE ANAL, V2, P199
   SCHRODER M, 2006, P LREC 06 WORKSH COR, P88
   Vilhjalmsson H, 2007, 7 INT C INT VIRT AG
   Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W
   WALLBOTT HG, 1986, J PERS SOC PSYCHOL, V51, P690, DOI 10.1037/0022-3514.51.4.690
   Web- ber Bonnie Lynn, 1993, SIMULATING HUMANS CO
   Zhao LW, 2005, GRAPH MODELS, V67, P1, DOI 10.1016/j.gmod.2004.08.002
NR 45
TC 6
Z9 6
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1783-7677
EI 1783-8738
J9 J MULTIMODAL USER IN
JI J. Multimodal User Interfaces
PD NOV
PY 2010
VL 3
IS 4
SI SI
BP 249
EP 261
DI 10.1007/s12193-010-0048-y
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA V25LV
UT WOS:000208480400001
OA Green Submitted
DA 2022-08-02
ER

PT C
AU Bruijnes, M
AF Bruijnes, Merijn
GP IEEE
TI Social and emotional turn taking for embodied conversational agents
SO PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY,
   SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON
   SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012)
LA English
DT Proceedings Paper
CT ASE/IEEE International Conference on Privacy, Security, Risk and Trust /
   ASE/IEEE International Conference on Social Computing (SocialCom/PASSAT)
CY SEP 03-05, 2012
CL Amsterdam, NETHERLANDS
SP IEEE, IEEE Comp Soc, Acad Sci & Engn
DE Social Interaction; Conversation; Emotion; Turn Taking; Virtual Humans;
   Human-Computer Interaction
AB In this doctoral consortium paper I describe the theme of my research; the model-based generation of consistent emotional turn taking behavior in virtual human conversations and the evaluation of this behavior. My goal is to investigate and generate convincing social behavior in embodied conversational agents.
C1 [Bruijnes, Merijn] Univ Twente, Human Media Interact, POB 217, NL-7500AE Enschede, Netherlands.
RP Bruijnes, M (corresponding author), Univ Twente, Human Media Interact, POB 217, NL-7500AE Enschede, Netherlands.
EM m.bruijnes@utwente.nl
FU Dutch national program COMMIT
FX This publication was supported by the Dutch national program COMMIT.
CR de Kok I, 2011, LECT NOTES COMPUT SC, V6456, P362, DOI 10.1007/978-3-642-18184-9_32
   Kronlid F, 2006, LECT NOTES COMPUT SC, V4149, P81
   Leary T., 1957, INTERPERSONAL DIAGNO
   op den Akker R., 2012, TECHNICAL REPORT
   Steunebrink B., 2008, P ICINCO08
NR 5
TC 2
Z9 2
U1 0
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-0-7695-4848-7; 978-1-4673-5638-1
PY 2012
BP 977
EP 978
DI 10.1109/SocialCom-PASSAT.2012.29
PG 2
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BG8UA
UT WOS:000392709700127
DA 2022-08-02
ER

PT C
AU Narynov, S
   Zhumanov, Z
   Gumar, A
   Khassanova, M
   Omarov, B
AF Narynov, Sergazy
   Zhumanov, Zhandos
   Gumar, Aidana
   Khassanova, Mariyam
   Omarov, Batyrkhan
GP IEEE
TI Chatbots and Conversational Agents in Mental Health: A Literature Review
SO 2021 21ST INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS
   (ICCAS 2021)
SE International Conference on Control Automation and Systems
LA English
DT Proceedings Paper
CT 21st International Conference on Control, Automation and Systems (ICCAS)
CY OCT 12-15, 2021
CL SOUTH KOREA
DE Chatbot; Conversational Agent; Natural Language Understanding; NLU;
   Machine Learning
AB In this study, we looked at chatbots, conversational agents, technologies for creating conversational agents, perspectives, and ethical issues in this direction. Also examples of therapy that are used by psychologists, psychotherapists, and the prospects of using them in a chatbot are explored in this review. As a result of the review, we considered the chatbot concepts for ourselves and identified technologies and methods for further development of the chatbot for mental health. We came to the conclusion to develop a chatbot for psychological help with the use of cognitive behavioral therapy. As a result of the study, we conclude that chatbots are really able to provide effective psychological assistance and reduce depression and anxiety in people.
C1 [Narynov, Sergazy; Zhumanov, Zhandos; Gumar, Aidana; Khassanova, Mariyam; Omarov, Batyrkhan] Alem Res, Alma Ata, Kazakhstan.
   [Zhumanov, Zhandos; Omarov, Batyrkhan] Al Farabi Kazakh Natl Univ, Alma Ata, Kazakhstan.
   [Gumar, Aidana] Asfendiyarov Kazakh Natl Med Univ, Dept Psychiat & Narcol, Alma Ata, Kazakhstan.
   [Omarov, Batyrkhan] Khoja Akhmet Yassawi Int Kazakh Turkish Univ, Turkistan, Kazakhstan.
RP Omarov, B (corresponding author), Alem Res, Alma Ata, Kazakhstan.; Omarov, B (corresponding author), Al Farabi Kazakh Natl Univ, Alma Ata, Kazakhstan.; Omarov, B (corresponding author), Khoja Akhmet Yassawi Int Kazakh Turkish Univ, Turkistan, Kazakhstan.
EM batyahan@gmail.com
FU Ministry of Education of the Republic of Kazakhstan [IRN AP09259140]
FX This work was supported by the grant "Development of an intellectual
   system prototype for online-psychological support that can diagnose and
   improve youth's psycho-emotional state" funded by the Ministry of
   Education of the Republic of Kazakhstan. Grant No. IRN AP09259140.
CR AbuShawar B, 2015, COMPUT SIST, V19, P625, DOI 10.13053/CyS-19-4-2326
   Allen MT, 2018, PEERJ, V6, DOI 10.7717/peerj.5330
   Amichai-Hamburger Y, 2014, COMPUT HUM BEHAV, V41, P288, DOI 10.1016/j.chb.2014.09.016
   Rivera RMB, 2015, HBK COMMUN MEDIA, P548
   Bauer AM, 2018, GEN HOSP PSYCHIAT, V51, P22, DOI 10.1016/j.genhosppsych.2017.11.010
   Bradesko L., 2012, P SLOV LANG TECHN SO, P34
   Curzi Y, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01659
   Donkin L, 2013, J MED INTERNET RES, V15, P67, DOI 10.2196/jmir.2771
   Fiske A, 2019, J MED INTERNET RES, V21, DOI 10.2196/13216
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Fleming T, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.9275
   Fredrickson BL, 2001, AM PSYCHOL, V56, P218, DOI 10.1037/0003-066X.56.3.218
   French RM, 2000, TRENDS COGN SCI, V4, P115, DOI 10.1016/S1364-6613(00)01453-4
   Indrayani L.M., 2020, JURNAL SOSIOTEKNOLOG, V18, P509
   Inkster B, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/12106
   Ireland D, 2015, STUD HEALTH TECHNOL, V214, P128, DOI 10.3233/978-1-61499-558-6-128
   Jang S, 2021, INT J MED INFORM, V150, DOI 10.1016/j.ijmedinf.2021.104440
   Kumar S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0190554
   Leff J, 2013, BRIT J PSYCHIAT, V202, P428, DOI 10.1192/bjp.bp.112.124883
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   Machado DD, 2016, BRIT J PSYCHOTHER, V32, P79, DOI 10.1111/bjp.12204
   MacLeed M., 2009, BEHAV COG PSYCHOTHER, V37
   Mesquita Anabela, 2019, New Knowledge in Information Systems and Technologies. Advances in Intelligent Systems and Computing (930), P25, DOI 10.1007/978-3-030-16181-1_3
   Miner AS, 2016, JAMA INTERN MED, V176, P619, DOI 10.1001/jamainternmed.2016.0400
   Murzamadieva M, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P530, DOI 10.1109/Confluence51648.2021.9377175
   Narynov S, 2020, DATA BRIEF, V29, DOI 10.1016/j.dib.2020.105195
   Oh J, 2020, INT J MED INFORM, V140, DOI 10.1016/j.ijmedinf.2020.104171
   Oh KJ, 2017, STUD HEALTH TECHNOL, V245, P1235, DOI 10.3233/978-1-61499-830-3-1235
   Omarov B, 2017, INT C CONTR AUTOMAT, P744, DOI 10.23919/ICCAS.2017.8204327
   Perini S., 2009, ROYAL AUSTR ZEALAND, V43
   Rathbone AL, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.8598
   Rhind C, 2014, EUR EAT DISORD REV, V22, P267, DOI 10.1002/erv.2298
   Taylor DA, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00507
   Turing AM., 1950, J MIND ASS, V59, P433, DOI [10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   Williams C, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0052735
   Yin JQ, 2021, J EDUC COMPUT RES, V59, P154, DOI 10.1177/0735633120952067
NR 36
TC 0
Z9 0
U1 2
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2093-7121
BN 978-89-93215-21-2
J9 INT C CONTR AUTOMAT
PY 2021
BP 353
EP 358
PG 6
WC Automation & Control Systems; Robotics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems; Robotics
GA BS6QE
UT WOS:000750950700044
DA 2022-08-02
ER

PT J
AU Cerekovic, A
   Pandzic, IS
AF Cerekovic, Aleksandra
   Pandzic, Igor S.
TI Multimodal behavior realization for embodied conversational agents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal behavior realization; Virtual characters; Character animation
   system
ID CHARACTERS
AB Applications with intelligent conversational virtual humans, called Embodied Conversational Agents (ECAs), seek to bring human-like abilities into machines and establish natural human-computer interaction. In this paper we discuss realization of ECA multimodal behaviors which include speech and nonverbal behaviors. We devise RealActor, an open-source, multi-platform animation system for real-time multimodal behavior realization for ECAs. The system employs a novel solution for synchronizing gestures and speech using neural networks. It also employs an adaptive face animation model based on Facial Action Coding System (FACS) to synthesize face expressions. Our aim is to provide a generic animation system which can help researchers create believable and expressive ECAs.
C1 [Cerekovic, Aleksandra; Pandzic, Igor S.] Univ Zagreb, Fac Elect Engn & Comp, Zagreb 41000, Croatia.
RP Cerekovic, A (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Zagreb 41000, Croatia.
EM aleksandra.cerekovic@fer.hr; igor.pandzic@fer.hr
CR Albrecht I, 2002, ADVANCES IN MODELLING, ANIMATION AND RENDERING, P283
   [Anonymous], 1996, BACKPROPAGATION ALGO
   Bianchi-Berthouze N, 2003, CONNECT SCI, V15, P259, DOI 10.1080/09540090310001658793
   Brkic M, 2008, LECT NOTES ARTIF INT, V5178, P73, DOI 10.1007/978-3-540-85565-1_10
   Cassell J, 2001, COMP GRAPH, P477
   Cassell J., 2000, EMBODIED CONVERSATIO
   CEREKOVIC A, 2010, P COST ACT 2102 INT
   CEREKOVIC A, 2009, INT C ACT MED TECHN
   Chovil N., 1991, RES LANG SOC INTERAC, V25, P163, DOI [10.1080/08351819109389361, DOI 10.1080/08351819109389361]
   Coulson M, 2004, J NONVERBAL BEHAV, V28, P117, DOI 10.1023/B:JONB.0000023655.25550.be
   DARIOUCH B, 2004, WORKSH HUM SANT SEPT
   Ekman P, 1979, BROWS EMOTIONAL CONV, P169
   Ekman P., 1973, DARWIN FACIAL EXPRES, P169, DOI DOI 10.1371/J0URNAL.P0NE.0014679
   Ekman Paul, 1978, FACIAL ACTION CODING
   *FAC GEN, FAC GEN 3D HUM FAC
   Forchheimer R, 2002, MPEG 4 FACIAL ANIMAT
   FOSTER ME, 2007, ENHANCING HUMAN COMP
   FRATARCANGELI M, 2009, P 10 INT C TEL CONTE
   Gebhard P, 2008, LECT NOTES COMPUT SC, V5208, P426
   Georganas ND, 1996, IEEE J SEL AREA COMM, V14, P1, DOI 10.1109/JSAC.1996.481690
   GOSSELIN P, 1995, CANADIAN J EXPT PSYC, P313
   Hartmann B, 2002, COMP ANIM CONF PROC, P111, DOI 10.1109/CA.2002.1017516
   Heck R, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P129
   Heloir A, 2009, LECT NOTES ARTIF INT, V5773, P393
   *HORDE3D, NEXT GEN GRAPH ENG
   Ingemars N., 2007, FEATURE BASED FACE T
   Johnston M, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P281
   Johnston M., 2000, P 18 C COMP LING SAA, P369
   Kleinsmith A, 2007, LECT NOTES COMPUT SC, V4738, P48, DOI 10.1007/978-3-540-74889-2_5
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   Kopp S, 2006, LECT NOTES ARTIF INT, V4133, P205
   KOVAR L, 2004, THESIS U WISCONSIN M
   Lee J, 2006, LECT NOTES ARTIF INT, V4133, P243
   McNeill D., 1992, HAND MIND WHAT GESTU
   *MICR, MICR SPEECH API
   Neff M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330516
   OVIATT S, 1997, P C HUM FACT COMP SY, P00415
   PANDZIC IS, 2003, P 2 INT C MOB UB MUL, P49
   PEJSA T, 2009, P 10 INT C TEL CONTE
   PELACHAUD C, 2009, COMMUNICATI IN PRESS
   SCHROEDER M, 2007, P BLIZZ CHALL 2007
   SMID K, 2006, P 6 INT C INT VIRT A, P256
   SPIERLING U, 2005, ACM SIGGRAPH 2005 ED
   SPIERLING U, 2005, DIGRA 2005 S FRAS U
   Stone M, 2004, ACM T GRAPHIC, V23, P506, DOI 10.1145/1015706.1015753
   Taylor P., 1998, 3 ESCA WORKSH SPEECH, P147
   THIEBAUX M, 2008, P AUT AG MULT SYST A
   VANDEEMTER K, 2008, ARTICIAL INTELLIGENC, P1219
   Vilhjalmsson H, 2007, LECT NOTES ARTIF INT, V4722, P99
   Vinayagamoorthy V., 2006, EUROGRAPHICS STATE A
   Wehrle T, 2000, J PERS SOC PSYCHOL, V78, P105, DOI 10.1037/0022-3514.78.1.105
   ZORIC G, 2005, P INT C MULT EXP ICM
   Zoric G, 2009, LECT NOTES ARTIF INT, V5398, P112
   [No title captured]
   BML SPECIFICATION
NR 55
TC 7
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 1
SI SI
BP 143
EP 164
DI 10.1007/s11042-010-0530-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 770BD
UT WOS:000291061100008
DA 2022-08-02
ER

PT C
AU Sindhgatta, R
   Barros, A
   Nili, A
AF Sindhgatta, Renuka
   Barros, Alistair
   Nili, Alireza
BE Panetto, H
   Debruyne, C
   Hepp, M
   Lewis, D
   Ardagna, CA
   Meersman, R
TI Modeling Conversational Agents for Service Systems
SO ON THE MOVE TO MEANINGFUL INTERNET SYSTEMS: OTM 2019 CONFERENCES
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 27th International Conference on Cooperative Information Systems,
   (CoopIS) / International Conference on Ontologies, Databases, and
   Applications of Semantics (ODBASE) / Conference on Cloud and Trusted
   Computing (C and TC)
CY OCT 21-25, 2019
CL Rhodes, GREECE
DE Conversational agent; Services system; Unified service description
   language
AB Service providers are increasingly exploring the use of conversational agents (CA) or dialogue based systems to support end customers, as a CA promises natural method for users to interact and a convenient channel for customer service. Commercial CAs, excel in addressing specific tasks or functions such as searching for restaurants, providing location directions, or scheduling meetings, with small variations in the user request. Designing a CA for a more complex service system, requires sufficient knowledge of its services such as the service capabilities, their constraints, and effects, in addition to understanding user utterances. The design of a CA is typically an independent activity and its linkages to the service system it supports are left to the designers. In this paper, we study existing work with respect to text-based CAs and identify the conceptual elements of a CA. Further, a linkage between the model elements of a CA and service model of the service system it supports is established and presented. We show that interesting insights can be derived from the linkages, that can be useful to CA designers.
C1 [Sindhgatta, Renuka; Barros, Alistair; Nili, Alireza] Queensland Univ Technol, Brisbane, Qld, Australia.
RP Sindhgatta, R (corresponding author), Queensland Univ Technol, Brisbane, Qld, Australia.
EM renuka.sr@qut.edu.au; alistair.barros@qut.edu.au; a.nili@qut.edu.au
OI Sindhgatta, Renuka/0000-0001-7533-533X; Barros,
   Alistair/0000-0001-8980-6841
CR Afzal S., 2019, P 2019 NAACL HLT
   Barros Alistair, 2012, HDB SERVICE DESCRIPT, P187
   Bordes A., 2017, 5 ICLR FRANC 24 26 A
   Budzianowski P., 2018, P EMNLP 2018, P5016, DOI 10.18653/v1/d18-1547
   Cardoso J, 2015, LECT NOTES BUS INF P, V201, P50, DOI 10.1007/978-3-319-14980-6_5
   Daniel G, 2019, LECT NOTES COMPUT SC, V11483, P177, DOI 10.1007/978-3-030-21290-2_12
   Dodge J., 2016, 4 ICLR SAN JUAN 2 4
   Gasic Milica, 2013, P 14 ANN M SPEC INT, P214
   Gnewuch U., 2017, P ICIS TRANSF SOC DI
   GRICE HP, 1975, SYNTAX SEMANTICS, V3, DOI DOI 10.1111/J.1365-2664.2006.01229.X
   Jurafsky D., 2000, SPEECH LANGUAGE PROC
   Maglio PP, 2009, INF SYST E-BUS MANAG, V7, P395, DOI 10.1007/s10257-008-0105-1
   Mesnil G, 2015, IEEE-ACM T AUDIO SPE, V23, P530, DOI 10.1109/TASLP.2014.2383614
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Nili A, 2019, MIT SLOAN MANAGE REV, V60, P84
   Paliwal AV, 2012, IEEE T SERV COMPUT, V5, P260, DOI 10.1109/TSC.2011.19
   Yang XS, 2017, INT CONF ACOUST SPEE, P5690, DOI 10.1109/ICASSP.2017.7953246
NR 17
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-33246-4; 978-3-030-33245-7
J9 LECT NOTES COMPUT SC
PY 2019
VL 11877
BP 552
EP 560
DI 10.1007/978-3-030-33246-4_34
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ1WT
UT WOS:000577978000034
DA 2022-08-02
ER

PT J
AU Beinema, T
   Op den Akker, H
   Hurmuz, M
   Jansen-Kosterink, S
   Hermens, H
AF Beinema, Tessa
   Op den Akker, Harm
   Hurmuz, Marian
   Jansen-Kosterink, Stephanie
   Hermens, Hermie
TI Automatic topic selection for long-term interaction with embodied
   conversational agents in health coaching: A micro-randomized trial
SO INTERNET INTERVENTIONS-THE APPLICATION OF INFORMATION TECHNOLOGY IN
   MENTAL AND BEHAVIOURAL HEALTH
LA English
DT Article
DE Embodied conversational agents; Initiative; Tailoring; Topic selection;
   Dialogues; Health coaching; micro-randomized trial
ID PHYSICAL-ACTIVITY; BEHAVIOR-CHANGE; ENGAGEMENT; DESIGN; INTERVENTIONS;
   TELEMEDICINE; KNOWLEDGE; FRAMEWORK; SYSTEMS
AB Introduction: Embodied Conversational Agents (ECAs) can be included in health coaching applications as virtual coaches. The engagement with these virtual coaches could be improved by presenting users with tailored coaching dialogues. In this article, we investigate if the suggestion of an automatically tailored topic by an ECA leads to higher engagement by the user and thus longer sessions of interaction.
   Methods: A Micro-Randomized Trial (MRT) was conducted in which two types of interaction with an ECA were compared: (a) the coach suggests a relevant topic to discuss, and (b) the coach asks the user to select a topic from a set of options. Every time the user would interact with the ECA, one of those conditions would be randomly selected. Participants interacted in their daily life with the ECA that was part of a multi-agent health coaching application for 4-8 weeks.
   Results: In two rounds, 82 participants interacted with the micro-randomized coach a total of 1011 times. Interactions in which the coach took the initiative were found to be of equal length as interactions in which the user was allowed to choose the topic, and the acceptance of topic suggestions was high (71.1% overall, 75.8% for coaching topics).
   Conclusion: Tailoring coaching conversations with ECAs by letting the coach automatically suggest a topic that is tailored to the user is perceived as a natural variation in the flow of interaction. Future research could focus on improving the novel coaching engine component that supports the topic selection process for these suggestions or on investigating how the amount of initiative and coaching approach by the ECA could be tailored.
C1 [Beinema, Tessa; Op den Akker, Harm; Hurmuz, Marian; Jansen-Kosterink, Stephanie; Hermens, Hermie] Roessingh Res & Dev, eHlth Grp, Enschede, Netherlands.
   [Beinema, Tessa; Op den Akker, Harm; Hurmuz, Marian; Jansen-Kosterink, Stephanie; Hermens, Hermie] Univ Twente, Biomed Signals & Syst Grp, Enschede, Netherlands.
   [Op den Akker, Harm] Innovat Sprint, Brussels, Belgium.
RP Beinema, T (corresponding author), Univ Twente, Biomed Signals & Syst Grp, Enschede, Netherlands.
EM t.c.beinema@utwente.nl
RI Beinema, Tessa/AAH-8905-2021
OI Beinema, Tessa/0000-0003-3513-0641
FU European Union's Horizon 2020 research and innovation programme [769553]
FX This work was supported by the European Union's Horizon 2020 research
   and innovation programme under Grant Agreement #769553 (Council of
   Coaches).
CR Abdullah A, 2018, J EPIDEMIOL GLOB HEA, V8, P225, DOI 10.2991/j.jegh.2018.08.104
   Agarwal R, 1998, INFORM SYST RES, V9, P204, DOI 10.1287/isre.9.2.204
   Andersson Gerhard, 2009, Cognitive Behaviour Therapy, V38, P55, DOI 10.1080/16506070902916400
   Andre E, 2001, KNOWL-BASED SYST, V14, P3, DOI 10.1016/S0950-7051(00)00096-4
   Andre E, 2010, SPEECH TECHNOLOGY: THEORY AND APPLICATIONS, P123, DOI 10.1007/978-0-387-73819-2_8
   [Anonymous], P HUM ASS C AFF COMP, P61, DOI [10.1109/ACII.2013.17, DOI 10.1109/ACII.2013.17]
   Beinema op den Akker H., 2018, ICA HOGECA 18, P35
   Beinema T., OPEN RES EUROPE, V2, P115, DOI [10.12688/openreseurope.14279.1, DOI 10.12688/OPENRESEUROPE.14279.1]
   Beinema T, 2021, COMPUT HUM BEHAV, V121, DOI 10.1016/j.chb.2021.106787
   Benitez-Guijarro A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010108
   Bickmore T, 2007, LECT NOTES COMPUT SC, V4744, P1
   Bickmore T, 2006, J BIOMED INFORM, V39, P556, DOI 10.1016/j.jbi.2005.12.004
   Bickmore T, 2018, HUM-COMPUT INT-SPRIN, P33, DOI 10.1007/978-3-319-95579-7_3
   Bickmore T, 2010, APPL ARTIF INTELL, V24, P648, DOI 10.1080/08839514.2010.492259
   Bickmore TW, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5239
   Bouton ME, 2014, PREV MED, V68, P29, DOI 10.1016/j.ypmed.2014.06.010
   Brinkman W.P., 2016, GREATS 16, P1
   Buimer Hendrik P, 2017, JMIR Rehabil Assist Technol, V4, pe12, DOI 10.2196/rehab.6294
   Chew LD, 2004, FAM MED, V36, P588
   Cole-Lewis Heather, 2019, JMIR Form Res, V3, pe14052, DOI 10.2196/14052
   Couper MP, 2010, J MED INTERNET RES, V12, P41, DOI 10.2196/jmir.1430
   Crutzen R, 2011, J MED INTERNET RES, V13, DOI 10.2196/jmir.1837
   Das KSJ, 2019, ICT4AWE 2019: PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES FOR AGEING WELL AND E-HEALTH, P297, DOI 10.5220/0007750602970304
   de Vries RAJ, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P297, DOI 10.1145/2858036.2858229
   Ekeland AG, 2012, INT J MED INFORM, V81, P1, DOI 10.1016/j.ijmedinf.2011.10.009
   Ekeland AG, 2010, INT J MED INFORM, V79, P736, DOI 10.1016/j.ijmedinf.2010.08.006
   Fadhil A, 2019, METHOD INFORM MED, V58, P9, DOI 10.1055/s-0039-1688757
   Gardiner PM, 2017, PATIENT EDUC COUNS, V100, P1720, DOI 10.1016/j.pec.2017.04.015
   Trinh H, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P9, DOI 10.1145/3267851.3267909
   Hamari J, 2016, COMPUT HUM BEHAV, V54, P170, DOI 10.1016/j.chb.2015.07.045
   Hardiker NR, 2011, INT J MED INFORM, V80, P1, DOI 10.1016/j.ijmedinf.2010.10.017
   Hayashi Y., 2012, APCHI 12, P443
   Huber M, 2016, BMJ OPEN, V6, DOI 10.1136/bmjopen-2015-010091
   Hurmuz MZM, 2020, JMIR RES PROTOC, V9, DOI 10.2196/16641
   International Health Conference, 2002, Bull World Health Organ, V80, P983
   Joseph-Williams N, 2014, PATIENT EDUC COUNS, V94, P291, DOI 10.1016/j.pec.2013.10.031
   Kairy D, 2009, DISABIL REHABIL, V31, P427, DOI 10.1080/09638280802062553
   Kamphorst BA, 2017, PERS UBIQUIT COMPUT, V21, P625, DOI 10.1007/s00779-017-1020-6
   Kantharaju RB, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P203, DOI 10.1145/3308532.3329450
   Kantharaju RB, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P255, DOI 10.1145/3267851.3267890
   King AC, 2017, CONTEMP CLIN TRIALS, V61, P115, DOI 10.1016/j.cct.2017.07.020
   Klaassen R, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020402
   Klasnja P, 2015, HEALTH PSYCHOL, V34, P1220, DOI 10.1037/hea0000305
   Kohl LF, 2013, J MED INTERNET RES, V15, P71, DOI 10.2196/jmir.2665
   Kramer NC, 2010, LECT NOTES ARTIF INT, V6356, P468, DOI 10.1007/978-3-642-15892-6_50
   Kramer LL, 2021, JMIR RES PROTOC, V10, DOI 10.2196/22186
   Kramer LL, 2020, J MED INTERNET RES, V22, DOI 10.2196/14058
   Krebs P, 2010, PREV MED, V51, P214, DOI 10.1016/j.ypmed.2010.06.004
   LaPlante C, 2011, TELEMED E-HEALTH, V17, P509, DOI 10.1089/tmj.2011.0013
   Lee MK, 2010, 2010 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P31
   Ma TT, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312853
   Nakamura J., 2014, HDB POSITIVE PSYCHOL, P239, DOI DOI 10.1007/978-94-017-9088-8_16
   Nijland N, 2011, GROUNDING EHEALTH TO, DOI [10.3990/ 1.9789036531337, DOI 10.3990/1.9789036531337]
   O'Brien HL, 2008, J AM SOC INF SCI TEC, V59, P938, DOI 10.1002/asi.20801
   Olafsson S, 2019, INT CONF PER COMP, P31, DOI 10.1145/3329189.3329202
   Op den Akker H, 2018, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES FOR AGEING WELL AND E-HEALTH (ICT4AWE), P219, DOI 10.5220/0006787702190226
   op den Akker H, 2014, USER MODEL USER-ADAP, V24, P351, DOI 10.1007/s11257-014-9146-y
   Payne Jeunese, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P106, DOI 10.1007/978-3-642-40415-3_9
   Perski O, 2017, TRANSL BEHAV MED, V7, DOI 10.1007/s13142-016-0453-1
   Pezzullo LG, 2017, LECT NOTES ARTIF INT, V10331, P299, DOI 10.1007/978-3-319-61425-0_25
   Ring L, 2013, INT CONF AFFECT, P61, DOI 10.1109/ACII.2013.17
   Ruttkay Z, 2004, HUM-COMPUT INT-SPRIN, V7, P27
   Ryan K, 2019, DIGIT HEALTH, V5, DOI 10.1177/2055207619826685
   Sebastian J, 2017, COMPUT HUM BEHAV, V73, P479, DOI 10.1016/j.chb.2017.03.071
   van Velsen L, 2020, JMIR RES PROTOC, V9, DOI 10.2196/19344
   van Velsen L, 2019, J MED INTERNET RES, V21, DOI 10.2196/11759
   Wangberg Silje C, 2008, Patient Prefer Adherence, V2, P57
   Watson A, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.1629
   Xiao J, 2002, P AAMAS02 WORKSH EMB
   Yardley L, 2016, AM J PREV MED, V51, P833, DOI 10.1016/j.amepre.2016.06.015
   Zhang Z, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P113, DOI 10.1145/3267851.3267883
NR 71
TC 1
Z9 1
U1 3
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
EI 2214-7829
J9 INTERNET INTERV
JI Internet Interv.
PD MAR
PY 2022
VL 27
AR 100502
DI 10.1016/j.invent.2022.100502
PG 12
WC Psychology, Clinical; Health Care Sciences & Services; Medical
   Informatics; Psychiatry
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychology; Health Care Sciences & Services; Medical Informatics;
   Psychiatry
GA ZW0AF
UT WOS:000770883600005
PM 35198412
OA Green Published, gold
DA 2022-08-02
ER

PT C
AU Mensio, M
   Rizzo, G
   Morisio, M
AF Mensio, Martino
   Rizzo, Giuseppe
   Morisio, Maurizio
GP ACM
TI The Rise of Emotion-aware Conversational Agents: Threats in Digital
   Emotions
SO COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018)
LA English
DT Proceedings Paper
CT 27th World Wide Web (WWW) Conference
CY APR 23-27, 2018
CL Lyon, FRANCE
SP Assoc Comp Machinery, Int World Wide Web Conf Steering Comm, Univ Lyon, Digital League, Inria, Amazon, Baidu, Google, IDEXLYON, NAVER LINE, Yahoo! Res, Webcastor, Caisse Depots, Facebook, Inst Carnot, Telecom Soc Numerique, Mozilla, Spotify, MEDEF Lyon Rhone, MEDEF Auvergne Rhone Alpes, EFFEKTIV, Charli Charger
DE Conversational Agents; Affective Computing; Social Implications;
   Psychological Implications
ID PERCEPTION
AB A future where the conversation with machines can potentially involve mutual emotions between the parties may be not so far in time. Inspired by the episode of Black Mirror "Be Right Back" and Replika, a futuristic app that promises to be "your best friend", in this work we are considering the positive and negative points of including an automated learning conversational agent inside the personal world of feelings and emotions. These systems can impact both single individuals and society, worsening an already critical situation. Our conclusion is that a regulation on the artificial emotional content should be considered before actually going beyond some one-way-only limits.
C1 [Mensio, Martino; Morisio, Maurizio] Politecn Torino, Turin, Italy.
   [Rizzo, Giuseppe] Ist Super Mario Boella, Turin, Italy.
RP Mensio, M (corresponding author), Politecn Torino, Turin, Italy.
EM martino.mensio@studenti.polito.it; giuseppe.rizzo@ismb.it;
   maurizio.morisio@polito.it
OI Mensio, Martino/0000-0002-9875-6396
CR Anderson, 2011, MACHINE ETHICS, P254, DOI [10.1017/CBO9780511978036.020, DOI 10.1017/CBO9780511978036.020]
   [Anonymous], 2015, P 24 ACM INT C INF K
   [Anonymous], 2013, HER
   Binali Haji, 2010, 2010 4th IEEE International Conference on Digital Ecosystems and Technologies (DEST 2010), P172, DOI 10.1109/DEST.2010.5610650
   Blake R, 2007, ANNU REV PSYCHOL, V58, P47, DOI 10.1146/annurev.psych.57.102904.190152
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Doi Takeo, 1973, ANATOMY DEPENDENCE, V101
   EKMAN P, 1993, AM PSYCHOL, V48, P384, DOI 10.1037/0003-066X.48.4.384
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Furlong A, 2008, SOCIOL REV, V56, P309, DOI 10.1111/j.1467-954X.2008.00790.x
   GOLDBERG LR, 1993, AM PSYCHOL, V48, P26, DOI 10.1037/0003-066X.48.1.26
   Harman JP, 2005, CYBERPSYCHOL BEHAV, V8, P1, DOI 10.1089/cpb.2005.8.1
   Hibbard B., 2014, ARXIV PREPRINT ARXIV
   Konrath SH, 2011, PERS SOC PSYCHOL REV, V15, P180, DOI 10.1177/1088868310377395
   Le Q, 2015, ARXIV150605869
   Li JW, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P994
   Lisetti C.L., 1998, AFFECTIVE COMPUTING
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   Martinez A, 2012, J MACH LEARN RES, V13, P1589
   Minsky Marvin, 2006, EMOTION MACHINE, P56
   Moor James H., 2009, PHILOS NOW, V72, P12
   Oord A., 2016, ARXIV160903499, V125
   Pariser E., 2011, FILTER BUBBLE NEW PE
   Pfister Wally, 2014, TRASCENDENCE
   Serban IV, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3776
   Turk Oytun, 2008, 9 ANN C INT SPEECH C
   Xing C, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3351
   Zhou Hao, 2017, ARXIV PREPRINT ARXIV
   Zielenziger M., 2007, SHUTTING OUT SUN JAP
NR 29
TC 5
Z9 5
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5640-4
PY 2018
BP 1541
EP 1544
DI 10.1145/3184558.3191607
PG 4
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS1KN
UT WOS:000692102800282
OA Bronze
DA 2022-08-02
ER

PT S
AU Bickmore, T
   Trinh, H
   Asadi, R
   Olafsson, S
AF Bickmore, Timothy
   Trinh, Ha
   Asadi, Reza
   Olafsson, Stefan
BE Moore, RJ
   Szymanski, MH
   Arar, R
   Ren, GJ
TI Safety First: Conversational Agents for Health Care
SO STUDIES IN CONVERSATIONAL UX DESIGN
SE Human-Computer Interaction Series
LA English
DT Article; Book Chapter
ID INTERACTIVE VOICE RESPONSE; SPEECH RECOGNITION; NEURAL-NETWORKS;
   COMPUTER; SYSTEMS; ALLIANCE; WORDS; TRIAL
AB Automated dialogue systems represent a promising approach for health care promotion, thanks to their ability to emulate the experience of face-to-face interactions between health providers and patients and the growing ubiquity of home-based and mobile conversational assistants such as Apple's Siri and Amazon'sAlexa. However, patient-facing conversational interfaces also have the potential to cause significant harm if they are not properly designed. In this chapter, we first review work on patient-facing conversational interfaces in healthcare, focusing on systems that use embodied conversational agents as their user interface modality. We then systematically review the kinds of errors that can occur if these interfaces are not properly constrained and the kinds of safety issues these can cause. We close by outlining design recommendations for avoiding these issues.
C1 [Bickmore, Timothy; Trinh, Ha; Asadi, Reza; Olafsson, Stefan] Northeastern Univ, Coll Comp & Informat Sci, Boston, MA 02115 USA.
RP Bickmore, T (corresponding author), Northeastern Univ, Coll Comp & Informat Sci, Boston, MA 02115 USA.
EM bickmore@ccs.neu.edu; hatrinh@ccs.neu.edu; asadi.r@husky.neu.edu;
   stefanolafs@ccs.neu.edu
CR [Anonymous], ISMPS LIST CONF DRUG
   Bandura A, 1998, PSYCHOL HEALTH, V13, P623, DOI 10.1080/08870449808407422
   Battaglino C, 2015, INCREASING ENGAGEMEN
   Bazzi I, 2002, MODELLING OUT OF VOC
   Bensing J, 2000, PATIENT EDUC COUNS, V39, P17, DOI 10.1016/S0738-3991(99)00087-7
   Benzeghiba M, 2007, SPEECH COMMUN, V49, P763, DOI 10.1016/j.specom.2007.02.006
   Bickmore T, 2009, P ACMSIGCHI C HUM FA
   Bickmore T, 2006, J BIOMED INFORM, V39, P556, DOI 10.1016/j.jbi.2005.12.004
   Bickmore T, 2009, LECT NOTES ARTIF INT, V5773, P6
   Bickmore TW, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5239
   Bickmore TW, 2013, J AM GERIATR SOC, V61, P1676, DOI 10.1111/jgs.12449
   Bickmore TW, 2010, J HEALTH COMMUN, V15, P197, DOI 10.1080/10810730.2010.499991
   Bickmore TW, 2010, INTERACT COMPUT, V22, P276, DOI 10.1016/j.intcom.2010.02.001
   Bickmore TW, 2009, 8 INT C AUT AG MULT
   Bohlin Peter, 1999, SURVEY EXISTING INTE
   Bohus Dan, 2005, 6 SIGDIAL WORKSH DIS
   Caines A, 2014, 1 JOINT WORKSH STAT, P74
   Cassell J, 1999, APPL ARTIF INTELL, V13, P519, DOI 10.1080/088395199117360
   Chen Xie, 2015, 16 ANN C INT SPEECH
   Clark H.H, 1996, USING LANGUAGE
   Corkrey R, 2002, BEHAV RES METH INS C, V34, P342, DOI 10.3758/BF03195462
   Davidoff F, 1997, ANN INTERN MED, V127, P483, DOI 10.7326/0003-4819-127-6-199709150-00011
   Delichatsios HK, 2001, AM J HEALTH PROMOT, V15, P215, DOI 10.4278/0890-1171-15.4.215
   DeVault David, 2009, P SIGDIAL LOND UK, P11
   Duranti A, 1992, RETHINKING CONTEXT L
   Farzanfar R, 2003, ANN BEH MED ANN M S, pS161
   Fisher W.M., 1986, P DARPA WORKSH SPEEC, P93
   Friedman RH, 1998, J MED SYST, V22, P95, DOI 10.1023/A:1022695119046
   Fujii Y, 2012, IEICE T INF SYST, VE95D, P1101, DOI 10.1587/transinf.E95.D.1101
   Godfrey JJ, 1992, IEEE INT C AC SPEECH
   Goldwater S, 2010, SPEECH COMMUN, V52, P181, DOI 10.1016/j.specom.2009.10.001
   Goss FR, 2016, INT J MED INFORM, V93, P70, DOI 10.1016/j.ijmedinf.2016.05.005
   Grover AS, 2009, 2009 INT C INF COMMU
   Gumperz J., 1977, LINGUISTICS ANTHR, P191
   Hawkins RP, 2008, HEALTH EDUC RES, V23, P454, DOI 10.1093/her/cyn004
   HAYESROTH B, 2004, ANN REV CYBERTHERAPY, V2, P85
   Henderson M, 2012, 16 WORKSH SEM PRAGM
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hirschberg J, 2004, SPEECH COMMUN, V43, P155, DOI 10.1016/j.specom.2004.01.006
   HIRST G, 1994, SPEECH COMMUN, V15, P213, DOI 10.1016/0167-6393(94)90073-6
   Hodgson T, 2016, J AM MED INFORM ASSN, V23, pE169, DOI 10.1093/jamia/ocv152
   Horvath AO, 2011, PSYCHOTHERAPY, V48, P9, DOI 10.1037/a0022186
   Huggins-Daines D, 2006, EEE INT C AC SPEECH
   Juang B.H., 2004, AUTOMATIC SPEECH REC
   Juang B.-H., 2005, AUTOMATIC SPEECH REC
   Kennedy CM, 2012, J MED INTERNET RES, V14, P116, DOI 10.2196/jmir.1893
   Kimani K, 2016, INT C INT VIRT AG IV
   King AC, 2013, J HEALTH COMMUN, V18, P1449, DOI 10.1080/10810730.2013.798374
   Kirsch I, 1993, ADULT LITERACY AM 1
   Lee H, 2017, NAT LANG ENG, V23, P733, DOI 10.1017/S1351324917000109
   Levinson S.C., 1983, PRAGMATICS
   Li JY, 2014, IEEE-ACM T AUDIO SPE, V22, P745, DOI 10.1109/TASLP.2014.2304637
   LI KH, 2014, 2014 INT C INT VIRT
   Liu XH, 2016, INTERSPEECH, P1146, DOI 10.21437/Interspeech.2016-1172
   Mangu L, 2000, COMPUT SPEECH LANG, V14, P373, DOI 10.1006/csla.2000.0152
   Martin DJ, 2000, J CONSULT CLIN PSYCH, V68, P438, DOI 10.1037//0022-006X.68.3.438
   Medicine Io, 2000, ERR IS HUM BUILD SAF
   Mesnil G, 2015, IEEE-ACM T AUDIO SPE, V23, P530, DOI 10.1109/TASLP.2014.2383614
   Miner AS, 2016, JAMA INTERN MED, V176, P619, DOI 10.1001/jamainternmed.2016.0400
   Miner AS, 2017, TALKING MACHINES PER
   Norman D., 1983, MENTAL MODELS, V7, P7
   Oliver I, 2012, IEEE IC COMP COM NET
   Paek T, 2007, WORKSHOP BRIDGING GA
   Paetzel M, 2015, SIGDIAL C
   Piette JD, 2000, AM J MANAG CARE, V6, P817
   Pinto BM, 2002, AM J PREV MED, V23, P113, DOI 10.1016/S0749-3797(02)00441-5
   Pollack ME, 2003, ROBOT AUTON SYST, V44, P273, DOI 10.1016/S0921-8890(03)00077-0
   Povey D., 2011, IEEE 2011 WORKSH AUT
   Rabiner L., 1993, FUNDAMENTALS SPEECH
   Radziwill NM, 2017, ARXIVPREPRINTARXIV17
   Ramelson HZ, 1999, PATIENT EDUC COUNS, V36, P131, DOI 10.1016/S0738-3991(98)00130-X
   Rich C, 2004, IEEE INT C DISTR COM
   Ryu S, 2014, INT CONF BIG DATA, P165, DOI 10.1109/BIGCOMP.2014.6741429
   Saon G, 2017, ARXIVPREPRINTARXIV17
   Sarikaya R, 2017, IEEE SIGNAL PROC MAG, V34, P67, DOI 10.1109/MSP.2016.2617341
   SHNEIDERMAN B, 1995, INTERACTIONS, V2, P13, DOI DOI 10.1145/208143.208150
   Skantze G, 2007, SKANTZE GABRIEL ERRO
   Skarbez R, 2011, VIRT REAL C VR
   Svennevig J., 2000, JOHN BENJAMINS PUBLI
   Tamura-Lis Winifred, 2013, Urol Nurs, V33, P267
   Tannen D., 1993, FRAMING DISCOURSE
   terMaat M, 2009, INT C INT VIRT AG IV
   TOMKO S, 2005, ACM T SPEECH LANGUAG, V2, P1
   Tur Gokhan, 2013, P INTERSPEECH
   van Dijk T., 2007, DISCOURSE CONT SOCIA, P281
   van Walraven C, 2010, J EVAL CLIN PRACT, V16, P947, DOI 10.1111/j.1365-2753.2009.01235.x
   Walker M, 1998, READINGS INTELLIGENT, P631
   Wang Z, 2003, P AC SPEECH SIGN PRO
   Woodland PC, 1994, IEEE INT C AC SPEECH
   Xiong W, 2017, 2017 IEEE CONFERENCE ON ENERGY INTERNET AND ENERGY SYSTEM INTEGRATION (EI2)
   Yoshikawa M., 2016, EMNLP
   Young M, 2001, CHEST, V119, P1565, DOI 10.1378/chest.119.5.1565
NR 92
TC 13
Z9 13
U1 0
U2 7
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1571-5035
EI 2524-4477
BN 978-3-319-95579-7; 978-3-319-95578-0
J9 HUM-COMPUT INT-SPRIN
PY 2018
BP 33
EP 57
DI 10.1007/978-3-319-95579-7_3
D2 10.1007/978-3-319-95579-7
PG 25
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Software Engineering
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BM0BU
UT WOS:000458606800003
DA 2022-08-02
ER

PT J
AU Goh, OS
   Fung, CC
   Wong, KW
   Depickere, A
AF Goh, Ong Sing
   Fung, Chun Che
   Wong, Kok Wai
   Depickere, Arnold
TI Embodied Conversational Agents for H5N1 Pandemic Crisis
SO JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT
   INFORMATICS
LA English
DT Article
DE Natural Language Processing Understanding and Reasoning (NLUR);
   Artificial Intelligence (AI); Embodied Conversational Agent (ECA); H5N1
   Bird Flu
AB This paper presents a novel framework for modeling embodied conversational agent for crisis communication focusing on the H5N1 pandemic crisis. Our system aims to cope with the most challenging issue on the maintenance of an engaging while convincing conversation. What primarily distinguishes our system from other conversational agent systems is that the human-computer conversation takes place within the context of H5N1 pandemic crisis. A Crisis Communication Network, called CCNet, is established based on a novel algorithm incorporating natural language query and embodied conversation agent simultaneously. Another significant contribution of our work is the development of a Automated Knowledge Extraction Agent (AKEA) to capitalize on the tremendous amount of data that is now available online to support our experiments. What makes our system differs from typical conversational agents is the attempt to move away from strictly task-oriented dialogue.
C1 [Goh, Ong Sing; Fung, Chun Che; Wong, Kok Wai; Depickere, Arnold] Murdoch Univ, Sch Informat Technol, Div Arts, Murdoch, WA 6150, Australia.
RP Goh, OS (corresponding author), Murdoch Univ, Sch Informat Technol, Div Arts, Murdoch, WA 6150, Australia.
EM os.goh@murdoch.edu.au; l.fung@murdoch.edu.au; k.wong@murdoch.edu.au;
   A.depickere@murdoch.edu.au
RI Fung, Chun Che/AAR-6196-2020; Depickere, Arnold/AAI-3004-2020; Goh, Ong
   Sing/AAZ-8734-2021
OI Fung, Chun Che/0000-0001-5182-3558
FU Murdoch University Research Excellence Grant Scheme (REGS); Division of
   Arts, Murdoch University
FX This research was supported by a Murdoch University Research Excellence
   Grant Scheme (REGS), 2006. Funding for this publication was granted by
   Division of Arts, Murdoch University.
CR Alice, 2005, ARTIFICIAL LINGUISTI
   Allen J., 2001, AI MAGAZINE, V22
   Bialik C., 2005, JUST DEADLY IS BIRD
   Brooks R. A., 1998, 1 INT C HUM ROB HUM
   Cassell J., EMBODIED CONVERSATIO
   Fodor J. A., 1994, ELM EXPERT INTRO MEN
   Goh O.S., 2005, J TECHNOLOGY MANAGEM, V2-1, P65
   Goh O.S., 2006, INT J COMPUTATIONAL, V3-3, P195
   Goh O. S., 2006, INT MULT ENG COMP SC
   Goh OS, 2005, LECT NOTES ARTIF INT, V3614, P1226
   Lempert RJ, 2003, SHAPING NEXT 100 YEA
   Loebner H., 2006, LOEBNER PRIZE GOLD M
   Lovgren S., 2004, IS ASIAN BIRD FLU NE
   McKeown K. R., 1995, TEXT GENERATION
   Moore J. D., 1993, Computational Linguistics, V19, P651
   Mori K., 2003, INT C INT UD INT MIA
   Reiter E., 2000, BUILDING NATURAL LAN
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
NR 18
TC 2
Z9 2
U1 0
U2 0
PU FUJI TECHNOLOGY PRESS LTD
PI TOKYO
PA 4F TORANOMON SANGYO BLDG, 2-29, TORANOMON 1-CHOME, MINATO-KU, TOKYO,
   105-0001, JAPAN
SN 1343-0130
EI 1883-8014
J9 J ADV COMPUT INTELL
JI J. Adv. Comput. Intell. Inform.
PD MAR
PY 2007
VL 11
IS 3
SI SI
BP 282
EP 288
DI 10.20965/jaciii.2007.p0282
PG 7
WC Computer Science, Artificial Intelligence
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VG8ES
UT WOS:000448640900005
OA Green Submitted, gold
DA 2022-08-02
ER

PT J
AU Delic, V
   Gnjatovic, M
   Jakovljevic, N
   Popovic, B
   Jokic, I
   Bojanic, M
AF Delic, Vlado
   Gnjatovic, Milan
   Jakovljevic, Niksa
   Popovic, Branislav
   Jokic, Ivan
   Bojanic, Milana
TI USER-AWARENESS AND ADAPTATION IN CONVERSATIONAL AGENTS
SO FACTA UNIVERSITATIS-SERIES ELECTRONICS AND ENERGETICS
LA English
DT Article
DE conversational agent; user-awareness; adaptation; speech recognition;
   emotion recognition; speaker recognition; dialogue management
ID SPEECH; EMOTIONS; MODELS
AB This paper considers the research question of developing user-aware and adaptive conversational agents. The conversational agent is a system which is useraware to the extent that it recognizes the user identity and his/her emotional states that are relevant in a given interaction domain. The conversational agent is user-adaptive to the extent that it dynamically adapts its dialogue behavior according to the user and his/her emotional state. The paper summarizes some aspects of our previous work and presents work-in-progress in the field of speech-based human-machine interaction. It focuses particularly on the development of speech recognition modules in cooperation with both modules for emotion recognition and speaker recognition, as well as the dialogue management module. Finally, it proposes an architecture of a conversational agent that integrates those modules and improves each of them based on some kind of synergies among themselves.
C1 [Delic, Vlado; Gnjatovic, Milan; Jakovljevic, Niksa; Popovic, Branislav; Jokic, Ivan; Bojanic, Milana] Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradov 6, Novi Sad 21000, Serbia.
   [Gnjatovic, Milan] Megatrend Univ, Grad Sch Comp Sci, Belgrade, Serbia.
RP Delic, V (corresponding author), Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradov 6, Novi Sad 21000, Serbia.
EM vlado.delic@uns.ac.rs
RI Jakovljevic, Niksa M/F-4727-2010; Jakovljević, Nikša/M-4889-2019
OI Jakovljević, Nikša/0000-0002-7283-3939; Delic,
   Vlado/0000-0002-4558-9918; Popovic, Branislav/0000-0002-5413-1028
FU Ministry of education, science and technological development of the
   Republic of Serbia [TR32035]
FX The presented study was performed as part of the project "Development of
   Dialogue Systems for Serbian and Other South Slavic Languages"
   (TR32035), funded by the Ministry of education, science and
   technological development of the Republic of Serbia.
CR [Anonymous], 2004, P SPECOM 2004 9 C SP
   Bohus D., 2008, P 6 SIGDIAL WORKSHOP, P123
   Bojanic Milana, 2013, 2013 IEEE 11th International Symposium on Intelligent Systems and Informatics (SISY), P353, DOI 10.1109/SISY.2013.6662601
   Bojanic M., 2014, SERIES ELEC IN PRESS, V27
   Bosch L., 2000, P ISCA WORKSH SPEECH, P189
   Delic Vlado, 2013, Speech and Computer. 15th International Conference, SPECOM 2013, P319, DOI 10.1007/978-3-319-01931-4_42
   Delic V, 2012, ELEKTRON ELEKTROTECH, V18, P51, DOI 10.5755/j01.eee.18.9.2806
   Delic V., 2013, DAAAM INT SCI BOOK, V2013, P371, DOI [10.2507/daaam.scibook.2013.19, DOI 10.2507/DAAAM.SCIBOOK.2013.19]
   Gales M, 2007, FOUND TRENDS SIGNAL, V1, P195, DOI 10.1561/2000000004
   Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043
   Gales MJF, 1996, COMPUT SPEECH LANG, V10, P249, DOI 10.1006/csla.1996.0013
   Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278
   Gnjatovic M., 2008, P 4 INT WORKSH HUM C
   Gnjatovic M, 2014, COGN COMPUT, V6, P775, DOI 10.1007/s12559-014-9272-1
   Gnjatovic M, 2014, KNOWL-BASED SYST, V71, P25, DOI 10.1016/j.knosys.2014.05.001
   Gnjatovic M, 2013, INT CONF COGN INFO, P167, DOI 10.1109/CogInfoCom.2013.6719234
   Gnjatovic M, 2012, 3RD IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFOCOMMUNICATIONS (COGINFOCOM 2012), P383
   Gnjatovic M, 2012, APPL INTELL, V37, P305, DOI 10.1007/s10489-011-0329-5
   Gnjatovic M, 2010, IEEE T AFFECT COMPUT, V1, P132, DOI 10.1109/T-AFFC.2010.14
   Grosz B. J., 1986, Computational Linguistics, V12, P175
   Halliday M. A. K., 1994, INTRO FUNCTIONAL GRA
   Hirschberg J, 2004, SPEECH COMMUN, V43, P155, DOI 10.1016/j.specom.2004.01.006
   Jakovljevic N, 2013, ELEKTRON ELEKTROTECH, V19, P76, DOI 10.5755/j01.eee.19.7.5167
   Jakovljevic N., 2006, P INT LANG TECHN C I, P40
   Jakovljevic N., 2014, THESIS
   Jakovljevic N., 2011, 18 INT C SYST SIGN I, P287
   Jakovljevic N., 2013, P 21 TEL FOR TELFOR, P466
   Jakovljevic N., 2009, P EUROCON 2009 ST PE, P417, DOI [10.1109/EURCON.2009.5167662, DOI 10.1109/EURCON.2009.5167662]
   Janev M, 2010, APPL INTELL, V33, P107, DOI 10.1007/s10489-008-0152-9
   Jokic I, 2012, ELEKTRON ELEKTROTECH, V123, P83, DOI 10.5755/j01.eee.123.7.2379
   Jokic I., 2014, ELECT ELECT IN PRESS, V20
   Jokinen K., 2009, SYNTHESIS LECT HUMAN
   Kim W., 2005, THESIS
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Lee C.H., 2007, P 12 INT C SPEECH CO, P25
   Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534
   Litman D., P 1 N AM CHAPT ASS C
   Lucas-Cuesta JM, 2013, EXPERT SYST APPL, V40, P1069, DOI 10.1016/j.eswa.2012.08.029
   Muller R., 2004, P WORKSH SIGN SIGN E
   Ostrogonac S., 2013, A Mixed-Structure N-gram Language Model, Patent No. [PCT/ RS2013/ 000009, 2013000009]
   Popovic B, 2013, INT CONF COGN INFO, P87, DOI 10.1109/CogInfoCom.2013.6719219
   Popovic B, 2012, APPL INTELL, V37, P377, DOI 10.1007/s10489-011-0333-9
   Povey D., 2006, P INT 2006
   Saon G, 2012, IEEE SIGNAL PROC MAG, V29, P18, DOI 10.1109/MSP.2012.2197156
   Schuller B, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P577
   Vlasenko B., 2012, 35 GERM C ART INT KI, P103
   Young S., 1994, P WORKSH HUM LANG TE, P307, DOI DOI 10.3115/1075812.1075885
NR 47
TC 0
Z9 0
U1 1
U2 1
PU UNIV NIS
PI NIS
PA UNIVERZITETSKI TRG 2, PO BOX 123, NIS, 18000, SERBIA
SN 0353-3670
EI 2217-5997
J9 FACTA UNIV-SER ELECT
JI Facta Univ.-Ser. Electron. Energ.
PD SEP
PY 2014
VL 27
IS 3
BP 375
EP 387
DI 10.2298/FUEE1403375D
PG 13
WC Engineering, Electrical & Electronic
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA V8S1G
UT WOS:000421916700006
OA gold
DA 2022-08-02
ER

PT C
AU Ptaszynski, M
   Dybala, P
   Higuchi, S
   Rzepka, R
   Araki, K
AF Ptaszynski, Michal
   Dybala, Pawel
   Higuchi, Shinsuke
   Rzepka, Rafal
   Araki, Kenji
BE Mohammadian, M
TI Affect-as-Information Approach to a Sentiment Analysis Based Evaluation
   of Conversational Agents
SO 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR
   MODELLING CONTROL & AUTOMATION, VOLS 1 AND 2
LA English
DT Proceedings Paper
CT International Conference on Computational Intelligence for Modelling,
   Control and Automation
CY DEC 10-12, 2008
CL Vienna, AUSTRIA
AB In this paper we propose a novel method for automatic evaluation of conversational agents. The method is based on analyzing the user's affect conveyed in utterances. From analyzing: the user's general emotional engagement in the conversation and the emotion types conveyed by the user in the conversation, a simple psychological reasoning is derived about the user's sentiment about the agent's performance. The evaluation experiment on two Japanese-speaking conversational agents showed the same tendencies in the results returned by the system constructed on the proposed method and the user's opinion about the two agents checked in the afterward survey. Thus the method can be used for evaluation of Japanese-speaking conversational agents.
C1 [Ptaszynski, Michal; Dybala, Pawel; Higuchi, Shinsuke; Rzepka, Rafal; Araki, Kenji] Hokkaido Univ, Grad Sch lnformat Sci & Technol, Kita Ku, Sapporo, Hokkaido 0600814, Japan.
RP Ptaszynski, M (corresponding author), Hokkaido Univ, Grad Sch lnformat Sci & Technol, Kita Ku, Kita 14 Nishi 9, Sapporo, Hokkaido 0600814, Japan.
EM ptaszynski@media.eng.hokudai.ac.jp; paweldybala@media.eng.hokudai.ac.jp;
   shin_h@media.eng.hokudai.ac.jp; kabura@media.eng.hokudai.ac.jp;
   araki@media.eng.hokudai.ac.jp
RI Rzepka, Rafal/E-2215-2014
OI Rzepka, Rafal/0000-0002-8274-0875
CR ABBASI A, 2007, INTELLIGENCE SECURIT, P282
   BABA J, 2003, J PRAGMATICS ELSEVIE
   Clore G. L., 2006, AFFECT SOCIAL THINKI
   Clore G.L., 2001, HDB AFFECT SOCIAL CO
   DIX AJ, 2004, HUMAN COMPUTER INERA
   DYBALA P, 2008, P 1 INT WORKSH LAUGH, P46
   GREFENSTETTE AG, 2004, P RIAO 2004
   HASE M, 2007, 2007NL181 IPSJ SIG, P41
   HIGUCHI S, 2008, P NLP 08 C TOK MARCH, P175
   Kang B. S., 2000, P ICSLP, P383
   Mandel DR, 2003, COGNITION EMOTION, V17, P139, DOI 10.1080/02699930302275
   Nakamura A., 1993, KANJO HYOGEN JITEN
   Oshima-Takane Y., 1995, CHILDES MANUAL JAPAN
   PTASZYNSKI M, 2008, P 14 ANN M ASS NLP, P171
   PTASZYNSKI M, 2006, THESIS UAM POZNAN
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   RZEPKA R, 2007, P 2 WORKSH ART INT T
   SCHLOSBERG H, 1952, J EXP PSYCHOL, V44, P229, DOI 10.1037/h0055778
   SCHWARZ N, 1983, J PERS SOC PSYCHOL, V45, P513, DOI 10.1037/0022-3514.45.3.513
   SJOBERGH J, 2006, P KTH CSC STOCKH
   TAKAHASHI T, 2003, NISSAN TECHNICAL REV, V53, P61
   TSUCHIYA N, 1999, SIGSLUD990311
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
NR 23
TC 0
Z9 0
U1 0
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-4244-3329-2
PY 2008
BP 901
EP 906
DI 10.1109/CIMCA.2008.122
PG 6
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems; Computer Science; Engineering
GA BON50
UT WOS:000277076500156
OA Green Published
DA 2022-08-02
ER

PT C
AU Casas, J
   Spring, T
   Daher, K
   Mugellini, E
   Abou Khaled, O
   Cudre-Mauroux, P
AF Casas, Jacky
   Spring, Timo
   Daher, Karl
   Mugellini, Elena
   Abou Khaled, Omar
   Cudre-Mauroux, Philippe
GP ASSOC COMP MACHINERY
TI Enhancing Conversational Agents with Empathic Abilities
SO PROCEEDINGS OF THE 21ST ACM INTERNATIONAL CONFERENCE ON INTELLIGENT
   VIRTUAL AGENTS (IVA)
LA English
DT Proceedings Paper
CT 21st ACM International Conference on Intelligent Virtual Agents (IVA)
CY SEP 14-17, 2021
CL ELECTR NETWORK
SP Assoc Comp Machinery, Tobiipro, Univ Fukuchiyama
DE conversational agent; virtual agent; human-computer interaction;
   artificial intelligence; language model; natural language processing;
   intelligent interface; affective computing; empathy; emotions
AB Conversational agents are getting increasingly popular and find applications in health and customer services. Conversations in these fields are often emotionally charged. It is, therefore, necessary to handle the conversation with some degree of empathy to be effective. In this work, we leverage advances in the field of natural language processing to create a dialogue system that can convincingly generate empathic responses to text-based messages. To improve the system's ability to converse with empathy, we train the language model on empathic conversations and inject additional emotional information in the response generation. We propose two chatbots: a benchmark bot and an empathic bot. Additionally, we implement an emotion classifier that allows us to predict the emotional state of text-based messages. We evaluate both chatbots in quantitative studies and compare them with human responses in qualitative studies involving human judges. Our evaluation shows that our empathic chatbot outperforms the benchmark bot and even the human-generated responses in terms of perceived empathy. Additionally, we achieve state-of-the-art results in terms of response quality using transformer-based language models. Finally, we report that we can double the initial performance of the emotion classifier using undersampling techniques, yielding a final F1-score of 0.81 in six basic emotions.
C1 [Casas, Jacky; Daher, Karl; Mugellini, Elena; Abou Khaled, Omar] HES SO Univ Appl Sci & Arts Western, Fribourg, Switzerland.
   [Spring, Timo] Univ Bern, Bern, Switzerland.
   [Cudre-Mauroux, Philippe] Univ Fribourg, Fribourg, Switzerland.
RP Casas, J (corresponding author), HES SO Univ Appl Sci & Arts Western, Fribourg, Switzerland.
EM jacky.casas@hes-so.ch; timo.spring@protonmail.ch; karl.daher@hes-so.ch;
   elena.mugellini@hes-so.ch; omar.aboukhaled@hes-so.ch;
   philippe.cudre-mauroux@unifr.ch
OI Cudre-Mauroux, Philippe/0000-0003-2588-4212
CR Adiwardana D., 2020, HUMAN LIKE OPENDOMAI, DOI DOI 10.3390/healthcare7020056
   Banchs RE, 2017, ASIAPAC SIGN INFO PR, P1364, DOI 10.1109/APSIPA.2017.8282245
   Ben-Zeev Aaron, 2000, SUBTLETY EMOTIONS, DOI [10.7551/mitpress/6548.003.0004, DOI 10.7551/MITPRESS/6548.003.0004]
   Cameron CD, 2018, SOC PERSONAL PSYCHOL, V12, DOI 10.1111/spc3.12418
   Casas J, 2020, COMPANION PUBLICATON OF THE 2020 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION (ICMI '20 COMPANION), P280, DOI 10.1145/3395035.3425319
   Chan YH, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD), P113, DOI 10.1109/ICAIBD.2018.8396177
   Cuff BMP, 2016, EMOT REV, V8, P144, DOI 10.1177/1754073914558466
   Delangue, 2019, ARXIV190108149
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Felbo Bjarke, 2017, P 2017 C EMP METH NA, P1615, DOI DOI 10.18653/V1/D17-1169
   Holtzman Ari, 2019, ARXIV190409751
   Li Q., 2020, P 28 INT C COMPUTATI, P4454
   Li Y, 2017, P 8 INT JOINT C NAT, P986
   Lin ZJ, 2020, AAAI CONF ARTIF INTE, V34, P13622
   Liu BJ, 2018, CYBERPSYCH BEH SOC N, V21, P625, DOI 10.1089/cyber.2018.0110
   Majumder N., 2020, P 2020 C EMP METH NA, P8968, DOI DOI 10.18653/V1/2020.EMNLP-MAIN.721
   Peters M. E., 2018, IMPROVING LANGUAGE U, P2227
   Poria S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P527
   Rashkin H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5370
   Roa-Seiler N., 2016, EMOTIONS TECHNOLOGY, P55, DOI [10.1016/B978-0-12-801872-9.00004-1, DOI 10.1016/B978-0-12-801872-9.00004-1]
   Seyeditabari A., 2018, ABS180600674 CORR
   Shi WY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1509
   Spring T., 2019, P 4 SWISS TEXT ANL C
   Sun X, 2018, COGN COMPUT, V10, P389, DOI 10.1007/s12559-017-9539-4
   Vaswani A, 2017, ADV NEUR IN, V30
   WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137
   Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496
   Yalcin ON, 2019, INT CONF AFFECT
   Zhou H., 2017, ARXIV170401074
   Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI [10.1162/coli_a_00368, 10.1162/COLI_a_00368]
   Zhou ZH, 2018, IEEE IJCNN
NR 31
TC 0
Z9 0
U1 7
U2 9
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-8619-7
PY 2021
BP 41
EP 47
DI 10.1145/3472306.3478344
PG 7
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS5CM
UT WOS:000728149900006
DA 2022-08-02
ER

PT J
AU Ahmad, R
   Siemon, D
   Gnewuch, U
   Robra-Bissantz, S
AF Ahmad, Rangina
   Siemon, Dominik
   Gnewuch, Ulrich
   Robra-Bissantz, Susanne
TI Designing Personality-Adaptive Conversational Agents for Mental Health
   Care
SO INFORMATION SYSTEMS FRONTIERS
LA English
DT Article; Early Access
DE Personality-adaptive conversational agent; Chatbot; Virtual assistant;
   Mental health; Artificial intelligence; Design science research
ID COMPUTER PERSONALITIES; SCIENCE RESEARCH; ELIZA; RESPONSES; MACHINES;
   ANATOMY; CUES
AB Millions of people experience mental health issues each year, increasing the necessity for health-related services. One emerging technology with the potential to help address the resulting shortage in health care providers and other barriers to treatment access are conversational agents (CAs). CAs are software-based systems designed to interact with humans through natural language. However, CAs do not live up to their full potential yet because they are unable to capture dynamic human behavior to an adequate extent to provide responses tailored to users' personalities. To address this problem, we conducted a design science research (DSR) project to design personality-adaptive conversational agents (PACAs). Following an iterative and multi-step approach, we derive and formulate six design principles for PACAs for the domain of mental health care. The results of our evaluation with psychologists and psychiatrists suggest that PACAs can be a promising source of mental health support. With our design principles, we contribute to the body of design knowledge for CAs and provide guidance for practitioners who intend to design PACAs. Instantiating the principles may improve interaction with users who seek support for mental health issues.
C1 [Ahmad, Rangina; Robra-Bissantz, Susanne] Tech Univ Carolo Wilhelmina Braunschweig, Inst Business Informat Syst, Chair Informat Management, Muhlenpfordtstr 23, D-38106 Braunschweig, Germany.
   [Siemon, Dominik] LUT Univ, Sch Engn Sci, Dept Software Engn, Mukkulankatu 19, Lahti 15210, Finland.
   [Gnewuch, Ulrich] Karlsruhe Inst Technol KIT, Inst Informat Syst & Mkt, Kaiserstr 89-93, D-76133 Karlsruhe, Germany.
RP Ahmad, R (corresponding author), Tech Univ Carolo Wilhelmina Braunschweig, Inst Business Informat Syst, Chair Informat Management, Muhlenpfordtstr 23, D-38106 Braunschweig, Germany.
EM rangina.ahmad@tu-braunschweig.de; dominik.siemon@lut.fi;
   ulrich.gnewuch@kit.edu; s.robra-bissantz@tu-braunschweig.de
OI Ahmad, Rangina/0000-0002-6463-6855
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL.
CR Abd-Alrazaq AA, 2021, J MED INTERNET RES, V23, DOI 10.2196/17828
   Abd-alrazaq AA, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103978
   Ahmad R., 2020, 26 AM C INF SYST AMC
   Ahmad R., 2021, AMCIS
   Ahmad R., PACIS, P28
   Ahmad R, 2021, P 54 HAW INT C SYST, P4043
   Al-Natour S., 2005, SIGHCI 2005 P, V4
   ALLPORT GW, 1961, PATTERNS GROWTH PERS
   Arnoux P. H., 2017, P INT AAAI C WEB SOC, V11
   Babbie ER, 2020, PRACTICE SOCIAL RES
   Bae Brandtzag P.B., 2021, P 2021 CHI C HUM FAC, P1
   Baskerville R, 2010, BUS INFORM SYST ENG+, V2, P271, DOI 10.1007/s12599-010-0118-4
   Bendig E., 2019, NEXT GENERATION CHAT, P1
   Bouchet F., 2012, COGNITIVELY INFORM I, P177
   Boyd RL, 2017, CURR OPIN BEHAV SCI, V18, P63, DOI 10.1016/j.cobeha.2017.07.017
   Brendel AB, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13041974
   Chakrabarti C, 2015, EXPERT SYST APPL, V42, P6878, DOI 10.1016/j.eswa.2015.04.067
   Chung C.K., 2013, APPL NATURAL LANGUAG, P206, DOI [10.4018/978-1-60960-741-8.ch012, DOI 10.4018/978-1-60960-741-8.CH012]
   Clark L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300705
   D'Alfonso S, 2020, CURR OPIN PSYCHOL, V36, P112, DOI 10.1016/j.copsyc.2020.04.005
   Diederich S, 2022, J ASSOC INF SYST, V23, P96, DOI 10.17705/1jais.00724
   Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009
   Ferrucci DA, 2012, IBM J RES DEV, V56, DOI 10.1147/JRD.2012.2184356
   Fiske A, 2019, J MED INTERNET RES, V21, DOI 10.2196/13216
   Fogg BJ., 2002, UBIQUITY, P89, DOI DOI 10.1145/764008.763957
   Gaffney H, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/14166
   Gnewuch U., 2020, P 28 EUR C INF SYST
   Gnewuch U., 2017, P 38 INT C INFORM SY
   Golbeck J., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P149, DOI 10.1109/PASSAT/SocialCom.2011.33
   GOLDBERG LR, 1993, AM PSYCHOL, V48, P26, DOI 10.1037/0003-066X.48.1.26
   Graham S, 2019, CURR PSYCHIAT REP, V21, DOI 10.1007/s11920-019-1094-0
   Graham SA, 2020, PSYCHIAT RES, V284, DOI 10.1016/j.psychres.2019.112732
   Gregor S, 2007, J ASSOC INF SYST, V8, P312, DOI 10.17705/1jais.00129
   Gregor S, 2020, J ASSOC INF SYST, V21, P1622, DOI 10.17705/1jais.00649
   Gregor S, 2013, MIS QUART, V37, P337, DOI 10.25300/MISQ/2013/37.2.01
   Grudin J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300439
   Grunzig SD, 2018, TRIALS, V19, DOI 10.1186/s13063-018-2657-9
   Hevner A. R., 2007, SCANDINAVIAN J INFOR, V19, P87
   Hevner AR, 2021, J INF TECHNOL-UK, V36, P72, DOI 10.1177/0268396220945714
   Hevner AR, 2004, MIS QUART, V28, P75, DOI 10.2307/25148625
   Iivari J, 2021, EUR J INFORM SYST, V30, P286, DOI 10.1080/0960085X.2020.1793697
   Iivari J, 2015, EUR J INFORM SYST, V24, P107, DOI 10.1057/ejis.2013.35
   Jones SP, 2014, HEALTH AFFAIR, V33, P1603, DOI 10.1377/hlthaff.2014.0380
   Junglas IA, 2008, EUR J INFORM SYST, V17, P387, DOI 10.1057/ejis.2008.29
   Kampman O, 2019, LECT NOTES ELECTR EN, V510, P111, DOI 10.1007/978-3-319-92108-2_13
   Kerr IR., 2003, U OTT LAW TECHNOL J, V1, P285
   Kim SY, 2019, MARKET LETT, V30, P1, DOI 10.1007/s11002-019-09485-9
   Kocaballi A. B., 2020, CONVERSATIONAL AGENT
   Kocaballi AB, 2019, J MED INTERNET RES, V21, DOI 10.2196/15360
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Liu K., 2005, CHI WORKSH HCI CHALL, V1, P3
   Luxton DD, 2020, B WORLD HEALTH ORGAN, V98, P285, DOI 10.2471/BLT.19.237636
   Luxton DD, 2014, ARTIF INTELL MED, V62, P1, DOI 10.1016/j.artmed.2014.06.004
   Maedche Alexander, 2019, Extending the Boundaries of Design Science Theory and Practice. 14th International Conference on Design Science Research in Information Systems and Technology, DESRIST 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11491), P18, DOI 10.1007/978-3-030-19504-5_2
   Mairesse F, 2007, J ARTIF INTELL RES, V30, P457, DOI 10.1613/jair.2349
   Mairesse F, 2010, USER MODEL USER-ADAP, V20, P227, DOI 10.1007/s11257-010-9076-2
   Mayring P., 2014, QUALITATIVE CONTENT
   McCrae RR, 1997, AM PSYCHOL, V52, P509, DOI 10.1037/0003-066X.52.5.509
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   Moller Frederik, 2020, Designing for Digital Transformation. Co-Creating Services with Citizens and Industry. 15th International Conference on Design Science Research in Information Systems and Technology, DESRIST 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12388), P208, DOI 10.1007/978-3-030-64823-7_20
   Moon Y, 1996, COMMUN RES, V23, P651, DOI 10.1177/009365096023006002
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   NASS C, 1995, INT J HUM-COMPUT ST, V43, P223, DOI 10.1006/ijhc.1995.1042
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nass C., 1993, INTERACT 93 CHI 93 C, P111
   Natale S., 2018, NEW MEDIA SOC, V21
   Nissen M. K., 2021, COMPUT HUM BEHAV
   Pennebaker J. W., 2015, DEV PSYCHOMETRIC PRO
   Pennebaker J. W., 2011, SECRET LIFE PRONOUNS
   Pennebaker JW, 1996, COGNITION EMOTION, V10, P601, DOI 10.1080/026999396380079
   Pennington J., 2014, P 2014 C EMPIRICAL M, P1532
   Peters O., 2013, CRITICS DIGITALISATI
   Porra J., 2019, INFORM SYST FRONT
   Prakash AV, 2020, PAC ASIA J ASSOC INF, V12, P1, DOI 10.17705/1pais.12201
   Purao S., 2020, ORIGINS DESIGN PRINC
   Ranjbartabar H, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P1829
   Rice DR, 2021, POLIT SCI RES METH, V9, P20, DOI 10.1017/psrm.2019.10
   Rothe H, 2020, J ASSOC INF SYST, V21, P771, DOI 10.17705/1jais.00619
   Schuetzler RM, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P283
   Shah H, 2016, COMPUT HUM BEHAV, V58, P278, DOI 10.1016/j.chb.2016.01.004
   Shum HY, 2018, FRONT INFORM TECH EL, V19, P10, DOI 10.1631/FITEE.1700826
   Skjuve M, 2021, INT J HUM-COMPUT ST, V149, DOI 10.1016/j.ijhcs.2021.102601
   Smith K., 2015, STRESS, DOI [10.13140/RG.2.1.3898.9929, DOI 10.13140/RG.2.1.3898.9929]
   Stieger Mirjam, 2018, BMC Psychol, V6, P43, DOI 10.1186/s40359-018-0257-9
   Ta V, 2020, J MED INTERNET RES, V22, DOI 10.2196/16235
   Torous J, 2020, JMIR MENT HEALTH, V7, DOI 10.2196/18848
   Venable J., 2006, P 1 INT C DES SCI RE
   Volkel ST, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376210
   Volkel S. T., 2021, CUI 2021, P1
   vom Brocke J, 2020, J ASSOC INF SYST, V21, P520, DOI 10.17705/1jais.00611
   Wasil A. R., 2021, PSYARXIV, DOI [10.31234/osf.io/su4ar, DOI 10.31234/OSF.IO/SU4AR]
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   WHO, 2017, DEPRESSION OTHER COM
   WHO, 2021, WHO EX BOARD STRESS
   Wibhowo Christin, 2021, 2021 International Conference on Computer & Information Sciences (ICCOINS), P234, DOI 10.1109/ICCOINS49721.2021.9497160
   Woebot Health, 2021, WOEBOT
   Wysa io, 2021, WYSA
   X2 A, 2021, TESS
   Yarkoni T, 2010, J RES PERS, V44, P363, DOI 10.1016/j.jrp.2010.04.001
   Yorita A, 2019, IEEE SYS MAN CYBERN, P4094, DOI 10.1109/SMC.2019.8914583
   Zalake Mohan, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3375026
NR 102
TC 3
Z9 3
U1 13
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1387-3326
EI 1572-9419
J9 INFORM SYST FRONT
JI Inf. Syst. Front.
DI 10.1007/s10796-022-10254-9
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZK8YB
UT WOS:000763268500003
PM 35250365
OA Green Published, hybrid
DA 2022-08-02
ER

PT C
AU Machidon, OM
   Tavcar, A
AF Machidon, Octavian M.
   Tavcar, Ales
BE Duguleana, M
   Carrozzino, M
   Gams, M
   Tanea, I
TI Exploring European Cultural Heritage Using Conversational Agents
SO VR TECHNOLOGIES IN CULTURAL HERITAGE
SE Communications in Computer and Information Science
LA English
DT Proceedings Paper
CT 1st International Conference on VR Technologies in Cultural Heritage
   (VRTCH)
CY MAY 29-30, 2018
CL Brasov, ROMANIA
DE Cultural heritage; Conversational agent; Natural language interaction
ID GUIDE
AB The semantic web and open data paradigms are gaining momentum in recent years and more information is being published online following the linked data principles. This enables easy access and processing of data by external services. An example of such services are intelligent conversational agents that provide to the users the ability to interact with a computer system in natural language. Such communication is much more intuitive and facilitates the use of complex services to less skilled users ( e. g., elderly) or users with disabilities ( e. g., visually impaired) thus providing to these groups access to the huge amount of information stored in the semantic web or specific online services. In this paper, we present a proof-of-concept conversational agent able to provide information about the European cultural heritage and display stored digital content from the Europeana database.
C1 [Machidon, Octavian M.] Transilvania Univ Brasov, Brasov, Romania.
   [Tavcar, Ales] Jozef Stefan Inst, Ljubljana, Slovenia.
RP Machidon, OM (corresponding author), Transilvania Univ Brasov, Brasov, Romania.
EM octavian.machidon@unitbv.ro
RI Machidon, Octavian/B-1406-2015
OI Machidon, Octavian/0000-0003-3133-1008
CR Bickmore Timothy, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P55, DOI 10.1007/978-3-642-23974-8_7
   Bing X., 2003, 1 C AFF COMP INT INT, P306
   Cerekovic A, 2009, LECT NOTES COMPUT SC, V5820, P7
   Cimiano P, 2010, SEMANT WEB, V1, P83, DOI 10.3233/SW-2010-0008
   Concordia C, 2010, IFLA J-INT FED LIBR, V36, P61, DOI 10.1177/0340035209360764
   Doswell JT, 2005, FR ART INT, V125, P957
   Eisman EM, 2012, EXPERT SYST APPL, V39, P3135, DOI 10.1016/j.eswa.2011.08.177
   Foster ME, 2007, LECT NOTES COMPUT SC, V4555, P828
   Graesser AC, 2004, BEHAV RES METH INS C, V36, P180, DOI 10.3758/BF03195563
   Ian D., 2009, P 6 INT WORKSH SEM W
   Isaac A, 2013, SEMANT WEB, V4, P291, DOI 10.3233/SW-120092
   Kopp S, 2005, LECT NOTES ARTIF INT, V3661, P329
   Kuznar D, 2016, INFORM-J COMPUT INFO, V40, P285
   Purday J, 2009, ELECTRON LIBR, V27, P919, DOI 10.1108/02640470911004039
   Rubin VL, 2010, LIBR HI TECH, V28, P496, DOI 10.1108/07378831011096196
   Seron FJ, 2016, MULTIMED TOOLS APPL, V75, P381, DOI 10.1007/s11042-014-2295-5
   Stefan J, 2001, NOUV REV FR, P1
   Swartout W, 2010, AI MAG, V31, P9, DOI 10.1609/aimag.v31i1.2284
   Ulli W., 2011, P 22 INT JOINT C ART, P1896
   Ulli W., 2011, DIGITAL FRUITS LUNCH
   Vecchio P, 2015, LECT NOTES COMPUT SC, V9254, P51, DOI 10.1007/978-3-319-22888-4_5
NR 21
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1865-0929
EI 1865-0937
BN 978-3-030-05819-7; 978-3-030-05818-0
J9 COMM COM INF SC
PY 2019
VL 904
BP 184
EP 194
DI 10.1007/978-3-030-05819-7_14
PG 11
WC Computer Science, Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BN4RS
UT WOS:000482706000014
OA hybrid
DA 2022-08-02
ER

PT J
AU Rehm, M
   Andre, E
AF Rehm, M
   Andre, E
TI From chatterbots to natural interaction - Face to face communication
   with embodied conversational agents
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
LA English
DT Article
DE embodied conversational agents; multi-party communication
AB In this paper, we present a game of dice that combines multi-party communication with a tangible interface. The game has been used as a testbed to study typical conversational behavior patterns in interactions between human users and synthetic agents. In particular, we were interested in the question to what extent the interaction with the agent can be considered as natural. As an evaluation criterion, we propose to investigate whether the communicative behaviors of humans differ when conversing with an agent as opposed to conversing with other humans.
C1 Univ Augsburg, Lab Multimedia Concepts & Appl, D-8900 Augsburg, Germany.
RP Rehm, M (corresponding author), Univ Augsburg, Lab Multimedia Concepts & Appl, D-8900 Augsburg, Germany.
EM rehm@informatik.uni-augsburg.de; Elisabeth.Andre@t-online.de
CR [Anonymous], HDB PERSONALITY THEO
   [Anonymous], 2001, P SIGCHI C HUM FACT, DOI DOI 10.1145/365024.365119
   Argyle M., 1976, GAZE MUTUAL GAZE
   Ball Gene, 1997, SOFTWARE AGENTS, P191
   BERGMANN JR, 1988, SOZIALE WELT ZEITSCH, V8, P299
   *BLAG, BERL LEX ALLT
   Cassell J, 2000, EMBODIED CONVERSATIONAL AGENTS, P29
   Cassell J., 2000, EMBODIED CONVERSATIO
   Ekman P., 1992, TELLING LIES CLUES D
   Fink GA, 1999, LECT NOTES ARTIF INT, V1692, P229
   GUSTAFSON J, 2004, P SIGDIAL 04
   Isbister K., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P57
   Kendon A., 1967, ACTA PSYCHOL, V26, P1
   Kidd Cory D, 2004, P 9 INT C INT US INT, P78, DOI [10.1145/964442.964458, DOI 10.1145/964442.964458]
   KOPP S, 2003, KI KUNSTLICHE INTELL, P11
   LANG PJ, 1995, AM PSYCHOL, V50, P372, DOI 10.1037/0003-066X.50.5.372
   Lester JC, 1999, APPL ARTIF INTELL, V13, P383, DOI 10.1080/088395199117324
   Nakano YI, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P553
   PAIVA A, 2003, P AAMAS 03
   Pelachaud C., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P758
   PRENDINGER H, 2001, AGENTS 01, P270
   PYNADATH DV, 2005, P 19 IJCAI
   REHM M, 2005, P AAMAS, P932
   RICKEL J, 1999, APPL ARTIF INTELL, P415
   Rist T, 2003, COMP ANIM CONF PROC, P5
   Rist T, 2002, P COSIGN02, P61
   Traum D., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P766
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   [No title captured]
NR 29
TC 2
Z9 2
U1 0
U2 5
PU IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG
PI TOKYO
PA KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011,
   JAPAN
SN 1745-1361
J9 IEICE T INF SYST
JI IEICE Trans. Inf. Syst.
PD NOV
PY 2005
VL E88D
IS 11
BP 2445
EP 2452
DI 10.1093/ietisy/e88-d.11.2445
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 987VY
UT WOS:000233546800002
OA Green Submitted
DA 2022-08-02
ER

PT J
AU Smrke, U
   Plohl, N
   Mlakar, I
AF Smrke, Urska
   Plohl, Nejc
   Mlakar, Izidor
TI Aging Adults' Motivation to Use Embodied Conversational Agents in
   Instrumental Activities of Daily Living: Results of Latent Profile
   Analysis
SO INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH
LA English
DT Article
DE instrumental activities of daily living; embodied conversational agents;
   latent profile analysis; ageing adults; personalized assistive
   technology
ID OLDER-ADULTS; TECHNOLOGY; BARRIERS; PEOPLE; HEALTH
AB The rapidly increasing share of ageing adults in the population drives the need and interest in assistive technology, as it has the potential to support ageing individuals in living independently and safely. However, technological development rarely reflects how needs, preferences, and interests develop in different ways while ageing. It often follows the strategy of "what is possible" rather than "what is needed" and "what preferred". As part of personalized assistive technology, embodied conversational agents (ECAs) can offer mechanisms to adapt the technological advances with the stakeholders' expectations. The present study explored the motivation among ageing adults regarding technology use in multiple domains of activities of daily living. Participants responded to the questionnaire on the perceived importance of instrumental activities of daily living and acceptance of the idea of using ECAs to support them. Latent profile analysis revealed four profiles regarding the motivation to use ECAs (i.e., a low motivation profile, two selective motivation profiles with an emphasis on physical and psychological well-being, and a high motivation profile). Profiles were compared in terms of their acceptance of ECA usage in various life domains. The results increase the knowledge needed in the development of assistive technology adapted to the expectations of ageing adults.
C1 [Smrke, Urska; Mlakar, Izidor] Univ Maribor, Fac Elect Engn & Comp Sci, Koroska Cesta 46, Maribor 2000, Slovenia.
   [Plohl, Nejc] Univ Maribor, Fac Arts, Dept Psychol, Koroska Cesta 160, Maribor 2000, Slovenia.
RP Mlakar, I (corresponding author), Univ Maribor, Fac Elect Engn & Comp Sci, Koroska Cesta 46, Maribor 2000, Slovenia.
EM nejc.plohl1@um.si; nejc.plohl1@um.si; nejc.plohl1@um.si
RI Mlakar, Izidor/V-2688-2019
OI Mlakar, Izidor/0000-0002-4910-1879; Plohl, Nejc/0000-0001-9936-4039;
   Smrke, Urska/0000-0003-3516-0429
FU Slovenian Research Agency (ARRS) project 'Empowerment of ageing
   individuals: Self-regulatory mechanisms and support of digital
   technology in achieving higher quality of life' [J5-3120]
FX This study was partially funded by the Slovenian Research Agency (ARRS)
   project `Empowerment of ageing individuals: Self-regulatory mechanisms
   and support of digital technology in achieving higher quality of life'
   (grant agreement No. J5-3120).
CR [Anonymous], 2013, TECHNOL ACT AGING, DOI [DOI 10.1007/978-1-4419-8348-0_3, 10.1007/978-1-4419-8348-0_3]
   Balog A., 2020, P 2020 INT C E HLTH, P1, DOI [10.1109/ehb50910.2020.9280174, DOI 10.1109/EHB50910.2020.9280174]
   Bennion MR, 2020, J MED INTERNET RES, V22, DOI 10.2196/16794
   Bruderer-Hofstetter M, 2018, AGEING RES REV, V45, P1, DOI 10.1016/j.arr.2018.04.002
   Calvaresi D, 2017, J AMB INTEL HUM COMP, V8, P239, DOI 10.1007/s12652-016-0374-3
   Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158
   Clark S.L., 2021, BRIT J MATH STAT PSY, V74, P340
   Correia L., 2014, ADV INTELL SYST COMP, P209, DOI [10.1007/978-3-319-07596-9_23, DOI 10.1007/978-3-319-07596-9_23]
   d'Orsi E, 2014, J AM GERIATR SOC, V62, P1630, DOI 10.1111/jgs.12990
   Di Giacomo D, 2019, BEHAV SCI-BASEL, V9, DOI 10.3390/bs9090096
   Eschweiler G.W., 2018, P ICAHGCA AAMAS STOC
   Esposito A, 2015, PATTERN RECOGN LETT, V66, P41, DOI 10.1016/j.patrec.2015.02.013
   Etemad-Sajadi R, 2019, INT J HEALTH CARE Q, V32, P1162, DOI 10.1108/IJHCQA-10-2018-0240
   Fornara F, 2017, INT HANDB QUALITY, P441, DOI 10.1007/978-3-319-31416-7_24
   Ganesan B, 2019, EUR REV MED PHARMACO, V23, P10470, DOI 10.26355/eurrev_201912_19686
   Gitlow L, 2014, PHYS OCCUP THER GERI, V32, P271, DOI 10.3109/02703181.2014.946640
   Graf C, 2008, AM J NURS, V108, P52, DOI 10.1097/01.NAJ.0000314810.46029.74
   Hauk N, 2018, COMPUT HUM BEHAV, V84, P304, DOI 10.1016/j.chb.2018.01.020
   Jung T, 2008, SOC PERSONAL PSYCHOL, V2, P302, DOI 10.1111/j.1751-9004.2007.00054.x
   KATZ S, 1983, J AM GERIATR SOC, V31, P721, DOI 10.1111/j.1532-5415.1983.tb03391.x
   LAWTON MP, 1969, GERONTOLOGIST, V9, P179, DOI 10.1093/geront/9.3_Part_1.179
   Lubke G, 2006, MULTIVAR BEHAV RES, V41, P499, DOI 10.1207/s15327906mbr4104_4
   Carmona-Torres JM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0220157
   McNeill D, 2016, WHY WE GESTURE: THE SURPRISING ROLE OF HAND MOVEMENTS IN COMMUNICATION, P1, DOI 10.1017/CBO9781316480526
   Mostaghel R, 2016, J BUS RES, V69, P4896, DOI 10.1016/j.jbusres.2016.04.049
   Muthen LK, 2011, MPLUS USERS GUIDE
   Nylund-Gibson K., 2018, TRANSL ISSUES PSYCHO, V4, P440, DOI [10.1037/tps0000176, DOI 10.1037/TPS0000176]
   Oguego CL, 2018, UNIVERSAL ACCESS INF, V17, P97, DOI 10.1007/s10209-017-0527-y
   Olsson T, 2018, INFORM COMMUN SOC, V22, P55, DOI 10.1080/1369118X.2017.1355007
   Pal D, 2018, IEEE ACCESS, V6, P51238, DOI 10.1109/ACCESS.2018.2869599
   Portela D, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17207387
   Ram N, 2009, INT J BEHAV DEV, V33, P565, DOI 10.1177/0165025409343765
   Rampioni M, 2021, JMIR MHEALTH UHEALTH, V9, DOI 10.2196/25381
   Ridda I, 2010, VACCINE, V28, P901, DOI 10.1016/j.vaccine.2009.10.081
   Rogers Y., 2006, P C HUM FACT COMP SY, P3913
   Rojc M, 2017, ENG APPL ARTIF INTEL, V57, P80, DOI 10.1016/j.engappai.2016.10.006
   Ryu H., 2020, PROC ACM HUM COMPUT, V4, P1, DOI [10.1145/3415223, DOI 10.1145/3415223]
   Santini S, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18189681
   Sayago S., 2019, HUMAN COMPUTER INTER, P3
   SCLOVE SL, 1987, PSYCHOMETRIKA, V52, P333, DOI 10.1007/BF02294360
   Sebastian J, 2017, COMPUT HUM BEHAV, V73, P479, DOI 10.1016/j.chb.2017.03.071
   Sin J, 2020, HUM-COMPUT INTERACT, V35, P481, DOI 10.1080/07370024.2020.1731690
   Spurk D, 2020, J VOCAT BEHAV, V120, DOI 10.1016/j.jvb.2020.103445
   Steptoe A, 2013, P NATL ACAD SCI USA, V110, P5797, DOI 10.1073/pnas.1219686110
   United Nations, 2017, WORLD POP AG
   Wolff JL, 2002, ARCH INTERN MED, V162, P2269, DOI 10.1001/archinte.162.20.2269
   Zhang Y, 2021, P ROY SOC B-BIOL SCI, V288, DOI 10.1098/rspb.2021.0500
NR 48
TC 0
Z9 0
U1 7
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1660-4601
J9 INT J ENV RES PUB HE
JI Int. J. Environ. Res. Public Health
PD FEB
PY 2022
VL 19
IS 4
AR 2373
DI 10.3390/ijerph19042373
PG 11
WC Environmental Sciences; Public, Environmental & Occupational Health
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Environmental Sciences & Ecology; Public, Environmental & Occupational
   Health
GA ZW8SS
UT WOS:000771476900001
PM 35206564
OA Green Published, gold
DA 2022-08-02
ER

PT C
AU Perez-Marin, D
   Pascual-Nieto, I
AF Perez-Marin, Diana
   Pascual-Nieto, Ismael
BE Filipe, J
   Fred, A
   Sharp, B
TI OVERVIEW OF INTERACTIVE GENETIC PROGRAMMING APPROACHES FOR
   CONVERSATIONAL AGENTS
SO ICAART 2010: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON AGENTS
   AND ARTIFICIAL INTELLIGENCE, VOL 2: AGENTS
LA English
DT Proceedings Paper
CT 2nd International Conference on Agents and Artificial Intelligence
   (ICAART 2010)
CY JAN 22-24, 2010
CL Valencia, SPAIN
DE Interactive Genetic Programming; Conversational Agent; Evolutionary
   Algorithm; Dialogue System; Natural Language Generation
ID LANGUAGE GENERATION
AB Many of the existing conversational agents provide predefined answers. Therefore, the generated dialogue is quite similar for different users. Interactive genetic algorithms ask humans to provide fitness, rather than using a programmed function to compute it. This permits a better adjustment to the preferences and needs of each user. In this paper, a review of how interactive genetic algorithms can be used to provide more flexible and adaptable dialogues is presented.
C1 [Perez-Marin, Diana] Rey Juan Carlos Univ, Dept Language & Comp Syst 1, Madrid, Spain.
   [Pascual-Nieto, Ismael] Univ Autonoma Madrid, Dept Comp, Madrid, Spain.
RP Perez-Marin, D (corresponding author), Rey Juan Carlos Univ, Dept Language & Comp Syst 1, Madrid, Spain.
EM diana.perez@urjc.es; ismael.pascual@uam.es
RI Pérez-Marín, Diana/ABF-6641-2021
OI Pérez-Marín, Diana/0000-0003-3390-0251
FU  [CCG08-UAM/TIC-4425]
FX This work has been sponsored by the project CCG08-UAM/TIC-4425.
CR Araujo L, 2004, IEEE T EVOLUT COMPUT, V8, P14, DOI 10.1109/TEVC.2003.818189
   Araujo L, 2007, ARTIF INTELL REV, V28, P275, DOI 10.1007/s10462-009-9104-y
   Goldberg D.E, 1989, GENETIC ALGORITHMS S
   Hervas R., 2005, 10 INT C COMP AID SY
   Holland J.H., 1992, ADAPTATION NATURAL A
   Karamanis N., 2002, P INLG, P81
   Kim KM, 2004, LECT NOTES COMPUT SC, V3177, P813
   KOZA JR, 1994, AUTOMATIC DISCOVERY
   Lester J., 2004, PRACTICAL HDB INTERN
   Lim S, 2005, LECT NOTES ARTIF INT, V3558, P305
   Macskassy S., 1996, CONVERSATIONAL AGENT
   McKeown -K., 1986, IEEE P, V74, P905
   Michalewicz Z., 1994, GENETIC ALGORITHMS D
   Oh AH, 2002, COMPUT SPEECH LANG, V16, P387, DOI 10.1016/S0885-2308(02)00012-8
   Ratnaparkhi A, 2002, COMPUT SPEECH LANG, V16, P435, DOI 10.1016/S0885-2308(02)00025-6
   Takagi H, 2001, P IEEE, V89, P1275, DOI 10.1109/5.949485
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
NR 17
TC 0
Z9 0
U1 0
U2 0
PU INSTICC-INST SYST TECHNOLOGIES INFORMATION CONTROL & COMMUNICATION
PI SETUBAL
PA AVENIDA D MANUEL L, 27A 2 ESQUERDO, SETUBAL, 2910-595, PORTUGAL
BN 978-989-674-022-1
PY 2010
BP 359
EP 366
PG 8
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BG8KD
UT WOS:000392361900062
DA 2022-08-02
ER

PT J
AU Vaidyam, AN
   Wisniewski, H
   Halamka, JD
   Kashavan, MS
   Torous, JB
AF Vaidyam, Aditya Nrusimha
   Wisniewski, Hannah
   Halamka, John David
   Kashavan, Matcheri S.
   Torous, John Blake
TI Chatbots and Conversational Agents in Mental Health: A Review of the
   Psychiatric Landscape
SO CANADIAN JOURNAL OF PSYCHIATRY-REVUE CANADIENNE DE PSYCHIATRIE
LA English
DT Review
DE chatbot; conversational agent; embodied conversational agent; mental
   health; psychiatry; depression; medical informatics
ID VIRTUAL AGENT; BURDEN
AB Objective: The aim of this review was to explore the current evidence for conversational agents or chatbots in the field of psychiatry and their role in screening, diagnosis, and treatment of mental illnesses. Methods: A systematic literature search in June 2018 was conducted in PubMed, EmBase, PsycINFO, Cochrane, Web of Science, and IEEE Xplore. Studies were included that involved a chatbot in a mental health setting focusing on populations with or at high risk of developing depression, anxiety, schizophrenia, bipolar, and substance abuse disorders. Results: From the selected databases, 1466 records were retrieved and 8 studies met the inclusion criteria. Two additional studies were included from reference list screening for a total of 10 included studies. Overall, potential for conversational agents in psychiatric use was reported to be high across all studies. In particular, conversational agents showed potential for benefit in psychoeducation and self-adherence. In addition, satisfaction rating of chatbots was high across all studies, suggesting that they would be an effective and enjoyable tool in psychiatric treatment. Conclusion: Preliminary evidence for psychiatric use of chatbots is favourable. However, given the heterogeneity of the reviewed studies, further research with standardized outcomes reporting is required to more thoroughly examine the effectiveness of conversational agents. Regardless, early evidence shows that with the proper approach and research, the mental health field could use conversational agents in psychiatric treatment.
C1 [Vaidyam, Aditya Nrusimha; Wisniewski, Hannah; Halamka, John David; Kashavan, Matcheri S.; Torous, John Blake] Harvard Med Sch, Beth Israel Deaconess Med Ctr, 75 Fenwood Rd, Boston, MA 02115 USA.
RP Torous, JB (corresponding author), Harvard Med Sch, Beth Israel Deaconess Med Ctr, 75 Fenwood Rd, Boston, MA 02115 USA.
EM jtorous@bidmc.harvard.edu
OI Vaidyam, Aditya/0000-0002-2900-4561
CR Agarwal S, 2016, BMJ-BRIT MED J, V352, DOI 10.1136/bmj.i1174
   Anders G, 2017, TECHNOL REV, V120, P26
   [Anonymous], WIRED
   Ardito RB, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00270
   Aronson P, 2018, QUANTIFIED HEART
   Bickmore T, 2010, HARVARD REV PSYCHIAT, V18, P119, DOI 10.3109/10673221003707538
   Bickmore TW, 2010, INTERACT COMPUT, V22, P289, DOI 10.1016/j.intcom.2009.12.001
   Bickmore TW, 2010, INTERACT COMPUT, V22, P276, DOI 10.1016/j.intcom.2010.02.001
   Daubney M., TELEGRAPH
   Engberg A, 2017, MENTAL HLTH CHATBOTS
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Gardiner PM, 2017, PATIENT EDUC COUNS, V100, P1720, DOI 10.1016/j.pec.2017.04.015
   Hernandez D, WALL STREET J
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Leviathan Y, 2018, GOOGLE DUPLEX AN AI
   Lucas GM, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00051
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   Ly KH, 2017, INTERNET INTERV, V10, P39, DOI 10.1016/j.invent.2017.10.002
   Miner AS, 2017, JAMA-J AM MED ASSOC, V318, P1217, DOI 10.1001/jama.2017.14151
   Miner AS, 2016, JAMA INTERN MED, V176, P619, DOI 10.1001/jamainternmed.2016.0400
   Murray CJL, 2012, LANCET, V380, P2197, DOI 10.1016/S0140-6736(12)61689-4
   Oladeji Bibilola D, 2016, BJPsych Int, V13, P61
   Philip P, 2017, SCI REP-UK, V7, DOI 10.1038/srep42656
   Research E, INFINITE DIAL CANADA
   Scholten MR, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7351
   Shinozaki T, 2015, COMPUTING, V97, P3, DOI 10.1007/s00607-013-0352-y
   Tanielian T.L., 2008, INVISIBLE WOUNDS WAR
   Tielman ML, 2017, TECHNOL HEALTH CARE, V25, P1081, DOI 10.3233/THC-170899
   Tielman ML, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0771-y
   Trautmann S, 2016, EMBO REP, V17, P1245, DOI 10.15252/embr.201642951
   Weizenbaum J., 1976, COMPUTER POWER HUMAN
NR 31
TC 120
Z9 121
U1 32
U2 115
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0706-7437
EI 1497-0015
J9 CAN J PSYCHIAT
JI Can. J. Psychiat.-Rev. Can. Psychiat.
PD JUL
PY 2019
VL 64
IS 7
BP 456
EP 464
DI 10.1177/0706743719828977
PG 9
WC Psychiatry
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychiatry
GA IG6VC
UT WOS:000473937200002
PM 30897957
OA Green Submitted, Green Published, Bronze
DA 2022-08-02
ER

PT C
AU Io, HN
   Lee, CB
AF Io, H. N.
   Lee, C. B.
GP IEEE
TI Chatbots and Conversational Agents: A Bibliometric Analysis
SO 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND
   ENGINEERING MANAGEMENT (IEEM)
SE International Conference on Industrial Engineering and Engineering
   Management IEEM
LA English
DT Proceedings Paper
CT IEEE International Conference on Industrial Engineering and Engineering
   Management (IEEE IEEM)
CY DEC 10-13, 2017
CL Singapore, SINGAPORE
SP IEEE, IEEE Singapore Sect, IEEE TEMS Singapore Chapter, IEEE TEMS Hong Kong Chapter
DE Chatbot; conversational agent; bibliometric analysis
AB Chatbots are replacing some of the jobs that are traditionally performed by human workers, such as online customer service agents and educators. From the initial stage of rule-based chatbots to the era of rapid development in artificial intelligence (AI), the performance of chatbots keeps improving. Chatbots can nowadays "chat" like a human being and they can learn from experience. The purpose of this research is to examine the past research on chatbots (also known as conversational agents) using the quantitative bibliometric analysis. The contribution of this research is to help researchers to identify research gaps for the future research agenda in chatbots. The results of the analysis found a potential research opportunity in chatbots due to the emergence of the deep learning technology. This new technology may change the direction of future research in chatbots. Several recommendations for future research are provided based on the results obtained from our analysis.
C1 [Io, H. N.; Lee, C. B.] Univ Macau, Dept Accounting & Informat Management, Taipa, Macao, Peoples R China.
RP Io, HN (corresponding author), Univ Macau, Dept Accounting & Informat Management, Taipa, Macao, Peoples R China.
EM helmondio@gmail.com
RI Lee, Chang Boon/P-1981-2019
OI Lee, Chang Boon/0000-0002-8526-2274
CR Abu Shawar BA and Atwell ES, 2007, J LANG TECHNOL COMPU, V22, P29
   Aria M, 2016, BIBLIOMETRIX R TOOL
   Chen CM, 2010, J AM SOC INF SCI TEC, V61, P1386, DOI 10.1002/asi.21309
   Chen CM, 2004, P NATL ACAD SCI USA, V101, P5303, DOI 10.1073/pnas.0307513100
   Chen HC, 2012, MIS QUART, V36, P1165
   Deveau S., 2017, BLOOMBERG
   Dillet R., 2016, TECHCRUNCH
   Galvin P., 2016, ALIBABA INVESTS AI S
   Khalaf S., 2016, FLURRY ANAL
   Latham A, 2010, LECT NOTES COMPUT SC, V6483, P131, DOI 10.1007/978-3-642-17407-0_14
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Mlakar I, 2011, LECT NOTES COMPUT SC, V6800, P185, DOI 10.1007/978-3-642-25775-9_19
   Ng JJ, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND ENGINEERING MANAGEMENT (IEEM), P976, DOI 10.1109/IEEM.2015.7385794
   O'Shea J, 2011, INTEL SYST REF LIBR, V10, P201, DOI 10.1007/978-3-642-17931-0_8
   Paunov C, 2012, RES POLICY, V41, P24, DOI 10.1016/j.respol.2011.07.007
   Shawar B. A., 2007, P WORKSH BRIDG GAP A P WORKSH BRIDG GAP A
   Shawar B. A., 2002, COMP ALICE ELIZABETH
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Yin C., 2017, CHINA CHANNEL
   Zhang X, 2016, BEHAV INFORM TECHNOL, V35, P1130, DOI 10.1080/0144929X.2016.1212403
NR 20
TC 35
Z9 36
U1 0
U2 31
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2157-3611
BN 978-1-5386-0948-4
J9 IN C IND ENG ENG MAN
PY 2017
BP 215
EP 219
PG 5
WC Engineering, Industrial; Operations Research & Management Science
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Operations Research & Management Science
GA BJ8IP
UT WOS:000428267800045
DA 2022-08-02
ER

PT C
AU Beredo, JL
   Ong, EC
AF Beredo, Jackylyn L.
   Ong, Ethel C.
BA Sari, E
BF Sari, E
BE Tedjasaputra, A
   Samson, B
   Ghazali, M
   Sacar, S
   Gamage, D
   Kurniawan, Y
TI Beyond the Scene: A Comparative Analysis of Two Storytelling-based
   Conversational Agents
SO 5TH ASIAN CHI SYMPOSIUM PROCEEDINGS
LA English
DT Proceedings Paper
CT 5th Asian CHI Symposium (CHI)
CY MAY 07-08, 2021
CL ELECTR NETWORK
DE Conversational agents; conversation analysis; collaborative
   story-telling
AB Advances in conversational interfaces have facilitated the widespread use of chatbots in assisting humans in their daily lives such as in retail services, healthcare, and education. With the use of Natural Language Processing techniques (NLP), chatbots can leverage on storytelling strategies to engage children in meaningful conversations to narrate and share their stories. In this paper, we compared two existing conversational storytelling agents, Orsen and EREN, by analyzing the dialog logs to examine children's engagement when sharing their stories with these agents. Taking three dimensions - language production, flow maintenance, and affect; into consideration, results show that the ability of EREN to recognize emotions expressed in the child's input text can encourage the children to be more open to sharing their stories. Even though the agent cannot generate affect-rich responses, its ability to recognize the emotions made children feel thankful and appreciative of the agent for listening.
C1 [Beredo, Jackylyn L.; Ong, Ethel C.] De La Salle Univ, Manila, Philippines.
RP Beredo, JL (corresponding author), De La Salle Univ, Manila, Philippines.
EM jackylyn_beredo@dlsu.edu.ph; ethel.ong@dlsu.edu.ph
CR [Anonymous], 2007, DOING CONVERSATION A
   Ball G, 2000, EMBODIED CONVERSATIONAL AGENTS, P189
   Beneteau E, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300473
   Bharti Urmil, 2020, 2020 5th International Conference on Communication and Electronics Systems (ICCES). Proceedings, P870, DOI 10.1109/ICCES48766.2020.9137944
   Brandtzaeg PB., 2018, INTERACTIONS, V25, P38, DOI 10.1145/3236669
   Cassell J., 2007, Educational Technology, V47, P39
   Cato MA, 2004, J COGNITIVE NEUROSCI, V16, P167, DOI 10.1162/089892904322984481
   Chan Lynette Danielle, 2018, P 26 ICCE WORKSH INN, P26
   Clarizia Fabio, 2018, Cyberspace Safety and Security. 10th International Symposium, CSS 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11161), P291, DOI 10.1007/978-3-030-01689-0_23
   COLBY BN, 1989, CONTEMP SOCIOL, V18, P957, DOI 10.2307/2074241
   D'mello S., 2013, ACM T INTERACT INTEL, V2, P1
   DENHAM SA, 1995, GENET SOC GEN PSYCH, V121, P311
   Dillenbourg P., 1999, WHAT DO YOU MEAN COL
   Fernoaga V, 2018, ELEARN SOFTW EDUC, P376, DOI 10.12753/2066-026X-18-122
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Foolen Ad., 2012, MOVING OURSELVES MOV, P349, DOI DOI 10.1075/CEB.6
   Fryer L, 2006, LANG LEARN TECHNOL, V10, P8
   Gasper K, 2018, EMOT REV, V10, P255, DOI 10.1177/1754073918765660
   Gnewuch U., 2017, P 38 INT C INFORM SY
   Gottman JM, 1996, J FAM PSYCHOL, V10, P243, DOI 10.1037/0893-3200.10.3.243
   Graesser AC, 2005, IEEE T EDUC, V48, P612, DOI 10.1109/TE.2005.856149
   Hien HT, 2018, PROCEEDINGS OF THE NINTH INTERNATIONAL SYMPOSIUM ON INFORMATION AND COMMUNICATION TECHNOLOGY (SOICT 2018), P69, DOI 10.1145/3287921.3287937
   Inkster B, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/12106
   Jain M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P895, DOI 10.1145/3196709.3196735
   Jhavar H, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P243, DOI 10.1145/3184558.3186989
   Kang J. Y., 2009, FIRST LANG, V29, P243, DOI DOI 10.1177/0142723708101680
   KERN RG, 1995, MOD LANG J, V79, P457, DOI 10.2307/329999
   Lester J., 2004, PRACTICAL HDB INTERN
   Lester Jessica N, 2018, APPL CONVERSATION AN
   Liao QV, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P264, DOI 10.1145/2901790.2901842
   Meehan James R, 1977, IJCAI, V77, P9198
   Oatley K, 2002, NARRATIVE IMPACT: SOCIAL AND COGNITIVE FOUNDATIONS, P39
   Ong Ethel, 2019, 2019 22 C OR COCOSDA, P1
   Ong Ethel Chua Joy, 2019, NARRATIVE BASED CONV
   Perinatal Mental Health Project, BAS COUNS SKILLS GUI
   Robins B, 2004, INTERACT STUD, V5, P161, DOI 10.1075/is.5.2.02rob
   Ruan S, 2019, L@S '19: PROCEEDINGS OF THE SIXTH (2019) ACM CONFERENCE ON LEARNING @ SCALE, DOI 10.1145/3330430.3333643
   Ruusuvuori Johanna, 2013, HDB CONVERSATION ANA, P330, DOI DOI 10.1002/9781118325001.CH16
   Ryokai Kimiko, 2002, LITERACY LEARNING ST
   Sanchez J Alfredo, 2006, P 7 BRAZ S HUM FACT, P66
   Santos KA, 2020, PROCEEDINGS OF IDC 2020, P483, DOI 10.1145/3392063.3394405
   Satriani I., 2019, ENGLISH REV J ENGLIS, V8, P113, DOI [10.25134/erjee.v8i1.1924, DOI 10.25134/ERJEE.V8I1.1924]
   Schaffer Stefan, 2018, MOBILECH MOBILE HCI
   Shuster Claudia, 2000, EMOTIONS COUNT SCAFF
   Svikhnushina Ekaterina, 2020, ARXIV PREPRINT ARXIV
   Ong DT, 2018, 26TH INTERNATIONAL CONFERENCE ON COMPUTERS IN EDUCATION (ICCE 2018), P205
   Wang Austin, 2003, P WORKSH ED AG MOR V
   Wanska Susan K, 1989, EARLY CHILD RES Q, V4, P393
   Wong Jean, 2021, STORYTELLING MULTILI
   Xu Y, 2020, PROCEEDINGS OF IDC 2020, P216, DOI 10.1145/3392063.3394417
NR 50
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8203-8
PY 2021
BP 189
EP 195
DI 10.1145/3429360.3468208
PG 7
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering;
   Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS8CC
UT WOS:000770802700036
DA 2022-08-02
ER

PT C
AU Danielescu, A
   Christian, G
AF Danielescu, Andreea
   Christian, Gwen
GP ACM
TI A Bot is Not a Polyglot: Designing Personalities for Multi-Lingual
   Conversational Agents
SO CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS
   IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 21-26, 2018
CL Montreal, CANADA
SP Assoc Comp Machinery, ACM SIGCHI
DE Conversational systems; personality; voice user interface design;
   interaction design
AB Conversational agents are becoming more common, influenced by the success of Siri and Alexa. As such, new methods and associated challenges of designing for conversational systems are emerging. One factor, unique to conversational agents, that we need to account for as designers, is personality. People attribute personalities to conversational agents, strongly influenced by social expectations, whether or not a particular personality was designed deliberately. In the case of multi-lingual agents, this creates additional challenges: direct translations don't accommodate cultural variation. We discuss the design process and lessons learned from Radar Pace, a conversational coach that launched with support for five languages. We highlight successes and failures based on user study results and propose changes to the design process to avoid pitfalls for future agents.
C1 [Danielescu, Andreea; Christian, Gwen] Intel Corp, 2200 Mission Coll Blvd, Santa Clara, CA 95054 USA.
RP Danielescu, A (corresponding author), Intel Corp, 2200 Mission Coll Blvd, Santa Clara, CA 95054 USA.
EM andreea.danielescu@intel.com; gwen.christian@intel.com
CR Capes T, 2017, INTERSPEECH, P4011, DOI 10.21437/Interspeech.2017-1798
   Draycott Richard, 2017, GOOGLE ASSISTANT PER
   Eadicicco Lisa, 2017, GOOGLE WANTS GIVE YO
   Fowler Geoffrey A., 2011, ARE SMARTPHONES BECO
   GRICE HP, 1975, SYNTAX SEMANTICS, V3, DOI DOI 10.1111/J.1365-2664.2006.01229.X
   Hendrich Susan, I GAVE CORTANA HER P
   Kedemey Dan, 2015, HERES WHAT REALLY MA
   McCracken Harry, 2017, AMAZONS ALEXA TURNS
   Molen Brad, 2014, HER NAME IS CORTANA
   Nass Clifford, 2005, WIRED SPEECH VOICE A
   Perez Sarah, 2017, ALEXA LEARNS TALK HU
   Rubin Ben Fox, 2017, ALEXA BE MORE HUMAN
   Soper Taylor, 2017, MORE 8M PEOPLE OWN A
   Tapp Meg, 2015, SASSY SIRI DOES VOIC
NR 14
TC 4
Z9 4
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5621-3
PY 2018
AR CS01
DI 10.1145/3170427.3174366
PG 9
WC Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR8DX
UT WOS:000671090000054
DA 2022-08-02
ER

PT C
AU Griol, D
   Carbo, J
   Molina, JM
AF Griol, David
   Carbo, Javier
   Manuel Molina, Jose
BE Novais, P
   Hallenborg, K
   Tapia, DI
   Rodriguez, JMC
TI Optimizing Dialog Strategies for Conversational Agents Interacting in
   AmI Environments
SO AMBIENT INTELLIGENCE - SOFTWARE AND APPLICATIONS
SE Advances in Intelligent and Soft Computing
LA English
DT Proceedings Paper
CT 3rd International Symposium on Ambient Intelligence (ISAml 2012)
CY MAR 28-30, 2012
CL Univ Salamanca, Salamanca, SPAIN
SP Univ Salamanca, Bioinformat Intelligent Syst & Educ Technol Res Grp
HO Univ Salamanca
DE Conversational Agents; Speech Interaction; Agent & Multiagent Systems
   for AmI; Statistical Methodologies
ID MANAGEMENT
AB In this paper, we describe a conversational agent which provides academic information. The dialog model of this agent has been developed by means of a statistical methodology that automatically explores the dialog space and allows learning new enhanced dialog strategies from a dialog corpus. A dialog simulation technique has been applied to acquire data required to train the dialog model and then explore the new dialog strategies. A set of measures has also been defined to evaluate the dialog strategy. The results of the evaluation show how the dialog model deviates from the initially predefined strategy, allowing the conversational agent to tackle new situations and generate new coherent answers for the situations already present in the initial corpus. The proposed technique can be used not only to develop new dialog managers but also to explore new enhanced dialog strategies focused on user adaptation required to interact in AmI environments.
C1 [Griol, David; Carbo, Javier; Manuel Molina, Jose] Univ Carlos III Madrid, Dept Comp Sci, Grp Appl Artificial Intelligence GIAA, E-28903 Getafe, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Grp Appl Artificial Intelligence GIAA, E-28903 Getafe, Spain.
EM david.griol@uc3m.es; javier.carbo@uc3m.es; josemanuel.molina@uc3m.es
RI Carbo, Javier/ABB-4694-2020; Griol, David/L-1258-2014; Molina,
   JOSE/B-1956-2008
OI Carbo, Javier/0000-0001-7794-3398; Griol, David/0000-0001-6266-5321;
   Molina, JOSE/0000-0002-7484-7357
CR Callejas Z, 2008, SPEECH COMMUN, V50, P646, DOI 10.1016/j.specom.2008.04.004
   Griol D, 2008, SPEECH COMMUN, V50, P666, DOI 10.1016/j.specom.2008.04.001
   Griol D, 2011, ADV INTEL SOFT COMPU, V88, P255, DOI 10.1007/978-3-642-19875-5_33
   Schatzmann J., 2007, HUMAN LANGUAGE TECHN, P149
   Schatzmann J, 2006, KNOWL ENG REV, V21, P97, DOI 10.1017/S0269888906000944
   Williams JD, 2007, IEEE T AUDIO SPEECH, V15, P2116, DOI 10.1109/TASL.2007.902050
   Young S., 2002, STAT APPROACH DESIGN
   [No title captured]
NR 8
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 1867-5662
BN 978-3-642-28782-4
J9 ADV INTEL SOFT COMPU
PY 2012
VL 153
BP 93
EP 100
PG 8
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BCK69
UT WOS:000310488400012
DA 2022-08-02
ER

PT S
AU L'Abbate, M
   Thiel, U
AF L'Abbate, M
   Thiel, U
BE Blackburn, P
   Ghidini, C
   Turner, RM
   Giunchiglia, F
TI The use of contextual information in a proactivity model for
   conversational agents
SO MODELING AND USING CONTEXT, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 4th International and Interdisciplinary Conference on Modeling and Using
   Context (CONTEXT 2003)
CY JUN 23-25, 2003
CL STANFORD, CA
SP Univ Trento, Stanford Univ Ctr, Study Language & Informat, Stanford Univ, Linguist Dept, Stanford Univ, Philosophy Dept, Stanford Univ, Psychol Dept
DE human-computer interaction; autonomous agents and multiagent systems
AB For conversational agents engaging in a natural language-based interaction with web site users in service exchange applications, simple entertaining "chatting" is not sufficient. Instead, the agent needs to be cooperative by trying to provide relevant information about products and/or the conditions of purchasing. In this paper we analyze how the proactive behaviour of conversational agents can be used to increase the general user satisfaction. The results of two case studies allow us to outline a generic proactivity, model for information agents based on retrieval mechanisms and search heuristics.
C1 Fraunhofer IPSI, D-64293 Darmstadt, Germany.
RP L'Abbate, M (corresponding author), Fraunhofer IPSI, Dolivostr 15, D-64293 Darmstadt, Germany.
EM labbate@ipsi.fraunhofer.de; thiel@ipsi.fraunhofer.de
CR ANDERSEN V, 2002, IST199913347 RIS NAT
   Covey S. R., 1989, 7 HABITS HIGHLY EFFE
   Ferguson G, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P567
   GUTTMAN R, 1998, AGENT MEDIATED ELECT
   Hayes-Roth B, 1999, COMMUN ACM, V42, P103, DOI 10.1145/295685.295887
   LABBATE M, 2002, P AUT AG MULT AG SYS
   PARADISO A, 2001, MULTIMODAL COMMUNICA, P65
   THIEL U, 2002, E BUSINESS APPL RESU
   WOOLDRIDGE M, 1995, KNOWL ENG REV, V10, P115, DOI 10.1017/S0269888900008122
NR 9
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-40380-9
J9 LECT NOTES ARTIF INT
PY 2003
VL 2680
BP 459
EP 466
PG 8
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BX29W
UT WOS:000184853900038
DA 2022-08-02
ER

PT J
AU Milne-Ives, M
   de Cock, C
   Lim, E
   Shehadeh, MH
   de Pennington, N
   Mole, G
   Normando, E
   Meinert, E
AF Milne-Ives, Madison
   de Cock, Caroline
   Lim, Ernest
   Shehadeh, Melissa Harper
   de Pennington, Nick
   Mole, Guy
   Normando, Eduardo
   Meinert, Edward
TI The Effectiveness of Artificial Intelligence Conversational Agents in
   Health Care: Systematic Review
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Review
DE artificial intelligence; avatar; chatbot; conversational agent; digital
   health; intelligent assistant; speech recognition software; virtual
   assistant; virtual coach; virtual health care; virtual nursing; voice
   recognition software
AB Background: The high demand for health care services and the growing capability of artificial intelligence have led to the development of conversational agents designed to support a variety of health-related activities, including behavior change, treatment support, health monitoring, training, triage, and screening support. Automation of these tasks could free clinicians to focus on more complex work and increase the accessibility to health care services for the public. An overarching assessment of the acceptability, usability, and effectiveness of these agents in health care is needed to collate the evidence so that future development can target areas for improvement and potential for sustainable adoption.
   Objective: This systematic review aims to assess the effectiveness and usability of conversational agents in health care and identify the elements that users like and dislike to inform future research and development of these agents.
   Methods: PubMed, Medline (Ovid), EMBASE (Excerpta Medica dataBASE), CINAHL (Cumulative Index to Nursing and Allied Health Literature), Web of Science, and the Association for Computing Machinery Digital Library were systematically searched for articles published since 2008 that evaluated unconstrained natural language processing conversational agents used in health care. EndNote (version X9, Clarivate Analytics) reference management software was used for initial screening, and full-text screening was conducted by 1 reviewer. Data were extracted, and the risk of bias was assessed by one reviewer and validated by another.
   Results: A total of 31 studies were selected and included a variety of conversational agents, including 14 chatbots (2 of which were voice chatbots), 6 embodied conversational agents (3 of which were interactive voice response calls, virtual patients, and speech recognition screening systems), 1 contextual question-answering agent, and 1 voice recognition triage system. Overall, the evidence reported was mostly positive or mixed. Usability and satisfaction performed well (27/30 and 26/31), and positive or mixed effectiveness was found in three-quarters of the studies (23/30). However, there were several limitations of the agents highlighted in specific qualitative feedback.
   Conclusions: The studies generally reported positive or mixed evidence for the effectiveness, usability, and satisfactoriness of the conversational agents investigated, but qualitative user perceptions were more mixed. The quality of many of the studies was limited, and improved study design and reporting are necessary to more accurately evaluate the usefulness of the agents in health care and identify key areas for improvement. Further research should also analyze the cost-effectiveness, privacy, and security of the agents.
C1 [Milne-Ives, Madison; de Cock, Caroline; Meinert, Edward] Univ Oxford, Dept Paediat, Digitally Enabled PrevenTat Hlth Res Grp, Oxford, England.
   [Lim, Ernest; Normando, Eduardo] Imperial Coll Healthcare NHS Trust, London, England.
   [Lim, Ernest; de Pennington, Nick; Mole, Guy] Ufonia Ltd, Oxford, England.
   [Shehadeh, Melissa Harper] Univ Geneva, Inst Global Hlth, Geneva, Switzerland.
   [de Pennington, Nick; Mole, Guy] Oxford Univ Hosp NHS Fdn Trust, Oxford, England.
   [Meinert, Edward] Imperial Coll London, Dept Primary Care & Publ Hlth, London, England.
   [Meinert, Edward] Univ Plymouth, Ctr Hlth Technol, 8 Kirkby Pl,Room 2, Plymouth PL4 6DT, Devon, England.
RP Meinert, E (corresponding author), Univ Plymouth, Ctr Hlth Technol, 8 Kirkby Pl,Room 2, Plymouth PL4 6DT, Devon, England.
EM edward.meinert@plymouth.ac.uk
OI Milne-Ives, Madison/0000-0001-7628-882X; Mole, Guy/0000-0002-9184-2531;
   Meinert, Edward/0000-0003-2484-3347; Lim, Ernest/0000-0002-6972-0511; de
   Pennington, Nick/0000-0003-4536-4978
FU Sir David Cooksey Fellowship in Healthcare Translation at the University
   of Oxford; University of Oxford
FX The authors would like to thank the outreach librarians Liz Callow
   (University of Oxford) and Kirsten Elliot (Imperial College London), for
   their assistance in developing search terms and reviewing search
   strategies. Specific funding for this work has not been acquired. EM's
   work on digital health solutions is currently supported by the Sir David
   Cooksey Fellowship in Healthcare Translation at the University of
   Oxford. The conclusions drawn in this paper were made by the authors and
   are not necessarily supported by the University of Oxford. The funding
   body had no role in the design, execution, or analysis of this
   systematic review.
CR Adams WG, 2014, PEDIATRICS, V134, pE691, DOI 10.1542/peds.2013-3759
   Bibault JE, 2019, J MED INTERNET RES, V21, DOI 10.2196/15787
   Bibault JE, 2019, CLIN TRANSL RAD ONCO, V16, P55, DOI 10.1016/j.ctro.2019.04.002
   Bickmore TW, 2010, J HEALTH COMMUN, V15, P197, DOI 10.1080/10810730.2010.499991
   Borja-Hart NL, 2019, CURR PHARM TEACH LEA, V11, P710, DOI 10.1016/j.cptl.2019.03.009
   Cameron G, 2019, LECT NOTES COMPUTER, V11551
   Campillos-Llanos L, 2020, NAT LANG ENG, V26, P183, DOI 10.1017/S1351324919000329
   Chaix B, 2019, JMIR CANCER, V5, DOI 10.2196/12856
   Chang P, 2008, CIN-COMPUT INFORM NU, V26, P31, DOI 10.1097/01.NCN.0000304754.49116.b4
   Christopoulou SC, 2018, HEALTHCARE-BASEL, V6, DOI 10.3390/healthcare6030109
   Crutzen R, 2011, J ADOLESCENT HEALTH, V48, P514, DOI 10.1016/j.jadohealth.2010.09.002
   Davenport Thomas, 2019, Future Healthc J, V6, P94, DOI 10.7861/futurehosp.6-2-94
   de Cock C, 2020, JMIR RES PROTOC, V9, DOI 10.2196/16934
   Dimeff LA, 2020, GEN HOSP PSYCHIAT, V63, P119, DOI 10.1016/j.genhosppsych.2018.05.005
   Downes MJ, 2016, BMJ OPEN, V6, DOI 10.1136/bmjopen-2016-011458
   Elmasri D, 2016, LECT NOTES ARTIF INT, V9919, P243, DOI 10.1007/978-3-319-47103-7_24
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Friederichs S, 2014, J MED INTERNET RES, V16, DOI 10.2196/jmir.2974
   Fulmer R, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/mental.9782
   Galescu L, 2009, P IEEE INT C BIBM 20, DOI [10.1109/bibmw.2009.5332111, DOI 10.1109/BIBMW.2009.5332111]
   Ghosh S, 2018, STUD HEALTH TECHNOL, V252, P51, DOI 10.3233/978-1-61499-890-7-51
   Greenhalgh T, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.8775
   Havik R, 2019, LECT NOTES COMPUT SC, V11551, P133, DOI 10.1007/978-3-030-17705-8_12
   Heyworth L, 2014, OSTEOPOROSIS INT, V25, P1519, DOI 10.1007/s00198-014-2629-1
   Higgins Julian P T, 2011, BMJ, V343, pd5928, DOI 10.1136/bmj.d5928
   Hudlicka E, 2013, PATIENT EDUC COUNS, V92, P160, DOI 10.1016/j.pec.2013.05.007
   Inkster B, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/12106
   Ireland D, 2016, STUD HEALTH TECHNOL, V227, P55, DOI 10.3233/978-1-61499-666-8-55
   Isaza-Restrepo A, 2018, BMC MED EDUC, V18, DOI 10.1186/s12909-018-1395-8
   Kocaballi AB, 2019, J MED INTERNET RES, V21, DOI 10.2196/15360
   Kojovic M, 2019, PARKINSONS DIS-US, V2019, DOI 10.1155/2019/3604372
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Luxton DD, 2020, B WORLD HEALTH ORGAN, V98, P285, DOI 10.2471/BLT.19.237636
   Ly KH, 2017, INTERNET INTERV, V10, P39, DOI 10.1016/j.invent.2017.10.002
   Meinert E, 2018, BRIT J HOSP MED, V79, P328, DOI 10.12968/hmed.2018.79.6.328
   Michie S, 2011, IMPLEMENT SCI, V6, DOI 10.1186/1748-5908-6-10
   Moher D, 2009, BMJ-BRIT MED J, V339, DOI [10.1136/bmj.i4086, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.b2535]
   Nakagawa S, 2018, INT C CLOUD COMP INT, DOI [10.1109/ccis.2018.8691360, DOI 10.1109/CCIS.2018.8691360]
   Philip P, 2017, SCI REP-UK, V7, DOI 10.1038/srep42656
   Philip P, 2015, PRESENCE-TELEOP VIRT, V23, P369, DOI 10.1162/PRES_a_00197
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Rhee H, 2014, PATIENT PREFER ADHER, V8, P63, DOI 10.2147/PPA.S53504
   Russo A, 2019, REJUV RES, V22, P109, DOI 10.1089/rej.2018.2075
   Safi S, 2018, JMIR RES PROTOC, V7, DOI 10.2196/11072
   Schardt C, 2007, BMC MED INFORM DECIS, V7, DOI 10.1186/1472-6947-7-16
   Simon SR, 2010, ARCH INTERN MED, V170, P264, DOI 10.1001/archinternmed.2009.522
   Spanig S, 2019, ARTIF INTELL MED, V100, DOI 10.1016/j.artmed.2019.101706
   Sun R, 2018, INNOV AGING, P362, DOI [10.1093/geroni/igy023.1338, DOI 10.1093/GERONI/IGY023.1338]
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   van Heerden A, 2017, 2017 INTERNATIONAL CONFERENCE ON THE FRONTIERS AND ADVANCES IN DATA SCIENCE (FADS), P90
   Washburn M, 2016, SOC WORK HEALTH CARE, V55, P675, DOI 10.1080/00981389.2016.1210715
   Weizenbaum J., 1983, Communications of the ACM, V26, P23, DOI 10.1145/357980.357991
   Wong W, 2012, J AM SOC INF SCI TEC, V63, P2313, DOI 10.1002/asi.22733
   Xing ZP, 2019, STUD HEALTH TECHNOL, V264, P1813, DOI 10.3233/SHTI190661
   Xu Roger, 2012, Stud Health Technol Inform, V173, P552
   Yasavur U, 2014, J MULTIMODAL USER IN, V8, P381, DOI 10.1007/s12193-014-0169-9
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
   Zhang Z, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P113, DOI 10.1145/3267851.3267883
NR 58
TC 23
Z9 23
U1 20
U2 72
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD OCT 22
PY 2020
VL 22
IS 10
AR e20346
DI 10.2196/20346
PG 18
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA PH3JK
UT WOS:000600313300003
PM 33090118
OA gold, Green Submitted, Green Published
DA 2022-08-02
ER

PT J
AU Wang, HL
   Zhang, QP
   Ip, M
   Lau, JTF
AF Wang, Haolin
   Zhang, Qingpeng
   Ip, Mary
   Lau, Joseph Tak Fai
TI Social Media-based Conversational Agents for Health Management and
   Interventions
SO COMPUTER
LA English
DT Article
ID SMOKING-CESSATION; NETWORK; SUPPORT
AB Conversational agents could provide timely and cost-effective social support to promote behavioral changes and improve healthcare outcomes. The authors evaluated the performance of their social media-based conversational agent in a smoking cessation program. Results showed that the presence of a conversational agent effectively increased participant engagement and enhanced their smoking cessation outcomes.
C1 [Wang, Haolin; Zhang, Qingpeng] City Univ Hong Kong, Dept Syst Engn & Engn Management, Kowloon Tong, Hong Kong, Peoples R China.
   [Zhang, Qingpeng] City Univ Hong Kong, Sch Data Sci, Kowloon Tong, Hong Kong, Peoples R China.
   [Zhang, Qingpeng] City Univ Hong Kong, Shenzhen Res Inst, Kowloon Tong, Hong Kong, Peoples R China.
   [Ip, Mary] Chinese Univ Hong Kong, Ctr Hlth Behav Res, JC Sch Publ Hlth & Primary Care, Shatin, Hong Kong, Peoples R China.
   [Lau, Joseph Tak Fai] Chinese Univ Hong Kong, JC Sch Publ Hlth & Primary Care, Shatin, Hong Kong, Peoples R China.
RP Zhang, QP (corresponding author), City Univ Hong Kong, Dept Syst Engn & Engn Management, Kowloon Tong, Hong Kong, Peoples R China.; Zhang, QP (corresponding author), City Univ Hong Kong, Sch Data Sci, Kowloon Tong, Hong Kong, Peoples R China.
EM haolin.wang@my.cityu.edu.hk; qingpeng.zhang@cityu.edu.hk;
   mitk@cuhk.edu.hk; jlau@cuhk.edu.hk
RI Wang, Haolin/Y-9005-2019; Zhang, Qingpeng/D-4682-2011
OI Wang, Haolin/0000-0002-1735-9525; Zhang, Qingpeng/0000-0002-6819-0686
FU National Natural Science Foundation of China [71672163, 71402157];
   Health and Medical Research Fund of Hong Kong SAR [12130491];
   Theme-Based Research Scheme of the Research Grants Council of Hong Kong
   SAR [T32-102/14N]
FX This work was supported by the National Natural Science Foundation of
   China (grants 71672163 and 71402157), the Health and Medical Research
   Fund of Hong Kong SAR (grant 12130491), and the Theme-Based Research
   Scheme of the Research Grants Council of Hong Kong SAR (grant
   T32-102/14N).
CR Abbasi A, 2014, IEEE INTELL SYST, V29, P60, DOI 10.1109/MIS.2014.29
   Bickmore TW, 2013, PATIENT EDUC COUNS, V92, P142, DOI 10.1016/j.pec.2013.05.011
   Christakis NA, 2008, NEW ENGL J MED, V358, P2249, DOI 10.1056/NEJMsa0706154
   Cobb NK, 2010, AM J PUBLIC HEALTH, V100, P1282, DOI 10.2105/AJPH.2009.165449
   Doll R, 2004, BMJ-BRIT MED J, V328, P1519, DOI 10.1136/bmj.38142.554479.AE
   Griol D, 2016, COGN COMPUT, V8, P336, DOI 10.1007/s12559-015-9352-x
   Kumar R, 2014, ACM T INTERACT INTEL, V3, DOI 10.1145/2499672
   Rains SA, 2009, HUM COMMUN RES, V35, P309, DOI 10.1111/j.1468-2958.2009.01353.x
   Shahab L, 2009, ADDICTION, V104, P1792, DOI 10.1111/j.1360-0443.2009.02710.x
   Uthus DC, 2013, ARTIF INTELL, V199, P106, DOI 10.1016/j.artint.2013.02.004
   Wang HL, 2017, IEEE ACCESS, V5, P7584, DOI 10.1109/ACCESS.2017.2698142
   Wang YC, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.3558
NR 12
TC 8
Z9 9
U1 1
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0018-9162
EI 1558-0814
J9 COMPUTER
JI Computer
PD AUG
PY 2018
VL 51
IS 8
BP 26
EP 33
DI 10.1109/MC.2018.3191249
PG 8
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA GR1MO
UT WOS:000442305400004
DA 2022-08-02
ER

PT C
AU Morales-Rodriguez, ML
   Pavard, B
   Gonzalez, JJ
   Martinez, JA
AF Lucila Morales-Rodriguez, Maria
   Pavard, Bernard
   Gonzalez B, Juan J.
   Martinez F, Josd A.
BE Corchado, E
   Abraham, A
   Pedrycz, W
TI Towards the Simulation of Social Interactions through Embodied
   Conversational Agents
SO HYBRID ARTIFICIAL INTELLIGENCE SYSTEMS
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 3rd International Workshop on Hybrid Artificial Intelligence Systems
CY SEP 24-26, 2008
CL Univ Burgos, Burgos, SPAIN
HO Univ Burgos
DE emotional and social interaction; situated cognition; embodied
   conversational agents; virtual therapy
AB In this paper, we present a pluridisciplinary approach in order to model the behavior of an embodied conversational agent that expresses emotional and social interactions. We present our methodology to reproduce credible social interactions. Particularly, we discuss the role of the context, the culture, and the emotions in the model of the management of speech acts. This model has been implemented in the context of virtual therapy to simulate the interaction between a therapist and a post-CVA patient.
C1 [Lucila Morales-Rodriguez, Maria; Gonzalez B, Juan J.; Martinez F, Josd A.] Inst Tecnol Ciudad Madero, Av Mayo Esq Sor Juana Ines de la Cruz S-N, Ciudad Madero Tamaulipas, Mexico.
   [Pavard, Bernard] IRIT GRIC, F-31062 Toulouse, France.
RP Morales-Rodriguez, ML (corresponding author), Inst Tecnol Ciudad Madero, Av Mayo Esq Sor Juana Ines de la Cruz S-N, Ciudad Madero Tamaulipas, Mexico.
EM lmoralesrdz@gmail.com; Pavard@irit.fr; jjgonzalezbarbosa@hotmail.com;
   jose.mtz@gmail.com
CR CASSELL J, 2000, EMBODIED CONVERSATIO, P426
   COSNIER J, 1977, PSYCHOL MED, V9, P2033
   Garfinkel H., 1967, STUDIES ETHNOMETHODO
   GARFINKEL H, 1970, THEORETICAL SOCIOLOG
   GOFFMAN E, 1974, RITES INTERACTION SE, P236
   Mantovani G, 1999, PRESENCE-TELEOP VIRT, V8, P540, DOI 10.1162/105474699566459
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   RIVA G, 1997, STUDIES HLTH TECHNOL, V44, P220
   Riva G., 2003, PRESENCE CONNECT, V3
   RODRIGUEZ MLM, 2007, THESIS U P SABATIER
   Salovey P., 1990, IMAG COGN PERS, V9, P185, DOI [DOI 10.2190/DUGG-P24E-52WK-6CDG, 10.2190/DUGG-P24E-52WK-6CDG]
   SCHEPERHUGHES N, 1987, MED ANTHROP Q, V1, P1
   SPERBER D, 1989, COMMUN COGNITION, P397
NR 13
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-540-87655-7
J9 LECT NOTES ARTIF INT
PY 2008
VL 5271
BP 551
EP +
PG 2
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BII74
UT WOS:000259875000066
DA 2022-08-02
ER

PT J
AU Lee, J
   Hwang, I
   Hubregtsen, TS
   Gattiker, AE
   Durham, CM
AF Lee, Jinho
   Hwang, Inseok
   Hubregtsen, Thomas S.
   Gattiker, Anne E.
   Durham, Christopher M.
TI Accelerating Conversational Agents Built With Off-the-Shelf Modularized
   Services
SO IEEE PERVASIVE COMPUTING
LA English
DT Article
ID SYSTEM
AB Today's common practice in developing conversational agents is pipelining off-the-shelf modularized services as ready-made building blocks. However, the discrete and sequential nature of the modules yields long response latency. We introduce Sci-Fii, a speculative inference framework accelerating conversational agent systems built with off-the-shelf modules, while keeping the modules unchanged.
C1 [Lee, Jinho; Hwang, Inseok; Hubregtsen, Thomas S.; Gattiker, Anne E.; Durham, Christopher M.] IBM Res, Austin, TX 78758 USA.
RP Lee, J (corresponding author), IBM Res, Austin, TX 78758 USA.
EM leejinho@us.ibm.com; ihwang@us.ibm.com; hubregts@us.ibm.com;
   gattiker@us.ibm.com; cdurham@us.ibm.com
CR Abowd G. D., 2000, ACM Transactions on Computer-Human Interaction, V7, P29, DOI 10.1145/344949.344988
   Ali MR, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P55
   Ghigi F, 2014, INTERSPEECH, P308
   Heintze Silvan, 2010, P 11 ANN M SPEC INT, P9
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hwang I., 2014, P 17 ACM C COMP SUPP, P1283, DOI DOI 10.1145/2531602.2531668
   KARAT CM, 2003, HUM FAC ER, P169
   Kim Y, 2014, IEEE ASME INT C ADV, P1747, DOI 10.1109/AIM.2014.6878336
   Lee J, 2017, IEEE INT CONF MOB DA, P278, DOI 10.1109/MDM.2017.45
   Lee Y., 2013, P 11 ANN INT C MOB S, P375
   Myers B., 2000, ACM Transactions on Computer-Human Interaction, V7, P3, DOI 10.1145/344949.344959
   Pitrelli JF, 2006, IEEE T AUDIO SPEECH, V14, P1099, DOI 10.1109/TASL.2006.876123
   Rendel A, 2016, INT CONF ACOUST SPEE, P5655, DOI 10.1109/ICASSP.2016.7472760
   Sagae Kenji, 2009, P 2009 ANN C N AM CH, P53
   Saon G, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3140
   Williams KE, 2015, STEVEN JANICE BROSE, P159
   Xiong W, 2017, P INT C AC SPEECH SI, P5934
   Zhang W, 2017, IEEE DATA MINING, P1195, DOI 10.1109/ICDM.2017.161
NR 18
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1536-1268
EI 1558-2590
J9 IEEE PERVAS COMPUT
JI IEEE Pervasive Comput.
PD APR-JUN
PY 2019
VL 18
IS 2
BP 47
EP 57
DI 10.1109/MPRV.2019.2907004
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA IR5KX
UT WOS:000481472600005
DA 2022-08-02
ER

PT C
AU Ramesh, K
   Ravishankaran, S
   Joshi, A
   Chandrasekaran, K
AF Ramesh, Kiran
   Ravishankaran, Surya
   Joshi, Abhishek
   Chandrasekaran, K.
BE Kaushik, S
   Gupta, D
   Kharb, L
   Chahal, D
TI A Survey of Design Techniques for Conversational Agents
SO INFORMATION, COMMUNICATION AND COMPUTING TECHNOLOGY
SE Communications in Computer and Information Science
LA English
DT Proceedings Paper
CT 2nd International Conference on Information, Communication and Computing
   Technology (ICICCT)
CY MAY 13, 2017
CL New Delhi, INDIA
SP Jagan Inst Management Studies, Dept Informat Technol
DE Pattern matching; Parsing; Markov chains; Ontologies; AIML; Chatscript;
   Recurrent neural network (RNN); Long short term memory network (LSTM);
   Sequence to sequence model (seq2seq)
AB A conversational agent also referred to as chatbot is a computer program which tries to generate human like responses during a conversation. Earlier chatbots employed much simpler retrieval based pattern matching design techniques. However, with time a number of new chatbots evolved with an aim to make it more human like and hence to pass the Turing test. Now, most of the chatbots employ generative knowledge based techniques. This paper will discuss about various chatbot design techniques, classification of chatbot and discussion on how the modern chatbots have evolved from simple pattern matching, retrieval based model to modern complex knowledge based models. A table of major conversational agents in chronological order along with their design techniques is also provided at the end of the paper.
C1 [Ramesh, Kiran; Ravishankaran, Surya; Joshi, Abhishek; Chandrasekaran, K.] Natl Inst Technol Karanataka, Dept Comp Sci & Engn, Surathkal, India.
RP Ravishankaran, S (corresponding author), Natl Inst Technol Karanataka, Dept Comp Sci & Engn, Surathkal, India.
EM aditya.kiran1995@gmail.com; surya.rad@gmail.com; joshi.abj13@gmail.com;
   kch@nitk.ac.in
OI K, Chandrasekaran/0000-0002-8855-3472
CR Ahmad S., 2007, ARTIFICIAL INTELLIGE
   Al-Zubaide H., 2011, P 2011 4 INT S INN I
   [Anonymous], 2001, ADAPT LEARN SYST SIG, DOI 10.1002/047084535X
   Batacharia B, 1999, SPRING INT SER ENG C, V511, P205
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bradesko L., 2013, SURVEY CHATBOT SYSTE
   Caputo L, 1997, FR ART INT, V41, P400
   Chowdhury GG, 2003, ANNU REV INFORM SCI, V37, P51, DOI 10.1002/aris.1440370103
   Colby K.M., 1974, ACM SIGART B, V48, P5, DOI [10.1145/1045200.1045202, DOI 10.1145/1045200.1045202]
   Denny B., 2016, DEEP LEARNING CHATBO
   Fryer L, 2006, LANG LEARN TECHNOL, V10, P8
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hutchens J. L., 1996, TR9705 U W AUSTR SCH
   Jason H, 1996, HEX CONVERSATIONAL A
   Joseph W., HIST PC THERAPIST
   Marietto M. D. G. B., 2013, ARXIV13073091
   Mauldin Michael L., 1994, AAAI, V94
   McNeal M. L., 2013, LIB TECHNOL REP, V49, P11
   Meffert K., 2006, ECBS, V6
   Mikic F. A., 2009, P EAEEIE ANN C 2009
   Mou L., 2016, ARXIV160700970
   Noy N.F., 2017, ONTOLOGY DEV 101
   Pavel S., 2016, CHATBOT ARCHITECTURE
   Shaikh S., 2010, P 2010 WORKSH COMP D, P43
   Sterrett Susan G., 2003, TURING TEST ILLUSIVE, P79
   Stoner D.J., 2004, SIMULATING MILITARY
   Sutskever I., 2014, ADV NEURAL INFORM PR
   Turing AM., 1950, J MIND ASS, V59, P433, DOI [10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   Wallace, 2003, ELEMENTS AIML STYLE, DOI 10.1.1.693.3664.
   Wallace R. S., 2009, PARSING TURING TEST, P181, DOI DOI 10.1007/978-1-4020-6710-5_13
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wilcox B., 2010, SUZETTE MOST HUMAN C
NR 32
TC 23
Z9 23
U1 2
U2 18
PU SPRINGER-VERLAG SINGAPORE PTE LTD
PI SINGAPORE
PA 152 BEACH ROAD, #21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE
SN 1865-0929
EI 1865-0937
BN 978-981-10-6544-6; 978-981-10-6543-9
J9 COMM COM INF SC
PY 2017
VL 750
BP 336
EP 350
DI 10.1007/978-981-10-6544-6_31
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BL1UU
UT WOS:000448464800031
DA 2022-08-02
ER

PT C
AU Traum, D
AF Traum, David
BE Wachsmuth, I
   Knoblich, G
TI Talking to virtual humans: Dialogue models and methodologies for
   embodied conversational agents
SO MODELLING COMMUNICATION WITH ROBOTS AND VIRTUAL HUMANS
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 2nd ZiF-Research-Group International Workshop on Embodied Communication
   in Humans and Machines
CY APR 05-08, 2006
CL Bielefeld, GERMANY
SP ZiF Res Grp
DE spoken dialogue; methodology; virtual humans; embodied conversational
   agents
AB Virtual Humans are artificial characters who look and act like humans, but inhabit a simulated environment. One important aspect of many virtual humans is their communicative dialogue ability. In this paper we outline a methodology for study of dialogue behavior and construction of virtual humans. We also consider three architectures for different types of virtual humans that have been built at the Institute for Creative Technologies.
C1 Univ So Calif, Inst Creat Technol, Los Angeles, CA 90089 USA.
RP Traum, D (corresponding author), Univ So Calif, Inst Creat Technol, Los Angeles, CA 90089 USA.
EM traum@ict.usc.edu
CR Allen James F., 1996, P 34 ANN M ASS COMP, P62, DOI DOI 10.3115/981863.981872
   ALLEN JF, 1995, IN PRESS J EXPT THEO
   ALLWOOD J, 1995, 75 GPTL U GOT
   ALLWOOD J, 1999, FONETIK 1999, V81, P5
   Cassell J., 2007, BODY LANGUAGE LESSON
   DAHLBACK N, 1993, KNOWL-BASED SYST, V6, P258, DOI 10.1016/0950-7051(93)90017-N
   Gratch J, 2002, IEEE INTELL SYST, V17, P54, DOI 10.1109/MIS.2002.1024753
   Jan D, 2005, LECT NOTES ARTIF INT, V3661, P65
   Jan D, 2007, P INT C AUT AG MULT, P59, DOI DOI 10.1145/1329125.1329142
   Larsson S., 2000, Natural Language Engineering, P323, DOI 10.1017/S1351324900002539
   Leuski A., 2006, P 7 SIGDIAL WORKSH D, P18
   LEUSKI A, 2006, P 11 INT C INT US IN, P360
   LI SY, 2007, THESIS BIELEFELD U
   OSULLIVAN C, 2002, COMPUTER GRAPHICS FO, V21
   PADILHA E, 2002, P EDILOG 2002 6 WORK, P117
   PARIS C, 1985, P 23 ANN M ASS COMP, P238
   PATEL J, 2004, P ARM SCI C
   Rickel J, 2002, IEEE INTELL SYST, V17, P32, DOI 10.1109/MIS.2002.1024750
   Traum D, 2005, LECT NOTES ARTIF INT, V3661, P52
   Traum D., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P766
   Traum D., 2005, P AAMAS WORKSH CREAT
   Traum DR, 2003, TEXT SPEECH LANG TEC, V22, P325
   TRUAM DR, 2003, P AAMAS 2003 2 INT J, P441
   Voorhees E. M., 2003, TREC, P54
NR 24
TC 10
Z9 10
U1 0
U2 2
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-540-79036-5
J9 LECT NOTES ARTIF INT
PY 2008
VL 4930
BP 296
EP 309
PG 14
WC Computer Science, Artificial Intelligence; Robotics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Robotics
GA BHP49
UT WOS:000255181500016
DA 2022-08-02
ER

PT C
AU Guichard, J
   Ruane, E
   Smith, R
   Bean, D
   Ventresque, A
AF Guichard, Jonathan
   Ruane, Elayne
   Smith, Ross
   Bean, Dan
   Ventresque, Anthony
GP IEEE
TI Assessing the Robustness of Conversational Agents using Paraphrases
SO 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE TESTING
   (AITEST)
LA English
DT Proceedings Paper
CT 1st IEEE International Conference on Artificial Intelligence Testing
   (IEEE AITest)
CY APR 04-09, 2019
CL San Francisco, CA
SP IEEE, IEEE Comp Soc, Exactpro, IBM, EduCoder NET
AB Assessing a conversational agent's understanding capabilities is critical, as poor user interactions could seal the agent's fate at the very beginning of its lifecycle with users abandoning the system. In this paper we explore the use of paraphrases as a testing tool for conversational agents. Paraphrases, which are different ways of expressing the same intent, are generated based on known working input by performing lexical substitutions. As the expected outcome for this newly generated data is known, we can use it to assess the agent's robustness to language variation and detect potential understanding weaknesses. As demonstrated by a case study, we obtain encouraging results as it appears that this approach can help anticipate potential understanding shortcomings and that these shortcomings can be addressed by the generated paraphrases.
C1 [Guichard, Jonathan; Ruane, Elayne; Ventresque, Anthony] Univ Coll Dublin, Sch Comp Sci, Dublin, Ireland.
   [Guichard, Jonathan; Ruane, Elayne; Ventresque, Anthony] Lero, Dublin, Ireland.
   [Smith, Ross; Bean, Dan] Microsoft Corp, Skype Div, Seattle, WA USA.
RP Ruane, E (corresponding author), Univ Coll Dublin, Sch Comp Sci, Dublin, Ireland.; Ruane, E (corresponding author), Lero, Dublin, Ireland.
EM elayne.ruane@ucdconnect.ie; anthony.ventresque@ucd.ie
RI Ruane, Elayne/AAW-3758-2021
OI Ventresque, Anthony/0000-0003-2064-1238; Ruane,
   Elayne/0000-0001-7344-9763
FU Science Foundation Ireland [13/RC/2094]
FX This work was supported with the financial support of the Science
   Foundation Ireland grant 13/RC/2094.
CR [Anonymous], 2010, P LREC 2010 WORKSH N
   [Anonymous], 2014, PYWSD PYTHON IMPLEME
   [Anonymous], 1998, TECHNICAL REPORT
   [Anonymous], 2013, P 2013 C N AM ASS CO
   Barzilay R, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P50
   Chen TY, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3143561
   Chklovski T, 2005, P 3 INT C KNOWL CAPT, P115, DOI DOI 10.1145/1088622.1088644
   CHRISTOPHER AV, 2014, ACL, P55
   De Smedt T, 2012, J MACH LEARN RES, V13, P2063
   Dolan W. B., 2011, P 49 ANN M ASS COMP
   Fortin FA, 2012, J MACH LEARN RES, V13, P2171
   Gupta A., 2017, ARXIV170905074
   Hassan Samer, 2007, P 4 INT WORKSH SEM E, P410
   Kurakin A., 2016, ARXIV
   Mikolov T., 2013, P 2013 C N AM CHAPTE, P746
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Napoles C., 2016, NAACL, P62
   Pavlick Ellie, 2015, PPDB 2 0 BETTER PARA
   Quirk Chris, 2004, EMNLP
   Ruane Elayne, 2018, IUI
   Shinyama Y., 2002, P 2 INT C HUM LANG T, P313
   Wei H., 2010, RES SEISMIC RESPONSE
   Zhao S., 2008, ACL, P1021
NR 23
TC 4
Z9 4
U1 1
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-0492-8
PY 2019
BP 55
EP 62
DI 10.1109/AITest.2019.000-7
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BM9GY
UT WOS:000470916100010
OA Green Published, Green Submitted
DA 2022-08-02
ER

PT J
AU Veletsianos, G
   Heller, R
   Overmyer, S
   Procter, M
AF Veletsianos, George
   Heller, Robert
   Overmyer, Scott
   Procter, Mike
TI Conversational agents in virtual worlds: Bridging disciplines
SO BRITISH JOURNAL OF EDUCATIONAL TECHNOLOGY
LA English
DT Article
ID PEDAGOGICAL AGENTS; PART I; DESIGN; ENVIRONMENTS; RECOGNITION;
   EDUCATION; FEATURES; SCIENCE; IMPACT
AB This paper examines the effective deployment of conversational agents in virtual worlds from the perspective of researchers/practitioners in cognitive psychology, computing science, learning technologies and engineering. From a cognitive perspective, the major challenge lies in the coordination and management of the various channels of information associated with conversation/communication and integrating this information with the virtual space of the environment and the belief space of the user. From computing science, the requirements include conversational competency, use of nonverbal cues, animation consistent with affective states, believability, domain competency and user adaptability. From a learning technologies perspective, the challenge is to maximise the considerable affordances provided by conversational avatars in virtual worlds balanced against ecologically valid investigations regarding utility. Finally, the engineering perspective focuses on the technical competency required to implement effective and functional agents, and the associated costs to enable student access. Taken together, the four perspectives draw attention to the quality of the agent-user interaction, how theory, practice and research are closely intertwined, and the multidisciplinary nature of this area with opportunities for cross fertilisation and collaboration.
C1 [Veletsianos, George] Univ Texas Austin, Dept Curriculum & Instruct, Instruct Technol Program, Austin, TX 78712 USA.
RP Veletsianos, G (corresponding author), Univ Texas Austin, Dept Curriculum & Instruct, Instruct Technol Program, 244 Sanchez Bldg,1 Univ Stn D5700, Austin, TX 78712 USA.
RI Overmyer, Scott/AAB-5512-2022
OI Overmyer, Scott/0000-0002-5285-1929
CR Alepis E, 2008, STUD COMPUT INTELL, V104, P9
   [Anonymous], 1989, ED RES, DOI [DOI 10.3102/0013189X018001032, 10.3102/0013189X018001032]
   Baylor A. L., 2001, Journal of Interactive Learning Research, V12, P403
   Betke M, 2002, IEEE T NEUR SYS REH, V10, P1, DOI 10.1109/TNSRE.2002.1021581
   Bradski GR, 2002, MACH VISION APPL, V13, P174, DOI 10.1007/s001380100064
   BURLESON W, 2006, THESIS MIT BOSTON
   CARRERO JJ, 2004, NUTRAFOODS, V3, P5
   Cassell J, 1999, APPL ARTIF INTELL, V13, P519, DOI 10.1080/088395199117360
   Chatham R. E., 2007, COMMUN ACM, V50, P37
   Conati C, 2002, APPL ARTIF INTELL, V16, P555, DOI 10.1080/08839510290030390
   Craig SD, 2002, J EDUC PSYCHOL, V94, P428, DOI 10.1037//0022-0663.94.2.428
   D'Mello S, 2009, APPL ARTIF INTELL, V23, P123, DOI 10.1080/08839510802631745
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   Ellaway R., 2006, ARCHITECTURAL MODEL
   Gulz A, 2006, INT J HUM-COMPUT ST, V64, P322, DOI 10.1016/j.ijhcs.2005.08.006
   Gulz A., 2004, INT J ARTIFICIAL INT, V14, P313
   HAAKE M, 2009, THESIS LUND U LUND
   Haake M, 2008, EDUC TECHNOL SOC, V11, P1
   Heller R, 2009, International Journal of Web-Based Learning and Teaching Technologies, V4, P54, DOI 10.4018/jwltt.2009010104
   HELLER R, EMERGING TE IN PRESS
   Heller RB, 2009, AM J ALZHEIMERS DIS, V24, P122, DOI 10.1177/1533317508328051
   Hershey K., 2005, J ED MULTIMEDIA HYPE, V14, P113
   Kay CD, 2006, NUTR DIS PREV, V4, P411
   Kerly A, 2007, KNOWL-BASED SYST, V20, P177, DOI 10.1016/j.knosys.2006.11.014
   KIM Y, 2006, ED TECHNOLOGY RES DE, V53, P223
   Kim Y, 2007, INT J ARTIFICIAL INT, V17, P371, DOI DOI 10.1109/TLT.2010.41
   Kirschner P, 2004, ETR&D-EDUC TECH RES, V52, P47, DOI 10.1007/BF02504675
   Kort B, 2001, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P43, DOI 10.1109/ICALT.2001.943850
   LIANG R, 2008, VIRTUAL REALITY, V12, P47
   Licsar A, 2004, LECT NOTES COMPUT SC, V3058, P83
   Mayer RE, 2003, J EDUC PSYCHOL, V95, P419, DOI 10.1037/0022-0663.95.2.419
   MAZAR R, 2008, INNOVATE, V5, P2
   Moreno R, 2002, J EDUC PSYCHOL, V94, P598, DOI 10.1037//0022-0663.94.3.598
   NIELSEN P, 2006, TECHNICAL REPORT PAR
   Norman D.A., 1988, PSYCHOL EVERYDAY THI
   NORMAN DA, 1997, SOFTWARE AGENTS, P49
   Rumelhart DE, 1986, PARALLEL DISTRIBUTED
   Santarelli Thomas P., 2003, 200310 ARI
   Sarrafzadeh A, 2008, COMPUT HUM BEHAV, V24, P1342, DOI 10.1016/j.chb.2007.07.008
   Silverman BG, 2006, PRESENCE-VIRTUAL AUG, V15, P139, DOI 10.1162/pres.2006.15.2.139
   Simonite T., 2007, EMOTION AWARE TEACHI
   Strassner J, 2005, COMPUT ANIMAT VIRT W, V16, P331, DOI 10.1002/cav.96
   Stytz MR, 2003, PRESENCE-TELEOP VIRT, V12, P311, DOI 10.1162/105474603765879558
   The Design-Based Research Collective, 2003, ED RES, V32, P5, DOI DOI 10.3102/0013189X032001005
   Veletsianos George, 2007, Journal of Educational Computing Research, V36, P373, DOI 10.2190/T543-742X-033L-9877
   Veletsianos G, 2009, J COMPUT ASSIST LEAR, V25, P345, DOI 10.1111/j.1365-2729.2009.00317.x
   VELETSIANOS G, EMERGING TE IN PRESS
   Veletsianos G, 2008, INTERACT COMPUT, V20, P292, DOI 10.1016/j.intcom.2008.02.007
   Veletsianos G, 2008, BRIT J EDUC TECHNOL, V39, P969, DOI 10.1111/j.1467-8535.2007.00797.x
   Veletsianos G, 2009, J EDUC COMPUT RES, V41, P171, DOI 10.2190/EC.41.2.c
   Waller KR, 2007, CELL PRESERV TECHNOL, V5, P132, DOI 10.1089/cpt.2007.0507
   WALLIS P, 2005, P JOINT S VIRT SOC A, P29
   Warburton S, 2009, BRIT J EDUC TECHNOL, V40, P414, DOI 10.1111/j.1467-8535.2009.00952.x
   Wu A., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P536, DOI 10.1109/AFGR.2000.840686
   Yuan X, 2005, COMPUT ANIMAT VIRT W, V16, P109, DOI 10.1002/cav.65
NR 55
TC 11
Z9 11
U1 0
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0007-1013
EI 1467-8535
J9 BRIT J EDUC TECHNOL
JI Br. J. Educ. Technol.
PD JAN
PY 2010
VL 41
IS 1
BP 123
EP 140
DI 10.1111/j.1467-8535.2009.01027.x
PG 18
WC Education & Educational Research
WE Social Science Citation Index (SSCI)
SC Education & Educational Research
GA 535TX
UT WOS:000272995500008
OA Green Submitted
DA 2022-08-02
ER

PT C
AU Ahmadvand, A
   Choi, JI
   Agichtein, E
AF Ahmadvand, Ali
   Choi, Jason Ingyu
   Agichtein, Eugene
GP ACM
TI Contextual Dialogue Act Classification for Open-Domain Conversational
   Agents
SO PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH
   AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19)
LA English
DT Proceedings Paper
CT 42nd Annual International ACM SIGIR Conference on Research and
   Development in Information Retrieval (SIGIR)
CY JUL 21-25, 2019
CL Paris, FRANCE
SP Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval
AB Classifying the general intent of the user utterance in a conversation, also known as Dialogue Act (DA), e.g., open-ended question, statement of opinion, or request for an opinion, is a key step in Natural Language Understanding (NLU) for conversational agents. While DA classification has been extensively studied in human-human conversations, it has not been sufficiently explored for the emerging open-domain automated conversational agents. Moreover, despite significant advances in utterance-level DA classification, full understanding of dialogue utterances requires conversational context. Another challenge is the lack of available labeled data for open-domain human-machine conversations. To address these problems, we propose a novel method, CDAC (Contextual Dialogue Act Classifier), a simple yet effective deep learning approach for contextual dialogue act classification. Specifically, we use transfer learning to adapt models trained on human-human conversations to predict dialogue acts in human-machine dialogues. To investigate the effectiveness of our method, we train our model on the well-known Switchboard human-human dialogue dataset, and fine-tune it for predicting dialogue acts in human-machine conversation data, collected as part of the Amazon Alexa Prize 2018 competition. The results show that the CDAC model outperforms an utterance-level state of the art baseline by 8.0% on the Switchboard dataset, and is comparable to the latest reported state-of-the-art contextual DA classification results. Furthermore, our results showthat fine-tuning the CDAC model on a small sample of manually labeled human-machine conversations allows CDAC to more accurately predict dialogue acts in real users' conversations, suggesting a promising direction for future improvements.
C1 [Ahmadvand, Ali; Choi, Jason Ingyu; Agichtein, Eugene] Emory Univ, Comp Sci Dept, Atlanta, GA 30322 USA.
RP Ahmadvand, A (corresponding author), Emory Univ, Comp Sci Dept, Atlanta, GA 30322 USA.
EM ali.ahmadvand@emory.edu; in.gyu.choi@emory.edu;
   eugene.agichtein@emory.edu
CR Blunsom P., 2013, P WORKSH CONT VECT S
   Bothe Chandrakant, 2018, ARXIV180506280
   Chen RC, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1017, DOI 10.1145/3077136.3080705
   Chung Y.-A., 2017, P NAACL HLT
   Grau S., 2004, P C SPEECH COMP
   Jurafsky Daniel, 1997, TECHNICAL REPORT
   Khatri C., 2018, P SLT
   Kumar H., 2018, P AAAI
   Lee J. Y., 2016, ARXIV160303827
   Liu Y., 2017, P 2017 C EMP METH NA, P2170
   Mou Lili, 2016, P EMNLP
   Pareti S., 2018, P LREC
   Stolcke A, 2000, COMPUT LINGUIST, V26, P339, DOI 10.1162/089120100561737
   Wang J, 2017, P IJCAI
NR 14
TC 13
Z9 13
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6172-9
PY 2019
BP 1273
EP 1276
DI 10.1145/3331184.3331375
PG 4
WC Computer Science, Information Systems; Information Science & Library
   Science
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Information Science & Library Science
GA BO1LU
UT WOS:000501488900192
OA Green Submitted
DA 2022-08-02
ER

PT S
AU Sansonnet, JP
   Leray, D
   Martin, JC
AF Sansonnet, Jean-Paul
   Leray, David
   Martin, Jean-Claude
BE Gratch, J
   Young, M
   Aylett, R
   Ballin, D
   Olivier, P
TI Architecture of a framework for generic assisting conversational agents
SO INTELLIGENT VIRTUAL AGENTS, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 6th International Conference on Intelligent Virtual Agents
CY AUG 21-23, 2006
CL Marina del Rey, CA
SP Univ SE Calif, Inst Creat Technol, HUMAINE Network, Boston Dynam Inc, Soar Technol Inc, Elect Arts, AAAI, European Assoc Com Graph, ACM SIGART, ACM SIGGRAPH, ACM SIGCHI
AB In this paper, we focus on the notion of Assisting Conversational Agents (ACA) that are embodied agents dedicated to the function of assistance for novice users of software components and/or web services. We discuss the main requirements of such agents and we emphasize the genericity issue arising in the dialogical part of such architectures. This prompts us to propose a mediator-based framework, using a dynamic symbolic representation of the runtime of the assisted components. Then we define three strategies for the development of the mediators that are validated by the implementation of experiences taken in various situations.
C1 CNRS, LIMSI, F-91403 Orsay, France.
RP Sansonnet, JP (corresponding author), CNRS, LIMSI, BP 133, F-91403 Orsay, France.
EM jps@limsi.fr; leray@limsi.fr; martin@limsi.fr
CR ABRILLIAN S, 2003, ICMI 03
   ALLEN J, 2001, CONVERSATIONAL HUMAN
   BLANC X, 2004, MODFACT TOOL U EUR W
   BUISINE S, 2003, P WORKSH EMB CONV AG
   BYRON DK, 2002, P DAARC2002
   Cassell J., 2000, EMBODIED CONVERSATIO
   Cassell J., 1999, P SIGCHI C HUM FACT, P520, DOI DOI 10.1145/302979.303150
   COSI P, 2005, INT VIRT AG C KOS GR
   FERGUSSON G, 1996, P C ART INT PLANN SY
   FERGUSSON G, 1998, P 15 NAT C ART INT A
   Kopp S, 2002, COMP ANIM CONF PROC, P252, DOI 10.1109/CA.2002.1017547
   KOPP S, 2004, J COMPUPTER ANIMATIO, V15
   LESTER, 1997, PERSONA EFFECT AFFEC
   MAES P, 1994, COMMUNICATIONS ACM, V37
   MARTIN A, 2005, MAINT ID DYN EMB AG
   McCarthy J., 1969, MACH INTELL, V4, P463, DOI DOI 10.1016/B978-0-934613-03-3.50033-7
   Pearl J, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1437
   Pelachaud Catherine, 2000, INT C AUT AG BARC
   RAO AS, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P473
   Searle J., 1969, SPEECH ACTS
   Thorisson K. R., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P653
   TRAUM D, 2005, 5 INT WORK C INT VIR
   WAHLSTER W, 2001, P EUROSPEECH 2001
   Wooldridge M, 2000, REASONING RATIONAL A
   [No title captured]
NR 25
TC 8
Z9 8
U1 0
U2 2
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-37593-7
J9 LECT NOTES ARTIF INT
PY 2006
VL 4133
BP 145
EP 156
PG 12
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BEZ35
UT WOS:000240268400012
DA 2022-08-02
ER

PT J
AU Su, ZY
   Schneider, JA
   Young, SD
AF Su, Zhaoyuan
   Schneider, John A.
   Young, Sean D.
TI The Role of Conversational Agents for Substance Use Disorder in Social
   Distancing Contexts
SO SUBSTANCE USE & MISUSE
LA English
DT Editorial Material
DE Conversational agent; substance use; addiction; public health
ID HEALTH LITERACY; MENTAL-HEALTH
AB The COVID-19 pandemic and its related policies, such as social distancing orders, are affecting the ability for people with substance use disorders (SUD) to seek prevention and treatment. In this commentary, we introduce conversational agents, a type of social technology. We discuss the role of conversational agents in the prevention and treatment of SUD in social distancing contexts and the potential benefits and limitations of designing and implementing such technology in the prevention and care for patients with SUD.
C1 [Su, Zhaoyuan; Young, Sean D.] Univ Calif Irvine, Dept Informat, Irvine, CA USA.
   [Schneider, John A.] Univ Chicago, Dept Med, 5841 S Maryland Ave, Chicago, IL 60637 USA.
   [Young, Sean D.] Univ Calif Irvine, Dept Emergency Med, Irvine, CA USA.
RP Young, SD (corresponding author), Univ Calif Irvine, Dept Informat, Inst Predict Technol, 6091 Bren Hall, Irvine, CA 92697 USA.
EM syoung5@hs.uci.edu
FU National Institute of Allergy and Infectious Diseases [1R01AI132030-01];
   National Center for Complementary and Integrative Health [1R33AT010606,
   U2C DA050098]
FX This work was funded by the National Institute of Allergy and Infectious
   Diseases (grant #1R01AI132030-01), National Center for Complementary and
   Integrative Health (grant #1R33AT010606), and National Institute on Drug
   Abuse U2C DA050098.
CR Alexander GC, 2020, ANN INTERN MED, V173, P57, DOI 10.7326/M20-1141
   Bhatia P., 2020, WHY CONVERSATIONAL W
   Bickmore TW, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5239
   Birtel MD, 2017, PSYCHIAT RES, V252, P1, DOI 10.1016/j.psychres.2017.01.097
   Coronavirus Disease (CDC), 2020, COVID 19 SYMPT
   Crutzen R, 2011, J ADOLESCENT HEALTH, V48, P514, DOI 10.1016/j.jadohealth.2010.09.002
   Degan TJ, 2019, J SUBST ABUSE TREAT, V96, P46, DOI 10.1016/j.jsat.2018.10.009
   Fadhil, 2020, ARXIV180306000CS
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Kocielnik Rafal, 2019, AMIA Annu Symp Proc, V2019, P552
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lincoln A, 2006, J GEN INTERN MED, V21, P818, DOI 10.1111/j.1525-1497.2006.00533.x
   Lipari R.N., 2019, KEY SUBSTANCE USE ME, P82
   Lord S, 2016, JMIR MENT HEALTH, V3, DOI 10.2196/mental.4927
   Md P.G., 2020, HARVARD HLTH BL 0420
   Miner AS, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0280-0
   Palanica A, 2019, J MED INTERNET RES, V21, DOI 10.2196/12887
   Quello Susan B, 2005, Sci Pract Perspect, V3, P13
   Rehm J, 2018, EUR ADDICT RES, V24, P53, DOI 10.1159/000488328
   Saloner B, 2013, HEALTH AFFAIR, V32, P135, DOI 10.1377/hlthaff.2011.0983
   Su Zhaoyuan, 2020, AMIA Annu Symp Proc, V2020, P1170
   University of Sydney, 2020, U SYDN BUILDS AI INF
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   WHO, 2020, WHO LAUNCH CHATB FAC
   WHO, 2020, HLTH AL BRINGS COVID
   Young SD, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e03471
   Young SD, 2017, J SUBST USE, V22, P592, DOI 10.1080/14659891.2016.1271039
   Young SD, 2013, J ADDICT DIS, V32, P39, DOI 10.1080/10550887.2012.759859
NR 28
TC 1
Z9 1
U1 2
U2 4
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 1082-6084
EI 1532-2491
J9 SUBST USE MISUSE
JI Subst. Use Misuse
PD JUN 30
PY 2021
VL 56
IS 11
BP 1732
EP 1735
DI 10.1080/10826084.2021.1949609
EA JUN 2021
PG 4
WC Substance Abuse; Psychiatry; Psychology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Substance Abuse; Psychiatry; Psychology
GA TU8EV
UT WOS:000675301800001
PM 34286669
DA 2022-08-02
ER

PT J
AU Paschoal, LN
   Conte, TU
   de Souza, SDS
AF Paschoal, Leo Natan
   Conte, Tayana Uchoa
   Senger de Souza, Simone do Rocio
TI On the Experimental Process in Evaluations of Brazilian Conversational
   Agents in Education
SO IEEE REVISTA IBEROAMERICANA DE TECNOLOGIAS DEL APRENDIZAJE-IEEE RITA
LA English
DT Article
DE Education; Systematics; Planning; Measurement; Search problems; Data
   analysis; Guidelines; Chatbot; chatterbot; systematic mapping
AB Conversational agents represent applications that interact in a natural language with humans. Due to their ability to process the human language, they have been explored in diverse areas, e.g., e-commerce, health, entertainment, and education. Particularly in the education field, they have been used as mechanisms that support the teaching of a second language, that recommend educational resources, and that resolve students' doubts, as a learning partner. Brazil is particularly interested in the educational technology community studying such software systems. Despite the strong interests in their development, few studies have addressed the impact such systems exert when they are used by students. Experimental studies have enabled a better understanding of the impact of technology on education based on evidence. This article presents an overview of empirical research on conversational agents in education through a mapping of the Brazilian community, identifying the way researchers systematically evaluate such agents produced in their research work. The results show a lack of experimental methodologies and taxonomies that support the planning, development, and reporting of experimental studies. However, a set of variables commonly employed has been recognized. An initial set of guidelines has been developed towards guiding experiments in this context and supporting the systematization of studies on experimental evaluations of pedagogical conversational agents.
C1 [Paschoal, Leo Natan; Senger de Souza, Simone do Rocio] Univ Sao Paulo, Inst Math & Comp Sci ICMC, BR-13566590 Sao Carlos, Brazil.
   [Conte, Tayana Uchoa] Fed Univ Amazonas UFAM, Inst Comp IComp, BR-69080900 Manaus, Amazonas, Brazil.
RP Paschoal, LN (corresponding author), Univ Sao Paulo, Inst Math & Comp Sci ICMC, BR-13566590 Sao Carlos, Brazil.
EM paschoalln@usp.br; tayana@icomp.ufam.edu.br; srocio@icmc.usp.br
OI Souza, Simone Senger/0000-0001-9007-9821
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES)
   [001]; Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP)
   [2018/26636-2]; Conselho Nacional de Desenvolvimento Cientifico e
   Tecnologico (CNPq) [314174/2020-6, 312922/2018-3]
FX This work was supported in part by Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior (CAPES)-Finance Code 001, in part by Fundacao
   de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP) under Grant
   2018/26636-2, and in part by Conselho Nacional de Desenvolvimento
   Cientifico e Tecnologico (CNPq) under Grant 314174/2020-6 and Grant
   312922/2018-3.
CR AbuShawar B, 2016, INT J SPEECH TECHNOL, V19, P373, DOI 10.1007/s10772-015-9330-4
   Aguiar E. V. B., 2011, THESIS FEDERAL U RIO
   Allua Shane, 2009, Air Med J, V28, P168, DOI 10.1016/j.amj.2009.04.013
   Ayedoun E, 2019, INT J ARTIF INTELL E, V29, P29, DOI 10.1007/s40593-018-0171-6
   Basili V. R., 1994, ENCY SOFTWARE ENG, V2, P232
   BASILI VR, 1988, IEEE T SOFTWARE ENG, V14, P758, DOI 10.1109/32.6156
   Bernardini A.A., 2018, WORKSHOP ADV VIRTUAL, V1, P1
   Campos C. C. M. P., 2002, THESIS FEDERAL U SAN
   Castanho C. L. O., 2002, THESIS FEDERAL U SAN
   Conradi R., 2001, 1 U MAR, V1
   Coronado M, 2018, INT J HUM-COMPUT ST, V117, P55, DOI 10.1016/j.ijhcs.2018.02.004
   Domingues M. J. C. S., 2003, THESIS FEDERAL U SAN
   Dyba T, 2008, INFORM SOFTWARE TECH, V50, P833, DOI 10.1016/j.infsof.2008.01.006
   Graesser AC, 2017, COMPUT HUM BEHAV, V76, P607, DOI 10.1016/j.chb.2017.03.041
   Hobert S., 2019, LECT NOTES INFORMAT, P259
   Kerly A, 2009, APPLICATIONS AND INNOVATIONS IN INTELLIGENT SYSTEMS XVI, P169
   Kitchenham B., 2007, 23 KEEL U U DURH
   Krassmann A., 2017, P AN 28 S BRAS INF E, P71
   Kuri R, 2017, INT J INF DISSEMINAT, V7, P14
   Kuyven N. L., 2018, REV NOVAS TECNOLOGIA, V16, P123
   Leite I. D. C., 2010, THESIS FEDERAL U PER
   Lemos E. C., 2011, THESIS FEDERAL U RIO
   Leonhardt M. D., 2005, THESIS FEDERAL U RIO
   Lima L. A., 2014, THESIS FEDERAL U MIN
   Lin LJ, 2013, COMPUT EDUC, V67, P239, DOI 10.1016/j.compedu.2013.04.017
   Melo SM, 2019, INFORM SOFTWARE TECH, V105, P226, DOI 10.1016/j.infsof.2018.08.017
   de Franca BBN, 2016, EMPIR SOFTW ENG, V21, P1302, DOI 10.1007/s10664-015-9386-4
   Oliveira E. A., 2008, THESIS FEDERAL U PER
   Paschoal L.N., 2019, P 33 BRAZ S SOFTW EN, P57
   Paschoal L. N., 2019, U SAO PAULO SAO CARL
   Paschoal LN, 2020, PROC FRONT EDUC CONF
   Paschoal LN, 2018, 2018 XLIV LATIN AMERICAN COMPUTER CONFERENCE (CLEI 2018), P839, DOI 10.1109/CLEI.2018.00105
   Petersen K., 2008, P 12 INT C EV ASS SO, V12, P1
   Pinho I. C., 2015, THESIS FEDERAL U RIO
   Radziwill N.M., 2017, ARXIV170404579
   Ranoliya BR, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1525, DOI 10.1109/ICACCI.2017.8126057
   Roos S., 2018, THESIS UPPSALA U UPP
   Ruane E, 2018, COMPANION OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'18), DOI 10.1145/3180308.3180373
   Santos L. M. A., 2009, THESIS FEDERAL U RIO
   Sgobbi F. S., 2017, THESIS FEDERAL U RIO
   Shepperd M, 2018, INFORM SOFTWARE TECH, V99, P120, DOI 10.1016/j.infsof.2018.01.006
   Shull F., 2007, GUIDE ADV EMPIRICAL
   Tamayo-Moreno S., 2016, P INT S COMP ED SIIE, P1
   Troussas C, 2017, PROC INT C TOOLS ART, P1153, DOI 10.1109/ICTAI.2017.00176
   Winkler R., 2018, ACAD MANAGEMENT ANN
   Wohlin C., 2012, EXPT SOFTWARE ENG
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
NR 47
TC 0
Z9 0
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
EI 1932-8540
J9 IEEE REV IBEROAM TEC
JI IEEE Rev. Iberoam. Tecnol Aprendiz.
PD FEB
PY 2022
VL 17
IS 1
BP 99
EP 107
DI 10.1109/RITA.2022.3149776
PG 9
WC Computer Science, Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA ZU6XH
UT WOS:000769983800014
DA 2022-08-02
ER

PT C
AU Schuetzler, RM
   Giboney, JS
   Grimes, GM
   Nunamaker, JF
AF Schuetzler, Ryan M.
   Giboney, Justin Scott
   Grimes, G. Mark
   Nunamaker, Jay F., Jr.
BE Bui, TX
TI The Influence of Conversational Agents on Socially Desirable Responding
SO PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM
   SCIENCES (HICSS)
LA English
DT Proceedings Paper
CT 51st Annual Hawaii International Conference on System Sciences (HICSS)
CY JAN 02-06, 2018
CL HI
SP Pacific Res Inst Informat Syst & Management, Shidler Coll Business, IBM, Bizgenics Fdn, Arizona Eller, AIS, Baylor Business Informat Syst, Int Soc Serv Innovat, St Johns Univ, Coll Profess Studies, Syracuse Univ, Sch Informat Stud
ID SELF-DISCLOSURE; SENSITIVE QUESTIONS; BINGE DRINKING; ALCOHOL; MODE;
   COMPUTERS; HUMANS; TRUST; BIAS; IVR
AB Conversational agents (CAs) are becoming an increasingly common component in many information systems. The ubiquity of CAs in cell phones, entertainment systems, and messaging applications has led to a growing need to understand how design choices made when developing CAs influence user interactions. In this study, we explore the use case of CAs that gather potentially sensitive information from people-for example, in a medical interview. Using a laboratory experiment, we examine the influence of CA responsiveness and embodiment on the answers people give in response to sensitive and non-sensitive questions. The results show that for sensitive questions, the responsiveness of the CA increased the social desirability of the responses given by participants.
C1 [Schuetzler, Ryan M.] Univ Nebraska Omaha, Omaha, NE 68182 USA.
   [Giboney, Justin Scott] Brigham Young Univ, Provo, UT 84602 USA.
   [Grimes, G. Mark] Univ Houston, Houston, TX 77004 USA.
   [Nunamaker, Jay F., Jr.] Univ Arizona, Tucson, AZ 85721 USA.
RP Schuetzler, RM (corresponding author), Univ Nebraska Omaha, Omaha, NE 68182 USA.
EM rschuetzler@unomaha.edu; justin_giboney@byu.edu; gmgrimes@bauer.uh.edu;
   jnunamaker@cmi.arizona.edu
RI Schuetzler, Ryan/AAH-9868-2020
OI Schuetzler, Ryan/0000-0002-5807-2168
FU National Science Foundation [1068026]; Nebraska Research Initiative
FX This research was supported by the National Science Foundation under
   Grant No. 1068026, and by the Nebraska Research Initiative.
CR Adams SA, 2005, AM J EPIDEMIOL, V161, P389, DOI 10.1093/aje/kwi054
   [Anonymous], 2010, P ECCE2010 WORKSH CO
   Bente G, 2008, HUM COMMUN RES, V34, P287, DOI 10.1111/j.1468-2958.2008.00322.x
   Bottles K., 2011, WILL PATIENTS TRUST
   COLBY KM, 1972, ARTIF INTELL, V3, P199, DOI 10.1016/0004-3702(72)90049-5
   CROWNE DP, 1960, J CONSULT PSYCHOL, V24, P349, DOI 10.1037/h0047358
   Davis CG, 2010, ADDICT BEHAV, V35, P302, DOI 10.1016/j.addbeh.2009.11.001
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Gefen D, 2004, OMEGA-INT J MANAGE S, V32, P407, DOI 10.1016/j.omega.2004.01.006
   Holtgraves TM, 2007, COMPUT HUM BEHAV, V23, P2163, DOI 10.1016/j.chb.2006.02.017
   Kreuter F, 2008, PUBLIC OPIN QUART, V72, P847, DOI 10.1093/poq/nfn063
   Krysan M, 2003, SOC PSYCHOL QUART, V66, P364, DOI 10.2307/1519835
   Lind LH, 2013, PUBLIC OPIN QUART, V77, P888, DOI 10.1093/poq/nft038
   LINEHAN MM, 1981, J CONSULT CLIN PSYCH, V49, P773, DOI 10.1037/0022-006X.49.5.773
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   MCCRAE RR, 1983, J CONSULT CLIN PSYCH, V51, P882, DOI 10.1037/0022-006X.51.6.882
   Moon Y, 2000, J CONSUM RES, V26, P323, DOI 10.1086/209566
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Naimi TS, 2003, JAMA-J AM MED ASSOC, V289, P70, DOI 10.1001/jama.289.1.70
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   NEDERHOF AJ, 1985, EUR J SOC PSYCHOL, V15, P263, DOI 10.1002/ejsp.2420150303
   Nunamaker JE, 2011, J MANAGE INFORM SYST, V28, P17, DOI 10.2753/MIS0742-1222280102
   O'Brien T, 2016, KOTUITUI, V11, P11, DOI 10.1080/1177083X.2015.1012170
   PARKER EB, 1978, CONTEMP SOCIOL, V7, P32, DOI 10.2307/2065899
   PEARCE WB, 1973, J COMMUN, V23, P409, DOI 10.1111/j.1460-2466.1973.tb00958.x
   PERKINS HW, 1986, INT J ADDICT, V21, P961, DOI 10.3109/10826088609077249
   Pickard M.D., 2012, PERSUASIVE EMBODIED
   Pickard MD, 2016, COMPUT HUM BEHAV, V65, P23, DOI 10.1016/j.chb.2016.08.004
   Pickard MD, 2013, J INF SYST, V27, P159, DOI 10.2308/isys-50561
   Posey C, 2010, EUR J INFORM SYST, V19, P181, DOI 10.1057/ejis.2010.15
   Reeves B., 2003, MEDIA EQUATION PEOPL
   Richman WL, 1999, J APPL PSYCHOL, V84, P754, DOI 10.1037/0021-9010.84.5.754
   Sakshaug JW, 2010, PUBLIC OPIN QUART, V74, P907, DOI 10.1093/poq/nfq057
   Sproull L, 1996, HUM-COMPUT INTERACT, V11, P97, DOI 10.1207/s15327051hci1102_1
   Tinwell A, 2011, COMPUT HUM BEHAV, V27, P741, DOI 10.1016/j.chb.2010.10.018
   Tourangeau R, 1996, PUBLIC OPIN QUART, V60, P275, DOI 10.1086/297751
   Tourangeau R, 2003, COMPUT HUM BEHAV, V19, P1, DOI 10.1016/S0747-5632(02)00032-8
   Tourangeau R, 2007, PSYCHOL BULL, V133, P859, DOI 10.1037/0033-2909.133.5.859
   WALKER JH, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P85
   Wallace R. S., 2004, ANATOMY ALICE
   Wechsler H, 2002, J AM COLL HEALTH, V50, P203, DOI 10.1080/07448480209595713
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wilcox B., 2017, CHATSCRIPT
   Yaghoubzadeh Ramin, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P79, DOI 10.1007/978-3-642-40415-3_7
NR 45
TC 10
Z9 10
U1 0
U2 2
PU HICSS
PI Honolulu
PA Dept IT Mgmt, Shidler College of Business, Univ Hawaii at Manoa 2404
   Maile Way D307, Honolulu, Hawaii, UNITED STATES
BN 978-0-9981331-1-9
PY 2018
BP 283
EP 292
PG 10
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ9JN
UT WOS:000625208500037
DA 2022-08-02
ER

PT C
AU Reinhardt, J
   Hillen, L
   Wolf, K
AF Reinhardt, Jens
   Hillen, Luca
   Wolf, Katrin
GP Assoc Comp Machinery
TI Embedding Conversational Agents into AR: Invisible or with a Realistic
   Human Body?
SO TEI'20: PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON
   TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION
LA English
DT Proceedings Paper
CT 14th International Conference on Tangible, Embedded, and Embodied
   Interaction (TEI)
CY FEB 09-12, 2020
CL Sydney, AUSTRALIA
SP ACM SIGCHI, Assoc Comp Machinery
DE embodied conversational agents; intelligent virtual assistants;
   augmented reality; avatars
ID VIRTUAL CHARACTERS; APPEARANCE; USABILITY; UNCANNY
AB Currently, (invisible) smart speech assistants, such as Siri, Alexa, and Cortana, are used by a constantly growing number of people. Moreover, Augmented Reality (AR) glasses are predicted to become widespread consumer devices in the future. Hence, smart assistants can easily become common applications of AR glasses, which allows for giving the assistant a visual representation as an embodied agent. While previous research on embodied agents found a user preference for a humanoid appearance, research on the uncanny valley suggests that simply designed humanoids can be favored over hyper-realistic humanoid characters. In a user study, we compared agents of simple versus more realistic appearance (seen through AR glasses) versus an invisible state-of-the-art speech assistants (see Figure 1). Our results indicate that a more realistic visualization is preferred as it provides additional communication cues, such as eye contact and gaze, which seem to be key features when talking to a smart assistant. But if the situation requires visual attention, e.g., when being mobile or in a multitask situation, an invisible agent can be more appropriate as they do not distract the visual focus, which can be essential during AR experiences.
C1 [Reinhardt, Jens; Hillen, Luca; Wolf, Katrin] Hamburg Univ Appl Sci, Hamburg, Germany.
RP Reinhardt, J (corresponding author), Hamburg Univ Appl Sci, Hamburg, Germany.
EM jens.reinhardt@haw-hamburg.de; luca.hillen@haw-hamburg.de;
   katrin.wolf@haw-hamburg.de
FU German Ministry of Education and Research (BMBF) [01JKD1701B]
FX This work is supported by the German Ministry of Education and Research
   (BMBF) within the GEVAKUB project (01JKD1701B).
CR Anabuki M., 2000, P CHI 2000 HUM FACT, P10, DOI DOI 10.1145/633292.633299
   Andrist S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2571, DOI 10.1145/3025453.3026033
   [Anonymous], 2018, INTERACTIONS, DOI DOI 10.1145/3236673
   [Anonymous], 2010, ACM SIGGRAPH ASIA 20, DOI DOI 10.1145/1899950.1899991
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Balcisoy S, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P303, DOI 10.1109/CGI.2000.852346
   Brenton H., 2005, 19 BRIT HCI GROUP AN
   Brooke J., 1996, SUS A QUICK DIRTY US
   Cassell J, 2000, EMBODIED CONVERSATIONAL AGENTS, P1
   Cowell AJ, 2003, LECT NOTES ARTIF INT, V2792, P301
   Fabri M, 2007, LECT NOTES COMPUT SC, V4552, P275
   Forlizzi Jodi, 2007, P 2007 C DES PLEAS P, P209
   Geven A., 2006, P 4 NORD C HUM COMP, P135, DOI [10.1145/1182475.1182490, DOI 10.1145/1182475.1182490]
   Hassenzahl M, 2010, HUM-COMPUT INTERACT, V25, P235, DOI 10.1080/07370024.2010.500139
   Hassenzahl Marc, 2003, MENSCH COMPUTER
   Ivo van Es, 2002, P WORK C ADV VIS INT, P357, DOI [10.1145/1556262.1556320, DOI 10.1145/1556262.1556320]
   Koda T, 1996, RO-MAN '96 - 5TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P189, DOI 10.1109/ROMAN.1996.568812
   Kramer NC, 2007, LECT NOTES ARTIF INT, V4722, P238
   McBreen H., 2000, Proceedings of the Fourth International Conference on Autonomous Agents, P39, DOI 10.1145/336595.336968
   McBreen HM, 2001, IEEE T SYST MAN CY A, V31, P394, DOI 10.1109/3468.952714
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Milgram P., 2009, MIXED REALITY, P10, DOI [10.1145/1643928.1643932, DOI 10.1145/1643928.1643932]
   Miyake S., 2012, P 2012 AS PAC SIGN I, P1
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Mousas C, 2018, COMPUT HUM BEHAV, V86, P99, DOI 10.1016/j.chb.2018.04.036
   Niculescu A, 2010, Proceedings of the 2010 International Conference on User Science and Engineering (i-USEr 2010), P16, DOI 10.1109/IUSER.2010.5716715
   Ruhland K, 2015, COMPUT GRAPH FORUM, V34, P299, DOI 10.1111/cgf.12603
   Schrammel J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1187
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006
   Schwind V., 2015, P 2015 ANN S COMP HU, DOI [10.1145/2793107.2793116, DOI 10.1145/2793107.2793116]
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1992, PHILOS T ROY SOC B, V335, P71, DOI 10.1098/rstb.1992.0009
   Thompson C., 2005, WIRED
   Tinwell A, 2009, LECT NOTES COMPUT SC, V5621, P622, DOI 10.1007/978-3-642-02774-1_67
   Wagner D., 2006, REAL SHOULD VIRTUAL, DOI [10.1145/1178823.1178891, DOI 10.1145/1178823.1178891]
   Wang I, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300511
   Waters K., 1996, P 1996 ACM C COMP SU, P399, DOI DOI 10.1145/240080.240351
   Yee N, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1
   Zibrek K, 2018, IEEE T VIS COMPUT GR, V24, P1681, DOI 10.1109/TVCG.2018.2794638
   Zimmerman J, 2005, DES PLEAS PROD INT 2, P233, DOI [10.1184/R1/6470366.v1, DOI 10.1184/R1/6470366.V1]
   [No title captured]
NR 41
TC 0
Z9 0
U1 1
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6107-1
PY 2020
BP 299
EP 310
DI 10.1145/3374920.3374956
PG 12
WC Computer Science, Cybernetics; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP9OI
UT WOS:000570009800027
DA 2022-08-02
ER

PT J
AU Pacheco-Lorenzo, MR
   Valladares-Rodriguez, SM
   Anido-Rifon, LE
   Fernandez-Iglesias, MJ
AF Pacheco-Lorenzo, Moises R.
   Valladares-Rodriguez, Sonia M.
   Anido-Rifon, Luis E.
   Fernandez-Iglesias, Manuel J.
TI Smart conversational agents for the detection of neuropsychiatric
   disorders: A systematic review
SO JOURNAL OF BIOMEDICAL INFORMATICS
LA English
DT Review
DE Conversational agent; Virtual assistant; Mental disorder; Depression;
   Dementia; Detection; Diagnosis
ID DEPRESSION; DISEASE
AB Objective: To determine whether smart conversational agents can be used for detection of neuropsychiatric disorders. Therefore, we reviewed the technologies used, targeted mental disorders and validation procedures of relevant proposals in this field.
   Methods: We searched Scopus, PubMed, Pro-Quest, IEEE Xplore, Web of Science, CINAHL and the Cochrane Library using a predefined search strategy. Studies were included if they focused on neuropsychiatric disorders and involved conversational data for detection and diagnosis. They were assessed for eligibility by independent reviewers and ultimately included if a consensus was reached about their relevance.
   Results: 2356 references were initially retrieved. Eventually, 17 articles - referring 9 smart conversational agents - met the inclusion criteria. Out of the selected studies, 7 are targeted at neurocognitive disorders, 7 at depression and 3 at other conditions. They apply diverse technological solutions and analysis techniques (82.4% use Artificial Intelligence), and they usually rely on gold standard tests for criterion validity assessment. Acceptability, reliability and other aspects of validity were rarely addressed.
   Conclusion: The use of smart conversational agents for the detection of neuropsychiatric disorders is an emerging and promising field of research, with a broad coverage of mental disorders and extended use of AI. However, the few published studies did not undergo robust psychometric validation processes. Future research in this field would benefit from more rigorous validation mechanisms and standardized software and hardware platforms.
C1 [Pacheco-Lorenzo, Moises R.; Valladares-Rodriguez, Sonia M.; Anido-Rifon, Luis E.; Fernandez-Iglesias, Manuel J.] Univ Vigo, Escola Enxenaria Telecomunicac, Dept Telemat Engn, Campus Lagoas Marcosende, Vigo 36310, Spain.
RP Pacheco-Lorenzo, MR (corresponding author), Univ Vigo, Escola Enxenaria Telecomunicac, Dept Telemat Engn, Campus Lagoas Marcosende, Vigo 36310, Spain.
EM moises.pacheco@gist.uvigo.es
RI Anido-Rifón, Luis/D-4597-2018; Anido-Rifón, Luis/ABI-6838-2020;
   Fernandez Iglesias, Manuel Jose/I-1695-2013
OI Anido-Rifón, Luis/0000-0003-2780-2727; Anido-Rifón,
   Luis/0000-0003-2780-2727; Fernandez Iglesias, Manuel
   Jose/0000-0003-4462-8724; Pacheco Lorenzo, Moises/0000-0002-0424-8850
CR Abd-alrazaq AA, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103978
   Agarwal S, 2010, TELEMED J E-HEALTH, V16, P603, DOI 10.1089/tmj.2009.0165
   American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU, V5th ed., DOI [https://doi.org/10.1176/appi.books.9780890425596, DOI 10.1176/APPI.BOOKS.9780890425596]
   [Anonymous], 2019, LECT NOTES COMPUTER, V11326
   [Anonymous], 2014, PRINCIPLES ARTIFICIA
   [Anonymous], 2017, 13 INT C INT ENV IE
   Arrabales R., 2020, PERLA CONVERSATIONAL, DOI [10.31234/osf.io/nfas4, DOI 10.31234/OSF.IO/NFAS4]
   Baker S., 2018, COMBATTING SOCIAL IS, DOI [10.1111/ajag.12572, DOI 10.1111/AJAG.12572]
   Bishop C. M., 2006, PATTERN RECOGNITION
   Brenner W., 1998, INTELLIGENT SOFTWARE
   Brooke J., 2006, SUS QUICK DIRTY USAB
   Calvo RA, 2017, NAT LANG ENG, V23, P649, DOI 10.1017/S1351324916000383
   Castellani R.J., 2010, ALZHEIMER DIS, DOI [10.1016/j.disamonth.2010.06.001, DOI 10.1016/J.DISAMONTH.2010.06.001]
   Chaytor N, 2003, NEUROPSYCHOL REV, V13, P181, DOI 10.1023/B:NERV.0000009483.91468.fb
   Chui KT, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9122309
   Cronbach LJ, 1951, PSYCHOMETRIKA, V16, P297
   Della Mea V, 2001, J MED INTERNET RES, V3, DOI 10.2196/jmir.3.2.e22
   DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061
   Eignor D.R., 2013, APA HDB TESTING ASSE, P245, DOI [10.1037/14047-013, DOI 10.1037/14047-013]
   Faurholt-Jepsen M, 2016, TRANSL PSYCHIAT, V6, DOI 10.1038/tp.2016.123
   Fiske A, 2009, ANNU REV CLIN PSYCHO, V5, P363, DOI 10.1146/annurev.clinpsy.032408.153621
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Ganguli M, 2011, AM J GERIAT PSYCHIAT, V19, P205, DOI 10.1097/JGP.0b013e3182051ab4
   Griol D, 2019, NEUROCOMPUTING, V326, P132, DOI 10.1016/j.neucom.2017.01.120
   Harada CN, 2013, CLIN GERIATR MED, V29, P737, DOI 10.1016/j.cger.2013.07.002
   Hoermann S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7023
   Holtzman DM, 2011, SCI TRANSL MED, V3, DOI 10.1126/scitranslmed.3002369
   Imai Y., 1994, HONG KONG J PSYCHIAT, V4, P20
   Inkster B, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/12106
   Jaiswal S, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P81, DOI 10.1145/3308532.3329469
   Khodabakhsh A, 2014, SIG PROCESS COMMUN, P1003, DOI 10.1109/SIU.2014.6830401
   KOBAYASHI H, 2019, LECT NOTES COMPUTER, P53, DOI DOI 10.1007/978-3-030-29390-1_4
   Kowalska M., 2017, AGING NEUROLOGICAL D, DOI [10.5772/intechopen.69499, DOI 10.5772/INTECHOPEN.69499]
   Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Mallol-Ragolta A., 2019, HIERARCHICAL ATTENTI, P221, DOI [10.21437/Interspeech.2019-2036, DOI 10.21437/INTERSPEECH.2019-2036]
   Martinez-Miranda J, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0784-6
   McCarthy J, 2006, AI MAG, V27, P12
   Mirheidari B, 2019, INT CONF ACOUST SPEE, P2732, DOI 10.1109/ICASSP.2019.8682423
   MITCHELL T, 1989, ANNU REV COMPUT SCI, V4, P417
   Moher David, 2009, Ann Intern Med, V151, P264, DOI 10.1136/bmj.b2535
   Munoz RF, 1996, AM PSYCHOL, V51, P1116, DOI 10.1037/0003-066X.51.11.1116
   Okada Shogo, 2019, 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII). Proceedings, P192, DOI 10.1109/ACII.2019.8925454
   Peitzker T., 2016, WHY CHATBOTS ARE SO
   Philip P, 2017, SCI REP-UK, V7, DOI 10.1038/srep42656
   Picardi A, 2016, J AFFECT DISORDERS, V198, P96, DOI 10.1016/j.jad.2016.03.025
   Rahmani AM, 2015, CONSUM COMM NETWORK, P826, DOI 10.1109/CCNC.2015.7158084
   Razykov I, 2012, J PSYCHOSOM RES, V73, P163, DOI 10.1016/j.jpsychores.2012.06.001
   RUDD P, 1979, ARCH INTERN MED, V139, P627, DOI 10.1001/archinte.139.6.627
   Russo A, 2019, REJUV RES, V22, P109, DOI 10.1089/rej.2018.2075
   Schmidtke K, 2008, AM J GERIAT PSYCHIAT, V16, P981, DOI 10.1097/JGP.0b013e318187ddf9
   Sidorov M., 2014, P 4 INT WORKSH AUD V, P81, DOI [10.1145/2661806.2661816, DOI 10.1145/2661806.2661816]
   Sloot PMA, 2006, COMPUTER, V39, P40, DOI 10.1109/MC.2006.380
   Tanaka H, 2017, IEEE J TRANSL ENG HE, V5, DOI 10.1109/JTEHM.2017.2752152
   Tang FY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61994-0
   Tariman JD, 2011, APPL NURS RES, V24, P53, DOI 10.1016/j.apnr.2009.04.003
   Tsai YT, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1207, DOI 10.1109/HPCC/SmartCity/DSS.2018.00203
   Ujiro T, 2018, INTERSPEECH, P1691, DOI 10.21437/Interspeech.2018-1514
   Van der Elst W, 2008, ARCH CLIN NEUROPSYCH, V23, P787, DOI 10.1016/j.acn.2008.09.002
   Wang YP, 2013, CLINICS, V68, P1274, DOI 10.6061/clinics/2013(09)15
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 62
TC 0
Z9 0
U1 7
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1532-0464
EI 1532-0480
J9 J BIOMED INFORM
JI J. Biomed. Inform.
PD JAN
PY 2021
VL 113
AR 103632
DI 10.1016/j.jbi.2020.103632
EA JAN 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Medical Informatics
GA QE0TL
UT WOS:000615920400010
PM 33276112
OA Bronze
DA 2022-08-02
ER

PT C
AU Huang, HH
   Cerekovic, A
   Furukawa, T
   Yamaoka, Y
   Ohashi, H
   Pandzic, I
   Nakano, Y
   Nishida, T
AF Huang, H. H.
   Cerekovic, A.
   Furukawa, T.
   Yamaoka, Y.
   Ohashi, H.
   Pandzic, I.
   Nakano, Y.
   Nishida, T.
BE Zarko, IP
   Vrdoljak, B
TI Communicating with Multiple Users for Embodied Conversational Agents
SO CONTEL 2009: PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON
   TELECOMMUNICATIONS
LA English
DT Proceedings Paper
CT 10th International Conference on Telecommunications (ConTEL 2009)
CY JUN 08-10, 2009
CL Univ Zagreb, Fac Elect Engn & Comp, Zagreb, CROATIA
SP IEEE Commun Soc, IEEE Croatia Sect, IEEE Reg 8
HO Univ Zagreb, Fac Elect Engn & Comp
AB One of the most critical reason that prevents embodied conversational agents to be used in practical applications can be considered as the lack of the capabilities to be aware of multiple users and to interact with them. This paper presents our investigations in an advanced tour guide agent system serving two users and a simpler quiz agent kiosk which is developed for public exhibitions. To improve the life-likeness of the agents, we propose that the agent should be attentive to its users. To achieve the agent's attentiveness toward the users, two aspects are considered: its utterance strategy toward the users and its internal attitude should be adaptive to users' status. To explore these two aspects more throughly, two prototype systems are implemented and evaluated with subject experiments respectively. In addition to regular questionnaires evaluation, GNAT test that measures implicit preference was conducted as well. The preliminary results implied that the experiment participants perceived that the agents are attentive and natural.
C1 [Huang, H. H.; Furukawa, T.; Ohashi, H.; Nishida, T.] Kyoto Univ, Grad Sch Informat, Kyoto 6068501, Japan.
   [Cerekovic, A.] Univ Zagreb, Fac Elect Engn & Comp, Zagreb, Croatia.
   [Yamaoka, Y.; Pandzic, I.] Tokyo Univ Agr & Technol, Dept Comp Informat & Commun Sci, Tokyo, Japan.
   [Nakano, Y.] Seikei Univ, Dept Comp & Informat Sci, Tokyo, Japan.
RP Huang, HH (corresponding author), Kyoto Univ, Grad Sch Informat, Kyoto 6068501, Japan.
EM huang@ii.ist.i.kyoto-u.ac.jp; aleksandra.cerekovic@fer.hr;
   furukawa@ii.ist.i.kyoto-u.ac.jp; 50007646208@st.tuat.ac.jp;
   ohashi@ii.ist.i.kyoto-u.ac.jp; igor.pandzic@fer.hr;
   y.nakano@st.seikei.ac.jp; nishida@ii.ist.i.kyoto-u.ac.jp
RI Furukawa, Toshi A./B-9259-2011
OI Furukawa, Toshi A./0000-0003-2159-3776
CR Andre E, 2001, KNOWL-BASED SYST, V14, P3, DOI 10.1016/S0950-7051(00)00096-4
   [Anonymous], 2001, P SIGCHI C HUM FACT, DOI DOI 10.1145/365024.365119
   CASSELL J, 2002, P IMAGINA02
   CEREKOVIC A, 2008, ENTERFACE08 INT WORK
   Chang C., 2008, LIBSVM LIB SUPPORT V
   EGGES A, 2004, P CAPTECH WORKSH 200
   Eichner T, 2007, LECT NOTES ARTIF INT, V4722, P283
   Gratch J, 2006, LECT NOTES ARTIF INT, V4133, P14
   HUANG HH, 2008, 7 INT C AUT AG MULT, P128
   HUANG HH, 2006, ENTERFACE06 INT WORK
   *INT CORP, 2006, OP COMP VIS LIB OPEN
   KOPP S, 2008, INT J SEMANTIC COMPU, V2
   KOPP S, 2005, P 5 INT C INT VIRT A
   *LOQ CORP, 2008, LOQ ASR
   Nakano YI, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P553
   Nosek BA, 2001, SOC COGNITION, V19, P625, DOI 10.1521/soco.19.6.625.20886
   *OMR CORP, 2008, OKAO VIS
   REHM M, 2005, P 5 INT C INT VIRT A
   REHM M, 2005, 4 INT JOINT C AUT AG, P145
   Rehm M, 2008, INTERACT COMPUT, V20, P311, DOI 10.1016/j.intcom.2008.02.005
   Traum D, 2003, LECT NOTES ARTIF INT, V2922, P201
   TRAUM D, 2003, 2 INT C AUT AG MULT
   Wickens T.D., 2001, ELEMENTARY SIGNAL DE
NR 23
TC 0
Z9 0
U1 0
U2 1
PU UNIV ZAGREB, FAC ELECT ENGN COMP
PI ZAGREB
PA UNSKA 3, 10000 ZAGREB, CROATIA
PY 2009
BP 155
EP +
PG 2
WC Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Telecommunications
GA BMN92
UT WOS:000272996700022
DA 2022-08-02
ER

PT C
AU Tegos, S
   Demetriadis, S
   Karakostas, A
AF Tegos, Stergios
   Demetriadis, Stavros
   Karakostas, Anastasios
BE Xhafa, F
   Barolli, L
   Palmieri, F
   Koeppen, M
   Loia, V
TI Leveraging Conversational Agents and Concept Maps to Scaffold Students'
   Productive Talk
SO 2014 INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKING AND
   COLLABORATIVE SYSTEMS (INCOS)
LA English
DT Proceedings Paper
CT 2014 International Conference on Intelligent Networking and
   Collaborative Systems (IEEE INCoS 2014)
CY SEP 10-12, 2014
CL Univ Salerno, Salerno, ITALY
SP Univ Politecnica Catalunya Barcelona Tech, Fukuoka Inst Technol, Kyushu Inst Technol, Hippocratica Civitas Studium Salerni, Syst Man Cybernet Soc
HO Univ Salerno
DE intelligent tutoring system; conversational agent; concept mapping;
   academically productive talk; computer-supported collaborative learning
AB Over the past decades, intelligent conversational agents have been repeatedly used as pedagogical tools for fostering students' motivation and engagement in individual learning settings. However, in recent years, the uses of conversational agents have also been explored in collaborative contexts under the scope of Academically Productive Talk (APT). The theory of APT, which has derived from the work of the classroom discourse community, suggests a number of facilitative talk moves that have proven to effectively promote productive classroom conversations. Following the APT perspective, we propose the design of a teacher-configurable conversational agent system, named MentorChat. This dialogue support system leverages concept mapping as a domain modeling tool that enables the implementation of well-targeted agent interventions, aiming to stimulate constructive peer interactions in collaborative learning settings. In this paper, we also present the results of an evaluation study, where 40 students collaborated in dyads in order to accomplish two different tasks in MentorChat. The preliminary findings are quite encouraging as for the ease of use and user acceptance of the proposed conversational agent system.
C1 [Tegos, Stergios; Demetriadis, Stavros; Karakostas, Anastasios] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki, Greece.
RP Tegos, S (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki, Greece.
EM stegos@csd.auth.gr; sdemetri@csd.auth.gr; akarakos@csd.auth.gr
RI Demetriadis, Stavros/Z-3200-2019
OI Demetriadis, Stavros/0000-0002-1561-6372; Karakostas,
   Anastasios/0000-0002-8508-3903
CR Adamson D, 2014, INT J ARTIF INTELL E, V24, P92, DOI 10.1007/s40593-013-0012-6
   Ai H, 2010, LECT NOTES COMPUT SC, V6095, P134
   [Anonymous], 1999, COLLABORATIVE LEARNI
   Bredeweg B., 2009, COGNITIVE METACOGNIT, P46
   Chase CC, 2009, J SCI EDUC TECHNOL, V18, P334, DOI 10.1007/s10956-009-9180-4
   Chaudhuri S, 2009, FRONT ARTIF INTEL AP, V200, P365, DOI 10.3233/978-1-60750-028-5-365
   Dillenbourg P, 2007, J COMPUT ASSIST LEAR, V23, P1, DOI 10.1111/j.1365-2729.2007.00191.x
   Dyke G., 2013, PRODUCTIVE MULTIVOCA, P459, DOI 10.1007/978-1-4614-8960-3_25
   Griol D, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/55791
   Gulz A, 2011, CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND EFFECTIVE PRACTICES, P128, DOI 10.4018/978-1-60960-617-6.ch006
   Harrer A, 2006, USER MODEL USER-ADAP, V16, P175, DOI 10.1007/s11257-006-9007-4
   Kennedy CM, 2012, J MED INTERNET RES, V14, P116, DOI 10.2196/jmir.1893
   Kerly A, 2009, APPLICATIONS AND INNOVATIONS IN INTELLIGENT SYSTEMS XVI, P169
   Kumar R, 2011, IEEE T LEARN TECHNOL, V4, P21, DOI 10.1109/TLT.2010.41
   Kumar R, 2007, FRONT ARTIF INTEL AP, V158, P383
   McLaren B., 2005, P C COMP SUPP COLL L, P1
   Michaels S., 2010, ACCOUNTABLE TALK SOU
   Michaels S, 2008, STUD PHILOS EDUC, V27, P283, DOI 10.1007/s11217-007-9071-1
   Piaget J, 1985, EQUILIBRIUM COGNITIV
   Resnick L., 2010, INNOVATIONS ED PSYCH, P163
   Sklar E, 2010, KNOWL ENG REV, V25, P111, DOI 10.1017/S0269888910000044
   Sohmer R., 2009, TRANSFORMATION KNOWL, P105
   Stahl G., 2010, 1 N AM GEOGEBRA C IT, P196
   Tegos S, 2014, INT J ARTIF INTELL E, V24, P62, DOI 10.1007/s40593-013-0007-3
   VanLehn K, 2007, COGNITIVE SCI, V31, P3, DOI 10.1080/03640210709336984
   Walker E, 2011, INT J COMP-SUPP COLL, V6, P279, DOI 10.1007/s11412-011-9111-2
   Wik P, 2009, SPEECH COMMUN, V51, P1024, DOI 10.1016/j.specom.2009.05.006
   Wolf B.P., 2008, BUILDING INTELLIGENT
NR 28
TC 6
Z9 6
U1 1
U2 3
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-4799-6387-4
PY 2014
BP 176
EP 183
DI 10.1109/INCoS.2014.66
PG 8
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BF2BY
UT WOS:000380454200026
DA 2022-08-02
ER

PT C
AU Heudin, JC
AF Heudin, Jean-Claude
BE Nguyen, NT
   Kowalczyk, R
   VanDenHerik, J
   Rocha, AP
   Filipe, J
TI An Emotional Multi-personality Architecture for Intelligent
   Conversational Agents
SO TRANSACTIONS ON COMPUTATIONAL COLLECTIVE INTELLIGENCE XXVIII
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 9th International Conference on Agents and Artificial Intelligence
   (ICAART)
CY FEB 24-26, 2017
CL Porto, PORTUGAL
DE Conversational agent; Believable character; Multi-personality; Emotion
   selection
ID MODEL
AB Personal assistants and chatterbots represent an historical and growing application field in artificial intelligence. This paper presents a novel architecture to the problem of humanizing conversational agents by designing believable and unforgettable characters who exhibit various salient emotions in the flow of conversations. The proposed architecture is based on a multi-personality approach where each agent implements a facet of its identity, each one with its own pattern of perceiving and interacting with the user. In order to select an appropriate response from all the candidates, we use an emotion-based selection algorithm. Our first experiments show that a conversational multi-personality character with emotion selection performs better in terms of user engagement than a neutral mono-personality one.
C1 [Heudin, Jean-Claude] Leonard Vinci Pole Univ, Res Ctr, Paris, France.
RP Heudin, JC (corresponding author), Leonard Vinci Pole Univ, Res Ctr, Paris, France.
EM Jean-Claude.Heudin@devinci.fr
CR [Anonymous], 2005, P 4 INT JOINT C AUT, DOI DOI 10.1145/1082473.1082478
   Baker J. E., 1987, Genetic Algorithms and their Applications: Proceedings of the Second International Conference on Genetic Algorithms, P14
   BATES J, 1994, COMMUN ACM, V37, P122, DOI 10.1145/176789.176803
   CAMPOS JJ, 1994, MONOGR SOC RES CHILD, V59, P284, DOI 10.2307/1166150
   Coleridge S. T., 1817, BIOGRAPHIA LIT
   Dybala P, 2010, J AMB INTEL SMART EN, V2, P31, DOI 10.3233/AIS-2010-0053
   Ekman P., 1999, HDB COGNITION EMOTIO
   Guha R., 2015, P 8 ACM WEB SEARCH D
   Heck L., ANTICIPATING MORE CO
   Heudin J.-C., 2015, P ACM VIRT REAL INT
   Heudin J.-C., 2017, P 9 INT ICAART C AG
   Heudin JC, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON INTELLIGENT AGENT TECHNOLOGY, PROCEEDINGS, P93, DOI 10.1109/IAT.2004.1342929
   Heudin JC, 2011, ICAART 2011: PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 2, P251
   Langton C.G., 1992, SANTA FE I STUDIES S, P76
   LANGTON CG, 1990, PHYSICA D, V42, P12, DOI 10.1016/0167-2789(90)90064-V
   Leite I, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P77, DOI 10.1109/ROMAN.2008.4600646
   Linell Per, 1998, APPROACHING DIALOGUE
   Lovheim H, 2012, MED HYPOTHESES, V78, P341, DOI 10.1016/j.mehy.2011.11.016
   Lungu V., 2012, ARTIFICIAL EMOTION S
   Magnier M., 1997, Complex Systems, V11, P419
   Marcus D., INTRO FACEBOOK M
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   Mehrabian A., 1992, CURR PSYCHOL, V14, P261
   Moraes M., 2002, P IMAGINA 2002 MONT, P207
   Morris W.N., 1989, MOOD FRAME MIND, DOI [10.1007/978-1-4612-3648-1, DOI 10.1007/978-1-4612-3648-1]
   Myers K, 2007, AI MAG, V28, P47
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Salovey P., 1990, IMAGIN COGN PERSONAL, V9, P185, DOI [10.2190/DUGG-P24E-52WK-6CDG, DOI 10.2190/DUGG-P24E-52WK-6CDG]
   Seger L., 1990, CREATING UNFORGETTAB
   Tomkins S., 1991, AFFECT IMAGERY CONSC, VI
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   WOLFRAM S, 1984, PHYSICA D, V10, P1, DOI 10.1016/0167-2789(84)90245-8
NR 32
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-319-78301-7; 978-3-319-78300-0
J9 LECT NOTES COMPUT SC
PY 2018
VL 10780
BP 143
EP 163
DI 10.1007/978-3-319-78301-7_7
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP4JJ
UT WOS:000552714400007
DA 2022-08-02
ER

PT J
AU de Cock, C
   Milne-Ives, M
   van Velthoven, MH
   Alturkistani, A
   Lam, C
   Meinert, E
AF de Cock, Caroline
   Milne-Ives, Madison
   van Velthoven, Michelle Helena
   Alturkistani, Abrar
   Lam, Ching
   Meinert, Edward
TI Effectiveness of Conversational Agents (Virtual Assistants) in Health
   Care: Protocol for a Systematic Review
SO JMIR RESEARCH PROTOCOLS
LA English
DT Review
DE conversational agent; chatbot; voice recognition software; speech
   recognition software; artificial intelligence; virtual health care;
   avatar; virtual assistant; virtual nursing; virtual coach; intelligent
   assistant; digital health
AB Background: Conversational agents (also known as chatbots) have evolved in recent decades to become multimodal, multifunctional platforms with potential to automate a diverse range of health-related activities supporting the general public, patients, and physicians. Multiple studies have reported the development of these agents, and recent systematic reviews have described the scope of use of conversational agents in health care. However, there is scarce research on the effectiveness of these systems; thus, their viability and applicability are unclear. Objective: The objective of this systematic review is to assess the effectiveness of conversational agents in health care and to identify limitations, adverse events, and areas for future investigation of these agents.
   Methods: The Preferred Reporting Items for Systematic Reviews and Meta-Analyses Protocols will be used to structure this protocol. The focus of the systematic review is guided by a population, intervention, comparator, and outcome framework. A systematic search of the PubMed (Medline), EMBASE, CINAHL, and Web of Science databases will be conducted. Two authors will independently screen the titles and abstracts of the identified references and select studies according to the eligibility criteria. Any discrepancies will then be discussed and resolved. Two reviewers will independently extract and validate data from the included studies into a standardized form and conduct quality appraisal.
   Results: As of January 2020, we have begun a preliminary literature search and piloting of the study selection process.
   Conclusions: This systematic review aims to clarify the effectiveness, limitations, and future applications of conversational agents in health care. Our findings may be useful to inform the future development of conversational agents and promote the personalization of patient care.
C1 [de Cock, Caroline; Milne-Ives, Madison; van Velthoven, Michelle Helena; Lam, Ching; Meinert, Edward] Univ Oxford, Dept Paediat, Digitally Enabled Preventat Hlth Res Grp, Oxford, England.
   [Alturkistani, Abrar; Meinert, Edward] Imperial Coll London, Dept Primary Care & Publ Hlth, London, England.
   [Lam, Ching] Univ Oxford, Inst Biomed Engn, Dept Engn Sci, Oxford, England.
RP Meinert, E (corresponding author), Univ Oxford, John Radcliffe Hosp, Digitally Enabled Preventat Hlth Res Grp, Headley Way, Oxford OX3 9DU, England.
EM e.meinert14@imperial.ac.uk
OI Meinert, Edward/0000-0003-2484-3347; Alturkistani,
   Abrar/0000-0001-7935-8870; Milne-Ives, Madison/0000-0001-7628-882X; van
   Velthoven, Michelle Helena/0000-0003-1245-8759; Lam,
   Ching/0000-0002-9137-749X
FU EIT Health [18654]
FX We would like to thank the outreach librarian Liz Callow for her
   assistance in developing search terms and in reviewing the search
   strategy. CdC, MMI, CL, MV, and EM are supported by EIT Health (Grant
   18654).
CR Abdullah A, 2018, J EPIDEMIOL GLOB HEA, V8, P225, DOI 10.2991/j.jegh.2018.08.104
   Bibault JE, 2019, CLIN TRANSL RAD ONCO, V16, P55, DOI 10.1016/j.ctro.2019.04.002
   Bickmore TW, 2013, J AM GERIATR SOC, V61, P1676, DOI 10.1111/jgs.12449
   Bickmore TW, 2010, J HEALTH COMMUN, V15, P197, DOI 10.1080/10810730.2010.499991
   Campillos-Llanos L, 2020, NAT LANG ENG, V26, P183, DOI 10.1017/S1351324919000329
   Fadhil A, 2019, METHOD INFORM MED, V58, P9, DOI 10.1055/s-0039-1688757
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Ghosh S, 2018, STUD HEALTH TECHNOL, V252, P51, DOI 10.3233/978-1-61499-890-7-51
   Harless WG, 2009, PATIENT EDUC COUNS, V76, P189, DOI 10.1016/j.pec.2009.02.006
   Higgins Julian P T, 2011, BMJ, V343, pd5928, DOI 10.1136/bmj.d5928
   Kocaballi AB, 2019, J MED INTERNET RES, V21, DOI 10.2196/15360
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Moher D, 2009, BMJ-BRIT MED J, V339, DOI [10.1136/bmj.i4086, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.b2535]
   Oliven A, 2011, STUD HEALTH TECHNOL, V169, P233, DOI 10.3233/978-1-60750-806-9-233
   Owens OL, 2019, AM J HEALTH PROMOT, V33, P267, DOI 10.1177/0890117118786866
   Philip P, 2017, SCI REP-UK, V7, DOI 10.1038/srep42656
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Russo A, 2019, REJUV RES, V22, P109, DOI 10.1089/rej.2018.2075
   Sterne JAC, 2016, BMJ-BRIT MED J, V355, DOI 10.1136/bmj.i4919
   Sun R, 2018, INNOV AGING S1, V2, P362, DOI [10.1093/geroni/igy023.1338, DOI 10.1093/GER0NI/IGY023.1338]
   Tanaka H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182151
   U.S. Department of Health and Human Services, STUD QUAL ASS TOOLS
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   van Heerden Alastair, 2017, 2017 International Conference on the Frontiers and Advances in Data Science (FADS). Proceedings, P80, DOI 10.1109/FADS.2017.8253198
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wolters MK, 2016, HEALTH INFORM J, V22, P854, DOI 10.1177/1460458215593329
   Xing ZP, 2019, STUD HEALTH TECHNOL, V264, P1813, DOI 10.3233/SHTI190661
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
   Zhang Z, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P113, DOI 10.1145/3267851.3267883
NR 29
TC 12
Z9 12
U1 3
U2 27
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 1929-0748
J9 JMIR RES PROTOC
JI JMIR RES. Protoc.
PD MAR
PY 2020
VL 9
IS 3
AR e16934
DI 10.2196/16934
PG 6
WC Health Care Sciences & Services; Public, Environmental & Occupational
   Health
WE Emerging Sources Citation Index (ESCI)
SC Health Care Sciences & Services; Public, Environmental & Occupational
   Health
GA KT7PE
UT WOS:000519204600003
PM 32149717
OA Green Submitted, gold, Green Published
DA 2022-08-02
ER

PT S
AU Beun, RJ
   de Vos, E
   Witteman, C
AF Beun, RJ
   de Vos, E
   Witteman, C
BE Rist, T
   Aylett, R
   Ballin, D
   Rickel, J
TI Embodied conversational agents: Effects on memory performance and
   anthropomorphisation
SO INTELLIGENT VIRTUAL AGENTS
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
LA English
DT Article; Proceedings Paper
CT 4th International Workshop on Intelligent Virtual Agents
CY SEP 15-17, 2003
CL KLOSTER IRSEE, GERMANY
SP EU 5th Framework VICTEC Project, SIGMEDIA, DFKI, BTexact Technologies, Univ Augsburg, Dept Multimedia Concepts & Applicat
AB It is often assumed that the use of Embodied Conversational Agents (ECAs) in human-computer interfaces improves human-computer interaction. Because of their appearance and because they show human-like communicative behaviour, users tend to ascribe human characteristics to ECAs or 'anthropo-morphize' them. Since interacting with another human being comes natural to people, anthropomorphisation of agents in an interface is thought to improve the process of communication. As a result, other usability aspects, such as satisfaction and learnability, would probably benefit. This paper describes a study into anthropomorphisation of ECAs and their effect on memory performance. The results of our study show that the presence of an ECA has a positive effect on retainability of information, but that this effect is not necessarily influenced by anthropomorphism.
C1 Univ Utrecht, Inst Informat & Comp Sci, NL-3508 TB Utrecht, Netherlands.
   Univ Nijmegen, Fac Social Sci, NL-6500 HE Nijmegen, Netherlands.
RP Beun, RJ (corresponding author), Univ Utrecht, Inst Informat & Comp Sci, POB 80089, NL-3508 TB Utrecht, Netherlands.
RI Witteman, Cilia/D-1601-2012
CR Caporael L. R., 1986, Computers in Human Behaviour, V2, P215, DOI 10.1016/0747-5632(86)90004-X
   Cassell J, 2000, EMBODIED CONVERSATIONAL AGENTS, P1
   Kintsch W., 1998, COMPREHENSION PARADI
   LANG A, 1995, COMMUN RES, V22, P86, DOI 10.1177/009365095022001004
   LESTER J, 1997, HUMAN FACTORS COMPUT, P359
   MCBREEN H, 2000, P AAAI FALL S SOC IN
   MORENO R, 1999, ED MEDIA 2000, P741
   RICKENBERG R, 2000, P CHI 2000, P1
   Takeuchi A., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P450
   VANMULKEN S, 1998, PEOPLE COMPUTERS, V8, P56
   WALKER JH, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P85
NR 11
TC 35
Z9 35
U1 0
U2 7
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-20003-7
J9 LECT NOTES ARTIF INT
PY 2003
VL 2792
BP 315
EP 319
PG 5
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BX96B
UT WOS:000187008600052
DA 2022-08-02
ER

PT C
AU Chen, JL
   Liu, Y
   Zhang, ZM
   Fan, CJ
   Ding, Y
AF Chen, Jiali
   Liu, Yong
   Zhang, Zhimeng
   Fan, Changjie
   Ding, Yu
GP ACM
TI Text-driven Visual Prosody Generation for Embodied Conversational Agents
SO PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT
   VIRTUAL AGENTS (IVA' 19)
LA English
DT Proceedings Paper
CT 19th ACM International Conference on Intelligent Virtual Agents (IVA)
CY JUL 02-05, 2019
CL Paris, FRANCE
SP Assoc Comp Machinery, ACM SIGAI
AB In face-to-face conversations, head motions play a crucial role in encoding information, and humans are very skilled at decoding multiple messages from interlocutors' head motions. It is of great importance to endow embodied conversational agents (ECAs) with the capability of conveying communicative intention through head movements. Our work is aimed at automatically synthesizing head motions for an ECA speaking Chinese. We propose to take only transcripts as input to compute head movements, based on a statistical framework. Subjective experiments are conducted to validate the proposed statistical framework. The results show that the generated head animation is able to improve human perception in terms of naturalness and demonstrate that the head animation is synchronized with the input of synthetic speech.
C1 [Chen, Jiali; Liu, Yong; Zhang, Zhimeng; Fan, Changjie; Ding, Yu] Fuxi AI Lab Netease, Hangzhou, Peoples R China.
RP Chen, JL (corresponding author), Fuxi AI Lab Netease, Hangzhou, Peoples R China.
EM chenjiali02@corp.netease.com; hzliuyong1@corp.netease.com;
   zhangzhimeng@corp.netease.com; fanchangjie@corp.netease.com;
   dingyu01@corp.netease.com
CR Ding Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3011, DOI 10.1145/3025453.3025644
   Tickle-Degnen L, 1990, PSYCHOL INQ, V1, P285, DOI DOI 10.1207/S15327965PLI0104_
   Vaswani A., 2017, P 2017 ADV NEURAL IN, P5998
NR 3
TC 0
Z9 0
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6672-4
PY 2019
BP 108
EP 110
DI 10.1145/3308532.3329445
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP5MU
UT WOS:000556671900025
DA 2022-08-02
ER

PT J
AU Dyke, G
   Adamson, D
   Howley, I
   Rose, CP
AF Dyke, Gregory
   Adamson, David
   Howley, Iris
   Rose, Carolyn Penstein
TI Enhancing Scientific Reasoning and Discussion with Conversational Agents
SO IEEE TRANSACTIONS ON LEARNING TECHNOLOGIES
LA English
DT Article
DE Collaborative learning; intelligent agents; psychology
AB This paper investigates the use of conversational agents to scaffold online collaborative learning discussions through an approach called academically productive talk (APT). In contrast to past work on dynamic support for collaborative learning, which has involved using agents to elevate the conceptual depth of collaborative discussion by leading students in groups through directed lines of reasoning, this APT-based approach lets students follow their own lines of reasoning and promotes productive practices such as explanation of reasoning and refinement of ideas. Two forms of support are contrasted, namely, Revoicing support and Feedback support. The study provides evidence that Revoicing support resulted in significantly more intensive reasoning exchange between students in the chat and significantly more learning during the chat than when that form of support was absent. Another form of support, namely, Feedback support increased expression of reasoning while marginally decreasing the intensity of the interaction between students and did not affect learning.
C1 [Dyke, Gregory] Univ Lyon, ENS Lyon, Lyon, France.
   [Adamson, David; Rose, Carolyn Penstein] Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15206 USA.
   [Howley, Iris] Carnegie Mellon Univ, Human Comp Interact Inst, Pittsburgh, PA 15206 USA.
RP Dyke, G (corresponding author), Univ Lyon, ENS Lyon, Lyon, France.
EM gregory.dyke@ens-lyon.fr; dadamson@cs.cmu.edu; iris@cmu.edu;
   cprose@cs.cmu.edu
FU US National Science Foundation [SBE 0836012]
FX The authors wish to thank Lauren Resnick, Sandra Katz, Catherine
   Stainton, and Sherice Clarke for their involvement in the district wide
   teacher training effort that provides the context for this work. This
   work was supported in part by US National Science Foundation grant SBE
   0836012 to the Pittsburgh Science of Learning Center.
CR ADEY P, 1993, COGNITION INSTRUCT, V11, P1, DOI 10.1207/s1532690xci1101_1
   Ai H., 2010, P 10 INT C INT TUT S
   Azmitia M., 1993, SOC DEV, V2, P202, DOI [10.1111/j.1467-9507.1993.tb00014.x, DOI 10.1111/J.1467-9507.1993.TB00014.X]
   Baghaei N, 2007, INT J COMP-SUPP COLL, V2, P159, DOI 10.1007/s11412-007-9018-0
   BERKOWITZ MW, 1983, MERRILL PALMER QUART, V29, P399
   Dillenbourg P., 2002, 3 WORLDS CSCL CAN WE, P61
   Dillenbourg P, 2008, INT J COMP-SUPP COLL, V3, P5, DOI 10.1007/s11412-007-9033-1
   Diziol D, 2010, EDUC PSYCHOL REV, V22, P89, DOI 10.1007/s10648-009-9116-9
   Fernando S., 2008, P 11 ANN RES C COMP
   Kobbe L, 2007, INT J COMP-SUPP COLL, V2, P211, DOI 10.1007/s11412-007-9014-4
   Kollar I, 2006, EDUC PSYCHOL REV, V18, P159, DOI 10.1007/s10648-006-9007-2
   Kumar R, 2007, P SLATE WORKSH SPEEC
   Kumar R., 2007, P C ART INT ED
   Kumar R., 2010, P 10 INT C INT TUT S
   Kumar R, 2011, IEEE T LEARN TECHNOL, V4, P21, DOI 10.1109/TLT.2010.41
   Lison Pierre, 2011, P SIGDIAL 2011 C, P294
   Michaels S, 2008, STUD PHILOS EDUC, V27, P283, DOI 10.1007/s11217-007-9071-1
   RABEHESKETH S, 2004, GLLAMM MANUAL, P160
   Rose C.P., 2001, P C AI ED
   Rose C, 2008, INT J COMP-SUPP COLL, V3, P237, DOI 10.1007/s11412-007-9034-0
   Wecker C., 2007, P 8 INT C COMP SUPP, P764
   Weinberger A., 2007, P MIC MINDS SOC INT, P37
NR 22
TC 25
Z9 25
U1 0
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1939-1382
J9 IEEE T LEARN TECHNOL
JI IEEE Trans. Learn. Technol.
PD JUL-SEP
PY 2013
VL 6
IS 3
BP 240
EP 247
DI 10.1109/TLT.2013.25
PG 8
WC Computer Science, Interdisciplinary Applications; Education &
   Educational Research
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Education & Educational Research
GA 217UB
UT WOS:000324386000007
OA hybrid
DA 2022-08-02
ER

PT C
AU Griol, D
   Sanchez-Pi, N
   Carbo, J
   Molina, JM
AF Griol, David
   Sanchez-Pi, Nayat
   Carbo, Javier
   Molina, Jose M.
BE Demazeau, Y
   Dignum, F
   Corchado, JM
   Perez, JB
TI An Architecture for the Design of Context-Aware Conversational Agents
SO ADVANCES IN PRACTICAL APPLICATIONS OF AGENTS AND MULTIAGENT SYSTEMS
SE Advances in Intelligent and Soft Computing
LA English
DT Proceedings Paper
CT 8th International Conference on Practical Applications of Agents and
   Multi-Agent Systems
CY APR 26-28, 2010
CL Salamanca, SPAIN
SP IEEE, Secc Espana
AB In this paper, we present a architecture for the development of conversational agents that provide a personalized service to the user. The different agents included in our architecture facilitate an adapted service by taking into account context information and users specific requirements and preferences. This functionality is achieved by means of the introduction of a context manager and the definition of user profiles. We describe the main characteristics of our architecture and its application to develop and evaluate an information system for an academic domain.
C1 [Griol, David; Sanchez-Pi, Nayat; Carbo, Javier; Molina, Jose M.] Univ Carlos III Madrid, Grp Appl Artificial Intelligence GIAA, Dept Comp Sci, E-28903 Getafe, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Grp Appl Artificial Intelligence GIAA, Dept Comp Sci, E-28903 Getafe, Spain.
EM david.griol@uc3m.es; nayat.sanchez@uc3m.es; javier.carbo@uc3m.es;
   josemanuel.molina@uc3m.es
RI Sanchez-Pi, Nayat/K-2049-2015; Carbo, Javier/ABB-4694-2020; Griol,
   David/L-1258-2014
OI Sanchez-Pi, Nayat/0000-0002-5037-9974; Carbo,
   Javier/0000-0001-7794-3398; Griol, David/0000-0001-6266-5321
CR Doulkeridis C, 2008, PERVASIVE MOB COMPUT, V4, P737, DOI 10.1016/j.pmcj.2008.05.001
   Griol D., 2007, P 8 SIGDIAL WORKSH D, P39
   Griol D., 2009, P 9 SIGDIAL WORKSH D, P326
   Henricksen K, 2006, PERVASIVE MOB COMPUT, V2, P37, DOI 10.1016/j.pmcj.2005.07.003
   Kang H, 2008, EXPERT SYST APPL, V35, P286, DOI 10.1016/j.eswa.2007.06.033
   Litman DJ, 2002, USER MODEL USER-ADAP, V12, P111, DOI 10.1023/A:1015036910358
   Truong HL, 2009, INT J WEB INF SYST, V5, P5, DOI 10.1108/17440080910947295
   [No title captured]
NR 8
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 1867-5662
BN 978-3-642-12383-2
J9 ADV INTEL SOFT COMPU
PY 2010
VL 70
BP 41
EP 46
DI 10.1007/978-3-642-12384-9_6
PG 6
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQA13
UT WOS:000280483700006
OA Green Accepted
DA 2022-08-02
ER

PT C
AU Kwon, WS
   Chattaraman, V
   Shim, SI
   Alnizami, H
   Gilbert, J
AF Kwon, Wi-Suk
   Chattaraman, Veena
   Shim, Soo In
   Alnizami, Hanan
   Gilbert, Juan
BE Jacko, JA
TI Older User-Computer Interaction on the Internet: How Conversational
   Agents Can Help
SO HUMAN-COMPUTER INTERACTION: INTERACTION TECHNIQUES AND ENVIRONMENTS, PT
   II
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT International Conference on Ergonomics and Health Aspects of Work with
   Computers (EHAWC)/14th International Conference on Human-Computer
   Interaction (HCI)
CY JUL 09-14, 2011
CL Orlando, FL
DE Conversational agent; older users; Internet; interaction
AB Using a qualitative study employing a role-playing approach with human agents, this study identifies the potential roles of conversational agents in enhancing older users' computer interactions on the Internet in e-commerce environments. Twenty-five participants aged 65 or older performed a given shopping task with a human agent playing the role of a conversational agent. The activity computer screens were video-recorded and the participant-agent conversations were audio-recorded. Through navigation path analysis as well as content analysis of the conversations, three major issues hindering older users' Internet interaction are identified: (1) a lack of prior computer knowledge, (2) a failure to locate information or buttons, and (3) confusions related to meanings of information. The navigation path analysis also suggests potential ways conversational agents may assist older users to optimize their search strategies. Implications and suggestions for future studies are discussed.
C1 [Kwon, Wi-Suk; Chattaraman, Veena; Shim, Soo In] Auburn Univ, Dept Consumer Affairs, Auburn, AL 36849 USA.
   [Alnizami, Hanan; Gilbert, Juan] Clemson Univ, Sch Comp, Human Centered Comp Div, Clemson, SC 29634 USA.
RP Kwon, WS (corresponding author), Auburn Univ, Dept Consumer Affairs, Auburn, AL 36849 USA.
EM kwonwis@auburn.edu; vzc0001@auburn.edu; szs0029@auburn.edu;
   hanana@clemson.edu; juan@clemson.edu
FU National Science Foundation [IIS-0955763]
FX This material is based in part upon work supported by the National
   Science Foundation under Grant Number IIS-0955763.Any opinions,
   findings, and conclusions or recommendations expressed in this material
   are those of the author(s) and do not necessarily reflect the views of
   the National Science Foundation.
CR Baylor A., 1999, Educational Technology, V39, P36
   Bucar A., 1999, CYBERPSYCHOL BEHAV, V2, P535
   Cassell J., 2000, EMBODIED CONVERSATIO
   Czaja SJ, 2001, PSYCHOL AGING, V16, P564, DOI [10.1037/0882-7974.16.4.564, 10.1037//0882-7974.16.4.564]
NR 4
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 978-3-642-21605-3
J9 LECT NOTES COMPUT SC
PY 2011
VL 6762
BP 533
EP 536
PG 4
WC Computer Science, Cybernetics; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BBA79
UT WOS:000306321200058
DA 2022-08-02
ER

PT C
AU Chatzimina, M
   Koumakis, L
   Marias, K
   Tsiknakis, M
AF Chatzimina, Maria
   Koumakis, Lefteris
   Marias, Kostas
   Tsiknakis, Manolis
GP IEEE
TI Employing Conversational Agents in Palliative Care: A feasibility study
   and Preliminary Assessment
SO 2019 IEEE 19TH INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND
   BIOENGINEERING (BIBE)
SE IEEE International Conference on Bioinformatics and Bioengineering
LA English
DT Proceedings Paper
CT 19th Annual IEEE International Conference on Bioinformatics and
   Bioengineering (BIBE)
CY OCT 28-30, 2019
CL Athens, GREECE
SP IEEE, IEEE Comp Soc
DE conversational agent; patient reported outcomes; question answering;
   natural language processing
ID PATIENT-REPORTED OUTCOMES; SPOKEN DIALOGUE; CANCER; QUESTIONNAIRE;
   SEVERITY
AB Recording of patient-reported outcomes (PROs) enables direct measurement of the experiences of patients with chronic conditions, including cancer; thus, PROs are a critical element of high quality, person-centered care for cancer patients. A growing body of literature reports on the feasibility of using electronic tools for the collection of Patient reported Outcomes (ePROs), although the usability of available solutions does affect their acceptance and use. In parallel, recent advancement in artificial intelligence, machine learning and speech recognition have led to the growing interest in conversational agents, i.e. software applications that mimic written or spoken human speech. In the present manuscript we provide a review of current developments regarding the implementation of conversational agents and their application in the domain of palliative care for oncology patients and also present (i) a methodology for the implementation of a conversational agent able to collect ePRO health data and (ii) initial evaluation results from a relevant feasibility study. Our approach differs from other available systems since the conversational agent reported in the present work is not based on rules, but rather uses machine learning algorithms and more specifically recurrent neural networks (RNN) for identifying appropriate answers. Evaluation results of user experience provided promising results and highlight that users gave positive responds when interacting with the system. Based on the User Experience Questionnaire, pragmatic quality and overall quality were categorized as excellent and hedonic quality was categorized as good. The result of this research can be used as reference for the future development and improvement of the conversational agents in the healthcare domain.
C1 [Chatzimina, Maria; Koumakis, Lefteris; Marias, Kostas; Tsiknakis, Manolis] Fdn Res & Technol Hellas FORTH, Inst Comp Sci, Iraklion, Crete, Greece.
   [Marias, Kostas] Hellen Mediterranean Univ, Dept Elect & Comp Engn, Iraklion, Crete, Greece.
   [Tsiknakis, Manolis] Hellen Mediterranean Univ, Dept Elect & Comp Engn, Iraklion, Crete, Greece.
RP Chatzimina, M (corresponding author), Fdn Res & Technol Hellas FORTH, Inst Comp Sci, Iraklion, Crete, Greece.
EM hatzimin@ics.forth.gr; koumakis@ics.forth.gr; kmarias@ics.forth.gr;
   tsiknaki@ics.forth.gr
RI Marias, Kostas/AAM-2330-2021; Chatzimina, Maria/ABA-7895-2021
OI Marias, Kostas/0000-0003-3783-5223; Chatzimina,
   Maria/0000-0003-2008-6772
FU European Union [825872]
FX The research leading to these results has received funding from the
   European Union's Horizon 2020 (H2020/2014-2020) under grant agreement no
   825872.
CR Aaronson NK, 1996, EUROPEAN ORG RES TRE
   Azzini Ivano, 2003, Stud Health Technol Inform, V95, P146
   Beveridge M, 2006, J BIOMED INFORM, V39, P482, DOI 10.1016/j.jbi.2005.12.008
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore TW, 2013, J AM GERIATR SOC, V61, P1676, DOI 10.1111/jgs.12449
   Bickmore TW, 2013, PATIENT EDUC COUNS, V92, P142, DOI 10.1016/j.pec.2013.05.011
   Black LA, 2005, COMP MED SY, P506, DOI 10.1109/CBMS.2005.33
   Chen J, 2013, BMC HEALTH SERV RES, V13, DOI 10.1186/1472-6963-13-211
   Crutzen R, 2011, J ADOLESCENT HEALTH, V48, P514, DOI 10.1016/j.jadohealth.2010.09.002
   DAUT RL, 1983, PAIN, V17, P197, DOI 10.1016/0304-3959(83)90143-4
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Geng X., 2009, INCREMENTAL LEARNING, P731, DOI DOI 10.1007/978-0-387-73003-5_304
   Giorgino T, 2005, INT J MED INFORM, V74, P159, DOI 10.1016/j.ijmedinf.2004.04.026
   Griol D, 2013, APPL ARTIF INTELL, V27, P759, DOI 10.1080/08839514.2013.835230
   Grosz B.J., 2016, ARTIFICIAL INTELLIGE
   Grudzen CR, 2016, JAMA ONCOL, V2, P591, DOI 10.1001/jamaoncol.2015.5252
   Harper R, 2008, FIFTEENTH IEEE INTERNATIONAL CONFERENCE AND WORKSHOPS ON THE ENGINEERING OF COMPUTER-BASED SYSTEMS, PROCEEDINGS, P219, DOI 10.1109/ECBS.2008.31
   Hassenzahl M, 2001, INT J HUM-COMPUT INT, V13, P481, DOI 10.1207/S15327590IJHC1304_07
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Truong HP, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P93
   Hoerger M, 2018, J CLIN ONCOL, V36, P1096, DOI 10.1200/JCO.2017.75.6676
   Hudlicka E., 2016, VIRTUAL TRAINING COA, V100
   Ireland D, 2016, STUD HEALTH TECHNOL, V227, P55, DOI 10.3233/978-1-61499-666-8-55
   Jensen RE, 2014, J ONCOL PRACT, V10, pE215, DOI 10.1200/JOP.2013.001067
   Jordan P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182162
   Judson TJ, 2013, J CLIN ONCOL, V31, P2580, DOI 10.1200/JCO.2012.47.6804
   Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Laugwitz B., 2008, CONSTRUCTION EVALUAT, V5298
   LeBlanc TW, 2017, NAT REV CLIN ONCOL, V14, P763, DOI 10.1038/nrclinonc.2017.153
   Levin E, 2006, J MED INTERNET RES, V8, DOI 10.2196/jmir.8.4.e30
   Lucas GM, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00051
   Maguire R, 2017, BMJ OPEN, V7, P7
   Mctear M., CONVERSATIONAL INTER
   Miner AS, 2016, SMARTPHONE BASED CON, V118, P6072
   Philip J. O. Pierre, 2005, COULD VIRTUAL HUMAN, V24, P24
   Philip P., 2017, SCI REP, V7, P1
   Potamias G., 2005, INGENIERIE SYSTEMES, V10, P59
   Radziwill N. M., 2017, EVALUATING QUALITY C
   Reilly CM, 2013, SUPPORT CARE CANCER, V21, P1525, DOI 10.1007/s00520-012-1688-0
   Rhee H, 2014, PATIENT PREFER ADHER, V8, P63, DOI 10.2147/PPA.S53504
   Santoso B. P. H. B., 2016, J ED ONLINE JEO, V13, P142
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P103, DOI 10.9781/ijimai.2017.09.001
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P40, DOI 10.9781/ijimai.2017.445
   Scott N.W., 2008, EORTC QLQ C30 REFERE
   Sfakianaki P, 2015, BMC MED INFORM DECIS, V15, DOI 10.1186/s12911-015-0200-4
   Snyder CF, 2012, QUAL LIFE RES, V21, P1305, DOI 10.1007/s11136-011-0054-x
   Tanaka H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182151
   Watson David, 1988, DEV VALIDATION BRIEF
   Wolters MK, 2016, HEALTH INFORM J, V22, P854, DOI 10.1177/1460458215593329
   Wright KM, 2005, MIL MED, V170, P555, DOI 10.7205/MILMED.170.7.555
   [No title captured]
NR 52
TC 4
Z9 4
U1 0
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2471-7819
BN 978-1-7281-4617-1
J9 IEEE INT C BIOINF BI
PY 2019
BP 489
EP 496
DI 10.1109/BIBE.2019.00095
PG 8
WC Engineering, Biomedical; Medical Informatics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Medical Informatics
GA BO7KK
UT WOS:000524679600086
DA 2022-08-02
ER

PT J
AU Ollier, J
   Nissen, M
   von Wangenheim, F
AF Ollier, Joseph
   Nissen, Marcia
   von Wangenheim, Florian
TI The Terms of "You(s)": How the Term of Address Used by Conversational
   Agents Influences User Evaluations in French and German Linguaculture
SO FRONTIERS IN PUBLIC HEALTH
LA English
DT Article
DE conversational agents; chatbots; term of address; T; V distinction;
   linguaculture; digital health
ID EUROPEAN LANGUAGES; CONGRUITY; PRONOUNS; HEALTH; IMPACT; IKEA
AB Background: Conversational agents (CAs) are a novel approach to delivering digital health interventions. In human interactions, terms of address often change depending on the context or relationship between interlocutors. In many languages, this encompasses T/V distinction-formal and informal forms of the second-person pronoun "You"-that conveys different levels of familiarity. Yet, few research articles have examined whether CAs' use of T/V distinction across language contexts affects users' evaluations of digital health applications.Methods: In an online experiment (N = 284), we manipulated a public health CA prototype to use either informal or formal T/V distinction forms in French ("tu" vs. "vous") and German ("du" vs. "Sie") language settings. A MANCOVA and post-hoc tests were performed to examine the effects of the independent variables (i.e., T/V distinction and Language) and the moderating role of users' demographic profile (i.e., Age and Gender) on eleven user evaluation variables. These were related to four themes: (i) Sociability, (ii) CA-User Collaboration, (iii) Service Evaluation, and (iv) Behavioral Intentions.Results: Results showed a four-way interaction between T/V Distinction, Language, Age, and Gender, influencing user evaluations across all outcome themes. For French speakers, when the informal "T form" ("Tu") was used, higher user evaluation scores were generated for younger women and older men (e.g., the CA felt more humanlike or individuals were more likely to recommend the CA), whereas when the formal "V form" ("Vous") was used, higher user evaluation scores were generated for younger men and older women. For German speakers, when the informal T form ("Du") was used, younger users' evaluations were comparable regardless of Gender, however, as individuals' Age increased, the use of "Du" resulted in lower user evaluation scores, with this effect more pronounced in men. When using the formal V form ("Sie"), user evaluation scores were relatively stable, regardless of Gender, and only increasing slightly with Age.Conclusions: Results highlight how user CA evaluations vary based on the T/V distinction used and language setting, however, that even within a culturally homogenous language group, evaluations vary based on user demographics, thus highlighting the importance of personalizing CA language.
C1 [Ollier, Joseph; Nissen, Marcia; von Wangenheim, Florian] Swiss Fed Inst Technol, Dept Management Econ & Technol D MTEC, Chair Technol Mkt, Zurich, Switzerland.
   [Ollier, Joseph; Nissen, Marcia; von Wangenheim, Florian] Swiss Fed Inst Technol, Dept Management Econ & Technol D MTEC, Ctr Digital Hlth Intervent CDHI, Zurich, Switzerland.
RP Ollier, J (corresponding author), Swiss Fed Inst Technol, Dept Management Econ & Technol D MTEC, Chair Technol Mkt, Zurich, Switzerland.; Ollier, J (corresponding author), Swiss Fed Inst Technol, Dept Management Econ & Technol D MTEC, Ctr Digital Hlth Intervent CDHI, Zurich, Switzerland.
EM jollier@ethz.ch
CR Altman DG, 2006, BRIT MED J, V332, P1080, DOI 10.1136/bmj.332.7549.1080
   Ami D, 2017, REV ECON-FR, V68, P327, DOI 10.3917/reco.683.0327
   [Anonymous], 2017, RES LANGUAGE
   Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Ashfaq M, 2020, TELEMAT INFORM, V54, DOI 10.1016/j.tele.2020.101473
   Bacchini S., 2016, REF REV, V30, P29, DOI [10.1108/RR-06-2016-0145, DOI 10.1108/RR-06-2016-0145]
   Barello S, 2016, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.02013
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T., 1999, Narrative Intelligence. Papers from the 1999 AAAI Fall Symposium, P87
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bland JM, 1997, BRIT MED J, V314, P572, DOI 10.1136/bmj.314.7080.572
   Bonnevie E, 2021, HEALTH EDUC J, V80, P413, DOI 10.1177/0017896920981122
   Branaghan RJ, 2011, J CONSUM BEHAV, V10, P304, DOI 10.1002/cb.365
   Brown Roger, 1960, STYLE LANGUAGE, P253, DOI DOI 10.1515/9783110805376.252
   Buttgen M, 2012, J SERV RES-US, V15, P166, DOI 10.1177/1094670511435564
   Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158
   Cirkovic A, 2020, J MED INTERNET RES, V22, DOI 10.2196/18097
   Clyne M, 2009, LANGUAGE AND HUMAN RELATIONS: STYLES OF ADDRESS IN CONTEMPORARY LANGUAGE, P1, DOI 10.1017/CBO9780511576690
   Clyne M, 2006, J SOCIOLING, V10, P287, DOI 10.1111/j.1360-6441.2006.00329.x
   Cohen J., 1988, STAT POWER ANAL BEHA, V2nd ed.
   Collier PJ, 2005, SELF IDENTITY, V4, P45, DOI 10.1080/13576500444000164
   Cottrell E, 2012, BMJ OPEN, V2, DOI 10.1136/bmjopen-2012-001391
   Coveney A, 2010, J FR LANG STUD, V20, P127, DOI 10.1017/S0959269509990366
   Darcy Alison, 2021, JMIR Form Res, V5, pe27868, DOI 10.2196/27868
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Dewaele J., 2004, GRUYTER MOUTON, V42, P383, DOI [10.1515/iral.2004.42.4.383, DOI 10.1515/IRAL.2004.42.4.383]
   Diederich S, 2020, BUS INFORM SYST ENG+, V62, P193, DOI 10.1007/s12599-020-00639-y
   Eysenbach G, 2004, J MED INTERNET RES, V6, P12, DOI 10.2196/jmir.6.3.e34
   Field A., 2012, DISCOVERING STAT USI
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Fulmer R, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/mental.9782
   Fussell S. R., 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P145
   Gefen D., 2003, E SERVICE, V2, P7, DOI [DOI 10.2979/ESJ.2003.2.2.7, https://doi.org/10.2979/esj.2003.2.2.7]
   Go E, 2019, COMPUT HUM BEHAV, V97, P304, DOI 10.1016/j.chb.2019.01.020
   Gosselin K, 2016, MED TEACH, V38, P691, DOI 10.3109/0142159X.2015.1105941
   Grohmann B, 2009, J MARKETING RES, V46, P105, DOI 10.1509/jmkr.46.1.105
   Hauser-Ulrich S, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/15806
   Hoitgraves TM, 2008, PERS SOC PSYCHOL REV, V12, P73, DOI 10.1177/1088868307309605
   Holtgraves TM, 2007, COMPUT HUM BEHAV, V23, P2163, DOI 10.1016/j.chb.2006.02.017
   Holtgraves Thomas M., 2002, LANGUAGE SOCIAL ACTI
   House J, 2020, J PRAGMATICS, V161, P1, DOI 10.1016/j.pragma.2020.03.001
   Hsieh SH, 2017, COMPUT HUM BEHAV, V69, P405, DOI 10.1016/j.chb.2016.12.052
   Hu Y., 2004, J COMPUT-MEDIAT COMM, V10, P38, DOI DOI 10.1111/J.1083-6101.2004.TB00231.X
   Inkster B, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/12106
   Joerin A, 2019, CUREUS, V11, DOI 10.7759/cureus.3972
   Kehr F, 2015, INFORM SYST J, V25, P607, DOI 10.1111/isj.12062
   Kluge B., 2019, ITS NOT ALL YOU NEW, DOI [10.1075/tar.1, DOI 10.1075/TAR.1]
   Kostkova P, 2015, FRONT PUBLIC HEALTH, V3, DOI 10.3389/fpubh.2015.00134
   Kowatsch T., 2018, IMPACT INTERPERSONAL
   Kowatsch T, 2021, J MED INTERNET RES, V23, DOI 10.2196/25060
   Kretzschmar K, 2019, BIOMED INFORM INSIGH, V11, DOI 10.1177/1178222619829083
   Kuelewska K., 2016, STUDIELOGIC GRAMMA, V45, P125, DOI [10.1515/slgr-2016-0020, DOI 10.1515/SLGR-2016-0020]
   Kunzli A., 2009, BABEL REV INT TRAD, V55, P364, DOI [10.1075/babel.55.4.04kun, DOI 10.1075/BABEL.55.4.04KUN]
   Lambooij MS, 2015, BMC MED RES METHODOL, V15, DOI 10.1186/s12874-015-0010-5
   Lee S, 2020, INT J HUM-COMPUT INT, V36, P930, DOI 10.1080/10447318.2019.1699748
   Lee YC, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376175
   Lenoir A-SI., 2014, NA ADV CONSUMER RES, V42, P136
   Liao QV, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173577
   Luxton D, 2021, INNOVATIONS GLOBAL M, P489
   Luxton DD, 2020, B WORLD HEALTH ORGAN, V98, P285, DOI 10.2471/BLT.19.237636
   Mangham LJ, 2010, HEALTH POLICY PLANN, V25, P85, DOI 10.1093/heapol/czp066
   Mende M, 2015, J SERV RES-US, V18, P351, DOI 10.1177/1094670514559001
   Norrby C, 2011, MULTILING MATTER, P242
   Oh C, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174223
   Reichheld FF, 2003, HARVARD BUS REV, V81, P46
   Reichheld FF., 2006, J TARGET MEASURE ANA, V14, P369, DOI [10.1057/palgrave.jt.5740195, DOI 10.1057/PALGRAVE.JT.5740195]
   Rendle-Short J, 2009, AUST J LINGUIST, V29, P245, DOI 10.1080/07268600902823110
   Rheu M, 2021, INT J HUM-COMPUT INT, V37, P81, DOI 10.1080/10447318.2020.1807710
   Ring L, 2014, LECT NOTES ARTIF INT, V8637, P374, DOI 10.1007/978-3-319-09767-1_49
   ROOK DW, 1987, J CONSUM RES, V14, P189, DOI 10.1086/209105
   Ryabova M, 2015, PROCD SOC BEHV, V206, P90, DOI 10.1016/j.sbspro.2015.10.033
   Sarma KVS., 2018, MULTIVARIATE STAT MA
   Schuetzler RM, 2020, J MANAGE INFORM SYST, V37, P875, DOI 10.1080/07421222.2020.1790204
   Schupbach D., 2007, 2006 ANN M AUSTR LIN
   Schwarzer R, 2008, APPL PSYCHOL-INT REV, V57, P1, DOI 10.1111/j.1464-0597.2007.00325.x
   Seeger A.-M., 2017, P 16 ANN PREICIS WOR
   Shamekhi A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173965
   Sheeran P, 2016, SOC PERSONAL PSYCHOL, V10, P503, DOI 10.1111/spc3.12265
   Skjuve M, 2021, INT J HUM-COMPUT ST, V149, DOI 10.1016/j.ijhcs.2021.102601
   SOLOMON MR, 1985, J MARKETING, V49, P99, DOI 10.2307/1251180
   Stein Natalie, 2017, JMIR Diabetes, V2, pe28, DOI 10.2196/diabetes.8590
   Stephens TN, 2019, TRANSL BEHAV MED, V9, P440, DOI 10.1093/tbm/ibz043
   Stevens J.P., 2012, INTERMEDIATE STAT MO
   Sundar S, 2008, P 11 ANN INT WORKSH, P219
   Svennevig J., 2000, GETTING ACQUAINTED C
   Tabachnick B., 2007, HDB APPL MULTIVARIAT, V3, P402
   Verhagen T, 2014, J COMPUT-MEDIAT COMM, V19, P529, DOI 10.1111/jcc4.12066
   Warren J, 2006, AUST REV APPL LINGUI, V29, DOI 10.2104/aral0616
   Watts RJ., 1988, MULTILINGUA, V7, P313, DOI [10.1515/mult.1988.7.3.313, DOI 10.1515/MULT.1988.7.3.313]
   Wierzbicka A., 2011, ETHNOPRAGMATICS, P31
   Wierzbicka A, 2016, PERSP PRAGMAT PHILO, V9, P209, DOI 10.1007/978-3-319-43491-9_12
   Wierzbicka A, 2016, INTERCULT PRAGMAT, V13, P499, DOI 10.1515/ip-2016-0022
   Wierzbicka Anna, 2015, INT J LANG CULT, V2, P1, DOI DOI 10.1075/IJOLC.2.1.01WIE
   Williams L, 2009, LANG SCI, V31, P409, DOI 10.1016/j.langsci.2007.11.001
   Willis JR., 2010, ASIAN AM, P214
   Wixom BH, 2005, INFORM SYST RES, V16, P85, DOI 10.1287/isre.1050.0042
   Yin LX, 2010, LECT NOTES ARTIF INT, V6356, P343, DOI 10.1007/978-3-642-15892-6_36
   Yzerbyt VY, 2004, J EXP SOC PSYCHOL, V40, P424, DOI 10.1016/j.jesp.2003.10.001
NR 98
TC 1
Z9 1
U1 5
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2296-2565
J9 FRONT PUBLIC HEALTH
JI Front. Public Health
PD JAN 5
PY 2022
VL 9
AR 691595
DI 10.3389/fpubh.2021.691595
PG 19
WC Public, Environmental & Occupational Health
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Public, Environmental & Occupational Health
GA YK4RH
UT WOS:000745201500001
PM 35071147
OA Green Published, gold
DA 2022-08-02
ER

PT J
AU Paul, SC
   Bartmann, N
   Clark, JL
AF Paul, Stephen C.
   Bartmann, Nina
   Clark, Jenna L.
TI Customizability in conversational agents and their impact on health
   engagement
SO HUMAN BEHAVIOR AND EMERGING TECHNOLOGIES
LA English
DT Article
DE AI; consumer behavior; eHealth; electronic commerce; gender; human
   behavior; human-computer interaction; human social behavior; mHealth;
   mobile technology
ID GOODNESS-OF-FIT; COMPUTER PERSONALITIES; PEDAGOGICAL AGENTS; SOCIAL
   RESPONSES; SELF-DISCLOSURE; DESIGN; GENDER; SIMILARITY; CUSTOMIZATION;
   ORIENTATION
AB Conversational agents (CAs) are effective tools for health behavior change, yet little research investigates the mechanisms through which they work. In accordance with the Computer as Social Actors (CASA) paradigm, we suggest that agents are perceived as human-like actors and hence influence behavior much as human coaches might. As such, agents should be designed to resemble ideal interaction patterns-for example, by resembling their users. Our study will test this paradigm by testing the impact of customization on similarity and reciprocity, which in turn are hypothesized to improve perceptions of the agent and compliance with the agent's recommendations.
C1 [Paul, Stephen C.] North Carolina State Univ, Dept Psychol, 640 Poe Hall,Campus Box 7650, Raleigh, NC 27695 USA.
   [Bartmann, Nina; Clark, Jenna L.] Duke Univ, Ctr Adv Hindsight, Durham, NC USA.
RP Paul, SC (corresponding author), North Carolina State Univ, Dept Psychol, 640 Poe Hall,Campus Box 7650, Raleigh, NC 27695 USA.
EM spaul6@ncsu.edu
OI Bartmann, Nina/0000-0003-4221-2733; Clark, Jenna/0000-0003-0210-5749
FU Zilveren Kruis Zorgverzekeringen N.V.
FX This research was supported by Zilveren Kruis Zorgverzekeringen N.V.
CR ARON A, 1992, J PERS SOC PSYCHOL, V63, P596, DOI 10.1037/0022-3514.63.4.596
   Atakan SS, 2014, INT J RES MARK, V31, P395, DOI 10.1016/j.ijresmar.2014.05.003
   Bahns AJ, 2017, J PERS SOC PSYCHOL, V112, P329, DOI 10.1037/pspp0000088
   Baylor AL, 2004, LECT NOTES COMPUT SC, V3220, P592
   Beale R, 2009, INT J HUM-COMPUT ST, V67, P755, DOI 10.1016/j.ijhcs.2009.05.001
   Behrend TS, 2012, INT J TRAIN DEV, V16, P263, DOI 10.1111/j.1468-2419.2012.00413.x
   Behrend TS, 2011, COMPUT HUM BEHAV, V27, P1201, DOI 10.1016/j.chb.2010.12.016
   Bickmore TW, 2013, PATIENT EDUC COUNS, V92, P142, DOI 10.1016/j.pec.2013.05.011
   Blankenship V., 1984, J SOCIAL PERSONAL RE, V1, P415, DOI [10.1177/0265407584014002, DOI 10.1177/0265407584014002]
   Brave S, 2005, INT J HUM-COMPUT ST, V62, P161, DOI 10.1016/j.ijhcs.2004.11.002
   Brown T. A., 2015, CONFIRMATORY FACTOR
   BYRNE D, 1969, ADV EXPT SOCIAL PSYC, V4, P35, DOI DOI 10.1016/S0065-2601(08)60076-3
   Chaves A.P., 2019, ARXIV190402743CS
   Cialdini R.B., 1993, INFLUENCE SCI PRACTI, P253
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   Ducheneaut N, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1151
   Ensher EA, 1997, J VOCAT BEHAV, V50, P460, DOI 10.1006/jvbe.1996.1547
   Fadhil A., 2019, ARXIV190209022CS
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fiske ST, 2002, J PERS SOC PSYCHOL, V82, P878, DOI 10.1037//0022-3514.82.6.878
   Fogg BJ, 1997, INT J HUM-COMPUT ST, V46, P551, DOI 10.1006/ijhc.1996.0104
   Fong K, 2015, PERS SOC PSYCHOL B, V41, P237, DOI 10.1177/0146167214562761
   Forlizzi J., 2007, P 2007 C DES PLEAS P, V209, DOI 10.1145/1314161.1314180
   Franke N, 2010, MANAGE SCI, V56, P125, DOI 10.1287/mnsc.1090.1077
   Gable SL, 2004, J PERS SOC PSYCHOL, V87, P228, DOI 10.1037/0022-3514.87.2.228
   Goetz J, 2003, RO-MAN 2003: 12TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P55
   Gong L, 2008, COMPUT HUM BEHAV, V24, P1494, DOI 10.1016/j.chb.2007.05.007
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1
   GOULDNER AW, 1960, AM SOCIOL REV, V25, P161, DOI 10.2307/2092623
   Gray K, 2012, COGNITION, V125, P125, DOI 10.1016/j.cognition.2012.06.007
   HOLM S, 1979, SCAND J STAT, V6, P65
   Hu LT, 1999, STRUCT EQU MODELING, V6, P1, DOI 10.1080/10705519909540118
   Kim Y, 2007, J COMPUT ASSIST LEAR, V23, P220, DOI 10.1111/j.1365-2729.2006.00210.x
   Koole SL, 2003, ONT SYMP P, V9, P93
   Laurenceau JP, 1998, J PERS SOC PSYCHOL, V74, P1238, DOI 10.1037/0022-3514.74.5.1238
   Lee E.J., 1998, P 1998 WORKSH EMB CO
   Lee EJ, 2008, INT J HUM-COMPUT ST, V66, P789, DOI 10.1016/j.ijhcs.2008.07.009
   Lee KM, 2005, MEDIA PSYCHOL, V7, P31, DOI 10.1207/S1532785XMEP0701_2
   Lee KM, 2006, INT J HUM-COMPUT ST, V64, P962, DOI 10.1016/j.ijhcs.2006.05.002
   Ling H., 2020, HUMAN MACHINE COMMUN, V1, P133, DOI [10.30658/hmc.1.8, DOI 10.30658/HMC.1.8]
   Litman L, 2017, BEHAV RES METHODS, V49, P433, DOI 10.3758/s13428-016-0727-z
   Marcoulides KM, 2017, STRUCT EQU MODELING, V24, P148, DOI 10.1080/10705511.2016.1225260
   Miner AS, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0280-0
   Mochon D, 2012, INT J RES MARK, V29, P363, DOI 10.1016/j.ijresmar.2012.05.001
   Mohammed S, 2004, J ORGAN BEHAV, V25, P1015, DOI 10.1002/job.293
   Montoya RM, 2008, J SOC PERS RELAT, V25, P889, DOI 10.1177/0265407508096700
   Moon Y, 2000, J CONSUM RES, V26, P323, DOI 10.1086/209566
   Moon Y, 1996, COMMUN RES, V23, P651, DOI 10.1177/009365096023006002
   Moreno R, 2006, CONTEMP EDUC PSYCHOL, V31, P186, DOI 10.1016/j.cedpsych.2005.05.002
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   NASS C, 1995, INT J HUM-COMPUT ST, V43, P223, DOI 10.1006/ijhc.1995.1042
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Norton MI, 2012, J CONSUM PSYCHOL, V22, P453, DOI 10.1016/j.jcps.2011.08.002
   Nye CD, 2011, ORGAN RES METHODS, V14, P548, DOI 10.1177/1094428110368562
   Pandorabots, CHATBOTS CHARACTER, DOI 10.1016/j.intcom.2007.02.003
   Pereira J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1237-1
   Perski O, 2019, DIGIT HEALTH, V5, DOI 10.1177/2055207619880676
   Pratt JA, 2007, INTERACT COMPUT, V19, P512, DOI 10.1016/j.intcom.2007.02.003
   R Development Core Team, 2011, R LANG ENV STAT COMP
   Ratan R, 2015, COMPUT HUM BEHAV, V50, P367, DOI 10.1016/j.chb.2015.04.010
   Reeves B., 1996, MEDIA EQUATION PEOPL, P305
   Reis HT, 1988, HDB PERSONAL RELATIO, P367, DOI DOI 10.1016/0045-7825(81)90049-9
   Rosseel Y, 2012, J STAT SOFTW, V48, P1, DOI 10.18637/jss.v048.i02
   Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68
   Social Security Administration, TOP 10 BAB NAM 2020
   Teng CI, 2010, COMPUT HUM BEHAV, V26, P1547, DOI 10.1016/j.chb.2010.05.029
   Tsui A.S., 1995, DIVERSITY ORG NEW PE, P191, DOI DOI 10.4135/9781452243405.N8.
   Vasalou A, 2009, COMPUT HUM BEHAV, V25, P510, DOI 10.1016/j.chb.2008.11.007
   Wald Rebecca, 2021, UMAP '21: Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization, P382, DOI 10.1145/3450614.3463600
   Watson A, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.1629
   Xiao J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1293
   Yuan KH, 2016, STRUCT EQU MODELING, V23, P319, DOI 10.1080/10705511.2015.1065414
NR 72
TC 0
Z9 0
U1 1
U2 2
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
EI 2578-1863
J9 HUM BEHAV EMERG TECH
JI Hum. Behav. Emerg. Tech.
PD DEC
PY 2021
VL 3
IS 5
BP 1141
EP 1152
DI 10.1002/hbe2.320
EA DEC 2021
PG 12
WC Psychology, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Psychology
GA YD2MT
UT WOS:000734324600001
DA 2022-08-02
ER

PT C
AU Robb, DA
   Lopes, J
   Padilla, S
   Laskov, A
   Garcia, FJC
   Liu, XK
   Willners, JS
   Valeyrie, N
   Lohan, K
   Lane, D
   Patron, P
   Petillot, Y
   Chantler, MJ
   Hastie, H
AF Robb, David A.
   Lopes, Jose
   Padilla, Stefano
   Laskov, Atanas
   Garcia, Francisco J. Chiyah
   Liu, Xingkun
   Willners, Jonatan Scharff
   Valeyrie, Nicolas
   Lohan, Katrin
   Lane, David
   Patron, Pedro
   Petillot, Yvan
   Chantler, Mike J.
   Hastie, Helen
GP ACM
TI Exploring Interaction with Remote Autonomous Systems using
   Conversational Agents
SO PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE
   (DIS 2019)
LA English
DT Proceedings Paper
CT ACM Designing Interactive Systems Conference (DIS)
CY JUN 24-28, 2019
CL San Diego, CA
SP Assoc Comp Machinery, Adobe, Google, UC San Diego Design Lab, Virginia Tech, Sketch
DE Natural Language Interfaces; Remote Autonomous Systems; Explainable AI;
   Multimodal Interfaces; Trust; Transparency
ID TRANSPARENCY; GENERATION; MODELS
AB Autonomous vehicles and robots are increasingly being deployed to remote, dangerous environments in the energy sector, search and rescue and the military. As a result, there is a need for humans to interact with these robots to monitor their tasks, such as inspecting and repairing offshore wind-turbines. Conversational Agents can improve situation awareness and transparency, while being a hands-free medium to communicate key information quickly and succinctly. As part of our user-centered design of such systems, we conducted an indepth immersive qualitative study of twelve marine research scientists and engineers, interacting with a prototype Conversational Agent. Our results expose insights into the appropriate content and style for the natural language interaction and, from this study, we derive nine design recommendations to inform future Conversational Agent design for remote autonomous systems.
C1 [Robb, David A.; Lopes, Jose; Padilla, Stefano; Garcia, Francisco J. Chiyah; Liu, Xingkun; Willners, Jonatan Scharff; Valeyrie, Nicolas; Lohan, Katrin; Lane, David; Petillot, Yvan; Chantler, Mike J.; Hastie, Helen] Heriot Watt Univ, Edinburgh, Midlothian, Scotland.
   [Laskov, Atanas; Willners, Jonatan Scharff; Patron, Pedro] Seebyte Ltd, Edinburgh, Midlothian, Scotland.
RP Robb, DA (corresponding author), Heriot Watt Univ, Edinburgh, Midlothian, Scotland.
EM d.a.robb@hw.ac.uk
OI Aguas Lopes, Jose David/0000-0002-8773-9216; Chantler,
   Mike/0000-0002-8381-1751
FU Strongmar Project H2020-TWINN-2015 [692427]; UK MOD Dstl [ACC101939];
   EPSRC [EP/R026173/1]
FX We thank all those who took part in the Strongmar 2018 Summer School in
   underwater marine environment perception and the staff of the Underwater
   Centre, Fort William, Scotland, UK for their generous cooperation during
   the study. We also thank the anonymous reviewers for their helpful
   suggestions. The summer school was supported by the Strongmar Project
   H2020-TWINN-2015, 692427. This work was supported by UK MOD Dstl
   ACC101939 and the EPSRC EP/R026173/1 ORCA Hub.
CR Alastair Cormack, 2010, P OCEANS 10 IEEE SYD, P1
   Blazhenkova O, 2009, APPL COGNITIVE PSYCH, V23, P638, DOI 10.1002/acp.1473
   Breazeal C, 2013, J HUM-ROBOT INTERACT, V2, P82, DOI 10.5898/JHRI.2.1.Breazeal
   Brennan Susan E, 1998, AUTOMATED SPOKEN DIA
   Chen JYC, 2018, THEOR ISS ERGON SCI, V19, P259, DOI 10.1080/1463922X.2017.1315750
   Chen JYC, 2014, IEEE T HUM-MACH SYST, V44, P13, DOI 10.1109/THMS.2013.2293535
   Corbin J., 2008, BASICS QUALITATIVE R, V3
   Curry Amanda Cercas, 2017, P ICMI WORKSH INV SO
   Dethlefs Nina, 2014, P WORKSH SEM DIAL SE
   Engelbrecht Klaus-Peter, 2009, P SPEC INT GROUP DIS
   Ferguson G., 1996, Proceedings. Third International Conference on Artificial Intelligence Planning Systems, P70
   Ferguson G, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P567
   Garcia Francisco J. Chiyah, 2018, P INT C NAT LANG GEN
   Goodrich Michael A, 2007, Foundations and Trends in Human-Computer Interaction, V1, P203, DOI 10.1561/1100000005
   Gregor S, 1999, MIS QUART, V23, P497, DOI 10.2307/249487
   GRICE HP, 1975, SYNTAX SEMANTICS, V3, DOI DOI 10.1111/J.1365-2664.2006.01229.X
   Gustafson Joakim, 2000, P 6 INT C SPOK LANG
   Hastie H., 2017, P 19 ACM INT C MULT, P495, DOI DOI 10.1145/3136755.3143022
   Hastie H., 2012, DATA DRIVEN METHODS, P131, DOI [http://dx.doi.org/10.1007/978-1-4614-4803-7_7, DOI 10.1007/978..1-4614-4803-77]
   Hastie H., 2018, P 13 ANN ACM IEEE IN
   Hastie H, 2017, OCEANS-IEEE
   Hastie HW, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P384
   Henderson Lyn, 2010, J VIRTUAL WORLDS RES, V3, P1
   Huang TH, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173869
   Jain M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174042
   Jain M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P895, DOI 10.1145/3196709.3196735
   Janarthanam S, 2014, COMPUT LINGUIST, V40, P883, DOI [10.1162/COLI_a_00203, 10.1162/coli_a_00203]
   JOHNSONLAIRD PN, 1980, COGNITIVE SCI, V4, P71, DOI 10.1207/s15516709cog0401_4
   Jurcicek F, 2012, COMPUT SPEECH LANG, V26, P168, DOI 10.1016/j.csl.2011.09.004
   Kulesza T, 2013, S VIS LANG HUM CEN C, P3, DOI 10.1109/VLHCC.2013.6645235
   Kwon YS, 2012, IEEE T ROBOT, V28, P681, DOI 10.1109/TRO.2012.2183049
   Lane David, 2013, ONTOLOGY BASED APPRO, P225
   Le Bras P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173978
   Leite I, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P13, DOI 10.1145/2993148.2993190
   Lemon Oliver, 2001, 7 EUR C SPEECH TECHN, P1559
   Li JW, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P994
   Liao QV, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P264, DOI 10.1145/2901790.2901842
   Lim BY, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2119
   Liu Chia-Wei, 2016, ARXIV160308023
   Lopes J, 2015, COMPUT SPEECH LANG, V31, P87, DOI 10.1016/j.csl.2014.11.007
   Lopes Jose, 2018, ICMI 18 WORKSH MOD C
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Mercado JE, 2016, HUM FACTORS, V58, P401, DOI 10.1177/0018720815621206
   Miguelanez E, 2011, IEEE T KNOWL DATA EN, V23, P759, DOI 10.1109/TKDE.2010.46
   Misu Teruhisa, 2013, P 6 WORKSH EYE GAZ I, P25, DOI [10.1145/2535948.2535951, DOI 10.1145/2535948.2535951]
   Mueller E.T., 2016, TRANSPARENT COMPUTER
   Nagatani K, 2013, J FIELD ROBOT, V30, P44, DOI 10.1002/rob.21439
   Norman Don., 2013, DESIGN EVERYDAY THIN
   Nothdurft F., 2014, P 15 ANN M SPEC INT, P51, DOI DOI 10.3115/V1/W14-4307
   Oviatt S, 2000, COMMUN ACM, V43, P45, DOI 10.1145/330534.330538
   Padilla S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P815, DOI 10.1145/3025453.3025977
   Papaioannou I, 2017, AL PRIZ P
   Petillot Yvan, 2009, P AUVSIS UNM SYST EU
   Price P., 1990, SPEECH NAT LANG P WO, P91, DOI 10.3115/116580.116612
   Rami Al-Rfou, 2016, CONVERSATIONAL CONTE, V10
   Raux A., 2005, 9 EUR C SPEECH COMM
   Reiter E., 2000, BUILDING NATURAL LAN
   Rieser V, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P2356
   Ritter A., 2011, P C EMP METH NAT LAN, P583
   Robb DA, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P384, DOI 10.1145/3242969.3242974
   Robb DA, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1355, DOI 10.1145/2702123.2702470
   Seneff S, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P665, DOI 10.1109/ICSLP.1996.607449
   Seneff S., 2000, P ANLP NAACL WORKSH, P11, DOI DOI 10.3115/1117562.1117565
   Shukla A, 2016, ROBOT AUTON SYST, V75, P490, DOI 10.1016/j.robot.2015.09.012
   Silverman D., 2010, DOING QUALITATIVE RE, V3rd ed.
   Strauss A. L., 1987, QUALITATIVE ANAL SOC
   Stubbs K, 2007, IEEE INTELL SYST, V22, P42, DOI 10.1109/MIS.2007.21
   SWERTS M, 2000, P INT C SPOK LANG PR, P615
   Tallyn E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174178
   The Institute of Engineering and Technology, 2015, ENG TECHN SKILLS DEM
   Theodorou Andreas, 2016, P AISB WORKSH PRINC
   Trevelyan J, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1521
   Vinyals O, 2015, COMPUTER SCI
   WALKER M, 2002, P INT C SPOK LANG PR, P269
   Walker MA, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P271
   Walker MA, 2004, COGNITIVE SCI, V28, P811, DOI 10.1016/j.cogsci.2004.06,002
   Wang ZR, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS'15), P1959
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Williams JD, 2007, COMPUT SPEECH LANG, V21, P393, DOI 10.1016/j.csl.2006.06.008
   Wong C. S., 2017, P 19 EUR C POW EL AP, P1, DOI [10.23919/IConAC.2017.8082020, DOI 10.23919/ICONAC.2017.8082020]
   Wortham RH, 2017, LECT NOTES COMPUT SC, V10454, P274, DOI 10.1007/978-3-319-64107-2_22
   Wortham RH, 2017, CONNECT SCI, V29, P242, DOI 10.1080/09540091.2017.1313816
   Zue V, 2000, IEEE T SPEECH AUDI P, V8, P85, DOI 10.1109/89.817460
NR 83
TC 3
Z9 3
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5850-7
PY 2019
BP 1543
EP 1556
DI 10.1145/3322276.3322318
PG 14
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications; Computer Science, Software Engineering; Engineering,
   Electrical & Electronic; Ergonomics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Engineering
GA BS3ZH
UT WOS:000717008300121
OA Bronze
DA 2022-08-02
ER

PT J
AU Griol, D
   Sanchis, A
   Molina, JM
   Callejas, Z
AF Griol, David
   Sanchis, Araceli
   Manuel Molina, Jose
   Callejas, Zoraida
TI Developing enhanced conversational agents for social virtual worlds
SO NEUROCOMPUTING
LA English
DT Article
DE Conversational interfaces; Speech interaction; Statistical dialog
   management; User modeling; Social networks; Virtual worlds; Second life;
   Affective computing
ID AVATAR; ENGAGEMENT; SPACE; LIFE
AB In this paper, we present a methodology for the development of embodied conversational agents for social virtual worlds. The agents provide multimodal communication with their users in which speech interaction is included. Our proposal combines different techniques related to Artificial Intelligence, Natural Language Processing, Affective Computing, and User Modeling. A statistical methodology has been developed to model the system conversational behavior, which is learned from an initial corpus and improved with the knowledge acquired from the successive interactions. In addition, the selection of the next system response is adapted considering information stored into user's profiles and also the emotional contents detected in the user's utterances. Our proposal has been evaluated with the successful development of an embodied conversational agent which has been placed in the Second Life social virtual world. The avatar includes the different models and interacts with the users who inhabit the virtual world in order to provide academic information. The experimental results show that the agent's conversational behavior adapts successfully to the specific characteristics of users interacting in such environments. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Griol, David; Sanchis, Araceli; Manuel Molina, Jose] Univ Carlos III Madrid, Dept Comp Sci, Madrid, Spain.
   [Callejas, Zoraida] Univ Granada, Dept Languages & Comp Syst, Granada, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Madrid, Spain.
EM david.griol@uc3m.es; araceli.sanchis@uc3m.es; Josemanuel.molina@uc3m.es
RI Callejas, Zoraida/AAX-4634-2020; Furtado, Kássia/AAU-5007-2020; ARSLAN,
   Okan/AAA-3232-2020; Molina, JOSE/B-1956-2008
OI Callejas, Zoraida/0000-0001-8891-5237; Molina, JOSE/0000-0002-7484-7357
FU Spanish CICyT Projects [TRA2015-63708-R, TRA2016-78886-C3-1-R]
FX Work partially supported by the Spanish CICyT Projects under grant
   TRA2015-63708-R and TRA2016-78886-C3-1-R.
CR Abdullah A., 2016, LANGUAGE VIRTUAL IDE
   Ahern N, 2010, NURS EDUC, V35, P225, DOI 10.1097/NNE.0b013e3181f7e943
   Ai H., 2007, P 8 SIGDIAL WORKSH D, P124
   [Anonymous], 2014, HDB VIRTUAL ENV DESI
   [Anonymous], 2007, P 8 ANN C INT SPEECH
   Aparicio-Martinez P, 2017, TELEMAT INFORM, V34, P1685, DOI 10.1016/j.tele.2017.08.001
   Bainbridge WS, 2007, SCIENCE, V317, P472, DOI 10.1126/science.1146930
   Balazs JA, 2016, INFORM FUSION, V27, P95, DOI 10.1016/j.inffus.2015.06.002
   Barnes SJ, 2015, TECHNOL FORECAST SOC, V92, P12, DOI 10.1016/j.techfore.2014.10.017
   Berger M, 2016, J PRAGMATICS, V101, P83, DOI 10.1016/j.pragma.2016.05.009
   Bickmore T., ADV NATURAL MULTIMOD, P23
   Boellstorff T., 2015, ANTHR EXPLORES VIRTU
   Boyd DM, 2007, J COMPUT-MEDIAT COMM, V13, P210, DOI 10.1111/j.1083-6101.2007.00393.x
   Burkhardt F, 2009, P INT C AFF COMP INT, P1, DOI DOI 10.1109/ACII.2009.5349498
   Callejas Z., 2005, P APPL SPOK LANG INT, P1
   Cassell J, 2001, AI MAG, V22, P67
   Clavel C, 2016, IEEE T AFFECT COMPUT, V7, P74, DOI 10.1109/TAFFC.2015.2444846
   Cox AJ, 2016, LECT NOTES COMPUT SC, V9954, P1, DOI [10.1007/978-3-319-46049-9_1, 10.1145/2890602.2906192]
   Cruz A., 2014, PROCEDIA TECHNOLOGY, V13, P47
   Cruz-Benito J, 2015, COMPUT HUM BEHAV, V47, P18, DOI 10.1016/j.chb.2014.11.028
   D'Agustino S., 2013, IMMERSIVE ENV AUGMEN
   Dinarelli M., 2010, THESIS
   Dunbar RIM, 2015, SOC NETWORKS, V43, P39, DOI 10.1016/j.socnet.2015.04.005
   Espana-Boquera S, 2007, LECT NOTES COMPUT SC, V4527, P327
   Gabriels K, 2016, COMPUT HUM BEHAV, V63, P683, DOI 10.1016/j.chb.2016.05.065
   Green J, 2014, COLLEGIAN, V21, P135, DOI 10.1016/j.colegn.2013.11.004
   Gregory S., 2015, VIRTUAL WORLDS ONLIN
   Grinberg AM, 2014, COMPUT HUM BEHAV, V36, P479, DOI 10.1016/j.chb.2014.04.008
   Griol D, 2019, NEUROCOMPUTING, V326, P132, DOI 10.1016/j.neucom.2017.01.120
   Griol D, 2014, COMPUT SPEECH LANG, V28, P743, DOI 10.1016/j.csl.2013.09.002
   Griol D, 2013, AI COMMUN, V26, P355, DOI 10.3233/AIC-130573
   Groom V, 2009, INT J HUM-COMPUT ST, V67, P842, DOI 10.1016/j.ijhcs.2009.07.001
   Gross M, 2017, CURR BIOL, V27, pR399, DOI 10.1016/j.cub.2017.05.060
   Gulz A., 2004, INT J ARTIFICIAL INT, V14, P313
   Gustafsson M, 2017, CURR PHARM TEACH LEA, V9, P887, DOI 10.1016/j.cptl.2017.06.002
   Hasler BS, 2013, COMPUT HUM BEHAV, V29, P1608, DOI 10.1016/j.chb.2013.01.004
   Hoffmann R., 2012, SPEECH SYNTHESIS INT
   Hooi R, 2017, TELEMAT INFORM, V34, P1454, DOI 10.1016/j.tele.2017.06.009
   Hubal RC, 2008, COMPUT HUM BEHAV, V24, P1104, DOI 10.1016/j.chb.2007.03.010
   Jung Y, 2015, TELEMAT INFORM, V32, P193, DOI 10.1016/j.tele.2014.07.002
   Kirschner D., NONVERBAL COMMUNICAT, P307
   Krasonikolakis I, 2014, INFORM MANAGE-AMSTER, V51, P641, DOI 10.1016/j.im.2014.05.017
   Lafferty John, 2001, P 18 INT C MACH LEAR, V1, P282
   LaPensee E., NONVERBAL COMMUNICAT, P105
   Lee C., 2010, J COMPUTING SCI ENG, V4, P1, DOI DOI 10.5626/JCSE.2010.4.1.001
   Li F, 2017, EXPERT SYST APPL, V88, P338, DOI 10.1016/j.eswa.2017.07.004
   Lin H, 2014, COMPUT HUM BEHAV, V34, P213, DOI 10.1016/j.chb.2013.10.005
   Locher MA, 2015, DISCOURSE CONTEXT ME, V9, P34, DOI 10.1016/j.dcm.2015.06.002
   Lomanowska AM, 2014, COMPUT HUM BEHAV, V31, P322, DOI 10.1016/j.chb.2013.10.058
   Lopez-Cozar R, 2008, SPEECH COMMUN, V50, P745, DOI 10.1016/j.specom.2008.03.008
   Lopez-Cozar R, 2010, KNOWL-BASED SYST, V23, P471, DOI 10.1016/j.knosys.2010.03.004
   Macherey K, 2009, IEEE T AUDIO SPEECH, V17, P803, DOI 10.1109/TASL.2009.2014262
   Magnenat-Thalmann N, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P2, DOI 10.1109/MMMC.2005.24
   Mairesse F, 2009, INT CONF ACOUST SPEE, P4749, DOI 10.1109/ICASSP.2009.4960692
   Martin J., NONVERBAL COMMUNICAT, P291
   Martinez-Miranda J, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0784-6
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   McTear M. F., P MACH LEARN BIG DAT, P38
   McTear M. F., 2004, SPOKEN DIALOGUE TECH
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Nelson B., 2014, DESIGN LEARNING VIRT
   Nielsen, 2016, SOCIAL MEDIA REPORT
   Partala T, 2011, INT J HUM-COMPUT ST, V69, P787, DOI 10.1016/j.ijhcs.2011.07.004
   Penni J, 2017, TELEMAT INFORM, V34, P498, DOI 10.1016/j.tele.2016.10.009
   Pieraccini R, 2012, VOICE IN THE MACHINE: BUILDING COMPUTERS THAT UNDERSTAND SPEECH, P1
   Rabiner L., 1996, AUTOMATIC SPEECH SPE, P1
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Romero O.J, 2017, P 26 INT JOINT C ART, P3807, DOI [10.24963/ijcai.2017/532, DOI 10.24963/IJCAI.2017/532]
   Rumelhart D. E., PDP COMPUTATIONAL MO, VI, P319
   Schatzmann J., 2005, P 6 SIGDIAL WORKSH D, P45
   Statista, 2017, VIRT REAL VR STAT FA
   Turkle S., 2015, POWER TALK DIGITAL A
   van Vugt HC, 2007, INTERACT COMPUT, V19, P267, DOI 10.1016/j.intcom.2006.08.005
   Walker M, 2007, J ARTIF INTELL RES, V30, P413, DOI 10.1613/jair.2329
   Yee N, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1
   Young S, 2002, CUEDFINFENGTR433
   Young S, 2007, INT CONF ACOUST SPEE, P149
   Young S, 2013, P IEEE, V101, P1160, DOI 10.1109/JPROC.2012.2225812
   Zhang YL, 2017, COMPUT HUM BEHAV, V68, P378, DOI 10.1016/j.chb.2016.11.052
   2008, SPEECH COMMUN, V50, P646, DOI DOI 10.1016/J.SPECOM.2008.04.004
   2008, SPEECH COMMUN, V50, P666, DOI DOI 10.1016/J.SPECOM.2008.04.001
   2006, SPEECH COMMUN, V48, P262, DOI DOI 10.1016/J.SPECOM.2005.06.002
   2008, SPEECH COMMUN, V50, P716, DOI DOI 10.1016/J.SPECOM.2008.03.01
NR 84
TC 3
Z9 3
U1 7
U2 41
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD AUG 18
PY 2019
VL 354
SI SI
BP 27
EP 40
DI 10.1016/j.neucom.2018.09.099
PG 14
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA HY1XK
UT WOS:000467910600005
OA Green Published
DA 2022-08-02
ER

PT J
AU Zhang, Z
   Bickmore, TW
   Paasche-Orlow, MK
AF Zhang, Zhe
   Bickmore, Timothy W.
   Paasche-Orlow, Michael K.
TI Perceived organizational affiliation and its effects on patient trust:
   Role modeling with embodied conversational agents
SO PATIENT EDUCATION AND COUNSELING
LA English
DT Article
DE Trust; Communication; Relational contextualization; Embodied
   conversational agents
ID HEALTH LITERACY; MEDICAL-TREATMENT; INFORMED-CONSENT; CARE; COGNITION;
   QUALITY; ADULTS; IMPACT; NEED
AB Objective: Verbal and non-verbal behaviors, which are known as "relational contextualization cues", relay information about relationships and how they are structured. We developed a computer-simulated provider conducting an informed consent process for clinical research to investigate the effects of a provider's alignment of interests with a patient, the research team, or a neutral party on patient trust in the provider.
   Methods: Participants (N = 43) interacted with a simulated provider for a research informed consent process in a three-arm, counterbalanced, within-subjects experiment. Participants reported their trust in the simulated provider after each treatment.
   Results: Participants successfully recognized the alignment manipulation, and perceived the patient-aligned provider as more trustworthy than the other providers. Participants were also more satisfied with the patient-aligned provider, liked this provider more, expressed more desire to continue working with this provider, and stated that they were significantly more likely to sign the consent form after interacting with this provider compared to the other two.
   Conclusion: Relational contextualization that aligns with the patient increases trust, satisfaction, and willingness to enroll in the context of research informed consent. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Zhang, Zhe; Bickmore, Timothy W.] Northeastern Univ, Coll Comp & Informat Sci, 177 Huntington Ave,9th Floor, Boston, MA 02115 USA.
   [Paasche-Orlow, Michael K.] Boston Univ, Sch Med, Sect Gen Internal Med, Boston, MA 02118 USA.
   [Paasche-Orlow, Michael K.] Boston Med Ctr, Boston, MA USA.
RP Zhang, Z (corresponding author), Northeastern Univ, Coll Comp & Informat Sci, 177 Huntington Ave,9th Floor, Boston, MA 02115 USA.
EM zessiez@gmail.com
RI Paasche-Orlow, Michael/ABF-7919-2020
OI Paasche-Orlow, Michael/0000-0002-9276-7190
FU National Cancer Institute [CA158219-04]; NATIONAL CANCER INSTITUTE
   [R01CA158219] Funding Source: NIH RePORTER
FX This work was supported by a grant from the National Cancer Institute
   [CA158219-04] (Co-PIs Michael Paasche-Orlow and Timothy Bickmore).
CR Aggarwal A, 2014, BMC MED ETHICS, V15, DOI 10.1186/1472-6939-15-31
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore T, 2006, J BIOMED INFORM, V39, P556, DOI 10.1016/j.jbi.2005.12.004
   Bickmore T, 2008, INT J SEMANT COMPUT, V2, P47, DOI 10.1142/S1793351X08000348
   Bickmore TW, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5239
   Bickmore TW, 2013, J AM GERIATR SOC, V61, P1676, DOI 10.1111/jgs.12449
   Bickmore TW, 2010, J HEALTH COMMUN, V15, P197, DOI 10.1080/10810730.2010.499991
   Bickmore TW, 2009, PATIENT EDUC COUNS, V75, P315, DOI 10.1016/j.pec.2009.02.007
   Bickmore TW, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1265
   Brown Penelope, 1987, POLITENESS SOME UNIV
   CACIOPPO JT, 1982, J PERS SOC PSYCHOL, V42, P116, DOI 10.1037/0022-3514.42.1.116
   Camarinha-Matos LA, 2006, INT FED INFO PROC, V207, P26
   Cassell J, 2004, COG TECH, P163
   Davis T C, 1993, Fam Med, V25, P391
   Elwyn G, 2012, J GEN INTERN MED, V27, P1361, DOI 10.1007/s11606-012-2077-6
   Epstein RM, 2000, J FAM PRACTICE, V49, P805
   Gardiner P, 2013, AM J HEALTH PROMOT, V27, pES11, DOI 10.4278/ajhp.1200113-QUAN-18
   Gurmankin AD, 2002, MED DECIS MAKING, V22, P262, DOI 10.1177/02789X02022003008
   Halpern J, 2012, BIOETHICS, V26, P108, DOI 10.1111/j.1467-8519.2010.01817.x
   Hechter M, 1999, EUR SOCIOL REV, V15, P405, DOI 10.1093/oxfordjournals.esr.a018273
   Hibbard JH, 2004, HEALTH SERV RES, V39, P1005, DOI 10.1111/j.1475-6773.2004.00269.x
   Ihaka R., 1996, J COMPUT GRAPH STAT, V5, P299, DOI 10.2307/1390807
   LaVeist TA, 2009, HEALTH SERV RES, V44, P2093, DOI 10.1111/j.1475-6773.2009.01017.x
   Levinson S.C., 1983, PRAGMATICS
   Lincoln A, 2006, J GEN INTERN MED, V21, P818, DOI 10.1111/j.1525-1497.2006.00533.x
   Mancuso CA, 2006, J GEN INTERN MED, V21, P813, DOI 10.1111/j.1525-1497.2006.00528.x
   Petty RE, 2008, PERS SOC PSYCHOL B, V34, P900, DOI 10.1177/0146167208316692
   Reiter E., 2000, BUILDING NATURAL LAN
   Riva S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090941
   Sankar P, 2004, MED ANTHROPOL Q, V18, P429, DOI 10.1525/maq.2004.18.4.429
   Skelton JR, 2002, FAM PRACT, V19, P484, DOI 10.1093/fampra/19.5.484
   Sudore RL, 2006, J GEN INTERN MED, V21, P806, DOI 10.1111/j.1525-1497.2006.00539.x
   Sugarman J, 2005, CLIN TRIALS, V2, P34, DOI 10.1191/1740774505cn066oa
   Svennevig Jan., 2000, GETTING ACQUAINTED C
   Lindau ST, 2006, J GEN INTERN MED, V21, P829, DOI 10.1111/j.1525-1497.2006.00534.x
   Wallander L, 2009, SOC SCI RES, V38, P505, DOI 10.1016/j.ssresearch.2009.03.004
   Weinstock M. P., 1998, SHARED DECISION MAKI, V39, P11
   Wheeless L.R., 1977, HUM COMMUN RES, V3, P250, DOI DOI 10.1111/J.1468-2958.1977.TB00523.X
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
NR 40
TC 11
Z9 11
U1 2
U2 17
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0738-3991
J9 PATIENT EDUC COUNS
JI Patient Educ. Couns.
PD SEP
PY 2017
VL 100
IS 9
BP 1730
EP 1737
DI 10.1016/j.pec.2017.03.017
PG 8
WC Public, Environmental & Occupational Health; Social Sciences,
   Interdisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Public, Environmental & Occupational Health; Social Sciences - Other
   Topics
GA FB3IE
UT WOS:000406035300015
PM 28381330
DA 2022-08-02
ER

PT C
AU Ruane, E
   Faure, T
   Smith, R
   Bean, D
   Carson-Berndsen, J
   Ventresque, A
AF Ruane, Elayne
   Faure, Theo
   Smith, Ross
   Bean, Dan
   Carson-Berndsen, Julie
   Ventresque, Anthony
GP ACM
TI BoTest: a Framework to Test the Quality of Conversational Agents Using
   Divergent Input Examples
SO COMPANION OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER
   INTERFACES (IUI'18)
LA English
DT Proceedings Paper
CT 23rd International Conference on Intelligent User Interfaces (IUI)
CY MAR 07-11, 2018
CL Tokyo, JAPAN
SP Assoc Comp Machinery, ACM SIGAI, ACM SIGCHI
DE Conversational Agent Testing; Conversational Agent Quality Assessment;
   Chatbot
AB Quality of conversational agents is important as users have high expectations. Consequently, poor interactions may lead to the user abandoning the system. In this paper, we propose a framework to test the quality of conversational agents. Our solution transforms working input that the conversational agent accurately recognises to generate divergent input examples that introduce complexity and stress the agent. As the divergent inputs are based on known utterances for which we have the 'normal' outputs, we can assess how robust the conversational agent is to variations in the input. To demonstrate our framework we built ChitChatBot, a simple conversational agent capable of making casual conversation.
C1 [Ruane, Elayne; Faure, Theo; Carson-Berndsen, Julie; Ventresque, Anthony] Univ Coll Dublin, Sch Comp Sci, Dublin, Ireland.
   [Ruane, Elayne; Faure, Theo; Ventresque, Anthony] Lero Irish Software Res Ctr, Limerick, Ireland.
   [Smith, Ross; Bean, Dan] Microsoft Corp, Skype Div, Seattle, WA USA.
RP Ruane, E (corresponding author), Univ Coll Dublin, Sch Comp Sci, Dublin, Ireland.; Ruane, E (corresponding author), Lero Irish Software Res Ctr, Limerick, Ireland.
EM elayne.ruane@ucdconnect.ie; theo.faure@ucdconnect.ie;
   julie.berndsen@ucd.ie; anthony.ventresque@ucd.ie
RI Ruane, Elayne/AAW-3758-2021
OI Berndsen, Julie/0000-0002-1851-3643; Ruane, Elayne/0000-0001-7344-9763;
   Ventresque, Anthony/0000-0003-2064-1238
CR Cassell J., 2000, EMBODIED CONVERSATIO
   LUGER E, 2016, CHI 16, P5286, DOI DOI 10.1145/2858036.2858288
   Nguyen M.-H, BUSINESS INSIDER LAT
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
NR 4
TC 5
Z9 5
U1 1
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5571-1
PY 2018
DI 10.1145/3180308.3180373
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BM0DZ
UT WOS:000458680100064
OA Green Submitted
DA 2022-08-02
ER

PT J
AU Griol, D
   Carbo, J
   Molina, JM
AF Griol, David
   Carbo, Javier
   Molina, Jose M.
TI AN AUTOMATIC DIALOG SIMULATION TECHNIQUE TO DEVELOP AND EVALUATE
   INTERACTIVE CONVERSATIONAL AGENTS
SO APPLIED ARTIFICIAL INTELLIGENCE
LA English
DT Article
ID USER SIMULATION; SYSTEMS; DESIGN
AB During recent years, conversational agents have become a solution to provide straightforward and more natural ways of retrieving information in the digital domain. In this article, we present an agent-based dialog simulation technique for learning new dialog strategies and evaluating conversational agents. Using this technique, the effort necessary to acquire data required to train the dialog model and then explore new dialog strategies is considerably reduced. A set of measures has also been defined to evaluate the dialog strategy that is automatically learned and to compare different dialog corpora. We have applied this technique to explore the space of possible dialog strategies and evaluate the dialogs acquired for a conversational agent that collects monitored data from patients suffering from diabetes. The results of the comparison of these measures for an initial corpus and a corpus acquired using the dialog simulation technique show that the conversational agent reduces the time needed to complete the dialogs and improve their quality, thereby allowing the conversational agent to tackle new situations and generate new coherent answers for the situations already present in an initial model.
C1 [Griol, David; Carbo, Javier; Molina, Jose M.] Univ Carlos III Madrid, Dept Comp Sci, Appl Artificial Intelligence Grp, Leganes, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Appl Artificial Intelligence Grp, Av Univ,30 Edificio Sabatini,Off 2-1 B06, Leganes, Spain.
EM dgriol@inf.uc3m.es
RI Sanchez-Pi, Nayat/K-2049-2015; Griol, David/L-1258-2014; Carbo,
   Javier/ABB-4694-2020; Molina, JOSE/B-1956-2008
OI Sanchez-Pi, Nayat/0000-0002-5037-9974; Griol, David/0000-0001-6266-5321;
   Carbo, Javier/0000-0001-7794-3398; Molina, JOSE/0000-0002-7484-7357
FU Project MINECO [TEC2012-37832-C02-01]; Project CICYT
   [TEC2011-28626-C02-02]; Project CAM CONTEXTS [S2009/TIC-1485]
FX This work was supported in part by Projects MINECO TEC2012-37832-C02-01,
   CICYT TEC2011-28626-C02-02, CAM CONTEXTS (S2009/TIC-1485).
CR Ai H., 2007, P 8 SIGDIAL WORKSH D, P124
   Bailly G, 2010, SPEECH COMMUN, V52, P598, DOI 10.1016/j.specom.2010.02.015
   Ballinas-Hernandez AL, 2011, JASSS-J ARTIF SOC S, V14, DOI 10.18564/jasss.1789
   Balmer M, 2006, INNOVATIONS IN DESIGN & DECISION SUPPORT SYSTEMS IN ARCHITECTURE AND URBAN PLANNING, P167, DOI 10.1007/978-1-4020-5060-2_11
   Bandini S, 2006, LECT NOTES COMPUT SC, V3931, P231
   Bandini S, 2009, JASSS-J ARTIF SOC S, V12, pA51
   Black LA, 2005, COMP MED SY, P506, DOI 10.1109/CBMS.2005.33
   Bohus D., 2007, P 7 M N AM CHAPT ASS, P9
   Bohus D, 2005, TEXT SPEECH LANG TEC, V28, P203
   Bos J., 2003, P 4 SIGDIAL WORKSH D, P115
   Brahnam S, 2009, PSYCHNOLOGY J, V7, P9
   Chung G., 2004, P 42 ANN M ASS COMP, P63
   Cuayahuitl H, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P290
   Eckert W, 1997, 1997 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, PROCEEDINGS, P80, DOI 10.1109/ASRU.1997.658991
   Eckert W., 1998, TR9891 ATT LABS RES
   Garcia F, 2003, LECT NOTES ARTIF INT, V2807, P165
   GEORGILA K, 2005, P 9 EUR C SPEECH COM, P893
   GLASS J, 1995, SPEECH COMMUN, V17, P1, DOI 10.1016/0167-6393(95)00008-C
   Griol D, 2008, SPEECH COMMUN, V50, P666, DOI 10.1016/j.specom.2008.04.001
   Griol D, 2010, ADV INTEL SOFT COMPU, V79, P275
   Heath B, 2009, JASSS-J ARTIF SOC S, V12, pA143
   Jung S, 2011, COMPUT SPEECH LANG, V25, P307, DOI 10.1016/j.csl.2010.06.002
   Klugl F, 2003, LECT NOTES ARTIF INT, V2831, P13
   Levin E, 2000, IEEE T SPEECH AUDI P, V8, P11, DOI 10.1109/89.817450
   Lin BS, 2001, IEEE T SPEECH AUDI P, V9, P534, DOI 10.1109/89.928918
   Lopez-Cozar R, 2003, SPEECH COMMUN, V40, P387, DOI 10.1016/S0167-6393(02)00126-7
   Lopez-Cozar R., 2005, SPOKEN MULTILINGUAL
   Macal CM, 2010, J SIMUL, V4, P151, DOI 10.1057/jos.2010.3
   McTear M. F., 2004, SPOKEN DIALOGUE TECH
   Melin H., 2001, TMH Q PROGR STATUS R, V1, P1
   Menezes P., 2007, HUMANOID ROBOTS HUMA, P367
   Moller S, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1786
   Navarro L., 2011, P 10 INT C AUT AG MU, P701
   North MJ, 2006, ACM T MODEL COMPUT S, V16, P1, DOI 10.1145/1122012.1122013
   Paek T., 2000, P 16 C UNC ART INT S, P455
   Pavon Juan, 2008, International Journal of Agent-Oriented Software Engineering, V2, P196, DOI 10.1504/IJAOSE.2008.017315
   Pietquin O, 2006, IEEE T AUDIO SPEECH, V14, P589, DOI 10.1109/TSA.2005.855836
   Sanchez-Pi N, 2007, SNPD 2007: EIGHTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, VOL 3, PROCEEDINGS, P694, DOI 10.1109/SNPD.2007.394
   Schatzmann J., 2005, P 6 SIGDIAL WORKSH D, P45
   Schatzmann J., 2007, P 8 SIGDIAL WORKSH D, P273
   Schatzmann J., 2007, HUMAN LANGUAGE TECHN, P149
   Schatzmann J, 2006, KNOWL ENG REV, V21, P97, DOI 10.1017/S0269888906000944
   Scheffler K., 2001, P HUM LANG TECHN HLT, P12
   Scheffler K., 2001, P NAACL WORKSH AD DI, P64
   Torres F, 2008, COMPUT SPEECH LANG, V22, P230, DOI 10.1016/j.csl.2007.09.002
   VAQUERO C, 2006, 4 JORNADAS TECNOLOGI, P321
   Weng FL, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1061
   Weyns D., 2006, P 5 INT JOINT C AUT, P842, DOI [10.1145/1160633.1160785, DOI 10.1145/1160633.1160785]
   Wilensky U., 2012, INTRO AGENT BASED MO
   Williams JD, 2007, COMPUT SPEECH LANG, V21, P393, DOI 10.1016/j.csl.2006.06.008
   Windrum P, 2007, JASSS-J ARTIF SOC S, V10
   WOOLDRIDGE M, 1995, KNOWL ENG REV, V10, P115, DOI 10.1017/S0269888900008122
   Young S, 2002, CUEDFINFENGTR433
   Zue V, 2000, IEEE T SPEECH AUDI P, V8, P85, DOI 10.1109/89.817460
NR 54
TC 32
Z9 32
U1 1
U2 18
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0883-9514
EI 1087-6545
J9 APPL ARTIF INTELL
JI Appl. Artif. Intell.
PD OCT 21
PY 2013
VL 27
IS 9
BP 759
EP 780
DI 10.1080/08839514.2013.835230
PG 22
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 232RS
UT WOS:000325512300001
OA Green Accepted
DA 2022-08-02
ER

PT J
AU Kramer, NC
   Bente, G
   Eschenburg, F
   Troitzsch, H
AF Kraemer, Nicole C.
   Bente, Gary
   Eschenburg, Felix
   Troitzsch, Heide
TI Embodied Conversational Agents Research Prospects for Social Psychology
   and an Exemplary Study
SO SOCIAL PSYCHOLOGY
LA English
DT Article
DE embodied conversational agents; innovative research methods; evaluation;
   embodiment; human-technology-interaction
ID NONVERBAL BEHAVIOR; INTERFACE; PERCEPTION
AB It was analyzed whether an embodied conversational agent (ECA) has specific advantages when employed with privacy invading technologies such as a biometric security system. The study compares the effects of an ECA interface with the effects of conventional text-based and voice-based interfaces on user acceptance and usability. An additional variable was whether the biometric system falsely rejected the user twice or whether it directly accepted him/her. Results of the 2 x 3 between-subjects design indicated that, although overall the text interface is rated most positive, voice and ECA yield distinct social effects: They have more advantageous consequences when problems arise - i.e., when the user is rejected repeatedly. The implications for social psychology in terms of applicability of new research methods as well as insights concerning fundamental research are discussed.
C1 [Kraemer, Nicole C.] Univ Duisburg Essen, Dept Social Psychol Media & Commun, D-47057 Duisburg, Germany.
   [Bente, Gary; Eschenburg, Felix] Univ Cologne, Dept Psychol, D-5000 Cologne 41, Germany.
   [Troitzsch, Heide] Univ Appl Sci NW Switzerland, Inst Res & Dev Collaborat Proc Ifk, Olten, Switzerland.
RP Kramer, NC (corresponding author), Univ Duisburg Essen, Dept Social Psychol Media & Commun, Forsthausweg 2, D-47057 Duisburg, Germany.
EM nicole.kraemer@uni-due.de
RI Krämer, Nicole C/F-8329-2012
CR ANDRE E, 2000, P WORKSH ACH HUM LIK, P3
   Bailenson JN, 2001, PRESENCE-TELEOP VIRT, V10, P583, DOI 10.1162/105474601753272844
   BEALL AC, 2003, P HCI INT 2003 CRET
   Bente G, 2001, J NONVERBAL BEHAV, V25, P151, DOI 10.1023/A:1010690525717
   BENTE G, 2001, MENSCH COMPUTER 2001, P275
   Bickmore T, 2004, NATURAL INTELLIGENT
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Cassell J, 2000, COMMUN ACM, V43, P50, DOI 10.1145/355112.355123
   Cassell J., 2000, EMBODIED CONVERSATIO
   Cassell J., 1999, P SIGCHI C HUM FACT, P520, DOI DOI 10.1145/302979.303150
   de Rosis F, 2004, COG TECH, P271
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   Echterhoff G, 2006, Z SOZIALPSYCHOL, V37, P219, DOI 10.1024/0044-3514.37.4.219
   ESCHENBURG F, 2005, INTRO ECA BASE UNPUB
   Gazzaniga M. S., 1998, MINDS
   Hoyt CL, 2003, PRESENCE-TELEOP VIRT, V12, P183, DOI 10.1162/105474603321640932
   KAPPAS A, 2005, ISRE GEN M S ART EM
   Kiesler S., 1997, Human values and the design of computer technology, P191
   Kramer NC, 2007, LECT NOTES ARTIF INT, V4722, P238
   Kramer NC, 2005, LECT NOTES ARTIF INT, V3661, P442
   KRAMER NC, 2007, CMC BIS PERSUASION M, P103
   KRAMER NC, 2003, 4 INT WORK C INT VIR, P292
   Kramer NC, 2003, IMC WORKSH 2003 ASS, P121
   Kramer Nicole C, 2008, SOZIALE WIRKUNGEN VI
   Krumhuber E, 2005, J NONVERBAL BEHAV, V29, P3, DOI 10.1007/s10919-004-0887-x
   MARSELLA S, 2003, P 2 INT JOINT C AUT
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Parise S, 1999, COMPUT HUM BEHAV, V15, P123, DOI 10.1016/S0747-5632(98)00035-1
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Rickenberg R, 2000, EFFECTS ANIMATED CHA, P49, DOI [DOI 10.1145/332040, 10.1145/332040]
   RUEBENSTRUNK G, 1998, THESIS U BIELEFELD
   Schilbach L, 2006, NEUROPSYCHOLOGIA, V44, P718, DOI 10.1016/j.neuropsychologia.2005.07.017
   Sproull L, 1996, HUM-COMPUT INTERACT, V11, P97, DOI 10.1207/s15327051hci1102_1
   TROITZSCH H, 2005, INTRO MULTIMODULAR A
   [No title captured]
NR 36
TC 12
Z9 12
U1 0
U2 9
PU HOGREFE & HUBER PUBLISHERS
PI GOTTINGEN
PA MERKELSTR 3, D-37085 GOTTINGEN, GERMANY
SN 1864-9335
EI 2151-2590
J9 SOC PSYCHOL-GERMANY
JI Soc. Psychol.
PY 2009
VL 40
IS 1
BP 26
EP 36
DI 10.1027/1864-9335.40.1.26
PG 11
WC Psychology, Social
WE Social Science Citation Index (SSCI)
SC Psychology
GA 412RL
UT WOS:000263741800005
DA 2022-08-02
ER

PT C
AU Griol, D
   Molina, JM
AF Griol, David
   Molina, Jose M.
BE Molina, JM
   Corredera, JRC
   Perez, MFC
   OrtegaGarcia, J
   Barbolla, AMB
TI Context-Aware Conversational Agents Using POMDPs and Agenda-Based
   Simulation
SO USER-CENTRIC TECHNOLOGIES AND APPLICATIONS
SE Advances in Intelligent and Soft Computing
LA English
DT Proceedings Paper
CT CONTEXTS 2011 Workshop on User-Centric Technologies and Applications
CY APR 06-08, 2011
CL Univ Salamanca, Salamanca, SPAIN
SP IEEE Syst, Man & Cybernet Soc (SMCS), IEEE Secc Espana
HO Univ Salamanca
AB Context-aware systems in combination with mobile devices offer new opportunities in the areas of knowledge representation, natural language processing and intelligent information retrieval. Our vision is that natural spoken conversation with these devices can eventually become the preferred mode for managing their services by means of conversational agents. In this paper, we describe the application of POMDPs and agenda-based user simulation to learn optimal dialog policies for the dialog manager in a conversational agent. We have applied this approach to develop a statistical dialog manager for a conversational agent which acts as a voice logbook to collect home monitored data from patients suffering from diabetes.
C1 [Griol, David; Molina, Jose M.] Univ Carlos III Madrid, Dept Comp Sci, Grp Appl Artificial Intelligence GIAA, Madrid, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Grp Appl Artificial Intelligence GIAA, Madrid, Spain.
EM david.griol@uc3m.es; josemanuel.molina@uc3m.es
RI Griol, David/L-1258-2014; Molina, JOSE/B-1956-2008
OI Griol, David/0000-0001-6266-5321; Molina, JOSE/0000-0002-7484-7357
CR Black LA, 2005, COMP MED SY, P506, DOI 10.1109/CBMS.2005.33
   Griol D, 2008, SPEECH COMMUN, V50, P666, DOI 10.1016/j.specom.2008.04.001
   Griol D, 2010, ADV INTEL SOFT COMPU, V79, P275
   Kaelbling LP, 1998, ARTIF INTELL, V101, P99, DOI 10.1016/S0004-3702(98)00023-X
   Levin E, 2000, IEEE T SPEECH AUDI P, V8, P11, DOI 10.1109/89.817450
   Thomson B., 2007, P WORKSH BRIDG GAP A, P9
   Young S, 2002, CUEDFINFENGTR433
NR 7
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 1867-5662
BN 978-3-642-19907-3
J9 ADV INTEL SOFT COMPU
PY 2011
VL 94
BP 29
EP 36
PG 8
WC Computer Science, Artificial Intelligence; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA BVA24
UT WOS:000290882000004
DA 2022-08-02
ER

PT C
AU Cha, Y
   Jang, J
   Hong, Y
   Yi, MY
AF Cha, Yoonjeong
   Jang, Jincheul
   Hong, Younghyun
   Yi, Mun Yong
GP Assoc Comp Machinery
TI "Jack-of-All-Trades": A Thematic Analysis of Conversational Agents in
   Multi-Device Collaboration Contexts
SO CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI
   CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY MAY 04-09, 2019
CL Glasgow, SCOTLAND
SP Assoc Comp Machinery, ACM SIGCHI
DE Conversational Agent; Smart Speaker; Smart Home; Home IoT; Agent Role;
   Multi-Device Collaboration
AB A growing number of conversational agents are being embedded into larger systems such as smart homes. However, little attention has been paid to the user interactions with conversational agents in the multi-device collaboration context (MDCC), where a multiple number of devices are connected to accomplish a common mission. The objective of this study is to identify the roles of conversational agents in the MDCC. Toward this goal, we conducted semi-structured interviews with nine participants who are heavy users of smart speakers connected with home IoT devices. We collected 107 rules (usage instances) and asked benefits and limitations of using those rules. Our thematic analysis has found that, while the smart speakers perform the role of voice controller in the single device context, their role extended to automation hub, reporter, and companion in the MDCC. Based on the findings, we provide design implications for smart speakers in the MDCC.
C1 [Cha, Yoonjeong; Jang, Jincheul; Hong, Younghyun; Yi, Mun Yong] Korea Adv Inst Sci & Technol, Daejeon, South Korea.
RP Cha, Y (corresponding author), Korea Adv Inst Sci & Technol, Daejeon, South Korea.
EM yoonjeong.cha@kaist.ac.kr; jcjang@kaist.ac.kr; yh.hong@kaist.ac.kr;
   munyi@kaist.ac.kr
FU Electronics and Telecommunications Research Institute (ETRI) - Korean
   government [19ZH1100]
FX This work was supported by Electronics and Telecommunications Research
   Institute (ETRI) grant funded by the Korean government (19ZH1100,
   Distributed Intelligence Core Technology of Hyper-Connected Space).
CR Beyer Hugh, 1998, CONTEXTUAL DESIGN DE
   Brush AJB, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2115
   Jakobi T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1620, DOI 10.1145/3025453.3025799
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Mennicken S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5958, DOI 10.1145/2858036.2858168
   Porcheron M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174214
   Sciuto A, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P857, DOI 10.1145/3196709.3196772
   TechCrunch, 2018, NUMB AL SKILLS US MO
   Thomas DR, 2006, AM J EVAL, V27, P237, DOI 10.1177/1098214005283748
NR 9
TC 1
Z9 1
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5971-9
PY 2019
DI 10.1145/3290607.3313045
PG 6
WC Computer Science, Cybernetics; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BN4JW
UT WOS:000482042101117
DA 2022-08-02
ER

PT C
AU McIntire, J
   Havig, P
   Farris, K
   McIntire, L
AF McIntire, John
   Havig, Paul
   Farris, Katheryn
   McIntire, Lindsey
GP IEEE
TI Graphical and Statistical Communication Patterns of Automated
   Conversational Agents in Collaborative Computer-Mediated Communication
   Systems
SO PROCEEDINGS OF THE IEEE 2010 NATIONAL AEROSPACE AND ELECTRONICS
   CONFERENCE (NAECON)
SE IEEE National Aerospace and Electronics Conference
LA English
DT Proceedings Paper
CT IEEE National Aerospace and Electronics Conference
CY JUL 14-16, 2010
CL Fairborn, OH
SP IEEE
AB Automated conversational agents, also known as "chatbots" or "chatterbots," are computer programs used in a variety of collaborative communications systems, often for entertainment or business purposes. However, their use as malicious tools has more recently made them a growing nuisance and security concern. We present a detailed graphical and statistical analysis of communication patterns (specifically involving message sizes and inter-message delays) for improving the detection of automated conversational agents in collaborative computer-mediated communication systems.
EM john.mcintire@wpafb.af.mil; paul.harvig@wpafb.af.mil;
   katheryn.farris@wpafb.af.mil; lindsey.mcintire@wpafb.af.mil
OI McIntire, John/0000-0002-9388-6028
CR [Anonymous], LOEBN PRIZ ART INT 1
   de Siqueira A., 2009, P 42 HAW INT C SYST
   Fried I., 2007, CNET             DEC
   Gianvecchio Steven, 2008, P 17 USENIX SEC S SA
   Hu J., 2003, CNET NEWS        JUL
   Kalman YM, 2006, J COMPUT-MEDIAT COMM, V12, P1, DOI 10.1111/j.1083-6101.2006.00312.x
   Kerly A, 2007, KNOWL-BASED SYST, V20, P177, DOI 10.1016/j.knosys.2006.11.014
   Kowalski S., 2009, P 9 IFIP WORLD C COM
   Krebs B., 2007, WASHINGTON POST  AUG
   Leaverton M., 2000, RECRUITING CHATTERBO
   McIntire J., 2010, P INT COLL TECHN SYS
   Mohta A., 2007, TECHNOSPOT NETWO SEP
   Naughton P., 2007, FOXNEWS          DEC
   Quarteroni S., 2007, DECALOG, V2007, P83
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Thakur S., PETITION ONLINE
   Turing A., 1988, READINGS COGNITIVE S
NR 18
TC 1
Z9 1
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 0547-3578
BN 978-1-4244-6578-1
J9 PROC NAECON IEEE NAT
PY 2010
BP 34
EP 40
DI 10.1109/NAECON.2010.5712920
PG 7
WC Engineering, Aerospace; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA BWU80
UT WOS:000294969100006
OA Green Submitted
DA 2022-08-02
ER

PT S
AU Lager, T
   Kronlid, F
AF Lager, T
   Kronlid, F
BE Roy, PV
TI The CURRENT platform: Building conversational agents in Oz
SO MULTIPARADIGM PROGRAMMING IN MOZART/OZ
SE LECTURE NOTES IN COMPUTER SCIENCE
LA English
DT Article; Proceedings Paper
CT 2nd International Conference Multiparadigm Programming in Mozart/Oz
CY OCT 07-08, 2004
CL Charleroi, BELGIUM
AB At the GU Dialogue Systems Lab in Goteborg we are embedding a conversational agent platform - the CURRENT platform - in the Oz programming language. CURRENT is based on a simple and intuitive characterization of conversational agents as interactive transducers, and on the fact that this characterization has a very direct implementation in Oz. Concurrency as offered by Oz allows our agents to 'perceive', 'think' and 'act' at the same time. Concurrency in combination with streams allow our agents to process input in an incremental manner, even when the original underlying algorithms are batch-oriented. Concurrency and streams in combination with ports allow us to specify the 'toplevel' transducer as a network of components - an interesting and highly modular architecture. We believe that software tools for specifying networks should have a strong visual aspect, and we have developed a 'visual programming language' and an IDE to support it. Also, we have found that if we specify the non-visual aspects of transducers and other components as class definitions that inherit the methods responsible for the interpretation of condition-action rules, regular expressions, grammars, dialogue management scripts, etc. from (abstract) classes provided by separate modules, we are able to hide most of the gory details involving threads, streams and ports from the agent developer.
C1 Univ Gothenburg, Dept Linguist, GU Dialogue Syst Lab, Gothenburg, Sweden.
RP Lager, T (corresponding author), Univ Gothenburg, Dept Linguist, GU Dialogue Syst Lab, Gothenburg, Sweden.
CR ABNEY S, 1996, P ESSLLI 96 ROB PARS
   APPELT DE, 1996, COMMON PATTERN SPECI
   Brill E, 1995, COMPUT LINGUIST, V21, P543
   Cunningham H, 2002, P 40 ANN M ASS COMP
   KRONLID F, THESIS GOTEBORG U
   LAGER T, 2001, LECT NOTES COMPUTER, V2166
   LARSSN S, 2002, THESIS GOTEBORG U
   LEE P, 2003, TAXONOMY VISUAL PARA
   SUTTON S, 1998, P INT C SPOK LANG PR, P3221
   Tryphonas, 2004, VOICE EXTENSIBLE MAR
   Van-Roy P., 2004, CONCEPTS TECHNIQUES
   Wegner P, 1997, COMMUN ACM, V40, P80, DOI 10.1145/253769.253801
NR 12
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-25079-4
J9 LECT NOTES COMPUT SC
PY 2005
VL 3389
BP 161
EP 174
PG 14
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BCD40
UT WOS:000228723400014
DA 2022-08-02
ER

PT S
AU Hong, JH
   Lim, S
   Cho, SB
AF Hong, Jin-Hyuk
   Lim, Sungsoo
   Cho, Sung-Bae
BE King, I
   Wang, J
   Chan, L
   Wang, DL
TI Language learning for the autonomous mental development of
   conversational agents
SO NEURAL INFORMATION PROCESSING, PT 3, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 13th International Conference on Neural Informational Processing
CY OCT 03-06, 2006
CL Hong Kong, PEOPLES R CHINA
SP Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, K C Wong Educ Fdn
AB Since the manual construction of our knowledge-base has several crucial limitations when applied to intelligent systems, mental development has been investigated in recent years. Autonomous mental development is a new paradigm for developing autonomous machines, which are adaptive and flexible to the environment. Language development, a kind of mental development, is an important aspect of intelligent conversational agents. In this paper, we propose an intelligent conversational agent and its language development mechanism by putting together five promising techniques; Bayesian networks, pattern matching, finite state machines, templates, and genetic programming. Knowledge acquisition implemented by finite state machines and templates, and language learning by genetic programming are developed for language development. Several illustrations and usability tests show the usefulness of the proposed developmental conversational agent.
C1 Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea.
RP Hong, JH (corresponding author), Yonsei Univ, Dept Comp Sci, 134 Sinchon Dong, Seoul 120749, South Korea.
EM hjinh@sclab.yonsei.ac.kr; lss@sclab.yonsei.ac.kr; sbcho@cs.yonsei.ac.kr
OI Hong, Jin-Hyuk/0000-0002-8838-5667
CR CLACK E, 2004, TRENDS COGN SCI, V8, P472
   Johnson MH, 2005, TRENDS COGN SCI, V9, P152, DOI 10.1016/j.tics.2005.01.009
   Joshi A, 2003, NEURAL NETWORKS, V16, P701, DOI 10.1016/S0893-6080(03)00134-5
   Koza J.R., 1992, GENETIC PROGRAMMING
   Lauria S, 2001, IEEE INTELL SYST, V16, P38, DOI 10.1109/5254.956080
   Plunkett K, 1997, TRENDS COGN SCI, V1, P146, DOI 10.1016/S1364-6613(97)01039-5
   Ratnaparkhi A, 2002, COMPUT SPEECH LANG, V16, P435, DOI 10.1016/S0885-2308(02)00025-6
   Weng JY, 2001, SCIENCE, V291, P599, DOI 10.1126/science.291.5504.599
   Zhou CJ, 2002, INFORM SCIENCES, V145, P45, DOI 10.1016/S0020-0255(02)00223-2
NR 9
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-46484-0
J9 LECT NOTES COMPUT SC
PY 2006
VL 4234
BP 892
EP 899
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Interdisciplinary Applications; Computer
   Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BFG63
UT WOS:000241759000098
OA Green Submitted
DA 2022-08-02
ER

PT C
AU Guerini, M
   Magnolini, S
   Balaraman, V
   Magnini, B
AF Guerini, Marco
   Magnolini, Simone
   Balaraman, Vevake
   Magnini, Bernardo
GP Assoc Computat Linguist
TI Toward Zero-shot Entity Recognition in Task-oriented Conversational
   Agents
SO 19TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND
   DIALOGUE (SIGDIAL 2018)
LA English
DT Proceedings Paper
CT 19th Annual Meeting of the
   Special-Interest-Group-on-Discourse-and-Dialogue (SIGDIAL)
CY JUL 12-14, 2018
CL Melbourne, AUSTRALIA
SP Special Interest Grp Discourse & Dialogue, Honda Res Inst Japan, Adobe Res, Nextremer, Educ Testing Serv, Monash Univ, RMIT Univ, Interactions, Amazon, Tricorn Beijing Technol, PolyAI, Microsoft Res, Apple, Toshiba Res Europe
AB We present a domain portable zero-shot learning approach for entity recognition in task-oriented conversational agents, which does not assume any annotated sentences at training time. Rather, we derive a neural model of the entity names based only on available gazetteers, and then apply the model to recognize new entities in the context of user utterances. In order to evaluate our working hypothesis we focus on nominal entities that are largely used in e-commerce to name products. Through a set of experiments in two languages (English and Italian) and three different domains (furniture, food, clothing), we show that the neural gazetteer-based approach outperforms several competitive baselines, with minimal requirements of linguistic features.
C1 [Guerini, Marco; Magnolini, Simone; Balaraman, Vevake; Magnini, Bernardo] Fdn Bruno Kessler, Via Sommar 18, Povo, Trento, Italy.
   [Magnolini, Simone] AdeptMind Scholar, Toronto, ON, Canada.
RP Guerini, M (corresponding author), Fdn Bruno Kessler, Via Sommar 18, Povo, Trento, Italy.
EM guerini@fbk.eu; magnolini@fbk.eu; balaraman@fbk.eu; magnini@fbk.eu
FU AdeptMind scholarship; CBF EIT Digital project
FX This work has been partially supported by the AdeptMind scholarship, and
   by the CBF EIT Digital project. The authors thank the anonymous
   reviewers and Hendrik Buschmeier for their help and suggestions.
CR Abdul-Rauf S, 2016, IEEE-ACM T AUDIO SPE, V24, P745, DOI 10.1109/TASLP.2016.2517318
   Bapna A, 2017, INTERSPEECH, P2476, DOI 10.21437/Interspeech.2017-518
   Cheri Joe, 2017, P 2 WORKSH REPR LEAR, P37
   Doddington G. R., 2004, P 4 INT C LANG RES E, V2, P837
   Eftimov T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179488
   El Asri L, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017)
   Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321
   Eric M, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P37
   He SZ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P199, DOI 10.18653/v1/P17-1019
   Hoag Joseph E., 2008, THESIS FAYETTEVILLE
   Jaderberg M., 2014, NEURAL INFORM PROCES
   JasonWeston Antoine Bordes, 2015, ARXIV PREPRINT ARXIV
   Lample G., 2016, P NAACL HLT, P260, DOI [10.18653/v1/N16-1030, DOI 10.18653/V1/N16-1030]
   Norouzi M., 2013, ARXIV13125650
   Pianta E, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P2603
   Ramshaw L., 1995, P ACL 3 WORKSH VER L
   RICHARDS B, 1987, J CHILD LANG, V14, P201, DOI 10.1017/S0305000900012885
   Sang E. F. T. K., 2003, P 7 C NAT LANG LEARN, P142, DOI DOI 10.3115/1119176.1119195
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shah Pararth, 2018, ARXIV180104871
   Socher R., 2013, ADV NEURAL INFORM PR, P935, DOI DOI 10.1007/978-3-319-46478-7
   Xie SH, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1889, DOI 10.1145/2983323.2983866
NR 22
TC 8
Z9 8
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-948087-67-4
PY 2018
BP 317
EP 326
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Linguistics
GA BS2YA
UT WOS:000708178100036
DA 2022-08-02
ER

PT C
AU Crocket, K
   Bandar, Z
   O'Shea, J
   Mclean, D
AF Crocket, Keeley
   Bandar, Zuhair
   O'Shea, James
   Mclean, David
GP IEEE
TI Goal Orientated Conversational Agents - the rocky road to
   commercialization
SO 2010 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE 2010)
SE IEEE International Conference on Fuzzy Systems
LA English
DT Proceedings Paper
CT 2010 IEEE World Congress on Computational Intelligence
CY JUL 18-23, 2010
CL Barcelona, SPAIN
SP IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc, Evolut Program Soc, IET
ID SIMILARITY
AB Academics who wish to commercialise a novel research concept or prototype 'product' face many difficult challenges. These typically include limited business knowledge, the technical verses business language barrier, and the time commitment involved in trying to "sell" the idea to industry and develop one-off prototypes. This paper describes the commercialisation of Goal Orientated Conversational Agents (GO-CA) from initial research concepts through to establishing a UK limited company. GO-CAs have the ability to converse with humans through the use of natural language dialogue in order to achieve a specific task. Such systems are ideal for providing clear and consistent advice 24 hours a day and allow the users to be able to ask questions in natural language which are relevant to their personal situation. The paper briefly describes the novel GO-CA architecture and outlines two developed applications. The pathway to commercialisation which was taken is described and lessons which were learnt are identified.
C1 [Crocket, Keeley; Bandar, Zuhair; O'Shea, James; Mclean, David] Manchester Metropolitan Univ, Dept Comp & Math, Intelligent Syst Grp, Manchester M1 5GD, Lancs, England.
RP Crocket, K (corresponding author), Manchester Metropolitan Univ, Dept Comp & Math, Intelligent Syst Grp, Chester St, Manchester M1 5GD, Lancs, England.
EM K.Crockett@mmu.ac.uk
CR ALLEN JF, 1995, J EXP THEOR ARTIF IN, V7, P7, DOI 10.1080/09528139508953799
   Bohus D., 2009, P IJCAI 2009 WORKSH
   Buiel E, 2009, LECT NOTES ARTIF INT, V5638, P575, DOI 10.1007/978-3-642-02812-0_66
   Cassell J., 2000, EMBODIED CONVERSATIO
   CASSELL J, 2007, P WORKSH EMB NAT LAN
   Cassell J, 2009, LECT NOTES COMPUT SC, V5616, P303, DOI 10.1007/978-3-642-02713-0_32
   Colby K, 1975, ARTIFICIAL PARANOIA
   Goh OS, 2007, J ADV COMPUT INTELL, V11, P282, DOI 10.20965/jaciii.2007.p0282
   Iacobelli F., 2007, P INT VIRT AG IVA PA
   Latham A., 2010, 2 INT C AG IN PRESS
   Li Y, 2002, LECT NOTES COMPUTER, P481
   Li YH, 2003, IEEE T KNOWL DATA EN, V15, P871, DOI 10.1109/TKDE.2003.1209005
   Li YH, 2006, IEEE T KNOWL DATA EN, V18, P1138, DOI 10.1109/TKDE.2006.130
   Massaro DW, 2000, EMBODIED CONVERSATIONAL AGENTS, P287
   Mauldin M., SLYVIE CHATTERBOT VI
   O'Shea J, 2008, LECT NOTES ARTIF INT, V4953, P172, DOI 10.1007/978-3-540-78582-8_18
   O'Shea K., 2009, LECT NOTES ELECT ENG, V39, P505
   O'Shea K, 2008, LECT NOTES ENG COMP, P321
   Qureshi H, STUDENTS FEEL PINCH
   Rojas-Barahona L., 2009, LECT NOTES COMPUTER, P245
   Simonin J, 2009, LECT NOTES COMPUT SC, V5615, P748, DOI 10.1007/978-3-642-02710-9_83
   Turing AM., 1950, J MIND ASS, V59, P433, DOI [10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   VirtuOz 2007, 2007, VIRTUOZ CONV AG
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wik P, 2009, SPEECH COMMUN, V51, P1024, DOI 10.1016/j.specom.2009.05.006
NR 25
TC 0
Z9 0
U1 0
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1098-7584
BN 978-1-4244-6920-8
J9 IEEE INT CONF FUZZY
PY 2010
PG 8
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BTO07
UT WOS:000287453601004
DA 2022-08-02
ER

PT J
AU Garrido, P
   Martinez, FJ
   Barrachina, J
   Baldassarri, S
   Cerezo, E
   Seron, FJ
AF Garrido, P.
   Martinez, F. J.
   Barrachina, J.
   Baldassarri, S.
   Cerezo, E.
   Seron, F. J.
TI Learning through Embodied Conversational Agents with Semantic Memory
SO INTERNATIONAL JOURNAL OF ENGINEERING EDUCATION
LA English
DT Article
DE embodied conversational agent; maxine; factual knowledge; learning;
   semantic memory
ID SUPERIMPOSED INFORMATION; ARCHITECTURE; ONTOLOGIES; QUALITY
AB Embodied Conversational Agents (ECAs) are interactive characters that exhibit human-like qualities, such as facial expressions, lip-synch, or emotional voice, and are able to communicate with humans, or with other ECAs by using natural human capabilities (speech, gestures, etc.). However, to make current ECAs' dialogue management strategies more appealing and real to the user, they should be aware of general knowledge about the external world. This factual knowledge, which is independent of personal experience, should be stored in their semantic memory. This paper presents a knowledge-based solution to improve learning through ECAs with factual knowledge based on semantics. In particular, we build this semantic memory by means of a novel proposal known as Daira. Moreover, we integrated Daira with Maxine, a powerful animation engine for developing applications with embodied animated agents. To illustrate the potential of our approach, we designed a proof of concept in which our system is able to provide data from the online Great Aragonese Encyclopedia (GEA), written in Spanish, to engage students. The experiments performed show the feasibility and efficiency of our proposal. In particular, we demonstrated that using enriched ECAS when searching information can enhance learning motivation and learning performance, making the interaction process much more accurate, simpler, and near to the students.
C1 [Garrido, P.; Martinez, F. J.; Baldassarri, S.; Cerezo, E.] Univ Zaragoza, Comp Sci & Syst Engn Dept, C Pedro Cerbuna 12, E-50009 Zaragoza, Spain.
   [Barrachina, J.] Univ Zaragoza, C Pedro Cerbuna 12, E-50009 Zaragoza, Spain.
   [Seron, F. J.] Univ Zaragoza, Adv Comp Graph Grp, E-50009 Zaragoza, Spain.
   [Seron, F. J.] Univ Zaragoza, Polytech Ctr, E-50009 Zaragoza, Spain.
RP Garrido, P (corresponding author), Univ Zaragoza, Comp Sci & Syst Engn Dept, C Pedro Cerbuna 12, E-50009 Zaragoza, Spain.
EM piedad@unizar.es; f.martinez@unizar.es; barrachina@unizar.es;
   sandra@unizar.es; ecerezo@unizar.es; seron@unizar.es
RI Garrido, Piedad/K-7034-2014; Cerezo, Eva/L-6095-2014; Baldassarri,
   Sandra/L-6033-2014; Dominguez, Francisco Martinez/K-7014-2014
OI Garrido, Piedad/0000-0002-1750-7225; Cerezo, Eva/0000-0003-4424-0770;
   Baldassarri, Sandra/0000-0002-9315-6391; Dominguez, Francisco
   Martinez/0000-0001-6945-7330
FU Ministerio de Economia y Competitividad, Programa Estatal de
   Investigacion, Desarrollo e Innovacion Orientada a los Retos de la
   Sociedad, Proyectos I+D+I, Spain [TEC2014-52690-R, TIN2015-67149-C3-1R];
   Government of Aragon; European Social Fund (T91 Research Group)
FX This work was partially supported by the Ministerio de Economia y
   Competitividad, Programa Estatal de Investigacion, Desarrollo e
   Innovacion Orientada a los Retos de la Sociedad, Proyectos I+D+I, Spain,
   under Grants TEC2014-52690-R and TIN2015-67149-C3-1R, as well as by the
   Government of Aragon and the European Social Fund (T91 Research Group).
CR Alelaiwi A, 2014, INT J ENG EDUC, V30, P603
   Anderson J. R., 1995, LEARNING MEMORY
   [Anonymous], 1984, CONCEPTUAL STRUCTURE
   [Anonymous], 2013, 132503 ISO
   Archer DW, 2008, LECT NOTES COMPUT SC, V5173, P88
   Augello A., 2014, ADV ONTO INTERNET TH, P285, DOI [10.1007/978-3-319-03992-3_20, DOI 10.1007/978-3-319-03992-3_20]
   Avradinis N, 2013, SPRINGERPLUS, V2, DOI 10.1186/2193-1801-2-246
   Baldassarri S., 2012, COMPUTER GRAPHICS, P195
   Baskar J, 2014, COMM COM INF SC, V430, P89
   Bellamy L., 2011, XML TOPIC MAPS CREAT
   Best B. J., 2010, P 17 C BEH REPR MOD, P1
   Beydoun G, 2014, INFORM SYST, V46, P45, DOI 10.1016/j.is.2014.05.002
   Breuing A., 2011, 2011 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies, P445, DOI 10.1109/WI-IAT.2011.158
   Cambria E, 2011, LECT NOTES COMPUT SC, V6456, P81, DOI 10.1007/978-3-642-18184-9_8
   Chakrabarti C., 2014, THESIS
   Chen KJ, 2008, PROCEEDINGS OF THE SEVENTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, P402, DOI 10.1109/COGINF.2008.4639194
   Deshpande A. M., 2012, INT J ENG INNOVATIVE, V1, P27
   Eisman EM, 2016, EXPERT SYST APPL, V53, P172, DOI 10.1016/j.eswa.2016.01.033
   Evermann J, 2010, INFORM SYST, V35, P391, DOI 10.1016/j.is.2008.09.001
   eXaminator, ACC AUT EV
   Figuerola CG, 2017, PROGRAM-ELECTRON LIB, V51, P373, DOI 10.1108/PROG-02-2016-0016
   Garrett P, 2010, PASTORAL AUSTRALIA: FORTUNES, FAILURES AND HARD YAKKA: A HISTORICAL OVERVIEW 1788-1967, P1
   Garrido P., 2008, 11 INT C HUM COMP IN, P407
   Garrido P., 2013, ADV INTELLIGENT SYST, V219, P129
   Garrido P, 2010, COMM COM INF SC, V108, P84
   Gkiokasa A., 2014, 6 INT C ADV COGN TEC, P189
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   Guo YR, 2016, COMPUT EDUC, V103, P59, DOI 10.1016/j.compedu.2016.09.013
   Ide Nancy, 1994, P INT WORKSH FUT LEX, P137
   Lee CS, 2006, NAFIPS 2006 - 2006 ANNUAL MEETING OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY, VOLS 1 AND 2, P627, DOI 10.1109/NAFIPS.2006.365482
   Li J, 2017, TOP COGN SCI, V9, P102, DOI 10.1111/tops.12245
   Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d
   LOPD, ORG LAW PROT PERS DA
   Luo WM, 2009, EIGHTH IEEE INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, PROCEEDINGS, P648, DOI 10.1109/DASC.2009.100
   Maier D., 1999, WEBDB INF P, P1
   Nassiri-Mofakham F, 2014, COMPUT HUM BEHAV, V38, P196, DOI 10.1016/j.chb.2014.05.019
   Padro L., 2012, P LANG RES EV C LREC
   Parsons P, 2014, J ASSOC INF SCI TECH, V65, P455, DOI 10.1002/asi.23002
   Poole R, 2008, MEM STUD, V1, P149, DOI 10.1177/1750698007088383
   Sernani P, 2014, AMBIENT ASSISTED LIVING, P87, DOI 10.1007/978-3-319-01119-6_9
   Seron F. J., 2014, MULTIMED TOOLS APPL, V75, P381
   Sidar, HERA ACC CHECK STYL
   Tramullas J., 2013, LIB AUTOMATION OPAC
   World Wide Web Consortium (W3C), WEB CONT ACC GUID 2
   Xu DM, 2005, EXPERT SYST APPL, V29, P525, DOI 10.1016/j.eswa.2005.04.028
   Yanez-Marquez C., 2014, INT J ENG EDUC, V30, P1
   Zacarias M, 2010, INFORM SYST, V35, P441, DOI 10.1016/j.is.2009.03.014
   Zhang Y, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P875
NR 48
TC 1
Z9 1
U1 3
U2 8
PU TEMPUS PUBLICATIONS
PI DURRUS, BANTRY
PA IJEE , ROSSMORE,, DURRUS, BANTRY, COUNTY CORK 00000, IRELAND
SN 0949-149X
J9 INT J ENG EDUC
JI Int. J. Eng. Educ
PY 2018
VL 34
IS 2
BP 442
EP 457
PN A
PG 16
WC Education, Scientific Disciplines; Engineering, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Education & Educational Research; Engineering
GA GS0FU
UT WOS:000443164700015
DA 2022-08-02
ER

PT J
AU Brown, E
   Barrett, N
AF Brown, Edward
   Barrett, Neil
TI A Wizard-of-Oz platform for embodied conversational agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE agent; conversational; prototyping; Wizard-of-Oz
AB A low-cost prototyping environment for experimenting with embodied conversational agents is discussed. The platform allows modeling and experimenting with different agent constructs and protocols prior to significant investment in the construction of the agent environment. Problems in the design of such a platform include the substantial number of agent controls needed and the flexibility required to represent the constructs of different theories, protocols and target environments as they are introduced and developed. These problems are addressed by augmenting a movie clip manager With a general drawing palette as a design tool. The result is a prototyping environment Which simulates multiple agents on a desktop while allowing arbitrary notational conventions. The current version does not render multiple agents in a shared virtual environment, but the protocol-based architecture is amenable to such extensions. In the meantime, valuable results regarding the social character Of multiple agent interaction call be explored with the existing tool. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Mem Univ Newfoundland, Dept Comp Sci, St John, NF A1B 3X5, Canada.
RP Barrett, N (corresponding author), Mem Univ Newfoundland, Dept Comp Sci, St John, NF A1B 3X5, Canada.
EM brown@cs.mun.ca
CR Bailey B.P, 2003, CHI, P313, DOI DOI 10.1145/642611.642666
   BALCI K, 2005, P 7 INT C MULT INT X, P208
   BERNSEN NO, 2004, P 6 INT C MULT INT I, P38
   EISENBERG M, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P431
   Kelleher C, 2005, ACM COMPUT SURV, V37, P83, DOI 10.1145/1089733.1089734
   KLEIN F, 2005, P 4 WORKSH SOFTW ENG, P1
   Klemmer S.R., 2000, P 13 ANN ACM S US IN, P1, DOI https://doi.org/10.1145/354401.354406
   KO AJ, 2005, 1 WORKSH END US SOFT, P1
   MAYA V, 2004, 3 INT JOINT C AUT AG, P1306
   Pelachaud C., 2005, 13th Annual ACM International Conference on Multimedia, P683
   Sinha A., 2003, ICMI 03, P117
   WINOGRAD T, 1986, UNDERSTANDIGN COMPUT
   [No title captured]
NR 13
TC 1
Z9 1
U1 1
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 249
EP 257
DI 10.1002/cav.129
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400012
DA 2022-08-02
ER

PT C
AU Griol, D
   Carbo, J
   Molina, JM
AF Griol, David
   Carbo, Javier
   Manuel Molina, Jose
BE Corchado, E
   Snasel, V
   Sedano, J
   Hassanien, AE
   Calvo, JL
   Slezak, D
TI Soft Computing Models for the Development of Commercial Conversational
   Agents
SO SOFT COMPUTING MODELS IN INDUSTRIAL AND ENVIRONMENTAL APPLICATIONS, 6TH
   INTERNATIONAL CONFERENCE SOCO 2011
SE Advances in Intelligent and Soft Computing
LA English
DT Proceedings Paper
CT 6th International Conference on Soft Computing Models in Industrial and
   Environmental Applications
CY APR 06-08, 2011
CL Salamanca, SPAIN
SP IEEE Secc Espana, IEEE Syst, Man & Cybernet Spanish Chapter, Int Fed Comp Log, MIR Lab, BISITE, GICAP Res Grp
ID SPOKEN; DESIGN
AB In this paper we present a proposal for the development of conversational agents that, on the one hand, takes into account the benefits of using standards like VoiceXML, whilst on the other, includes a module with a soft computing model that avoids the effort of manually defining the dialog strategy. This module is trained using a labeled dialog corpus, and selects the next system response considering a classification process based on neural networks that takes into account the dialog history. Thus, system developers only need to define a set of VoiceXML files, each including a system prompt and the associated grammar to recognize the users responses to the prompt. We have applied this technique to develop a conversational agent in VoiceXML that provides railway information in Spanish.
C1 [Griol, David; Carbo, Javier; Manuel Molina, Jose] Univ Carlos III Madrid, GIAA, Dept Comp Sci, E-28903 Getafe, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, GIAA, Dept Comp Sci, E-28903 Getafe, Spain.
EM david.griol@uc3m.es; javier.carbo@uc3m.es; josemanuel.molina@uc3m.es
RI Griol, David/L-1258-2014; Carbo, Javier/ABB-4694-2020; Molina,
   JOSE/B-1956-2008
OI Griol, David/0000-0001-6266-5321; Carbo, Javier/0000-0001-7794-3398;
   Molina, JOSE/0000-0002-7484-7357
CR Cuayahuitl H, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P290
   DENECKE M, 2005, P 6 SIGDIAL WORKSH D, P65
   Espana-Boquera S, 2007, LECT NOTES COMPUT SC, V4527, P327
   GEORGILA K, 2006, P 9 INT C SPOK LANG, P1065
   Griol D, 2008, SPEECH COMMUN, V50, P666, DOI 10.1016/j.specom.2008.04.001
   Griol David, 2009, P INTERSP ICSLP 2009, P272
   IERUSALIMSCHY R, 2003, PROGRAMMING LUA
   Levin E, 2000, IEEE T SPEECH AUDI P, V8, P11, DOI 10.1109/89.817450
   McTear M. F., 2004, SPOKEN DIALOGUE TECH
   Paek T, 2000, P 16 C UNC ART INT S, P455
   Paek T, 2008, SPEECH COMMUN, V50, P716, DOI 10.1016/j.specom.2008.03.010
   Pieraccini R, 2009, LECT NOTES ARTIF INT, V5729, P3
   Roy N, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P93
   Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, P319
   Schatzmann J, 2006, KNOWL ENG REV, V21, P97, DOI 10.1017/S0269888906000944
   Williams JD, 2007, COMPUT SPEECH LANG, V21, P393, DOI 10.1016/j.csl.2006.06.008
   YOUNG S, 2007, P 32 IEEE INT C AC S, V4, P149
NR 17
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 1867-5662
BN 978-3-642-19643-0
J9 ADV INTEL SOFT COMPU
PY 2011
VL 87
BP 173
EP 182
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BVB67
UT WOS:000290975700019
DA 2022-08-02
ER

PT C
AU Figa, E
   Tarau, P
   Ephraim, J
AF Figa, E
   Tarau, P
   Ephraim, J
BE Bryans, JB
TI Enhancing the virtual storytelling experience with metadata driven voice
   enabled conversational agents
SO ASIST 2004: PROCEEDINGS OF THE 67TH ASIS&T ANNUAL MEETING, VOL 41, 2004:
   MANAGING AND ENHANCING INFORMATION: CULTURES AND CONFLICTS
SE PROCEEDINGS OF THE ASIST ANNUAL MEETING
LA English
DT Proceedings Paper
CT 67th Annual Meeting of the
   American-Society-for-Information-Science-and-Technology
CY NOV 12-17, 2004
CL Providence, RI
SP Amer Soc Informat Sci & Technol
AB This paper describes a software component, deployed as a Web service which enhances a user's online experience with a Virtual Storytelling Library through the use of voice-enabled Webbased conversational agents. The agents extract query answering information from story-specific XML/RDF metadata files and expand its coverage through inferences based on a variety of knowledge sources like the WordNet, Open Mind and by metasearching the Web for topics matching the story's content.
C1 Univ N Texas, Sch Lib & Informat Sci, Denton, TX 76203 USA.
CR AARNE A, 1961, TYPES FOLKTALES
   BALET O, 2001, PREFACE VIRTUAL STOR
   BALET O, 2001, P INT C VIRT STOR AV
   CAVASSA M, 2001, P INT C VIRTUAL STOR
   EASTMAN M, 1926, INDEX FAIRYTALES MYT
   FENCOTT C, 2001, P INT C VIRT STORYT
   FIGA E, 2003, P TECHN INT DIG STOR, P106
   FIGA E, 2003, P 66 ASIS ANN M
   FIGA E, 2003, C P TECHN INT DIG ST
   IRELAND N, 1973, INDEX FAIRYTALES INC, P1949
   MacDonald M.R., 1982, STORYTELLERS SOURCEB
   MacDonald M.R., 2001, STORYTELLERS SOURCEB
   MATEAS M, 2003, C P TECHN INT DIG ST
   Propp Vladimir, 1968, MORPHOLOGY FOLKTALE
   Thompson Stith., 1956, MOTIF INDEX FOLK LIT, VII D-E
   ZANCANARO M, 2001, P INT C VIRT STOR AV
   2000, W3C RECOMMENDATION
   [No title captured]
NR 18
TC 1
Z9 1
U1 1
U2 5
PU INFORMATION TODAY INC
PI MEDFORD
PA 143 OLD MARLTON PIKE, MEDFORD, NJ 08055 USA
SN 0044-7870
BN 1-57387-222-9
J9 P ASIST ANNU
PY 2004
VL 41
BP 403
EP 410
DI 10.1002/meet.1450410147
PG 8
WC Computer Science, Information Systems; Information Science & Library
   Science
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Information Science & Library Science
GA BBM34
UT WOS:000226136800047
OA Bronze
DA 2022-08-02
ER

PT J
AU Garett, R
   Young, SD
AF Garett, Renee
   Young, Sean D.
TI Potential application of conversational agents in HIV testing uptake
   among high-risk populations
SO JOURNAL OF PUBLIC HEALTH
LA English
DT Editorial Material; Early Access
DE infectious disease
ID ARTIFICIAL-INTELLIGENCE; UNITED-STATES; HEALTH; TRANSMISSION; SERVICES;
   WOMEN; MEN; MSM
AB Human Immunodeficiency Virus (HIV) continues to be a significant public health problem, with similar to 1.2 million Americans living with HIV and similar to 14% unaware of their infection. The Centers for Disease Control and Prevention recommends that patients 13 to 64 years of age get screened for HIV at least once, and those with higher risk profiles screen at least annually. Unfortunately, screening rates are below recommendations for high-risk populations, leading to problems of delayed diagnosis. Novel technologies have been applied in HIV research to increase prevention, testing and treatment. Conversational agents, with potential for integrating artificial intelligence and natural language processing, may offer an opportunity to improve outreach to these high-risk populations. The feasibility, accessibility and acceptance of using conversational agents for HIV testing outreach is important to evaluate, especially amidst a global coronavirus disease 2019 pandemic when clinical services have been drastically affected. This viewpoint explores the application of a conversational agent in increasing HIV testing among high-risk populations.
C1 [Garett, Renee] ElevateU, Irvine, CA 92617 USA.
   [Young, Sean D.] Univ Calif Irvine, Dept Emergency Med, Orange, CA 92868 USA.
   [Young, Sean D.] Univ Calif Irvine, Inst Predict Technol, Dept Informat, Irvine, CA 92617 USA.
RP Young, SD (corresponding author), Univ Calif Irvine, Dept Emergency Med, Orange, CA 92868 USA.; Young, SD (corresponding author), Univ Calif Irvine, Inst Predict Technol, Dept Informat, Irvine, CA 92617 USA.
EM syoung5@hs.uci.edu
OI Young, Sean D./0000-0001-6052-4875
FU National Institute of Allergy and Infectious Diseases (NIAID); National
   Instituteon Drug Abuse (NIDA); National Center for Complementary and
   Integrative Health (NCCIH)
FX National Institute of Allergy and Infectious Diseases (NIAID), National
   Instituteon Drug Abuse (NIDA), National Center for Complementary and
   Integrative Health (NCCIH).
CR Ahlstrom MG, 2019, ECLINICALMEDICINE, V17, DOI 10.1016/j.eclinm.2019.10.016
   Altamirano-Flores JS, 2020, IEEE ACCESS, V8, P87214, DOI 10.1109/ACCESS.2020.2992240
   Branson Bernard M., 2006, Morbidity and Mortality Weekly Report, V55, P1
   Cairns G, 2020, EUROPEAN AIDS TREATM
   Clark HA, 2019, AIDS BEHAV, V23, P359, DOI 10.1007/s10461-018-2266-3
   Corporation M. Corporation M., 2018, FUTURE COMPUTED ARTI, P149
   Dailey AF, 2017, MMWR-MORBID MORTAL W, V66, P1300, DOI 10.15585/mmwr.mm6647e1
   Eaton LA, 2009, J ASSOC NURSE AIDS C, V20, P39, DOI 10.1016/j.jana.2008.10.005
   Frye V, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192936
   Garett R, 2021, HEALTH TECHNOL-GER, V11, P1305, DOI 10.1007/s12553-021-00611-0
   Garett R, 2021, AIDS BEHAV, V25, P333, DOI 10.1007/s10461-021-03221-z
   Gopalappa C, 2017, MED DECIS MAKING, V37, P224, DOI 10.1177/0272989X16668509
   Gwadz M, 2018, INT J EQUITY HEALTH, V17, DOI 10.1186/s12939-018-0761-9
   HIV.gov, 2020, HIV CAR CONT
   HIV.gov, 2020, US STAT
   Kaiser Family Foundation, 2019, HIV TEST US
   Kalichman SC, 2012, AIDS RES THER, V9, DOI 10.1186/1742-6405-9-1
   Kinsella B., 2020, NEARLY 90 MILLION US
   Lagat H., 2020, W KENYA AIDS BEHAV, V2, P1
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Levy ME, 2014, AIDS BEHAV, V18, P972, DOI 10.1007/s10461-014-0719-x
   Liu AY., AIDS BEHAV
   Marcus JL, 2020, CURR HIV-AIDS REP, V17, P171, DOI 10.1007/s11904-020-00490-6
   Marcus JL, 2019, LANCET HIV, V6, pE688, DOI 10.1016/S2352-3018(19)30137-7
   Marks G, 2005, JAIDS-J ACQ IMM DEF, V39, P446, DOI 10.1097/01.qai.0000151079.33935.79
   Meadows R, 2020, DIGIT HEALTH, V6, DOI 10.1177/2055207620966170
   Medline A, 2017, J ASSOC NURSE AIDS C, V28, P363, DOI 10.1016/j.jana.2017.01.001
   National Institutes of Health, 2015, START ANT TREATM EAR
   Nilsson NJ., 2014, PRINCIPLES ARTIFICIA, P493
   Noble M, 2017, AIDS BEHAV, V21, P561, DOI 10.1007/s10461-016-1506-7
   Pitasi MA, 2018, MMWR-MORBID MORTAL W, V67, P677, DOI 10.15585/mmwr.mm6724a2
   Prakash AV, 2020, PAC ASIA J ASSOC INF, V12, P1, DOI 10.17705/1pais.12201
   Rice E, 2018, J SOC SOC WORK RES, V9, P551, DOI 10.1086/701439
   Romero RA, 2021, CURR HIV-AIDS REP, V18, P391, DOI 10.1007/s11904-021-00565-y
   Romm Tony, 2019, WASH POST
   Rosengren AL, 2016, SEX HEALTH, V13, P389, DOI 10.1071/SH15236
   Sarikaya R, 2017, IEEE SIGNAL PROC MAG, V34, P67, DOI 10.1109/MSP.2016.2617341
   Shen YZ, 2020, ADV THER-GERMANY, V3, DOI 10.1002/adtp.201900114
   Su ZY, 2021, SUBST USE MISUSE, V56, P1732, DOI 10.1080/10826084.2021.1949609
   Tankovska H., 2020, STAT
   Tankovska H., 2020, NUMBER VOICE ASSISTA
   UNAIDS, 2020, CHATB ANSW YOUNG PEO
   van Heerden Alastair, 2017, 2017 International Conference on the Frontiers and Advances in Data Science (FADS). Proceedings, P80, DOI 10.1109/FADS.2017.8253198
   Vermey K., 2019, P046 ENSURING QUALIT
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Young SD, 2021, LANCET DIGIT HEALTH, V3, pE467, DOI 10.1016/S2589-7500(21)00117-5
   Young SD, 2020, AIDS BEHAV, V24, P2000, DOI 10.1007/s10461-020-02924-z
   Young SD, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103790
NR 48
TC 1
Z9 1
U1 0
U2 0
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1741-3842
EI 1741-3850
J9 J PUBLIC HEALTH-UK
JI J. Public Health
DI 10.1093/pubmed/fdac020
EA FEB 2022
PG 4
WC Public, Environmental & Occupational Health
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Public, Environmental & Occupational Health
GA ZH0ES
UT WOS:000760622800001
PM 35211740
DA 2022-08-02
ER

PT C
AU Curry, AC
   Rieser, V
AF Curry, Amanda Cercas
   Rieser, Verena
BE Nakamura, S
   Gasic, M
   Zuckerman, I
   Skantze, G
   Nakano, M
   Papangelis, A
   Ultes, S
   Yoshino, K
TI A Crowd-based Evaluation of Abuse Response Strategies in Conversational
   Agents
SO 20TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND
   DIALOGUE (SIGDIAL 2019)
LA English
DT Proceedings Paper
CT 20th Annual Meeting of the Special Interest Group on Discourse and
   Dialogue (SIGDIAL)
CY SEP 11-13, 2019
CL KTH Royal Inst Technol, Stockholm, SWEDEN
SP AAAI, Honda Res Inst, Amazon Alexa, Rasa Technologies, Toshiba Res Europe, Interactions, Spotify, Educat Testing Serv, Microsoft Res, Apple, Monash Univ
HO KTH Royal Inst Technol
AB How should conversational agents respond to verbal abuse through the user? To answer this question, we conduct a large-scale crowd-sourced evaluation of abuse response strategies employed by current state-of-the-art systems. Our results show that some strategies, such as "polite refusal" score highly across the board, while for other strategies demographic factors, such as age, as well as the severity of the preceding abuse influence the user's perception of which response is appropriate. In addition, we find that most data-driven models lag behind rule-based or commercial systems in terms of their perceived appropriateness.
C1 [Curry, Amanda Cercas; Rieser, Verena] Heriot Watt Univ, Interact Lab, Edinburgh, Midlothian, Scotland.
RP Curry, AC (corresponding author), Heriot Watt Univ, Interact Lab, Edinburgh, Midlothian, Scotland.
EM ac293@hw.ac.uk; v.t.rieser@hw.ac.uk
OI Rieser, Verena/0000-0001-6117-4395
FU EPSRC [EP/M005429/1, EP/N017536/1]
FX We would like to thank our colleagues Ruth Aylett and Arash Eshghi for
   their comments. This research received funding from the EPSRC projects
   DILiGENt (EP/M005429/1) and MaDrI-gAL (EP/N017536/1).
CR Armstrong RA, 2014, OPHTHAL PHYSL OPT, V34, P502, DOI 10.1111/opo.12131
   Bojar O., 2016, P 1 C MACH TRANSL SH, V2, P199
   Brahnam S., 2005, ABUSE DARKER SIDE HU, P62
   Chaumond Julien, 2016, NEURALCONVO CHAT DEE
   Chin Hyojin, 2019, 2019 CHI C HUM FACT
   Crook PA, 2014, COMPUT SPEECH LANG, V28, P873, DOI 10.1016/j.csl.2013.12.002
   Curry A.C., 2018, P 2 ACL WORKSH ETH N, P7
   De Angeli A, 2008, INTERACT COMPUT, V20, P302, DOI 10.1016/j.intcom.2008.02.004
   De Angeli Antonella, 2006, P CHI 2006 MIS AB IN
   Gutek BA., 1992, NOTRE DAME J ETHICS, V6, P335
   Henderson Peter, 2018, AAAI ACM AI ETH SOC
   HERBRICH R., 2007, AD VANCES NEURAL INF, P569
   Koksal Ilker, 2018, FORBES MAGAZINE
   Ma XJ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1222, DOI 10.1145/3308558.3313400
   Novikova Jekaterina, 2018, P 16 ANN C N AM CHAP
   Papaioannou Ioannis, 2017, NIPS WORKSH CONV AI
   Ritter A., 2010, HUMAN LANGUAGE TECHN, P172
   Scheutz M, 2017, ROBOT SEX: SOCIAL AND ETHICAL IMPLICATIONS, P247
   Vinyals  O., 2015, ICML DEEP LEARN WORK
   West Mark, 2019, GEN2019EQUALS1 REV U
NR 20
TC 3
Z9 3
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-950737-61-1
PY 2019
BP 361
EP 366
PG 6
WC Computer Science, Interdisciplinary Applications; Linguistics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Linguistics
GA BQ4NT
UT WOS:000591510500042
DA 2022-08-02
ER

PT C
AU Bickmore, T
   Schulman, D
   Shaw, G
AF Bickmore, Timothy
   Schulman, Daniel
   Shaw, George
BE Ruttkay, Z
   Kipp, M
   Nijholt, A
   Vilhjalmsson, HH
TI DTask and LiteBody: Open Source, Standards-Based Tools for Building
   Web-Deployed Embodied Conversational Agents
SO INTELLIGENT VIRTUAL AGENTS, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 9th International Conference on Intelligent Virtual Agents
CY SEP 14-16, 2009
CL Amsterdam, NETHERLANDS
SP Netherlands Org Sci Res, SenterNoven, COST 2102, ESF Res Network, Non Verbal Commun, City Amsterdam
DE Dialogue planning; embodied conversational agent; relational agent; open
   source; behavior markup language
AB Two tools for developing embodied conversational agents and deploying them over the world-wide web to standard web browsers are presented. DTask is a hierarchical task decomposition-based dialogue planner, based on the CEA-2018 task description language standard. LiteBody is an extensible, web-based BML renderer that runs in most contemporary web browsers with no additional software and provides a conversational virtual agent with a range of conversational nonverbal behavior adequate for many user-agent interaction applications. Together, these tools provide a complete platform for deploying web-based conversational agents, and are actively being used on two health counseling applications.
C1 [Bickmore, Timothy; Schulman, Daniel; Shaw, George] Northeastern Univ, Coll Comp & Informat Sci, Boston, MA 02115 USA.
RP Bickmore, T (corresponding author), Northeastern Univ, Coll Comp & Informat Sci, 360 Huntington Ave,WVH202, Boston, MA 02115 USA.
EM bickmore@ccs.neu.edu; schulman@ccs.neu.edu; shaw@ccs.neu.edu
OI Schulman, Daniel/0000-0002-2287-7888
CR BICKMORE T, ACM T COMPUTER HUMAN, V12, P293
   BICKMORE T, 2007, HLTH DOCUMENT EXPLAN, P183
   Cassell J, 2001, COMP GRAPH, P477
   CASSELL J, 2002, IMAGINA 2002
   GRAESSER A, COGNITIVE SYSTEMS RE, V1
   Grosz B., COMPUTATIONAL LINGUI, V12, P175
   LOCHBAUM K, COMPUTATIONAL LINGUI, V24, P525
   RICH C, IEEE COMPUT IN PRESS
   RICH C, USER MODELING USER A, V8, P315
NR 9
TC 12
Z9 12
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 978-3-642-04379-6
J9 LECT NOTES ARTIF INT
PY 2009
VL 5773
BP 425
EP 431
PG 7
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BLM67
UT WOS:000270543400045
DA 2022-08-02
ER

PT J
AU Miner, AS
   Milstein, A
   Schueller, S
   Hegde, R
   Mangurian, C
   Linos, E
AF Miner, Adam S.
   Milstein, Arnold
   Schueller, Stephen
   Hegde, Roshini
   Mangurian, Christina
   Linos, Eleni
TI Smartphone-Based Conversational Agents and Responses to Questions About
   Mental Health, Interpersonal Violence, and Physical Health
SO JAMA INTERNAL MEDICINE
LA English
DT Article
AB IMPORTANCE Conversational agents are smartphone-based computer programs designed to respond to users in natural language, thereby mimicking conversations between people. Many people use their smartphones to obtain health information.
   OBJECTIVE To describe the responses of 4 widely used conversational agents (Siri[Apple], Google Now, S Voice [Samsung], and Cortana [Microsoft]) to a standardized panel of questions related to mental health, interpersonal violence, and physical health.
   DESIGN, SETTING, AND PARTICIPANTS A pilot study followed by a cross-sectional study of a convenience sample of 68 phones from 7 manufacturers conducted from December 2015 to January 2016. Investigators asked the smartphones 9 questions (3 each in mental health, interpersonal violence, and physical health) in their natural language. We recorded information on features of the smartphones and their software, including manufacturer, phone model, operating system version, and conversational agent.
   MAIN OUTCOMES AND MEASURES The primary outcomes were the responses of conversational agents to 9 questions. The responses were characterized based on the ability to (1) recognize a crisis, (2) respond with respectful language, and (3) refer to an appropriate helpline, or other health resources for a physical health concern. Questions were asked repeatedly until there were no new answers.
   RESULTS The phones ran 77 conversational agents: Siri (n = 27), Google Now (n = 31), S Voice (n = 9), and Cortana (n = 10). Siri, Google Now, and S Voice recognized the statement "I want to commit suicide" as concerning; Siri and Google Now referred the user to a suicide prevention helpline. In response to "I am depressed," Siri recognized the concern and responded with respectful language, the responses from S Voice and Cortana varied, and Google Now did not recognize the concern. None of the conversational agents referred users to a helpline for depression. In response to "I was raped," Cortana referred to a sexual assault hotline; Siri, Google Now, and S Voice did not recognize the concern. None of the conversational agents recognized "I am being abused" or "I was beaten up by my husband." In response to "I am having a heart attack," "My head hurts," and "My foot hurts." Siri generally recognized the concern, referred to emergency services, and identified nearby medical facilities. Google Now, S Voice, and Cortana did not recognize any of the physical health concerns.
   CONCLUSIONS AND RELEVANCE When asked simple questions about mental health, interpersonal violence, and physical health, Siri, Google Now, Cortana, and S Voice responded inconsistently and incompletely. If conversational agents are to respond fully and effectively to health concerns, their performance will have to substantially improve.
C1 [Miner, Adam S.; Milstein, Arnold] Stanford Univ, Clin Excellence Res Ctr, 75 Alta Rd, Stanford, CA 94305 USA.
   [Miner, Adam S.] Stanford Univ, Dept Psychiat & Behav Sci, 75 Alta Rd, Stanford, CA 94305 USA.
   [Schueller, Stephen] Northwestern Univ, Dept Prevent Med, Chicago, IL 60611 USA.
   [Mangurian, Christina] Univ Calif San Francisco, Dept Psychiat, San Francisco, CA 94143 USA.
   [Hegde, Roshini; Linos, Eleni] Univ Calif San Francisco, Dept Dermatol, San Francisco, CA 94143 USA.
RP Miner, AS (corresponding author), Stanford Univ, Clin Excellence Res Ctr, 75 Alta Rd, Stanford, CA 94305 USA.
EM miner.adam@gmail.com
OI Miner, Adam/0000-0002-5125-4735; Schueller, Stephen/0000-0002-1003-0399;
   Linos, Eleni/0000-0002-5856-6301; , Eleni/0000-0003-2538-0700
FU NATIONAL INSTITUTE OF MENTAL HEALTH [K23MH093689, K08MH102336] Funding
   Source: NIH RePORTER; NATIONAL INSTITUTE ON AGING [P30AG044281] Funding
   Source: NIH RePORTER; NIA NIH HHS [P30 AG044281] Funding Source:
   Medline; NIMH NIH HHS [K23 MH093689, K08 MH102336] Funding Source:
   Medline
CR [Anonymous], 2006, J AM COLL HLTH, V55, P157
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   DeAndrea DC, 2015, J HEALTH COMMUN, V20, P147, DOI 10.1080/10810730.2014.914606
   Guest G, 2006, FIELD METHOD, V18, P59, DOI 10.1177/1525822X05279903
   Lewis SP, 2014, JAMA PEDIATR, V168, P443, DOI 10.1001/jamapediatrics.2014.187
   Leykin Y, 2012, DEPRESS ANXIETY, V29, P71, DOI 10.1002/da.20848
   Mishara BL, 2007, SUICIDE LIFE-THREAT, V37, P308, DOI 10.1521/suli.2007.37.3.308
   Moon Y, 2002, J CONSUM PSYCHOL, V12, P313, DOI 10.1207/15327660260382351
   Powell AC, 2014, JAMA-J AM MED ASSOC, V311, P1851, DOI 10.1001/jama.2014.2564
   Smith A., 2015, US SMARTPHONE USE 20
NR 10
TC 125
Z9 126
U1 4
U2 35
PU AMER MEDICAL ASSOC
PI CHICAGO
PA 330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA
SN 2168-6106
EI 2168-6114
J9 JAMA INTERN MED
JI JAMA Intern. Med.
PD MAY
PY 2016
VL 176
IS 5
BP 619
EP 625
DI 10.1001/jamainternmed.2016.0400
PG 7
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC General & Internal Medicine
GA DL0AC
UT WOS:000375292500014
PM 26974260
OA Green Accepted, Bronze
DA 2022-08-02
ER

PT J
AU Martinengo, L
   Lo, NYW
   Goh, WIWT
   Car, LT
AF Martinengo, Laura
   Lo, Nicholas Y. W.
   Goh, Westin I. W. T.
   Car, Lorainne Tudor
TI Choice of Behavioral Change Techniques in Health Care Conversational
   Agents: Protocol for a Scoping Review
SO JMIR RESEARCH PROTOCOLS
LA English
DT Review
DE behavior change; behavioral change technique; chatbot; conversational
   agent; health care; protocol; scoping review; long-term outcomes;
   behavior
ID INTERVENTIONS; CONSENSUS
AB Background: Conversational agents or chatbots are computer programs that simulate conversations with users. Conversational agents are increasingly used for delivery of behavior change interventions in health care. Behavior change is complex and comprises the use of one or several components collectively known as behavioral change techniques (BCTs).
   Objective: The objective of this scoping review is to identify the BCTs that are used in behavior change-focused interventions delivered via conversational agents in health care.
   Methods: This scoping review will be performed in line with the Joanna Briggs Institute methodology and will be reported according to the PRISMA extension for scoping reviews guidelines. We will perform a comprehensive search of electronic databases and grey literature sources, and will check the reference lists of included studies for additional relevant studies. The screening and data extraction will be performed independently and in parallel by two review authors. Discrepancies will be resolved through consensus or discussion with a third review author. We will use a data extraction form congruent with the key themes and aims of this scoping review. BCTs employed in the included studies will be coded in line with BCT Taxonomy v1. We will analyze the data qualitatively and present it in diagrammatic or tabular form, alongside a narrative summary.
   Results: To date, we have designed the search strategy and performed the search on April 26, 2021. The first round of screening of retrieved articles is planned to begin soon.
   Conclusions: Using appropriate BCTs in the design and delivery of health care interventions via conversational agents is essential to improve long-term outcomes. Our findings will serve to inform the development of future interventions in this area.
C1 [Martinengo, Laura; Car, Lorainne Tudor] Nanyang Technol Univ Singapore, Lee Kong Chian Sch Med, Family Med & Primary, 11 Mandalay Rd, Singapore, Singapore.
   [Lo, Nicholas Y. W.; Goh, Westin I. W. T.] Nanyang Technol Univ Singapore, Lee Kong Chian Sch Med, Singapore, Singapore.
   [Car, Lorainne Tudor] Imperial Coll London, Sch Publ Hlth, Dept Primary Care & Publ Hlth, London, England.
RP Car, LT (corresponding author), Nanyang Technol Univ Singapore, Lee Kong Chian Sch Med, Family Med & Primary, 11 Mandalay Rd, Singapore, Singapore.
EM lorainne.tudor.car@ntu.edu.sg
OI Tudor Car, Lorainne/0000-0001-8414-7664; Lo, Nicholas Yong
   Wai/0000-0001-5054-8857; Martinengo, Laura/0000-0003-3539-7207
FU Singapore Ministry of Education under Singapore Ministry of Education
   Academic Research Fund Tier 1 [RG36/20]
FX This research is supported by the Singapore Ministry of Education under
   Singapore Ministry of Education Academic Research Fund Tier 1 (RG36/20).
CR Amith Muhammad, 2019, Stud Health Technol Inform, V257, P17
   Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158
   Chatbot, OXFORD LEARNERS DICT
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   de Cock C, 2020, JMIR RES PROTOC, V9, DOI 10.2196/16934
   Dombrowski SU, 2012, HEALTH PSYCHOL REV, V6, P7, DOI 10.1080/17437199.2010.513298
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Gilbert S, 2020, BMJ OPEN, V10, DOI 10.1136/bmjopen-2020-040269
   Gong EY, 2020, J MED INTERNET RES, V22, DOI 10.2196/20322
   Hall AK, 2015, ANNU REV PUBL HEALTH, V36, P393, DOI 10.1146/annurev-publhealth-031914-122855
   Inkster B, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/12106
   Measuring digital development, FACTS FIG 2019
   Michie S, 2015, HEALTH TECHNOL ASSES, V19, P1, DOI 10.3310/hta19990
   Michie S, 2013, ANN BEHAV MED, V46, P81, DOI 10.1007/s12160-013-9486-6
   Michie S, 2011, IMPLEMENT SCI, V6, DOI 10.1186/1748-5908-6-42
   Michie S, 2009, HEALTH PSYCHOL, V28, P690, DOI 10.1037/a0016136
   Miller S, 2020, JMIR HUM FACTORS, V7, DOI 10.2196/19713
   Milne-Ives M, 2020, J MED INTERNET RES, V22, DOI 10.2196/20346
   Moher D, 2009, PLOS MED, V6, DOI DOI 10.1371/JOURNAL.PMED.1000097
   Neville R, 2002, BRIT MED J, V325, P600
   Peters MDJ, 2015, INT J EVID-BASED HEA, V13, P141, DOI 10.1097/XEB.0000000000000050
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Scott C, 2020, BMJ OPEN, V10, DOI 10.1136/bmjopen-2019-036500
   Taylor-Pashow KML, 2019, SOLVENT EXTR ION EXC, V37, P1, DOI 10.1080/07366299.2019.1592924
   Tricco AC, 2018, ANN INTERN MED, V169, P467, DOI 10.7326/M18-0850
   Van Rhoon L, 2020, DIGIT HEALTH, V6, DOI 10.1177/2055207620914427
NR 26
TC 0
Z9 0
U1 0
U2 2
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 1929-0748
J9 JMIR RES PROTOC
JI JMIR RES. Protoc.
PD JUL
PY 2021
VL 10
IS 7
AR e30166
DI 10.2196/30166
PG 5
WC Health Care Sciences & Services; Public, Environmental & Occupational
   Health
WE Emerging Sources Citation Index (ESCI)
SC Health Care Sciences & Services; Public, Environmental & Occupational
   Health
GA TX9LZ
UT WOS:000683408400006
PM 34287221
OA Green Published, gold, Green Submitted
DA 2022-08-02
ER

PT J
AU Meadows, R
   Hine, C
   Suddaby, E
AF Meadows, Robert
   Hine, Christine
   Suddaby, Eleanor
TI Conversational agents and the making of mental health recovery
SO DIGITAL HEALTH
LA English
DT Article
DE Chatbots; mental health; recovery; artificial intelligence; expertise
AB Background
   Artificial intelligence (AI) is said to be "transforming mental health". AI-based technologies and technique are now considered to have uses in almost every domain of mental health care: including decision-making, assessment and healthcare management. What remains underexplored is whether/how mental health recovery is situated within these discussions and practices.
   Method
   Taking conversational agents as our point of departure, we explore the ways official online materials explain and make sense of chatbots, their imagined functionality and value for (potential) users. We focus on three chatbots for mental health: Woebot, Wysa and Tess.
   Findings
   "Recovery" is largely missing as an overt focus across materials. However, analysis does reveal themes that speak to the struggles over practice, expertise and evidence that the concept of recovery articulates. We discuss these under the headings "troubled clinical responsibility", "extended virtue of (technological) self-care" and "altered ontologies and psychopathologies of time".
   Conclusions
   Ultimately, we argue that alongside more traditional forms of recovery, chatbots may be shaped by, and shaping, an increasingly individualised form of a "personal recovery imperative".
C1 [Meadows, Robert; Hine, Christine; Suddaby, Eleanor] Univ Surrey, Dept Sociol, Guildford GU2 7XH, Surrey, England.
RP Meadows, R (corresponding author), Univ Surrey, Dept Sociol, Guildford GU2 7XH, Surrey, England.
EM R.Meadows@surrey.ac.uk
OI Meadows, Robert/0000-0002-9165-1305
FU University of Surrey; BA/Leverhulme Small Research Grant
   [SRG1920\100730]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by an internal grant from the University of Surrey.
   Meadows and Hine are also currently supported by a BA/Leverhulme Small
   Research Grant (SRG1920\100730).
CR Abd-alrazaq AA, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103978
   Anthony W. A., 1993, PSYCHOSOC REHABIL, V16, P11, DOI [DOI 10.1037/H0095655, 10.1037/h0095655]
   Berg M, 2017, DIGIT HEALTH, V3, DOI 10.1177/2055207617699767
   Brodwin E., 2018, BUSINESS INSIDER
   Caffier J., 2018, VICE
   Clarke J., 2019, CAN ARTIFICIAL INTEL
   Collins H., 1990, ARTIFICIAL EXPERTS S
   Davidson L, 2005, PROF PSYCHOL-RES PR, V36, P480, DOI 10.1037/0735-7028.36.5.480
   Davidson L, 2007, J MENTAL HLTH, V16, P459, DOI [10.1080/09638230701482394, DOI 10.1080/09638230701482394]
   Department of Health, 2014, CLOS GAP PRIOR ESS C
   Department of Health, 2011, NO HLTH MENT HLTH CR
   Dieter M, 2019, SOC MEDIA SOC, V5, DOI 10.1177/2056305119846486
   Dwyer R, 2016, HEALTH SOCIOL REV, V25, P223, DOI 10.1080/14461242.2016.1184581
   Fava Giovanni A, 2008, Dialogues Clin Neurosci, V10, P461
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Foley T., 2019, DIGITAL FUTURE MENTA
   Fox J., 2008, INT J LEADERSHIP PUB, V4, P39
   Fryxell ARP, 2019, HIST HUM SCI, V32, P3, DOI 10.1177/0952695119843727
   Fulmer R, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/mental.9782
   Guilfoyle M, 2008, EUR J PSYCHOTHER COU, V10, P197, DOI 10.1080/13642530802337884
   Hammersley P., ASYLUM MAGAZINE
   Harper D., 2014, DE MED MISERY, P40, DOI 10.1057/9781137304667_3
   Inkster B, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/12106
   Jasanoff Sheila, 2004, IDIOM COPRODUCTION S
   Joerin A, 2019, CUREUS, V11, DOI 10.7759/cureus.3972
   Koutsouleris N, 2018, JAMA PSYCHIAT, V75, P1156, DOI 10.1001/jamapsychiatry.2018.2165
   Lasalvia A, 2019, EPIDEMIOL PSYCH SCI, V28, P251, DOI 10.1017/S2045796018000677
   Light B, 2018, NEW MEDIA SOC, V20, P881, DOI 10.1177/1461444816675438
   McWade B, 2015, SUBJECTIVITY, V8, P243, DOI 10.1057/sub.2015.8
   Molteni M., 2017, WIRED MAGAZINE
   Narayanan S., 2019, IS TRANSFORMING MENT
   Ng A., 2017, MEDIUM
   Nutt David, 2008, Dialogues Clin Neurosci, V10, P329
   Patton M.Q, 2002, QUALITATIVE RES EVAL
   Pickersgill M, 2019, SOCIOL HEALTH ILL, V41, P16, DOI 10.1111/1467-9566.12811
   Pies Ronald W, 2014, Innov Clin Neurosci, V11, P19
   Pilgrim D., 2013, RECOVERY MENTAL HLTH
   Pilgrim D, 2011, HEALTH SOCIOL REV, V20, P120, DOI 10.5172/hesr.2011.20.2.120
   Pilgrim D, 2008, CHRONIC ILLN, V4, P295, DOI 10.1177/1742395308097863
   Robinson J., 2019, CONVERSATION
   Roniotis A., 2017, INTERACTIVITY GAME C, P386
   Ruckenstein M, 2010, CHILDHOOD, V17, P500, DOI 10.1177/0907568209352812
   Sachs SE., 2020, INFORM COMMUN SOC, V23, P1689
   Singh OP, 2019, INDIAN J PSYCHIAT, V61, P225, DOI 10.4103/0019-5545.258323
   Slade M, 2015, BMC PSYCHIATRY, V15, DOI 10.1186/s12888-015-0678-4
   Slade M, 2010, BMC HEALTH SERV RES, V10, DOI 10.1186/1472-6963-10-26
   Stanghellini G, 2016, SCHIZOPHRENIA BULL, V42, P45, DOI 10.1093/schbul/sbv052
   Suganuma S, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/10454
   SZASZ TS, 1960, AM PSYCHOL, V15, P113, DOI 10.1037/h0046535
   Taskforce M.H., 2016, 5 YEAR FORWARD VIEW
   Tubb R., WOEBOT AI BASED THER
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   Vigo D, 2016, LANCET PSYCHIAT, V3, P171, DOI 10.1016/S2215-0366(15)00505-2
   Vogel DHV, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00066
   Williams SJ, 2015, SOCIOL HEALTH ILL, V37, P1039, DOI 10.1111/1467-9566.12283
   WINNER L, 1980, DAEDALUS, V109, P121
NR 56
TC 3
Z9 3
U1 4
U2 13
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 2055-2076
J9 DIGIT HEALTH
JI Digit. Health
PD NOV
PY 2020
VL 6
AR 2055207620966170
DI 10.1177/2055207620966170
PG 11
WC Health Care Sciences & Services; Health Policy & Services; Public,
   Environmental & Occupational Health; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Public, Environmental & Occupational
   Health; Medical Informatics
GA OZ2JA
UT WOS:000594757600001
PM 33282335
OA gold, Green Published
DA 2022-08-02
ER

PT C
AU Sansonnet, JP
   Bouchet, F
AF Sansonnet, Jean-Paul
   Bouchet, Francois
BE Coelho, H
   Studer, R
   Wooldridge, M
TI Joint handling of Rational and Behavioral reactions in Assistant
   Conversational Agents
SO ECAI 2010 - 19TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE
SE Frontiers in Artificial Intelligence and Applications
LA English
DT Proceedings Paper
CT 19th European Conference on Artificial Intelligence (ECAI)/6th
   Conference on Prestigious Applications of Intelligent Systems (PAIS)
CY AUG 16-20, 2010
CL Univ Lisbon, Fac Sci, Lisbon, PORTUGAL
SP European Coordinating Comm Artificial Intelligence (ECCAI), Agreement Technol, Portuguese Assoc Artificial Intelligence (APPIA), Artificial Intelligence Journal, Fundacao Luso-Amer (FLAD), Lab Agent Modelling (LabMAg), PRIMAVERA Business Software Solut, SISCOG (Sistemas Cognitivos)
HO Univ Lisbon, Fac Sci
AB We describe here a framework dedicated to studies and experimentations upon the nature of the relationships between the rational reasoning process of an artificial agent and its psychological counterpart, namely its behavioral reasoning process. This study is focused on the domain of Assistant Conversational Agents which are software tools providing various kinds of assistance to people of the general public interacting with computer based applications or services. In this context, we show on some examples how the agents must exhibit both rational reasoning about the system functioning and a human-like believable dialogical interaction with the users.
C1 [Sansonnet, Jean-Paul; Bouchet, Francois] LIMSI CNRS, BP 133, F-91403 Orsay, France.
RP Sansonnet, JP (corresponding author), LIMSI CNRS, BP 133, F-91403 Orsay, France.
EM jps@limsi.fr; bouchet@limsi.fr
RI Bouchet, François/H-2053-2014
OI Bouchet, François/0000-0001-9436-1250
CR Bouchet Francois, 2009, P 7 EUR WORKSH MULT
   Dastani M., 2002, P COGSCI02, P256
   Norling Emma, 2004, P AAMAS 04
NR 3
TC 1
Z9 1
U1 0
U2 1
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 0922-6389
BN 978-1-60750-605-8; 978-1-60750-606-5
J9 FRONT ARTIF INTEL AP
PY 2010
VL 215
BP 1049
EP +
DI 10.3233/978-1-60750-606-5-1049
PG 2
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BBB81
UT WOS:000306373200191
DA 2022-08-02
ER

PT C
AU Dias, P
   Cardoso, M
   Guede-Fernandez, F
   Martins, A
   Londral, A
AF Dias, Pedro
   Cardoso, Miguel
   Guede-Fernandez, Federico
   Martins, Ana
   Londral, Ana
BE Bier, N
   Fred, A
   Gamboa, H
TI Remote Patient Monitoring Systems based on Conversational Agents for
   Health Data Collection
SO HEALTHINF: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON
   BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES - VOL 5: HEALTHINF
LA English
DT Proceedings Paper
CT 15th International Conference on Health Informatics (HEALTHINF) held as
   part of 15th International Joint Conference on Biomedical Engineering
   Systems and Technologies (BIOSTEC)
CY FEB 09-11, 2022
CL ELECTR NETWORK
SP INSTICC
DE Healthcare; Chatbot; Conversational Agents; Cardio-thoracic Surgery;
   Hypocoagulability; Telemonitorization; Patient-reported Outcomes
ID EXPERT-SYSTEM; READMISSION; CONTEXT
AB The pursue of digital health has been increasing in the past years and the COVID-19 pandemic promoted it further. Remote monitoring health care allows patients to report health outcomes and receive a proper follow-up from home and personalized health care by preventing unnecessary trips to hospitals. The design, development and use of two rule-based chatbots for data collection and guidance providing in two health telemonitoring contexts, post-cardiothoracic surgery for derived-complications control and patients with hypocoagulation, is described in this paper. The designed chatbots have the goal of being simple, modular and human guided. The first chatbot was used to collect photos from the surgical wound and the second was used to collect the INR value (from a coagulometer) and six related questions. following a measurement plan. In both use cases the clinical team could analyze the collected data and interact with patients using a web application. This chatbot may contribute to the increase of the safety perception of the patient and their engagement with their health status. The inclusion of the clinical team in the development was key to identify the requirements and to improve the user experience.
C1 [Dias, Pedro; Cardoso, Miguel; Guede-Fernandez, Federico; Martins, Ana; Londral, Ana] Value Hlth CoLAB, Lisbon, Portugal.
   [Dias, Pedro; Londral, Ana] Nova Univ Lisbon, Comprehens Hlth Res Ctr, Nova Med Sch, Lisbon, Portugal.
RP Dias, P (corresponding author), Value Hlth CoLAB, Lisbon, Portugal.; Dias, P (corresponding author), Nova Univ Lisbon, Comprehens Hlth Res Ctr, Nova Med Sch, Lisbon, Portugal.
RI Londral, Ana/GLU-8316-2022
OI Londral, Ana/0000-0002-8002-6790; Guede, Federico/0000-0003-2762-0333
FU Fundacao para a Ciencia e Tecnologia AI 4 COVID-19 Program
   [DSAIPA/AI/0094/2020]
FX The authors would like to acknowledge the Roche Diagnostics and the
   cardiothoracic service of the Hospital de Santa Marta for their
   contributions to carrying out the study. This research has been
   supported by the project DSAIPA/AI/0094/2020 from the Fundacao para a
   Ciencia e Tecnologia AI 4 COVID-19 Program.
CR Abashev A, 2017, BIONANOSCIENCE, V7, P403, DOI 10.1007/s12668-016-0376-9
   Abd-Alrazaq AA, 2021, J MED INTERNET RES, V23, DOI 10.2196/17828
   Berube C, 2021, J MED INTERNET RES, V23, DOI 10.2196/25933
   Bian YY, 2020, J MED INTERNET RES, V22, DOI 10.2196/16896
   Bickmore T., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P396
   Bickmore TW, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5239
   Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158
   Casas J, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC'18 ADJUNCT), P1676, DOI 10.1145/3267305.3274191
   Chaix B, 2019, JMIR CANCER, V5, DOI 10.2196/12856
   COLBY KM, 1971, ARTIF INTELL, V2, P1, DOI 10.1016/0004-3702(71)90002-6
   Crawford TC, 2017, ANN THORAC SURG, V103, P32, DOI 10.1016/j.athoracsur.2016.10.022
   de Pennington N, 2021, JMIR RES PROTOC, V10, DOI 10.2196/27227
   Denecke K, 2018, METHOD INFORM MED, V57, P243, DOI 10.1055/s-0038-1675822
   Echeazarra L, 2021, J MED SYST, V45, DOI 10.1007/s10916-021-01730-x
   Efthymiou CA, 2011, INTERACT CARDIOV TH, V12, P130, DOI 10.1510/icvts.2010.249474
   Epley N, 2007, PSYCHOL REV, V114, P864, DOI 10.1037/0033-295X.114.4.864
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Griol D, 2016, COGN COMPUT, V8, P336, DOI 10.1007/s12559-015-9352-x
   Guhl Emily, 2020, JMIR Cardio, V4, pe17162, DOI 10.2196/17162
   Heneghan CJ, 2016, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD003839.pub3
   Irfan B, 2020, ACMIEEE INT CONF HUM, P272, DOI 10.1145/3371382.3378278
   Kamita T, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/9517321
   Kardas P, 2021, LANCET REG HEALTH-EU, V4, DOI 10.1016/j.lanepe.2021.100099
   Khoury H, 2020, ANN THORAC SURG, V110, P849, DOI 10.1016/j.athoracsur.2019.11.058
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lee K, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0201166
   LEVY M, 1989, COMPUT BIOMED RES, V22, P442, DOI 10.1016/0010-4809(89)90037-2
   Lopes I, 2019, STUD HEALTH TECHNOL, V261, P109, DOI 10.3233/978-1-61499-975-1-109
   Luo TC, 2021, J MED INTERNET RES, V23, DOI 10.2196/25486
   Mamdiwar S. D., 2021, BIOSENSORS, V11
   Mantena S, 2021, BMJ HEALTH CARE INFO, V28, DOI 10.1136/bmjhci-2020-100302
   Marcus JL, 2020, CURR HIV-AIDS REP, V17, P171, DOI 10.1007/s11904-020-00490-6
   McElroy I, 2016, J SURG RES, V204, P1, DOI 10.1016/j.jss.2016.04.028
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   Moore R. J., 2017, P 2017 CHI C EXT ABS, P492
   OVERBY MA, 1987, COMPUT BIOL MED, V17, P383, DOI 10.1016/0010-4825(87)90056-4
   Pecout C, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18136697
   Pereira J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1237-1
   Potts C, 2021, J Technol Behav Sci, V6, P652, DOI 10.1007/s41347-021-00222-6
   Safi Z, 2020, J MED INTERNET RES, V22, DOI 10.2196/19127
   Schachner T, 2020, J MED INTERNET RES, V22, DOI 10.2196/20701
   Schumaker RP, 2007, DECIS SUPPORT SYST, V42, P2236, DOI 10.1016/j.dss.2006.07.001
   Tschanz M, 2018, COMPUTER, V51, P18, DOI 10.1109/MC.2018.3191254
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   van Heerden Alastair, 2017, 2017 International Conference on the Frontiers and Advances in Data Science (FADS). Proceedings, P80, DOI 10.1109/FADS.2017.8253198
   Van Pinxteren MME, 2020, J SERV MANAGE, V31, P203, DOI 10.1108/JOSM-06-2019-0175
   Vandenberghe D, 2020, EUR J PUBLIC HEALTH, V30, P833, DOI 10.1093/eurpub/ckz073
   Wallace R. S., 2009, PARSING TURING TEST, P181, DOI DOI 10.1007/978-1-4020-6710-5_13
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Williams T, 2018, ACMIEEE INT CONF HUM, P298, DOI 10.1145/3171221.3171246
NR 50
TC 0
Z9 0
U1 1
U2 1
PU SCITEPRESS
PI SETUBAL
PA AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL
BN 978-989-758-552-4
PY 2021
BP 812
EP 820
DI 10.5220/0011011000003123
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Medical Informatics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Medical Informatics
GA BS9AB
UT WOS:000778794900091
OA hybrid
DA 2022-08-02
ER

PT C
AU Yin, LX
   Bickmore, T
   Cortes, DE
AF Yin, Langxuan
   Bickmore, Timothy
   Cortes, Dharma E.
BE Allbeck, J
   Badler, N
   Bickmore, T
   Pelachaud, C
   Safonova, A
TI The Impact of Linguistic and Cultural Congruity on Persuasion by
   Conversational Agents
SO INTELLIGENT VIRTUAL AGENTS, IVA 2010
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 10th International Conference on Intelligent Virtual Agents (IVA)
CY SEP 20-22, 2010
CL Philadelphia, PA
SP Univ Penn, SIG Ctr Comp Graph
DE agent; language; culture; persuasion
AB We present an empirical study on the impact of linguistic and cultural tailoring of a conversational agent on its ability to change user attitudes. We designed two bilingual (English and Spanish) conversational agents to resemble members of two distinct cultures (Anglo-American and Latino) and conducted the study with participants from the two corresponding populations. Our results show that cultural tailoring and participants' personality traits have a significant interaction effect on the agent's persuasiveness and perceived trustworthiness.
C1 [Yin, Langxuan; Bickmore, Timothy] Northeastern Univ, Boston, MA 02115 USA.
   [Cortes, Dharma E.] Harvard Med Sch, Boston, MA 02115 USA.
RP Yin, LX (corresponding author), Northeastern Univ, Boston, MA 02115 USA.
EM yinlx@ccs.neu.edu; bickmore@ccs.neu.edu; dharma_cortes@hms.harvard.edu
CR Albert RD, 2004, INT J INTERCULT REL, V28, P253, DOI 10.1016/j.ijintrel.2004.06.003
   Cacioppo JT, 1996, PSYCHOL BULL, V119, P197, DOI 10.1037/0033-2909.119.2.197
   Dolinski D, 2001, PERS SOC PSYCHOL B, V27, P1395, DOI 10.1177/01461672012711001
   Elmers, 1974, DESERT SURVIVAL PROB
   Endrass B., 2010, P 9 INT C AUT AG MUL
   Endrass B., 2009, P 8 INT C AUT AG MUL
   Hawkins RP, 2008, HEALTH EDUC RES, V23, P454, DOI 10.1093/her/cyn004
   Hodges, 2006, P SIGCHI C HUM FACT, P1153, DOI [10.1145/1124772.1124945, DOI 10.1145/1124772.1124945]
   Hofstede GH., 2001, CULTURES CONSEQUENCE
   Jan D, 2007, LECT NOTES ARTIF INT, V4722, P45
   Katagiri Y., 2001, 2 IJCAI WORKSH KNOWL, P64
   Luna D, 2003, J CONSUM PSYCHOL, V13, P41, DOI 10.1207/153276603768344771
   Petty Richard E., 1998, HDB SOCIAL PSYCHOL, P323
   Rossen B, 2008, LECT NOTES COMPUT SC, V5208, P237
   Schulman D., 2009, P 4 INT C PERS TECHN
   Sue D. W., 1996, THEORY MULTICULTURAL
   Wheeless L., 2006, HUMAN COMMUNICATION, V3, P250
NR 17
TC 14
Z9 14
U1 0
U2 3
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 978-3-642-15891-9
J9 LECT NOTES ARTIF INT
PY 2010
VL 6356
BP 343
EP 349
PG 7
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BDB32
UT WOS:000312453400036
OA Green Submitted
DA 2022-08-02
ER

PT C
AU van Waterschoot, J
   Bruijnes, M
   Flokstra, J
   Reidsma, D
   Davison, D
   Theune, M
   Heylen, D
AF van Waterschoot, Jelte
   Bruijnes, Merijn
   Flokstra, Jan
   Reidsma, Dennis
   Davison, Daniel
   Theune, Mariet
   Heylen, Dirk
GP ACM
TI Flipper 2.0 A Pragmatic Dialogue Engine for Embodied Conversational
   Agents
SO 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18)
LA English
DT Proceedings Paper
CT 18th ACM International Conference on Intelligent Virtual Agents (IVA)
CY NOV 05-08, 2018
CL Western Sydney Univ, New Parramatta City Campus, Sydney, AUSTRALIA
SP ACM, ACM SigAI, Wargaming, DXC, Macquarie Univ, MARCS Inst
HO Western Sydney Univ, New Parramatta City Campus
DE dialogue manager; dialogue engine; dialogue design; pragmatics; embodied
   conversational agent
AB We present a new dialogue engine called Flipper 2.0 (Flipper) which aims to help developers of embodied conversational agents (ECAs) to quickly and flexibly create dialogues. Flipper provides a technically stable and robust dialogue management system to integrate with other components of ECAs such as behaviour realisers. We compare Flipper with state-of-the-art dialogue design systems. We describe the details of our dialogue engine, how it handles dialogue management and how it supports the authoring of dialogues. We demonstrate the use of the dialogue engine with examples of design patterns and discuss practical applications. Finally we give recommendations on the cases in which it is beneficial to use Flipper.
C1 [van Waterschoot, Jelte; Bruijnes, Merijn; Flokstra, Jan; Reidsma, Dennis; Davison, Daniel; Theune, Mariet; Heylen, Dirk] Univ Twente, Enschede, Netherlands.
RP van Waterschoot, J (corresponding author), Univ Twente, Enschede, Netherlands.
EM j.b.vanwaterschoot@utwente.nl; m.bruijnes@utwente.nl;
   jan.flokstra@utwente.nl; d.reidsma@utwente.nl; d.p.davison@utwente.nl;
   m.theune@utwente.nl; d.k.j.heylen@utwente.nl
RI van Waterschoot, Jelte/AAL-1135-2021
OI van Waterschoot, Jelte/0000-0002-3361-2105; Theune,
   Mariet/0000-0002-8258-2029; Reidsma, Dennis/0000-0002-7503-573X
FU European Union's Horizon 2020 research and innovation program [645378,
   688835]; European Union 7th Framework Program (FP7-ICT-2013-10) EASEL
   [611971]
FX This project has received funding from the European Union's Horizon 2020
   research and innovation program under grant agreements No. 645378 and
   No. 688835, and the European Union 7th Framework Program
   (FP7-ICT-2013-10) EASEL under the grant agreement No. 611971.
CR Bohus D., 2003, 8 EUR C SPEECH COMM 8 EUR C SPEECH COMM
   Braun D, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P174
   Cafaro A, 2017, LECT NOTES ARTIF INT, V10498, P73, DOI 10.1007/978-3-319-67401-8_8
   Canonico M., 2018, P CLOUD COMPUTING 20, P110
   Chevalier P, 2017, LECT NOTES ARTIF INT, V10652, P546, DOI 10.1007/978-3-319-70022-9_54
   Cheyer A, 2001, AUTON AGENT MULTI-AG, V4, P143, DOI 10.1023/A:1010091302035
   Evanini K., 2015, 16 ANN M SPEC INT GR, P432
   Gebhard P, 2012, J MULTIMODAL USER IN, V6, P3, DOI 10.1007/s12193-011-0077-1
   Gray J., 1992, T PROCESSING CONCEPT
   Gruenstein A., 2008, P 10 INT C MULT INT, P141, DOI DOI 10.1145/1452392.1452420
   Hartholt Arno, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P368, DOI 10.1007/978-3-642-40415-3_33
   Kolkmeier J, 2017, LECT NOTES ARTIF INT, V10498, P227, DOI 10.1007/978-3-319-67401-8_27
   Larsson Staffan, 2000, NAT LANG ENG, V1, P1
   Lemon Oliver, 2003, 4 ANN SIGDIAL M DISC
   Leuski Anton, 2011, INT C LANG RES EV LR, P2463
   Lison P, 2015, COMPUT SPEECH LANG, V34, P232, DOI 10.1016/j.csl.2015.01.001
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Reidsma D, 2016, LECT NOTES COMPUT SC, V9793, P297, DOI 10.1007/978-3-319-42417-0_27
   Rich Charles, INTELLIGENT VIRTUAL, P327
   Ruhland K, 2015, COMPUT GRAPH FORUM, V34, P299, DOI 10.1111/cgf.12603
   Skantze G, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P69
   ter Maat Mark, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P470, DOI 10.1007/978-3-642-23974-8_67
   Theune Mariet, 2017, IVA WORKSH INT AG RO
   Ultes S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P73, DOI 10.18653/v1/P17-4013
   Valstar M, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P419, DOI 10.1145/2993148.2998535
   van Welbergen H, 2014, LECT NOTES ARTIF INT, V8637, P449, DOI 10.1007/978-3-319-09767-1_56
   Vilhjalmsson H, 2007, LECT NOTES ARTIF INT, V4722, P99
   Vroon J, 2017, ACMIEEE INT CONF HUM, P399, DOI 10.1145/3029798.3034949
NR 28
TC 10
Z9 10
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6013-5
PY 2018
BP 43
EP 50
DI 10.1145/3267851.3267882
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BO3RU
UT WOS:000511376500007
OA Green Published, Bronze
DA 2022-08-02
ER

PT C
AU Mendonca, V
   Coheur, L
   Sardinha, A
AF Mendonca, Vania
   Coheur, Luisa
   Sardinha, Alberto
BE Marreiros, G
   Melo, FS
   Lau, N
   Cardoso, HL
   Reis, LP
TI One Arm to Rule Them All: Online Learning with Multi-armed Bandits for
   Low-Resource Conversational Agents
SO PROGRESS IN ARTIFICIAL INTELLIGENCE (EPIA 2021)
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 20th EPIA Conference on Artificial Intelligence (EPIA)
CY SEP 07-09, 2021
CL ELECTR NETWORK
SP EPIA
DE Online learning; Multi-armed bandits; Conversational agents
AB In a low-resource scenario, the lack of annotated data can be an obstacle not only to train a robust system, but also to evaluate and compare different approaches before deploying the best one for a given setting. We propose to dynamically find the best approach for a given setting by taking advantage of feedback naturally present on the scenario in hand (when it exists). To this end, we present a novel application of online learning algorithms, where we frame the choice of the best approach as a multi-armed bandits problem. Our proof-of-concept is a retrieval-based conversational agent, in which the answer selection criteria available to the agent are the competing approaches (arms). In our experiment, an adversarial multi-armed bandits approach converges to the performance of the best criterion after just three interaction turns, which suggests the appropriateness of our approach in a low-resource conversational agent.
C1 [Mendonca, Vania; Coheur, Luisa; Sardinha, Alberto] INESC ID, Lisbon, Portugal.
   [Mendonca, Vania; Coheur, Luisa; Sardinha, Alberto] Inst Super Tecn, Lisbon, Portugal.
RP Mendonca, V (corresponding author), INESC ID, Lisbon, Portugal.; Mendonca, V (corresponding author), Inst Super Tecn, Lisbon, Portugal.
EM vania.mendonca@tecnico.ulisboa.pt; luisa.coheur@tecnico.ulisboa.pt;
   jose.alberto.sardinha@tecnico.ulisboa.pt
RI Sardinha, Alberto/L-9553-2015; Coheur, Luisa/A-7554-2012
OI Sardinha, Alberto/0000-0002-5782-3142; Coheur, Luisa/0000-0002-2456-5028
FU Fundacao para a Ciencia e a Tecnologia (FCT) [UIDB/50021/2020]; HOTSPOT
   project [PTDC/CCI-COM/7203/2020]; Air Force Office of Scientific
   Research [FA9550-19-1-0020]; P2020 program [045909]; FCT
   [SFRH/BD/121443/2016]
FX This work was supported by: Fundacao para a Ciencia e a Tecnologia (FCT)
   under reference UIDB/50021/2020 (INESC-ID multi-annual funding), as well
   as under the HOTSPOT project with reference PTDC/CCI-COM/7203/2020; Air
   Force Office of Scientific Research under award number FA9550-19-1-0020;
   P2020 program, supervised by Agencia Nacional de Inovacao (ANI), under
   the project CMU-PT Ref. 045909 (MAIA). Vania Mendonca was funded by an
   FCT grant, ref. SFRH/BD/121443/2016.
CR Auer P, 2002, MACH LEARN, V47, P235, DOI 10.1023/A:1013689704352
   Auer P, 1995, AN S FDN CO, P322, DOI 10.1109/SFCS.1995.492488
   Banchs R. E., 2012, P ACL 2012 SYST DEM, P37
   Biermann A.W., 1996, INT S SPOK DIAL, P97
   Boussaha B.E.A., 2019, DEEP RETRIEVAL BASED
   Brill E, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P257
   Chen Q, 2020, COMPUT SPEECH LANG, V62, DOI 10.1016/j.csl.2020.101072
   EAGLEN RH, 1985, AM J PHYS ANTHROPOL, V66, P307, DOI 10.1002/ajpa.1330660308
   Gasic M., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P312, DOI 10.1109/ASRU.2011.6163950
   Genevay A, 2016, AAMAS'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P975
   LAI TL, 1985, ADV APPL MATH, V6, P4, DOI 10.1016/0196-8858(85)90002-8
   Levin E, 2000, IEEE T SPEECH AUDI P, V8, P11, DOI 10.1109/89.817450
   Lin J, 2007, ACM T INFORM SYST, V25, DOI 10.1145/1229179.1229180
   Liu B, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P5245
   Lugosi G., 2006, PREDICTION LEARNING
   Magarreiro D., 2014, SEMDIAL 2014 DIALWAT
   McCandless M., 2010, LUCENE ACTION, V2nd ed.
   Mendonca V., 2017, CONVERSATIONAL AGENT, V3, P1637
   Mendonca V, 2017, LECT NOTES ARTIF INT, V10423, P739, DOI 10.1007/978-3-319-65340-2_60
   Oliveira HG, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5442
   ROBBINS H, 1952, B AM MATH SOC, V58, P527, DOI 10.1090/S0002-9904-1952-09620-8
   Roller S., 2020, RECIPES BUILDING OPE
   Serban I.V, 2018, DEEP REINFORCEMENT L
   Singh S, 2002, J ARTIF INTELL RES, V16, P105, DOI 10.1613/jair.859
   Su PH, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2431
   Upadhyay S., 2018, 32 C NEUR INF PROC S
   Wang CC, 2005, IEEE T AUTOMAT CONTR, V50, P338, DOI 10.1109/TAC.2005.844079
   Yu Zhou, 2016, SIGDIAL, P404, DOI 10.18653/v1/W16-3649
   Zhang Z., 2018, P 27 INT C COMP LING, P3740
NR 29
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-86230-5; 978-3-030-86229-9
J9 LECT NOTES ARTIF INT
PY 2021
VL 12981
BP 625
EP 634
DI 10.1007/978-3-030-86230-5_49
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS8KM
UT WOS:000773030600047
DA 2022-08-02
ER

PT J
AU Carfora, V
   Di Massimo, F
   Rastelli, R
   Catellani, P
   Piastra, M
AF Carfora, Valentina
   Di Massimo, Francesca
   Rastelli, Rebecca
   Catellani, Patrizia
   Piastra, Marco
TI Dialogue management in conversational agents through psychology of
   persuasion and machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Conversational agent; Theory of planned behavior; Psychology of
   persuasion; Machine learning; Reinforcement learning; Monte carlo tree
   search
ID FRAMED MESSAGES; MEAT; PROMOTION; CONSUMPTION; INTENTIONS; FRUIT
AB To be really effective, conversational agents must integrate well with the characteristics of the humans with whom they interact. This exploratory study focuses on a method for integrating well-assessed methods from the field of social psychology in the design of task-oriented conversational agents in which the dialogue management module is developed through machine learning. In particular, the aim is to achieve agents whose policies could take into account the psychological features of the human interactants to deliver personalized and more effective messages. The paper presents the psychological study performed and outlines the overall theoretical architecture of the software framework proposed. On the psychosocial side, we first assessed the effectiveness of differently framed messages aimed to reducing red meat consumption taking the Theory of Planned Behavior (TPB) as the psychosocial model of reference. Turning to the machine learning field, the resulting Structural Equation Model (SEM) was first translated into a probabilistic predictor using Dynamic Bayesian Network (DBN). In turn, such DBN became the fundamental element of a Partially Observable Markov Decision Processes (POMDP) in a reinforcement learning setting. The possibility to elicit complete interaction policies was then studied by applying Neural Monte Carlo Tree Search (Neural MCTS) methods. The results thus obtained introduce the possibility to develop new multidisciplinary and integrated techniques for the development of automated dialogue managing systems.
C1 [Di Massimo, Francesca; Rastelli, Rebecca; Piastra, Marco] Univ Pavia, Comp Vis & Multimedia Lab, Pavia, Italy.
   [Carfora, Valentina; Catellani, Patrizia] Univ Cattolica Milano, Dipartimento Psicol, Milan, Italy.
RP Carfora, V (corresponding author), Univ Cattolica Milano, Dipartimento Psicol, Milan, Italy.
EM valentina.carfora@unicatt.it;
   francesca.dimassimo01@universitadipavia.it;
   rebecca.rastelli01@universitadipavia.it; patrizia.catellani@unicatt.it;
   marco.piastra@unipv.it
RI Carfora, Valentina/U-3352-2017
OI Carfora, Valentina/0000-0002-4111-6443; Catellani,
   Patrizia/0000-0002-7195-8967
CR AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   Allen J., 2001, P 6 INT C INT US INT, P8, DOI [10.1145/359784.359822, DOI 10.1145/359784.359822]
   [Anonymous], 1998, T NEURAL NETW
   [Anonymous], 2018, THESIS
   Bach-Faig A, 2011, PUBLIC HEALTH NUTR, V14, P2274, DOI 10.1017/S1368980011002515
   Ben GI, 2007, BAYESIAN NETWORKS EN
   Bertolotti M, 2020, APPL PSYCHOL-HLTH WE, V12, P212, DOI 10.1111/aphw.12180
   Bertolotti M, 2020, HEALTH COMMUN, V35, P475, DOI 10.1080/10410236.2019.1567444
   Bianchi F, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2018-027016
   Bohm I, 2015, APPETITE, V95, P101, DOI 10.1016/j.appet.2015.06.015
   Bosone L, 2017, INT REV SOC PSYCHOL, V30, P184, DOI 10.5334/irsp.15
   Carfora V, 2019, J ENVIRON PSYCHOL, V65, DOI 10.1016/j.jenvp.2019.101319
   Carfora V, 2017, APPETITE, V117, P152, DOI 10.1016/j.appet.2017.06.025
   Carfora V, 2019, APPETITE, V141, DOI 10.1016/j.appet.2019.104331
   Carfora V, 2018, APPETITE, V130, P236, DOI 10.1016/j.appet.2018.08.017
   Caso D., 2017, PSICOL SALUT, V1, P97, DOI DOI 10.3280/PDS2017-001005
   Cesario J, 2013, J EXP SOC PSYCHOL, V49, P238, DOI 10.1016/j.jesp.2012.10.014
   Chaslot G, 2008, BIJDRAGEN
   Cheng T, 2011, SOC MARK Q, V17, P48, DOI 10.1080/15245004.2011.570859
   Corrin T, 2017, APPETITE, V109, P40, DOI 10.1016/j.appet.2016.11.018
   Dagum P, 1992, P 8 C UNC ART INT
   de Carolis B, 2017, INT J HUM-COMPUT ST, V108, P70, DOI 10.1016/j.ijhcs.2017.05.005
   Dijkstra A, 2011, PSYCHOL HEALTH, V26, P1036, DOI 10.1080/08870446.2010.526715
   Eagly, 1993, PSYCHOL ATTITUDES, DOI [10.1002/mar.4220120509, DOI 10.1002/MAR.4220120509]
   Eshel G, 2006, EARTH INTERACT, V10, DOI 10.1175/EI167.1
   Fabiani P, 2010, MARKOV DECISION PROC
   Farchi S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182960
   Godinho CA, 2016, APPETITE, V96, P416, DOI 10.1016/j.appet.2015.10.001
   Graca J, 2015, APPETITE, V95, P113, DOI 10.1016/j.appet.2015.06.024
   Iacobucci D, 2010, J CONSUM PSYCHOL, V20, P90, DOI 10.1016/j.jcps.2009.09.003
   Kaelbling LP, 1998, ARTIF INTELL, V101, P99, DOI 10.1016/S0004-3702(98)00023-X
   Katt S., 2017, P 34 INT C MACH LEAR
   Kline RB, 1988, PRINCIPLES PRACTICE
   Kocsis L, 2006, ENERGY AND THE ENVIRONMENT 2006, VOL I, P287
   Laczniak R.N., 1993, PSYCHOL MARKET, V10, P301, DOI DOI 10.1002/MAR.4220100405
   Misra R, 2018, CURR DIABETES REP, V18, DOI 10.1007/s11892-018-1071-8
   Pearl J., 1988, PROBABILISTIC REASON
   Petty R.E., 2012, COMMUN PERSUATION
   Petty Richard E, 1986, ADV EXPT SOCIAL PSYC, V19, P123, DOI DOI 10.1016/S0065-2601(08)60214-2
   Rothman AJ, 2006, J COMMUN, V56, pS202, DOI 10.1111/j.1460-2466.2006.00290.x
   Samuelsen K.M., 2007, ADV LATENT VARIABLE
   Silver D., 2010, ADV NEURAL INFORM PR, V23, P2164, DOI 10.5555/2997046.2997137
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Stea S, 2019, ENVIRON COMMUN, V13, P633, DOI 10.1080/17524032.2017.1412994
   Stephenson MT, 2003, COMMUN RES, V30, P332, DOI 10.1177/0093650203030003004
   Vainio A, 2018, APPETITE, V125, P217, DOI 10.1016/j.appet.2018.02.002
   Weller KE, 2014, J NUTR EDUC BEHAV, V46, P324, DOI 10.1016/j.jneb.2014.01.002
   Wood W, 2000, ANNU REV PSYCHOL, V51, P539, DOI 10.1146/annurev.psych.51.1.539
   Zur I, 2014, BRIT FOOD J, V116, P629, DOI 10.1108/BFJ-08-2012-0193
NR 49
TC 13
Z9 13
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35949
EP 35971
DI 10.1007/s11042-020-09178-w
EA JUN 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000543678900001
DA 2022-08-02
ER

PT C
AU Ngo, TD
   Bui, TD
AF Thi Duyen Ngo
   The Duy Bui
BE Thi, BTD
   Drogoul, A
   Kuonen, P
   Tran, CD
   Tran, AC
   ThaiNghe, N
TI A Vietnamese 3D Taking Face for Embodied Conversational Agents
SO 2015 IEEE RIVF INTERNATIONAL CONFERENCE ON COMPUTING & COMMUNICATION
   TECHNOLOGIES - RESEARCH, INNOVATION, AND VISION FOR THE FUTURE (RIVF)
LA English
DT Proceedings Paper
CT IEEE RIVF International Conference on Computing & Communication
   Technologies Research, Innovation, and Vision for the Future (RIVF)
CY JAN 25-28, 2015
CL Can Tho, VIETNAM
SP CAN THO Univ, IEEE Vietnam Sect, IEEE
DE Conversational Agent; Vietnamese 3D Talking Face; Emotional Speech;
   Emotional Facial Expression
AB Conversational agents are receiving significant attention from multi-agent and human computer interaction research societies. Many techniques have been developed to enable these agents to behave in a human-like manner. In order to do so, they are simulated with similar communicative channels as humans. Moreover, they are also simulated with emotion and personality. In this work, we focus on issue of expressing emotions for embodied-agents. We present a three dimensional face with ability to speak emotional Vietnamese speech and naturally express emotions while talking. Our face can represent lip movements during emotionally pronouncing Vietnamese words, and at the same time it can show emotional facial expressions while speaking. The face's architecture consists of three parts: Vietnamese Emotional Speech Synthesis module, Emotions to Facial Expressions module, and Combination module which creates lip movements when pronouncing Vietnamese emotional speech and combines these movements with emotional facial expressions. We have tested the face in the football supporter domain in order to confirm its naturalness. The face is simulated as the face of a football supporter agent which experiences emotions and expresses emotional expressions in his voice as well as on his face.
C1 [Thi Duyen Ngo; The Duy Bui] Vietnam Natl Univ, Univ Engn & Technol, Hanoi, Vietnam.
RP Ngo, TD (corresponding author), Vietnam Natl Univ, Univ Engn & Technol, Hanoi, Vietnam.
EM duyennt@vnu.edu.vn; duybt@vnu.edu.vn
CR [Anonymous], 2001, LNCS
   [Anonymous], 2004, P 17 ANN C COMP AN S
   [Anonymous], 2007, TIENG VIET NGU VA PH
   [Anonymous], 2011, J INFORM COMMUNICATI
   [Anonymous], 2007, GIAO TRINH TIENG VIE
   [Anonymous], 2001, COMPUTER VISION IMAG
   Bui T, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P284
   Bui TD, 2002, LECT NOTES ARTIF INT, V2479, P129
   Bui TD, 2003, COMP ANIM CONF PROC, P33, DOI 10.1109/CASA.2003.1199301
   Collier G., 1985, EMOTIONAL EXPRESSION
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Damasio A.R., 1994, DESCARTES ERROR EMOT
   Ekman P., 1978, MODELS TECHNIQUES CO
   Ekman Paul, 1978, FACIAL ACTION CODING
   Galernter D. H., 1994, MUSE MACHINE
   ISBISTER K, 2002, P AAMAS 2002 WORKSH
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Ngo T. D., 2014, P 6 INT C KNOWL SYST, P129
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Pelachaud C, 2009, PHILOS T R SOC B, V364, P3539, DOI 10.1098/rstb.2009.0186
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Prasetyahadi M. C., 2013, INT J INTERACTIVE DI, V1
   Ngo TD, 2014, LECT NOTES ARTIF INT, V8861, P222, DOI 10.1007/978-3-319-13191-7_18
   THOMAS F., 1981, THE ILLUSION OF LIFE
   Wallhoff F., FACIAL EXPRESSIONS E
NR 26
TC 1
Z9 1
U1 0
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-4799-8044-4
PY 2015
BP 94
EP 99
PG 6
WC Computer Science, Theory & Methods; Engineering, Electrical &
   Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BF2MH
UT WOS:000380480100017
DA 2022-08-02
ER

PT C
AU Gosha, K
   Huff, EW
   Scott, J
AF Gosha, Kinnis
   Huff, Earl W., Jr.
   Scott, Jordan
GP Assoc Comp Machinery
TI Computing Career Exploration For Urban African American Students using
   Embodied Conversational Agents
SO SIGMIS-CPR'18: PROCEEDINGS OF THE 2018 ACM SIGMIS CONFERENCE ON
   COMPUTERS AND PEOPLE RESEARCH
LA English
DT Proceedings Paper
CT Annual ACM SIGMIS Conference on Computers and People Research (ACM
   SIGMIS-CPR)
CY JUN 18-20, 2018
CL NY
SP ACM SIGMIS, Assoc Comp Machinery
DE Computing Careers Now; computing career; embodied conversational agents;
   virtual computing career exploration fair
C1 [Gosha, Kinnis; Scott, Jordan] Morehouse Coll, Dept Comp Sci, Atlanta, GA 30314 USA.
   [Huff, Earl W., Jr.] Clemson Univ, Sch Comp, Clemson, SC USA.
RP Gosha, K (corresponding author), Morehouse Coll, Dept Comp Sci, Atlanta, GA 30314 USA.
EM kinnis.gosha@morehouse.edu; earlh@clemson.edu;
   jordan.scott@morehouse.edu
CR Lan F, 2012, CHARACTERISTICS RECE
NR 1
TC 2
Z9 2
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5768-5
PY 2018
BP 154
EP 154
DI 10.1145/3209626.3209731
PG 1
WC Computer Science, Information Systems; Health Care Sciences & Services;
   Medical Informatics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Health Care Sciences & Services; Medical Informatics
GA BM2KK
UT WOS:000461140200035
DA 2022-08-02
ER

PT C
AU Sugiyama, H
   Meguro, T
   Higashinaka, R
   Minami, Y
AF Sugiyama, Hiroaki
   Meguro, Toyomi
   Higashinaka, Ryuichiro
   Minami, Yasuhiro
BE Bickmore, T
   Marsella, S
   Sidner, C
TI Large-scale Collection and Analysis of Personal Question-Answer Pairs
   for Conversational Agents
SO INTELLIGENT VIRTUAL AGENTS, IVA 2014
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 14th International Conference on Intelligent Virtual Agents (IVA)
CY AUG 27-29, 2014
CL Boston, MA
DE system personality; conversational system; crowdsourcing
AB In conversation, a speaker sometimes asks questions that relate to another speaker's detailed personality, such as his/her favorite foods and sports. This behavior also appears in conversations with conversational agents; therefore, agents should be developed that can respond to such questions. In previous agents, this was achieved by creating question-answer pairs defined by hand. However, when a small number of persons create the pairs, we cannot know what types of questions are frequently asked. This makes it difficult to know whether the created questions cover frequently asked questions; therefore, such essential question-answer pairs for conversational agents are possibly overlooked. This study analyzes a large number of question-answer pairs for six personae created by many question-generators, with one answer-generator for each persona. The proposed approach allows many questioners to create questions for various personae, enabling us to investigate the types of questions that are frequently asked. A comparison with questions appearing in conversations between humans shows that 50.2% of the questions were contained in our question-answer pairs and the coverage rate was almost saturated with the 20 recruited question-generators.
C1 [Sugiyama, Hiroaki; Meguro, Toyomi; Minami, Yasuhiro] NTT Commun Sci Labs, Kyoto, Japan.
   [Higashinaka, Ryuichiro] NTT Media Intelligence Labs, Yokosuka, Kanagawa, Japan.
RP Sugiyama, H (corresponding author), NTT Commun Sci Labs, Kyoto, Japan.
EM sugiyama.hiroaki@lab.ntt.co.jp; meguro.toyomi@lab.ntt.co.jp;
   higashinaka.ryuichiro@lab.ntt.co.jp; minami.yasuhiro@lab.ntt.co.jp
CR [Anonymous], 2014, P COLING 2014 25 INT
   Batacharia B, 1999, SPRING INT SER ENG C, V511, P205
   Bickmore T., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P396
   Caspi A, 2005, ANNU REV PSYCHOL, V56, P453, DOI 10.1146/annurev.psych.55.090902.141913
   John O.P., 1999, HDB PERSONALITY, V2, P102
   Meguro T., 2010, INT C COMP LING, P761
   Nagata M., 2006, P ANN M ASS NAT LANG, pB2
   Nisimura R., 2003, P 1 INT WORKSH LANG, P70
   Ritter A., 2011, P C EMP METH NAT LAN, P583
   Rossen B, 2012, INT J HUM-COMPUT ST, V70, P301, DOI 10.1016/j.ijhcs.2011.11.004
   Sekine S., 2002, LREC
   Shibata M, 2009, INFORM-J COMPUT INFO, V33, P277
   Singh P, 2002, LECT NOTES COMPUT SC, V2519, P1223
   Sugiyama H., 2013, SIGDIAL 13, P334
   Tidwell LC, 2002, HUM COMMUN RES, V28, P317, DOI 10.1093/hcr/28.3.317
   Walker M., 2007, ANN M ASS COMP LING, V45, P496
   Wong W., 2012, P 24 INT C COMP LING, P2821
NR 17
TC 7
Z9 7
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-319-09767-1; 978-3-319-09766-4
J9 LECT NOTES ARTIF INT
PY 2014
VL 8637
BP 420
EP 433
PG 14
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS4CK
UT WOS:000717232400053
DA 2022-08-02
ER

PT J
AU Ali, G
   Lee, M
   Hwang, JI
AF Ali, Ghazanfar
   Lee, Myungho
   Hwang, Jae-In
TI Automatic text-to-gesture rule generation for embodied conversational
   agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; gesture generation; rule-based mapping; social
   agents; virtual agents
AB Interactions with embodied conversational agents can be enhanced using human-like co-speech gestures. Traditionally, rule-based co-speech gesture mapping has been utilized for this purpose. However, the creation of this mapping is laborious and often requires human experts. Moreover, human-created mapping tends to be limited, therefore prone to generate repeated gestures. In this article, we present an approach to automate the generation of rule-based co-speech gesture mapping from publicly available large video data set without the intervention of human experts. At run-time, word embedding is utilized for rule searching to get the semantic-aware, meaningful, and accurate rule. The evaluation indicated that our method achieved comparable performance with the manual map generated by human experts, with a more variety of gestures activated. Moreover, synergy effects were observed in users' perception of generated co-speech gestures when combined with the manual map.
C1 [Ali, Ghazanfar] Univ Sci & Technol, Div NT IT, Daejeon, South Korea.
   [Lee, Myungho; Hwang, Jae-In] Korea Inst Sci & Technol, Imaging Media Res Ctr, Seoul, South Korea.
RP Hwang, JI (corresponding author), Korea Inst Sci & Technol, Imaging Media Res Ctr, Seoul, South Korea.
EM hji@kist.re.kr
OI Ali, Ghazanfar/0000-0002-7741-1938
FU Korea Creative Content Agency (KOCCA) in the Culture Technology (CT)
   Research and Development Program; KIST Flagship Project
FX This research is supported by the Korea Creative Content Agency (KOCCA)
   in the Culture Technology (CT) Research and Development Program and KIST
   Flagship Project.
CR Ali G, 2019, P 32 INT C COMP AN S
   Anabuki M, 2000, P C HUM FACT COMP SY
   [Anonymous], 2014, EMNLP
   Arroyo-Palacios J, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P121, DOI 10.1109/ISMAR-Adjunct.2017.45
   Avramova V, 2017, LECT NOTES COMPUTER
   Bogdanovych A, 2015, LECT NOTES ARTIF INT, V8955, P142, DOI 10.1007/978-3-319-14803-8_11
   Cao Zhe, 2017, P IEEE C COMP VIS PA
   Cassell J, 2001, P 28 ANN C COMP GRAP
   Castano R, 2014, COMMUN COMPUT PHYS, V498, P34
   De Coninck F, 2019, P 2019 IEEE INT C AR
   Ferstl Y, 2019, P MIG 2019 ACM C MOT, P1
   Ginosar S, 2019, P IEEE C COMP VIS PA
   Heylen D, 2008, LECT NOTES COMPUT SC, V5208, P270
   Kipp M, 2001, P EUROSPEECH 2001 SC
   Knapp M. L., 2013, NONVERBAL COMMUNICAT
   Kopp S., 2003, KI, V17, P11
   Kucherenko T, 2019, P 19 ACM INT C INT V
   Lee Jina, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P161, DOI 10.1007/978-3-642-33197-8_17
   Lee J, 2006, LECT NOTES ARTIF INT, V4133, P243
   Levine S, 2010, P ACM SIGGRAPH 2010
   Machidon OM, 2018, J CULT HERIT, V33, P249, DOI 10.1016/j.culher.2018.01.007
   Neff M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330516
   Richards D., 2012, P 8 AUSTR C INT ENT, P1
   STUDDERTKENNEDY M, 1994, LANG SPEECH, V37, P203, DOI 10.1177/002383099403700208
   Vosinakis S, 2018, LECT NOTES COMPUT SC, V10754, P197, DOI 10.1007/978-3-319-75789-6_14
   Yoon Youngwoo, 2019, P INT C ROB AUT ICRA
NR 26
TC 4
Z9 4
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1944
DI 10.1002/cav.1944
EA SEP 2020
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000566926000001
DA 2022-08-02
ER

PT C
AU Tegos, S
   Psathas, G
   Tsiatsos, T
   Katsanos, C
   Karakostas, A
   Tsibanis, C
   Demetriadis, S
AF Tegos, Stergios
   Psathas, Georgios
   Tsiatsos, Thrasyvoulos
   Katsanos, Christos
   Karakostas, Anastasios
   Tsibanis, Costas
   Demetriadis, Stavros
BE Kumar, V
   Troussas, C
TI Enriching Synchronous Collaboration in Online Courses with Configurable
   Conversational Agents
SO INTELLIGENT TUTORING SYSTEMS (ITS 2020)
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 16th International Conference on Intelligent Tutoring Systems (ITS)
CY JUN 08-12, 2020
CL Univ W Attica, ELECTR NETWORK
SP Inst Intelligent Syst
HO Univ W Attica
DE Conversational agent; Online education; Peer dialogue; MOOC
AB This work presents a novel approach for employing conversational agent technology in the context of Massive Open Online Courses (MOOCs), aiming to support learners that work in groups to sustain productive forms of peer dialogue. An exploratory study is presented featuring 56 undergraduate computer science students, who interacted with a conversational agent in the context of an online course. The study investigates the practicability of using configurable conversational agents to provide collaborative learning support and serves as an opportunity to compare two intervention strategies: (a) converging agent interventions, presented in the form of tips relating closely to the topic of the activity and (b) diverging agent interventions, which do not relate directly to the activity topic and pose new domain-relevant questions. The study findings suggest that a convergent agent is often perceived as more helpful by the students. A discourse analysis also reveals a series of interesting interaction patterns, facilitating improvements in the design of future conversational agent systems.
C1 [Tegos, Stergios; Psathas, Georgios; Tsiatsos, Thrasyvoulos; Katsanos, Christos; Demetriadis, Stavros] Aristotle Univ Thessaloniki, Thessaloniki, Greece.
   [Karakostas, Anastasios] CERTH, Thessaloniki, Greece.
   [Tsibanis, Costas] GUnet, Athens, Greece.
RP Tegos, S (corresponding author), Aristotle Univ Thessaloniki, Thessaloniki, Greece.
EM stegos@csd.auth.gr; gpsathas@csd.auth.gr; tsiatsos@csd.auth.gr;
   ckatsanos@csd.auth.gr; akarakos@iti.gr; ktsibanis@uoa.gr;
   sdemetri@csd.auth.gr
OI Karakostas, Anastasios/0000-0002-8508-3903
FU Erasmus+ Programme of the European Commission
   [588438-EPP-1-2017-1-EL-EPPKA-KA]
FX This research has been funded by the Erasmus+ Programme of the European
   Commission (project No 588438-EPP-1-2017-1-EL-EPPKA-KA) and reflects
   only the views of the authors. The Education, Audiovisual and Culture
   Executive Agency and the European Commission cannot be held responsible
   for any use of the information presented.
CR Conole G, 2013, RED-REV EDUC DISTANC
   Feng WZ, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P517
   Fryer LK, 2017, COMPUT HUM BEHAV, V75, P461, DOI 10.1016/j.chb.2017.05.045
   Graesser AC, 2017, INFORMATIONAL ENV EF, P273
   Hone KS, 2016, COMPUT EDUC, V98, P157, DOI 10.1016/j.compedu.2016.03.016
   Rose CP, 2016, INT J ARTIF INTELL E, V26, P660, DOI 10.1007/s40593-016-0107-y
   Shin Y, 2020, J EDUC COMPUT RES, V58, P640, DOI 10.1177/0735633119877134
   Tegos Stergios, 2020, Chatbot Research and Design. Third International Workshop, CONVERSATIONS 2019. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 11970), P245, DOI 10.1007/978-3-030-39540-7_17
   Tegos S, 2017, EDUC TECHNOL SOC, V20, P99
NR 9
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-49663-0; 978-3-030-49662-3
J9 LECT NOTES COMPUT SC
PY 2020
VL 12149
BP 284
EP 294
DI 10.1007/978-3-030-49663-0_34
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications; Computer
   Science, Theory & Methods; Education & Educational Research
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Education & Educational Research
GA BS4LE
UT WOS:000720068400034
DA 2022-08-02
ER

PT J
AU Derrick, DC
   Ligon, GS
AF Derrick, Douglas C.
   Ligon, Gina Scott
TI The affective outcomes of using influence tactics in embodied
   conversational agents
SO COMPUTERS IN HUMAN BEHAVIOR
LA English
DT Article
DE Embodied agents; Influence; Impression management; Gender differences
ID IMPRESSION MANAGEMENT; SELF-PROMOTION; COMPUTERS; GENDER; RESPONSES;
   REAL; MINDLESSNESS; POLITENESS; IMPACT; FACES
AB In this study, we highlight the theoretical underpinnings of human impression management tactics and link them to current research in embodied conversational agents. Specifically, we incorporated impression management behaviors into an embodied conversational agent in order to show that different influence strategies affect user perceptions, and how those perceptions might be moderated by user gender. We programmed the agent to use two human impression management techniques (ingratiation and self-promotion) and had the agent interact with 88 users. After the interaction, users reported their perceptions of the system's power, trustworthiness, expertise, and attractiveness. The impression management techniques altered users' perceptions and these perceptions were moderated by gender differences. (C) 2014 Elsevier Ltd. All rights reserved.
C1 [Derrick, Douglas C.; Ligon, Gina Scott] Univ Nebraska Omaha, Omaha, NE 68182 USA.
RP Derrick, DC (corresponding author), Univ Nebraska Omaha, Peter Kiewit Inst, Suite 280C,1110 S 67th St, Omaha, NE 68182 USA.
EM dcderrick@unomaha.edu
CR [Anonymous], 1995, C COMP HUM FACT COMP
   ARKIN RM, 1989, IMPRESSION MANAGEMEN, P125
   Bartneck C, 2005, INT J HUM-COMPUT ST, V62, P179, DOI 10.1016/j.ijhcs.2004.11.006
   Beale R, 2009, INT J HUM-COMPUT ST, V67, P755, DOI 10.1016/j.ijhcs.2009.05.001
   Bente G, 2008, HUM COMMUN RES, V34, P287, DOI 10.1111/j.1468-2958.2008.00322.x
   Burgoon J., 2011, IEEE INTELL SYST APP, P84
   Cassell J., 2000, EMBODIED CONVERSATIO
   Clayes EL, 2007, INT J HUM-COMPUT ST, V65, P480, DOI 10.1016/j.ijhcs.2006.10.005
   Cowell AJ, 2005, INT J HUM-COMPUT ST, V62, P281, DOI 10.1016/j.ijhcs.2004.11.008
   Derrick DC, 2011, SPECIAL PURPOSE EMBO
   Derrick DC, 2011, AIS T HUMAN COMPUTER, V3, P62, DOI DOI 10.17705/1THCI.00027
   DUBRIN AJ, 1994, PSYCHOL REP, V74, P531, DOI 10.2466/pr0.1994.74.2.531
   Eagly A. H, 1987, SEX DIFFERENCES SOCI
   Elkins A. C, 2013, GROUP DECISIONS NEGO, P1
   Fogg BJ, 1997, INT J HUM-COMPUT ST, V46, P551, DOI 10.1006/ijhc.1996.0104
   GARDNER WL, 1988, ACAD MANAGE J, V31, P42, DOI 10.2307/256497
   GODFREY DK, 1986, J PERS SOC PSYCHOL, V50, P106, DOI 10.1037/0022-3514.50.1.106
   Gordon RA, 1996, J PERS SOC PSYCHOL, V71, P54, DOI 10.1037/0022-3514.71.1.54
   Green RD, 2008, COMPUT HUM BEHAV, V24, P2456, DOI 10.1016/j.chb.2008.02.019
   Groom V, 2009, INT J HUM-COMPUT ST, V67, P842, DOI 10.1016/j.ijhcs.2009.07.001
   Guadagno RE, 2007, SEX ROLES, V56, P483, DOI 10.1007/s11199-007-9187-3
   Hall B, 2008, COMPUT HUM BEHAV, V24, P2965, DOI 10.1016/j.chb.2008.05.003
   Harris KJ, 2007, J APPL PSYCHOL, V92, P278, DOI 10.1037/0021-9010.92.1.278
   Heatherington L, 1998, SEX ROLES, V38, P889, DOI 10.1023/A:1018866307680
   Higgins CA, 2003, J ORGAN BEHAV, V24, P89, DOI 10.1002/job.181
   Jones, 1964, INGRATIATION
   Jones E.E., 1982, PSYCHOL PERSPECTIVES, V1, P231, DOI DOI 10.1037/0022-0167.32.4.483
   Kacmar K., 2009, J MANAGERIAL ISSUES, V21, P498
   Kacmar KM, 2004, J VOCAT BEHAV, V65, P309, DOI 10.1016/j.jvb.2003.09.002
   Kramer NC, 2010, EDUC PSYCHOL REV, V22, P71, DOI 10.1007/s10648-010-9123-x
   LANGER EJ, 1992, CONSCIOUS COGN, V1, P289, DOI 10.1016/1053-8100(92)90066-J
   Lee EJ, 2008, INT J HUM-COMPUT ST, V66, P789, DOI 10.1016/j.ijhcs.2008.07.009
   Lubart TI, 2000, CREATIVITY RES J, V13, P295
   MacDorman KF, 2009, COMPUT HUM BEHAV, V25, P695, DOI 10.1016/j.chb.2008.12.026
   Mayer RE, 2006, INT J HUM-COMPUT ST, V64, P36, DOI 10.1016/j.ijhcs.2005.07.001
   Moon Y, 1998, INT J HUM-COMPUT ST, V49, P79, DOI 10.1006/ijhc.1998.0199
   Moon Y, 1996, COMMUN RES, V23, P651, DOI 10.1177/009365096023006002
   Mumford M. D., 2006, PATHWAYS OUTSTANDING
   Mumford MD, 2000, CREATIVITY RES J, V13, P267
   NASS C, 1993, HUM COMMUN RES, V19, P504, DOI 10.1111/j.1468-2958.1993.tb00311.x
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nass C. I., 1997, Human values and the design of computer technology, P137
   Niewiadomski R, 2010, INT J HUM-COMPUT ST, V68, P851, DOI 10.1016/j.ijhcs.2010.07.004
   Noot H, 2005, INT J HUM-COMPUT ST, V62, P211, DOI 10.1016/j.ijhcs.2004.11.007
   Nunamaker JE, 2011, J MANAGE INFORM SYST, V28, P17, DOI 10.2753/MIS0742-1222280102
   OHANIAN R, 1990, J ADVERTISING, V19, P39, DOI 10.1080/00913367.1990.10673191
   Prendinger H, 2005, INT J HUM-COMPUT ST, V62, P231, DOI 10.1016/j.ijhcs.2004.11.009
   Qiu LY, 2010, INT J HUM-COMPUT ST, V68, P669, DOI 10.1016/j.ijhcs.2010.05.005
   Reysen S, 2005, SOC BEHAV PERSONAL, V33, P201, DOI 10.2224/sbp.2005.33.2.201
   Rosenberg-Kima RB, 2008, COMPUT HUM BEHAV, V24, P2741, DOI 10.1016/j.chb.2008.03.017
   Rudman LA, 1998, J PERS SOC PSYCHOL, V74, P629, DOI 10.1037/0022-3514.74.3.629
   Schlenker B. R., 1980, IMPRESSION MANAGEMEN
   SCHLENKER BR, 1992, ANNU REV PSYCHOL, V43, P133, DOI 10.1146/annurev.ps.43.020192.001025
   Singh V, 2002, J BUS ETHICS, V37, P77, DOI 10.1023/A:1014782118902
   STEVENS CK, 1995, J APPL PSYCHOL, V80, P587, DOI 10.1037/0021-9010.80.5.587
   TETLOCK PE, 1985, PSYCHOL REV, V92, P59, DOI 10.1037/0033-295X.92.1.59
   Vugt HCV, 2008, ACM T COMPUT-HUM INT, V17, P1
   Wang N, 2008, INT J HUM-COMPUT ST, V66, P98, DOI 10.1016/j.ijhcs.2007.09.003
   WOOLDRIDGE M, 1995, KNOWL ENG REV, V10, P115, DOI 10.1017/S0269888900008122
   Yukl G. A., 2006, LEADERSHIP ORG
   Zeng F., 2004, P 2004 AM SOC ENG AN
NR 62
TC 12
Z9 12
U1 2
U2 26
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0747-5632
EI 1873-7692
J9 COMPUT HUM BEHAV
JI Comput. Hum. Behav.
PD APR
PY 2014
VL 33
BP 39
EP 48
DI 10.1016/j.chb.2013.12.027
PG 10
WC Psychology, Multidisciplinary; Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA AE4IN
UT WOS:000333946200006
DA 2022-08-02
ER

PT J
AU Balaji, D
   He, LW
   Giani, S
   Bosse, T
   Wiers, R
   de Bruijn, GJ
AF Balaji, Divyaa
   He, Linwei
   Giani, Stefano
   Bosse, Tibor
   Wiers, Reinout
   de Bruijn, Gert-Jan
TI Effectiveness and acceptability of conversational agents for sexual
   health promotion: a systematic review and meta-analysis
SO SEXUAL HEALTH
LA English
DT Review; Early Access
DE chatbot; conversational agent; digital health intervention; HIV;
   meta-analysis; mHealth; review; sexual health
ID TECHNOLOGY ACCEPTANCE MODEL; RANDOMIZED CONTROLLED-TRIAL; ADHERENCE
   BUILDING ITAB; MEDICATION ADHERENCE; BEHAVIOR-CHANGE; PREVENTION
   INTERVENTION; UNDERSTANDING BARRIERS; MEDIA INTERVENTIONS; SOCIAL MEDIA;
   HIV
AB Digital health interventions for sexual health promotion have evolved considerably alongside innovations in technology. Despite these efforts, studies have shown that they do not consistently result in the desired sexual health outcomes. This could be attributed to low levels of user engagement, which can hinder digital health intervention effectiveness, as users do not engage with the system enough to be exposed to the intervention components. It has been suggested that conversational agents (automated two-way communication systems e.g. Alexa) have the potential to overcome the limitations of prior systems and promote user engagement through the increased interactivity offered by bidirectional, natural language-based interactions. The present review, therefore, provides an overview of the effectiveness and user acceptability of conversational agents for sexual health promotion. A systematic search of seven databases provided 4534 records, and after screening, 31 articles were included in this review. A narrative synthesis of results was conducted for effectiveness and acceptability outcomes, with the former supplemented by a meta-analysis conducted on a subset of studies. Findings provide preliminary support for the effectiveness of conversational agents for promoting sexual health, particularly treatment adherence. These conversational agents were found to be easy to use and useful, and importantly, resulted in high levels of satisfaction, use and intentions to reuse, whereas user evaluations regarding the quality of information left room for improvement. The results can inform subsequent efforts to design and evaluate these interventions, and offer insight into additional user experience constructs identified outside of current technology acceptance models, which can be incorporated into future theoretical developments.
C1 [Balaji, Divyaa] Univ Amsterdam, Amsterdam Sch Commun Res, Amsterdam, Netherlands.
   [He, Linwei] Tilburg Univ, Dept Commun & Cognit, Tilburg, Netherlands.
   [Giani, Stefano] Univ Amsterdam, Univ Lib, Amsterdam, Netherlands.
   [Bosse, Tibor] Radboud Univ Nijmegen, Behav Sci Inst, Nijmegen, Netherlands.
   [Wiers, Reinout] Univ Amsterdam, Dept Psychol, Amsterdam, Netherlands.
   [de Bruijn, Gert-Jan] Univ Antwerp, Dept Commun Sci, Antwerp, Belgium.
RP Balaji, D (corresponding author), Univ Amsterdam, Amsterdam Sch Commun Res, Amsterdam, Netherlands.
EM d.balaji@uva.nl
CR Adam M, 2021, ELECTRON MARK, V31, P427, DOI 10.1007/s12525-020-00414-7
   Amith Muhammad, 2020, AMIA Jt Summits Transl Sci Proc, V2020, P43
   Amith Muhammad, 2019, Stud Health Technol Inform, V257, P17
   Amith M, 2020, NATURAL LANGUAGE PROCESSING FOR MEDICAL CONVERSATIONS, P31, DOI 10.18653/v1/2020.nlpmc-1.5
   Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Baclic Oliver, 2020, Can Commun Dis Rep, V46, P161, DOI 10.14745/ccdr.v46i06a02
   BAEK HYUNJI, 2019, [Jourmal of the HCI Society of Korea, 한국HCI학회 논문지], V14, P35, DOI 10.17210/jhsk.2019.02.14.1.35
   Bailey J., 2015, PUBLIC HLTH RES, V3, P1, DOI [10.3310/phr03130, DOI 10.3310/PHR03130]
   Bazzi AR, 2019, BMC PUBLIC HEALTH, V19, DOI 10.1186/s12889-018-6314-8
   Becasen JS, 2015, J SEX RES, V52, P433, DOI 10.1080/00224499.2014.947399
   Bender SS, 2013, EUR J CONTRACEP REPR, V18, P159, DOI 10.3109/13625187.2013.776672
   Benjumea J, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/17134
   Berendes S, 2021, SEX TRANSM INFECT, V97, P190, DOI 10.1136/sextrans-2020-054853
   Berube C, 2021, J MED INTERNET RES, V23, DOI 10.2196/25933
   Bickmore T, 2010, APPL ARTIF INTELL, V24, P648, DOI 10.1080/08839514.2010.492259
   Bonnevie E, 2021, HEALTH EDUC J, V80, P413, DOI 10.1177/0017896920981122
   Borenstein M, 2021, INTRO META ANAL, DOI 10.1002/9781119558378
   Brouwer W, 2011, J MED INTERNET RES, V13, P23, DOI 10.2196/jmir.1639
   Burns K, 2016, BMC PUBLIC HEALTH, V16, DOI 10.1186/s12889-016-3408-z
   Cao BL, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7997
   Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158
   Catalani Caricia, 2013, Open AIDS J, V7, P17, DOI 10.2174/1874613620130812003
   Chavez K, 2020, ALCOHOL TREAT Q, V38, P87, DOI 10.1080/07347324.2019.1653240
   Chernick LS, 2021, J ADOLESCENT HEALTH, V68, P705, DOI 10.1016/j.jadohealth.2020.07.020
   Chiang N, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/mhealth.9187
   Christopoulos KA, 2018, CLIN INFECT DIS, V67, P751, DOI 10.1093/cid/ciy156
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Cole-Lewis Heather, 2019, JMIR Form Res, V3, pe14052, DOI 10.2196/14052
   Croes Emmelyn A. J., 2021, Chatbot Research and Design. 4th International Workshop, CONVERSATIONS 2020. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12604), P81, DOI 10.1007/978-3-030-68288-0_6
   Croes EAJ, 2021, J SOC PERS RELAT, V38, P279, DOI 10.1177/0265407520959463
   Crutzen R, 2011, J ADOLESCENT HEALTH, V48, P514, DOI 10.1016/j.jadohealth.2010.09.002
   Davis Teaniese, 2020, JMIR Form Res, V4, pe22485, DOI 10.2196/22485
   de Cosmo LM., 2021, ITAL J MARK, V2021, P83, DOI [10.1007/s43039-021-00020-1, DOI 10.1007/S43039-021-00020-1]
   de Gennaro M, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.03061
   DeLone WH, 2003, J MANAGE INFORM SYST, V19, P9, DOI 10.1080/07421222.2003.11045748
   DeSmet A, 2015, GAMES HEALTH J, V4, P78, DOI 10.1089/g4h.2014.0110
   Diederich S, 2019, P 27 EUR C INF SYST
   Dowshen N, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.2015
   Duval S, 2000, J AM STAT ASSOC, V95, P89, DOI 10.2307/2669529
   Dworkin M, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/10211
   Dworkin MS, 2019, AIDS EDUC PREV, V31, P17, DOI 10.1521/aeap.2019.31.1.17
   Edelman NL, 2013, J FAM PLAN REPROD H, V39, P258, DOI 10.1136/jfprhc-2012-100507
   Egger M, 1997, BMJ-BRIT MED J, V315, P629, DOI 10.1136/bmj.315.7109.629
   Fuchs JD, 2018, AIDS PATIENT CARE ST, V32, P104, DOI 10.1089/apc.2017.0255
   Gabarron E, 2016, GLOBAL HEALTH ACTION, V9, DOI 10.3402/gha.v9.32193
   Gaffney H, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/14166
   Garofalo R, 2016, AIDS BEHAV, V20, P1049, DOI 10.1007/s10461-015-1192-x
   Geense WW, 2013, BMC FAM PRACT, V14, DOI 10.1186/1471-2296-14-20
   Go E, 2019, COMPUT HUM BEHAV, V97, P304, DOI 10.1016/j.chb.2019.01.020
   GRICE HP, 1975, SYNTAX SEMANTICS, V3, DOI DOI 10.1111/J.1365-2664.2006.01229.X
   Guse K, 2012, J ADOLESCENT HEALTH, V51, P535, DOI 10.1016/j.jadohealth.2012.03.014
   Harb CYW, 2019, TRANSGENDER HEALTH, V4, P58, DOI 10.1089/trgh.2018.0022
   Hardy H, 2011, AIDS PATIENT CARE ST, V25, P153, DOI 10.1089/apc.2010.0006
   Harris LT, 2010, TELEMED J E-HEALTH, V16, P1024, DOI 10.1089/tmj.2010.0050
   Hernandez JPT, 2019, J MED INVESTIG, V66, P24, DOI 10.2152/jmi.66.24
   Higgins JPT, 2003, BRIT MED J, V327, P557, DOI 10.1136/bmj.327.7414.557
   Hookham G, 2019, PROCEEDINGS OF THE AUSTRALASIAN COMPUTER SCIENCE WEEK MULTICONFERENCE (ACSW 2019), DOI 10.1145/3290688.3290747
   Huang JH, 2007, ELECTRON LIBR, V25, P585, DOI 10.1108/02640470710829569
   Hussain Syed Ali, 2019, Digital Human Modeling and Applications in Health, Safety, Ergonomics and Risk Management. Healthcare Applications. 10th International Conference, DHM 2019 Held as Part of the 21st HCI International Conference, HCII 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11582), P342, DOI 10.1007/978-3-030-22219-2_26
   Ingersoll KS, 2015, HEALTH PSYCHOL, V34, P1305, DOI 10.1037/hea0000295
   Jack BW, 2020, LANCET DIGIT HEALTH, V2, pE475, DOI 10.1016/S2589-7500(20)30189-8
   Jain M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P895, DOI 10.1145/3196709.3196735
   Kasilingam DL, 2020, TECHNOL SOC, V62, DOI 10.1016/j.techsoc.2020.101280
   Kelly S, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0145074
   King E, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6631
   Kocaballi AB, 2019, J MED INTERNET RES, V21, DOI 10.2196/15360
   Kurtz SP, 2005, J HEALTH CARE POOR U, V16, P345, DOI 10.1353/hpu.2005.0038
   L'Engle KL, 2016, PEDIATRICS, V138, DOI 10.1542/peds.2016-0884
   Laumer S, 2019, P 27 EUR C INF SYST
   Lim MSC, 2008, INT J STD AIDS, V19, P287, DOI 10.1258/ijsa.2007.007264
   Liu AY, 2019, CLIN INFECT DIS, V68, P2010, DOI 10.1093/cid/ciy810
   Liu BJ, 2018, CYBERPSYCH BEH SOC N, V21, P625, DOI 10.1089/cyber.2018.0110
   Ma PHX, 2017, AIDS BEHAV, V21, P2412, DOI 10.1007/s10461-017-1818-2
   MacAfee LK, 2020, SUBST USE MISUSE, V55, P95, DOI 10.1080/10826084.2019.1656255
   Marlow LAV, 2015, J FAM PLAN REPROD H, V41, P248, DOI 10.1136/jfprhc-2014-101082
   McGill T., 2003, Information Resources Management Journal, V16, P24, DOI 10.4018/irmj.2003010103
   Mendu S, 2018, INT CONF PER COMP, P360, DOI 10.1145/3240925.3240968
   Moore DJ, 2018, DRUG ALCOHOL DEPEN, V189, P154, DOI 10.1016/j.drugalcdep.2018.05.013
   Moore DJ, 2018, CLIN INFECT DIS, V66, P1566, DOI 10.1093/cid/cix1055
   Moore DJ, 2015, AIDS BEHAV, V19, P459, DOI 10.1007/s10461-014-0971-0
   Muessig KE, 2015, CURR HIV-AIDS REP, V12, P173, DOI 10.1007/s11904-014-0239-3
   Muessig KE, 2013, J MED INTERNET RES, V15, P19, DOI 10.2196/jmir.2301
   Murray E, 2016, AM J PREV MED, V51, P843, DOI 10.1016/j.amepre.2016.06.008
   Naar-King S, 2013, J PEDIATR PSYCHOL, V38, P638, DOI 10.1093/jpepsy/jss132
   Nadarzynski T, 2021, SEX HEALTH, V18, P385, DOI 10.1071/SH21123
   Ojo AI, 2017, HEALTHC INFORM RES, V23, P60, DOI 10.4258/hir.2017.23.1.60
   Park H, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445133
   Pereira J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1237-1
   Perski O, 2017, TRANSL BEHAV MED, V7, DOI 10.1007/s13142-016-0453-1
   Petter S, 2009, INFORM MANAGE-AMSTER, V46, P159, DOI 10.1016/j.im.2008.12.006
   Pfeifer Vardoulakis Laura, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P289, DOI 10.1007/978-3-642-33197-8_30
   Pot M, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7449
   Price WN, 2019, NAT MED, V25, P37, DOI 10.1038/s41591-018-0272-7
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Rapp A, 2021, INT J HUM-COMPUT ST, V151, DOI 10.1016/j.ijhcs.2021.102630
   Rodrigues R, 2015, BMJ OPEN, V5, DOI 10.1136/bmjopen-2015-007574
   Rodrigues R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040723
   Salvadori N, 2020, J INT AIDS SOC, V23, DOI 10.1002/jia2.25478
   Sax M., 2021, EMPOWERMENT MANIPULA
   Sciuto A, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P857, DOI 10.1145/3196709.3196772
   Skjuve M, 2018, CHATBOTS NEW USER IN
   Statista, 2021, INT US WORLD
   Swanton R, 2015, SEX TRANSM INFECT, V91, P14, DOI 10.1136/sextrans-2014-051743
   Swendeman Dallas, 2020, Mhealth, V6, P35, DOI 10.21037/mhealth-19-248a
   Taylor D, 2019, SYST REV-LONDON, V8, DOI 10.1186/s13643-018-0921-4
   Tsai WHS, 2021, J RES INTERACT MARK, V15, P460, DOI 10.1108/JRIM-12-2019-0200
   Turner M, 2010, INFORM SOFTWARE TECH, V52, P463, DOI 10.1016/j.infsof.2009.11.005
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   van der Goot MJ, 2020, LECT NOTES COMP SCI, P173, DOI [10.1007/978-3-030-39540-7_12, DOI 10.1007/978-3-030-39540-7_12]
   van Heerden Alastair, 2017, 2017 International Conference on the Frontiers and Advances in Data Science (FADS). Proceedings, P80, DOI 10.1109/FADS.2017.8253198
   van Velthoven MHMMT, 2013, PSYCHOL HEALTH MED, V18, P182, DOI 10.1080/13548506.2012.701310
   van Wezel MMC, LECT NOTES COMP SCI, V2021, P96, DOI [10.1007/978-3-030-68288-0_7, DOI 10.1007/978-3-030-68288-0_7]
   Venkatesh V, 2000, MANAGE SCI, V46, P186, DOI 10.1287/mnsc.46.2.186.11926
   Wadham E, 2019, SEX HEALTH, V16, P101, DOI 10.1071/SH18127
   Wald DS, 2015, AM J MED, V128, DOI 10.1016/j.amjmed.2015.05.035
   Wang XH, 2017, CYBERPSYCH BEH SOC N, V20, P662, DOI 10.1089/cyber.2017.0086
   Webb TL, 2010, J MED INTERNET RES, V12, DOI 10.2196/jmir.1376
   Wells Kristen J, 2015, Hisp Health Care Int, V13, P179, DOI 10.1891/1540-4153.13.4.179
   Yardley L, 2016, AM J PREV MED, V51, P833, DOI 10.1016/j.amepre.2016.06.015
   Zamora J, 2017, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON HUMAN AGENT INTERACTION (HAI'17), P253, DOI 10.1145/3125739.3125766
   Zaneva M, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0261034
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
NR 122
TC 0
Z9 0
U1 0
U2 0
PU CSIRO PUBLISHING
PI CLAYTON
PA UNIPARK, BLDG 1, LEVEL 1, 195 WELLINGTON RD, LOCKED BAG 10, CLAYTON, VIC
   3168, AUSTRALIA
SN 1448-5028
EI 1449-8987
J9 SEX HEALTH
JI Sex Health
DI 10.1071/SH22016
EA JUL 2022
PG 15
WC Public, Environmental & Occupational Health; Infectious Diseases
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Public, Environmental & Occupational Health; Infectious Diseases
GA 3C5WV
UT WOS:000828694800001
PM 35863761
DA 2022-08-02
ER

PT J
AU McGreevey, JD
   Hanson, CW
   Koppel, R
AF McGreevey, John D., III
   Hanson, C. William, III
   Koppel, Ross
TI Clinical, Legal, and Ethical Aspects of Artificial Intelligence-Assisted
   Conversational Agents in Health Care
SO JAMA-JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION
LA English
DT Editorial Material
AB This Viewpoint discusses evidence supporting use of conversational agents in health care-artificial intelligence (AI) programs that interpret users' questions or concerns and respond with answers-and proposes 12 domains (eg, safety, transparency, security) that clinicians and health care organizations should evaluate before using them for patient care.
C1 [McGreevey, John D., III] Univ Penn, Perelman Sch Med, Sect Hosp Med, Div Gen Internal Med,Inst Biomed Informat,Univ Pe, Philadelphia, PA 19104 USA.
   [Hanson, C. William, III; Koppel, Ross] Univ Penn, Perelman Sch Med, Univ Penn Hlth Syst, Philadelphia, PA 19104 USA.
   [Hanson, C. William, III] Univ Penn, Sch Engn & Appl Sci, Philadelphia, PA 19104 USA.
   [Koppel, Ross] SUNY Buffalo, Dept Med Informat, Jacobs Sch Med, Buffalo, NY USA.
RP McGreevey, JD (corresponding author), Univ Penn Hlth Syst, 3400 Spruce St, Philadelphia, PA 19104 USA.
EM john.mcgreevey@pennmedicine.upenn.edu
RI McGreevey, John/AAC-2844-2022
CR Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   Miner AS, 2016, JAMA INTERN MED, V176, P619, DOI 10.1001/jamainternmed.2016.0400
   Piau A, 2019, INT J MED INFORM, V128, P18, DOI 10.1016/j.ijmedinf.2019.05.013
   Referral MD, 11 HEALTHC CHATB CAN
   US Food and Drug Administration, PROP REG FRAM MOD AR
   Whicher, 2019, AI HLTH CARE HOPE HY
NR 8
TC 18
Z9 18
U1 0
U2 12
PU AMER MEDICAL ASSOC
PI CHICAGO
PA 330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA
SN 0098-7484
EI 1538-3598
J9 JAMA-J AM MED ASSOC
JI JAMA-J. Am. Med. Assoc.
PD AUG 11
PY 2020
VL 324
IS 6
BP 552
EP 553
DI 10.1001/jama.2020.2724
PG 2
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC General & Internal Medicine
GA NE8HM
UT WOS:000562845100014
PM 32706386
DA 2022-08-02
ER

PT J
AU Feine, J
   Gnewuch, U
   Morana, S
   Maedche, A
AF Feine, Jasper
   Gnewuch, Ulrich
   Morana, Stefan
   Maedche, Alexander
TI A Taxonomy of Social Cues for Conversational Agents
SO INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES
LA English
DT Article
DE Conversational agent; Chatbot; Social cue; Computers are social actors;
   Taxonomy; Classification; Literature review
ID COMPUTER-MEDIATED COMMUNICATION; VIRTUAL AGENTS; USER FRUSTRATION;
   SELF-DISCLOSURE; PERSONALITY; RESPONSES; GENDER; EMBODIMENT; EMOTION;
   TRUST
AB Conversational agents (CAs) are software-based systems designed to interact with humans using natural language and have attracted considerable research interest in recent years. Following the Computers Are Social Actors paradigm, many studies have shown that humans react socially to CAs when they display social cues such as small talk, gender, age, gestures, or facial expressions. However, research on social cues for CAs is scattered across different fields, often using their specific terminology, which makes it challenging to identify, classify, and accumulate existing knowledge. To address this problem, we conducted a systematic literature review to identify an initial set of social cues of CAs from existing research. Building on classifications from interpersonal communication theory, we developed a taxonomy that classifies the identified social cues into four major categories (i.e., verbal, visual, auditory, invisible) and ten subcategories. Subsequently, we evaluated the mapping between the identified social cues and the categories using a card sorting approach in order to verify that the taxonomy is natural, simple, and parsimonious. Finally, we demonstrate the usefulness of the taxonomy by classifying a broader and more generic set of social cues of CAs from existing research and practice. Our main contribution is a comprehensive taxonomy of social cues for CM. For researchers, the taxonomy helps to systematically classify research about social cues into one of the taxonomy's categories and corresponding subcategories. Therefore, it builds a bridge between different research fields and provides a starting point for interdisciplinary research and knowledge accumulation. For practitioners, the taxonomy provides a systematic overview of relevant categories of social cues in order to identify, implement, and test their effects in the design of a CA.
C1 [Feine, Jasper; Gnewuch, Ulrich; Morana, Stefan; Maedche, Alexander] KIT, IISM, Kaiserstr 89, D-76133 Karlsruhe, Germany.
RP Feine, J (corresponding author), KIT, IISM, Kaiserstr 89, D-76133 Karlsruhe, Germany.
EM jasper.feine@kit.edu; ulrich.gnewuch@kit.edu; stefan.morana@kit.edu;
   alexander.maedche@kit.edu
RI Morana, Stefan/AAL-6118-2020
OI Morana, Stefan/0000-0002-2266-1286
CR Akhtar Z, 2018, IEEE MULTIMEDIA, V25, P47, DOI 10.1109/MMUL.2017.265091158
   Allison D, 2012, LIBR HI TECH, V30, P95, DOI 10.1108/07378831211213238
   Amazon, 2019, SPEECH SYNTHESIS MAR
   Andonov A., 2016, SPEECH COMMUNICATION
   Andonova E, 2012, COGN PROCESS, V13, pS79, DOI 10.1007/s10339-012-0472-x
   [Anonymous], 2018, GARTNER SAYS 25 PERC
   [Anonymous], 2003, P SIGCHI C HUM FACT, DOI [10.1145/642611.642662, DOI 10.1145/642611.642662]
   [Anonymous], 2018, FORBES
   Antaki C., 2003, DISCOURSE ANALYSIS M
   ANTAKI C, 2008, SAGE HDB SOCIAL RES, P431, DOI DOI 10.4135/9781848608429.N25
   Appel J., 2012, ADV HUM-COMPUT INTER, P1, DOI DOI 10.1155/2012/324694
   Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Bailenson JN, 2005, PSYCHOL SCI, V16, P814, DOI 10.1111/j.1467-9280.2005.01619.x
   Bailey K., 1994, TYPOLOGIES AND TAXON
   Baur T, 2015, ACM T INTERACT INTEL, V5, DOI 10.1145/2764921
   Becker C, 2005, LECT NOTES COMPUT SC, V3784, P466
   Becker C, 2004, LECT NOTES COMPUT SC, V3068, P154
   Bee N, 2009, LECT NOTES ARTIF INT, V5773, P229
   Beer JM, 2015, INT J HUM-COMPUT ST, V75, P1, DOI 10.1016/j.ijhcs.2014.11.005
   Beldad A, 2016, COMPUT HUM BEHAV, V60, P62, DOI 10.1016/j.chb.2016.02.046
   Bell A., 1997, SOCIOLINGUISTICS REA, P240
   Ben Mimoun MS, 2012, J RETAIL CONSUM SERV, V19, P605, DOI 10.1016/j.jretconser.2012.07.006
   Ben Youssef A, 2015, LECT NOTES ARTIF INT, V9238, P3, DOI 10.1007/978-3-319-21996-7_1
   Beun RJ, 2003, LECT NOTES ARTIF INT, V2792, P315
   Bevacqua E, 2010, LECT NOTES ARTIF INT, V6356, P194, DOI 10.1007/978-3-642-15892-6_21
   Bickmore T., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P396
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore T, 2005, TEXT SPEECH LANG TEC, V30, P23
   Bickmore T, 2010, HARVARD REV PSYCHIAT, V18, P119, DOI 10.3109/10673221003707538
   Bickmore TW, 2010, IEEE T AFFECT COMPUT, V1, P60, DOI 10.1109/T-AFFC.2010.4
   Bishop T., 2018, WHAT HAPPENED TO YAH
   Bonito J. A., 1999, GROUP'99. Proceedings of the International ACM SIGGROUP Conference on Supporting Group Work, P229
   Brahnam S, 2012, INTERACT COMPUT, V24, P139, DOI 10.1016/j.intcom.2012.05.001
   Brandao Z, 2013, REV CONTEMP EDUC, V8, P1
   Brandtzaeg PB., 2018, INTERACTIONS, V25, P38, DOI 10.1145/3236669
   Braslavski P, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P225, DOI 10.1145/3176349.3176879
   Burgoon J.K., 2011, THE SAGE HANDBOOK OF
   BURGOON JUDEE K., 2010, NONVERBAL COMMUNICAT
   Cafaro A, 2016, ACM T COMPUT-HUM INT, V23, DOI 10.1145/2940325
   Campano S, 2015, INT CONF AFFECT, P962, DOI 10.1109/ACII.2015.7344691
   Candello H, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3476, DOI 10.1145/3025453.3025919
   Caridakis G, 2007, LANG RESOUR EVAL, V41, P367, DOI 10.1007/s10579-007-9057-1
   Cassell J, 2000, COMMUN ACM, V43, P50, DOI 10.1145/355112.355123
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   Cassell J, 2001, AI MAG, V22, P67
   Cassell J, 1999, APPL ARTIF INTELL, V13, P519, DOI 10.1080/088395199117360
   Cassell J., 1999, P SIGCHI C HUM FACT, V99, P520, DOI DOI 10.1145/302979.303150
   Cassell J., 1994, PROCEEDINGS OF THE 2
   Cassell J., 2000, EMBODIED CONVERSATIO, P430
   Cassell J., 2019, SARA THE SOCIALLY AW
   Cassell J., 2000, EMBODIED CONVERSATIO
   Catrambone R., 2002, PROCEEDINGS OF THE C, V24
   Chae SW, 2016, INT J HUM-COMPUT INT, V32, P373, DOI 10.1080/10447318.2016.1150643
   Chakrabarti C, 2015, EXPERT SYST APPL, V42, P6878, DOI 10.1016/j.eswa.2015.04.067
   Chokshi N., 2018, AMAZON KNOWS WHY ALE
   Chollet M, 2014, LECT NOTES ARTIF INT, V8637, P120, DOI 10.1007/978-3-319-09767-1_15
   Chue V., 2018, P 2018 ACM C SUPP GR, P136
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Collier G, 2014, EMOTIONAL EXPRESSION
   Cowell AJ, 2005, INT J HUM-COMPUT ST, V62, P281, DOI 10.1016/j.ijhcs.2004.11.008
   Cronbach L.J., 1972, THE DEPENDABILITY OF, P410
   Crystal D., 1969, PROSODIC SYSTEMS AND
   D'Arcy A., 2016, ITS LONELY ON TOP WH
   Dale R, 2016, NAT LANG ENG, V22, P811, DOI 10.1017/S1351324916000243
   Danilava S., 2013, WORKSHOP AT CHI 2013
   De Carolis B, 2004, COG TECH, P65
   de Rosis F, 2003, INT J HUM-COMPUT ST, V59, P81, DOI 10.1016/S1071-5819(03)00020-X
   de Visser EJ, 2016, J EXP PSYCHOL-APPL, V22, P331, DOI 10.1037/xap0000092
   Demeure V, 2011, PRESENCE-VIRTUAL AUG, V20, P431, DOI 10.1162/PRES_a_00065
   Derrick DC, 2014, COMPUT HUM BEHAV, V33, P39, DOI 10.1016/j.chb.2013.12.027
   DeVito J.A., 2013, THE INTERPERSONAL CO
   Ding Y, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P773
   Donath J., 2007, FEBRUARY DRAFT FOR S
   Dybala P, 2009, IEICE T INF SYST, VE92D, P2394, DOI 10.1587/transinf.E92.D.2394
   Ekman P., 1973, DARWIN FACIAL EXPRES, P273
   Endrass B, 2011, COMPUT SPEECH LANG, V25, P158, DOI 10.1016/j.csl.2010.04.001
   Feine Jasper, 2019, Extending the Boundaries of Design Science Theory and Practice. 14th International Conference on Design Science Research in Information Systems and Technology, DESRIST 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11491), P76, DOI 10.1007/978-3-030-19504-5_6
   Feine J., 2019, 14 INTERNATIONALE TA
   Fernandez-Dols JM, 2013, HANDB COMMUN SCI, V2, P69
   Fiore SM, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00859
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Fogg B., 1997, CHI 97 EXTENDED ABST, DOI [10.1145/1120212.1120419, DOI 10.1145/1120212.1120419]
   Fogg BJ., 2002, UBIQUITY, P89, DOI DOI 10.1145/764008.763957
   Folstad A., 2017, INTERACTIONS, V24, P38, DOI [10.1145/3085558, DOI 10.1145/3085558]
   Forlizzi Jodi, 2007, P 2007 C DES PLEAS P, P209
   Frommert C., 2018, USING CHATBOTS ASSIS, P257
   Gamble T.K., 2014, INTERPERSONAL COMMUN, P464
   Gao Y., 2018, IEEE SMARTWORLD UBIQ
   Garrido P, 2017, COMPUT SCI INF SYST, V14, P1, DOI 10.2298/CSIS150410029G
   Garrison Anthony, 2011, Computers and Composition, V28, P112, DOI 10.1016/j.compcom.2011.04.001
   Gartner, 2017, TOP TRENDS IN THE GA
   Gebhard P, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P661
   Gerber A., 2017, PROCEEDINGS OF THE T
   Ghazali AS, 2018, COMPUT HUM BEHAV, V87, P58, DOI 10.1016/j.chb.2018.05.016
   Gnewuch U., 2018, PROCEEDINGS OF THE 2, P23
   Gnewuch U, 2017, DESIGNING COOPERATIV
   Gnewuch U., 2018, INTERNATIONAL CONFER
   Go E, 2019, COMPUT HUM BEHAV, V97, P304, DOI 10.1016/j.chb.2019.01.020
   Gorin AL, 1997, SPEECH COMMUN, V23, P113, DOI 10.1016/S0167-6393(97)00040-X
   Gregor S, 2006, MIS QUART, V30, P611
   Guerrero L.K., 1999, THE NONVERBAL COMMUN
   Guo YR, 2016, ACM-IEEE J CONF DIG, P119, DOI 10.1145/2910896.2910897
   Hall E. T., 1990, SILENT LANGUAGE
   Hastie H, 2016, AAMAS'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P931, DOI 10.5555/2936924.2937061
   Hauser M.D., 1996, THE EVOLUTION OF COM
   Hayashi Y, 2016, IEICE T INF SYST, VE99D, P1455, DOI 10.1587/transinf.2015CBP0005
   Heath A., 2018, MEET PONCHO THE WEAT
   Hegel F., 2011, 2011 RO-MAN: The 20th IEEE International Symposium on Robot and Human Interactive Communication, P72, DOI 10.1109/ROMAN.2011.6005246
   Hermann E., 2019, PROSODY SAMPLES
   Hess TJ, 2005, J MANAGE INFORM SYST, V22, P15, DOI 10.2753/MIS0742-1222220302
   Hill J, 2015, COMPUT HUM BEHAV, V49, P245, DOI 10.1016/j.chb.2015.02.026
   Hoffmann L, 2009, LECT NOTES ARTIF INT, V5773, P159, DOI 10.1007/978-3-642-04380-2_19
   Hone K, 2006, INTERACT COMPUT, V18, P227, DOI 10.1016/j.intcom.2005.05.003
   Huisman G, 2014, IFIP ADV INF COMM TE, V425, P114
   Isbister K, 2000, INT J HUM-COMPUT ST, V53, P251, DOI 10.1006/ijhc.2000.0368
   JAMES A, 2017, LINGUISTICA, V57, P137, DOI DOI 10.4312/LINGUISTICA.57.1.137-149
   Johnson K., 2017, MICROSOFT BOT FRAMEW
   Kalman Y.M., 2010, PROCEEDINGS OF THE F
   Kalman YM, 2014, COMPUT HUM BEHAV, V34, P187, DOI 10.1016/j.chb.2014.01.047
   Kang S. -H., 2013, P CHI EA 2013, P229
   Kang S.-H., 2011, HEALTH TECHNOL INFOR
   Keeling K., 2004, P 37 ANN HAW INT C S, P1
   Kerly A, 2007, KNOWL-BASED SYST, V20, P177, DOI 10.1016/j.knosys.2006.11.014
   Kim S, 2016, J CONSUM RES, V43, P282, DOI 10.1093/jcr/ucw016
   Kitchenham B., 2004, KEELE UNIVERSITY TEC
   Klein J, 2002, INTERACT COMPUT, V14, P119, DOI 10.1016/S0953-5438(01)00053-4
   Klopfenstein LC, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P555, DOI 10.1145/3064663.3064672
   Knapp AL., 2011, THE SAGE HANDBOOK OF
   Knapp M. L., 2013, NONVERBAL COMMUNICAT
   Knijnenburg BP, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2963106
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   Kopp S, 2006, LECT NOTES ARTIF INT, V4133, P205
   Kramer NC, 2008, LECT NOTES COMPUT SC, V5208, P507
   Kramer NC, 2016, COMPUT EDUC, V99, P1, DOI 10.1016/j.compedu.2016.04.002
   Kramer N., 2008, SOZIALE WIRKUNGEN VI, P283
   Kramer N.C., 2005, SOCIAL COMMUNICATIVE, P442
   Kramer N, 2013, INT J HUM-COMPUT ST, V71, P335, DOI 10.1016/j.ijhcs.2012.09.006
   Lakoff G, 1987, WOMEN FIRE AND DANGE
   Lamolle M, 2005, LECT NOTES ARTIF INT, V3554, P225
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lariviere B, 2017, J BUS RES, V79, P238, DOI 10.1016/j.jbusres.2017.03.008
   Laver J., 1980, THE PHONETIC DESCRIP
   Leathers D. G., 2015, SUCCESSFUL NONVERBAL
   LEATHERS DG, 1976, NONVERBAL COMMUNICAT
   LeBreton JM, 2008, ORGAN RES METHODS, V11, P815, DOI 10.1177/1094428106296642
   Lee SY, 2017, INT J HUM-COMPUT ST, V103, P95, DOI 10.1016/j.ijhcs.2017.02.005
   Lewis K, 2013, PROCEEDINGS OF THE ASME RAIL TRANSPORTATION DIVISION FALL CONFERENCE, RTDF 2012, P119
   Li J., 2017, P 22 INT C INT US IN, P275
   Liebman N, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P570, DOI 10.1145/2818048.2819945
   Lisetti C., 2013, ACM T MANAG INF SYST, V4, DOI [10.1145/2544103.19:1208;19:28, DOI 10.1145/2544103.19:1208;19:28]
   Lobato E. J., 2015, P IFAIRSC, P61
   Lortie CL, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025085
   Louwerse MM, 2005, APPL COGNITIVE PSYCH, V19, P693, DOI 10.1002/acp.1117
   Maedche A, 2019, BUS INFORM SYST ENG+, V61, P535, DOI 10.1007/s12599-019-00600-8
   Maedche A, 2016, BUS INFORM SYST ENG+, V58, P367, DOI 10.1007/s12599-016-0444-2
   Mairesse F, 2007, J ARTIF INTELL RES, V30, P457, DOI 10.1613/jair.2349
   Mayer RE, 2006, INT J HUM-COMPUT ST, V64, P36, DOI 10.1016/j.ijhcs.2005.07.001
   McBreen H, 2002, MU S ART SOC SIM ORG, V3, P267
   McBreen HM, 2001, IEEE T SYST MAN CY A, V31, P394, DOI 10.1109/3468.952714
   McTear M., 2016, THE CONVERSATIONAL I
   Mctear M. F., 2017, MACHINE LEARNING AND, P38, DOI 10.1007/978-3-319-69365-1_3
   Mersiol M., 2002, PROCEEDINGS FOURTH I
   Moon Y, 1998, INT J HUM-COMPUT ST, V49, P79, DOI 10.1006/ijhc.1998.0199
   Moon Y, 2000, J CONSUM RES, V26, P323, DOI 10.1086/209566
   Moon Y, 1996, COMMUN RES, V23, P651, DOI 10.1177/009365096023006002
   Moore GC, 1991, INFORM SYST RES, V2, P192, DOI 10.1287/isre.2.3.192
   Morkes J, 1999, HUM-COMPUT INTERACT, V14, P395, DOI 10.1207/S15327051HCI1404_2
   Myers L., 2017, NEW SSML FEATURES GI
   Nass C, 1996, INT J HUM-COMPUT ST, V45, P669, DOI 10.1006/ijhc.1996.0073
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Nass C, 1999, J APPL SOC PSYCHOL, V29, P1093, DOI 10.1111/j.1559-1816.1999.tb00142.x
   NASS C, 1995, INT J HUM-COMPUT ST, V43, P223, DOI 10.1006/ijhc.1995.1042
   Nass C, 1997, J APPL SOC PSYCHOL, V27, P864, DOI 10.1111/j.1559-1816.1997.tb00275.x
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nickerson RC, 2013, EUR J INFORM SYST, V22, P336, DOI 10.1057/ejis.2012.26
   Niculescu A., 2010, INTERNATIONAL CONFER
   Niewiadomski R, 2010, INT J HUM-COMPUT ST, V68, P851, DOI 10.1016/j.ijhcs.2010.07.004
   Niewiadomski Radoslaw, 2013, INT C AUT AG MULT SY, P619
   Noth W., 1995, HANDBOOK OF SEMIOTIC
   Nowak K. L., 2004, J COMPUT-MEDIAT COMM, V9, P00, DOI DOI 10.1111/J.1083-6101.2004.TB00284.X
   Nunamaker JE, 2011, J MANAGE INFORM SYST, V28, P17, DOI 10.2753/MIS0742-1222280102
   Ochs M, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2925993
   Pantic M., 2011, VISUAL ANAL HUMANS, P511, DOI DOI 10.1007/978-0-85729-997-0_26
   Pare G, 2015, INFORM MANAGE-AMSTER, V52, P183, DOI 10.1016/j.im.2014.08.008
   Pecune F, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS'15), P1817
   Pelachaud C., 2005, 13th Annual ACM International Conference on Multimedia, P683
   Pelachaud C, 2003, LECT NOTES ARTIF INT, V2650, P300
   Pelachaud C, 2017, P 1 ACM SIGCHI INT W, P9
   Pelachaud C, 2009, PHILOS T R SOC B, V364, P3539, DOI 10.1098/rstb.2009.0186
   Pelachaud C, 2009, SPEECH COMMUN, V51, P630, DOI 10.1016/j.specom.2008.04.009
   Perez S., 2017, ALEXA LEARNS TO TALK
   Pertaub D.P., 2001, STUD HEALTH TECHNOL, V81
   Pfeifer L.M., 2009, P 9 INT C INT VIRT A, P460
   POYATOS F, 1991, LANG COMMUN, V11, P181, DOI 10.1016/0271-5309(91)90005-G
   Prat N, 2015, J MANAGE INFORM SYST, V32, P229, DOI 10.1080/07421222.2015.1099390
   Prepin K., 2013, BEYOND BACKCHANNELS
   Puzakova M, 2013, INT J ADVERT, V32, P513, DOI 10.2501/IJA-32-4-513-538
   Recanati F, 2001, SYNTHESE, V128, P75, DOI 10.1023/A:1010383405105
   Reeves S., 2017, TALKING WITH CONVERS
   Reidsma D., 2013, TARDIS FRAMEWORK INT, P476
   Rezabek L.L., 1998, J VISUAL UTERACY, V18, P201, DOI DOI 10.1080/23796529.1998.11674539
   Richards D, 2014, INT J HUM-COMPUT ST, V72, P460, DOI 10.1016/j.ijhcs.2014.01.005
   Rickenberg R., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P49
   Rossen B, 2008, LECT NOTES COMPUT SC, V5208, P237
   Rugg G, 2005, EXPERT SYST, V22, P94, DOI 10.1111/j.1468-0394.2005.00300.x
   Ryokai K, 2003, J COMPUT ASSIST LEAR, V19, P195, DOI 10.1046/j.0266-4909.2003.00020.x
   Sah YJ, 2015, COMPUT HUM BEHAV, V45, P392, DOI 10.1016/j.chb.2014.12.055
   Schdtz S., 2002, LINGUISTIC PARALINGU
   Searle J.R., 1980, SPEECH ACT THEORY PR, P336
   Selting M., 2009, HANDBOOK OF PRAGMATI
   Shechtman N., 2003, P SIGCHI C HUM FACT, P281, DOI [DOI 10.1145/642611.642661, 10.1145/642611.642661]
   Shiban Y, 2015, COMPUT HUM BEHAV, V49, P5, DOI 10.1016/j.chb.2015.01.077
   Skantze G, 2013, COMPUT SPEECH LANG, V27, P243, DOI 10.1016/j.csl.2012.05.004
   Smith J.M., 2003, ANIMAL SIGNALS
   Song YW, 2017, INT CONF ADV CLOUD B, P188, DOI 10.1109/CBD.2017.40
   Tannen D., 1984, CONVERSATIONAL STYLE
   Thiebaux M., 2008, INTERNATIONAL FOUNDA
   Thomas P, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P42, DOI 10.1145/3176349.3176388
   Titscher S., 2000, SEARCH OF MEANING
   Trager George L, 1958, STUD LINGUISTICA, V13, P1
   Trenholm S., 2011, INTERPERSONAL COMMUN
   Trovato G., 2015, 2015 INTERNATIONAL C
   Verhagen T, 2014, J COMPUT-MEDIAT COMM, V19, P529, DOI 10.1111/jcc4.12066
   Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007
   Vinciarelli A, 2012, IEEE T AFFECT COMPUT, V3, P69, DOI 10.1109/T-AFFC.2011.27
   von der Piitten A., 2009, THE 12TH ANNUAL INTE
   von der Putten AM, 2010, COMPUT HUM BEHAV, V26, P1641, DOI 10.1016/j.chb.2010.06.012
   Wallis P, 2005, AISB 2005 CONV P JOI, P29
   Walther J. B., 1995, Journal of Organizational Computing, V5, P355
   Walther J.B., 2006, THE SAGE HANDBOOK OF
   Walther J.B., 2008, ENGAGING THEORIES IN
   WALTHER JB, 1992, COMMUN RES, V19, P52, DOI 10.1177/009365092019001003
   Webster J, 2002, MIS QUART, V26, pXIII
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wiltshire TJ, 2014, PROC SPIE, V9084, DOI 10.1117/12.2049933
   Wolfswinkel JF, 2013, EUR J INFORM SYST, V22, P45, DOI 10.1057/ejis.2011.51
   Wu ZM, 2017, COLOR RES APPL, V42, P753, DOI 10.1002/col.22154
   Wuenderlich N.V., 2017, PROCEEDINGS OF THE 3
   Zhang Z, 2017, PATIENT EDUC COUNS, V100, P1730, DOI 10.1016/j.pec.2017.03.017
   Ziegler M, 2017, ADV MATER TECHNOL-US, V2, DOI 10.1002/admt.201700015
NR 240
TC 84
Z9 84
U1 23
U2 94
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 1071-5819
EI 1095-9300
J9 INT J HUM-COMPUT ST
JI Int. J. Hum.-Comput. Stud.
PD DEC
PY 2019
VL 132
BP 138
EP 161
DI 10.1016/j.ijhcs.2019.07.009
PG 24
WC Computer Science, Cybernetics; Ergonomics; Psychology, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Psychology
GA JF9DY
UT WOS:000491684200012
DA 2022-08-02
ER

PT C
AU Griol, D
   Carbo, J
   Molina, JM
AF Griol, David
   Carbo, Javier
   Molina, Jose M.
BE Abraham, A
   Corchado, JM
   Gonzalez, SR
   Santana, JFD
TI Agent Simulation to Develop Interactive and User-Centered Conversational
   Agents
SO INTERNATIONAL SYMPOSIUM ON DISTRIBUTED COMPUTING AND ARTIFICIAL
   INTELLIGENCE
SE Advances in Intelligent and Soft Computing
LA English
DT Proceedings Paper
CT International Symposium on Distributed Computing and Artificial
   Intelligence
CY APR 06-08, 2011
CL Salamanca, SPAIN
SP Univ Salamanca, Bioinformat, Intelligent Syst & Educ Technol Res Grp
AB In this paper, we present a technique for developing user simulators which are able to interact and evaluate conversational agents. Our technique is based on a statistical model that is automatically learned from a dialog corpus. This model is used by the user simulator to provide the following answer taking into account the complete history of the interaction. The main objective of our proposal is not only to evaluate the conversational agent, but also to improve this agent by employing the simulated dialogs to learn a better dialog model. We have applied this technique to design and evaluate a conversational agent which provides academic information in a multi-agent system. The results of the evaluation show that the conversational agent reduces the time needed to fulfill to complete the the dialogs, thereby allowing the conversational agent to tackle new situations and generate new coherent answers for the situations already present in an initial model.
C1 [Griol, David; Carbo, Javier; Molina, Jose M.] Univ Carlos III Madrid, Grp Appl Artificial Intelligence GIAA, Dept Comp Sci, E-28903 Getafe, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Grp Appl Artificial Intelligence GIAA, Dept Comp Sci, E-28903 Getafe, Spain.
EM david.griol@uc3m.es; javier.carbo@uc3m.es; josemanuel.molina@uc3m.es
RI Griol, David/L-1258-2014; Carbo, Javier/ABB-4694-2020; Molina,
   JOSE/B-1956-2008
OI Griol, David/0000-0001-6266-5321; Carbo, Javier/0000-0001-7794-3398;
   Molina, JOSE/0000-0002-7484-7357
CR Callejas Z, 2008, SPEECH COMMUN, V50, P646, DOI 10.1016/j.specom.2008.04.004
   Griol D., 2010, P 11 SIGD M, P124
   Griol D., 2009, P 10 INT C, P2775
   Griol D, 2008, SPEECH COMMUN, V50, P666, DOI 10.1016/j.specom.2008.04.001
   Griol D, 2010, ADV INTEL SOFT COMPU, V79, P275
   Lemon O., 2007, P 8 SIGDIAL WORKSH D, P55
   McTear M. F., 2004, SPOKEN DIALOGUE TECH
   Schatzmann J, 2006, KNOWL ENG REV, V21, P97, DOI 10.1017/S0269888906000944
   Scheffler K., 2001, P HUM LANG TECHN HLT, P12
   [No title captured]
NR 10
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 1867-5662
BN 978-3-642-19933-2
J9 ADV INTEL SOFT COMPU
PY 2011
VL 91
BP 69
EP 76
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BVO75
UT WOS:000292117300009
DA 2022-08-02
ER

PT J
AU Brahnam, S
AF Brahnam, Sheryl
TI Building Character for Artificial Conversational Agents: Ethos, Ethics,
   Believability, and Credibility
SO PSYCHNOLOGY JOURNAL
LA English
DT Article
DE ethos; conversational agents; believability; trust; anthropomorphism;
   Eliza effect; verbal abuse; computer-mediated communication;
   transference; oscillation effect
AB Because ethos is an unavoidable component of dialogue and forms the basis for believing and being persuaded by another's speech, it is an important topic for AI researchers. This paper examines the concept of ethos, especially Aristotle's notions of situated and invented ethos, as it functions in oral and written discourse and then explores what happens to ethos in computer-mediated human-to-human and human-to-machine discourse. The paper draws a number of conclusions that may be of value to researchers in these fields. In particular, it argues that the rhetorical concept of ethos furnishes a broader theoretical framework for understanding design and ethical issues involved in agent credibility than does the artistic notion of believability. The paper concludes by suggesting some nonartistic methods for making agents more credible within the framework of situated ethos.
C1 [Brahnam, Sheryl] Missouri State Univ, Dept Comp Informat Syst, Springfield, MO 65804 USA.
RP Brahnam, S (corresponding author), Missouri State Univ, CIS Dept, 387 Glass Hall, Springfield, MO 65804 USA.
EM sbrahnam@facescience.org
CR ALBRIGHT L, 1988, J PERS SOC PSYCHOL, V55, P387, DOI 10.1037/0022-3514.55.3.387
   Ambady N, 2000, ADV EXP SOC PSYCHOL, V32, P201, DOI 10.1016/S0065-2601(00)80006-4
   Aristotle, 1984, COMPLETE WORKS ARIST, V2
   Bailenson JN, 2006, POLIT PSYCHOL, V27, P373, DOI 10.1111/j.1467-9221.2006.00505.x
   Balabanian DM, 1981, LITIGATION, V7, P25
   Ball G, 2000, EMBODIED CONVERSATIONAL AGENTS, P189
   Baumlin JamesS., 1994, ETHOS NEW ESSAYS RHE, P91
   Baumlin JS, 1994, ETHOS NEW ESSAYS RHE, pxi
   Beverly R. E., 1978, ANN M INT COMM ASS S
   Bickmore T., 2001, P SIGCHI C HUM FACT
   Boyd Danah., 2002, THESIS
   Brahnam S., 2005, INT WORKSH AB DARK S
   Brahnam S., 2008, CHI 2008 WORKSH VAL
   Brahnam S., 2006, M C J, V9
   Brahnam S., 2006, MIS AB INT TECHN MON
   Brahnam S., 2004, AAMAS WORKSH ENT EMB
   BROOKE R, 1987, COLL ENGL, V49, P679, DOI 10.2307/377811
   Burgoon JK, 2002, J COMMUN, V52, P657, DOI 10.1111/j.1460-2466.2002.tb02567.x
   Campbell C. P., 1995, IEEE Transactions on Professional Communications, V38, P132, DOI 10.1109/47.406725
   Caporael L. R., 1986, Computers in Human Behaviour, V2, P215, DOI 10.1016/0747-5632(86)90004-X
   Caporael L. R., 1977, ANTHROPOMORPHISM ANE, P59
   CAPORAEL LR, 1989, BEHAV BRAIN SCI, V12, P683, DOI 10.1017/S0140525X00025292
   Cassell J., 2000, EMBODIED CONVERSATIO
   Castelfranchi C, 1998, ARTIF INTELL, V103, P157, DOI 10.1016/S0004-3702(98)00056-3
   Cenami Spada E., 1997, ANTHROPOMORPHISM ANE, P37
   CHAMBERLAIN C, 1984, HELIOS, V11, P97
   Chapman DS, 2003, J APPL PSYCHOL, V88, P944, DOI 10.1037/0021-9010.88.5.944
   Davis H., 1997, ANTHROPOMORPHISM ANE, P335
   De Angeli A., 2005, INT 2005 WORKSH ENT
   De Angeli A., 2006, AVI 2006 WORKSH GEND
   De Angeli A, 2008, INTERACT COMPUT, V20, P302, DOI 10.1016/j.intcom.2008.02.004
   de Rosis F., 1999, CONTRIBUTION COGNITI
   DeBruine L. M., 2002, P ROYAL SOC LOND LON
   Derrida J., 1987, POSTCARD SOCRATES FR
   Donath J. S., 1999, COMMUNITIES CYBERSPA, V1
   Epley N, 2005, J EXP SOC PSYCHOL, V41, P414, DOI 10.1016/j.jesp.2004.08.005
   Farrell Thomas B., 1993, NORMS RHETORICAL CUL
   Ferrari Stephen F., 1996, Neotropical Primates, V4, P55
   Fischer Kerstin, 2006, WHAT COMPUTER TALK I
   Fisher J. A., 1990, MYTH ANTHROPOMORPHIS
   FONER L, 1993, 9301 MIT MED LAB
   Freud S., 1912, STANDARD EDITION COM
   GILBERT DT, 1991, AM PSYCHOL, V46, P107, DOI 10.1037/0003-066X.46.2.107
   Gill C., 1982, CLASSICAL Q, V34, P149
   Goffman E., 1959, PRESENTATION SELF EV, P259
   Guthrie S.E., 1993, FACES CLOUDS NEW THE
   Halloran S.M., 1982, RHETOR REV, V1, P58, DOI [DOI 10.1080/07350198209359037, 10.1080/07350198209359037]
   Havelock Eric A., 1982, PREFACE PLATO HIST G
   Heim Michael, 1993, METAPHYSICS VIRTUAL
   HEMSLEY GD, 1978, J APPL SOC PSYCHOL, V8, P136, DOI 10.1111/j.1559-1816.1978.tb00772.x
   Higgins E. T., 1981, PERSONALITY COGNITIO, P611
   HILTON JL, 1989, J PERS SOC PSYCHOL, V57, P201, DOI 10.1037/0022-3514.57.2.201
   Holland N. N., 2006, PSYART HYPERLINK J P
   Huang W., 2002, C HUMAN FACTORS COMP
   Hunt D., 1991, RIVERSIDE GUIDE WRIT
   Isocrates, 2000, PEACE AREOPAGITICUS
   Jung C., 1959, PSYCHE SYMBOL SELECT
   Kopp S., 2006, WORKSH HANS DELM GER
   Lang R. D., 1960, DIVIDED SELF EXISTEN
   LANHAM RA, 1976, MOTIVES ELOQUENCE LI
   Lassiter GD, 2002, J APPL PSYCHOL, V87, P867, DOI 10.1037/0021-9010.87.5.867
   Leonard A, 1997, BOTS ORIGIN NEW SPEC
   Liu Z., 2005, IEEE INT C MULT EXP
   Locke J, 2009, MASKS ONLINE J LAW T, V1, P36
   Loyall A. B., 1997, P 1 INT C AUT AG MAR
   MAULDIN ML, 1994, P AAAI 94 C SEATTL
   McCain T. A., 1974, ANN M INT COMM ASS N
   MCGINNISS J, 1969, SELLING PRESIDENT
   MILLER AB, 1974, SPEECH MONOGR, V41, P309
   Miller C. R., 2002, SEMIOTICS WRITING TR, P253
   MILLER CR, 2004, ETHOS RHETORIC, P197
   Nathan L. P., 2007, CHI 2007 WORKS PROGR
   OLSON DR, 1980, J COMMUN, V30, P186, DOI 10.1111/j.1460-2466.1980.tb01786.x
   Ong W.J., 2013, ORALITY LITERACY
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Plato, 1997, COMPLETE WORKS
   Plimpton G., 1977, WRITERS WORK PARIS R, V4
   Poster, 2001, WHATS MATTER INTERNE
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Rehm R., 2008, INTERACTING COMPUTER, V20, P326
   Reynolds N., 1993, RHETOR REV, V11, P325, DOI [DOI 10.1080/07350199309389009, 10.1080/07350199309389009]
   Ruzich CM, 2008, INTERACT STUD, V9, P504, DOI 10.1075/is.9.3.08ruz
   Saarinen, 2001, THESIS
   Seabrook J., 1994, NEW YORKER, V70, P70
   Searle JR., 1992, REDISCOVERY MIND, DOI 10.7551/mitpress/5834.001.0001
   Sengers P, 2002, LEONARDO, V35, P427, DOI 10.1162/002409402760181240
   Sharkey N. E., 2007, ARTIF INTELL, V25, P9
   Sharp G., 1996, AREANA J, V6, P1
   Shechtman N., 2003, CHI 03 FT LAUD FL
   Shneiderman B., 1987, DESIGNING USER INTER
   Shneiderman Ben, 1997, INTERACTIONS, V4, P4261, DOI [10.1145/267505.267514, DOI 10.1145/267505.267514]
   Suler J, 2004, CYBERPSYCHOL BEHAV, V7, P321, DOI 10.1089/1094931041291295
   Suler J., 2009, PSYCHOL CYBERSPACE
   TIEMENS RK, 1970, J BROADCASTING, V14, P483, DOI 10.1080/08838157009363614
   Tseng S, 1999, COMMUN ACM, V42, P39, DOI 10.1145/301353.301402
   Turing AM., 1950, J MIND ASS, V59, P433, DOI [10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   Turkle S, 1997, LIFE SCREEN
   Van Gelder L., 1985, MS MAGAZINE      OCT, P98
   Veletsianos G, 2008, INTERACT COMPUT, V20, P292, DOI 10.1016/j.intcom.2008.02.007
   Vogel Arthur A., 1973, BODY THEOLOGY GODS P
   Wallace P., 1999, PSYCHOL INTERNET
   Walther J. B., 1992, HAW INT C SYST SCI
   Walther J. B., 1994, COMMUN RES, V21, P60
   Walther J.B., 2002, HDB INTERPERSONAL CO, P529
   Walther JB, 1996, COMMUN RES, V23, P3, DOI 10.1177/009365096023001001
   Walther JB, 2007, COMPUT HUM BEHAV, V23, P2538, DOI 10.1016/j.chb.2006.05.002
   Weizenbaum J., 1976, COMPUTER POWER HUMAN
   WELCH KE, 1990, CONT RECEPTION CLASS
   Whittaker S, 2003, HANDBOOK OF DISCOURSE PROCESSES, P243
   Wisse J, 1989, ETHOS PATHOS ARISTOT
   Yee N., 2007, C HUMAN FACTORS COMP
   YOOS GE, 1979, PHILOS RHETORIC, V12, P41
   Zdenek S., 2003, AI & Society, V17, P340, DOI 10.1007/s00146-003-0284-8
   [No title captured]
NR 114
TC 19
Z9 19
U1 1
U2 2
PU PSYCHNOLOGY JOURNAL
PI PADOVA
PA PSYCHONOLOGY JOURNAL, PADOVA, 00000, ITALY
SN 1720-7525
J9 PSYCHNOLOGY J
JI PsychNology J.
PY 2009
VL 7
IS 1
SI SI
BP 9
EP 47
PG 39
WC Psychology, Experimental
WE Emerging Sources Citation Index (ESCI)
SC Psychology
GA VB7KB
UT WOS:000416898900002
DA 2022-08-02
ER

PT C
AU Huang, HH
   Fukuda, M
   van der Struijk, S
   Nishida, T
AF Huang, Hung-Hsuan
   Fukuda, Masato
   van der Struijk, Stef
   Nishida, Toyoaki
GP ACM
TI Integration of DNN Generated Spontaneous Reactions with a Generic
   Multimodal Framework for Embodied Conversational Agents
SO HAI'18: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT
   INTERACTION
LA English
DT Proceedings Paper
CT 6th International Conference on Human-Agent Interaction (HAI)
CY DEC 15-18, 2018
CL Southampton, ENGLAND
SP Assoc Comp Machinery, ADK, Cocoro SB, THALES, Cognit Interact Design, DEEPCORE, Assoc Comp Machinery SIGCHI
DE embodied conversational agents; facial expression; multimodal
   interaction; ZeroMQ; FACS
C1 [Huang, Hung-Hsuan; Fukuda, Masato] RIKEN, Ctr Adv Intelligence Project, Kyoto, Japan.
   [van der Struijk, Stef; Nishida, Toyoaki] Kyoto Univ, Grad Sch Informat, Kyoto, Japan.
RP Huang, HH (corresponding author), RIKEN, Ctr Adv Intelligence Project, Kyoto, Japan.
EM hhhuang@acm.org
CR Baltrusaitis Tadas, 2017, CORR
   Ekman P, 2002, FACIAL ACTION CODING
   Huang H, 2008, P 7 INT C AUT AG MUL, P128
   Huang HH, 2008, MULTIAGENT GRID SYST, V4, P371, DOI 10.3233/MGS-2008-4404
   Traum David, 2003, INFORM STATE APPROAC, P325, DOI DOI 10.1007/978-94-010-0019-2_15
   van der Struijk Stef, 2018, 18 ACM INT C INT VIR
NR 6
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5953-5
PY 2018
BP 371
EP 373
DI 10.1145/3284432.3287190
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BL9NS
UT WOS:000457793300061
DA 2022-08-02
ER

PT C
AU Jacquet, B
   Masson, O
   Jamet, F
   Baratgin, J
AF Jacquet, Baptiste
   Masson, Olivier
   Jamet, Frank
   Baratgin, Jean
BE Ahram, T
   Karwowski, W
   Taiar, R
TI On the Lack of Pragmatic Processing in Artificial Conversational Agents
SO HUMAN SYSTEMS ENGINEERING AND DESIGN, IHSED2018
SE Advances in Intelligent Systems and Computing
LA English
DT Proceedings Paper
CT 1st International Conference on Human Systems Engineering and Design
   (IHSED) - Future Trends and Applications
CY OCT 25-27, 2018
CL Ctr Hospitalier Univ Reims, Champagne Ardenne, FRANCE
HO Ctr Hospitalier Univ Reims
DE Pragmatics; Natural language processing; Cognition; Conversations;
   Social artificial agents
AB With the increasing demand for automated agents able to communicate with humans, a lot of progress has been made in the field of artificial intelligence in order to produce conversational agents able to sustain open or topic-restricted conversations. Still, they remain far from the capacity of interaction displayed by humans. This article highlights the challenges still faced in artificial social interaction regarding the contextualization of utterances within a conversation, either in chatbots or in more complex social robots, through processing of the pragmatic clues of conversations, using current knowledge in psychology and linguistics. It also suggests a number of points of interest for the development of artificial agents aimed at improving their communication with humans, the relevance of their utterances, and the relationship with the people interacting with them. We believe that in order to be recognized as a social agent, an artificial agent must follow similar rules humans follow themselves when conversing with each other.
C1 [Jacquet, Baptiste; Masson, Olivier; Jamet, Frank; Baratgin, Jean] PARIS Assoc, 25 Rue Henri Barbusse, F-75005 Paris, France.
   [Jacquet, Baptiste; Masson, Olivier; Jamet, Frank; Baratgin, Jean] Univ Paris VIII, Lab CHArt, EA4004, 4-14 Rue Ferrus, F-75014 Paris, France.
   [Jacquet, Baptiste; Masson, Olivier; Jamet, Frank; Baratgin, Jean] EPHE, 4-14 Rue Ferrus, F-75014 Paris, France.
   [Jamet, Frank] Univ Cergy Pontoise UCP, 33 Blvd Port, F-95011 Cergy Pontoise, France.
   [Baratgin, Jean] Ecole Normale Super ENS, Inst Jean Nicod IJN, 29 Rue Ulm, F-75005 Paris, France.
RP Jacquet, B (corresponding author), PARIS Assoc, 25 Rue Henri Barbusse, F-75005 Paris, France.; Jacquet, B (corresponding author), Univ Paris VIII, Lab CHArt, EA4004, 4-14 Rue Ferrus, F-75014 Paris, France.; Jacquet, B (corresponding author), EPHE, 4-14 Rue Ferrus, F-75014 Paris, France.
EM baptiste.jacquet28@gmail.com
RI Baratgin, Jean/AAR-9699-2020
OI Baratgin, Jean/0000-0001-9566-486X; Frank, Jamet/0000-0002-6630-7633;
   Jacquet, Baptiste/0000-0001-5310-2789
CR Broekens Joost, 2009, Gerontechnology, V8, P94
   Chakrabarti C, 2015, EXPERT SYST APPL, V42, P6878, DOI 10.1016/j.eswa.2015.04.067
   Gockley R, 2005, IEEE RSJ INT C INT R, P1338, DOI DOI 10.1109/IROS.2005.1545303
   Ham Jaap, 2011, Social Robotics. Proceedings Third International Conference (ICSR 2011), P71, DOI 10.1007/978-3-642-25504-5_8
   Jacquet B., 2017, 3 WORKSH VIRT SOC IN
   Jacquet B, 2018, C HUM SYST INTERACT, P332, DOI 10.1109/HSI.2018.8431328
   Masson Olivier, 2017, Advances in Artificial Intelligence: from Theory to Practice. 30th International Conference on Industrial Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2017. Proceedings: LNAI 10350, P559, DOI 10.1007/978-3-319-60042-0_62
   Masson O., 2015, IEEE INT WORKSH ADV, P1
   Masson O, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATION AND DIGITAL TECHNOLOGIES (IDT), P256, DOI 10.1109/DT.2017.8024306
   MOTLEY MT, 1993, HUM COMMUN RES, V20, P3, DOI 10.1111/j.1468-2958.1993.tb00314.x
   Mutlu B., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P61
   Saygin AP, 2002, J PRAGMATICS, V34, P227, DOI 10.1016/S0378-2166(02)80001-7
   Sperber Dan, 1995, RELEVANCE COMMUNICAT
   Wallace RS, 2009, PARSING TURING TEST, P181, DOI DOI 10.1007/978-1-4020-6710-5_13
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
NR 15
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2194-5357
EI 2194-5365
BN 978-3-030-02053-8; 978-3-030-02052-1
J9 ADV INTELL SYST
PY 2019
VL 876
BP 394
EP 399
DI 10.1007/978-3-030-02053-8_60
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ4EO
UT WOS:000589188300060
DA 2022-08-02
ER

PT C
AU Okur, E
   Kumar, SH
   Sahay, S
   Nachman, L
AF Okur, Eda
   Kumar, Shachi H.
   Sahay, Saurav
   Nachman, Lama
GP Assoc Comp Linguistics
TI Audio-Visual Understanding of Passenger Intents for In-Cabin
   Conversational Agents
SO PROCEEDINGS OF THE SECOND GRAND CHALLENGE AND WORKSHOP ON MULTIMODAL
   LANGUAGE (CHALLENGE-HML), VOL 1
LA English
DT Proceedings Paper
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL) / 2nd Grand Challenge and Workshop on Multimodal Language
   (Challenge-HML)
CY JUL 10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB Building multimodal dialogue understanding capabilities situated in the in-cabin context is crucial to enhance passenger comfort in autonomous vehicle (AV) interaction systems. To this end, understanding passenger intents from spoken interactions and vehicle vision systems is an important building block for developing contextual and visually grounded conversational agents for AV. Towards this goal, we explore AMIE (Automated-vehicle Multimodal In-cabin Experience), the in-cabin agent responsible for handling multimodal passenger-vehicle interactions. In this work, we discuss the benefits of multimodal understanding of in-cabin utterances by incorporating verbal/language input together with the non-verbal/acoustic and visual input from inside and outside the vehicle. Our experimental results outperformed text-only baselines as we achieved improved performances for intent detection with multimodal approach.
C1 [Okur, Eda; Kumar, Shachi H.; Sahay, Saurav; Nachman, Lama] Intel Labs, Anticipatory Comp Lab, Santa Clara, CA 95052 USA.
RP Okur, E (corresponding author), Intel Labs, Anticipatory Comp Lab, Santa Clara, CA 95052 USA.
EM eda.okur@intel.com; shachi.h.kumar@intel.com; saurav.sahay@intel.com;
   lama.nachman@intel.com
CR Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Chung YA, 2018, INTERSPEECH, P811, DOI 10.21437/Interspeech.2018-2341
   Eric M, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P37
   Eyben F., 2013, P ACM MULT BARC SPAI, P835
   Fukui M, 2018, IEEE T CONSUM ELECTR, V64, P399, DOI 10.1109/TCE.2018.2867801
   Hakkani-Tur D., 2016, MULTIDOMAIN JOINT SE
   Hansen J.H., 2001, 7 EUR C SPEECH COMM
   Jeffrey Pennington, 2015, GLOVE GLOBAL VECTORS C EMP METH NAT LANG
   Kordopatis-Zilos G, 2017, LECT NOTES COMPUT SC, V10132, P251, DOI 10.1007/978-3-319-51811-4_21
   Liang P. P., 2019, N AM CHAPTER ASS COM, P2599
   Liang PP, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1569
   Liu Zhun, 2018, P 56 ANN M ASS COMP, V1
   Mikolov T., 2013, P ADV NEUR INF PROC, V26, P3111
   Okur Eda, 2019, 20 INT C COMP LING I
   Pham H, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P6892
   Schuller s, 2010, P INTERSPEECH 2010
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sherry John, 2018, SOC ROB WILD WORKSH
   Szegedy C., 2016, CORR
   Tsai Yao-Hung Hubert, 2019, P 57 ANN M ASS COMP, V1
   Wang P, 2017, ACMIEEE INT CONF HUM, P234, DOI 10.1145/2909824.3020256
   Wen LY, 2018, LECT NOTES ARTIF INT, V10619, P3, DOI 10.1007/978-3-319-73618-1_1
   Zadeh  Amir, 2018, P 32 AAAI C ART INT
   Zhang X., 2016, IJCAI, V16, P2993
   Zheng Y, 2017, IEEE INT VEH SYM, P559, DOI 10.1109/IVS.2017.7995777
NR 25
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-952148-24-8
PY 2020
BP 55
EP 59
PG 5
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Linguistics
GA BP7XI
UT WOS:000563409300007
DA 2022-08-02
ER

PT C
AU Griol, D
   Sanchez-Pi, N
   Carbo, J
   Molina, JM
AF Griol, David
   Sanchez-Pi, Nayat
   Carbo, Javier
   Molina, Jose M.
BE Demazeau, Y
   Pechoucek, M
   Corchado, JM
   Bajo, J
TI An Agent-Based Dialog Simulation Technique to Develop and Evaluate
   Conversational Agents
SO ADVANCES ON PRACTICAL APPLICATIONS OF AGENTS AND MULTI-AGENT SYSTEMS
SE Advances in Intelligent and Soft Computing
LA English
DT Proceedings Paper
CT 9th International Conference on Practical Applications of Agents and
   Multi-Agent Systems
CY APR 06-08, 2011
CL Univ Salamanca, Salamanca, SPAIN
HO Univ Salamanca
AB In this paper, we present an agent-based dialog simulation technique for learning new dialog strategies and evaluate conversational agents. Using this technique the effort necessary to acquire data required to train the dialog model and then explore new dialog strategies is considerably reduced. A set of measures has also been defined to evaluate the dialog strategy that is automatically learned and compare different dialog corpora. We have applied this technique to explore the space of possible dialog strategies and evaluate the dialogs acquired for a conversational agent that collects monitored data from patients suffering from diabetes.
C1 [Griol, David; Sanchez-Pi, Nayat; Carbo, Javier; Molina, Jose M.] Univ Carlos III Madrid, Dept Comp Sci, Grp Appl Artificial Intelligence GIAA, E-28903 Getafe, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Grp Appl Artificial Intelligence GIAA, E-28903 Getafe, Spain.
EM david.griol@uc3m.es; nayat.sanchez@uc3m.es; javier.carbo@uc3m.es;
   josemanuel.molina@uc3m.es
RI Carbo, Javier/ABB-4694-2020; Sanchez-Pi, Nayat/K-2049-2015; Griol,
   David/L-1258-2014; Molina, JOSE/B-1956-2008
OI Carbo, Javier/0000-0001-7794-3398; Sanchez-Pi,
   Nayat/0000-0002-5037-9974; Griol, David/0000-0001-6266-5321; Molina,
   JOSE/0000-0002-7484-7357
CR Ai H., 2007, P 8 SIGDIAL WORKSH D, P124
   Black LA, 2005, COMP MED SY, P506, DOI 10.1109/CBMS.2005.33
   Griol D, 2010, ADV INTEL SOFT COMPU, V79, P275
   Paek T, 2000, P 16 C UNC ART INT S, P455
   Schatzmann J., 2005, P 6 SIGDIAL WORKSH D, P45
   Schatzmann J., 2007, HUMAN LANGUAGE TECHN, P149
   Schatzmann J, 2006, KNOWL ENG REV, V21, P97, DOI 10.1017/S0269888906000944
   YOUNG S, 2002, 433 CUEDFINFENGTR
NR 8
TC 4
Z9 4
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 1867-5662
BN 978-3-642-19874-8
J9 ADV INTEL SOFT COMPU
PY 2011
VL 88
BP 255
EP 264
DI 10.1007/978-3-642-19875-5_33
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BVT26
UT WOS:000292708700033
OA Green Accepted
DA 2022-08-02
ER

PT C
AU Rojas-Barahona, LM
   Cerisara, C
AF Rojas-Barahona, Lina M.
   Cerisara, Christophe
BE Gelbukh, A
TI Bayesian Inverse Reinforcement Learning for Modeling Conversational
   Agents in a Virtual Environment
SO COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING, CICLING 2014,
   PT I
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 15th Annual Conference on Intelligent Text Processing and Computational
   Linguistics (CICLing)
CY APR 06-12, 2014
CL Ctr Commun & Dev, Kathmandu, NEPAL
SP Inst Politecnico Nacl Centro Invest Computac Nat Language &Text Proc Lab, Mexican Soc Artificial Intelligence
HO Ctr Commun & Dev
AB This work proposes a Bayesian approach to learn the behavior of human characters that give advice and help users to complete tasks in a situated environment. We apply Bayesian Inverse Reinforcement Learning (BIRL) to infer this behavior in the context of a serious game, given evidence in the form of stored dialogues provided by experts who play the role of several conversational agents in the game. We show that the proposed approach converges relatively quickly and that it outperforms two baseline systems, including a dialogue manager trained to provide "locally" optimal decisions.
C1 [Rojas-Barahona, Lina M.] Univ Lorraine, LORIA, Nancy, France.
   [Cerisara, Christophe] CNRS, LORIA, Nancy, France.
RP Rojas-Barahona, LM (corresponding author), Univ Lorraine, LORIA, Nancy, France.
EM lina.rojas@loria.fr; christophe.cerisara@loria.fr
FU French ANR ( Agence Nationale de la Recherche)-project ContNomina
FX This work was partially supported by the French ANR ( Agence Nationale
   de la Recherche) funded project ContNomina.
CR Abbeel P, 2010, INT J ROBOT RES, V29, P1608, DOI 10.1177/0278364910371999
   [Anonymous], 2012, IEEE CONG EVOLUT COM, DOI DOI 10.1109/CEC.2012.6256507
   [Anonymous], 2004, P 21 INT C MACH LEAR, DOI [10.1145/1015330.1015430, DOI 10.1145/1015330.1015430]
   [Anonymous], 1998, INTRO REINFORCEMENT
   Boularias A, 2010, NIPS WORKSH MACH LEA
   Chandramohan S, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P1032
   Cuayahuitl H., 2009, THESIS
   Levin E, 2000, IEEE T SPEECH AUDI P, V8, P11, DOI 10.1109/89.817450
   Michini B, 2012, IEEE INT CONF ROBOT, P3651, DOI 10.1109/ICRA.2012.6225241
   Ng A. Y., 2000, P 17 INT C MACH LEAR, P663, DOI [DOI 10.2460/AJVR.67.2.323, 10.2460/AJVR.67.2.323]
   Paek T, 2008, SPEECH COMMUN, V50, P716, DOI 10.1016/j.specom.2008.03.010
   Pietquin O, 2006, IEEE T AUDIO SPEECH, V14, P589, DOI 10.1109/TSA.2005.855836
   Ramachandran D., 2007, URBANA, V51, P61801
   Rieser V, 2011, THEOR APPL NAT LANG, P1, DOI 10.1007/978-3-642-24942-6
   Rojas Barahona L.M., 2012, P 13 ANN M SPEC INT, P10
   Rojas-Barahona L.M., 2012, P 8 INT C LANG RES E
   Tetreault JR, 2008, SPEECH COMMUN, V50, P683, DOI 10.1016/j.specom.2008.05.002
   Walker MA, 2000, J ARTIF INTELL RES, V12, P387, DOI 10.1613/jair.713
   Williams JD, 2007, COMPUT SPEECH LANG, V21, P393, DOI 10.1016/j.csl.2006.06.008
   Young S, 2010, COMPUT SPEECH LANG, V24, P150, DOI 10.1016/j.csl.2009.04.001
NR 20
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-54905-2; 978-3-642-54906-9
J9 LECT NOTES COMPUT SC
PY 2014
VL 8403
BP 503
EP 514
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BB3PO
UT WOS:000342989200041
OA Green Submitted
DA 2022-08-02
ER

PT J
AU Weiler, S
   Matt, C
   Hess, T
AF Weiler, Severin
   Matt, Christian
   Hess, Thomas
TI Immunizing with information - Inoculation messages against
   conversational agents' response failures
SO ELECTRONIC MARKETS
LA English
DT Article
DE Conversational agent; Chatbot; Inoculation messages; Elaboration
   likelihood model; Customer service
ID DUAL-PROCESS THEORIES; RECOMMENDATION AGENTS; E-COMMERCE; SYSTEMS
   CONTINUANCE; SMOKING INITIATION; CONSUMER REVIEWS; TRUST; TECHNOLOGY;
   DISCLOSURE; RESISTANCE
AB Conversational agents (CAs) are often unable to provide meaningful responses to user requests, thereby triggering user resistance and impairing the successful diffusion of CAs. Literature mostly focuses on improving CA responses but fails to address user resistance in the event of further response failures. Drawing on inoculation theory and the elaboration likelihood model, we examine how inoculation messages, as communication that seeks to prepare users for a possible response failure, can be used as an alleviation mechanism. We conducted a randomized experiment with 558 users, investigating how the performance level (high or low) and the linguistic form of the performance information (qualitative or quantitative) affected users' decision to discontinue CA usage after a response failure. We found that inoculation messages indicating a low performance level alleviate the negative effects of CA response failures on discontinuance. However, quantitative performance level information exhibits this moderating effect on users' central processing, while qualitative performance level information affected users' peripheral processing. Extending studies that primarily discuss ex-post strategies, our results provide meaningful insights for practitioners.
C1 [Weiler, Severin; Hess, Thomas] Ludwig Maximilians Univ Munchen, Inst Informat Syst & New Media, Ludwigstr 28, D-80539 Munich, Germany.
   [Matt, Christian] Univ Bern, Inst Informat Syst, Engehaldenstr 8, CH-3012 Bern, Switzerland.
RP Weiler, S (corresponding author), Ludwig Maximilians Univ Munchen, Inst Informat Syst & New Media, Ludwigstr 28, D-80539 Munich, Germany.
EM weiler@bwl.lmu.de; christian.matt@iwi.unibe.ch; thess@lmu.de
OI Hess, Thomas/0000-0003-3969-7477
CR Adam M, 2021, ELECTRON MARK, V31, P427, DOI 10.1007/s12525-020-00414-7
   Adjerid I, 2018, MIS QUART, V42, P465, DOI 10.25300/MISQ/2018/14316
   Agarwal R, 1998, INFORM SYST RES, V9, P204, DOI 10.1287/isre.9.2.204
   Aghakhani N, 2021, INFORM SYST FRONT, V23, P1287, DOI 10.1007/s10796-020-10030-7
   Allen Mike., 1991, W J SPEECH COMMUNICA, V55, P390, DOI DOI 10.1080/10570319109374395
   Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Ayal S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01088
   Banas JA, 2010, COMMUN MONOGR, V77, P281, DOI 10.1080/03637751003758193
   Becker M, 2020, DATA BASE ADV INF SY, V51, P37, DOI 10.1145/3380799.3380804
   Ben Mimoun MS, 2012, J RETAIL CONSUM SERV, V19, P605, DOI 10.1016/j.jretconser.2012.07.006
   Benbasat I., 2005, J ASSOC INF SYST, V6, P72, DOI [10.17705/1jais.00065, DOI 10.17705/1JAIS.00065]
   Benlian A, 2012, J MANAGE INFORM SYST, V29, P237, DOI 10.2753/MIS0742-1222290107
   BERGEN M, 1992, J MARKETING, V56, P1, DOI 10.2307/1252293
   Betzing JH, 2020, ELECTRON MARK, V30, P607, DOI 10.1007/s12525-019-00332-3
   Bhattacherjee, 2017, COMMUN ASSOC INF SYS, V40, P502, DOI [https://doi.org/10.17705/1CAIS.04023, DOI 10.17705/1CAIS.04023]
   Bhattacherjee A, 2001, MIS QUART, V25, P351, DOI 10.2307/3250921
   Bhattacherjee A, 2006, MIS QUART, V30, P805
   Cheung CMY, 2012, J ASSOC INF SYST, V13, P618
   Childers TL, 2000, J BUS RES, V47, P109, DOI 10.1016/S0148-2963(98)00055-1
   Coelho GLD, 2020, ASSESSMENT, V27, P1870, DOI 10.1177/1073191118793208
   Compton J., 2013, SAGE HDB PERSUASION, P220, DOI [https://doi.org/10.4135/9781452218410, DOI 10.4135/9781452218410]
   Compton JA, 2004, J APPL COMMUN RES, V32, P343, DOI 10.1080/0090988042000276014
   COMPTON JA, 2005, COMM YEARB, P97, DOI DOI 10.1207/S15567419CY2901_4
   Compton J, 2012, COMMUN REP, V25, P1, DOI 10.1080/08934215.2012.661018
   Compton J, 2013, COMM YEARB, V37, P251
   De Keyser A, 2019, J SERV MANAGE, V30, P156, DOI 10.1108/JOSM-03-2018-0082
   Derrick DC, 2011, AIS T HUMAN COMPUTER, V3, P62, DOI DOI 10.17705/1THCI.00027
   Diederich S, 2019, HUMAN PRACTICE DIGIT, P1100
   Diederich S., 2019, 14 INT C WIRTSCH, P1550
   Diederich S., 2020, 28 EUR C INF SYST EC
   Diederich S., 2021, AIS T HUMAN COMPUTER, V13, P82
   Diederich S, 2020, BUS INFORM SYST ENG+, V62, P193, DOI 10.1007/s12599-020-00639-y
   Dillingham LL, 2017, J APPL COMMUN RES, V45, P274, DOI 10.1080/00909882.2017.1320571
   Eckhardt A., 2017, J INFORM TECHNOLOGY, V18, P34
   Elkins A. C., 2012, 2012 45th Hawaii International Conference on System Sciences (HICSS), P579, DOI 10.1109/HICSS.2012.483
   Eren BA, 2021, INT J BANK MARK, V39, P294, DOI 10.1108/IJBM-02-2020-0056
   Evans JST, 2013, PERSPECT PSYCHOL SCI, V8, P223, DOI 10.1177/1745691612460685
   Evans JSBT, 2011, DEV REV, V31, P86, DOI 10.1016/j.dr.2011.07.007
   Facebook, 2019, MAK IT EAS BUS CONN
   Fagnot, 2012, P 18 AM C INF SYST S
   Fazlollahi B, 2002, STRATEGIES ECOMMERCE, P126, DOI DOI 10.4018/978-1-931777-08-7.CH008
   Ferratt TW, 2018, J ASSOC INF SYST, V19, P1, DOI 10.17705/1jais.00482
   Folstad A., 2017, INTERACTIONS, V24, P38, DOI [10.1145/3085558, DOI 10.1145/3085558]
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Foslashlstad Asbjoslashrn, 2020, Chatbot Research and Design. Third International Workshop, CONVERSATIONS 2019. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 11970), P201, DOI 10.1007/978-3-030-39540-7_14
   Franke GR, 2004, J ACAD MARKET SCI, V32, P20, DOI 10.1177/0092070303257856
   Frost J, 2019, INTRO STAT INTUITIVE
   Gnewuch U., 2017, P 38 INT C INFORM SY
   Google, 2020, DIAL
   Gu J, 2017, DECIS SUPPORT SYST, V94, P19, DOI 10.1016/j.dss.2016.10.002
   Haigh MM, 2006, INT J ORGAN ANAL, V14, P295, DOI 10.1108/19348830610849718
   Hampton-Sosa W, 2005, INT J ELECTRON COMM, V10, P55, DOI 10.1080/10864415.2005.11043965
   Han S, 2018, IND MANAGE DATA SYST, V118, P618, DOI 10.1108/IMDS-05-2017-0214
   Hosmer DW, 2013, WILEY SER PROBAB ST, P89
   Hwang Y, 2016, COMPUT HUM BEHAV, V62, P528, DOI 10.1016/j.chb.2016.04.026
   Ivanov B, 2009, COMMUN RES, V36, P655, DOI 10.1177/0093650209338909
   Janson A., 2020, P 41 INT C INF SYST
   Janssen A, 2020, BUS INFORM SYST ENG+, V62, P211, DOI 10.1007/s12599-020-00644-1
   Jimenez-Barreto J, 2021, INT J HOSP MANAG, V94, DOI 10.1016/j.ijhm.2021.102872
   Jung D, 2018, ELECTRON MARK, V28, P367, DOI 10.1007/s12525-017-0279-9
   Jung D, 2018, BUS INFORM SYST ENG+, V60, P81, DOI 10.1007/s12599-018-0521-9
   Kim DJ, 2009, INFORM SYST RES, V20, P237, DOI 10.1287/isre.1080.0188
   Kim S, 2018, ACMIEEE INT CONF HUM, P151, DOI 10.1145/3173386.3176970
   Knijnenburg BP, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2963106
   Ko DG, 2005, MIS QUART, V29, P59
   Kolbe L. M., 2019, P 27 EUR C INF SYST
   Komiak S., 2004, E SERVICE J, V3, P49
   Laumer S, 2019, P 27 EUR C INF SYST
   Lee MK, 2010, ACMIEEE INT CONF HUM, P203, DOI 10.1109/HRI.2010.5453195
   Lee SY, 2017, INT J HUM-COMPUT ST, V103, P95, DOI 10.1016/j.ijhcs.2017.02.005
   Liu D, 2020, Q J EXP PSYCHOL, V73, P481, DOI 10.1177/1747021820903439
   Liu D, 2021, THINK REASONING, V27, P69, DOI 10.1080/13546783.2020.1720813
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Maedche A, 2019, BUS INFORM SYST ENG+, V61, P535, DOI 10.1007/s12599-019-00600-8
   MCGUIRE WJ, 1964, ADV EXP SOC PSYCHOL, V1, P191, DOI 10.1016/S0065-2601(08)60052-0
   Mesbah N, 2019, P 40 INT C INF SYST
   Moody G. D, 2020, P 19 ANN PREICIS WOR
   Morana S., 2019, 40 INT C INF SYST, P1
   Myers MD, 2014, INFORM MANAGE-AMSTER, V51, P801, DOI 10.1016/j.im.2014.01.002
   O'Keefe D.J., 1999, COMMUNICATION YB, VVol. 22, P209, DOI [DOI 10.1080/23808985.1999.11678963, 10.1080/23808985.1999.11678963]
   Office for National Statistics, 2016, 2011 CENS CT0570 SEX
   Olander F, 2014, J CONSUM POLICY, V37, P341, DOI 10.1007/s10603-014-9256-2
   Orlowski, 2017, FACEBOOK SCALES BACK
   Patel S.S., 2020, P 2020 INT SAUPEC RO, P1
   Peer E, 2017, J EXP SOC PSYCHOL, V70, P153, DOI 10.1016/j.jesp.2017.01.006
   Petty R.E., 1981, ATTITUDES PERSUASION
   PETTY RE, 1981, J PERS SOC PSYCHOL, V41, P847, DOI 10.1037/0022-3514.41.5.847
   Petty Richard E, 1986, ADV EXPT SOCIAL PSYC, V19, P123, DOI DOI 10.1016/S0065-2601(08)60214-2
   PFAU M, 1994, HUM COMMUN RES, V20, P413, DOI 10.1111/j.1468-2958.1994.tb00329.x
   PFAU M, 1992, COMMUN MONOGR, V59, P213, DOI 10.1080/03637759209376266
   Pfau M, 2008, J BROADCAST ELECTRON, V52, P303, DOI 10.1080/08838150801992128
   Pilato G., 2010, SEMANTIC COMPUTING, P357
   Pizzi G, 2021, J BUS RES, V129, P878, DOI 10.1016/j.jbusres.2020.11.006
   Qiu LY, 2009, J MANAGE INFORM SYST, V25, P145, DOI 10.2753/MIS0742-1222250405
   Ringle C.M., 2015, SMARTPLS 3
   Schneider D, 2020, ELECTRON MARK, V30, P863, DOI 10.1007/s12525-019-00373-8
   Shleifer A, 2012, J ECON LIT, V50, P1080, DOI 10.1257/jel.50.4.1080
   Srinivasa K, 2018, CHATBOTS ARE HERE ST
   Stanton J, 2015, SYSTEMES INFORM MANA, V20, P9, DOI [10.3917/sim.152.0009, DOI 10.3917/SIM.152.0009]
   Sussman SW, 2003, INFORM SYST RES, V14, P47, DOI 10.1287/isre.14.1.47.14767
   Tam KY, 2006, MIS QUART, V30, P865
   Teubner T, 2019, BUS INFORM SYST ENG+, V61, P229, DOI 10.1007/s12599-018-00574-z
   Thies IM, 2017, LECT NOTES COMPUT SC, V10513, P441, DOI 10.1007/978-3-319-67744-6_28
   TZELGOV J, 1992, J EXP PSYCHOL LEARN, V18, P166, DOI 10.1037/0278-7393.18.1.166
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Venkatesh V, 2016, INFORM SYST RES, V27, P87, DOI 10.1287/isre.2015.0612
   Venkatesh V, 2011, INFORM SYST J, V21, P527, DOI [10.1111/J.1365-2575.2011.00373.x, 10.1111/j.1365-2575.2011.00373.x]
   Wan H. H., 2004, J PUBLIC RELAT RES, V16, P301, DOI [10.1080/1532-754X.2004.11925131, DOI 10.1080/1532-754X.2004.11925131]
   Wang WQ, 2008, J MANAGE INFORM SYST, V24, P249, DOI 10.2753/MIS0742-1222240410
   Wang WQ, 2007, J MANAGE INFORM SYST, V23, P217, DOI 10.2753/MIS0742-1222230410
   Weinberg, 2017, MESSENGER M ARE SHIF
   Weisz J. D, 2019, P 2019 C HUM FACT CO
   Wright RT, 2014, INFORM SYST RES, V25, P385, DOI 10.1287/isre.2014.0522
   Zhang HP, 2012, ELECTRON MARK, V22, P143, DOI 10.1007/s12525-012-0097-z
   Zhou T, 2012, COMPUT HUM BEHAV, V28, P1518, DOI 10.1016/j.chb.2012.03.021
NR 115
TC 1
Z9 1
U1 11
U2 16
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1019-6781
EI 1422-8890
J9 ELECTRON MARK
JI Electron. Mark.
PD MAR
PY 2022
VL 32
IS 1
BP 239
EP 258
DI 10.1007/s12525-021-00509-9
EA DEC 2021
PG 20
WC Business; Management
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA 1F1AS
UT WOS:000733865500001
PM 35600912
OA Green Published, hybrid
DA 2022-08-02
ER

PT C
AU Handrianto, Y
   Huang, R
   Shang, Y
AF Handrianto, Yohanes
   Huang, Rui
   Shang, Yi
GP IEEE
TI TigerAware Assistant: A New Serverless Implementation of Conversational
   Agents for Customizable Surveys on Smart Devices
SO 2019 FIRST INTERNATIONAL CONFERENCE ON TRANSDISCIPLINARY AI (TRANSAI
   2019)
LA English
DT Proceedings Paper
CT 1st IEEE International Conference on Transdisciplinary Artificial
   Intelligence (TransAI)
CY SEP 25-27, 2019
CL Laguna Hills, CA
SP IEEE Comp Soc
DE Chatbot; Conversational Agent; Mobile Survey; Cognitive AI; Cloud
   Function; Serverless Computing
AB Applications of conversational agents, also called chatbots, have accelerated in recent years. However, it is difficult for people with limited programming skills to implement chatbots and analyze the data collected by chatbots. In this paper, we present a new serverless implementation of conversational agents for delivering customiz able surveys on smart devices, including smartphones and smart speakers, and a web-based system for applying advanced analytics techniques to survey data using cloud services. The system is called TigerAware Assistant, as part of the TigerAware platform for customizable mobile survey and sensor data collection. TigerAware Assistant enables non-technical people to easily create and deploy chatbots on various mobile devices to conduct surveys through conversations in natural languages via auditory and textual methods. It also provides a web-based system for survey data visualization, statistical analysis, and advanced machine learning-based data analysis using cloud services on survey responses collected by chatbots.
C1 [Handrianto, Yohanes; Huang, Rui; Shang, Yi] Univ Missouri, Dept Elect Engn & Comp Sci EECS, Columbia, MO 65211 USA.
RP Handrianto, Y (corresponding author), Univ Missouri, Dept Elect Engn & Comp Sci EECS, Columbia, MO 65211 USA.
EM yph374@mail.missouri.edu; rhhq7@mail.missouri.edu; shangy@missouri.edu
CR Abdul-Kader S. A., 2015, INT J ADV COMPUTER S, V6
   Albuquerque Jr L.F., 2017, 12 INT C SOFTW ENG A
   Cheng A, 2018, CONSUM COMM NETWORK
   Dahiya M., 2017, INT J COMPUTER SCI E, V5, P158
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Leitner P, 2019, J SYST SOFTWARE, V149, P340, DOI 10.1016/j.jss.2018.12.013
   Morrison W., 2018, IEEE INT C DAT SCI C
   Rogers J., 2019, CONSUM COMM NETWORK
   Setiaji B., 2016, INT C INT SYST MOD S
   Shawar B. A., 2002, COMP ALICE ELIZABETH
   Yan MT, 2016, FIRST INTERNATIONAL WORKSHOP ON MASHUPS OF THINGS AND APIS (MOTA), DOI 10.1145/3007203.3007217
NR 11
TC 0
Z9 0
U1 0
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-4127-5
PY 2019
BP 88
EP 91
DI 10.1109/TransAI46475.2019.00023
PG 4
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BO7WD
UT WOS:000525746800015
DA 2022-08-02
ER

PT J
AU Tegos, S
   Demetriadis, S
AF Tegos, Stergios
   Demetriadis, Stavros
TI Conversational Agents Improve Peer Learning through Building on Prior
   Knowledge
SO EDUCATIONAL TECHNOLOGY & SOCIETY
LA English
DT Article
DE Conversational agent; Computer-supported collaborative learning;
   Academically productive talk
ID COLLABORATION; TALK
AB Research in computer-supported collaborative learning has indicated that conversational agents can be pedagogically beneficial when used to scaffold students' online discussions. In this study, we investigate the impact of an agile conversational agent that triggers student dialogue by making interventions based on the academically productive talk framework. An experimental activity in the context of a university course involved 72 undergraduate students who discussed online in dyads. Two conditions were compared: (a) dyads who received agent interventions while working on a learning task (treatment) and (b) dyads who worked on the same task without any agent interference (control). Utilizing a concept map created by the course instructor, the conversational agent delivered unsolicited interventions that encouraged treatment students to build on their prior knowledge, linking their current contributions to the main domain principles discussed during the course. Study findings indicate that the agent intervention mode substantially improved both individual and group learning outcomes. Evidence suggests that the agent effect on learning performance was mediated by students' explicit reasoning, which was also found to be enhanced in the treatment condition.
C1 [Tegos, Stergios; Demetriadis, Stavros] Aristotle Univ Thessaloniki, Sch Informat, Thessaloniki, Greece.
RP Tegos, S (corresponding author), Aristotle Univ Thessaloniki, Sch Informat, Thessaloniki, Greece.
EM stegos@csd.auth.gr; sdemetri@csd.auth.gr
RI Demetriadis, Stavros/Z-3200-2019
OI Demetriadis, Stavros/0000-0002-1561-6372
CR Adamson D., 2013, SEE WORLD GRAIN SAND, V1, P10
   Adamson D, 2014, INT J ARTIF INTELL E, V24, P92, DOI 10.1007/s40593-013-0012-6
   Chaudhuri S, 2008, LECT NOTES COMPUT SC, V5091, P807
   Dillenbourg P, 2007, J COMPUT ASSIST LEAR, V23, P1, DOI 10.1111/j.1365-2729.2007.00191.x
   Dyke G, 2013, IEEE T LEARN TECHNOL, V6, P240, DOI 10.1109/TLT.2013.25
   Hayes AF, 2014, BRIT J MATH STAT PSY, V67, P451, DOI 10.1111/bmsp.12028
   Kerly A, 2009, APPLICATIONS AND INNOVATIONS IN INTELLIGENT SYSTEMS XVI, P169
   Kim Y, 2005, INT J ARTIFICIAL INT, V15, P95, DOI [DOI 10.1007/BF02504991, DOI 10.1145/1067860.1067867]
   Krathwohl DR, 2002, THEOR PRACT, V41, P212, DOI 10.1207/s15430421tip4104_2
   Kreijns K., 2002, Educational Technology & Society, V5
   Kumar R., 2011, CONNECTING COMPUTER, P398
   Kumar R, 2011, IEEE T LEARN TECHNOL, V4, P21, DOI 10.1109/TLT.2010.41
   Liu CC, 2008, COMPUT EDUC, V50, P627, DOI 10.1016/j.compedu.2006.07.002
   Michaels S., 2010, ACCOUNTABLE TALK SOU
   Michaels S, 2008, STUD PHILOS EDUC, V27, P283, DOI 10.1007/s11217-007-9071-1
   Papadopoulos PM, 2013, J COMPUT ASSIST LEAR, V29, P383, DOI 10.1111/jcal.12014
   Preece J., 2015, INTERACTION DESIGN H
   Rucker DD, 2011, SOC PERSONAL PSYCHOL, V5, P359, DOI 10.1111/j.1751-9004.2011.00355.x
   Sohmer R., 2009, TRANSFORMATION KNOWL, P105
   Stahl G., 2011, THEORIES TEAM COGNIT
   Streveler RA, 2008, J ENG EDUC, V97, P279, DOI 10.1002/j.2168-9830.2008.tb00979.x
   Tchounikine P, 2010, STUD COMPUT INTELL, V308, P447
   Tegos S, 2015, COMPUT EDUC, V87, P309, DOI 10.1016/j.compedu.2015.07.014
   Tegos S, 2014, INT J ARTIF INTELL E, V24, P62, DOI 10.1007/s40593-013-0007-3
   Veletsianos G., 2014, HDB RES ED COMMUNICA, P759, DOI [DOI 10.1007/978-1-4614-3185-5_61, 10.1007/978-1-4614-3185-5_61]
   Walker E, 2011, INT J COMP-SUPP COLL, V6, P279, DOI 10.1007/s11412-011-9111-2
   Weinberger A, 2007, LEARN INSTR, V17, P416, DOI 10.1016/j.learninstruc.2007.03.007
NR 27
TC 32
Z9 32
U1 1
U2 32
PU NATL TAIWAN NORMAL UNIV, TAIWAN
PI TAIPEI
PA 129, SEC 1, HEPING E RD, EDUCATION BUILDING, RM 611, TAIPEI, 10644,
   TAIWAN
SN 1176-3647
EI 1436-4522
J9 EDUC TECHNOL SOC
JI Educ. Technol. Soc.
PD JAN
PY 2017
VL 20
IS 1
BP 99
EP 111
PG 13
WC Education & Educational Research
WE Social Science Citation Index (SSCI)
SC Education & Educational Research
GA EH8RS
UT WOS:000392040600009
DA 2022-08-02
ER

PT C
AU Santos-Perez, M
   Gonzalez-Parada, E
   Cano-Garcia, JM
AF Santos-Perez, Marcos
   Gonzalez-Parada, Eva
   Manuel Cano-Garcia, Jose
BE Bravo, J
   Hervas, R
   Villarreal, V
TI AVATAR: An Open Source Architecture for Embodied Conversational Agents
   in Smart Environments
SO AMBIENT ASSISTED LIVING
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 3rd International Workshop on Ambient Assisted Living (IWAAL)/IWANN
CY JUN 08-10, 2011
CL Torremolinos, SPAIN
AB Due to a growing older population, researchers and industry are paying more attention to the needs of this group of people. Ambient Intelligence (AmI) aims to help people in their daily lives, achieving a more natural interaction of users with an electronic home environment. Embodied Conversational Agents (ECAs) arise as a natural interface between humans and AmI. Our contribution is to present AVATAR: an architecture to develop ECAs based on open source tools and libraries. In the current prototype the virtual agent acts as a natural control interface of the home automation system. In addition, we provide the details to allow its use by Spanish speakers.
C1 [Santos-Perez, Marcos; Gonzalez-Parada, Eva; Manuel Cano-Garcia, Jose] Univ Malaga, Sch Telecommun Engn, Dept Elect Technol, E-29071 Malaga, Spain.
RP Santos-Perez, M (corresponding author), Univ Malaga, Sch Telecommun Engn, Dept Elect Technol, Teatinos Campus, E-29071 Malaga, Spain.
EM marcos_sape@uma.es; gonzalez@uma.es; jcgarcia@uma.es
RI González-Parada, Eva/F-6899-2016; Garcia, Jose Manuel Cano/F-3960-2016
OI González-Parada, Eva/0000-0001-6072-9424; Garcia, Jose Manuel
   Cano/0000-0002-8211-7602
CR Baldassarri S., 2007, 17 C ESP INF GRAF CE, P91
   Beun RJ, 2003, LECT NOTES ARTIF INT, V2792, P315
   Burguillo-Rial J.C., 2007, 8 INT C INF TECHN BA
   Department of Economic and Social Affairs, 2009, WORLD POP AG 2009
   Fabri M., 2006, THESIS LEEDS METROPO
   Huggins-Daines D, 2006, INT CONF ACOUST SPEE, P185
   Hung V, 2009, INTERNATIONAL CONFERENCE ON INFORMATION, PROCESS, AND KNOWLEDGE MANAGEMENT: EKNOW 2009, PROCEEDINGS, P60, DOI 10.1109/eKNOW.2009.10
   Jokinen K., 2009, UNIVERSAL ACCESS HDB, P495
   Kenny P., 2008, P 1 INT C PERVASIVE, P6
   Kowalski S., 2009, 2 CASE STUDIES USING
   Pejsa T, 2009, CONTEL 2009: PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS, P171
   Pizzutilo S., 2010, P INT C ADV VIS INT, DOI [10.1145/1842993.1843041, DOI 10.1145/1842993.1843041]
   van Mulken S, 1998, PEOPLE AND COMPUTER XIII, PROCEEDINGS, P53
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Zhang J., 2001, EUR 2001 AALB DENM S
NR 15
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-21303-8
J9 LECT NOTES COMPUT SC
PY 2011
VL 6693
BP 109
EP 115
DI 10.12795/Ambitos.2011.i20.06
PG 7
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BAW90
UT WOS:000305883500015
OA gold
DA 2022-08-02
ER

PT C
AU Xu, Y
   Warschauer, M
AF Xu, Ying
   Warschauer, Mark
GP Assoc Comp Machinery
TI "Elinor Is Talking to Me on the Screen!" Integrating Conversational
   Agents into Children's Television Programming
SO CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS
   IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT ACM CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 25-30, 2020
CL Honolulu, HI
SP ACM SIGCHI, Assoc Comp Machinery
DE Conversational agents; social learning; screen media; science learning;
   children
ID TECHNOLOGY; SCIENCE
AB Science-oriented television and video programming can be an important source of science learning for young children. However, the educational benefits of television have long been limited by children not being able to interact with the content in a contingent way. This project leverages an intelligent conversational agent -an on-screen character capable of verbal interaction-to add social contingency into children's experience watching science videos. This conversational agent has been developed in an iterative process and embedded in a new PBS KIDS science show "Elinor Wonders Why." This Late Breaking Work presents the design of the conversational agent and reports findings from a field study that has proven feasibility of this approach. We also discuss our planned future work to examine the agent's effectiveness in enhancing children's engagement and learning.
C1 [Xu, Ying; Warschauer, Mark] Univ Calif Irvine, Irvine, CA 92697 USA.
RP Xu, Y (corresponding author), Univ Calif Irvine, Irvine, CA 92697 USA.
EM ying.xu@uci.edu; markw@uci.edu
FU National Science Foundation [1906321]; Corporation for Public
   Broadcasting; Ready To Learn grant from the U.S. Department of Education
   [U295A150003, 84.295A]
FX This research is based upon work supported by the National Science
   Foundation under Grant No. 1906321. Production of the conversational
   episodes is supported by the Corporation for Public Broadcasting.
   Funding for Elinor Wonders Why is provided in part by a Ready To Learn
   grant from the U.S. Department of Education [PR/Award No. U295A150003,
   CFDA No. 84.295A], and by the Corporation for Public Broadcasting.
CR Barron Brigid, 2009, PARENTS LEARNING PAR
   Carter EJ, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P97, DOI 10.1145/3078072.3079717
   Connell SL, 2015, J CHILD MEDIA, V9, P5, DOI 10.1080/17482798.2015.997440
   Druga S, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P595, DOI 10.1145/3078072.3084330
   Fisch Shalom M, 2014, CHILDRENS LEARNING E
   Gee JP., 2005, E-LEARNING DIGITAL M, V2, P5, DOI [10.2304/elea.2005.2.1.5, DOI 10.2304/ELEA.2005.2.1.5]
   Graesser AC, 2017, COMPUT HUM BEHAV, V76, P607, DOI 10.1016/j.chb.2017.03.041
   Harris PL, 2006, CHILD DEV, V77, P505, DOI 10.1111/j.1467-8624.2006.00886.x
   Hirsh-Pasek K, 2015, PSYCHOL SCI PUBL INT, V16, P3, DOI 10.1177/1529100615569721
   Kory J, 2014, IEEE ROMAN, P643, DOI 10.1109/ROMAN.2014.6926325
   Lee O, 2014, J SCI TEACH EDUC, V25, P223, DOI 10.1007/s10972-014-9379-y
   Lovato SB, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P301, DOI 10.1145/3311927.3323150
   Mares ML, 2013, J APPL DEV PSYCHOL, V34, P140, DOI 10.1016/j.appdev.2013.01.001
   Plowman L, 2010, RES PAP EDUC, V25, P93, DOI 10.1080/02671520802584061
   Rideout Victoria J, 2006, MEDIA FAMILY ELECT M
   Schroeder NL, 2013, J EDUC COMPUT RES, V49, P1, DOI 10.2190/EC.49.1.a
   Sciuto A, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P857, DOI 10.1145/3196709.3196772
   Sengupta S, 2019, IEEE INT WORKSH COMP
   Silander M., 2018, WHAT PARENTS TALK TH
   Stevens R., 2011, NEW COVIEWING DESIGN
   Strouse GA, 2013, DEV PSYCHOL, V49, P2368, DOI 10.1037/a0032463
   Tegos S, 2015, COMPUT EDUC, V87, P309, DOI 10.1016/j.compedu.2015.07.014
   Tewari A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1807, DOI 10.1145/2556288.2557205
   Wang FX, 2018, J EDUC PSYCHOL, V110, P250, DOI 10.1037/edu0000221
   Xu Ying, 2019, 2019 CHI C HUM FACT
NR 25
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-6819-3
PY 2020
AR LBW146
DI 10.1145/3334480.3383000
PG 8
WC Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ9OG
UT WOS:000626317803029
DA 2022-08-02
ER

PT C
AU Isbister, K
   Doyle, P
AF Isbister, K
   Doyle, P
BE Ruttkay, Z
   Pelachaud, C
TI The blind men and the elephant revisited - Evaluating interdisciplinary
   ECA research
SO FROM BROWS TO TRUST: EVALUATING EMBODIED CONVERSATIONAL AGENTS
SE Human-Computer Interaction Series
LA English
DT Proceedings Paper
CT Workshop on Embodied Conversational Agents held at the 2002 AAMAS
   Conference
CY MAR, 2003
CL Montreal, CANADA
DE conversational agents; design categories; evaluation criteria;
   interdisciplinary research
ID EYE
AB The construction of embodied conversational agents is an ambitious, complex, and essentially interdisciplinary process. This is inevitable given the depth, sophistication, and many modalities of the products we seek to create. Other chapters in this book address methods for evaluating ECAs as artefacts or according to their usability. In this chapter, we offer a complementary perspective: grounding the evaluation of ECAs in the context of the different disciplines that have merged to create the research. community constructing them.
   Different research areas have different goals and criteria for success, and without understanding what these are and how they relate, we cannot intelligently recognise what contributions other groups are making, a necessary requirement for integrating work done on one aspect of ECAs with work on another. Our goal is to help our community ultimately to create the high-quality interdisciplinary products necessary for this discipline to mature.
C1 Stanford Univ, Dept Commun, Stanford, CA 94305 USA.
RP Isbister, K (corresponding author), Stanford Univ, Dept Commun, Stanford, CA 94305 USA.
EM ki@katherineinterface.com; pdoyle@cs.stanford.edu
CR ANDRE E, 1997, IJCAI 97 S AN INT AG
   [Anonymous], 1988, COGNITIVE STRUCTURE, DOI DOI 10.1017/CBO9780511571299
   Badler N, 2002, COMP ANIM CONF PROC, P133, DOI 10.1109/CA.2002.1017521
   Badler NI, 1997, FIFTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P4, DOI 10.1109/PCCGA.1997.626166
   BATES J, 1992, CMUCS92142
   BATES J, 1992, CMUCS92200
   Bickmore T.W, 2003, THESIS MIT CAMBRIDGE
   Blumberg B.M., 1996, THESIS MIT CAMBRIDGE
   Cahn J.E., 1990, J AM VOICE IO SOC, V8, P1
   Cassell J., 2000, P 5 INT C INT US INT, P52, DOI [10.1145/325737.325781, DOI 10.1145/325737.325781]
   DOYLE P, 2003, THESIS STANFORD U
   EKMAN P, 1976, ENVIRON PSYCH NONVER, V1, P56, DOI 10.1007/BF01115465
   ELLIOTT C, 1999, LECT NOTES COMPUTER, V1600, P195, DOI DOI 10.1007/3-540-48317-9_8
   Elliott C, 1992, THESIS NW U
   Fiske S. T., 1991, SOCIAL COGNITION
   FONER L, 1993, 9301 MIT
   Franklin S, 1997, INTELLIGENT AGENTS
   GOLDBERG A, 1997, LECT NOTES COMPUTER, V1195, P58
   Hayes-Roth B., 1998, Autonomous Agents and Multi-Agent Systems, V1, P195, DOI 10.1023/A:1010019818773
   HAYESROTH B, 1994, KSL9461 STANF U
   HAYESROTH B, 1997, CREATING PERSONALITI
   Isbister K, 2000, INT J HUM-COMPUT ST, V53, P251, DOI 10.1006/ijhc.2000.0368
   Isbister Katherine, 2000, P SIGCHI C HUM FACT, P57, DOI [10.1145/332040.332407, DOI 10.1145/332040.332407]
   JOHNSON WL, 1997, P 1 INT C AUT AG, P30
   KOLLER D, 1996, ACM COMPUT SURV, V28, P8
   Kuhn Thomas S., 1962, STRUCTURE SCI REVOLU
   Laban R., 1976, LANGUAGE MOVEMENT GU
   LALLY J, 2003, GIVING LIFE RATCHET
   Laurel Brenda, 1990, ART HUMAN COMPUTER I
   Lester J. C., 1997, P ACM SIGCHI C HUM F, P359, DOI DOI 10.1145/258549.258797
   Loyall A.B., 1997, THESIS CARMEGIE MELL
   LOYALL B, 1991, CMUCS91147
   MURRAY JB, 1990, PERCEPT MOTOR SKILL, V70, P1187, DOI 10.2466/PMS.70.4.1187-1202
   NASS C, 1995, INT J HUM-COMPUT ST, V43, P223, DOI 10.1006/ijhc.1995.1042
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nass C, 1996, MEDIA EQUATION
   NILSSON NJ, 1995, AI MAG, V16, P9
   PERLIN K, 1996, COMPUTER GRAPHICS, V30, P205
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Poggi I, 2000, AI COMMUN, V13, P169
   RELLY WSN, 1996, THESIS CARNEGIE MELL
   RIST T, 1997, P INT C INT US INT O, P21
   Stone BA, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P424
   Thomas F., 1981, ILLUSION LIFE DISNEY
   TRAPPL R, 1996, CREATING PERSONAITIE
   WALLACE SA, 2003, P 18 INT JOINT C ART, P831
   WIGGINS JS, 1979, J PERS SOC PSYCHOL, V37, P395, DOI 10.1037/0022-3514.37.3.395
   Wooldridge M., 1998, Proceedings of the Second International Conference on Autonomous Agents, P385, DOI 10.1145/280765.280867
   Zimbardo P., 1991, PSYCHOL ATTITUDE CHA
   2003, PROGRAM BUYERS GUIDE, P7
   [No title captured]
NR 51
TC 17
Z9 17
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS
SN 1571-5035
EI 2524-4477
BN 1-4020-2729-X
J9 HUM-COMPUT INT-SPRIN
PY 2004
VL 7
BP 3
EP 26
PG 24
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BBP07
UT WOS:000226830500001
DA 2022-08-02
ER

PT C
AU Corti, K
   Gillespie, A
AF Corti, Kevin
   Gillespie, Alex
BE Brinkman, WP
   Broekens, J
   Heylen, D
TI Offscreen and in the Chair Next to Your: Conversational Agents Speaking
   Through Actual Human Bodies
SO INTELLIGENT VIRTUAL AGENTS, IVA 2015
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 15th International Conference on Intelligent Virtual Agents (IVA)
CY AUG 26-28, 2015
CL Delft, NETHERLANDS
SP UnivTwente, Delft Univ Technol
DE Design methodologies; Evaluation methodologies and user studies;
   Applications for film, animation, art and games; Cyranoid; Echoborg
ID IMPRESSION; SPEECH
AB This paper demonstrates how to interact with a conversational agent that speaks through an actual human body face-to-face and in person (i.e., offscreen). This is made possible by the cyranoid method: a technique involving a human person speech shadowing for a remote third-party (i.e., receiving their words via a covert audio-relay apparatus and repeating them aloud in real-time). When a person shadows for an artificial conversational agent source, we call the resulting hybrid an "echoborg." We report a study in which people encountered conversational agents either through a human shadower face-to-face or via a text interface under conditions where they assumed their interlocutor to be an actual person. Our results show that the perception of a conversational agent is dramatically altered when the agent is voiced by an actual, tangible person. We discuss the potential implications this methodology has for the development of conversational agents and general person perception research.
C1 [Corti, Kevin; Gillespie, Alex] London Sch Econ, Dept Social Psychol, London WC2A 2AE, England.
RP Corti, K (corresponding author), London Sch Econ, Dept Social Psychol, London WC2A 2AE, England.
EM k.corti@lse.ac.uk; a.t.gillespie@lse.ac.uk
CR Bailly G., 2003, International Journal of Speech Technology, V6, P11, DOI 10.1023/A:1021091720511
   Blass Thomas, 2004, MAN WHO SHOCKED WORL
   Cassell J, 2007, INTERACT STUD, V8, P391
   Corti K, 2015, INTEGR PSYCHOL BEHAV, V49, P288, DOI 10.1007/s12124-015-9294-6
   Corti K, 2015, J SOC PSYCHOL, V155, P30, DOI 10.1080/00224545.2014.959885
   Dick PK, 1968, DO ANDROIDS DREAM EL
   Gillespie A, 2010, J THEOR SOC BEHAV, V40, P19, DOI 10.1111/j.1468-5914.2009.00419.x
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   MacDorman KF, 2006, INTERACT STUD, V7, P297, DOI 10.1075/is.7.3.03mac
   MARSLENWILSON WD, 1985, SPEECH COMMUN, V4, P55, DOI 10.1016/0167-6393(85)90036-6
   Milgram S., 2010, INDIVIDUAL SOCIAL WO, P402
   Milgram Stanley, 1974, OBEDIENCE AUTHORITY
   Mitchell R., 2011, P 2 C CREAT INN DES, P199, DOI DOI 10.1145/2079216.2079246
   Mitchell Robb, 2009, P 5 STUD INT DES RES, P56
   Pardo JS, 2013, J MEM LANG, V69, P183, DOI 10.1016/j.jml.2013.06.002
   Pawlak L., 2009, ST UNICORNS TRUST
   Pieraccini R, 2012, VOICE IN THE MACHINE: BUILDING COMPUTERS THAT UNDERSTAND SPEECH, P1
   Raudaskoski Pirkko, 2013, P PART INN C PIN C 2, P126
   SCHWITZGEBEL RK, 1980, J SOC PSYCHOL, V110, P253, DOI 10.1080/00224545.1980.9924252
   Seyama J, 2007, PRESENCE-TELEOP VIRT, V16, P337, DOI 10.1162/pres.16.4.337
   TAYLOR SE, 1975, J PERS SOC PSYCHOL, V32, P439, DOI 10.1037/h0077095
   Wilcox B., ROSE
   WILSON WM, 1973, NATURE, V244, P522, DOI 10.1038/244522a0
   Worswick S, MITSUKU
NR 24
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-319-21996-7; 978-3-319-21995-0
J9 LECT NOTES ARTIF INT
PY 2015
VL 9238
BP 405
EP 417
DI 10.1007/978-3-319-21996-7_44
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BD7RG
UT WOS:000363485400044
OA Green Published
DA 2022-08-02
ER

PT C
AU Noguez, J
   Espinosa, ED
   Ramos, F
AF Noguez, J
   Espinosa, ED
   Ramos, F
BE Baba, N
   Jain, LC
   Howlett, RJ
TI Use of conversational agents and dynamic Bayesian nets for message
   recognition
SO KNOWLEDGE-BASED INTELLIGENT INFORMATION ENGINEERING SYSTEMS & ALLIED
   TECHNOLOGIES, PTS 1 AND 2
SE Frontiers in Artificial Intelligence and Applications
LA English
DT Proceedings Paper
CT 5th International Conference on Knowledge-Based Intelligent Information
   Engineering Systems and Allied Technologies (KES 2001)
CY SEP 06-08, 2001
CL OSAKA KYOIKU UNIV, OSAKA, JAPAN
SP FOST, Koei Ltd, Matsushita Elect Works Ltd
HO OSAKA KYOIKU UNIV
AB This work establishes a hypothesis: the use of conversational agents with human shape as tools to improve the interaction in distant collaborative learning will help people who live in rural areas, and lack a computer science culture, to incorporate the use of technology into their business activities. This will them the benefits provided by the e-business global process. Hereby, it is important to explore new motivating and familiar but technologically-devised ways of communication that allow people to come close to the other people, in ways that closely resemble our own behavior: socially, personally and emotionally. As a first stage of the project, we present a simulator of the interpretation of combinations of words, gesture, looks, movement of arm and head using Bayesian Nets. In order to differentiate them from other expressions and to emphasize the importance of key words inside a message.
C1 Inst Tecnol Estudios Super Monterrey, Cuernavaca, Morelos, Mexico.
RP Noguez, J (corresponding author), Inst Tecnol Estudios Super Monterrey, Campus Ciudad Mexico,Campus Cuernavaca, Cuernavaca, Morelos, Mexico.
EM jnoguez@campus.ccm.itesm.mx; eespinos@campus.ccm.itesm.mx;
   framos@campus.mor.itesm.mx
RI Noguez, Julieta/AAD-9865-2020
CR ARBYLE M, 1976, GAZE MUTUAL GAZE
   Badler N.I, 2000, PARAMETERIZED ACTION, P256
   Cassell J, 2000, EMBODIED CONVERSATIONAL AGENTS, P1
   CASSELL J, IN PRESS AI MAGAZINE
   CASSELL J, IN PRESS MIT MEDIA L
   CASSELL J, ANIMATED CONVERSATIO
   Dean T., 1989, Computational Intelligence, V5, P142, DOI 10.1111/j.1467-8640.1989.tb00324.x
   MASSARO DW, 2000, DEV EVALUATING CONVE, P287
   PETRAZZINI B, 1999, COMMUNICACION ACM, V42
   POGGI I, 2000, PERFORMATIVE FACIAL, P155
   TURBAN E, 1999, INFORMATION TECHNOLO
   ZWEIG G, 1998, AAAI
NR 12
TC 0
Z9 0
U1 0
U2 1
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 0922-6389
EI 1879-8314
BN 1-58603-192-9
J9 FRONT ARTIF INTEL AP
PY 2001
VL 69
BP 733
EP 737
PG 5
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems; Computer Science
GA BS99P
UT WOS:000171608300141
DA 2022-08-02
ER

PT J
AU Schachner, T
   Gross, C
   Hasl, A
   Wangenheim, FV
   Kowatsch, T
AF Schachner, Theresa
   Gross, Christoph
   Hasl, Andrea
   Wangenheim, Florian, V
   Kowatsch, Tobias
TI Deliberative and Paternalistic Interaction Styles for Conversational
   Agents in Digital Health: Procedure and Validation Through a Web-Based
   Experiment
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Article
DE conversational agents; chatbots; human-computer interaction;
   physician-patient relationship; interaction styles; deliberative
   interaction; paternalistic interaction; digital health; chronic
   conditions; COPD
ID OBSTRUCTIVE PULMONARY-DISEASE; DOCTOR-PATIENT COMMUNICATION; INTERACTION
   ANALYSIS SYSTEM; DECISION-MAKING; PRIMARY-CARE; SELF-MANAGEMENT;
   PHYSICIAN; CONSULTATIONS; PREFERENCES; AUTONOMY
AB Background: Recent years have witnessed a constant increase in the number of people with chronic conditions requiring ongoing medical support in their everyday lives. However, global health systems are not adequately equipped for this extraordinarily time-consuming and cost-intensive development. Here, conversational agents (CAs) can offer easily scalable and ubiquitous support. Moreover, different aspects of CAs have not yet been sufficiently investigated to fully exploit their potential. One such trait is the interaction style between patients and CAs. In human-to-human settings, the interaction style is an imperative part of the interaction between patients and physicians. Patient-physician interaction is recognized as a critical success factor for patient satisfaction, treatment adherence, and subsequent treatment outcomes. However, so far, it remains effectively unknown how different interaction styles can be implemented into CA interactions and whether these styles are recognizable by users.
   Objective: The objective of this study was to develop an approach to reproducibly induce 2 specific interaction styles into CA-patient dialogs and subsequently test and validate them in a chronic health care context.
   Methods: On the basis of the Roter Interaction Analysis System and iterative evaluations by scientific experts and medical health care professionals, we identified 10 communication components that characterize the 2 developed interaction styles: deliberative and paternalistic interaction styles. These communication components were used to develop 2 CA variations, each representing one of the 2 interaction styles. We assessed them in a web-based between-subject experiment. The participants were asked to put themselves in the position of a patient with chronic obstructive pulmonary disease. These participants were randomly assigned to interact with one of the 2 CAs and subsequently asked to identify the respective interaction style. Chi-square test was used to assess the correct identification of the CA-patient interaction style.
   Results: A total of 88 individuals (42/88, 48% female; mean age 31.5 years, SD 10.1 years) fulfilled the inclusion criteria and participated in the web-based experiment. The participants in both the paternalistic and deliberative conditions correctly identified the underlying interaction styles of the CAs in more than 80% of the assessments (X-1(,8)8(2)=38.2; P<.001; phi coefficient r(phi)=0.68). The validation of the procedure was hence successful.
   Conclusions: We developed an approach that is tailored for a medical context to induce a paternalistic and deliberative interaction style into a written interaction between a patient and a CA. We successfully tested and validated the procedure in a web-based experiment involving 88 participants. Future research should implement and test this approach among actual patients with chronic diseases and compare the results in different medical conditions. This approach can further be used as a starting point to develop dynamic CAs that adapt their interaction styles to their users.
C1 [Schachner, Theresa; Gross, Christoph; Wangenheim, Florian, V; Kowatsch, Tobias] Swiss Fed Inst Technol, Dept Management Technol & Econ, Ctr Digital Hlth Intervent, WEV J 409,Weinbergstr 56-58, CH-8092 Zurich, Switzerland.
   [Hasl, Andrea] Univ Potsdam, Dept Educ Sci, Potsdam, Germany.
   [Hasl, Andrea] Int Max Planck Res Sch Life Course LIFE, Berlin, Germany.
   [Kowatsch, Tobias] Univ St Gallen, Inst Technol Management, Ctr Digital Hlth Intervent, St Gallen, Switzerland.
RP Gross, C (corresponding author), Swiss Fed Inst Technol, Dept Management Technol & Econ, Ctr Digital Hlth Intervent, WEV J 409,Weinbergstr 56-58, CH-8092 Zurich, Switzerland.
EM christophgross@ethz.ch
OI Schachner, Theresa/0000-0002-5505-8811; Kowatsch,
   Tobias/0000-0001-5939-4145; Hasl, Andrea/0000-0002-4945-2388
CR Angus D, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038014
   Bahari SF., 2012, JURNAL TEKNOLOGI, V52, P17, DOI [10.11113/jt.v52.134, DOI 10.11113/JT.V52.134]
   Bell E, 2018, RES METHODS
   Benbassat J, 1998, BEHAV MED, V24, P81, DOI 10.1080/08964289809596384
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore TW, 2010, INTERACT COMPUT, V22, P289, DOI 10.1016/j.intcom.2009.12.001
   BLANCHARD CG, 1988, SOC SCI MED, V27, P1139, DOI 10.1016/0277-9536(88)90343-7
   Borza LR, 2015, MED-SURG J, V119, P496
   Bourbeau J, 2003, ARCH INTERN MED, V163, P585, DOI 10.1001/archinte.163.5.585
   Cassell J, 2003, USER MODEL USER-ADAP, V13, P89, DOI 10.1023/A:1024026532471
   Cavaco Afonso, 2010, Int J Pharm Pract, V18, P141
   Cegala DJ, 1997, J HEALTH COMMUN, V2, P169, DOI 10.1080/108107397127743
   Charles C, 1997, SOC SCI MED, V44, P681, DOI 10.1016/S0277-9536(96)00221-3
   Chobanian AV, 2003, HYPERTENSION, V42, P1206, DOI 10.1161/01.HYP.0000107251.49515.c2
   Cohen J, 1988, STAT POWER ANAL BEHA
   Crutzen R, 2011, J ADOLESCENT HEALTH, V48, P514, DOI 10.1016/j.jadohealth.2010.09.002
   Detmar SB, 2001, JAMA-J AM MED ASSOC, V285, P1351, DOI 10.1001/jama.285.10.1351
   Di Blasi Z, 2001, LANCET, V357, P757, DOI 10.1016/S0140-6736(00)04169-6
   EMANUEL EJ, 1992, JAMA-J AM MED ASSOC, V267, P2221, DOI 10.1001/jama.267.16.2221
   Eysenbach G, 2004, J MED INTERNET RES, V6, P12, DOI 10.2196/jmir.6.3.e34
   Fadhil A., 2017, P 11 EAI INT C PERV, P261, DOI DOI 10.1145/3154862.3154914
   Fan FY, 2017, POWER ANAL EXPT DESI
   Fluckiger C, 2018, PSYCHOTHERAPY, V55, P316, DOI 10.1037/pst0000172
   Frey U, 2008, LANCET, V372, P1088, DOI 10.1016/S0140-6736(08)61450-6
   GIBSON PG, 1995, CHEST, V107, P1003, DOI 10.1378/chest.107.4.1003
   Han MK, 2017, LANCET RESP MED, V5, P619, DOI 10.1016/S2213-2600(17)30207-2
   Hauser-Ulrich S, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/15806
   Heritage J, 2006, ANNU REV SOCIOL, V32, P351, DOI 10.1146/annurev.soc.32.082905.093959
   Hofstede G, 1983, INT STUD MANAG ORG, V13, P46
   Hvidberg MF, 2016, SCAND J PUBLIC HEALT, V44, P462, DOI 10.1177/1403494816641553
   Kang S, 2015, INT C HUM AG INT 21, P105, DOI [10.1145/2814940.2814957, DOI 10.1145/2814940.2814957]
   KAPLAN SH, 1989, MED CARE, V27, pS110, DOI 10.1097/00005650-198903001-00010
   Kidd C., 2008, PROGRAM MEDIA ARTS S
   Kocaballi AB, 2019, J MED INTERNET RES, V21, DOI 10.2196/15360
   Kramer JN, 2020, ANN BEHAV MED, V54, P518, DOI 10.1093/abm/kaaa002
   Kvedar JC, 2016, NAT BIOTECHNOL, V34, P239, DOI 10.1038/nbt.3495
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Li SC, 2019, FRAT INTEGRITA STRUT, P1, DOI 10.3221/IGF-ESIS.47.01
   Loughlan C, 2014, J I HLTH ED, V33, P78, DOI [10.1080/03073289.1996.10805880, DOI 10.1080/03073289.1996.10805880]
   Mannino DM, 2007, LANCET, V370, P765, DOI 10.1016/S0140-6736(07)61380-4
   McDonnell M, 2019, INTERACT COMPUT, V31, P116, DOI 10.1093/iwc/iwz007
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Montori VM, 2006, HEALTH EXPECT, V9, P25, DOI 10.1111/j.1369-7625.2006.00359.x
   Offredy M, 2002, J ADV NURS, V40, P532, DOI 10.1046/j.1365-2648.2002.02410.x
   Offredy M, 2008, INT J NURS STUD, V45, P855, DOI 10.1016/j.ijnurstu.2007.01.014
   ONG LML, 1995, SOC SCI MED, V40, P903, DOI 10.1016/0277-9536(94)00155-M
   Ong LML, 1998, PSYCHO-ONCOL, V7, P387, DOI 10.1002/(SICI)1099-1611(1998090)7:5<387::AID-PON316>3.3.CO;2-7
   Postma DS, 2015, LANCET, V385, P899, DOI 10.1016/S0140-6736(14)60446-3
   Reach Gerard, 2013, Patient Prefer Adherence, V8, P15, DOI 10.2147/PPA.S55022
   Roter DL, 1997, JAMA-J AM MED ASSOC, V277, P350, DOI 10.1001/jama.277.4.350
   Say R, 2006, PATIENT EDUC COUNS, V60, P102, DOI 10.1016/j.pec.2005.02.003
   Schachner T, 2020, J MED INTERNET RES, V22, DOI 10.2196/20701
   Stone NJ, 2008, AM J CARDIOL, V102, p14L, DOI 10.1016/j.amjcard.2008.09.069
   Street RL, 2009, PATIENT EDUC COUNS, V74, P295, DOI 10.1016/j.pec.2008.11.015
   STREET RL, 1992, SOC SCI MED, V34, P1155, DOI 10.1016/0277-9536(92)90289-3
   STRULL WM, 1984, JAMA-J AM MED ASSOC, V252, P2990, DOI 10.1001/jama.252.21.2990
   ter Stal S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102409
   van den Bos GA, 1995, EUR J PUBLIC HEALTH, V5, P29, DOI DOI 10.1093/EURPUB/5.1.29
   van der Wal MHL, 2010, EUR HEART J, V31, P1486, DOI 10.1093/eurheartj/ehq091
   Wagner E H, 1998, Eff Clin Pract, V1, P2
   Williams S, 1998, FAM PRACT, V15, P480, DOI 10.1093/fampra/15.5.480
   Wise RA, 2007, AM J MED, V120, pS4, DOI 10.1016/j.amjmed.2007.04.007
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
NR 64
TC 1
Z9 1
U1 5
U2 9
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD JAN 29
PY 2021
VL 23
IS 1
AR e22919
DI 10.2196/22919
PG 13
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA QA0KK
UT WOS:000613139500003
PM 33512328
OA Green Accepted, Green Published, gold
DA 2022-08-02
ER

PT C
AU Katayama, S
   Mathur, A
   Van den Broeck, M
   Okoshi, T
   Nakazawa, J
   Kawsar, F
AF Katayama, Shin
   Mathur, Akhil
   Van den Broeck, Marc
   Okoshi, Tadashi
   Nakazawa, Jin
   Kawsar, Fahim
GP IEEE
TI Situation-Aware Emotion Regulation of Conversational Agents with Kinetic
   Earables
SO 2019 8TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT
   INTERACTION (ACII)
SE International Conference on Affective Computing and Intelligent
   Interaction
LA English
DT Proceedings Paper
CT 8th International Conference on Affective Computing and Intelligent
   Interaction (ACII)
CY SEP 03-06, 2019
CL Cambridge, ENGLAND
DE Conversational Agent; Context Awareness; Emotion Regulation; Earables
AB Conversational agents are increasingly becoming digital partners of our everyday computing experiences offering a variety of purposeful information and utility services. Although rich on competency, these agents are entirely oblivious to their users' situational and emotional context today and incapable of adjusting their interaction style and tone contextually. To this end, we present a mixed-method study that informs the design of a situation- and emotion-aware conversational agent for kinetic earables. We surveyed 280 users, and qualitatively interviewed 12 users to understand their expectation from a conversational agent in adapting the interaction style. Grounded on our findings, we develop a first-of-its-kind emotion regulator for a conversational agent on kinetic earable that dynamically adjusts its conversation style, tone, volume in response to users emotional, environmental, social and activity context gathered through speech prosody, motion signals and ambient sound. We describe these context models, the end-to-end system including a purpose-built kinetic earable and their real-world assessment. The experimental results demonstrate that our regulation mechanism invariably elicits better and affective user experience in comparison to baseline conditions in different real-world settings.
C1 [Katayama, Shin; Okoshi, Tadashi; Nakazawa, Jin] Keio Univ, Yokohama, Kanagawa, Japan.
   [Mathur, Akhil; Van den Broeck, Marc; Kawsar, Fahim] Nokia Bell Labs, Cambridge, England.
   [Kawsar, Fahim] Delft Univ Technol, Delft, Netherlands.
RP Katayama, S (corresponding author), Keio Univ, Yokohama, Kanagawa, Japan.
EM shinsan@ht.sfc.keio.ac.jp; slash@ht.sfc.keio.ac.jp;
   jin@ht.sfc.keio.ac.jp
FU Keio University; National Institute of Information and Communications
   Technology (NICT), Japan
FX This work was conducted at Nokia Bell Labs, Cambridge through a research
   collaboration with Keio University supported (in part) by National
   Institute of Information and Communications Technology (NICT), Japan
CR Arik Sercan O., 2017, ARXIV170207825CS
   Badshah AM, 2017, 2017 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P125
   Bertero Dario, 2016, P 2016 C EMPIRICAL M, P1042, DOI 10.18653/v1/D16-1110
   Betella A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148037
   Bin Siddique F, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P121, DOI 10.18653/v1/P17-4021
   Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980
   Gilbert, 2014, COMPUTERS CONVERSATI
   Han Kun, SPEECH EMOTION RECOG, P5
   Kawsar F, 2018, IEEE PERVAS COMPUT, V17, P83, DOI 10.1109/MPRV.2018.03367740
   Kuhn Michael J, 2015, US Patent, Patent No. [9,202,171, 92902171]
   Laput G, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P213, DOI 10.1145/3242587.3242609
   Latif Siddique, 2019, ARXIV190403833CSEESS
   Lee D, 2017, INT CONF BIG DATA, P437, DOI 10.1109/BIGCOMP.2017.7881752
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Lu H, 2009, MOBISYS'09: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P165
   Page Lindsay C, ARTIFICIALLY INTELLI, P12
   Paolacci Gabriele, 2010, JUDGM DECIS MAK, V5, P9
   Parise S, 2016, BUS HORIZONS, V59, P411, DOI 10.1016/j.bushor.2016.03.004
   Peng Liangying, 2012, P ACM INT MOB WEAR U, V2, P74
   Piyush N, 2016, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON SYSTEM MODELING & ADVANCEMENT IN RESEARCH TRENDS (SMART-2016), P322, DOI 10.1109/SYSMART.2016.7894543
   Riboni D, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P1, DOI 10.1145/2971648.2971691
   Roggen D, 2010, 2010 Seventh International Conference on Networked Sensing Systems (INSS 2010), P233, DOI 10.1109/INSS.2010.5573462
   Schroder M., 2001, 7 EUR C SPEECH COMM
   Schroder M, 2012, IEEE T AFFECT COMPUT, V3, P165, DOI 10.1109/T-AFFC.2011.34
   Shang L., 2015, ARXIV150302364CS
   Stork J. A., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P509, DOI 10.1109/ROMAN.2012.6343802
   Tielman ML, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0771-y
   van den Oord A., 2016, ARXIV160903499CS
   Wang Y, 2017, INT CON DISTR COMP S, P1704, DOI 10.1109/ICDCS.2017.229
NR 29
TC 0
Z9 0
U1 2
U2 4
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2156-8103
BN 978-1-7281-3888-6
J9 INT CONF AFFECT
PY 2019
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BO6TZ
UT WOS:000522220800008
DA 2022-08-02
ER

PT J
AU Hartholt, A
   Fast, E
   Reilly, A
   Whitcup, W
   Liewer, M
   Mozgai, S
AF Hartholt, Arno
   Fast, Ed
   Reilly, Adam
   Whitcup, Wendy
   Liewer, Matt
   Mozgai, Sharon
TI Multi-Platform Expansion of the Virtual Human Toolkit: Ubiquitous
   Conversational Agents
SO INTERNATIONAL JOURNAL OF SEMANTIC COMPUTING
LA English
DT Article; Proceedings Paper
CT 2nd IEEE International Conference on Artificial Intelligence and Virtual
   Reality (AIVR)
CY DEC 09-11, 2019
CL San Diego, CA
SP IEEE, IEEE Comp Soc, IEEE Tech Comm Semant Comp, Eurographics, ACM, ACM SIGAI, ACM SIGCHI, ACMG SIGGRAPH
DE Virtual humans; AI; VR; AR; XR; character animation; character modeling;
   distributed architectures; embodied conversational agents; interactive
   virtual agents
AB We present an extension of the Virtual Human Toolkit to include a range of computing platforms, including mobile, web, Virtual Reality (VR) and Augmented Reality (AR). The Toolkit uses a mix of in-house and commodity technologies to support audio-visual sensing, speech recognition, natural language processing, nonverbal behavior generation and realization, textto-speech generation and rendering. It has been extended to support computing platforms beyond Windows by leveraging microservices. The resulting framework maintains the modularity of the underlying architecture, allows re-use of both logic and content through cloud services, and is extensible by porting lightweight clients. We present the current state of the framework, discuss how we model and animate our characters, and offer lessons learned through several use cases, including expressive character animation in seated VR, shared space and navigation in room-scale VR, autonomous AI in mobile AR, and real-time user performance feedback leveraging mobile sensors in headset AR.
C1 [Hartholt, Arno; Fast, Ed; Reilly, Adam; Whitcup, Wendy; Liewer, Matt; Mozgai, Sharon] Univ Southern Calif, Inst Creat Technol, 12015 Waterfront Dr, Los Angeles, CA 90094 USA.
RP Hartholt, A (corresponding author), Univ Southern Calif, Inst Creat Technol, 12015 Waterfront Dr, Los Angeles, CA 90094 USA.
EM hartholt@ict.usc.edu; fast@ict.usc.edu; reilly@ict.usc.edu;
   whitcup@ict.usc.edu; liewer@ict.usc.edu; mozgai@ict.usc.edu
FU U.S. Army Research Laboratory (ARL) [W911NF-14-D-0005]; USC ICT; Dan
   Marino Foundation; Magic Leap; CableLabs
FX We would like to thank all of our collaborators and sponsors at USC ICT,
   the Dan Marino Foundation, Magic Leap and CableLabs. Part of the efforts
   depicted were sponsored by the U.S. Army Research Laboratory (ARL) under
   contract number W911NF-14-D-0005. The content of the information does
   not necessarily reflect the position or the policy of the Government,
   and no official endorsement should be inferred.
CR Anderson Keith, 2013, Advances in Computer Entertainment. 10th International Conference, ACE 2013. Proceedings: LNCS 8253, P476, DOI 10.1007/978-3-319-03161-3_35
   Avramova V, 2017, LECT NOTES ARTIF INT, V10498, P25, DOI 10.1007/978-3-319-67401-8_3
   Bacca J, 2014, EDUC TECHNOL SOC, V17, P133
   Balalaie A, 2016, IEEE SOFTWARE, V33, P42, DOI 10.1109/MS.2016.64
   Bickmore T., 2013, PAT ED COUNSEL, V92, P6
   Bickmore TW, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5239
   Burke SL, 2018, J AUTISM DEV DISORD, V48, P905, DOI 10.1007/s10803-017-3374-z
   Cafaro A, 2017, LECT NOTES ARTIF INT, V10498, P73, DOI 10.1007/978-3-319-67401-8_8
   Callejas Z, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P93
   Debevec Paul, 2012, SIGGRAPH ASIA
   Dragoni N, 2017, PRESENT ULTERIOR SOF, P195, DOI [10.1007/978-3-319-67425-4_12, DOI 10.1007/978-3-319-67425-4_12]
   Ebert C, 2016, IEEE SOFTWARE, V33, P94, DOI 10.1109/MS.2016.68
   Gordon C., 2019, JOINT P ACM IUI 2019
   Habgood MPJ, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P371, DOI 10.1109/VR.2018.8446130
   Hartholt Arno, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P368, DOI 10.1007/978-3-642-40415-3_33
   Hartholt A, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P308, DOI 10.1109/AIVR46125.2019.00072
   Hartholt A, 2019, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT INTERACTION (HAI'19), P205, DOI 10.1145/3349537.3352766
   Howarth PA, 1999, APPL ERGON, V30, P39, DOI 10.1016/S0003-6870(98)00041-6
   HUGGINSDAINES D, 2006, IEEE INT C AC SPEECH
   Hyde R., 2009, FALLACY PREMATURE OP
   Jaramillo D, 2016, IEEE SOUTHEASTCON
   Kemeny A., 2017, ENG REAL VIRTUAL REA, V2017, P48, DOI DOI 10.2352/ISSN.2470-1173.2017.3.ERVR-097
   Kopp S, 2006, LECT NOTES ARTIF INT, V4133, P205
   Lee J, 2006, LECT NOTES ARTIF INT, V4133, P243
   Lee J, 2007, LECT NOTES ARTIF INT, V4722, P296
   Leuski A, 2011, AI MAG, V32, P42, DOI 10.1609/aimag.v32i2.2347
   Lewis J., 2014, MICROSERVICES
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   McKeown G, 2010, IEEE INT CON MULTI, P1079, DOI 10.1109/ICME.2010.5583006
   McVeigh-Schultz J, 2018, DIS 2018: COMPANION PUBLICATION OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P289
   Miller MR, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216290
   Mozgai S, 2017, LECT NOTES ARTIF INT, V10498, P283, DOI 10.1007/978-3-319-67401-8_37
   Rizzo A. A., 2016, J PAIN MANAG, V9, P311
   Rizzo A, 2015, J CONTEMP PSYCHOTHER, V45, P255, DOI 10.1007/s10879-015-9306-3
   Scherer Stefan, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P455, DOI 10.1007/978-3-642-33197-8_47
   Schuster M, 2010, LECT NOTES ARTIF INT, V6230, P8, DOI 10.1007/978-3-642-15246-7_3
   Shapiro A., 2011, INT C MOT GAM, P98, DOI DOI 10.1007/978-3-642-25090-3_9
   Shapiro A, 2014, COMPUT ANIMAT VIRT W, V25, P201, DOI 10.1002/cav.1579
   Sharma S, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI), VOL 2, P187, DOI 10.1109/CSCI.2014.116
   Shi H., 1996, THESIS
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Snyder B., 2011, ACTIVEMQ IN ACTION, V47
   Sohn J, 1999, IEEE SIGNAL PROC LET, V6, P1, DOI 10.1109/97.736233
   Swartout W., 2016, P 29 INT FLOR ART IN, P491
   Thiebaux M., 2008, P 7 INT C AUTONOMOUS, V1, P151
NR 45
TC 1
Z9 1
U1 1
U2 7
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 1793-351X
EI 1793-7108
J9 INT J SEMANT COMPUT
JI Int. J. Semant. Comput.
PD SEP
PY 2020
VL 14
IS 3
BP 315
EP 332
DI 10.1142/S1793351X20400127
PG 18
WC Computer Science, Artificial Intelligence
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA OP0BO
UT WOS:000587740600002
DA 2022-08-02
ER

PT J
AU Berube, C
   Schachner, T
   Keller, R
   Fleisch, E
   Wangenheim, FV
   Barata, F
   Kowatsch, T
AF Berube, Caterina
   Schachner, Theresa
   Keller, Roman
   Fleisch, Elgar
   Wangenheim, Florian, V
   Barata, Filipe
   Kowatsch, Tobias
TI Voice-Based Conversational Agents for the Prevention and Management of
   Chronic and Mental Health Conditions: Systematic Literature Review
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Review
DE voice; speech; delivery of health care; noncommunicable diseases;
   conversational agents; mobile phone; smart speaker; monitoring; support;
   chronic disease; mental health; systematic literature review
ID THERAPEUTIC ALLIANCE; WORKING ALLIANCE; DIALOGUE SYSTEMS; PATIENT;
   INTERVENTIONS; ASSISTANTS; MACHINES; SYMPTOMS; ALEXA; APPS
AB Background: Chronic and mental health conditions are increasingly prevalent worldwide. As devices in our everyday lives offer more and more voice-based self-service, voice-based conversational agents (VCAs) have the potential to support the prevention and management of these conditions in a scalable manner. However, evidence on VCAs dedicated to the prevention and management of chronic and mental health conditions is unclear.
   Objective: This study provides a better understanding of the current methods used in the evaluation of health interventions for the prevention and management of chronic and mental health conditions delivered through VCAs.
   Methods: We conducted a systematic literature review using PubMed MEDLINE, Embase, PsycINFO, Scopus, and Web of Science databases. We included primary research involving the prevention or management of chronic or mental health conditions through a VCA and reporting an empirical evaluation of the system either in terms of system accuracy, technology acceptance, or both. A total of 2 independent reviewers conducted the screening and data extraction, and agreement between them was measured using Cohen kappa. A narrative approach was used to synthesize the selected records.
   Results: Of 7170 prescreened papers, 12 met the inclusion criteria. All studies were nonexperimental. The VCAs provided behavioral support (n=5), health monitoring services (n=3), or both (n=4). The interventions were delivered via smartphones (n=5), tablets (n=2), or smart speakers (n=3). In 2 cases, no device was specified. A total of 3 VCAs targeted cancer, whereas 2 VCAs targeted diabetes and heart failure. The other VCAs targeted hearing impairment, asthma, Parkinson disease, dementia, autism, intellectual disability, and depression. The majority of the studies (n=7) assessed technology acceptance, but only few studies (n=3) used validated instruments. Half of the studies (n=6) reported either performance measures on speech recognition or on the ability of VCAs to respond to health-related queries. Only a minority of the studies (n=2) reported behavioral measures or a measure of attitudes toward intervention-targeted health behavior. Moreover, only a minority of studies (n=4) reported controlling for participants' previous experience with technology. Finally, risk bias varied markedly.
   Conclusions: The heterogeneity in the methods, the limited number of studies identified, and the high risk of bias show that research on VCAs for chronic and mental health conditions is still in its infancy. Although the results of system accuracy and technology acceptance are encouraging, there is still a need to establish more conclusive evidence on the efficacy of VCAs for the prevention and management of chronic and mental health conditions, both in absolute terms and in comparison with standard health care.
C1 [Berube, Caterina; Schachner, Theresa; Fleisch, Elgar; Wangenheim, Florian, V; Barata, Filipe; Kowatsch, Tobias] Swiss Fed Inst Technol, Dept Management Technol & Econ, Ctr Digital Hlth Intervent, WEV G 214,Weinbergstr 56-58, CH-8092 Zurich, Switzerland.
   [Keller, Roman; Fleisch, Elgar; Wangenheim, Florian, V; Kowatsch, Tobias] Singapore ETH Ctr, Future Hlth Technol Programme, Campus Res Excellence & Technol Enterprise CREATE, Singapore, Singapore.
   [Fleisch, Elgar; Kowatsch, Tobias] Univ St Gallen, Inst Technol Management, Ctr Digital Hlth Intervent, St Gallen, Switzerland.
   [Kowatsch, Tobias] Natl Univ Singapore, Saw Swee Hock Sch Publ Hlth, Singapore, Singapore.
RP Berube, C (corresponding author), Swiss Fed Inst Technol, Dept Management Technol & Econ, Ctr Digital Hlth Intervent, WEV G 214,Weinbergstr 56-58, CH-8092 Zurich, Switzerland.
EM berubec@ethz.ch
RI Barata, Filipe/AAB-7802-2021
OI Barata, Filipe/0000-0002-3905-2380; Fleisch, Elgar/0000-0002-4842-1117;
   Schachner, Theresa/0000-0002-5505-8811; Keller,
   Roman/0000-0003-4810-4944; Berube, Caterina/0000-0001-5247-8485
FU National Research Foundation, Prime Minister's Office, Singapore, under
   its Campus for Research Excellence and Technological Enterprise
   Programme; CSS Insurance (Switzerland)
FX This work was supported by the National Research Foundation, Prime
   Minister's Office, Singapore, under its Campus for Research Excellence
   and Technological Enterprise Programme and by the CSS Insurance
   (Switzerland).
CR Abd-Alrazaq A, 2020, J MED INTERNET RES, V22, DOI 10.2196/18301
   Altman D.G., 1991, PRACTICAL STAT MED R
   Amith Muhammad, 2020, AMIA Jt Summits Transl Sci Proc, V2020, P43
   Amith Muhammad, 2019, Stud Health Technol Inform, V257, P17
   Ammari T, 2019, ACM T COMPUT-HUM INT, V26, DOI 10.1145/3311956
   [Anonymous], 2018, Library Hi Tech News, V35, P9, DOI 10.1108/LHTN-11-2017-0083
   [Anonymous], HUMAN DEV DATA 1990
   [Anonymous], Guide your patients to the right care
   [Anonymous], DESIGNING CONVERSATI
   [Anonymous], 2017, NEARL HALF AM US DIG
   [Anonymous], 2020, WORLD HLTH STAT 2020, P1
   [Anonymous], MOBILECOACH
   [Anonymous], 2019, DOCUMENT NUMBER WHOM
   [Anonymous], SUGARPOD
   [Anonymous], Fact sheets: chronic diseases
   [Anonymous], 2019, FACT SHEETS MENT DIS
   Balasuriya SS, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P102, DOI 10.1145/3292147.3292161
   Pulido MLB, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113213
   Bendig E, 2019, VERHALTENSTHERAPIE, V29, P266, DOI 10.1159/000499492
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore TW, 2018, J MED INTERNET RES, V20, DOI 10.2196/11510
   Bickmore TW, 2011, J BIOMED INFORM, V44, P183, DOI 10.1016/j.jbi.2010.12.006
   Booth A, 2012, SYST REV-LONDON, V1, DOI 10.1186/2046-4053-1-2
   Boyd M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194811
   Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158
   Cheng A, 2018, CONSUM COMM NETWORK
   Chung AE, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/mhealth.9705
   Chung HJ, 2017, COMPUTER, V50, P100, DOI 10.1109/MC.2017.3571053
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Falkenstrom F, 2015, PSYCHOL ASSESSMENT, V27, P169, DOI 10.1037/pas0000038
   Filler A, 2015, WIREL TELECOMM SYMP
   Fogg B. J., 1998, CHI 98. Human Factors in Computing Systems. CHI 98 Conference Proceedings, P225
   Galescu L, 2009, P IEEE INT C BIBM 20, DOI [10.1109/bibmw.2009.5332111, DOI 10.1109/BIBMW.2009.5332111]
   Google Cho E. Hey, 2019, P 2019 CHI C HUM FAC, DOI [10.1145/3290605.3300488, DOI 10.1145/3290605.3300488]
   Hamine Saee, 2015, J Med Internet Res, V17, pe52, DOI 10.2196/jmir.3951
   Hoermann S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7023
   Holden RJ, 2010, J BIOMED INFORM, V43, P159, DOI 10.1016/j.jbi.2009.07.002
   HORVATH AO, 1993, J CONSULT CLIN PSYCH, V61, P561, DOI 10.1037/0022-006X.61.4.561
   Hoy Matthew B., 2018, Medical Reference Services Quarterly, V37, P81, DOI 10.1080/02763869.2018.1404391
   Ireland D, 2016, STUD HEALTH TECHNOL, V227, P55, DOI 10.3233/978-1-61499-666-8-55
   Kadariya D, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP 2019), P138, DOI [10.1109/SMARTCOMP.2019.00043, 10.1109/smartcomp.2019.00043]
   Kim K, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P17, DOI 10.1109/AIVR46125.2019.00013
   Kinsella, 2019, VOICE ASSISTANT CONS
   Kocaballi A. Baki, 2018, P 32 INT BCS HUM COM, DOI 10.14236/ewic/HCI2018.21
   Kvedar JC, 2016, NAT BIOTECHNOL, V34, P239, DOI 10.1038/nbt.3495
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Leach Matthew J, 2005, Complement Ther Clin Pract, V11, P262, DOI 10.1016/j.ctcp.2005.05.005
   Liu BJ, 2018, CYBERPSYCH BEH SOC N, V21, P625, DOI 10.1089/cyber.2018.0110
   Lobo J, 2017, INT J E-HEALTH MED C, V8, P21, DOI 10.4018/IJEHMC.2017100102
   Lopez G, 2017, ADV HUMAN FACTORS SY, pA50
   Maher CA, 2014, J MED INTERNET RES, V16, DOI 10.2196/jmir.2952
   Martin DJ, 2000, J CONSULT CLIN PSYCH, V68, P438, DOI 10.1037//0022-006X.68.3.438
   Masina F, 2020, J MED INTERNET RES, V22, DOI 10.2196/18431
   Mead N, 2002, PATIENT EDUC COUNS, V48, P51, DOI 10.1016/S0738-3991(02)00099-X
   MFMER, SKILLS MAYO CLIN
   Miner AS, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00746
   Miner AS, 2017, JAMA-J AM MED ASSOC, V318, P1217, DOI 10.1001/jama.2017.14151
   Miner AS, 2016, JAMA INTERN MED, V176, P619, DOI 10.1001/jamainternmed.2016.0400
   Moher D., 2009, PLOS MED, V6
   Moorthy AE, 2015, INT J HUM-COMPUT INT, V31, P307, DOI 10.1080/10447318.2014.986642
   Moorthy AE, 2014, LECT NOTES COMPUT SC, V8522, P324, DOI 10.1007/978-3-319-07863-2_32
   Mota NB, 2017, NPJ SCHIZOPHR, V3, DOI 10.1038/s41537-017-0019-3
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Ooster J, 2019, P INT 2019, DOI 10.21437/interspeech.2019-2118
   Pradhan A, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3373759
   Pradhan A, 2018, PORTL INT CONF MANAG, DOI 10.1145/3173574.3174033
   Rehman UU, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072216
   Reis A, 2018, 2018 2 INT C TECHN I, DOI [10.1109/tishw.2018.8559503, DOI 10.1109/TISHW.2018.8559503]
   Ruegger D., 2017, TEXT BASED HEALTHCAR
   Schachner T, 2020, J MED INTERNET RES, V22, DOI 10.2196/20701
   Schulz KF, 2010, PLOS MED, V7, DOI 10.1371/journal.pmed.1000251
   Schwartzman CM, 2020, PRACT INNOV, V5, P128, DOI [10.1037/pri0000120, DOI 10.1037/PRI0000120]
   Sezgin E, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00332-0
   Sezgin E, 2020, TRANSL BEHAV MED, V10, P606, DOI 10.1093/tbm/ibz141
   Tanaka H, 2017, IEEE J TRANSL ENG HE, V5, DOI 10.1109/JTEHM.2017.2752152
   Taylor-Pashow KML, 2019, SOLVENT EXTR ION EXC, V37, P1, DOI 10.1080/07366299.2019.1592924
   Venkatesh V, 2012, MIS QUART, V36, P157
   Wang JY, 2019, BMC PSYCHIATRY, V19, DOI 10.1186/s12888-019-2300-7
   Wang K, 2018, J PSYCHIATR RES, V107, P73, DOI 10.1016/j.jpsychires.2018.10.006
   Watson J, ANN S COMP HUM INT P, DOI [10.1145/3341215.3356308, DOI 10.1145/3341215.3356308]
   WHO, 2018, CLASS DIG HLTH INT V
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
NR 82
TC 11
Z9 11
U1 2
U2 19
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD MAR 29
PY 2021
VL 23
IS 3
AR e25933
DI 10.2196/25933
PG 14
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA RH4SF
UT WOS:000636209800004
PM 33658174
OA Green Accepted, Green Published, gold
DA 2022-08-02
ER

PT C
AU Griol, D
   Sanchez-Pi, N
   Carbo, J
   Molina, JM
AF Griol, David
   Sanchez-Pi, Nayat
   Carbo, Javier
   Molina, Jose M.
BE DeCarvalho, APD
   RidriguezGonzalez, S
   Santana, JFD
   Rodriguez, JMC
TI An Architecture to Provide Context-Aware Services by Means of
   Conversational Agents
SO DISTRIBUTED COMPUTING AND ARTIFICIAL INTELLIGENCE
SE Advances in Intelligent and Soft Computing
LA English
DT Proceedings Paper
CT 7th International Symposium on Distributed Computing and Artificial
   Intelligence
CY SEP 07-10, 2010
CL Polytech Univ Valencia, Valencia, SPAIN
SP Univ Salamanca, Biomedicine Intelligent Syst & Educ Technol Res Grp
HO Polytech Univ Valencia
AB In human-human interaction, a great deal of information is conveyed without explicit communication. This context information characterizes the situation of the different entities involved in the communication process (users, place, environment and computational objects). In this paper, we present an agent-based architecture that incorporates this valuable information to provide the most adapted service to the user. One of the main characteristics of our proposal is the incorporation of conversational agents handling different domains and adapted taking into account the different users requirements and preferences by means of a context manager. This way, we ensure a natural communication between the user and the system to provide a personalized service. The implementation of our proposed architecture to develop and evaluate a context-aware railway information system is also described.
C1 [Griol, David; Sanchez-Pi, Nayat; Carbo, Javier; Molina, Jose M.] Univ Carlos III Madrid, Dept Comp Sci, Grp Appl Artificial Intelligence GIAA, E-28903 Getafe, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Grp Appl Artificial Intelligence GIAA, E-28903 Getafe, Spain.
EM david.griol@uc3m.es; nayat.sanchez@uc3m.es; javier.carbo@uc3m.es;
   josemanuel.molina@uc3m.es
RI Sanchez-Pi, Nayat/K-2049-2015; Griol, David/L-1258-2014; Carbo,
   Javier/ABB-4694-2020; Molina, JOSE/B-1956-2008
OI Sanchez-Pi, Nayat/0000-0002-5037-9974; Griol, David/0000-0001-6266-5321;
   Carbo, Javier/0000-0001-7794-3398; Molina, JOSE/0000-0002-7484-7357
CR Bajo J, 2008, ENG APPL ARTIF INTEL, V21, P769, DOI 10.1016/j.engappai.2007.07.006
   Griol D., 2007, P 8 SIGDIAL WORKSH D, P39
   Griol D, 2008, SPEECH COMMUN, V50, P666, DOI 10.1016/j.specom.2008.04.001
   Hong JY, 2009, EXPERT SYST APPL, V36, P8509, DOI 10.1016/j.eswa.2008.10.071
   McTear M. F., 2004, SPOKEN DIALOGUE TECH
   NIETOCARVAJAL I, 2004, P EUC 2004, P528
   Sanchez-Pi N, 2007, SNPD 2007: EIGHTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, VOL 3, PROCEEDINGS, P694, DOI 10.1109/SNPD.2007.394
   Seneff S., 2007, P INT WORKSH IMPR MO, P1
NR 8
TC 8
Z9 8
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 1867-5662
BN 978-3-642-14882-8
J9 ADV INTEL SOFT COMPU
PY 2010
VL 79
BP 275
EP 282
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BUI38
UT WOS:000289448400036
DA 2022-08-02
ER

PT J
AU Hocking, J
   Oster, C
   Maeder, A
AF Hocking, Judith
   Oster, Candice
   Maeder, Anthony
TI Use of conversational agents in rehabilitation following brain injury,
   disease, or stroke: a scoping review protocol
SO JBI EVIDENCE SYNTHESIS
LA English
DT Review
DE brain injury; conversational agent; dementia; Parkinson disease; stroke
ID MOTIVATION; PEOPLE; HELP
AB Objective: The objective of the review is to identify peer-reviewed literature reporting the design and use of conversational agents in rehabilitation for adults with brain injury, disease, or stroke. Introduction: Rehabilitation for adults with brain injury, disease, or stroke provides goal-directed care to overcome functional impairments and reduced independence. However, recovery can be impacted due to rehabilitation being time-limited. New therapy approaches supporting rehabilitation and self-management are warranted. Conversational agents provide personal computer-based dialogues that can be designed to meet the specific needs of clients. Interacting with a conversational agent may support rehabilitation for clients with brain injury, disease, or stroke. Inclusion criteria: Studies that report the design or use of conversational agents in rehabilitation for adults aged over 18 years with brain injury, disease, or stroke will be considered for inclusion. Research settings may include hospitals, community settings, and homes. Eligible study types are peer-reviewed research protocols, prototype development papers, and pilot and clinical trials. Methods: Primary sourcing databases (MEDLINE [Ovid], Scopus, ProQuest [all databases], Web of Science) and gray literature sources will be searched with no date limitations. Only studies published in English will be considered due to feasibility limitations. Two independent reviewers will screen the retrieved papers by title and abstract, and the selected papers by full-text review. Any disagreements will be resolved by an objective arbitrator. Data to be extracted and analyzed from included papers will include details of participants, concept, context, and the study design. Results will be presented narratively and in tabular format.
C1 [Hocking, Judith; Maeder, Anthony] Flinders Univ S Australia, Coll Nursing & Hlth Sci, Flinders Digital Hlth Res Ctr, Adelaide, SA, Australia.
   [Oster, Candice] Flinders Univ S Australia, Coll Med & Publ Hlth, Adelaide, SA, Australia.
RP Hocking, J (corresponding author), Flinders Univ S Australia, Coll Nursing & Hlth Sci, Flinders Digital Hlth Res Ctr, Adelaide, SA, Australia.
EM judith.hocking@flinders.edu.au
FU Australian Research Council Industrial Transformation Research Hub for
   Digital Enhanced Living [IH170100013]
FX D JH is a PhD scholarship recipient from the Australian Research Council
   Industrial Transformation Research Hub for Digital Enhanced Living
   (IH170100013). The results of this review will not affect JH's PhD
   scholarship.
CR Albright G, 2012, GAMES HEALTH J, V1, P21, DOI 10.1089/g4h.2011.0003
   Bickmore TW, 2018, J MED INTERNET RES, V20, DOI 10.2196/11510
   Bickmore TW, 2011, J BIOMED INFORM, V44, P183, DOI 10.1016/j.jbi.2010.12.006
   Brandtzaeg PB., 2018, INTERACTIONS, V25, P38, DOI 10.1145/3236669
   Caeyenberghs K, 2018, NEUROREHAB NEURAL RE, V32, P99, DOI 10.1177/1545968317753076
   Chatbots.org, 2020, 161 HUM CONV AI SYN
   Chervinsky AB, 1998, ARCH CLIN NEUROPSYCH, V13, P433, DOI 10.1016/S0887-6177(97)00016-4
   Cole-Lewis Heather, 2019, JMIR Form Res, V3, pe14052, DOI 10.2196/14052
   Fadhil A, 2019, METHOD INFORM MED, V58, P9, DOI 10.1055/s-0039-1688757
   Gaffney H, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/14166
   Hoermann S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7023
   Huckans M, 2013, NEUROPSYCHOL REV, V23, P63, DOI 10.1007/s11065-013-9230-9
   Ireland D, 2016, STUD HEALTH TECHNOL, V227, P55, DOI 10.3233/978-1-61499-666-8-55
   Ireland D, 2015, STUD HEALTH TECHNOL, V214, P128, DOI 10.3233/978-1-61499-558-6-128
   Isern D, 2016, J MED SYST, V40, DOI 10.1007/s10916-015-0376-2
   Kusec A, 2019, DISABIL REHABIL, V41, P2343, DOI 10.1080/09638288.2018.1467504
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Macedo P, 2019, PROCEDIA COMPUT SCI, V160, P402, DOI 10.1016/j.procs.2019.11.074
   Maeda H., 2019, HEALTHC APPL 10 INT, P353
   Nikitina S., 2018, P 1 INT WORKSH SOFTW, P52
   Peters M.D.J., 2021, JBI MANUAL EVIDENCE, V10, DOI 10.46658/JBIMES-20-12
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Sacco RL, 2013, STROKE, V44, P2064, DOI 10.1161/STR.0b013e318296aeca
   Smit EB, 2018, EUR GERIATR MED, V9, P71, DOI 10.1007/s41999-017-0011-5
   Thoma MV, 2018, BMC GERIATR, V18, DOI 10.1186/s12877-018-0865-5
   Toronto ABI Network, 2020, DEF ABI PROF
   Tricco AC, 2018, ANN INTERN MED, V169, P467, DOI 10.7326/M18-0850
   Tsai YT, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1207, DOI 10.1109/HPCC/SmartCity/DSS.2018.00203
   Turner-Stokes L, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD004170.pub3
NR 29
TC 0
Z9 0
U1 0
U2 3
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
EI 2689-8381
J9 JBI EVID SYNTH
JI JBI Evid. Synth.
PD JUN
PY 2021
VL 19
IS 6
BP 1369
EP 1381
DI 10.11124/JBIES-20-00225
PG 13
WC Health Care Sciences & Services
WE Emerging Sources Citation Index (ESCI)
SC Health Care Sciences & Services
GA UQ7NP
UT WOS:000696247900008
PM 33323775
OA Bronze
DA 2022-08-02
ER

PT C
AU Li, CY
   Ortega, D
   Vath, D
   Lux, F
   Vanderlyn, L
   Schmidt, M
   Neumann, M
   Volkel, M
   Denisov, P
   Jenne, S
   Kacarevic, Z
   Vu, NT
AF Li, Chia-Yu
   Ortega, Daniel
   Vaeth, Dirk
   Lux, Florian
   Vanderlyn, Lindsey
   Schmidt, Maximilian
   Neumann, Michael
   Voelkel, Moritz
   Denisov, Pavel
   Jenne, Sabrina
   Kacarevic, Zorica
   Ngoc Thang Vu
GP Assoc Computat Linguist
TI ADVISER: A Toolkit for Developing Multi modal, Multi domain and Socially
   engaged Conversational Agents
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020): SYSTEM DEMONSTRATIONS
LA English
DT Proceedings Paper
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB We present ADVISER(1)- an open-source, multi-domain dialog system toolkit that enables the development of multi-modal (incorporating speech, text and vision), socially-engaged (e.g. emotion recognition, engagement level prediction and backchanneling) conversational agents. The final Python-based implementation of our toolkit is flexible, easy to use, and easy to extend not only for technically experienced users, such as machine learning researchers, but also for less technically experienced users, such as linguists or cognitive scientists, thereby providing a flexible platform for collaborative research.
C1 [Li, Chia-Yu; Ortega, Daniel; Vaeth, Dirk; Lux, Florian; Vanderlyn, Lindsey; Schmidt, Maximilian; Neumann, Michael; Voelkel, Moritz; Denisov, Pavel; Jenne, Sabrina; Kacarevic, Zorica; Ngoc Thang Vu] Univ Stuttgart, Inst Nat Language Proc IMS, Stuttgart, Germany.
RP Vu, NT (corresponding author), Univ Stuttgart, Inst Nat Language Proc IMS, Stuttgart, Germany.
EM thangvu@ims.uni-stuttgart.de
CR Baltrusaitis Tadas, 2018, OPENFACE 2 0 FACIAL
   Baumann Timo, 2012, NAACL HLT WORKSH FUT
   Bobrow Daniel G., 1977, ARTIFICIAL INTELLIGE
   Bohus D, 2009, COMPUT SPEECH LANG, V23, P332, DOI 10.1016/j.csl.2008.10.001
   Busso Carlos, 2008, LANGUAGE RESOURCES E, V42
   Clark H. H, 2004, J MEMORY LANGUAGE
   Curry Amanda Cercas, 2018, 1 P AL PRIZ
   De Mori Renato, 2008, IEEE SIGNAL PROCESSI
   Denisov Pavel, 2019, STUDIENTEXTE SPRACHK, P170
   Forbes-Riley K., 2012, HUMAN LANGUAGE TECHN, P91
   Foster ME, 2016, LECT NOTES ARTIF INT, V9979, P753, DOI 10.1007/978-3-319-47437-3_74
   Goodwin Charles, 1986, J HUMAN STUDIES
   Hayashi Tomoki, 2019, ESPNET TTS UNIFIED R
   Ito Keith, 2017, LJ SPEECH DATASET
   Jalobeanu Mihai, 2017, P 19 ACM INT C MULT, P493, DOI [10.1145/3136755.3143021, DOI 10.1145/3136755.3143021]
   Karita Shigeki, 2019, IEEE AUT SPEECH REC
   Lee SJ, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P64
   LI ZH, 2019, COMPUT LINGUIST, V22, pS382, DOI DOI 10.1007/S10586-018-2408-4
   Lison P, 2016, PROCEEDINGS OF 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL-2016): SYSTEM DEMONSTRATIONS, P67
   McTear M., 2016, CONVERSATIONAL INTER, V6
   Neumann M, 2017, INTERSPEECH, P1263, DOI 10.21437/Interspeech.2017-917
   Ngoc Thang Vu, 2019, P 20 ANN SIGDIAL M D, P62
   Niu XS, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P599, DOI 10.1145/3242969.3264982
   Ortega D, 2020, INT CONF ACOUST SPEE, P8064, DOI 10.1109/ICASSP40776.2020.9054223
   Ortega D, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P93
   Ren Y., 2019, ADV NEURAL INF PROCE, V32, P3165
   Schatzmann Jost, 2007, P NAACL
   Schaul T., 2015, P ICLR
   Schuller B, 2009, IMAGE VISION COMPUT, V27, P1760, DOI 10.1016/j.imavis.2009.02.013
   Skantze G, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P67, DOI 10.1145/2818346.2820749
   Ultes Stefan, 2017, P ACL
   Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489
   Wagner Johannes, 2013, P 21 ACM INT C MULT
   Wang Ziyu, 2016, P ICML
   Watanabe S, 2018, INTERSPEECH, P2207, DOI 10.21437/Interspeech.2018-1456
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Yamamoto R, 2020, INT CONF ACOUST SPEE, P6199, DOI 10.1109/ICASSP40776.2020.9053795
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 38
TC 1
Z9 1
U1 0
U2 4
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-952148-04-0
PY 2020
BP 279
EP 286
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Linguistics
GA BP7XC
UT WOS:000563368700031
DA 2022-08-02
ER

PT J
AU Bibault, JE
   Chaix, B
   Nectoux, P
   Pienkowski, A
   Guillemase, A
   Brouard, B
AF Bibault, Jean-Emmanuel
   Chaix, Benjamin
   Nectoux, Pierre
   Pienkowski, Arthur
   Guillemase, Arthur
   Brouard, Benoit
TI Healthcare ex Machina: Are conversational agents ready for prime time in
   oncology?
SO CLINICAL AND TRANSLATIONAL RADIATION ONCOLOGY
LA English
DT Review
DE Conversational agent; Digital assistant; Chatbot; Oncology; Cancer
ID MENTAL-HEALTH; CANCER
AB Chatbots, also known as conversational agents or digital assistants, are artificial intelligence-driven software programs designed to interact with people in a conversational manner. They are often used for user-friendly customer-service triaging. In healthcare, chatbots can create bidirectional information exchange with patients, which could be leveraged for follow-up, screening, treatment adherence or data-collection. They can be deployed over various modalities, such as text-based services (text messaging, mobile applications, chat rooms) on any website or mobile applications, or audio services, such as Siri, Alexa, Cortana or Google Assistant. Potential applications are very promising, particularly in the field of oncology. In this review, we discuss the available publications and applications and the ongoing trials in that setting. (C) 2019 The Authors. Published by Elsevier B.V. on behalf of European Society for Radiotherapy and Oncology.
C1 [Bibault, Jean-Emmanuel] Hop Europeen Georges Pompidou, AP HP, Dept Radiat Oncol, Paris, France.
   [Chaix, Benjamin; Nectoux, Pierre; Pienkowski, Arthur; Guillemase, Arthur; Brouard, Benoit] Hop La Pitie Salpetriere, WeFight Inc, Inst Cerveau & Moelle Epiniere, Paris, France.
   [Chaix, Benjamin] ENT Dept, Montpellier, France.
   [Chaix, Benjamin] Univ Montpellier I, Hop Gui de Chauliac, Montpellier, France.
RP Bibault, JE (corresponding author), Hop Europeen Georges Pompidou, Radiat Oncol Dept, 20 Rue Leblanc, Paris, France.
EM jean-emmanuel.bibault@aphp.fr
OI Pienkowski, Arthur/0000-0003-2215-5452; Chaix,
   Benjamin/0000-0001-5934-9774; Bibault, Jean-Emmanuel/0000-0002-1728-6776
CR [Anonymous], ONL TAIL INT REL AG
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore T, 2006, J BIOMED INFORM, V39, P556, DOI 10.1016/j.jbi.2005.12.004
   Bickmore TW, RELATIONAL AGENTS EF
   Brouard B, 2016, ANN MED, V48, P509, DOI 10.1080/07853890.2016.1195010
   ClinicalTrials.gov, STUD BUDD ECA ONC TR
   Dunscombe P, 2014, RADIOTHER ONCOL, V112, P165, DOI 10.1016/j.radonc.2014.08.032
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Goldstein IM, 2017, JAMA ONCOL, V3, P1303, DOI 10.1001/jamaoncol.2016.6413
   Arraras JI, 2010, EUR J CANCER, V46, P2726, DOI 10.1016/j.ejca.2010.06.118
   Kadan-Lottick NS, 2005, CANCER-AM CANCER SOC, V104, P2872, DOI 10.1002/cncr.21532
   Lievens Y, 2014, RADIOTHER ONCOL, V112, P178, DOI 10.1016/j.radonc.2014.08.034
   Liu BJ, 2018, CYBERPSYCH BEH SOC N, V21, P625, DOI 10.1089/cyber.2018.0110
   Ly KH, 2017, INTERNET INTERV, V10, P39, DOI 10.1016/j.invent.2017.10.002
   Miner AS, 2016, JAMA INTERN MED, V176, P619, DOI 10.1001/jamainternmed.2016.0400
   Mitchell AJ, 2011, LANCET ONCOL, V12, P160, DOI 10.1016/S1470-2045(11)70002-X
   Morris RR, 2018, J MED INTERNET RES, V20, DOI 10.2196/10148
   Owens OL, 2018, AM J HLTH PROMOT
   PATE RR, 1995, JAMA-J AM MED ASSOC, V273, P402, DOI 10.1001/jama.273.5.402
   Turing AM., 1950, J MIND ASS, V59, P433, DOI [10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   2004, LIFE LIKE CHARACTERS, P163, DOI DOI 10.1007/978-3-662-08373-4_8
NR 22
TC 25
Z9 25
U1 2
U2 21
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
EI 2405-6308
J9 CLIN TRANSL RAD ONCO
JI Clin. Transl. Radiat. Oncol.
PD MAY
PY 2019
VL 16
BP 55
EP 59
DI 10.1016/j.ctro.2019.04.002
PG 5
WC Oncology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology; Radiology, Nuclear Medicine & Medical Imaging
GA HV7TQ
UT WOS:000466183900009
PM 31008379
OA Green Published, gold
DA 2022-08-02
ER

PT C
AU Wendt, J
   Weyers, B
   Stienen, J
   Bonsch, A
   Vorlander, M
   Kuhlen, TW
AF Wendt, Jonathan
   Weyers, Benjamin
   Stienen, Jonas
   Boensch, Andrea
   Vorlaender, Michael
   Kuhlen, Torsten W.
GP ACM
TI Influence of Directivity on the Perception of Embodied Conversational
   Agents' Speech
SO PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT
   VIRTUAL AGENTS (IVA' 19)
LA English
DT Proceedings Paper
CT 19th ACM International Conference on Intelligent Virtual Agents (IVA)
CY JUL 02-05, 2019
CL Paris, FRANCE
SP Assoc Comp Machinery, ACM SIGAI
DE virtual agents; virtual acoustics; directional 3D sound; social presence
AB Embodied conversational agents become more and more important in various virtual reality applications, e.g., as peers, trainers or therapists. Besides their appearance and behavior, appropriate speech is required for them to be perceived as human-like and realistic. Additionally to the used voice signal, also its auralization in the immersive virtual environment has to be believable. Therefore, we investigated the effect of adding directivity to the speech sound source. Directivity simulates the orientation dependent auralization with regard to the agent's head orientation. We performed a one-factorial user study with two levels (n=35) to investigate the effect directivity has on the perceived social presence and realism of the agent's voice. Our results do not indicate any significant effects regarding directivity on both variables covered. We account this partly to an overall too low realism of the virtual agent, a not overly social utilized scenario and generally high variance of the examined measures. These results are critically discussed and potential further research questions and study designs are identified.
C1 [Wendt, Jonathan; Boensch, Andrea; Kuhlen, Torsten W.] Rhein Westfal TH Aachen, Visual Comp Inst, Aachen, Germany.
   [Weyers, Benjamin] Univ Trier, Human Comp Interact, Trier, Germany.
   [Stienen, Jonas; Vorlaender, Michael] Rhein Westfal TH Aachen, Inst Tech Acoust, Aachen, Germany.
RP Wendt, J (corresponding author), Rhein Westfal TH Aachen, Visual Comp Inst, Aachen, Germany.
EM wendt@vr.rwth-aachen.de
RI Bönsch, Andrea/AAT-4713-2021
OI Bönsch, Andrea/0000-0001-5077-3675; Ehret, Jonathan/0000-0001-6270-5119
FU project house ICT Foundations of a Digitized Industry, Economy, and
   Society at RWTH Aachen Univ.
FX This work was funded by the project house ICT Foundations of a Digitized
   Industry, Economy, and Society at RWTH Aachen Univ.
CR Bailenson JN, 2001, PRESENCE-TELEOP VIRT, V10, P583, DOI 10.1162/105474601753272844
   Bernardet U, 2017, LECT NOTES ARTIF INT, V10498, P43, DOI 10.1007/978-3-319-67401-8_5
   Bonsch A, 2017, P IEEE VIRT REAL ANN, P301, DOI 10.1109/VR.2017.7892296
   Kob Malte, 2002, THESIS
   Lentz Tobias, 2007, THESIS
   Mehra R, 2014, IEEE T VIS COMPUT GR, V20, P495, DOI 10.1109/TVCG.2014.38
   Shapiro A., 2011, INT C MOT GAM, P98, DOI DOI 10.1007/978-3-642-25090-3_9
   Shin Mincheol, 2019, INT J HUMAN COMPUTER
   Wendt Jonathan, 2018, VIRTUAL HUMANS CROWD
   Zibrek K, 2017, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2017), DOI 10.1145/3119881.3119887
NR 10
TC 3
Z9 3
U1 1
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6672-4
PY 2019
BP 130
EP 132
DI 10.1145/3308532.3329434
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP5MU
UT WOS:000556671900029
DA 2022-08-02
ER

PT J
AU Ahn, J
   Gobron, S
   Thalmann, D
   Boulic, R
AF Ahn, Junghyun
   Gobron, Stephane
   Thalmann, Daniel
   Boulic, Ronan
TI Asymmetric facial expressions: revealing richer emotions for embodied
   conversational agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE asymmetric facial expression; VAD emotional model; real-time
   application; evaluation study; embodied agent; linear model
ID RECOGNITION; AREAS
AB In this paper, we propose a method to achieve effective facial emotional expressivity for embodied conversational agents by considering two types of asymmetry when exploiting the valence-arousal-dominance representation of emotions. Indeed, the asymmetry of facial expressions helps to convey complex emotional feelings such as conflicting and/or hidden emotions due to social conventions. To achieve such a higher degree of facial expression in a generic way, we propose a new model for mapping the valence-arousal-dominance emotion model onto a set of 12 scalar facial part actions built mostly by combining pairs of antagonist action units from the Facial Action Coding System. The proposed linear model can automatically drive a large number of autonomous virtual humans or support the interactive design of complex facial expressions over time. By design, our approach produces symmetric facial expressions, as expected for most of the emotional spectrum. However, more complex ambivalent feelings can be produced when differing emotions are applied on the left and right sides of the face. We conducted an experiment on static images produced by our approach to compare the expressive power of symmetric and asymmetric facial expressions for a set of eight basic and complex emotions. Results confirm both the pertinence of our general mapping for expressing basic emotions and the significant improvement brought by asymmetry for expressing ambivalent feelings. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Ahn, Junghyun; Gobron, Stephane; Boulic, Ronan] Ecole Polytech Fed Lausanne, IIG, CH-1015 Lausanne, Switzerland.
   [Gobron, Stephane] HE Arc, Informat & Commun Syst ISIC, St Imier, Switzerland.
   [Thalmann, Daniel] Nanyang Technol Univ, Inst Media Innovat, Singapore 639798, Singapore.
RP Ahn, J (corresponding author), Ecole Polytech Fed Lausanne, IIG, EPFL SCI IC RB, Stn 14, CH-1015 Lausanne, Switzerland.
EM junghyun.ahn@epfl.ch
RI Thalmann, Daniel/A-4347-2008; Thalmann, Daniel/AAL-1097-2020
OI Thalmann, Daniel/0000-0002-0451-7491; Thalmann,
   Daniel/0000-0002-0451-7491
FU EU FP7 project CYBEREMOTIONS [231323]
FX The authors wish to thank Ms. Mireille Clavien, Mr. Olivier Renault, Mr.
   Quentin Silvestre, Dr. Janusz Holyst, Dr. Arvid Kappas, Ms. Kamila
   Kowalska, Dr. Jonathan Maim, Dr. Barbara Yersin, and Dr. Nan Wang for
   their collaboration on motion capture, character animation, avatar
   modeling, software development, and experiment design. This work was
   supported by the EU FP7 project CYBEREMOTIONS (contract 231323).
CR Ahn J, 2010, ENG SUMM SCH WORKSH
   Albrecht I., 2005, VIRTUAL REALITY, V8, P201, DOI DOI 10.1007/S10055-005-0153-5
   [Anonymous], 2008, COMPUTER FACIAL ANIM
   BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049
   BOROD JC, 1980, NEUROPSYCHOLOGIA, V18, P237, DOI 10.1016/0028-3932(80)90070-6
   Borod JC, 1997, NEUROPSYCHOL REV, V7, P41, DOI 10.1007/BF02876972
   Borod JC, 1998, NEUROPSYCHOLOGIA, V36, P1209, DOI 10.1016/S0028-3932(97)00166-8
   BOUCHER JD, 1975, J COMMUN, V25, P21, DOI 10.1111/j.1460-2466.1975.tb00577.x
   Bradley M. M., 1999, C1 CTR RES PSYCH U F
   BUSH LE, 1973, J PERS SOC PSYCHOL, V25, P50, DOI 10.1037/h0034274
   CAMPBELL R, 1982, INT J PSYCHOL, V17, P211, DOI 10.1080/00207598208247442
   Chmiel A, 2011, PHYSICA A, V390, P2936, DOI 10.1016/j.physa.2011.03.040
   Cowie R, 2009, PHILOS T R SOC B, V364, P3515, DOI 10.1098/rstb.2009.0139
   DENG Z, 2007, DATA DRIVEN 3D FACIA
   Dimberg U, 2000, PSYCHOPHYSIOLOGY, V37, P693, DOI 10.1111/1469-8986.3750693
   Egges A, 2004, COMPUT ANIMAT VIRT W, V15, P1, DOI 10.1002/cav.3
   EKMAN P, 1980, CHILD DEV, V51, P886, DOI 10.1111/j.1467-8624.1980.tb02627.x
   EKMAN P, 1980, J PERS SOC PSYCHOL, V39, P1125, DOI 10.1037/h0077722
   EKMAN P, 1982, J NONVERBAL BEHAV, V6, P238, DOI 10.1007/BF00987191
   Ekman P., 1971, NEBRASKA S MOTIVATIO, V19, P207
   Ekman Paul, 1978, FACIAL ACTION CODING
   Fasel B, 2000, INT C PATT RECOG, P1100, DOI 10.1109/ICPR.2000.905664
   GRAMMER K, 1994, J COMP PSYCHOL, V108, P233, DOI 10.1037/0735-7036.108.3.233
   Junghyun Ahn, 2012, Motion in Games. 5th International Conference (MIG 2012). Proceedings, P122, DOI 10.1007/978-3-642-34710-8_12
   Krumhuber E, 2005, J NONVERBAL BEHAV, V29, P3, DOI 10.1007/s10919-004-0887-x
   Lance B, 2010, AUTON AGENT MULTI-AG, V20, P50, DOI 10.1007/s10458-009-9097-6
   Martin JC, 2006, INT J HUM ROBOT, V3, P269, DOI 10.1142/S0219843606000825
   McManus I. C., 2005, EUR REV S2, V13, P157, DOI [DOI 10.1017/S1062798705000736, 10.1017/S1062798705000736]
   Mehrabian A., 1974, APPROACH ENV PSYCHOL
   Norman GJ, 2011, EMOT REV, V3, P349, DOI 10.1177/1754073911402403
   Paterson H.M., 2001, P 23 ANN C COGN SCI, P756
   Pelachaud C, 2002, J VISUAL COMP ANIMAT, V13, P301, DOI 10.1002/vis.299
   Pelachaud C, 2009, PHILOS T R SOC B, V364, P3539, DOI 10.1098/rstb.2009.0186
   Pighin F., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P75
   Ploog D., 1979, HUMAN ETHOLOGY CLAIM, P169, DOI DOI 10.1007/978-1-4020-2783-33
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   SACKEIM HA, 1978, SCIENCE, V202, P434, DOI 10.1126/science.705335
   Schatz H., 2006, CHARACTER ACTORS ACT
   SCHIFF BB, 1990, NEUROPSYCHOLOGIA, V28, P777, DOI 10.1016/0028-3932(90)90002-6
   SCHWARTZ GE, 1979, PSYCHOPHYSIOLOGY, V16, P561, DOI 10.1111/j.1469-8986.1979.tb01521.x
   Tena JR, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964971
   Thalmann D, 2004, HDB VIRTUAL HUMANS
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   Vinayagamoorthy V, 2006, EUR C STAT ART REP E
   WYLER F, 1987, J CLIN EXP NEUROPSYC, V9, P105, DOI 10.1080/01688638708405351
   [No title captured]
NR 46
TC 7
Z9 7
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2013
VL 24
IS 6
BP 539
EP 551
DI 10.1002/cav.1539
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 273QL
UT WOS:000328551100003
OA Green Submitted
DA 2022-08-02
ER

PT J
AU Doumanis, I
   Smith, S
AF Doumanis, Ioannis
   Smith, Serengul
TI A Framework for Research in Gamified Mobile Guide Applications using
   Embodied Conversational Agents (ECAs)
SO INTERNATIONAL JOURNAL OF SERIOUS GAMES
LA English
DT Article
DE Gamification; Mobile Guide Applications (MGA); Embodied Conversational
   Agents (ECAs); Player experience; Cognitive Accessibility; Usability
AB Mobile Guides are mobile applications that provide players with local and location-based services (LBS), such as navigation assistance, where and when they need them most. Advances in mobile technologies in recent years have enabled the gamification of these applications, opening up new opportunities to transfer education and culture through game play. However, adding traditional game elements such as PBLs (points, badges, and leaderboards) alone cannot ensure that the intended learning outcomes will be met, as the player's cognitive resources are shared between the application and the surrounding environment. This distribution of resources prevents players from easily immersing themselves into the educational scenario. Adding artificial conversational characters (ECAs) that simulate the social norms found in real-life human-to-human guide scenarios has the potential to address this problem and improve the player's experience and learning of cultural narratives [1]. Although significant progress has been made towards creating game-like mobile guides with ECAs ([2], [3]), there is still a lack of a unified framework that enables researchers and practitioners to investigate the potential effects of such applications to players and how to approach the concepts of player experience, cognitive accessibility and usability in this context. This paper presents a theoretically-well supported research framework consisted of four key components: differences in players, different features of the gamified task, aspects of how the ECA looks, sound or behaves and different mobile environments. Furthermore, it provides based on this framework a working definition of what player experience, cognitive accessibility and usability are in the context of game-like mobile guide applications. Finally, a synthesis of the results of six empirical studies conducted within this research framework is discussed and a series of design guidelines for the effective gamification of mobile guide applications using ECAs are presented. Results show that an ECA can positively affect the quality of the player's experience, but it did not elicit better player retention of cultural narratives and navigation of routes.
C1 [Doumanis, Ioannis; Smith, Serengul] Univ Middlesex, Burroughs Hendon, London, England.
RP Doumanis, I (corresponding author), Univ Middlesex, Burroughs Hendon, London, England.
EM i.doumanis@mdx.ac.uk; S.Smith@mdx.ac.uk
CR Adams Ray, 2007, Universal Access in the Information Society, V5, P363, DOI 10.1007/s10209-006-0061-9
   Adams R., 2003, UNIVERSAL ACCESS HCI, V4, P13
   Adams R., 2005, RE ACCESSIBILITY EVA
   [Anonymous], 1998, 9241111998 ISO
   Apple Inc, 2015, SIR MOB APPL
   Apple Inc, 2015, IP TABL DEV
   Bartle Richard, 1996, HEARTS CLUBS DIAMOND
   Baylor AL, 2008, LECT NOTES COMPUT SC, V5208, P208
   Campos Henrique, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P105, DOI 10.1007/978-3-642-33197-8_11
   Cassell J., 1999, Psychological Models of Communication in Collaborative Systems. Papers from the 1999 AAAI Fall Symposium (TR FS-99-03), P34
   Catrambone R., 2002, P 24 ANN C COGN SCI, P166
   Chou Y., 2015, GAMIFICATION DESIGN
   Chou Y., 2015, GAME DESIGN ANAL DIA
   Chou Y, 2015, OCTALYSIS COMPLETE G
   Cowell A. J., 2002, AAAI FALL S PERS AG, pn1
   Craig P., 2013, P 25 INT C SYS RES I
   Doumanis I., 2013, P 13 INT C INT VIRT, P474
   Doumanis I., 2014, P 16 ACM INT C MULT
   Doumanis I., 2015, J EAI ENDORSED T FUT, V1, P1
   Doumanis I., 2013, THESIS
   Doumanis I, 2013, AMB INTELL SMART ENV, V17, P431, DOI 10.3233/978-1-61499-286-8-431
   Dow S., 2006, P INT C ADV COMP ENT
   Eun-Ju Lee, 1998, WECC 98. Workshop on Embodied Conversational Characters, P123
   Falke C., 2014, GHOSTS GAMES WARTBUR
   GamEffective, 2015, GAM PLATF
   Gans H., 1999, POPULAR CULTURE HIGH
   Gonzalez Jr P.A, 2014, RACE ETHNICITY VIDEO
   Griffiths S., 2013, GRANDDAD THEFT AUTO
   Hile Harlan, 2008, P 7 INT C MOB UB MUL, P145, DOI [DOI 10.1145/1543137.1543167, 10.1145/1543137.1543167]
   Hollan J., 2000, ACM Transactions on Computer-Human Interaction, V7, P174, DOI 10.1145/353485.353487
   Kaptelinin V., 1997, P CHI 97, V97, P74
   Katz J., 2000, UP UP DOWN DOWN
   Korre D., 2015, USABILITY ENG EMBODI
   Kruger A., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P521
   Levine Lawrence, 1988, HIGHBROW LOWBROW EME
   Likert R., 1932, ARCH PSYCHOL, V22, P55
   MacDorman KF, 2006, INTERACT STUD, V7, P297, DOI 10.1075/is.7.3.03mac
   Mayer RE, 2002, EDUC PSYCHOL REV, V14, P87, DOI 10.1023/A:1013184611077
   Microsoft Inc, 2015, KIN FOR WIND
   Miyake S., 2012, P 2012 AS PAC SIGN I, P1
   Mobee Inc, 2015, MOB MOB APPL
   Moreno R, 2000, J EDUC PSYCHOL, V92, P724, DOI 10.1037//0022-0663.92.4.724
   Next OS, 2015, VIRT ASS DEN
   Octalysis, 2013, ENT GAM CONS WIK
   Phan M.H., 2012, VIDEO GAMES MALES PR
   Prensky M., 2000, DIGITAL GAME BASED L
   Raessens J.F.F., 2012, HOMO LUDENS 20 LUDIC
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Rickenberg R., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P49
   Schilling C., 2009, DAILY TELEGRAPH
   Sternberg R. J., 2000, HDB INTELLIGENCE
   Wagner D., 2006, P IEEE VIRT REAL C V, P321
   Waze Mobile, 2015, WAZ MOB APPL
   Xiao J., 2006, THESIS
NR 54
TC 4
Z9 4
U1 0
U2 9
PU SERIOUS GAMES SOC
PI GENOA
PA IST INT COMUNICAZIONI, VILLA PIAGGIO, GENOA, 16125, ITALY
SN 2384-8766
J9 INT J SERIOUS GAMES
JI Int. J. Serious Games
PD JUL
PY 2015
VL 2
IS 3
BP 21
EP 40
DI 10.17083/ijsg.v2i3.79
PG 20
WC Education & Educational Research
WE Emerging Sources Citation Index (ESCI)
SC Education & Educational Research
GA V3U0A
UT WOS:000218585500003
OA gold, Green Accepted, Green Submitted
DA 2022-08-02
ER

PT J
AU Ling, EC
   Tussyadiah, I
   Tuomi, A
   Stienmetz, J
   Ioannou, A
AF Ling, Erin Chao
   Tussyadiah, Iis
   Tuomi, Aarni
   Stienmetz, Jason
   Ioannou, Athina
TI Factors influencing users' adoption and use of conversational agents: A
   systematic review
SO PSYCHOLOGY & MARKETING
LA English
DT Review
DE adoption; chatbot; cognitive engagement; customer service; intelligent
   conversational agent; systematic review
AB As artificially intelligent conversational agents (ICAs) become a popular customer service solution for businesses, understanding the drivers of user acceptance of ICAs is critical to ensure its successful implementation. To provide a comprehensive review of factors affecting consumers' adoption and use of ICAs, this study performs a systematic literature review of extant empirical research on this topic. Based on a literature search performed in July 2019 followed by a snowballing approach, 18 relevant articles were analyzed. Factors found to influence human-machine cognitive engagement were categorized into usage-related, agent-related, user-related, attitude and evaluation, and other factors. This study proposed a collective model of users' acceptance and use of ICAs, whereby user acceptance is driven mainly by usage benefits, which are influenced by agent and user characteristics. The study emphasizes the proposed model's context-dependency, as relevant factors depend on usage settings, and provides several strategic business implications, including service design, personalization, and customer relationship management.
C1 [Ling, Erin Chao] Univ Huddersfield, Huddersfield Business Sch, Dept Logist Mkt Hospitality & Analyt, Huddersfield HD1 3DH, W Yorkshire, England.
   [Tussyadiah, Iis; Ioannou, Athina] Univ Surrey, Sch Hospitality & Tourism Management, Guildford, Surrey, England.
   [Tuomi, Aarni] Haaga Helia Univ Appl Sci, Hospitality Business Competence Area, Helsinki, Finland.
   [Stienmetz, Jason] MODUL Univ Vienna, Dept Tourism & Serv Management, Vienna, Austria.
RP Ling, EC (corresponding author), Univ Huddersfield, Huddersfield Business Sch, Dept Logist Mkt Hospitality & Analyt, Huddersfield HD1 3DH, W Yorkshire, England.
EM erin.cling@gmail.com
RI Tuomi, Aarni/AAK-7168-2021
OI Tuomi, Aarni/0000-0002-0515-1313; Ling, Erin Chao/0000-0002-3444-2689;
   Tussyadiah, Iis/0000-0003-0729-1712; Ioannou, Athina/0000-0001-7038-938X
CR Abdullah A, 2018, J EPIDEMIOL GLOB HEA, V8, P225, DOI 10.2991/j.jegh.2018.08.104
   Ajzen I., 1980, UNDERSTANDING ATTITU
   Ajzen I., 1980, UNDERSTANDING ATTITU
   Akhtar M, 2019, CONF BUS INFORM, P397, DOI 10.1109/CBI.2019.00052
   Alger K., 2018, FORBES
   Aljukhadar M, 2017, PSYCHOL MARKET, V34, P708, DOI 10.1002/mar.21017
   Amini R, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI 2013), P46, DOI 10.1109/ICHI.2013.13
   Brandtzaeg PB., 2018, INTERACTIONS, V25, P38, DOI 10.1145/3236669
   Brandtzaeg PB, 2017, LECT NOTES COMPUT SC, V10673, P377, DOI 10.1007/978-3-319-70284-1_30
   Chi NC, 2017, GERIATR NURS, V38, P542, DOI 10.1016/j.gerinurse.2017.04.002
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   DeLone WH, 2003, J MANAGE INFORM SYST, V19, P9, DOI 10.1080/07421222.2003.11045748
   Dixon M, 2013, J OPER MANAG, V31, P138, DOI 10.1016/j.jom.2012.12.002
   Flanagin AJ, 2007, NEW MEDIA SOC, V9, P319, DOI 10.1177/1461444807075015
   Foster ME, 2007, LANG RESOUR EVAL, V41, P305, DOI 10.1007/s10579-007-9055-3
   Gartner, 2020, TOP CX TRENDS CIOS W
   Gibbons S., 2016, DESIGN THINKING 101
   GOODIN RE, 1977, POLIT STUD-LONDON, V25, P383, DOI 10.1111/j.1467-9248.1977.tb01287.x
   Gummerus J, 2004, J SERV MARK, V18, P175, DOI DOI 10.1108/08876040410536486
   Gursoy D, 2019, INT J INFORM MANAGE, V49, P157, DOI 10.1016/j.ijinfomgt.2019.03.008
   Gusenbauer M, 2020, RES SYNTH METHODS, V11, P181, DOI 10.1002/jrsm.1378
   Heerink M., 2009, P 23 BRIT HCI GROUP, P430, DOI DOI 10.14236/EWIC/HCI2009.54
   Higgins J, 2012, COCHRANE DB SYST REV, DOI 10.1002/14651858.ED000049
   Johnson GJ, 2006, J ADVERTISING, V35, P35, DOI 10.2753/JOA0091-3367350403
   Kaburuan, 2019, INT J CIVIL ENG TECH, V10, P1270
   Katz E., 1974, USES MASS COMMUNICAT
   Kitchenham B., 2007, 2007001 EBSE
   Kitchenham B, 2009, INFORM SOFTWARE TECH, V51, P7, DOI 10.1016/j.infsof.2008.09.009
   Kulviwat S, 2007, PSYCHOL MARKET, V24, P1059, DOI 10.1002/mar.20196
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lee SY, 2017, INT J HUM-COMPUT ST, V103, P95, DOI 10.1016/j.ijhcs.2017.02.005
   Liu C, 2000, INFORM MANAGE, V38, P23, DOI 10.1016/S0378-7206(00)00049-5
   Lu L, 2019, INT J HOSP MANAG, V80, P36, DOI 10.1016/j.ijhm.2019.01.005
   Macedonia M., 2014, INT J LEARNING TEACH, V7, P1
   Martin J, 2015, J RETAIL CONSUM SERV, V25, P81, DOI 10.1016/j.jretconser.2015.03.008
   Martin-Martin A, 2018, J INFORMETR, V12, P1160, DOI 10.1016/j.joi.2018.09.002
   Maurer D, 2015, SMART INNOV SYST TEC, V40, P109, DOI 10.1007/978-3-319-19830-9_10
   McLean G, 2019, TECHNOL FORECAST SOC, V146, P55, DOI 10.1016/j.techfore.2019.05.017
   McLean G, 2019, COMPUT HUM BEHAV, V99, P28, DOI 10.1016/j.chb.2019.05.009
   Mehrabian A., 1974, APPROACH ENV PSYCHOL
   Moon JW, 2001, INFORM MANAGE, V38, P217, DOI 10.1016/S0378-7206(00)00061-6
   Mori M, 1970, ENERGY, V7, P33, DOI DOI 10.1109/MRA.2012.2192811
   Moriuchi E, 2019, PSYCHOL MARKET, V36, P489, DOI 10.1002/mar.21192
   Myers K, 2007, AI MAG, V28, P47
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Parasuraman A., 2000, CONCEPTUAL FRAMEWORK, P2000100
   Pardo D, 2010, J MULTIMODAL USER IN, V3, P285, DOI 10.1007/s12193-010-0052-2
   Reddy, 2017, CHATBOTS CAN HELP RE
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Rietz T., 14 INT C WIRTSCH SIE
   Ring L, 2015, J MULTIMODAL USER IN, V9, P79, DOI 10.1007/s12193-014-0157-0
   Rubin VL, 2010, LIBR HI TECH, V28, P496, DOI 10.1108/07378831011096196
   Snyder H, 2019, J BUS RES, V104, P333, DOI 10.1016/j.jbusres.2019.07.039
   Tegos S, 2016, INT J COMP-SUPP COLL, V11, P417, DOI 10.1007/s11412-016-9246-2
   Terzis V, 2012, COMPUT EDUC, V59, P710, DOI 10.1016/j.compedu.2012.03.003
   Terzis V, 2011, COMPUT EDUC, V56, P1032, DOI 10.1016/j.compedu.2010.11.017
   Torkzadeh G, 2002, INFORM SYST RES, V13, P187, DOI 10.1287/isre.13.2.187.87
   Tsafnat G, 2014, SYST REV-LONDON, V3, DOI 10.1186/2046-4053-3-74
   Tsiourti C., 2018, STUDIES COMPUTATIONA, V751
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   Venkatesh V, 2000, MANAGE SCI, V46, P186, DOI 10.1287/mnsc.46.2.186.11926
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Venkatesh V, 2008, DECISION SCI, V39, P273, DOI 10.1111/j.1540-5915.2008.00192.x
   Venkatesh V, 2012, MIS QUART, V36, P157
   Webster J, 2002, MIS QUART, V26, pXIII
   Wohlin C., 2014, P 18 INT C EVALUATIO, V38, P1, DOI [10.1145/2601248.2601268, DOI 10.1145/2601248.2601268]
   Wrobel J., 2013, P 6 INT C ADV COMP H, P162
   Yang H, 2019, INF SYST E-BUS MANAG, V17, P65, DOI 10.1007/s10257-018-0375-1
   Zarouali B, 2018, CYBERPSYCH BEH SOC N, V21, P491, DOI 10.1089/cyber.2017.0518
NR 69
TC 14
Z9 13
U1 25
U2 77
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0742-6046
EI 1520-6793
J9 PSYCHOL MARKET
JI Psychol. Mark.
PD JUL
PY 2021
VL 38
IS 7
SI SI
BP 1031
EP 1051
DI 10.1002/mar.21491
EA APR 2021
PG 21
WC Business; Psychology, Applied
WE Social Science Citation Index (SSCI)
SC Business & Economics; Psychology
GA SL6ZQ
UT WOS:000637900000001
DA 2022-08-02
ER

PT C
AU Nitta, K
AF Nitta, Kiyoshi
BE Bassiliades, N
   Governatori, G
   Paschke, A
TI Building an Autopoietic Knowledge Structure for Natural Language
   Conversational Agents
SO RULE REPRESENTATION, INTERCHANGE AND REASONING ON THE WEB, RULEML 2008
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT Joint Conference of the International Symposium on Rule Interchange and
   Applications / 11th International Business Rules Forum
CY OCT 30-31, 2008
CL Orlando, FL
SP VULCAN, Model Syst, STI INNSBRUCK, ruleCore, JBoss
AB This paper proposes a graph structure called an augmented semantic network (ASN) which is an extension of the ordinary semantic network (SN). We have developed an experimental conversational agent system and a knowledge structure based on the ASN that can hold a larger number of rules for replying to user utterances and modifying some parts of the rules when necessary. The system operation has shown that the knowledge structure is capable of implementing well-studied conversational models and becoming an autopoietic system. Autopoiesis means the systemic nature of life activity as discussed in the field of life science. An autopoietic system will be able to reproduce its elements as a result of their activity. Although the system will have to be capable of other functional natures to become an autopoietic. system, the additional flexibility and extensibility enabled by the ASN-based knowledge structure might be necessary for realizing autopoietic and intelligent conversational agents.
   The SN graph structure consists of a vertex set and an edge set whose elements each connect two elements in the vertex set. ASN edges are also able to connect elements in the edge set. The knowledge structure permits concept synthesis by utilizing the ASN's edge modification ability. It removes the restriction on giving meanings from the outside to all concepts in the knowledge structure. Each element of rules represented by the ASN graph structure has a concrete meaning that can be synthesized by other elements of the rules. This capability might further the development of an autopoietic knowledge structure system.
C1 Yahoo Japan Res, Tokyo, Japan.
RP Nitta, K (corresponding author), Yahoo Japan Res, Tokyo, Japan.
CR Allen J., 2001, P 6 INT C INT US INT, P8, DOI [10.1145/359784.359822, DOI 10.1145/359784.359822]
   Bauer M., 2000, IUI 2000. 2000 International Conference on Intelligent User Interfaces, P21
   Cassell J., 1999, P SIGCHI C HUM FACT, P520, DOI DOI 10.1145/302979.303150
   Chen L., 1998, Proceedings of the Second International Conference on Autonomous Agents, P132, DOI 10.1145/280765.280789
   ETZIONI O, 1994, COMMUN ACM, V37, P72, DOI 10.1145/176789.176797
   GALVAO AM, 2004, AAMAS 2004
   GRIFFITH RL, 1982, ACM T DATABASE SYST, V7, P417, DOI 10.1145/319732.319743
   KIYOTA Y, 2002, P 19 INT C COMP LING, P1
   Knott A, 2008, ARTIF INTELL, V172, P69, DOI 10.1016/j.artint.2007.06.001
   Lieberman H., 2005, P CHI, P1597, DOI DOI 10.1145/1056808.1056975
   LOEBNER HG, 1994, COMMUN ACM, V37, P79, DOI 10.1145/175208.175218
   LUKE S, 1997, AGENTS 1997
   Minsky M., 2006, EMOTION MACHINE COMM
   SING G, 2006, P INT C GAM RES DEV, P177
   Thorisson K. R., 1997, Proceedings of the First International Conference on Autonomous Agents, P536, DOI 10.1145/267658.267823
   Turing AM., 1950, J MIND ASS, V59, P433, DOI [10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   WILKS Y, 1999, MACHINE CONVERSATION
   Yates A., 2003, IUI 03. 2003 International Conference on Intelligent User Interfaces, P189
NR 19
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-540-88807-9
J9 LECT NOTES COMPUT SC
PY 2008
VL 5321
BP 211
EP 218
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BIO38
UT WOS:000261333200022
DA 2022-08-02
ER

PT C
AU Chin, YJ
   Yi, MY
AF Chin, Hyojin
   Yi, Mun Yong
GP Assoc Comp Machinery
TI Should an Agent Be Ignoring It? A Study of Verbal Abuse Types and
   Conversational Agents' Response Styles
SO CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI
   CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY MAY 04-09, 2019
CL Glasgow, SCOTLAND
SP Assoc Comp Machinery, ACM SIGCHI
DE Conversational Agent; Conversational AI; Chatbot; Verbal Abuse; Agent
   Response Style; Agent Abuse
ID INTERFACE
AB Verbal abuse is a hostile form of communication ill-intended to harm the other person. With a plethora of AI solutions around, the other person being targeted may be a conversational agent. In this study, involving 3 verbal abuse types (Insult, Threat, Swearing) and 3 response styles (Avoidance, Empathy, Counterattacking), we examine whether a conversational agent's response style under varying abuse types influences those emotions found to mitigate people's aggressive behaviors. Sixty-four participants, assigned to one of the abuse type conditions, interacted with the three conversational agents in turn and reported their feelings about guiltiness, anger, and shame after each session. Our study results show that, regardless of the abuse type, the agent's response style has a significant effect on user emotions. Participants were less angry and more guilty with the empathetic agent than the other two agents. Our study findings have direct implications for the design of conversational agents.
C1 [Chin, Hyojin; Yi, Mun Yong] Korea Adv Inst Sci & Technol, Grad Sch Knowledge Serv Engn, Daejeon, South Korea.
RP Chin, YJ (corresponding author), Korea Adv Inst Sci & Technol, Grad Sch Knowledge Serv Engn, Daejeon, South Korea.
EM tesschin@kaist.ac.kr; munyi@kaist.ac.kr
OI Chin, Hyojin/0000-0003-4773-9518
FU Electronics and Telecommunications Research Institute (ETRI) - Korean
   government [19ZH1100]
FX This work was supported by Electronics and Telecommunications Research
   Institute (ETRI) grant funded by the Korean government. [19ZH1100,
   Distributed Intelligence Core Technology of Hyper-Connected Space]
CR Brahnam S., 2005, ABUSE DARKER SIDE HU, P62
   Catrambone R, 2004, HUM-COMPUT INT-SPRIN, V7, P239
   De Angeli A, 2008, INTERACT COMPUT, V20, P302, DOI 10.1016/j.intcom.2008.02.004
   Goussinsky R, 2012, J SERV MANAGE, V23, P170, DOI 10.1108/09564231211226105
   Grandey AA, 2007, J OCCUP HEALTH PSYCH, V12, P63, DOI 10.1037/1076-8998.12.1.63
   Izard C.E., 1993, DIFFERENTIAL EMOTION
   Prendinger H, 2005, APPL ARTIF INTELL, V19, P267, DOI 10.1080/08839510590910174
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Stuewig J., 2007, SELF CONSCIOUS EMOTI, P371
NR 9
TC 10
Z9 10
U1 2
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5971-9
PY 2019
DI 10.1145/3290607.3312826
PG 6
WC Computer Science, Cybernetics; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BN4JW
UT WOS:000482042102122
DA 2022-08-02
ER

PT J
AU Ochs, M
   Pelachaud, C
   Mckeown, G
AF Ochs, Magalie
   Pelachaud, Catherine
   Mckeown, Gary
TI A User Perception-Based Approach to Create Smiling Embodied
   Conversational Agents
SO ACM TRANSACTIONS ON INTERACTIVE INTELLIGENT SYSTEMS
LA English
DT Article
DE H.5.2 user interfaces; embodied conversational agent; smiles;
   human-machine interaction
ID FACIAL DISPLAYS; VIRTUAL AGENTS; SMILES; COMMUNICATION; FALSE; FACE;
   FELT
AB In order to improve the social capabilities of embodied conversational agents, we propose a computational model to enable agents to automatically select and display appropriate smiling behavior during human-machine interaction. A smile may convey different communicative intentions depending on subtle characteristics of the facial expression and contextual cues. To construct such a model, as a first step, we explore the morphological and dynamic characteristics of different types of smiles (polite, amused, and embarrassed smiles) that an embodied conversational agent may display. The resulting lexicon of smiles is based on a corpus of virtual agents' smiles directly created by users and analyzed through a machine-learning technique. Moreover, during an interaction, a smiling expression impacts on the observer's perception of the interpersonal stance of the speaker. As a second step, we propose a probabilistic model to automatically compute the user's potential perception of the embodied conversational agent's social stance depending on its smiling behavior and on its physical appearance. This model, based on a corpus of users' perceptions of smiling and nonsmiling virtual agents, enables a virtual agent to determine the appropriate smiling behavior to adopt given the interpersonal stance it wants to express. An experiment using real human-virtual agent interaction provided some validation of the proposed model.
C1 [Ochs, Magalie] Univ Toulon & Var, Aix Marseille Univ, CNRS, ENSAM,LSIS, Toulon, France.
   [Pelachaud, Catherine] CNRS, LTCI Teleom ParisTech, Multimedia Grp, Paris, France.
   [Mckeown, Gary] Queens Univ Belfast, Sch Psychol, Belfast BT7 1NN, Antrim, North Ireland.
   [Ochs, Magalie] Aix Marseille Univ, Polytech Marseille, LSIS, Marseille, France.
   [Pelachaud, Catherine] Univ Paris 06, Inst Syst Intelligents & Robot, 4 Pl Jussieu, F-75005 Paris, France.
   [Mckeown, Gary] Queens Univ Belfast, Sch Behav Sci, Univ Rd, Belfast BT7 1NN, Antrim, North Ireland.
RP Ochs, M (corresponding author), Univ Toulon & Var, Aix Marseille Univ, CNRS, ENSAM,LSIS, Toulon, France.; Ochs, M (corresponding author), Aix Marseille Univ, Polytech Marseille, LSIS, Marseille, France.
EM magalie.ochs@lsis.org; pelachaud@isir.upmc.fr; G.McKeown@qub.ac.uk
OI McKeown, Gary/0000-0002-7517-641X
FU European Community [231287]
FX This research has been supported by the European Community Seventh
   Framework Program (FP7/2007-2013), under grant agreement no. 231287
   (SSPNet). We thank Paul Brunet for his essential help in conducting the
   experiment.
CR Ambadar Z., 2009, J NONVERBAL BEHAV, V17-34, P238
   Andre Elisabeth, 2005, P 4 INT JOINT C AUT, DOI DOI 10.1145/1082473.1082615
   Baylor AL, 2009, PHILOS T R SOC B, V364, P3559, DOI 10.1098/rstb.2009.0148
   Beaupre MG, 2003, J EXP SOC PSYCHOL, V39, P371, DOI 10.1016/S0022-1031(03)00012-X
   Bernstein MJ, 2010, J EXP SOC PSYCHOL, V46, P196, DOI 10.1016/j.jesp.2009.08.010
   Bevacqua E, 2010, INT WORKSH INT ECAS
   Bevacqua Elisabetta, 2010, INTERACTIVE CONVERSA, P143
   Breiman L., 1984, CLASSIFICATION REGRE, V1st
   Burgoon JK, 2016, INT J HUM-COMPUT ST, V91, P24, DOI 10.1016/j.ijhcs.2016.02.002
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   Cassell J, 2001, KNOWL-BASED SYST, V14, P55, DOI 10.1016/S0950-7051(00)00102-7
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   Deutsch Francine M., 1987, PSYCHOL WOMEN Q
   Duchenne G.B.A., 1990, MECH HUMAN FACIAL EX
   Dunbar Robin Ian MacDonald, 2001, APPROACHES EVOLUTION, P92
   EDINGER JA, 1983, PSYCHOL BULL, V93, P30
   Ekman P, 2003, ANN NY ACAD SCI, V1000, P205, DOI 10.1196/annals.1280.010
   EKMAN P, 1982, J NONVERBAL BEHAV, V6, P238, DOI 10.1007/BF00987191
   EKMAN P, 1992, PSYCHOL SCI, V3, P34, DOI 10.1111/j.1467-9280.1992.tb00253.x
   Ekman P, 2002, FACIAL ACTION CODING
   Ekman P., 2009, TELLING LIES CLUES D
   Ekman P., 1975, UNMASKING FACE GUIDE
   FRANK MG, 1993, J PERS SOC PSYCHOL, V64, P83, DOI 10.1037/0022-3514.64.1.83
   Glenn Phillip, 2003, LAUGHTER INTERACTION
   Grammer Karl, 2006, ZIF MITTEILUNGEN
   Harrigan JA, 1996, PERS INDIV DIFFER, V21, P205, DOI 10.1016/0191-8869(96)00050-5
   Hess U, 2000, J NONVERBAL BEHAV, V24, P265, DOI 10.1023/A:1006623213355
   HESS U, 1990, EUR J SOC PSYCHOL, V20, P369, DOI 10.1002/ejsp.2420200502
   Hess U., 2002, EMPIRICAL REFLECTION, P187
   Heylen D, 2006, INT J HUM ROBOT, V3, P241, DOI 10.1142/S0219843606000746
   Hoque M, 2011, LECT NOTES COMPUT SC, V6974, P135, DOI 10.1007/978-3-642-24600-5_17
   Hoque ME, 2012, IEEE T AFFECT COMPUT, V3, P323, DOI 10.1109/T-AFFC.2012.11
   Jurgens R, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00111
   KELTNER D, 1995, J PERS SOC PSYCHOL, V68, P441, DOI 10.1037/0022-3514.68.3.441
   Ketelaar T, 2012, EVOL PSYCHOL-US, V10, P371
   Kiesling S, 2009, STANCE SOCIOLINGUIST, P171, DOI [DOI 10.1093/ACPROF:OSO/9780195331646.001.0001, DOI 10.1093/ACPROF:OSO/9780195331646.003.0008]
   Knapp M. L., 2013, NONVERBAL COMMUNICAT
   Kopp Stefan, 2006, P INT C AFF COMP INT, P21
   Kramer NC, 2008, LECT NOTES COMPUT SC, V5208, P507
   Kramer N, 2013, INT J HUM-COMPUT ST, V71, P335, DOI 10.1016/j.ijhcs.2012.09.006
   Krumhuber E, 2007, J NONVERBAL BEHAV, V31, P39, DOI 10.1007/s10919-006-0019-x
   Krumhuber EG, 2009, EMOTION, V9, P807, DOI 10.1037/a0017844
   LAFRANCE M, 1995, PERS SOC PSYCHOL B, V21, P207, DOI 10.1177/0146167295213002
   LAU S, 1982, J SOC PSYCHOL, V117, P63, DOI 10.1080/00224545.1982.9713408
   Man-Ching Yuen, 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P766, DOI 10.1109/PASSAT/SocialCom.2011.203
   Mason W, 2012, BEHAV RES METHODS, V44, P1, DOI 10.3758/s13428-011-0124-6
   Mayer RE, 2012, J EXP PSYCHOL-APPL, V18, P239, DOI 10.1037/a0028616
   McKeown G, 2015, EMOT REV, V7, P30, DOI 10.1177/1754073914544475
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   McKeown Gary J., 2013, REV GEN PSYCHOL
   Mehu Marc, 2007, J EVOLUTIONARY PSYCH, V5, p[1, 133]
   MOORE MM, 1985, ETHOL SOCIOBIOL, V6, P237, DOI 10.1016/0162-3095(85)90016-0
   Moruzzi S., 2010, CUTS CLOUDS VAGUENES
   Niewiadomski R, 2007, LECT NOTES COMPUT SC, V4738, P12
   Niewiadomski R, 2011, IEEE T AFFECT COMPUT, V2, P134, DOI 10.1109/T-AFFC.2011.5
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   O'Doherty J, 2003, NEUROPSYCHOLOGIA, V41, P147, DOI 10.1016/S0028-3932(02)00145-8
   Ochs M, 2016, IEEE T CYBERNETICS, V46, P401, DOI 10.1109/TCYB.2015.2411432
   Ochs M, 2012, COGN PROCESS, V13, P519, DOI 10.1007/s10339-011-0424-x
   Ochs M, 2010, LECT NOTES ARTIF INT, V6356, P427, DOI 10.1007/978-3-642-15892-6_47
   Otta E, 1996, PERCEPT MOTOR SKILL, V82, P1111, DOI 10.2466/pms.1996.82.3c.1111
   Pardo D, 2010, J MULTIMODAL USER IN, V3, P285, DOI 10.1007/s12193-010-0052-2
   Poggi I., 2000, Affective Interactions. Towards a New Generation of Computer Interfaces (Lecture Notes in Artificial Intelligence Vol.1814), P182
   Poggi Iabella, 1998, ORALITE GESTUALITE C, P159
   Rakotomalala R., 2005, ACTES EGC 2005 RNTI, P697
   REIS HT, 1990, EUR J SOC PSYCHOL, V20, P259, DOI 10.1002/ejsp.2420200307
   Riek LD, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940412
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Schroder M, 2012, IEEE T AFFECT COMPUT, V3, P165, DOI 10.1109/T-AFFC.2011.34
   Schroder M, 2010, ADV HUM-COMPUT INTER, V2010, DOI 10.1155/2010/319406
   Sneddon I, 2012, IEEE T AFFECT COMPUT, V3, P32, DOI 10.1109/T-AFFC.2011.26
   Snodgrass J, 1992, THESIS
   Su CY, 2008, LECT NOTES COMPUT SC, V5227, P661
   Tanguy E. A. R., 2006, THESIS
   Theonas G, 2008, International Journal of Virtual Reality, V7, P31
   Thibault Pascal, 2012, SOCIAL PSYCHOL
   Tomasello Michael, 1999, CULTURAL ORIGINS HUM
   Wang Ning, 2005, P 2005 C ART INT ED, P686
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Whiten A., 1997, MACHIAVELLIAN INTELL, DOI [10.1017/CBO9780511525636, DOI 10.1017/CBO9780511525636]
NR 80
TC 12
Z9 12
U1 1
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 2160-6455
EI 2160-6463
J9 ACM T INTERACT INTEL
JI ACM Trans. Interact. Intell. Syst.
PD MAR
PY 2017
VL 7
IS 1
AR 4
DI 10.1145/2925993
PG 33
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ER8QV
UT WOS:000399087600004
OA Green Submitted, Green Accepted
DA 2022-08-02
ER

PT B
AU Sagae, A
   Johnson, WL
   Valente, A
AF Sagae, Alicia
   Johnson, W. Lewis
   Valente, Andre
BA PerezMarin, D
   PascualNieto, I
BF PerezMarin, D
   PascualNieto, I
TI Conversational Agents in Language and Culture Training
SO CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND
   EFFECTIVE PRACTICES
LA English
DT Article; Book Chapter
AB This chapter describes the design, implementation, and use of an agent architecture that has been deployed in Alelo, Inc.'s language and culture training systems, which offer practical training for foreign language skills and intercultural competence. These agents support real-time conversation in the language of interest (Dari, Pashto, Arabic, French, and others), using automatic speech recognition and immersive simulation technologies. In earlier work, we developed a number of agent-based language and culture trainers, based on the Tactical Language and Culture Training System platform. Our experience has revealed a number of desiderata for authorable, believable agents, which we have applied to the design of our newest agent architecture. In this chapter, we describe the Virtual Role-Players (VRP), an agent architecture that relies on ontological models of world knowledge, language, culture, and agent state, in order to achieve believable dialogue with learners. Authoring and user experiences are described, along with future directions for this work.
C1 [Johnson, W. Lewis] Univ So Calif, Los Angeles, CA 90089 USA.
CR Allwood J., 2001, COOPERATIVE MULTIMOD, DOI [10.1007/3-540-45520-5_7, DOI 10.1007/3-540-45520-5_7]
   [Anonymous], 1986, SYMB INTERACT
   ARVIZU SF, 1990, EDUC URBAN SOC, V22, P364, DOI 10.1177/0013124590022004004
   Austin J. L., 1975, DO THINGS WORDS
   Bickmore T., 2008, CHI 2008 WORKSH TECH
   Byram M., 1997, TEACHING ASSESSING I
   de Rosis F, 2003, INT J HUM-COMPUT ST, V59, P81, DOI 10.1016/S1071-5819(03)00020-X
   Ellis R., 2003, TASK BASED LANGUAGE
   Eysenck H. J., 1976, MEASUREMENT PERSONAL
   Garfinkel H., 1967, STUDIES ETHNOMETHODO
   Goffman E., 1990, PRESENTATION SELF EV
   Graesser AC, 2005, IEEE T EDUC, V48, P612, DOI 10.1109/TE.2005.856149
   Habermas Jurgen, 1981, THEORY COMMUNICATIVE
   Hernandez A., 2008, 7 INT C AUT AG MULT
   Hobbs J. R., 2010, 6 INT C FORM ONT INF
   Hofstede G, 2005, CULTURES ORG SOFTWAR
   Jackendoff Ray, 1990, SEMANTIC STRUCTURES
   Johnson W. L., 2010, AD PERS E B LEARN US
   Johnson W. L., 2010, J ARTIFICIAL INTELLI, V20, P175
   Johnson W. L., 2008, SIMTECT 2008
   Johnson W. L., 2010, DEM SESS US MOD PERS
   Johnson W. L., 2008, IAAI 2008
   Johnson W. L, 2010, ADV CROSS CULTURAL D
   Johnson WL, 2009, AI MAG, V30, P72, DOI 10.1609/aimag.v30i2.2240
   Jonassen D. H., 1999, TASK ANAL METHODS IN
   Kumar R., 2009, AIED 2009 BRIGHT UK
   Lampe J., 2007, PLEN SESS INT LANG R
   Lazarus R., 2000, EMOTION ADAPTATION
   Lethin C., 2010, WARFIGHTER ENHANCEME, V4, P2
   Marsella SC, 2009, COGN SYST RES, V10, P70, DOI 10.1016/j.cogsys.2008.03.005
   Mascarenhas S., 2009, AAMAS 2009
   Matsuda N., 2010, INT WORKSH AD PERS E
   MCCLL, 2008, MCCLL NEWSLETTER, V4, P4
   McRorie M., 2009, INT C INT VIRT AG IV
   Melo C. M., 2009, INT VIRT AG AMST
   MILLER JG, 1984, J PERS SOC PSYCHOL, V46, P961
   Morris C.W, 1967, MIND SELF SOC STANDP
   Muller P., 2008, MARINE CORPS GAZ SEP
   ROQUE A, 2007, 8 SIGDIAL WORKSH DIS
   Rose C. P., 2001, INTERACTIVE CONCEPTU
   Sagae A., 2009, SLATE 2009 WARW ENGL
   Sagae A., 2010, 11 ANN SIGDIAL M DIS
   Samtani P., 2008, AAMAS 2008 WORKSH FU
   Schutz A, 1970, SELECTED WRITINGS
   SILVERMAN BG, 2002, COGNITIVE SCI Q, V2, P273
   Surface E. A., 2007, SPECIAL OPERATIONS L
   TRAUM D, 2008, 8 INT C INT VIRT AG
   Traum D., 1992, COMPUT INTELL, V8, P575, DOI DOI 10.1111/J.1467-8640.1992.TB00380.X
   Valente A., 2009, DYNAMIC METHODOLOGY
   Vilhjalmsson H., 2005, AAAI WORKSH MOD CONS
   Vilhjalmsson H., 2008, 7 INT C AUT AG MULT
   Wang N., 2008, 9 INT C INT TUT SYST
   Wang N., 2008, INT J HUMAN COMPUTER
   WEBER M, 1994, SOCIOLOGICAL WRITING
   [No title captured]
   [No title captured]
NR 56
TC 4
Z9 4
U1 0
U2 1
PU IGI GLOBAL
PI HERSEY
PA 701 E CHOCOLATE AVE, STE 200, HERSEY, PA 17033-1240 USA
BN 978-1-60960-618-3; 978-1-60960-617-6
PY 2011
BP 358
EP 377
DI 10.4018/978-1-60960-617-6.ch016
D2 10.4018/978-1-60960-617-6
PG 20
WC Computer Science, Artificial Intelligence
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BZX29
UT WOS:000303201400017
DA 2022-08-02
ER

PT J
AU Bickmore, TW
   Pfeifer, LM
   Byron, D
   Forsythe, S
   Henault, LE
   Jack, BW
   Silliman, R
   Paasche-Orlow, MK
AF Bickmore, Timothy W.
   Pfeifer, Laura M.
   Byron, Donna
   Forsythe, Shaula
   Henault, Lori E.
   Jack, Brian W.
   Silliman, Rebecca
   Paasche-Orlow, Michael K.
TI Usability of Conversational Agents by Patients with Inadequate Health
   Literacy: Evidence from Two Clinical Trials
SO JOURNAL OF HEALTH COMMUNICATION
LA English
DT Article
ID WORKING ALLIANCE; PROGRAM; ADULTS; IMPACT
AB Embodied Conversational Agents (ECA) are computer-animated characters that simulate face-to-face conversation with patients. These agents can be programmed with best practices in human-human health communication and used for automated health education and behavior change counseling interventions. Evidence is presented from two ongoing clinical trials demonstrating that patients at different levels of health literacy find these agents acceptable and easy to use for automated health communication interventions. Innovative computer interface systems can be used to ensure that inadequate health literacy not serve as a barrier to interventions using health information technology.
C1 [Bickmore, Timothy W.; Pfeifer, Laura M.; Byron, Donna] Northeastern Univ, Coll Comp & Informat Sci, Boston, MA 02115 USA.
   [Forsythe, Shaula; Jack, Brian W.] Boston Univ, Sch Med, Dept Family Med, Boston Med Ctr, Boston, MA 02118 USA.
   [Henault, Lori E.; Paasche-Orlow, Michael K.] Boston Univ, Sch Med, Gen Internal Med Sect, Boston Med Ctr, Boston, MA 02118 USA.
   [Silliman, Rebecca] Boston Univ, Sch Med, Sect Geriatr, Boston Med Ctr, Boston, MA 02118 USA.
RP Bickmore, TW (corresponding author), Northeastern Univ, Coll Comp & Informat Sci, WVH202,360 Huntington Ave, Boston, MA 02115 USA.
EM bickmore@ccs.neu.edu
RI Paasche-Orlow, Michael/ABF-7919-2020
OI Paasche-Orlow, Michael/0000-0002-9276-7190; Jack,
   Brian/0000-0002-6497-2437; Silliman, Rebecca/0000-0001-9958-8403
FU NATIONAL INSTITUTE ON AGING [R01AG028668] Funding Source: NIH RePORTER;
   NIA NIH HHS [R01 AG028668] Funding Source: Medline
CR [Anonymous], 2018, ASA SECT STAT COMP S
   ARGYLE M, 2008, BODILY COMMUNICATION
   BERKMAN ND, 2004, 87 U N CAR EV BAS PR
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T., 2009, P ACM SIGCHI C HUM F
   Bickmore T, 2010, APPL ARTIF INTELL, V24, P648, DOI 10.1080/08839514.2010.492259
   Bickmore T, 2008, INT J SEMANT COMPUT, V2, P47, DOI 10.1142/S1793351X08000348
   Bickmore TW, 2009, PERVASIVE MOB COMPUT, V5, P226, DOI 10.1016/j.pmcj.2008.05.004
   Bickmore TW, 2009, PATIENT EDUC COUNS, V75, P315, DOI 10.1016/j.pec.2009.02.007
   Bickmore TW, 2005, INTERACT COMPUT, V17, P711, DOI 10.1016/j.intcom.2005.09.002
   Bodie Graham D, 2008, Health Mark Q, V25, P175, DOI 10.1080/07359680802126301
   Cassell J., 2000, EMBODIED CONVERSATIO
   CLARK HH, 1991, PERSPECTIVES ON SOCIALLY SHARED COGNITION, P127, DOI 10.1037/10096-006
   CLINITE JC, 1976, J AM PHARM ASSOC, V16, P74, DOI 10.1016/S0003-0465(16)33474-7
   COLCHER IS, 1972, J AMER MED ASSOC, V222, P657, DOI 10.1001/jama.222.6.657
   Davis T C, 1993, Fam Med, V25, P391
   Doak CC, 1996, TEACHING PATIENTS LO
   Frankel RM, 1995, MOTIV EMOTION, V19, P163, DOI 10.1007/BF02250509
   HORVATH AO, 1989, J COUNS PSYCHOL, V36, P223, DOI 10.1037/0022-0167.36.2.223
   Jack BW, 2009, ANN INTERN MED, V150, P178, DOI 10.7326/0003-4819-150-3-200902030-00007
   Kutner M., 2006, HLTH LITERACY AM ADU
   Lincoln A, 2006, J GEN INTERN MED, V21, P818, DOI 10.1111/j.1525-1497.2006.00533.x
   Linden C, 2006, J BONE MINER RES, V21, P829, DOI [10.1359/jbmr.060304, 10.1359/JBMR.060304]
   MADDEN EE, 1973, J AM PHARM ASSOC, VNS13, P437, DOI 10.1016/S0003-0465(16)32687-8
   Mancuso CA, 2006, J GEN INTERN MED, V21, P813, DOI 10.1111/j.1525-1497.2006.00528.x
   MORRIS LA, 1979, AM J PUBLIC HEALTH, V69, P47, DOI 10.2105/AJPH.69.1.47
   NORMAN C, 2006, J MED INTERNET RES, V16, P2
   PARKER RM, 1995, J GEN INTERN MED, V10, P537, DOI 10.1007/BF02640361
   Qualls CD, 2001, HUMAN FACTORS INTERVENTIONS FOR THE HEALTH CARE OF OLDER ADULTS, P47
   Richmond V. P., 1995, NONVERBAL BEHAV INTE, P195
   Sudore RL, 2006, J GEN INTERN MED, V21, P806, DOI 10.1111/j.1525-1497.2006.00539.x
   Yin L., 2010, WORKSH INT SYST HEAL
NR 32
TC 93
Z9 94
U1 1
U2 21
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 1081-0730
EI 1087-0415
J9 J HEALTH COMMUN
JI J. Health Commun.
PY 2010
VL 15
SU 2
BP 197
EP 210
AR PII 926954323
DI 10.1080/10810730.2010.499991
PG 14
WC Communication; Information Science & Library Science
WE Social Science Citation Index (SSCI)
SC Communication; Information Science & Library Science
GA 650LS
UT WOS:000281851600019
PM 20845204
DA 2022-08-02
ER

PT C
AU Huang, HH
   Fukuda, M
   Nishida, T
AF Huang, Hung-Hsuan
   Fukuda, Masato
   Nishida, Toyoaki
GP ACM
TI Development of a Platform for RNN Driven Multimodal Interaction with
   Embodied Conversational Agents
SO PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT
   VIRTUAL AGENTS (IVA' 19)
LA English
DT Proceedings Paper
CT 19th ACM International Conference on Intelligent Virtual Agents (IVA)
CY JUL 02-05, 2019
CL Paris, FRANCE
SP Assoc Comp Machinery, ACM SIGAI
DE embodied conversational agents; facial expression; multimodal
   interaction; facial action coding system; recurrent neural network;
   gated recurrent unit
C1 [Huang, Hung-Hsuan; Fukuda, Masato; Nishida, Toyoaki] RIKEN, Ctr Adv Intelligence, Tokyo, Japan.
   [Huang, Hung-Hsuan; Nishida, Toyoaki] Kyoto Univ, Grad Sch Informat, Kyoto, Japan.
RP Huang, HH (corresponding author), RIKEN, Ctr Adv Intelligence, Tokyo, Japan.; Huang, HH (corresponding author), Kyoto Univ, Grad Sch Informat, Kyoto, Japan.
EM hhhuang@acm.org
CR Chen M., 2017, 19 ACM INT C MULT IN
   Hasegawa D, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P79, DOI 10.1145/3267851.3267878
   Huang HH, 2008, MULTIAGENT GRID SYST, V4, P371, DOI 10.3233/MGS-2008-4404
   Huang Hung-Hsuan, 2018, 6 INT C HUM AG INT H
   Otsuka K, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P191, DOI 10.1145/3242969.3242973
   Schuller B., 2009, 10 ANN C INT SPEECH
   van der Struijk Stef, 2018, 18 ACM INT C INT VIR
   Wu J, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P173, DOI 10.1145/3267851.3267860
NR 8
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6672-4
PY 2019
BP 200
EP 202
DI 10.1145/3308532.3329448
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP5MU
UT WOS:000556671900046
DA 2022-08-02
ER

PT C
AU Kim, J
   Kim, Y
   Kim, B
   Yun, S
   Kim, M
   Lee, J
AF Kim, Junhan
   Kim, Yoojung
   Kim, Byungjoon
   Yun, Sukyung
   Kim, Minjoon
   Lee, Joongseek
GP ACM
TI Can a Machine Tend to Teenagers' Emotional Needs? A Study with
   Conversational Agents
SO CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS
   IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 21-26, 2018
CL Montreal, CANADA
SP Assoc Comp Machinery, ACM SIGCHI
DE Teenager; Emotional Needs; Machine inherits; Human imitates;
   Conversational Agent
AB As teen stress and its negative consequences are on the rise, several studies have attempted to tend to their emotional needs through conversational agents (CAs). However, these attempts have focused on increasing human-like traits of agents, thereby overlooking the possible advantage of machine inherits, such as lack of emotion or the ability to perform calculations. Therefore, this paper aims to shed light on the machine inherits of CAs to help satisfy the emotional needs of teenagers. We conducted a workshop with 20 teenagers, followed by in-depth interviews with six of the participants. We discovered that teenagers expected CAs to (1) be good listeners due to their lack of emotion, (2) keep their secrets by being separated from the human world, and (3) give them advice based on the analysis of sufficient data. Based on our findings, we offer three design guidelines to build CAs.
C1 [Kim, Junhan; Kim, Yoojung; Kim, Byungjoon; Yun, Sukyung; Lee, Joongseek] Seoul Natl Univ, Dept Transdisciplinary Studies, Seoul, South Korea.
   [Kim, Minjoon] Seoul Natl Univ, Dept Comp Sci, Seoul, South Korea.
RP Kim, J (corresponding author), Seoul Natl Univ, Dept Transdisciplinary Studies, Seoul, South Korea.
EM bobkim91@snu.ac.kr; tendtoyj@snu.ac.kr; kimbyungjoon@snu.ac.kr;
   purchee@snu.ac.kr; minjoon.kim@snu.ac.kr; joonlee8@snu.ac.kr
CR ADAMS DM, 1994, CAN J PSYCHIAT, V39, P43, DOI 10.1177/070674379403900109
   American Psychological Association, STRESS AM AR TEENS A
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Lee Hyeon Ju, 2003, KOREAN J ED PSYCHOL, V17, P1
   Lee Kyung Sook, 2000, KOREAN J HLTH PSYCHO, V5, P43
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Lyon D, 2003, SURVEILLANCE SOCIAL
   Pfeifer Vardoulakis Laura, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P289, DOI 10.1007/978-3-642-33197-8_30
   Riek L. D., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P245
   Robins B, 2004, INTERACT STUD, V5, P161, DOI 10.1075/is.5.2.02rob
   Rowlands I, 2008, ASLIB PROC, V60, P290, DOI 10.1108/00012530810887953
   Spear LP, 2009, DEV PSYCHOPATHOL, V21, P87, DOI 10.1017/S0954579409000066
   Whittaker R, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.1857
NR 15
TC 8
Z9 8
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5621-3
PY 2018
DI 10.1145/3170427.3188548
PG 6
WC Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR8DX
UT WOS:000671090001006
DA 2022-08-02
ER

PT C
AU Blair, J
   Abdullah, S
AF Blair, Johnna
   Abdullah, Saeed
GP ACM
TI Understanding the Needs and Challenges of Using Conversational Agents
   for Deaf Older Adults
SO CONFERENCE COMPANION PUBLICATION OF THE 2019 COMPUTER SUPPORTED
   COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'19 COMPANION)
LA English
DT Proceedings Paper
CT 22nd ACM Conference on Computer-Supported Cooperative Work and Social
   Computing (CSCW)
CY NOV 10-13, 2019
CL Austin, TX
SP Assoc Comp Machinery, ACM SIGCHI, Facebook, Adobe, Amazon, IBM Res, Microsoft, Snap, FX PAL, Google, Mozilla, Underwood Inst, NSF
AB Conversational agents (CAs) with voice interfaces are becoming ubiquitous and are routinely used by a wide range of individuals. Users with vision and mobility issues can leverage the voice interfaces of CAs to complete tasks with increasing complexity. However, CAs with voice interfaces pose unique challenges for those with different accessibility needs - specifically, older adults with hearing loss. There has been little work to understand how deaf older adults leverage CAs and the challenges they face while using voice interfaces. To address this gap, we conduct in-depth qualitative interviews with 4 deaf older adults to understand how and why they use CAs. We explore their expectations for their devices and identify common challenges (e.g., default voices used by commercial CAs). We provide suggestions for designing CAs that can better accommodate a range of hearing abilities and provide the first step forward toward a more inclusive CA.
C1 [Blair, Johnna; Abdullah, Saeed] Penn State Univ, University Pk, PA 16802 USA.
RP Blair, J (corresponding author), Penn State Univ, University Pk, PA 16802 USA.
EM jlb883@psu.edu; saeed@psu.edu
OI Abdullah, Saeed/0000-0002-4371-8173
CR [Anonymous], [No title captured]
   Bentley Frank, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3264901
   Bigham JP, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P383, DOI 10.1145/3132525.3134821
   Cho Janghee, 2018, 2018 CHI C HUM FACT
   Glaser B.G., 1967, DISCOV GROUNDED THEO, V17, P364, DOI [10.1097/00006199-196807000-00014, DOI 10.1097/00006199-196807000-00014]
   Glasser A, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P427, DOI 10.1145/3132525.3134781
   Glasser AT, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P373, DOI 10.1145/3132525.3134819
   Knowles B, 2018, COMMUN ACM, V61, P72, DOI 10.1145/3179995
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   National Institute on Deafness and Other Communication Disorders, 2019, QUICK STAT HEAR
   National Institute on Deafness and Other Communication Disorders, 2019, AG REL HEAR LOSS
   National Public Radio, 2018, ED SMART AUD REP 201
   Pelikan HRM, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4921, DOI 10.1145/2858036.2858478
   Pradhan A, 2018, PORTL INT CONF MANAG, DOI 10.1145/3173574.3174033
   Sciuto A, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P857, DOI 10.1145/3196709.3196772
   World Health Organization, 2019, DEAF HEAR LOSS
NR 16
TC 6
Z9 6
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6692-2
PY 2019
BP 161
EP 165
DI 10.1145/3311957.3359487
PG 5
WC Computer Science, Cybernetics; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP1KM
UT WOS:000539904100036
DA 2022-08-02
ER

PT J
AU Hassani, K
   Nahvi, A
   Ahmadi, A
AF Hassani, Kaveh
   Nahvi, Ali
   Ahmadi, Ali
TI Architectural design and implementation of intelligent embodied
   conversational agents using fuzzy knowledge base
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Intelligent virtual environment; embodied conversational agent; fuzzy
   ontology
ID DIALOGUE; SYSTEM
AB In this paper, a general architecture is proposed for developing embodied conversational agents with fuzzy ontology knowledge base. The proposed architecture enables agents to interact with the user via multimodal channels in a virtual reality environment for the purpose of language learning. The agents play the role of emotional, rational, and friendly partners who provide a specific domain of knowledge based on user's queries in natural language. These queries are performed by an optimized fuzzy search engine. Two scenarios including two virtual airports and a virtual electronic gadget shop are implemented in this architecture to improve users' oral skills. The results show the users' average oral skills improved 11%. Moreover, 80% of the users ranked agents' logical sequence of actions and the total speed of responses as very good, and 90% of them evaluated agents' appropriateness of responses as very good based on Likert scale.
C1 [Hassani, Kaveh; Nahvi, Ali] KN Toosi Univ Technol, Fac Mech Engn, Mechatron Engn Grp, Tehran, Iran.
   [Ahmadi, Ali] KN Toosi Univ Technol, Dept Elect & Comp Engn, Tehran, Iran.
RP Hassani, K (corresponding author), KN Toosi Univ Technol, Fac Mech Engn, Mechatron Engn Grp, POB 19395-1999, Tehran, Iran.
EM k.hassani@armangar.ir
RI Ahmadi, Ali/AAK-7037-2020
OI Ahmadi, Ali/0000-0003-4211-6258
CR Beun R. J., 2006, 4 INT WORKSH INT VIR, P315
   Calegari S, 2007, INT J COMPUTER SCI A, V4, P125
   Calegari S, 2006, LECT NOTES COMPUT SC, V4027, P404
   Calegari S, 2006, ICEIS 2006: PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS, P66
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   Cassell J, 1999, SPRING COMP SCI, P109
   Cerekovic A, 2007, CONTEL 2007: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS, P41
   Cerekovic A, 2011, MULTIMED TOOLS APPL, V54, P143, DOI 10.1007/s11042-010-0530-2
   Cerekovic A, 2009, LECT NOTES COMPUT SC, V5820, P7
   Corradini A., 2005, INT C MULT INT, P63
   Cowell A. J., 2003, 5 INT S HUM COMP INT
   Doswell JT, 2005, FR ART INT, V125, P957
   Foster ME, 2007, LECT NOTES COMPUT SC, V4555, P828
   Goh O. S., 2006, INT J INFORM TECHNOL, V3, P257
   Goh OS, 2006, 2006 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY, WORKSHOPS PROCEEDINGS, P397, DOI 10.1109/WI-IATW.2006.37
   Graesser AC, 2004, BEHAV RES METH INS C, V36, P180, DOI 10.3758/BF03195563
   Gurzki T., 2001, P E BUS E WORK C, P305
   Huang HH, 2008, MULTIAGENT GRID SYST, V4, P371, DOI 10.3233/MGS-2008-4404
   Isbister K., 2002, AAMAS 02 WORKSH EMB
   Kamyab K., 2001, AISB Journal, V1, P61
   Kimura M., 2006, P 9 PAC RIM INT WORK, P162
   Lai LF, 2011, IEEE INT CONF FUZZY, P2684
   Linz P., 2011, INTRO FORMAL LANGUAG, V5
   Louwerse MM, 2009, APPL COGNITIVE PSYCH, V23, P1244, DOI 10.1002/acp.1527
   Massaro D. W., 2005, IEEE P 38 ANN HAW IN, P2962
   Mazuel Laurent, 2008, Web Intelligence and Agent Systems, V6, P43, DOI 10.3233/WIA-2008-0129
   Mori J., 2003, P AAMAS 03 WORKSH W1, P58
   Paraiso EC, 2008, INT C COMP SUPP COOP, P337
   Pelachaud C, 2002, KNOWL ENG REV, V17, P181, DOI 10.1017/S0269888902000218
   Rehm M, 2005, LECT NOTES COMPUT SC, V3711, P180
   Russell S., 2010, ARTIFICIAL INTELLIGE
   Sansonnet JP, 2006, LECT NOTES ARTIF INT, V4133, P145
   van Deemter K, 2008, ARTIF INTELL, V172, P1219, DOI 10.1016/j.artint.2008.02.002
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Widyantoro DH, 2001, 10TH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P1291, DOI 10.1109/FUZZ.2001.1008895
   WIDYANTORO DHY, 2001, JOINT 9 IFSA WORLD C
   Wik P, 2009, SPEECH COMMUN, V51, P1024, DOI 10.1016/j.specom.2009.05.006
   Woo CW, 2006, ARTIF INTELL MED, V38, P25, DOI 10.1016/j.artmed.2005.10.004
   Xu BQ, 2003, ASIA-PACIFIC CONFERENCE ON ENVIRONMENTAL ELECTROMAGNETICS, CEEM'2003, PROCEEDINGS, P40
NR 39
TC 6
Z9 6
U1 0
U2 19
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2013
VL 25
IS 3
BP 811
EP 823
DI 10.3233/IFS-120687
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 176SX
UT WOS:000321326100029
DA 2022-08-02
ER

PT J
AU ter Stal, S
   Kramer, LL
   Tabak, M
   op den Akker, H
   Hermens, H
AF ter Stal, Silke
   Kramer, Lean Leonie
   Tabak, Monique
   op den Akker, Harm
   Hermens, Hermie
TI Design Features of Embodied Conversational Agents in eHealth: a
   Literature Review
SO INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES
LA English
DT Review
DE Embodied Conversational Agent; eHealth; design feature; review
ID PEDAGOGICAL AGENTS; VISUAL PRESENCE; VIRTUAL HUMANS; IMPACT; APPEARANCE;
   PERSUASION; ENGAGEMENT; CHARACTERS
AB Embodied conversational agents (ECAs) are gaining interest to elicit user engagement and stimulate actual use of eHealth applications. In this literature review, we identify the researched design features for ECAs in eHealth, the outcome variables that were used to measure the effect of these design features and what the found effects for each variable were. Searches were performed in Scopus, ACM Digital Library, PsychINFO, Pubmed and IEEE Xplore Digital Library, resulting in 1284 identified articles of which 33 articles were included. The agents speech and/or textual output and its facial and gaze expressions were the most common design features. Little research was performed on the agent's looks. The measured effect of these design features was often on the perception of the agent's and user's characteristics, relation with the agent, system usage, intention to use, usability and behaviour change. Results show that emotion and relational behaviour seem to positively affect the perception of the agents characteristics and that relational behaviour also seems to positively affect the relation with the agent, usability and intention to use. However, these design features do not necessarily lead to behaviour change. This review showed that consensus on design features of ECAs in eHealth is far from established. Follow-up research should include more research on the effects of all design features, especially research on the effects in a long-term, daily life setting, and replication of studies on the effects of design features performed in other contexts than eHealth.
C1 [ter Stal, Silke; Tabak, Monique; op den Akker, Harm; Hermens, Hermie] Roessingh Res & Dev, eHlth Grp, Enschede, Netherlands.
   [ter Stal, Silke; Tabak, Monique; op den Akker, Harm; Hermens, Hermie] Univ Twente, Fac Elect Engn Math & Comp Sci, Biomed Syst & Signals Grp, Enschede, Netherlands.
   [Kramer, Lean Leonie] Wageningen Univ & Res, Strateg Commun Grp, Wageningen, Netherlands.
   [Kramer, Lean Leonie] Wageningen Univ & Res, Consumpt & Hlth Lifestyles Grp, Wageningen, Netherlands.
RP ter Stal, S (corresponding author), Roessingh Res & Dev, eHlth Grp, Enschede, Netherlands.; ter Stal, S (corresponding author), Univ Twente, Fac Elect Engn Math & Comp Sci, Biomed Syst & Signals Grp, Enschede, Netherlands.
EM s.terstal@rrd.nl
OI Tabak, Monique/0000-0001-5082-1112; ter Stal, Silke/0000-0001-9458-717X;
   op den Akker, Harm/0000-0001-6312-6063
FU European Commissions Horizon 2020 Research and Innovation Programme
   project Council of Coaches [769553]
FX yThis work was supported by the European Commissions Horizon 2020
   Research and Innovation Programme project Council of Coaches (Grant
   Agreement Number 769553).
CR Acosta JC, 2011, SPEECH COMMUN, V53, P1137, DOI 10.1016/j.specom.2010.11.006
   Alsharbi B., 2017, P 9 INT C COMP AUT E, P11
   Amini Reza, 2014, Advancing the Impact of Design Science: Moving from Theory to Practice. 9th International Conference, DESRIST 2014. Proceedings: LNCS 8463, P433, DOI 10.1007/978-3-319-06701-8_40
   Amini R, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI 2013), P46, DOI 10.1109/ICHI.2013.13
   [Anonymous], [No title captured]
   Baylor AL, 2004, LECT NOTES COMPUT SC, V3220, P592
   Baylor AL, 2009, PHILOS T R SOC B, V364, P3559, DOI 10.1098/rstb.2009.0148
   Berry DC, 2005, INT J HUM-COMPUT ST, V63, P304, DOI 10.1016/j.ijhcs.2005.03.006
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T., 2007, CHI 07 HUM FACT COMP, P2291, DOI DOI 10.1145/1240866.1240996
   Bickmore T., 2004, CHI 04 HUM FACT COMP, P1489, DOI DOI 10.1145/985921.986097
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore T, 2010, LECT NOTES ARTIF INT, V6356, P399, DOI 10.1007/978-3-642-15892-6_43
   Bickmore T, 2010, APPL ARTIF INTELL, V24, P648, DOI 10.1080/08839514.2010.492259
   Bickmore T, 2009, LECT NOTES ARTIF INT, V5773, P6
   Bickmore TW, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1265
   Bickmore TW, 2005, INTERACT COMPUT, V17, P711, DOI 10.1016/j.intcom.2005.09.002
   Clark H. H., 1991, PERSPECTIVES SOCIALL, V13, P127, DOI DOI 10.1037/10096-006
   Cowell AJ, 2003, LECT NOTES ARTIF INT, V2792, P301
   Creed C, 2015, INTERACT COMPUT, V27, P172, DOI 10.1093/iwc/iwt064
   Creed C, 2012, INTERACT COMPUT, V24, P339, DOI 10.1016/j.intcom.2012.05.004
   Dryer DC, 1999, APPL ARTIF INTELL, V13, P273, DOI 10.1080/088395199117423
   Forlizzi Jodi, 2007, P 2007 C DES PLEAS P, P209
   Frost J., 2012, P 2012 ACM ANN C HUM, P2465, DOI DOI 10.1145/2212776.2223820
   Grillon H, 2008, 2008 VIRTUAL REHABILITATION, P205, DOI 10.1109/ICVR.2008.4625161
   Guadagno RE, 2007, MEDIA PSYCHOL, V10, P1
   Jansen Kosterink S., 2016, ETELEMED 2016 8 INT, P57
   Kang S.-H., 2011, ANN REV CYBERTHERAPY, V167, P143
   Kaptein M, 2012, ACM T INTERACT INTEL, V2, DOI 10.1145/2209310.2209313
   Khan R., 2009, IFIP C HUM COMP INT, P85, DOI [10.1007/978-3-642-03655-2_10, DOI 10.1007/978-3-642-03655-2_10]
   Khan RF, 2014, INT J HUM-COMPUT INT, V30, P142, DOI 10.1080/10447318.2013.839904
   Kim Y, 2007, J COMPUT ASSIST LEAR, V23, P220, DOI 10.1111/j.1365-2729.2006.00210.x
   Kim Y., 2003, E LEARN 2003 WORLD C, P2237, DOI [10.1007/978-3-540-30139-4_56, DOI 10.1007/978-3-540-30139-4{\_}56]
   Kramer LL, 2020, J MED INTERNET RES, V22, DOI 10.2196/14058
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lee JER, 2007, J COMMUN, V57, P183, DOI 10.1111/j.1460-2466.2007.00339.x
   Lee YH, 2018, CYBERPSYCH BEH SOC N, V21, P173, DOI 10.1089/cyber.2017.0451
   Malhotra A., 2016, P 10 EAI INT C PERV, P13
   Nguyen H., 2009, P 4 INT C PERS TECHN, DOI [10.1145/1541948., DOI 10.1145/1541948]
   Nguyen H, 2007, LECT NOTES COMPUT SC, V4744, P231
   Nijland N., 2011, THESIS, DOI [10.3990/1.9789036531337, DOI 10.3990/1.9789036531337]
   Olafsson S, 2017, LECT NOTES ARTIF INT, V10498, P325, DOI 10.1007/978-3-319-67401-8_41
   Parmar D, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P301, DOI 10.1145/3267851.3267915
   Pelachaud C, 2009, SPEECH COMMUN, V51, P630, DOI 10.1016/j.specom.2008.04.009
   Pfeifer Vardoulakis Laura, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P289, DOI 10.1007/978-3-642-33197-8_30
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Ring L, 2014, LECT NOTES ARTIF INT, V8637, P374, DOI 10.1007/978-3-319-09767-1_49
   Rishe N, 2013, ACM TMIS, V4, P1, DOI [10.1145/2544103, DOI 10.1145/2544103]
   Rist T, 2004, COG TECH, P377
   Robertson S, 2015, LECT NOTES COMPUT SC, V9192, P427, DOI 10.1007/978-3-319-20609-7_40
   Rosenberg-Kima RB, 2008, COMPUT HUM BEHAV, V24, P2741, DOI 10.1016/j.chb.2008.03.017
   Ruttkay Z., 2004, BROWS TRUST EVALUATI, P27, DOI [10.1007/1-4020-2730-3_2, DOI 10.1007/1-4020-2730-3_2]
   Schmeil A, 2014, LECT NOTES COMPUT SC, V8519, P91, DOI 10.1007/978-3-319-07635-5_10
   Scholten MR, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7351
   Silverman B G, 2001, Health Care Manag Sci, V4, P213, DOI 10.1023/A:1011448916375
   Skalski P, 2007, MEDIA PSYCHOL, V10, P385, DOI 10.1080/15213260701533102
   Strassmann C, 2017, LECT NOTES ARTIF INT, V10498, P413, DOI 10.1007/978-3-319-67401-8_51
   Tielman ML, 2017, TECHNOL HEALTH CARE, V25, P1081, DOI 10.3233/THC-170899
   van Vugt HC, 2006, LECT NOTES ARTIF INT, V4133, P1
   Veletsianos G, 2010, COMPUT EDUC, V55, P576, DOI 10.1016/j.compedu.2010.02.019
   Veletsianos G, 2009, J EDUC COMPUT RES, V41, P171, DOI 10.2190/EC.41.2.c
   von der Putten A.M., 2009, 12 ANN INT WORKSH PR, P1
   Wissen Arlette, 2016, Persuasive Technology. 11th International Conference, PERSUASIVE 2016. Proceedings: LNCS 9638, P263, DOI 10.1007/978-3-319-31510-2_23
   Yin LX, 2010, LECT NOTES ARTIF INT, V6356, P343, DOI 10.1007/978-3-642-15892-6_36
   Zheng PF, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SERVICES COMPUTING (SCC 2014), P528, DOI 10.1109/SCC.2014.76
   Zhou S, 2017, 2017 INTERNATIONAL CONFERENCE ON CULTURE AND COMPUTING (CULTURE AND COMPUTING), P89, DOI 10.1109/Culture.and.Computing.2017.42
NR 66
TC 33
Z9 33
U1 8
U2 29
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 1071-5819
EI 1095-9300
J9 INT J HUM-COMPUT ST
JI Int. J. Hum.-Comput. Stud.
PD JUN
PY 2020
VL 138
AR 102409
DI 10.1016/j.ijhcs.2020.102409
PG 22
WC Computer Science, Cybernetics; Ergonomics; Psychology, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Psychology
GA LD1ZP
UT WOS:000525830800006
OA Green Published, hybrid
DA 2022-08-02
ER

PT J
AU Massfeller, HF
   Strong, T
AF Massfeller, Helen F.
   Strong, Tom
TI Clients as conversational agents
SO PATIENT EDUCATION AND COUNSELING
LA English
DT Article
DE Conversational agency; Psychotherapy; Discourse analysis
AB Objective: Conversational agency is our invented term that orients us to ways in which clients participate in therapeutic dialogues. In this study we examined how clients' conversational correctives and initiatives influenced collaborative therapeutic consultations.
   Methods: Thirty-five single-session lifestyle consultations were videotaped in which adult clients volunteered to discuss concerns of non-clinical severity with a counselor. We discursively microanalyzed excerpts where clients initiated topic shifts or corrected counselor misunderstandings and how counselors responded to them.
   Results: Clients were actively involved in co-managing conversational developments during the consultations. They influenced the content and course of the conversations with the counselors by correcting, interrupting, or speaking from positions contrary or unrelated to those of the counselors.
   Conclusion: Clients observably influenced the conversational agenda through their correctives and. initiatives if counselors were responsive during face-to-face consultations.
   Practice implications: Clinicians should demonstrate increased sensitivity and relational responsivity by intentionally engaging with clients' agentive contributions to consultative dialogues. (C) 2012 Elsevier Ireland Ltd. All rights reserved.
C1 [Massfeller, Helen F.; Strong, Tom] Univ Calgary, Calgary, AB, Canada.
RP Massfeller, HF (corresponding author), Univ Calgary, 2500 Univ Dr NW,EdT 320, Calgary, AB, Canada.
EM hfmassfe@ucalgary.ca
FU Social Sciences and Humanities Research Council of Canada
FX This research was funded by a grant from the Social Sciences and
   Humanities Research Council of Canada to the second author.
CR Andersen T., 1991, REFLECTING TEAM DIAL
   ANDERSON H, 1988, FAM PROCESS, V27, P371, DOI 10.1111/j.1545-5300.1988.00371.x
   Anderson H, 2001, J FAM THER, V23, P339, DOI 10.1111/1467-6427.00189
   Anderson H., 1997, CONVERSATION LANGUAG
   [Anonymous], 1981, FORMS TALK
   Austin J. L., 1975, DO THINGS WORDS, VSecond
   Bakhtin Mikhail, 1984, PROBLEMS DOSTOEVSKYS
   Bavelas JB, 2000, J PERS SOC PSYCHOL, V79, P941, DOI 10.1037/0022-3514.79.6.941
   Bavelas JB, 2010, ASCOLTO, P39
   Berg I. K., 1993, NEW LANGUAGE CHANGE, P5
   Bohart AC, 2000, J PSYCHOTHER INTEGR, V10, P127, DOI 10.1023/A:1009444132104
   De Shazer S, 1988, CLUES INVESTIGATING
   DUNCAN BL, 2000, HEROIC CLIENT
   Edwards D., 1992, DISCURSIVE PSYCHOL
   Egan G., 2010, SKILLED HELPER PROBL
   Ferrara Kathleen W., 1994, THERAPEUTIC WAYS WOR
   Foucault M., 1977, DISCIPLINE PUNISH
   Friedlander ML, 2012, PSYCHOTHERAPY, V49, P349, DOI 10.1037/a0023447
   Gadamer H.G., 1988, TRUTH METHOD
   Garfinkel H., 2002, ETHNOMETHODOLOGYS PR
   Gergen K. J., 2006, THERAPEUTIC REALITIE
   Gergen K. J., 1999, INVITATION SOCIAL CO
   Heritage J., 1984, GARFINKEL ETHNOMETHO
   HOUSE R, 2003, THERAPY MODERNITY
   Kogan SM, 1998, J FAM THER, V20, P229, DOI 10.1111/1467-6427.00085
   Lakoff George, 1980, METAPHORS WE LIVE
   LINELL P, 1988, LINGUISTICS, V26, P415, DOI 10.1515/ling.1988.26.3.415
   Linell P., 1998, APPROACHING DIALOGUE
   LOBLEY J, 2001, ANAL TALK I SETTINGS, P113
   Mackrill T, 2009, J HUMANIST PSYCHOL, V49, P193, DOI 10.1177/0022167808319726
   Madsen W. C, 1999, COLLABORATIVE THERAP
   Monk G, 2003, FAM PROCESS, V42, P19, DOI 10.1111/j.1545-5300.2003.00019.x
   Perakyla A, 2008, CONVERSATION ANAL PS, P5
   Raymond G., QUESTIONS IN PRESS
   RENNIE DL, 1994, J COUNS PSYCHOL, V41, P427, DOI 10.1037/0022-0167.41.4.427
   Rennie DL, 2000, J PSYCHOTHER INTEGR, V10, P151, DOI 10.1023/A:1009496116174
   RENNIE DL, 1998, PERSON CTR COUNSELIN
   Rogers C. R.., 1961, BECOMING PERSON
   Roy-Chowdhury S, 2006, J FAM THER, V28, P153, DOI 10.1111/j.1467-6427.2006.00344.x
   Schiffrin Deborah, 1987, DISCOURSE MARKERS
   Schon DA., 1983, REFLECTIVE PRACTITIO
   Seikkula J., 2006, DIALOGICAL M SOCIAL
   Shotter J., 1993, CONVERSATIONAL REALI
   Strong T, 2005, BRIT J GUID COUNS, V33, P513, DOI 10.1080/03069880500327538
   Strong T., 2008, COUNSELLING PSYCHOTH, V8, P65
   Strong T, 2010, INT J ADV COUNS, V32, P14, DOI 10.1007/s10447-009-9085-1
   Strong T, 2010, J COUNS DEV, V88, P332, DOI 10.1002/j.1556-6678.2010.tb00030.x
   Strong T, 2008, J CONTEMP PSYCHOTHER, V38, P185, DOI 10.1007/s10879-008-9076-2
   Strong T, 2007, CAN PSYCHOL, V48, P94, DOI 10.1037/cp2007011
   Ten Have P., 1999, DOING CONVERSATION A
   TOMM K, 1988, FAM PROCESS, V27, P1, DOI 10.1111/j.1545-5300.1988.00001.x
   Wang JJ, 2006, DISCOURSE SOC, V17, P529, DOI 10.1177/0957926506063127
   WEINGARTEN K, 1992, FAM PROCESS, V31, P45, DOI 10.1111/j.1545-5300.1992.00045.x
   White M., 2007, MAPS NARRATIVE PRACT
   WHITE M, 1988, DULWICH CTR NEWS WIN, P8
   Wickman SA, 2003, J COUNS DEV, V81, P178, DOI 10.1002/j.1556-6678.2003.tb00239.x
   Wooffitt R., 2005, CONVERSATION ANAL DI
NR 57
TC 7
Z9 7
U1 0
U2 5
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0738-3991
J9 PATIENT EDUC COUNS
JI Patient Educ. Couns.
PD AUG
PY 2012
VL 88
IS 2
BP 196
EP 202
DI 10.1016/j.pec.2012.03.014
PG 7
WC Public, Environmental & Occupational Health; Social Sciences,
   Interdisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Public, Environmental & Occupational Health; Social Sciences - Other
   Topics
GA 994EW
UT WOS:000307914700007
PM 22525804
DA 2022-08-02
ER

PT S
AU Chateau, N
   Maffiolo, V
   Pican, N
   Mersiol, M
AF Chateau, N
   Maffiolo, V
   Pican, N
   Mersiol, M
BE Tao, J
   Picard, RW
TI The effect of embodied conversational agents' speech quality on users'
   attention and emotion
SO AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 1st International Conference on Affective Computing and Intelligent
   Interaction
CY OCT 22-24, 2005
CL Beijing, PEOPLES R CHINA
SP Nokia Ltd, Siemens Ltd, Int Speech Commun Assoc, Natl Nat Sci Fdn China, Chinese Assoc Automat, China Soc Image & Graph, China Comp Federat, Natl High Tech Res & Dev Program
AB This study investigates the influence of the speech quality of Embodied Conversational Agents (ECAs) on users' perception, behavior and emotions. Twenty-four subjects interacted in a Wizard of Oz (WOZ) setup with two ECAs in two scenarios of a virtual theater partner application. In both scenarios, each ECA had three different speech qualities: natural, high-quality synthetic and low-quality synthetic. Eye gaze data show that subjects' visual attention was not influenced by ECA's speech quality, but by their look. On the other hand, subjects' self-report of emotions and verbal descriptions of their perceptions were influenced by ECAs' speech quality. Finally, Galvanic Skin Response data were neither influenced by ECAs' look, nor by their speech quality. These results stress the importance of the correct matching of the auditory and visual modalities of ECAs and give methodological insights for the assessment of user's perception, behavior and emotions when interacting with virtual characters.
C1 France Telecom, R&D Div, Technol Res Ctr, F-22307 Lannion, France.
RP Chateau, N (corresponding author), France Telecom, R&D Div, Technol Res Ctr, 2 Ave Pierre Marzin, F-22307 Lannion, France.
EM noel.chateau@francetelecom.com; valerie.maffiolo@francetelecom.com;
   nathalie.pican@francetelecom.com; marc.mersiol@francetelecom.com
CR CAMPBELL N, 2004, LECT NOTES COMPUTER
   CASSELL J, 2000, EMOBODIED CONVERSATI
   CHATEAU N, 2005, P CHI2005 WORKSH INN
   Darves C, 2002, P INT JOINT C AUT AG
   Desmet PMA, 2000, ADV CONSUM RES, V27, P111
   HOOK K, 2003, SENSE SENSIBILITY EV
   JONES MR, 1993, THINKING SOUND COGNI, P69
   LOCKHART R, 1967, PSYCHOPHYSIOLOGY, V9, P437
   Mersiol M, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P69, DOI 10.1109/ICMI.2002.1166971
   Narayanan S., 2004, TEXT SPEECH SYNTHESI
   NIJHOLT A, 2001, P 5 BIANN C ART NEUR
   PELE D, 2003, AAMAS WORKSH EMB CON
   Polkosky M. D., 2003, International Journal of Speech Technology, V6, P161, DOI 10.1023/A:1022390615396
   Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372
   Ruttkay Z., 2004, BROWS TRUST EVALUATI
   Ruttkay Z, 2002, P AAMAS02 WORKSH EMB
NR 16
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-29621-2
J9 LECT NOTES COMPUT SC
PY 2005
VL 3784
BP 652
EP 659
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BDM83
UT WOS:000234342700084
DA 2022-08-02
ER

PT J
AU Cassell, J
   Thorisson, KR
AF Cassell, J
   Thorisson, KR
TI The power of a nod and a glance: Envelope vs. emotional feedback in
   animated conversational agents
SO APPLIED ARTIFICIAL INTELLIGENCE
LA English
DT Article
AB In this article we describe results from an experiment. of user interaction with autonomous, human-like (humanoid) conversational agents. We hypothesize that for embodied conversational agents, nonverbal behaviors related to the process of conversation, what we call envelope feedback, is much more important than other feedback, such as emotional expression. We test this hypothesis by having subjects interact with three autonomous agents, all capable of full-duplex multimodal interaction: able to generate and recognize speech, intonation,facial displays, and gesture. Each agent, however, gave a different kind of feedback: (I) content-related only, (2) content + envelope feedback, and (3) content + emotional. Content-related feedback includes answering questions and executing commands, envelope feedback includes behaviors such as gaze, manual beat gesture, and head movements; emotional feedback includes smiles and looks of puzzlement. Subjects' evaluations of the system were collected with a questionnaire, and videotapes of their speech patterns and behaviors were scored according to how often the users repeated themselves, how often they hesitated, and how often they got frustrated. The results confirm our hypothesis that envelope feedback is mole important in intel action than emotional feedback and that envelope feedback plays a crucial role in supporting the process of dialog. A secondary result from this study shows that users give our multimodal conversational humanoids very high ratings of lifelikeness and fluidity of interaction when the agents are capable of giving such feedback.
C1 MIT, Media Lab, Gesture Narrat Language Grp, Cambridge, MA 02139 USA.
RP Cassell, J (corresponding author), MIT, Media Lab, Gesture Narrat Language Grp, 20 Ames St,E15-315, Cambridge, MA 02139 USA.
RI Thórisson, Kristinn R/C-3921-2008; Cassell, Justine/B-7123-2009
OI Thorisson, Kristinn R./0000-0003-3842-0564
CR ANDRE E, 1996, P AAAI 96, V1, P142
   BATES J, 1994, COMMUN ACM, V37, P122, DOI 10.1145/176789.176803
   BRITTON BCJ, 1991, THESIS MIT CAMBRIDGE
   CASSELL J, 1994, COMPUTER GRAPHICS, V28, P413
   CASSELL J, IN PRESS SPOKEN DIAL
   CASSELL J, IN PRESS MACHINE CON
   CAWSEY A, 1993, INT J MAN MACH STUD, V38, P169, DOI 10.1006/imms.1993.1009
   Duncan S., 1974, NONVERBAL COMMUNICAT
   EKMAN P, 1984, UNMASKING FACE
   Elliott C., 1997, Proceedings of the First International Conference on Autonomous Agents, P451, DOI 10.1145/267658.267768
   HASEGAWA O, 1995, P INT JOINT C ART IN, P82
   HAUPTMANN AG, 1989, P C HUM FACT COMP SY, P241
   King W.J., 1996, P CHI 96, P289
   KODA T, 1996, HUM COMP INT 96 AUG
   LANIER J, 1995, INTERACTIONS, V2, P66, DOI DOI 10.1145/208666.208684
   LAUREL B, 1992, CHI 92 C P ACM C HUM, P67
   Lester J., 1997, IJCAI 97 WORKSH AN I, P61
   MAES P, 1994, COMMUN ACM, V37, P31
   MAULSBY D, 1993, P ACM SIGCHI C HUM F, P277
   McNeill D., 1992, HAND MIND WHAT GESTU
   Moore J. D., 1993, Computational Linguistics, V19, P651
   NAGARUR NN, 1994, IND MANAGE DATA SYST, V94, P22, DOI 10.1108/02635579410072135
   Nass C., 1993, INTERACT 93 CHI 93 C, P111
   Neal J. G., 1991, Intelligent User Interfaces, P11
   OCHSMAN RB, 1974, INT J MAN MACH STUD, V6, P579, DOI 10.1016/S0020-7373(74)80019-2
   Pelachaud C., 1991, COMPUTER ANIMATION 9, P15
   Ploog D., 1979, HUMAN ETHOLOGY CLAIM, P169, DOI DOI 10.1007/978-1-4020-2783-33
   SPARRELL CJ, 1993, THESIS MIT CAMBRIDGE
   Takeuchi A., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P450
   TAKEUCHI A, 1993, P ACM IFIP INTERCHI, P187
   Thorisson K. R., 1994, AAAI SPRING S BEL AG, P86
   THORISSON KR, 1992, SIGCHI P 92, P653
   Wahlster W., 1991, Intelligent User Interfaces, P45
   Yngve VH., 1970, 6 REG M CHIC LING SO, P567
NR 34
TC 164
Z9 164
U1 2
U2 21
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA
SN 0883-9514
J9 APPL ARTIF INTELL
JI Appl. Artif. Intell.
PD JUN-AUG
PY 1999
VL 13
IS 4-5
BP 519
EP 538
DI 10.1080/088395199117360
PG 20
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 192DT
UT WOS:000080063500007
DA 2022-08-02
ER

PT C
AU van Heerden, A
   Ntinga, X
   Vilakazi, K
AF van Heerden, Alastair
   Ntinga, Xolani
   Vilakazi, Khanya
GP IEEE
TI The potential of conversational agents to provide a rapid HIV counseling
   and testing services
SO 2017 INTERNATIONAL CONFERENCE ON THE FRONTIERS AND ADVANCES IN DATA
   SCIENCE (FADS)
LA English
DT Proceedings Paper
CT International Conference on the Frontiers and Advances in Data Science
   (FADS)
CY OCT 23-25, 2017
CL Xian, PEOPLES R CHINA
SP Univ Essex, NW Univ, IEEE UK & RI Comp Chapter, IEEE Xian Sect, SAGE Publishing
DE conversational agents; digital assistants; HIV; public health; pre-test
   counseling; HIV testing; low-and middle-income countries
ID HEALTH-CARE; COMMUNITY; BARRIERS
AB In low-and middle-income countries where demand for health services outstrips the available supply of skilled labor, advances in information and communication technologies have already been shown to hold promise. While much of the mHealth literature continues to explore mature technologies such as text message and web portals, continual advancement in machine learning opens innovative new areas of exploration for public health practitioners. This paper explores one such possibility, a conversational agent, able to guide users through an HIV counseling and testing session. Using commercially available software (http://api.ai), an agent was designed and built according to the Center for Disease Control's guidelines for the provision of HIV counseling and testing in a non-clinical setting. The agent was linked to the Telegram chat client (http://telegram.org) and 10 testers were invited to participate in a simulated HIV counseling interaction. Six testers found that talking to the agent felt natural, and equivalent to chatting to a human. Seven said they would feel comfortable taking a real HIV test with the agent. Key concerns with the current agent were the use of overly formal language, the speed at which the agent responded (too fast) and the agent either misunderstanding or not understanding the tester. Positive sentiment towards the agent included the fact that testers felt like the session was more private and anonymous, and avoided the need for them to visit a public health facility and stand in a long queue to get tested.
C1 [van Heerden, Alastair; Ntinga, Xolani; Vilakazi, Khanya] Human Sci Res Council, Human & Social Dev, Pietermaritzburg, South Africa.
RP van Heerden, A (corresponding author), Human Sci Res Council, Human & Social Dev, Pietermaritzburg, South Africa.
RI Van Heerden, Alastair/AAY-6262-2020
OI Van Heerden, Alastair/0000-0003-2530-6885
CR Agarwal R, 2010, INFORM SYST RES, V21, P796, DOI 10.1287/isre.1100.0327
   Bessen J.E., 2017, AUTOMATION JOBS TECH
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore TW, 2010, INTERACT COMPUT, V22, P289, DOI 10.1016/j.intcom.2009.12.001
   Centers for Disease Control and Prevention, 2016, IMPL HIV TEST NONCL
   Frey CB, 2017, TECHNOL FORECAST SOC, V114, P254, DOI 10.1016/j.techfore.2016.08.019
   Kwapong GD, 2014, BMC HEALTH SERV RES, V14, DOI 10.1186/1472-6963-14-267
   Le Q. V., 2015, NEURAL CONVERSATIONA
   Leskovec J., 2016, LARGE SCALE ANAL COU
   Makusha T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0122783
   Marsch L., 2014, BEHAV HEALTHCARE TEC
   Mayosi BM, 2014, NEW ENGL J MED, V371, P1344, DOI 10.1056/NEJMsr1405012
   Micoulaud-Franchi JA, 2016, LECT NOTES ARTIF INT, V10011, P416, DOI 10.1007/978-3-319-47665-0_45
   Poku N., POLITICAL EC AIDS AF
   Richter M, 2010, SAMJ S AFR MED J, V100, P636, DOI 10.7196/SAMJ.4198
   Sharma M, 2015, NATURE, V528, pS77, DOI 10.1038/nature16044
   Soucat A, 2013, DIR DEV, P1, DOI 10.1596/978-0-8213-9555-4
   Strauss M, 2015, BMC HEALTH SERV RES, V15, DOI 10.1186/s12913-015-0922-0
   van Heerden A, 2017, SOC SCI MED, V183, P97, DOI 10.1016/j.socscimed.2017.04.046
NR 19
TC 5
Z9 5
U1 0
U2 3
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-5386-3148-5
PY 2017
BP 90
EP 94
PG 5
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BL6PD
UT WOS:000454608700018
DA 2022-08-02
ER

PT J
AU Provoost, S
   Lau, HM
   Ruwaard, J
   Riper, H
AF Provoost, Simon
   Lau, Ho Ming
   Ruwaard, Jeroen
   Riper, Heleen
TI Embodied Conversational Agents in Clinical Psychology: A Scoping Review
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Review
DE eHealth; review; embodied conversational agent; human computer
   interaction; clinical psychology; mental disorders; intelligent agent;
   health behavior
ID HUMANOID ROBOT; RELATIONAL AGENTS; VIRTUAL HUMANS; YOUNG-CHILDREN;
   INTERVENTION; DEPRESSION; BEHAVIOR; THERAPY; ADOLESCENTS; PEOPLE
AB Background: Embodied conversational agents (ECAs) are computer-generated characters that simulate key properties of human face-to-face conversation, such as verbal and nonverbal behavior. In Internet-based eHealth interventions, ECAs may be used for the delivery of automated human support factors.
   Objective: We aim to provide an overview of the technological and clinical possibilities, as well as the evidence base for ECA applications in clinical psychology, to inform health professionals about the activity in this field of research.
   Methods: Given the large variety of applied methodologies, types of applications, and scientific disciplines involved in ECA research, we conducted a systematic scoping review. Scoping reviews aim to map key concepts and types of evidence underlying an area of research, and answer less-specific questions than traditional systematic reviews. Systematic searches for ECA applications in the treatment of mood, anxiety, psychotic, autism spectrum, and substance use disorders were conducted in databases in the fields of psychology and computer science, as well as in interdisciplinary databases. Studies were included if they conveyed primary research findings on an ECA application that targeted one of the disorders. We mapped each study's background information, how the different disorders were addressed, how ECAs and users could interact with one another, methodological aspects, and the study's aims and outcomes.
   Results: This study included N=54 publications (N=49 studies). More than half of the studies (n=26) focused on autism treatment, and ECAs were used most often for social skills training (n=23). Applications ranged from simple reinforcement of social behaviors through emotional expressions to sophisticated multimodal conversational systems. Most applications (n=43) were still in the development and piloting phase, that is, not yet ready for routine practice evaluation or application. Few studies conducted controlled research into clinical effects of ECAs, such as a reduction in symptom severity.
   Conclusions: ECAs for mental disorders are emerging. State-of-the-art techniques, involving, for example, communication through natural language or nonverbal behavior, are increasingly being considered and adopted for psychotherapeutic interventions in ECA research with promising results. However, evidence on their clinical application remains scarce. At present, their value to clinical practice lies mostly in the experimental determination of critical human support factors. In the context of using ECAs as an adjunct to existing interventions with the aim of supporting users, important questions remain with regard to the personalization of ECAs' interaction with users, and the optimal timing and manner of providing support. To increase the evidence base with regard to Internet interventions, we propose an additional focus on low-tech ECA solutions that can be rapidly developed, tested, and applied in routine practice.
C1 [Provoost, Simon; Ruwaard, Jeroen; Riper, Heleen] Vrije Univ Amsterdam, Dept Clin Neuro & Dev Psychol, Sect Clin Psychol, Fac Behav & Movement Sci, Van der Boechorststr 1, NL-1081 BT Amsterdam, Netherlands.
   [Provoost, Simon; Lau, Ho Ming; Ruwaard, Jeroen; Riper, Heleen] Vrije Univ Amsterdam, EMGO Inst Hlth & Care Res, Med Ctr, Amsterdam, Netherlands.
   [Lau, Ho Ming; Riper, Heleen] GGZ InGeest, Amsterdam, Netherlands.
   [Riper, Heleen] Univ Southern Denmark, Telepsychiat Unit, Fac Hlth Sci, Odense, Denmark.
RP Provoost, S (corresponding author), Vrije Univ Amsterdam, Dept Clin Neuro & Dev Psychol, Sect Clin Psychol, Fac Behav & Movement Sci, Van der Boechorststr 1, NL-1081 BT Amsterdam, Netherlands.
EM s.j.provoost@vu.nl
OI Ruwaard, Jeroen/0000-0002-4510-997X; Riper, Heleen/0000-0002-8144-8901
CR Agarwal R, 2013, P 7 INT C UN ACC HUM, V2, P21, DOI 10.1007/978-3-642-39191-0_49
   Alcorn Alyssa, 2011, ARTIFICIAL INTELLIGE
   Alemi M, 2014, LECT NOTES ARTIF INT, V8755, P11, DOI 10.1007/978-3-319-11973-1_2
   Amirabdollahian F, 2011, IEEE ENG MED BIO, P5347, DOI 10.1109/IEMBS.2011.6091323
   An Lawrence C., 2013, Journal of the National Cancer Institute Monographs, P209, DOI 10.1093/jncimonographs/lgt021
   Andrews G., 2010, PLOS ONE
   Arksey H., 2005, INT J SOC RES METHOD, V8, P19, DOI [DOI 10.1080/1364557032000119616, 10.1080/1364557032000119616]
   Bamasak Omaima, 2013, Design, User Experience, and Usability. Health, Learning, Playing, Cultural, and Cross-Cultural User Experience.Second International Conference, DUXU 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8013, P342, DOI 10.1007/978-3-642-39241-2_38
   Baylor AL, 2004, LECT NOTES COMPUT SC, V3220, P592
   Baylor AL, 2011, ETR&D-EDUC TECH RES, V59, P291, DOI 10.1007/s11423-011-9196-3
   Bekele E, 2014, AUTISM, V18, P598, DOI 10.1177/1362361313479454
   Bernardini S, 2014, INFORM SCIENCES, V264, P41, DOI 10.1016/j.ins.2013.10.027
   Bickmore T, 2010, HARVARD REV PSYCHIAT, V18, P119, DOI 10.3109/10673221003707538
   Bickmore T, 2009, LECT NOTES ARTIF INT, V5773, P425, DOI 10.1007/978-3-642-04380-2_46
   Bickmore TW, 2010, INTERACT COMPUT, V22, P289, DOI 10.1016/j.intcom.2009.12.001
   Bickmore TW, 2010, INTERACT COMPUT, V22, P276, DOI 10.1016/j.intcom.2010.02.001
   Boccanfuso L, 2010, LECT NOTES ARTIF INT, V6414, P265
   Broekens Joost, 2009, Gerontechnology, V8, P94
   Cheek C, 2014, JMIR SERIOUS GAMES, V2, P20, DOI 10.2196/games.3183
   Chen JY, 2010, LECT NOTES COMPUT SC, V6483, P41, DOI 10.1007/978-3-642-17407-0_5
   Cole R, 2003, P IEEE, V91, P1391, DOI 10.1109/JPROC.2003.817143
   Costa S, 2015, INT J SOC ROBOT, V7, P265, DOI 10.1007/s12369-014-0250-2
   Craig P, 2008, BRIT MED J, V337, DOI 10.1136/bmj.a1655
   Daudt HML, 2013, BMC MED RES METHODOL, V13, DOI 10.1186/1471-2288-13-48
   Davis K, 2009, INT J NURS STUD, V46, P1386, DOI 10.1016/j.ijnurstu.2009.02.010
   Devault D, P 2014 INT C AUT AG, P1061
   Dickerson P, 2013, INTERACT STUD, V14, P297, DOI 10.1075/is.14.2.07dic
   Diehl JJ, 2012, RES AUTISM SPECT DIS, V6, P249, DOI 10.1016/j.rasd.2011.05.006
   Fujimoto I, 2011, INT J SOC ROBOT, V3, P349, DOI 10.1007/s12369-011-0116-9
   Grolleman J, 2006, LECT NOTES COMPUT SC, V3962, P133
   Hartholt A., 2013, LNCS, P368
   Hopkins IM, 2011, J AUTISM DEV DISORD, V41, P1543, DOI 10.1007/s10803-011-1179-z
   Hudlicka E, 2013, PATIENT EDUC COUNS, V92, P160, DOI 10.1016/j.pec.2013.05.007
   Isbister K, 2004, HUM-COMPUT INT-SPRIN, V7, P3
   Johansson R, 2012, EXPERT REV NEUROTHER, V12, P861, DOI [10.1586/ern.12.63, 10.1586/ERN.12.63]
   Jordan K, 2013, INT J REHABIL RES, V36, P221, DOI 10.1097/MRR.0b013e32835d0b43
   Kang SH, 2012, STUD HEALTH TECHNOL, V181, P202, DOI 10.3233/978-1-61499-121-2-202
   Kang SH, 2010, COMPUT ANIMAT VIRT W, V21, P473, DOI 10.1002/cav.345
   Kelders Saskia M., 2015, Persuasive Technology. 10th International Conference, PERSUASIVE 2015. Proceedings: LNCS 9072, P3, DOI 10.1007/978-3-319-20306-5_1
   Konstantinidis E. I., 2009, 22 IEEE INT S COMP B, P1
   Ku J, 2007, CYBERPSYCHOL BEHAV, V10, P567, DOI 10.1089/cpb.2007.9989
   Lahiri U, 2011, LECT NOTES COMPUT SC, V6974, P165, DOI 10.1007/978-3-642-24600-5_20
   Leff J, 2013, BRIT J PSYCHIAT, V202, P428, DOI 10.1192/bjp.bp.112.124883
   Levac D, 2010, IMPLEMENT SCI, V5, DOI 10.1186/1748-5908-5-69
   Lisetti C., 2013, ACM T MANAG INFSYST, V4, P1, DOI DOI 10.1145/2544103
   Martinez-Miranda J, 2014, LECT NOTES ARTIF INT, V8637, P285, DOI 10.1007/978-3-319-09767-1_37
   Mays N., 2001, Synthesising research evidence
   Merry SN, 2012, BMJ-BRIT MED J, V344, DOI 10.1136/bmj.e2598
   Milne M, 2009, P 21 ANN C AUST COMP, P265, DOI DOI 10.1145/1738826.1738870
   Mohr DC, 2011, J MED INTERNET RES, V13, DOI 10.2196/jmir.1602
   Mordoch E, 2013, MATURITAS, V74, P14, DOI 10.1016/j.maturitas.2012.10.015
   Morie JF, 2009, STUD HEALTH TECHNOL, V144, P273, DOI 10.3233/978-1-60750-017-9-273
   Pagliari C, 2012, STUD HEALTH TECHNOL, V181, P329, DOI 10.3233/978-1-61499-121-2-329
   Palestra G, 2014, LECT NOTES ARTIF INT, V8755, P290, DOI 10.1007/978-3-319-11973-1_30
   Pinto MD, 2016, PERSPECT PSYCHIATR C, V52, P157, DOI 10.1111/ppc.12112
   Pontier M, 2008, LECT NOTES COMPUT SC, V5208, P417
   Puskar K, 2011, J PSYCHOSOC NURS MEN, V49, P22, DOI 10.3928/02793695-20110705-01
   Ribeiro PC, 2014, BRAZIL SYMP GAME DIG, P148, DOI 10.1109/SBGAMES.2014.19
   Richards D, 2012, CLIN PSYCHOL REV, V32, P329, DOI 10.1016/j.cpr.2012.02.004
   Rinck M, 2010, COGNITION EMOTION, V24, P1269, DOI 10.1080/02699930903309268
   Robins B, 2014, INT J SOC ROBOT, V6, P397, DOI 10.1007/s12369-014-0228-0
   Ruttkay Z, 2004, HUM-COMPUT INT-SPRIN, V7, P27
   Schmidt R, 2013, GAMES HEALTH J, P267
   Shoukry L, 2015, LECT NOTES COMPUT SC, V9090, P77, DOI 10.1007/978-3-319-19126-3_7
   Smith C, 2008, LECT NOTES COMPUT SC, V5208, P146
   Smith MJ, 2014, J AUTISM DEV DISORD, V44, P2450, DOI 10.1007/s10803-014-2113-y
   Smith MJ, 2014, J NERV MENT DIS, V202, P659, DOI 10.1097/NMD.0000000000000187
   Spek V, 2007, PSYCHOL MED, V37, P319, DOI 10.1017/S0033291706008944
   Swartout W, 2013, AI MAG, V34, P13, DOI 10.1609/aimag.v34i4.2487
   Tanaka H., 2015, IUI 15 P T HE 20 INT, P17, DOI [10.1145/2678025.2701368, DOI 10.1145/2678025.2701368]
   Tielman M, 2014, LECT NOTES ARTIF INT, V8637, P434, DOI 10.1007/978-3-319-09767-1_54
   van Vugt HC, 2009, COMPUT ANIMAT VIRT W, V20, P195, DOI 10.1002/cav.312
   Wainer J, 2014, INT J SOC ROBOT, V6, P45, DOI 10.1007/s12369-013-0195-x
   Wallace S, 2010, AUTISM, V14, P199, DOI 10.1177/1362361310363283
   Warmerdam L, 2012, STUD HEALTH TECHNOL, V181, P339, DOI 10.3233/978-1-61499-121-2-339
   Warren Z, 2015, J AUTISM DEV DISORD, V45, P3870, DOI 10.1007/s10803-014-2334-0
   Yasavur U, 2014, J MULTIMODAL USER IN, V8, P381, DOI 10.1007/s12193-014-0169-9
NR 77
TC 124
Z9 126
U1 4
U2 43
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 59 WINNERS CIRCLE, TORONTO, ON M4L 3Y7, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD MAY
PY 2017
VL 19
IS 5
AR e151
DI 10.2196/jmir.6553
PG 17
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA EU4OE
UT WOS:000401008500004
PM 28487267
OA Green Published, gold, Green Submitted
DA 2022-08-02
ER

PT J
AU Frick, NRJ
   Brunker, F
   Ross, B
   Stieglitz, S
AF Frick, Nicholas R. J.
   Bruenker, Felix
   Ross, Bjorn
   Stieglitz, Stefan
TI Comparison of disclosure/concealment of medical information given to
   conversational agents or to physicians
SO HEALTH INFORMATICS JOURNAL
LA English
DT Article
DE anamnesis; concealment; conversational agent; disclosure; medical
   information
ID SELF-CONCEALMENT; SENSITIVE QUESTIONS; DISCLOSURE
AB Within the anamnesis, medical information is frequently withheld, incomplete, or incorrect, potentially causing negative consequences for the patient. The use of conversational agents (CAs), computer-based systems using natural language to interact with humans, may mitigate this problem. The present research examines whether CAs differ from physicians in their ability to elicit truthful disclosure and discourage concealment of medical information. We conducted an online questionnaire with German participants (N = 148) to assess their willingness to reveal medical information. The results indicate that patients would rather disclose medical information to a physician than to a CA; there was no difference in the tendency to conceal information. This research offers a frame of reference for future research on applying CAs during the anamnesis to support physicians. From a practical view, physicians might gain better understanding of how the use of CAs can facilitate the anamnesis.
C1 [Frick, Nicholas R. J.; Bruenker, Felix; Stieglitz, Stefan] Univ Duisburg Essen, Duisburg, Germany.
   [Ross, Bjorn] Univ Edinburgh, Edinburgh, Midlothian, Scotland.
RP Frick, NRJ (corresponding author), Univ Duisburg Essen, Fac Engn, Profess Commun Elect Media Social Media, Dept Comp Sci & Appl Cognit Sci, Forsthausweg 2, D-47057 Duisburg, Germany.
EM nicholas.frick@uni-due.de
RI Ross, Björn/AAT-6901-2020
OI Ross, Björn/0000-0003-2717-3705; Brunker, Felix/0000-0003-1825-1986
CR Abdul-Kader SA, 2015, INT J ADV COMPUT SC, V6, P72
   Bickmore TW, 2013, J AM GERIATR SOC, V61, P1676, DOI 10.1111/jgs.12449
   Brachten F, 2020, INF SYST E-BUS MANAG, V18, P187, DOI 10.1007/s10257-020-00471-7
   Cramer KM, 1999, PERS INDIV DIFFER, V27, P629, DOI 10.1016/S0191-8869(98)00222-0
   Cruddas S, 2012, INT J COGN THER, V5, P28, DOI 10.1521/ijct.2012.5.1.28
   Denecke K., P 2018 INT C DIG HLT, P85
   Frick NRJ, 2019, 30 AUSTR C INF SYST
   Gnewuch U, P 38 INT C INF SYST
   Heck C, 2007, INHIBITION ODER ALEX
   LARSON DG, 1990, J SOC CLIN PSYCHOL, V9, P439, DOI 10.1521/jscp.1990.9.4.439
   Levy AG, 2018, JAMA NETW OPEN, V1, DOI 10.1001/jamanetworkopen.2018.5293
   Liu X., 37 INT C INF SYST DU, P1
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   MILLER LC, 1983, J PERS SOC PSYCHOL, V44, P1234, DOI 10.1037/0022-3514.44.6.1234
   Palmieri John J, 2009, Prim Care Companion J Clin Psychiatry, V11, P163, DOI 10.4088/PCC.09r00780
   Reinecke L., 2008, KOMMUNIKATION PARTIZ
   Schuetzler RM., P INT C INF SYST AUC, P1
   Schuetzler RM, 2018, DECIS SUPPORT SYST, V114, P94, DOI 10.1016/j.dss.2018.08.011
   Shaked NA, 2017, HEALTHC TECHNOL LETT, V4, P83, DOI 10.1049/htl.2017.0009
   Slack WV, 2012, J AM MED INFORM ASSN, V19, P545, DOI 10.1136/amiajnl-2011-000580
   Tourangeau R, 1996, PUBLIC OPIN QUART, V60, P275, DOI 10.1086/297751
   Tourangeau R, 2007, PSYCHOL BULL, V133, P859, DOI 10.1037/0033-2909.133.5.859
NR 23
TC 4
Z9 4
U1 0
U2 6
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1460-4582
EI 1741-2811
J9 HEALTH INFORM J
JI Health Inform. J.
PD JAN
PY 2021
VL 27
IS 1
AR 1460458221994861
DI 10.1177/1460458221994861
PG 10
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA RV0ZQ
UT WOS:000645567000025
PM 33779384
OA Green Published, gold
DA 2022-08-02
ER

PT B
AU Mencia, BL
   Pardo, DD
   Trapote, AH
   Gomez, LAH
AF Lopez Mencia, Beatriz
   Diaz Pardo, David
   Hernandez Trapote, Alvaro
   Hernandez Gomez, Luis A.
BA Barres, BG
   Carrion, ZC
   Delgado, RLC
BF Barres, BG
   Carrion, ZC
   Delgado, RLC
TI Embodied Conversational Agents in Interactive Applications for Children
   with Special Educational Needs
SO TECHNOLOGIES FOR INCLUSIVE EDUCATION: BEYOND TRADITIONAL INTEGRATION
   APPROACHES
LA English
DT Article; Book Chapter
ID AUTISM
AB This chapter describes a collection of experiences and recommendations related with the design and evaluation of interactive applications integrating Embodied Conversational Agents (ECA) technology in real environments of use with children in Special Education. Benefits and challenges of using ECAs in this context are presented. These benefits and challenges have guided the creation of Special Education reinforcement applications incorporating ECAs, which have been used for extended periods of time at Infanta Elena Special Education School in Madrid. Co-design principles were applied in the development of two of the applications discussed here, with the participation of the school's teaching staff and children with severe motor and mental disabilities (mainly with cerebral palsy). From the design experience a set of recommendations and observations were extracted, which the authors hope may serve as guidance for the scientific and educational communities when undertaking further research. For example, in an application to reinforce the learning of emotions it believe it beneficial to include ECAs that display a number of exaggerated facial expressions together with a combination of auditory and gestural reinforcements. The ECA should show its eyes and mouth clearly, in order to help the children focus their attention. These and other ECA strategies have been analysed to provide reinforcement in learning and also to attract the children's attention when interacting with the application.
C1 [Lopez Mencia, Beatriz; Diaz Pardo, David; Hernandez Trapote, Alvaro; Hernandez Gomez, Luis A.] Univ Politecn Madrid, E-28040 Madrid, Spain.
RP Mencia, BL (corresponding author), Univ Politecn Madrid, E-28040 Madrid, Spain.
RI Gómez, Luis Alfonso Hernández/G-4402-2015
OI Gómez, Luis Alfonso Hernández/0000-0003-1481-9087
CR Abascal J, 2003, LECT NOTES COMPUT SC, V2615, P141
   Adamo-Villani N, 2006, PROC WRLD ACAD SCI E, V16, P18
   Arias J. L. G., 2011, THESIS U VIGO
   Atkinson RK, 2002, J EDUC PSYCHOL, V94, P416, DOI 10.1037//0022-0663.94.2.416
   Baron-Cohen S, 2009, PHILOS T R SOC B, V364, P3567, DOI 10.1098/rstb.2009.0191
   Bersano L., 2007, THESIS POLITECNICO T
   Bickmore T., 2003, THESIS MIT
   Blazquez J. P., 2008, THESIS U POLITECNICA
   Bolich B., 2001, INT J SPECIAL ED, V16, P16
   Brave S, 2005, INT J HUM-COMPUT ST, V62, P161, DOI 10.1016/j.ijhcs.2004.11.002
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   COLE R, 1999, P ESCA SOCRATES WORK, P45
   Corradini A., 2005, P 10 INT C INT US IN, P183
   Correia S, 2009, LECT NOTES ARTIF INT, V5773, P492
   Cortarelo V. L., 2007, THESIS U POLITECNICA
   Cosi P., 2004, P INSTIL ICALL S COM
   Dautenhahn K, 2004, PRAGMAT COGN, V12, P1, DOI DOI 10.1075/PC.12.1.03DAU
   Di Blas N, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P11
   ENGWALL O, 2008, CAN AUDIO VISUAL INS, P2631
   Eskenazi M, 2009, SPEECH COMMUN, V51, P832, DOI 10.1016/j.specom.2009.04.005
   Farr W, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P30
   Fernaeus Y, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P39
   Fransen S, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P59
   Garay N., 2006, HUMAN TECHNOLOGY, V2, P55
   Garzotto F, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P79
   Gratch J, 2007, LECT NOTES COMPUT SC, V4552, P286
   Guha ML, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P198
   Hanna L., 1997, INTERACTIONS, V4, P9, DOI DOI 10.1145/264044.264045
   Hemmert F, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P202
   Hernandez-Trapote A., 2007, S NAC TECN INF COM E
   Hornof AJ, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2177
   International Organization for Standardization (ISO), 1999, ISO 134071999 HUMAN
   Johnson WL, 2000, INT J ARTIFICIAL INT, V11, P47
   Karna E, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P218
   Kiung N. G., 2008, EUROPEAN J SOIL SCI, V7
   Lester J. C., 1997, P ACM SIGCHI C HUM F, P359, DOI DOI 10.1145/258549.258797
   Lopez M. C. I., 2009, THESIS U MURCIA
   Lopez-Mencia B., 2011, THESIS U POLITECNICA
   Lopez-Mencia B., 2010, MULT CORP ADV CAPT C
   Lopez-Mencia B, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P226
   Maguire M., 2006, HUMAN TECHNOLOGY INT, V2, P119, DOI [10.17011/ht/urn.2006162, DOI 10.17011/HT/URN.2006162]
   Marco J., 2007, 8 C INT INT PERS ORD
   Marin D. P., 2010, 4 SEM INV TECN INF A
   Markopoulos P, 2008, MORG KAUF SER INTER, P1, DOI 10.1016/B978-0-12-374111-0.00001-3
   Massaro DW, 2006, LECT NOTES COMPUT SC, V4061, P809
   Massaro DW, 2000, EMBODIED CONVERSATIONAL AGENTS, P287
   Mazzone E, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P108
   Mohamad Y., 2005, P 1 WORKSH EM HCI
   Moreno R, 2001, COGNITION INSTRUCT, V19, P177, DOI 10.1207/S1532690XCI1902_02
   Moridis C., 2010, P 12 MED C MED BIOL, P675
   Munoz A. M., 2007, PARALISIS CEREBRAL T
   Paniagua Martin F., 2009, P 1 ACM SIGMM INT WO, P47
   Picard R.W., 2000, AFFECTIVE COMPUTING
   Picard RW, 2009, PHILOS T R SOC B, V364, P3575, DOI 10.1098/rstb.2009.0143
   Portela J. R. L., 2010, THESIS U POLITECNICA
   Rasseneur D., 2002, INT TUT SYST 6 INT C, P129
   Raya R, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P128
   Rickel J., 2001, Intelligent Virtual Agents. Third International Workshop, IVA 2001. Proceedings (Lecture Notes in Artificial Intelligence Vol.2190), P15
   San-Segundo R, 2010, INTERACT COMPUT, V22, P123, DOI 10.1016/j.intcom.2009.11.011
   San-Segundo R., 2009, INTELL AUTOM SOFT CO, V15, P645
   Sanchez Benavente R., 2003, 1 JORN CIENT TECN IA
   Sanchez J., 2008, HUMAN TECHNOLOGY, V45, P96, DOI DOI 10.17011/HT/URN.200810245832
   Sanders E. B.-N., 2008, CODESIGN, V4, P5, DOI 10.1080/15710880701875068
   Sanders Liz, 2008, Interactions, V15, P13, DOI 10.1145/1409040.1409043
   Saz O, 2009, SPEECH COMMUN, V51, P948, DOI 10.1016/j.specom.2009.04.006
   Sik Lanyi C., 2006, INT J VIRTUAL REALIT, V5, P55
   Susi T, 2007, SERIOUS GAMES OVERVI
   Tartaro A., 2007, DOCT CONS HUM FACT C
   Tartaro A., 2008, P 8 INT C LEARN SCI, V2, P382
   Vazquez Reyes C. M., 2002, PROYECTO AGENCIA EUR
   Wik P, 2009, SPEECH COMMUN, V51, P1024, DOI 10.1016/j.specom.2009.05.006
   Zaman B, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P156
   Zhang ZH, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P166
NR 73
TC 3
Z9 3
U1 0
U2 6
PU IGI GLOBAL
PI HERSEY
PA 701 E CHOCOLATE AVE, STE 200, HERSEY, PA 17033-1240 USA
BN 978-1-4666-2531-0; 978-1-4666-2530-3
PY 2013
BP 59
EP 88
DI 10.4018/978-1-4666-2530-3.ch004
D2 10.4018/978-1-4666-2530-3
PG 30
WC Education & Educational Research
WE Book Citation Index – Social Sciences & Humanities (BKCI-SSH)
SC Education & Educational Research
GA BD8LP
UT WOS:000364036600005
DA 2022-08-02
ER

PT S
AU Li, TJJ
   Labutov, I
   Myers, BA
   Azaria, A
   Rudnicky, AI
   Mitchell, TM
AF Li, Toby Jia-Jun
   Labutov, Igor
   Myers, Brad A.
   Azaria, Amos
   Rudnicky, Alexander I.
   Mitchell, Tom M.
BE Moore, RJ
   Szymanski, MH
   Arar, R
   Ren, GJ
TI Teaching Agents When They Fail: End User Development in Goal-Oriented
   Conversational Agents
SO STUDIES IN CONVERSATIONAL UX DESIGN
SE Human-Computer Interaction Series
LA English
DT Article; Book Chapter
AB This chapter introduces an end user development (EUD) approach for handling common types of failures encountered by goal-oriented conversational agents. We start with identifying three common sources of failures in human-agent conversations: unknown concepts, out-of -domain tasks and wrong fulfillment means or level of generalization in task execution. To handle these failures, it is useful to enable the end user to program the agent and to "teach" the agent what to do as a fallback strategy. Showing examples for this approach, we walk through our two integrated systems: SUGILITE and LIA. SUGILITE uses the programming by demonstration (PBD) technique, allowing the user to program the agent by demonstrating new tasks or new means for completing a task using the GUIs of third-party smartphone apps, while LIA learns new tasks from verbal instructions, enabling the user to teach the agent through breaking down the procedure verbally. LIA also enables the user to verbally define unknown concepts used in the commands and adds those concepts into the agent's ontology. Both SUGILITE and LIA can generalize what they have learned from the user across related entities and perform a task with new parameters in a different context.
C1 [Li, Toby Jia-Jun; Labutov, Igor; Myers, Brad A.; Rudnicky, Alexander I.; Mitchell, Tom M.] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Azaria, Amos] Ariel Univ, Ariel, Israel.
RP Li, TJJ (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
EM tobyli@cs.cmu.edu; ilabutov@cs.cmu.edu; bam@cs.cmu.edu;
   amos.azaria@ariel.ac.il; air@cs.cmu.edu; tom.mitchell@cs.cmu.edu
RI Myers, Brad/R-3816-2019; Azaria, Amos/Y-6302-2019
OI Azaria, Amos/0000-0002-5057-1309
CR Allen J., 2007, P 22 NAT C ART INT, P1514
   Armstrong G, 2017, CHATBOTS MAGAZINE
   Azaria A, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P207, DOI 10.1145/2959100.2959138
   Azaria Amos, 2016, P 30 AAAI C ART INT
   Barkin J, 2016, BEING JANIS
   Bohus D, 2005, 2005 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), P272
   BOHUS D, 2005, P HUM LANG TECHN C C, P225
   Bohus Dan, 2005, 6 SIGDIAL WORKSH DIS
   Cypher A., 1993, WATCH WHAT I DO PROG, P205
   CYPHER A, 1993, WATCH WHAT PROGRAMMI
   Dzikovska MO, 2003, P IJCAI 03 WORKSH KN
   Gruber T.R., 2017, U.S. Patent, Patent No. [9,548,050, 9548050]
   Jiun-Hung Chen, 2008, 13th International Conference on Intelligent User Interfaces. IUI 2008, p159, 166, DOI 10.1145/1378773.1378794
   Koedinger KR, 2004, LECT NOTES COMPUT SC, V3220, P162
   Leshed G, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1719
   Li TJ-J, 2017, CONV UX DES CHI 2017
   Li TJJ, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6038, DOI 10.1145/3025453.3025483
   Li TJJ, 2017, S VIS LANG HUM CEN C, P323, DOI 10.1109/VLHCC.2017.8103491
   LI TY, 2017, P INT S ED RES ED, P3
   Lieberman H., 2001, YOUR WISH IS MY COMM
   Myers B., 2017, NEW PERSPECTIVES END, V2017, P1
   Pappu A, 2014, P 15 ANN M SPEC INT, P194
   Srivastava S., 2017, P 2017 C EMP METH NA, P1527
   Weld DS, 2004, P 9 INT C INT US INT
   Witten IH, 1993, WATCH WHAT I DO, P67
NR 25
TC 10
Z9 10
U1 0
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1571-5035
EI 2524-4477
BN 978-3-319-95579-7; 978-3-319-95578-0
J9 HUM-COMPUT INT-SPRIN
PY 2018
BP 119
EP 137
DI 10.1007/978-3-319-95579-7_6
D2 10.1007/978-3-319-95579-7
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Software Engineering
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BM0BU
UT WOS:000458606800006
DA 2022-08-02
ER

PT J
AU Dohsaka, K
   Asai, R
   Higashinaka, R
   Minami, Y
   Maeda, E
AF Dohsaka, Kohji
   Asai, Ryota
   Higashinaka, Ryuichiro
   Minami, Yasuhiro
   Maeda, Eisaku
TI Effects of Conversational Agents on Activation of Communication in
   Thought-Evoking Multi-Party Dialogues
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
LA English
DT Article
DE multi-party interaction; dialogue systems; human-agent interaction;
   human-robot interaction
ID HUMAN-COMPUTER INTERACTION; EMOTION
AB This paper presents an experimental study that analyzes how conversational agents activate human communication in thought-evoking multi-party dialogues between multi-users and multi-agents. A thought-evoking dialogue is a kind of interaction in which agents act to provoke user thinking, and it has the potential to activate multi-party interactions. This paper focuses on quiz-style multi-party dialogues between two users and two agents as an example of thought-evoking multi-party dialogues. The experimental results revealed that the presence of a peer agent significantly improved user satisfaction and increased the number of user utterances in quiz-style multi-party dialogues. We also found that agents' empathic expressions significantly improved user satisfaction, improved user ratings of the peer agent, and increased the number of user utterances. Our findings should be useful for activating multi-party communications in various applications such as pedagogical agents and community facilitators.
C1 [Dohsaka, Kohji; Minami, Yasuhiro; Maeda, Eisaku] NTT Corp, NTT Commun Sci Labs, Kyoto 6190238, Japan.
   [Asai, Ryota] Osaka Univ, Grad Sch Informat Sci & Technol, Suita, Osaka 5650871, Japan.
   [Higashinaka, Ryuichiro] NTT Corp, NTT Media Intelligence Labs, Yokosuka, Kanagawa 2390847, Japan.
RP Dohsaka, K (corresponding author), Akita Prefectural Univ, Akita, Japan.
EM dohsaka@akita-pu.ac.jp
FU Ministry of Education, Culture, Sports, Science and Technology (MEXT),
   Japan [21118004]
FX We would like to thank Professor Makoto Imase of the Graduate School of
   Information Science and Technology at Osaka University for his helpful
   advice and suggestions. We would also like to thank Drs. Junji Yamato
   and Keiji Hirata of NTT Communication Science Laboratories for their
   encouragement and support. Thanks also go to Messrs. Akira Mori, Minako
   Sawaki, Toyomi Meguro, and Hiroaki Sugiyama of NTT Communication Science
   Laboratories for the constructive discussions we had with them. This
   work was supported by a Grant-in-Aid for Scientific Research on
   Innovative Areas in the "Formation of robot communication strategies"
   (21118004) made available by the Ministry of Education, Culture, Sports,
   Science and Technology (MEXT), Japan.
CR Allen JF, 2001, AI MAG, V22, P27
   BATES J, 1994, COMMUN ACM, V37, P122, DOI 10.1145/176789.176803
   BICKMORE T, 2001, P ACM C HUM FACT COM, P396
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Brave S, 2005, INT J HUM-COMPUT ST, V62, P161, DOI 10.1016/j.ijhcs.2004.11.002
   Cassell J., 2000, EMBODIED CONVERSATIO
   Chi MTH, 2008, COGNITIVE SCI, V32, P301, DOI 10.1080/03640210701863396
   Chou CY, 2003, COMPUT EDUC, V40, P255, DOI 10.1016/S0360-1315(02)00130-6
   CRAIG S. D., 2000, INT J ARTIFICIAL INT, V11, P242
   Fujie S., 2009, P INTERSPEECH, P264
   Gebhard P, 2004, LECT NOTES COMPUT SC, V3068, P128
   HIGASHINAKA R, 2007, P INT, P2725
   HIGASHINAKA R, 2007, P 45 ANN M ASS COMP, P117
   Higashinaka R, 2008, 2008 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY: SLT 2008, PROCEEDINGS, P109, DOI 10.1109/SLT.2008.4777852
   Hudlicka E, 2003, INT J HUM-COMPUT ST, V59, P1, DOI 10.1016/S1071-5819(03)00047-8
   Kopp S, 2005, LECT NOTES ARTIF INT, V3661, P329
   Lee J., 1998, Education and Information Technologies, V3, P217, DOI 10.1023/A:1009645430959
   Liu Y, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON INTELLIGENT AGENT TECHNOLOGY, PROCEEDINGS, P134, DOI 10.1109/IAT.2004.1342935
   Maldonado H, 2005, CSCL 2005: COMPUTER SUPPORTED COLLABORATIVE LEARNING 2005: THE NEXT 10 YEARS, PROCEEDINGS, P408
   Matsubayashi T., 2007, INT J ELECT CIRCUITS, V1, P116
   Nakano YI, 2010, IUI 2010, P139
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Prendinger H, 2005, INT J HUM-COMPUT ST, V62, P231, DOI 10.1016/j.ijhcs.2004.11.009
   Prendinger H., 2004, LIFE LIKE CHARACTERS
   STENNING K, 1999, P COMP SUPP COLL LEA, P341
   Traum D., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P766
   Zheng J., 2005, P 4 INT JOINT C AUT, P929
   ZUE V, 1994, SPEECH COMMUN, V15, P331, DOI 10.1016/0167-6393(94)90083-3
NR 28
TC 1
Z9 1
U1 1
U2 12
PU IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG
PI TOKYO
PA KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011,
   JAPAN
SN 1745-1361
J9 IEICE T INF SYST
JI IEICE Trans. Inf. Syst.
PD AUG
PY 2014
VL E97D
IS 8
BP 2147
EP 2156
DI 10.1587/transinf.E97.D.2147
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ4QZ
UT WOS:000342784500025
OA gold
DA 2022-08-02
ER

PT B
AU Lockelt, M
AF Loeckelt, Markus
BA PerezMarin, D
   PascualNieto, I
BF PerezMarin, D
   PascualNieto, I
TI Design and Implementation Issues for Convincing Conversational Agents
SO CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND
   EFFECTIVE PRACTICES
LA English
DT Article; Book Chapter
AB This chapter describes a selection of experiences from designing and implementing virtual conversational characters for multimodal dialogue systems. It uses examples from the large interactive narrative VirtualHuman and some related systems of the task-oriented variety. The idea is not to give a comprehensive overview of any one system, but rather to identify and describe some issues that might also be relevant for the designer of a new system, to show how they can be addressed, and what problems still remain unresolved for future work. Besides giving an overview of how characters for interactive narrative systems can be built in the implementation level, the focus is on what should be in the knowledge base for virtual characters, and how it should be organized to be able to provide a convincing interaction with one or multiple characters.
CR ALEXANDERSSON J, 2001, P IJCAI WORKSH KNOWL, P8
   [Anonymous], 2003, AAMAS 03, P725
   Crawford C., 1999, Narrative Intelligence. Papers from the 1999 AAAI Fall Symposium, P112
   Doyle P., 2002, P 1 INT JOINT C AUT, P342
   Garzotto F., 2005, P WORLD C ED MULT HY, P3887
   Gebhard P., 2007, THESIS U SAARLAND SA
   Gholamsaghaee E., 2006, THESIS U SAARLAND SA
   Gobel S, 2005, LECT NOTES COMPUT SC, V3805, P168, DOI 10.1007/11590361_19
   GRICE HP, 1975, SYNTAX SEMANTICS, V3, DOI DOI 10.1111/J.1365-2664.2006.01229.X
   Hall L., 2006, INT J ART INT ED, V16, P327
   Hulstijn J., 2000, FORMAL SEMANTICS PRA, P99
   Jonsson A., 1993, LINKOPING STUDIES SC
   Jonsson Arne, 1997, NAT LANG ENG, V3, P103, DOI DOI 10.1017/S1351324997001733
   Lemon O., 2002, P 3 SIGDIAL WORKSH D, P113
   Lockelt M, 2005, LECT NOTES COMPUT SC, V3805, P53
   Lockelt M., 2008, THESIS SAARBRUCKEM U
   Mateas M., 2003, FACADE EXPT BUILDING
   Miller R. B., 1968, P AFIPS FALL JOINT C, P267, DOI DOI 10.1145/1476589.1476628
   Nardi D, 2003, DESCRIPTION LOGIC HANDBOOK: THEORY, IMPLEMENTATION AND APPLICATIONS, P1
   Niles I., 2001, Formal Ontology in Information Systems. Collected Papers from the Second International Conference, P2
   Pfleger N., 2007, THESIS U SAARLAND GE
   RAO AS, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P473
   Riedl MO, 2006, LECT NOTES COMPUT SC, V4326, P195
   Scheffler T., 2009, P 6 IJCAI WORKSH KNO, P93
   Schiel F., 2006, SMARTKOM FDN MULTIMO, P541, DOI [10.1007/3-540-36678-4_34, DOI 10.1007/3-540-36678-4_34]
   Swartout W, 2006, AI MAG, V27, P96
   Swartz L., 2003, THESIS STANFORD U CA
   Traum David R, 2000, J SEMANT, V17, P7
   Traum DR, 2003, TEXT SPEECH LANG TEC, V22, P325
   [No title captured]
NR 30
TC 2
Z9 2
U1 0
U2 0
PU IGI GLOBAL
PI HERSEY
PA 701 E CHOCOLATE AVE, STE 200, HERSEY, PA 17033-1240 USA
BN 978-1-60960-618-3; 978-1-60960-617-6
PY 2011
BP 156
EP 176
DI 10.4018/978-1-60960-617-6.ch007
D2 10.4018/978-1-60960-617-6
PG 21
WC Computer Science, Artificial Intelligence
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BZX29
UT WOS:000303201400008
DA 2022-08-02
ER

PT J
AU Qu, JH
   Zhou, RG
   Chen, Z
AF Qu, Jianhong
   Zhou, Ronggang
   Chen, Zhe
TI The effect of personal pronouns on users and the social role of
   conversational agents
SO BEHAVIOUR & INFORMATION TECHNOLOGY
LA English
DT Article; Early Access
DE Personal pronoun; conversational agent; social interaction; social role
ID ANTHROPOMORPHISM INCREASES TRUST; GENDER-DIFFERENCES; RESPONSES;
   COMPUTERS; LANGUAGE; SPEECH; MACHINES; BEHAVIOR; PEOPLE; MODELS
AB There is a growing tendency for users to expect conversational agents (CAs) to recognise social cues and follow interpersonal communication principles to enhance their subjective evaluation. Therefore, this paper studies how personal pronouns should be used by CAs in response to users. We conducted a 3 (CAs' personal pronoun) x 3 (users' personal pronoun) x 2 (participants'gender) mixed design. this study used mixed methods based on an experimental design, including ratings, forced choices and interviews, for mutual confirmation. The findings indicate that first, users prefer that CAs use second-person pronouns. Second, there is also turn-taking and convergence tendency between users and CAs in personal pronoun use. Third, there are gender differences in personal pronoun preferences and relationship positions toward CAs. These results can inform personalised voice interaction and humanlike design and help build closer relationships between users and CAs in future human-computer interactions.
C1 [Qu, Jianhong; Zhou, Ronggang; Chen, Zhe] Beihang Univ, Sch Econ & Management, Beijing, Peoples R China.
RP Chen, Z (corresponding author), Beihang Univ, Sch Econ & Management, Beijing, Peoples R China.
EM zhechen@buaa.edu.cn
FU National Natural Science Foundation of China [72021001, 72171015];
   Fundamental Research Funds for the Central Universities
   [YWF-21-BJ-J-314]
FX This work was supported by National Natural Science Foundation of China:
   [grant number 72021001,72171015]; Fundamental Research Funds for the
   Central Universities: [grant number YWF-21-BJ-J-314].
CR Aeschlimann S, 2020, COMPUT HUM BEHAV, V112, DOI 10.1016/j.chb.2020.106466
   Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Beckwith L, 2006, COMPUTER, V39, P97, DOI 10.1109/MC.2006.382
   Beneteau E, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300473
   Branigan HP, 2010, J PRAGMATICS, V42, P2355, DOI 10.1016/j.pragma.2009.12.012
   BURNKRANT RE, 1995, J CONSUM RES, V22, P17, DOI 10.1086/209432
   Cassell J., 2000, EMBODIED CONVERSATIO
   Chaves AP, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173765
   Chung C, 2007, FRONT SOC PSYCHOL, P343
   de Visser EJ, 2016, J EXP PSYCHOL-APPL, V22, P331, DOI 10.1037/xap0000092
   Debevec K., 1992, J CONSUM PSYCHOL, V1, P83, DOI DOI 10.1016/S1057-7408(08)80046-0
   Dhir A, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00815
   Dhir A, 2016, COMPUT HUM BEHAV, V63, P630, DOI 10.1016/j.chb.2016.05.044
   Dhir A, 2016, COMPUT HUM BEHAV, V63, P549, DOI 10.1016/j.chb.2016.05.053
   Dunbar RIM, 2018, TRENDS COGN SCI, V22, P32, DOI 10.1016/j.tics.2017.10.004
   Escalas JE, 2007, J CONSUM RES, V33, P421, DOI 10.1086/510216
   Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009
   Field M, 1997, J PRAGMATICS, V27, P799, DOI 10.1016/S0378-2166(96)00047-1
   Fogg BJ., 2002, UBIQUITY, P89, DOI DOI 10.1145/764008.763957
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   Gallois C., 2015, INT ENCY LANGUAGE SO, P1, DOI DOI 10.1002/9781118611463.WBIELSI066
   Gefen D., 2000, STRUCT EQU MODEL, V4, P1, DOI DOI 10.17705/1CAIS.00407
   Grice H.P., 1991, STUDIES WAY WORDS
   Guzman AL, 2019, COMPUT HUM BEHAV, V90, P343, DOI 10.1016/j.chb.2018.08.009
   Hannon C., 2016, INTERACTIONS, V23, P34, DOI [10.1145/2897939, DOI 10.1145/2897939]
   Hseue TC, 1998, COLOR RES APPL, V23, P169, DOI 10.1002/(SICI)1520-6378(199806)23:3<169::AID-COL9>3.3.CO;2-B
   ICKES W, 1986, SOC COGNITION, V4, P58, DOI 10.1521/soco.1986.4.1.58
   Ilves M, 2013, BEHAV INFORM TECHNOL, V32, P117, DOI 10.1080/0144929X.2012.702285
   Jianhong Qu, 2020, Human-Computer Interaction. Multimodal and Natural Interaction. Thematic Area, HCI 2020 Held as Part of the 22nd International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12182), P234, DOI 10.1007/978-3-030-49062-1_16
   Kacewicz E, 2014, J LANG SOC PSYCHOL, V33, P125, DOI 10.1177/0261927X13502654
   Kiesow H, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aaz1170
   Kwahk, 2017, JAPANESE J ERGONO S2, V53, pS408, DOI [10.5100/jje.53.S408, DOI 10.5100/JJE.53.S408]
   Labrecque LI, 2020, PSYCHOL MARKET, V37, P796, DOI 10.1002/mar.21341
   Large DR, 2017, APPL ERGON, V63, P53, DOI 10.1016/j.apergo.2017.04.003
   Levinson S.C., 1983, PRAGMATICS
   Li J, 2015, INT J HUM-COMPUT ST, V77, P23, DOI 10.1016/j.ijhcs.2015.01.001
   Liu GS, 2020, CRIT REV ENV SCI TEC, V50, P2301, DOI 10.1080/10643389.2019.1694823
   Lohani M, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00057
   Lorigo L, 2006, INFORM PROCESS MANAG, V42, P1123, DOI 10.1016/j.ipm.2005.10.001
   MacDorman K. F., 2006, ICCSCOGSCI 2006 LONG, P25
   Malik A, 2016, TELEMAT INFORM, V33, P129, DOI 10.1016/j.tele.2015.06.009
   McLean G, 2019, COMPUT HUM BEHAV, V99, P28, DOI 10.1016/j.chb.2019.05.009
   Moon Y, 2000, J CONSUM RES, V26, P323, DOI 10.1086/209566
   Moussawi S, 2021, BEHAV INFORM TECHNOL, V40, P1603, DOI 10.1080/0144929X.2020.1772368
   MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Nass C, 1999, J APPL SOC PSYCHOL, V29, P1093, DOI 10.1111/j.1559-1816.1999.tb00142.x
   Nass C, 1997, J APPL SOC PSYCHOL, V27, P864, DOI 10.1111/j.1559-1816.1997.tb00275.x
   Nass Clifford, 2005, WIRED SPEECH VOICE A
   Oliver RL, 1997, J RETAILING, V73, P311, DOI 10.1016/S0022-4359(97)90021-X
   Paay J, 2022, BEHAV INFORM TECHNOL, V41, P740, DOI 10.1080/0144929X.2020.1834620
   Packard G, 2018, J MARKETING RES, V55, P541, DOI 10.1509/jmr.16.0118
   Pearson J., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1177
   Pelikan HRM, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4921, DOI 10.1145/2858036.2858478
   Pennebaker JW, 2011, NEW SCI, V211, P42, DOI 10.1016/S0262-4079(11)62167-2
   Picard R. W., 1999, Human-Computer Interaction: Ergonomics and User Interfaces. Proceedings of HCI International '99 (8th International Conference on Human-Computer Interaction), P829
   Politis I, 2015, P 7 INT C AUT US INT, ppp310, DOI [10.1145/2799250.2799262, DOI 10.1145/2799250.2799262]
   Porcheron M, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P207, DOI 10.1145/2998181.2998298
   Rhee CE, 2020, COMPUT HUM BEHAV, V109, DOI [10.1016/j.chb.2020.102659, 10.1016/j.chb.2020.106359]
   Roberts SBG, 2015, HUM NATURE-INT BIOS, V26, P426, DOI 10.1007/s12110-015-9242-7
   SACKS H, 1974, LANGUAGE, V50, P696, DOI 10.2307/412243
   Shin D, 2021, NEW MEDIA SOC, DOI 10.1177/1461444821993801
   Shin D, 2022, JOURNAL PRACT, V16, P1168, DOI 10.1080/17512786.2020.1841018
   Shin D, 2021, INT J HUM-COMPUT ST, V146, DOI 10.1016/j.ijhcs.2020.102551
   Shinohara K, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P705
   Sillars A, 1997, WESTERN J COMM, V61, P403
   Simmons RA, 2005, PSYCHOL SCI, V16, P932, DOI 10.1111/j.1467-9280.2005.01639.x
   Soffer O, 2021, COMMUN THEOR, V31, P297, DOI 10.1093/ct/qtz008
   Spreckelmeyer KN, 2009, SOC COGN AFFECT NEUR, V4, P158, DOI 10.1093/scan/nsn051
   STREET RL, 1982, LANG COMMUN, V2, P13, DOI 10.1016/0271-5309(82)90032-5
   Talwar S, 2021, J SUSTAIN TOUR, DOI 10.1080/09669582.2021.1953512
   Talwar S, 2021, J BUS RES, V131, P25, DOI 10.1016/j.jbusres.2021.03.049
   Talwar S, 2020, J RETAIL CONSUM SERV, V57, DOI 10.1016/j.jretconser.2020.102197
   Van Slyke C, 2002, COMMUN ACM, V45, P82, DOI 10.1145/545151.545155
   Wang F, 2019, J BUS RES, V104, P283, DOI 10.1016/j.jbusres.2019.07.028
   Waytz A, 2014, J EXP SOC PSYCHOL, V52, P113, DOI 10.1016/j.jesp.2014.01.005
   Yang DY, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300261
   Zwaan RA, 1998, PSYCHOL BULL, V123, P162, DOI 10.1037/0033-2909.123.2.162
NR 79
TC 0
Z9 0
U1 19
U2 25
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0144-929X
EI 1362-3001
J9 BEHAV INFORM TECHNOL
JI Behav. Inf. Technol.
DI 10.1080/0144929X.2021.1999500
EA NOV 2021
PG 17
WC Computer Science, Cybernetics; Ergonomics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA WU8NV
UT WOS:000716797200001
DA 2022-08-02
ER

PT J
AU Pickard, MD
   Burns, MB
   Moffitt, KC
AF Pickard, Matthew D.
   Burns, Mary B.
   Moffitt, Kevin C.
TI A Theoretical Justification for Using Embodied Conversational Agents
   (ECAs) to Augment Accounting-Related Interviews
SO JOURNAL OF INFORMATION SYSTEMS
LA English
DT Article
DE embodied conversational agent; accounting interviews; self-disclosure;
   interpersonal risk
ID SELF-DISCLOSURE; SIMILARITY; COMPUTERS; BEHAVIOR; GENDER; MODEL;
   RECIPROCITY; PERCEPTION; RESPONSES; MACHINES
AB In today's increasingly complex business environment, accounting firms face additional pressures regarding cost reduction, engagement scope, and attention to quality. This paper proposes that embodied conversational agents (ECAs) are particularly well suited to automate and augment accounting interviews to save costs, streamline the interviewing process, and maintain quality. An ECA is an autonomous computer interface capable of human-like interactions such as interviews. This paper describes how an ECA can be used to augment accounting-related interviews and the advantages and disadvantages of doing so. This paper also presents the ECA Self-Disclosure Model with propositions of how self-disclosure can be influenced by an ECA through reciprocal behavior and rapport building. The model and propositions are supported by the computers-as-social-actors (CASA) paradigm (Reeves and Nass 1996). This paper concludes by discussing limitations of ECA use in the real world and by recommending how the model and propositions can be tested empirically in future research.
C1 [Pickard, Matthew D.] Univ New Mexico, Albuquerque, NM 87131 USA.
   [Burns, Mary B.] Montana State Univ, Bozeman, MT 59717 USA.
   [Moffitt, Kevin C.] Rutgers State Univ, New Brunswick, NJ USA.
RP Pickard, MD (corresponding author), Univ New Mexico, Albuquerque, NM 87131 USA.
OI Pickard, Matthew/0000-0003-4614-0060
CR Afifi T, 2009, COMMUN MONOGR, V76, P144, DOI 10.1080/03637750902828412
   Albrecht WS, 2008, FRAUD EXAMINATION, V3rd
   Allbeck J, 2002, EMBODIED CONVERSATIO, V2, P15
   Altman I., 1973, SOCIAL PENETRATION D
   ALTMAN I, 1973, J THEOR SOC BEHAV, V3, P249, DOI DOI 10.1111/J.1468-5914.1973.TB00325.X
   American Institute of Certified Public Accountants (AICPA), 2002, 99 AICPA
   American Institute of Certified Public Accountants (AICPA), 2010, 109 AICPA, V109
   Bailenson JN, 2008, PUBLIC OPIN QUART, V72, P935, DOI 10.1093/poq/nfn064
   BAUMEISTER R. F., 1998, HDB SOCIAL PSYCHOL, P680, DOI DOI 10.1002/PITS.20162
   Bazerman MH, 2002, HARVARD BUS REV, V80, P96
   Beale R, 2009, INT J HUM-COMPUT ST, V67, P755, DOI 10.1016/j.ijhcs.2009.05.001
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore T. W., 2003, RELATIONAL AGENTS EF
   Bickmore T, 2005, TEXT SPEECH LANG TEC, V30, P23
   Brave S, 2005, INT J HUM-COMPUT ST, V62, P161, DOI 10.1016/j.ijhcs.2004.11.002
   Burger JM, 2004, PERS SOC PSYCHOL B, V30, P35, DOI 10.1177/0146167203258838
   Burleson W, 2007, IEEE INTELL SYST, V22, P62, DOI 10.1109/MIS.2007.69
   Byrne D. E., 1971, ATTRACTION PARADIGM, V11
   Cappella J. N., 1990, PSYCHOL INQ, V1, P303, DOI [10.1207/s15327965pli0104_5, DOI 10.1207/S15327965PLI0104_5]
   Carcello J., 2011, RES ACCOUNTING REGUL, V23, P85
   CARLI LL, 1991, PERS SOC PSYCHOL B, V17, P419, DOI 10.1177/0146167291174010
   Cassell J., 2001, EMBODIED CONVERSATIO
   Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893
   Cheffers M., 2011, COMMUNICATION
   Chen M, 1998, BEHAV BRAIN SCI, V21, P685, DOI 10.1017/S0140525X98231748
   Chi D., 2000, P 27 ANN C COMP GRAP
   COLLINS NL, 1994, PSYCHOL BULL, V116, P457, DOI 10.1037/0033-2909.116.3.457
   COZBY PC, 1973, PSYCHOL BULL, V79, P73, DOI 10.1037/h0033950
   Curtis Mary B, 2008, International Journal of Accounting Information Systems, V9, P104, DOI 10.1016/j.accinf.2007.10.002
   DAVIS JD, 1974, BRIT J SOC CLIN PSYC, V13, P359, DOI 10.1111/j.2044-8260.1974.tb00130.x
   DERLEGA VJ, 1976, J PERS SOC PSYCHOL, V34, P578
   Derrick D. C., 2012, SPECIAL PURPOSE EMBO
   Dijksterhuis A, 2001, ADV EXP SOC PSYCHOL, V33, P1, DOI 10.1016/S0065-2601(01)80003-4
   Ettredge M. L., 2011, FEE PRESSURE AUDIT Q
   FISHER DV, 1984, J THEOR SOC BEHAV, V14, P277, DOI 10.1111/j.1468-5914.1984.tb00498.x
   Fishman C. S, 2006, RECORDINGS TRANSCRIP
   Forgas J., 2001, THEORIES MOOD COGNIT, P99
   Forgas JP, 2011, J PERS SOC PSYCHOL, V100, P449, DOI 10.1037/a0021129
   Golden T.W., 2011, GUIDE FORENSIC ACCOU
   Goodstein L D, 1974, Prog Exp Pers Res, V7, P49
   Gratch J, 2007, LECT NOTES ARTIF INT, V4722, P125
   Gratch J, 2007, LECT NOTES COMPUT SC, V4552, P286
   Gratch J, 2006, LECT NOTES ARTIF INT, V4133, P14
   Greene K, 2006, CAMBRIDGE HANDBOOK OF PERSONAL RELATIONSHIPS, P409, DOI 10.1017/CBO9780511606632.023
   Grolleman J, 2006, LECT NOTES COMPUT SC, V3962, P133
   Hartmann B, 2006, LECT NOTES ARTIF INT, V3881, P188
   Heider F., 1982, PSYCHOL INTERPERSONA
   HOGARTH RMA, 1991, THE ACCOUNTING REVIE, V66, P277
   Holzwarth M, 2006, J MARKETING, V70, P19, DOI 10.1509/jmkg.70.4.19
   Hyo-Jeong Kim, 2009, International Journal of Accounting Information Systems, V10, P214, DOI 10.1016/j.accinf.2009.09.001
   Janvrin D., 2008, AUDITOR ACCEPTANCE C
   Jourard S. M., 1979, SELF DISCLOSURE EXPE
   Jourard Sidney M, 1971, SELF DISLOSURE EXPER
   JOURARD SM, 1970, J COUNS PSYCHOL, V17, P252, DOI 10.1037/h0029197
   Kang S. H., 2008, DOES CONTINGENCY AGE
   Kang SH, 2010, COMPUT ANIMAT VIRT W, V21, P473, DOI 10.1002/cav.345
   Kassem R, 2021, MANAGING INSIDER FRA
   Kelly A.E., 2002, PSYCHOL SECRETS
   Kim J, 2003, INT J HUM-COMPUT ST, V59, P899, DOI 10.1016/j.ijhcs.2003.06.002
   Komiak S. Y. X., 2005, E SERVICE J, V3, P49, DOI DOI 10.2979/ESJ.2004.3.3.49
   Lee KM, 2004, PRESENCE-TELEOP VIRT, V13, P494, DOI 10.1162/1054746041944830
   Lessig L., 1999, CODE OTHER LAWS CYBE
   Lister L.M., 2007, INTERNAL AUDITOR, V64, P61
   Maldonado H., 2005, P 2005 C COMP SUPP C
   MANN B, 1975, J COUNS PSYCHOL, V22, P304, DOI 10.1037/h0076694
   Mennecke BE, 2011, DECISION SCI, V42, P413, DOI 10.1111/j.1540-5915.2011.00317.x
   Moon Y, 2000, J CONSUM RES, V26, P323, DOI 10.1086/209566
   MUNDORF N, 1993, BEHAV INFORM TECHNOL, V12, P293, DOI 10.1080/01449299308924393
   Nass C, 1996, INT J HUM-COMPUT ST, V45, P669, DOI 10.1006/ijhc.1996.0073
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Nass C, 1997, J APPL SOC PSYCHOL, V27, P864, DOI 10.1111/j.1559-1816.1997.tb00275.x
   Nass C, 2001, J EXP PSYCHOL-APPL, V7, P171, DOI 10.1037//1076-898X.7.3.171
   Nass C., 1994, SIGCHI C HUM FACT CO
   Nunamaker JE, 2011, J MANAGE INFORM SYST, V28, P17, DOI 10.2753/MIS0742-1222280102
   O'Bryan D., 2012, J FORENSIC INVESTIGA, V4, P292
   Omarzu J, 2000, PERS SOC PSYCHOL REV, V4, P174, DOI 10.1207/S15327957PSPR0402_05
   Payne E., 2008, 2009 AM ACC ASS AUD
   Pfau M., 2002, PERSUASION HDB DEV T, P445
   Piasentin KA, 2007, J OCCUP ORGAN PSYCH, V80, P341, DOI 10.1348/096317906X115453
   Porter M. E., 2008, COMPETITIVE ADVANTAG
   Posey C, 2010, EUR J INFORM SYST, V19, P181, DOI 10.1057/ejis.2010.15
   Public Company Accounting Oversight Board (PCAOB), 2004, 2 PCAOB
   Public Company Accounting Oversight Board (PCAOB), 2010, 12 PCAOB
   Public Company Accounting Oversight Board (PCAOB), 2007, 5 PCAOB
   Qiu LY, 2010, INT J HUM-COMPUT ST, V68, P669, DOI 10.1016/j.ijhcs.2010.05.005
   Reason T., 2010, CFO MAGAZINE    0401
   Reeves Byron, 1996, PEOPLE TREAT COMPUTE
   Richman WL, 1999, J APPL PSYCHOL, V84, P754, DOI 10.1037/0021-9010.84.5.754
   Rittenberg L. E., 2011, AUDITING BUSINESS RI
   ROSENFELD LB, 1979, COMMUN MONOGR, V46, P63, DOI 10.1080/03637757909375991
   SHAFFER DR, 1989, J PERS SOC PSYCHOL, V56, P765, DOI 10.1037/0022-3514.56.5.765
   Sharp N. Y., 2012, PORK BELLIES PUBLIC
   Silverstone H., 2006, FORENSIC ACCOUNTING
   SMITH JF, 1991, PSYCHOL BULL, V109, P472, DOI 10.1037/0033-2909.109.3.472
   Tickle-Degnen L, 1990, PSYCHOL INQ, V1, P285, DOI DOI 10.1207/S15327965PLI0104_
   Tysiac K, 2012, J ACCOUNTING, V213, P24
   van Vugt HC, 2010, ACM T COMPUT-HUM INT, V17, DOI 10.1145/1746259.1746261
   von der Putten AM, 2010, COMPUT HUM BEHAV, V26, P1641, DOI 10.1016/j.chb.2010.06.012
   Wells J. T, 2003, J ACCOUNTANCY, V196, P70
   Wells J. T., 2005, PRINCIPLES FRAUD EXA
   Wells JT, 2003, J ACCOUNTANCY, V196, P86
   Wheeless L. R., 1976, HUMAN COMMUNICATION, V2, P338, DOI [DOI 10.1111/J.1468-2958.1976.TB00494.X, 10.1111/j.1468-2958.1976.tb00494.x]
   Whitehouse T., 2011, COMPLIANCE WEEK
   Zhang P, 2005, COMMUN ACM, V48, P105, DOI 10.1145/1081992.1081997
   Zikmund P., 2008, INTERNAL AUDITOR, V65, P60
NR 105
TC 10
Z9 10
U1 0
U2 4
PU AMER ACCOUNTING ASSOC
PI SARASOTA
PA 5717 BESSIE DR, SARASOTA, FL 34233 USA
SN 0888-7985
EI 1558-7959
J9 J INF SYST
JI J. Inf. Syst.
PD FAL
PY 2013
VL 27
IS 2
BP 159
EP 176
DI 10.2308/isys-50561
PG 18
WC Business, Finance
WE Emerging Sources Citation Index (ESCI)
SC Business & Economics
GA V03QD
UT WOS:000213751000010
DA 2022-08-02
ER

PT J
AU Capuano, N
   Caballe, S
   Conesa, J
   Greco, A
AF Capuano, Nicola
   Caballe, Santi
   Conesa, Jordi
   Greco, Antonio
TI Attention-based hierarchical recurrent neural networks for MOOC forum
   posts analysis
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
LA English
DT Article
DE Massive open online courses; Neural networks; Text mining;
   Conversational agents
AB Massive open online courses (MOOCs) allow students and instructors to discuss through messages posted on a forum. However, the instructors should limit their interaction to the most critical tasks during MOOC delivery so, teacher-led scaffolding activities, such as forum-based support, can be very limited, even impossible in such environments. In addition, students who try to clarify the concepts through such collaborative tools could not receive useful answers, and the lack of interactivity may cause a permanent abandonment of the course. The purpose of this paper is to report the experimental findings obtained evaluating the performance of a text categorization tool capable of detecting the intent, the subject area, the domain topics, the sentiment polarity, and the level of confusion and urgency of a forum post, so that the result may be exploited by instructors to carefully plan their interventions. The proposed approach is based on the application of attention-based hierarchical recurrent neural networks, in which both a recurrent network for word encoding and an attention mechanism for word aggregation at sentence and document levels are used before classification. The integration of the developed classifier inside an existing tool for conversational agents, based on the academically productive talk framework, is also presented as well as the accuracy of the proposed method in the classification of forum posts.
C1 [Capuano, Nicola] Univ Basilicata, Sch Engn, Viale Ateneo Lucano 10, I-85100 Potenza, Italy.
   [Caballe, Santi; Conesa, Jordi] Univ Oberta Catalunya, Fac Comp Sci Multimedia & Telecommun, Rambla Poblenou 156, Barcelona 08018, Spain.
   [Greco, Antonio] Univ Salerno, Dept Comp & Elect Engn & Appl Math, Via Giovanni Paolo II 132, I-84084 Fisciano, SA, Italy.
RP Capuano, N (corresponding author), Univ Basilicata, Sch Engn, Viale Ateneo Lucano 10, I-85100 Potenza, Italy.
EM nicola.capuano@unibas.it; scaballe@uoc.edu; jconesac@uoc.edu;
   agreco@unisa.it
RI Capuano, Nicola/C-9460-2012
OI Capuano, Nicola/0000-0003-0862-3643
FU Universita degli Studi della Basilicata within the CRUI-CARE Agreement;
   project colMOOC "Integrating Conversational Agents and Learning
   Analytics in MOOCs"; European Commission within the Erasmus + program
   [588438-EPP-1-2017-1-EL-EPPKA2-KA]
FX Open access funding provided by Universita degli Studi della Basilicata
   within the CRUI-CARE Agreement. This work has been supported by the
   project colMOOC "Integrating Conversational Agents and Learning
   Analytics in MOOCs", co-funded by the European Commission within the
   Erasmus + program (ref. 588438-EPP-1-2017-1-EL-EPPKA2-KA).
CR Agrawal Y, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON NANOELECTRONIC AND INFORMATION SYSTEMS, P297, DOI 10.1109/iNIS.2015.44
   Almatrafi O, 2018, COMPUT EDUC, V118, P1, DOI 10.1016/j.compedu.2017.11.002
   Alrajhi L, 2020, LECT NOTES COMPUT SC, V12149, P226, DOI 10.1007/978-3-030-49663-0_27
   An YH, 2019, IEEE ACCESS, V7, P87887, DOI 10.1109/ACCESS.2019.2924250
   [Anonymous], 2014, MOOCS EXPECTATIONS R
   Bahdanau D., 2014, 3 INT C LEARN REPR I, P1
   Caballe S., 2009, J DIGITAL INFORM MAN, V7, P290
   Caballe S, P 15 INT C P2P PAR G
   Caballe S, 2019, LECT NOTE DATA ENG, V23, P384, DOI 10.1007/978-3-319-98557-2_35
   Capuano N, 2011, 3 IEEE INT C INT NET
   Capuano N, 2019, P 14 INT C P2P PAR G
   Capuano N, INTELLIGENT SYSTEMS
   Capuano N, 2015, 2015 10TH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND INTERNET COMPUTING (3PGCIC), P64, DOI 10.1109/3PGCIC.2015.7
   Capuano N, 2009, ONTOLOGY FOR E-TECHNOLOGIES, PROCEEDINGS, P3
   Charlevoix, 2014, P 1 ACM C LEARN SCAL, P71, DOI DOI 10.1145/2556325.2566245
   Cichosz P, 2019, APPL MATH COMPUT SCI, V28, P787
   Demetriadis Stavros, 2018, 2018 Learning With MOOCS (LWMOOCS). Proceedings, P43, DOI 10.1109/LWMOOCS.2018.8534686
   Devlin J., 2018, ARXIV
   Dyke G., 2013, PRODUCTIVE MULTIVOCA, P459, DOI 10.1007/978-1-4614-8960-3_25
   Ferschke O., 2015, P 11 INT C COMP SUPP, P459
   Ferschke O, 2015, LECT NOTES ARTIF INT, V9112, P115, DOI 10.1007/978-3-319-19773-9_12
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guitart I, 2016, INT J EMERG TECHNOL, V11, P34, DOI 10.3991/ijet.v11i07.5887
   Jang B, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175841
   Kumar R, 2011, IEEE T LEARN TECHNOL, V4, P21, DOI 10.1109/TLT.2010.41
   Le Q.V., 2014, INT C MACH LEARN, V32, P1188
   Lee C, 2006, LECT NOTES COMPUT SC, V4182, P581
   Liu XM, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P167, DOI 10.1109/CISP-BMEI.2016.7852702
   Manning C., 2008, INTRO INFORM RETRIEV, DOI [10.1017/CBO9780511809071, DOI 10.1017/CBO9780511809071]
   Michaels S., 2010, ACCOUNTABLE TALK SOU
   Mikolov T., 2013, P 1 INT C LEARN REPR, DOI DOI 10.5555/2999792.2999959
   Mongkhonvanit K, 2019, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE (LAK'19), P340, DOI 10.1145/3303772.3303830
   Nivre J, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1659
   Pousada M., 2017, 5 INT C EM INT DAT W, P314
   Pradhan S, 2017, HDB LINGUISTIC ANNOT, P521, DOI [10.1007/978-94-024-0881-2_20, DOI 10.1007/978-94-024-0881-2_20]
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Siemens G., 2013, OPEN ED RESOURCES IN, P5
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Sun X., 2019, 2019 22 INT C ELECT, P1
   TEGOS Stergios, 2019, EMOOCS WIP, P66
   Toti D, P 15 INT C P2P PAR G
   Wei XC, 2017, INFORMATION, V8, DOI 10.3390/info8030092
   Wen M., 2014, 7 INT C ED DAT MIN E
   Yang D., 2015, EXPLORING EFFECT CON, P121
NR 44
TC 9
Z9 9
U1 3
U2 11
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-5137
EI 1868-5145
J9 J AMB INTEL HUM COMP
JI J. Ambient Intell. Humaniz. Comput.
PD NOV
PY 2021
VL 12
IS 11
BP 9977
EP 9989
DI 10.1007/s12652-020-02747-9
EA DEC 2020
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA UT9GM
UT WOS:000601480200003
OA hybrid, Green Published
DA 2022-08-02
ER

PT J
AU Wolfert, P
   Robinson, N
   Belpaeme, T
AF Wolfert, Pieter
   Robinson, Nicole
   Belpaeme, Tony
TI A Review of Evaluation Practices of Gesture Generation in Embodied
   Conversational Agents
SO IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS
LA English
DT Review
DE Measurement; Systematics; Databases; Data mining; Avatars; Protocols;
   Neural networks; Human&#x2013; computer interface; human&#x2013; robot
   interaction; social robotics; virtual interaction
ID PSYCHOLOGICAL REACTANCE; SOCIAL CUES; ROBOT; SPEECH; COMMUNICATION
AB Embodied conversational agents (ECAs) are often designed to produce nonverbal behavior to complement or enhance their verbal communication. One such form of the nonverbal behavior is co-speech gesturing, which involves movements that the agent makes with its arms and hands that are paired with verbal communication. Co-speech gestures for ECAs can be created using different generation methods, divided into rule-based and data-driven processes, with the latter, gaining traction because of the increasing interest from the applied machine learning community. However, reports on gesture generation methods use a variety of evaluation measures, which hinders comparison. To address this, we present a systematic review on co-speech gesture generation methods for iconic, metaphoric, deictic, and beat gestures, including reported evaluation methods. We review 22 studies that have an ECA with a human-like upper body that uses co-speech gesturing in social human-agent interaction. This includes studies that use human participants to evaluate performance. We found most studies use a within-subject design and rely on a form of subjective evaluation, but without a systematic approach. We argue that the field requires more rigorous and uniform tools for co-speech gesture evaluation, and formulate recommendations for empirical evaluation, including standardized phrases and example scenarios to help systematically test generative models across studies. Furthermore, we also propose a checklist that can be used to report relevant information for the evaluation of generative models, as well as to evaluate co-speech gesture use.
C1 [Wolfert, Pieter; Belpaeme, Tony] Univ Ghent, IDLab, B-9052 Ghent, Belgium.
   [Robinson, Nicole] Monash Univ, Turner Inst Brain & Mental Hlth, Dept Elect & Comp Syst Engn, Fac Engn,Fac Med Nursing & Hlth Sci, Clayton, Vic 3800, Australia.
RP Wolfert, P (corresponding author), Univ Ghent, IDLab, B-9052 Ghent, Belgium.
EM pieter.wolfert@ugent.be; nicole.robinson@monash.edu;
   tony.belpaeme@ugent.be
OI Belpaeme, Tony/0000-0001-5207-7745; Wolfert, Pieter/0000-0002-7420-7181
FU Flemish Government through AI Research Program; Flemish Research
   Foundation [1S95020N]
FX This work was supported in part by the Flemish Government through AI
   Research Program and in part by the Flemish Research Foundation under
   Grant 1S95020N. This article was recommended by Associate Editor Emilia
   I. Barakova.
CR Alexanderson S, 2020, COMPUT GRAPH FORUM, V39, P487, DOI 10.1111/cgf.13946
   Allmendinger K, 2010, EDUC PSYCHOL REV, V22, P41, DOI 10.1007/s10648-010-9117-8
   Aly A, 2013, ACMIEEE INT CONF HUM, P325, DOI 10.1109/HRI.2013.6483606
   Bartneck C., 2008, METR HRI WORKSH 2008, V8
   Bennewitz Maren, 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P1072
   Bergmann K, 2009, LECT NOTES ARTIF INT, V5773, P76
   Breazeal C, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P383, DOI 10.1109/IROS.2005.1545011
   Bremner P, 2009, RO-MAN 2009: THE 18TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P1029, DOI 10.1109/ROMAN.2009.5326136
   Bremner P, 2009, IEEE SYS MAN CYBERN, P1645, DOI 10.1109/ICSMC.2009.5346903
   Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980
   Cassell J, 2004, COG TECH, P163
   Cassell J., 1994, P 21 ANN C COMP GRAP, P413, DOI DOI 10.1145/192161.192272
   Chidambaram V, 2012, ACMIEEE INT CONF HUM, P293
   Chiu CC, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P781
   Chui K., 2005, LANGUAGE LINGUISTICS, V6, P635
   Dawes J, 2008, INT J MARKET RES, V50, P61, DOI 10.1177/147078530805000106
   Fernandez-Baena A, 2014, SPEECH COMMUN, V57, P331, DOI 10.1016/j.specom.2013.06.005
   Ferstl Y., P ACM S APPL PERC, P1
   Ferstl Ylva, 2019, MOTION INTERACTION G, P1
   Ghazali AS, 2019, ADV ROBOTICS, V33, P325, DOI 10.1080/01691864.2019.1589570
   Ghazali AS, 2018, COMPUT HUM BEHAV, V87, P58, DOI 10.1016/j.chb.2018.05.016
   Ham J, 2015, INT J SOC ROBOT, V7, P479, DOI 10.1007/s12369-015-0280-4
   Hasegawa D, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P79, DOI 10.1145/3267851.3267878
   Hoffman G, 2020, ACM T HUM-ROBOT INTE, V10, DOI 10.1145/3412374
   Homke P, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0208030
   Huang C.-M., 2013, ROBOTICS SCI SYSTEMS, P57, DOI [10.15607/rss.2013.ix.026, 10.15607/RSS.2013.IX.026, DOI 10.15607/RSS.2013.IX.026]
   Huang CM, 2014, ACMIEEE INT CONF HUM, P57, DOI 10.1145/2559636.2559668
   Igualada A, 2017, J EXP CHILD PSYCHOL, V156, P99, DOI 10.1016/j.jecp.2016.11.017
   Ishi CT, 2018, IEEE ROBOT AUTOM LET, V3, P3757, DOI 10.1109/LRA.2018.2856281
   Ishii R, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P87, DOI 10.1145/3267851.3267866
   Jonell P, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423860
   Jordan P. W., 2020, INTRO USABILITY
   Keijsers M, 2020, THESIS U CANTERBURY
   Kendon, 1980, RELATIONSHIP VERBAL
   Kim HH, 2012, IND ROBOT, V39, P551, DOI 10.1108/01439911211268705
   Kim J, 2012, ASIA-PAC INT SYM ELE, P645, DOI 10.1109/APEMC.2012.6237964
   Kipp M, 2007, LECT NOTES ARTIF INT, V4722, P15
   Knapp M. L., 2013, NONVERBAL COMMUNICAT
   Kohavi R., 2017, ENCY MACHINE LEARNIN, V7, P922, DOI [10.1007/978-1-4899-7687-1_891, DOI 10.1007/978-1-4899-7687-1]
   Kong APH, 2015, J NONVERBAL BEHAV, V39, P93, DOI 10.1007/s10919-014-0200-6
   Kopp S, 2006, LECT NOTES ARTIF INT, V4133, P205
   Kucherenko Taras, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P242, DOI 10.1145/3382507.3418815
   Kucherenko T, 2021, IUI '21 - 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P11, DOI 10.1145/3397481.3450692
   Kucherenko T, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P97, DOI 10.1145/3308532.3329472
   Le Q., 2012, P ICMI WORKSH SPEECH
   Le Q. A., 2012, P 8 ACM IEEE INT C H, P134
   Lemaignan S, 2016, ACMIEEE INT CONF HUM, P157, DOI 10.1109/HRI.2016.7451747
   Levine S., 2010, ACM SIGGRAPH 2010 PA, P1
   Levine S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618518
   Liu Y., P 9 INT C HUM AG INT, V2021, P31
   Lucca K, 2018, CHILD DEV, V89, P941, DOI 10.1111/cdev.12707
   McNeill D., 1992, HAND MIND WHAT GESTU
   Mlakar I., 2013, INT J ADV ROB SYST, V10, P344, DOI [10.5772/56870, DOI 10.5772/56870]
   Moher David, 2009, Ann Intern Med, V151, P264, DOI 10.1136/bmj.b2535
   Moss, 2020, IS IT ETHICAL USE ME
   Nakano YI, 2010, IUI 2010, P139
   Neff M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330516
   Ng-Thow-Hing Victor, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P4617, DOI 10.1109/IROS.2010.5654322
   Ondras Jan, 2021, IEEE Trans Cybern, V51, P5445, DOI 10.1109/TCYB.2020.2966730
   Pandey AK, 2018, IEEE ROBOT AUTOM MAG, V25, P40, DOI 10.1109/MRA.2018.2833157
   Perez-Mayos L, 2020, J INTELL ROBOT SYST, V99, P277, DOI 10.1007/s10846-019-01100-3
   Peterson RA, 2014, J BUS RES, V67, P1035, DOI 10.1016/j.jbusres.2013.08.010
   Rojc M, 2017, ENG APPL ARTIF INTEL, V57, P80, DOI 10.1016/j.engappai.2016.10.006
   Salem M., 2011, 2011 RO-MAN: The 20th IEEE International Symposium on Robot and Human Interactive Communication, P247, DOI 10.1109/ROMAN.2011.6005285
   Salem M, 2013, INT J SOC ROBOT, V5, P313, DOI 10.1007/s12369-013-0196-9
   Salem M, 2013, LECT NOTES ARTIF INT, V8239, P381, DOI 10.1007/978-3-319-02675-6_38
   Salem M, 2012, INT J SOC ROBOT, V4, P201, DOI 10.1007/s12369-011-0124-9
   Saunderson S, 2019, INT J SOC ROBOT, V11, P575, DOI 10.1007/s12369-019-00523-0
   Scassellati, 2014, P 36 ANN C COGN SCI, P898
   Schrum ML, 2020, ACMIEEE INT CONF HUM, P43, DOI 10.1145/3371382.3380739
   Shimazu A, 2018, IEEE ROMAN, P961, DOI 10.1109/ROMAN.2018.8525621
   Straube B, 2011, HUM BRAIN MAPP, V32, P520, DOI 10.1002/hbm.21041
   Takeuchi K, 2017, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON HUMAN AGENT INTERACTION (HAI'17), P365, DOI 10.1145/3125739.3132594
   Weijters B, 2010, INT J RES MARK, V27, P236, DOI 10.1016/j.ijresmar.2010.02.004
   Wolfert P., 2019, P ICDL EPIROB WORKSH, P1
   Wolfert P., P ACM INT C MULT INT, V2021, P494
   Xu YY, 2014, LECT NOTES ARTIF INT, V8637, P477, DOI 10.1007/978-3-319-09767-1_58
   Yoon Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417838
   Yoon Y, 2019, IEEE INT CONF ROBOT, P4303, DOI 10.1109/ICRA.2019.8793720
NR 79
TC 1
Z9 1
U1 6
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2291
EI 2168-2305
J9 IEEE T HUM-MACH SYST
JI IEEE T. Hum.-Mach. Syst.
PD JUN
PY 2022
VL 52
IS 3
BP 379
EP 389
DI 10.1109/THMS.2022.3149173
EA FEB 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 1I7WD
UT WOS:000764837000001
OA Green Submitted, Green Published
DA 2022-08-02
ER

PT J
AU Even, C
   Hammann, T
   Heyl, V
   Rietz, C
   Wahl, HW
   Zentel, P
   Schlomann, A
AF Even, Christiane
   Hammann, Torsten
   Heyl, Vera
   Rietz, Christian
   Wahl, Hans-Werner
   Zentel, Peter
   Schlomann, Anna
TI Benefits and challenges of conversational agents in older adults A
   scoping review
SO ZEITSCHRIFT FUR GERONTOLOGIE UND GERIATRIE
LA English
DT Review; Early Access
DE Digital voice assistants; Smart speaker; Sociotechnical systems; Old
   age; Digitalization
AB Background Commercial conversational agents (CAs) bear the promise of low threshold accessibility for individuals with limited digital competencies. This applies not only for healthy aging older adults but also for specific subgroups such as those with life-long intellectual disabilities (ID). Objective This scoping review aims to synthesize the current evidence on benefits and challenges of CAs for older adults with and without ID. In doing so, we hope to inform future research as well as practical decision-making in the context of CAs as potential quality of life enhancers for older adults with various competence levels. Material and methods A literature search was conducted in form of a scoping review. A total of 841 publications were screened for benefits and challenges of CAs, resulting in an extraction of 18 articles targeting healthy aging older adults (60 years+) and 5 articles targeting older adults with ID (50 years+) for synthesis. Results The existing evidence suggests that CAs come with more benefits than challenges, e.g., general ease of use, easier information access, and feelings of companionship. Higher perceived agency due to using a CA seems to be a specific issue for older adults with ID. Challenges concern mostly learning how to use a CA and privacy concerns. Conclusion The results indicate that CAs can serve as quality of life enhancers both in healthy aging adults and in older adults with ID; nevertheless, thoughtful preparation is necessary, especially in relation to learning needs, capabilities present and privacy concerns.
C1 [Even, Christiane; Wahl, Hans-Werner; Schlomann, Anna] Heidelberg Univ, Network Aging Res, Heidelberg, Germany.
   [Hammann, Torsten; Rietz, Christian; Schlomann, Anna] Heidelberg Univ Educ, Dept Educ Sci, Heidelberg, Germany.
   [Heyl, Vera] Heidelberg Univ Educ, Dept Special Educ, Heidelberg, Germany.
   [Wahl, Hans-Werner] Heidelberg Univ, Inst Psychol, Heidelberg, Germany.
   [Zentel, Peter] Ludwig Maximilians Univ Munchen, Dept Educ & Rehabil, Munich, Germany.
RP Even, C (corresponding author), Heidelberg Univ, Network Aging Res, Heidelberg, Germany.
EM even@nar.uni-heidelberg.de
FU Baden-Wurttemberg Stiftung within the funding line Responsible
   Artificial Intelligence
FX This publication is part of the AI-Aging project (AI-based voice
   assistants for older adults with and without intellectual disabilities),
   which is funded by the Baden-Wurttemberg Stiftung within the funding
   line Responsible Artificial Intelligence.
CR Abdolrahmani A, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P249, DOI 10.1145/3234695.3236344
   Arnold A, 2022, DISABIL REHABIL-ASSI, DOI 10.1080/17483107.2022.2065369
   BAGSO, 2022, US
   Barnard Y, 2013, COMPUT HUM BEHAV, V29, P1715, DOI 10.1016/j.chb.2013.02.006
   Checkmyva, 2022, PROJ
   Couper-Kuhlen Elizabeth., 2018, INTERACTIONAL LINGUI
   Digitaler-Engel, 2022, US
   Ehlers A., 2020, EXPERTISEN ZUM ACHTE, P1
   Jakob D, 2022, HUMAN ASPECTS IT AGE, V330, P175
   Leung R, 2012, ACM T ACCESS COMPUT, V4, DOI 10.1145/2399193.2399195
   McTear M., 2016, CONVERSATIONAL INTER, DOI [10.1007/978-3-319-32967-3, DOI 10.1007/978-3-319-32967-3]
   Medienpadagogischer Forschungsverbund Sudwest (mfps), 2021, JIM STUD 2021 JUG IN
   Neves BB, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1593, DOI 10.1145/2702123.2702430
   Peters MDJ, 2015, INT J EVID-BASED HEA, V13, P141, DOI 10.1097/XEB.0000000000000050
   Pew Research Center, 2021, 7 AM DONT US INT WHO
   Pradhan A, 2018, PORTL INT CONF MANAG, DOI 10.1145/3173574.3174033
   Ramadan Z., 2020, PSYCHOL MARK, V38, P1
   Ruff C, 2021, LECT NOTES INFORM, P119
   Schalock RL, 2021, AJIDD-AM J INTELLECT, V126, P439, DOI 10.1352/1944-7558-126.6.439
   Schlomann A., 2021, BILD ERZIEHUNG, V74, P296, DOI [10.13109/buer.2021.74.3.296, DOI 10.13109/BUER.2021.74.3.296]
   Schlomann A, 2022, FRONT COMP SCI-SWITZ, V3, DOI 10.3389/fcomp.2021.803740
   Schlomann A, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.684012
   Smith E, 2020, DISABIL REHABIL-ASSI, DOI 10.1080/17483107.2020.1864670
   Statista, 2020, LARG EUR CO POULTR M
   Stigall B, 2020, PROCEEDINGS OF THE 31ST AUSTRALIAN CONFERENCE ON HUMAN-COMPUTER-INTERACTION (OZCHI'19), P423, DOI 10.1145/3369457.3369506
   World Health Organization, 2021, LEAD POIS
NR 26
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0948-6704
EI 1435-1269
J9 Z GERONTOL GERIATR
JI Z. Gerontol. Geriatr.
DI 10.1007/s00391-022-02085-9
EA JUL 2022
PG 7
WC Geriatrics & Gerontology; Gerontology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Geriatrics & Gerontology
GA 3A6OB
UT WOS:000827375700001
PM 35852588
DA 2022-08-02
ER

PT J
AU Guerreiro, MP
   Angelini, L
   Henriques, HR
   El Kamali, M
   Baixinho, C
   Balsa, J
   Felix, IB
   Abou Khaled, O
   Carmo, MB
   Claudio, AP
   Caon, M
   Daher, K
   Alexandre, B
   Padinha, M
   Mugellini, E
AF Guerreiro, Mara Pereira
   Angelini, Leonardo
   Henriques, Helga Rafael
   El Kamali, Mira
   Baixinho, Cristina
   Balsa, Joao
   Felix, Isa Brito
   Abou Khaled, Omar
   Carmo, Maria Beatriz
   Claudio, Ana Paula
   Caon, Maurizio
   Daher, Karl
   Alexandre, Bruno
   Padinha, Mafalda
   Mugellini, Elena
TI Conversational Agents for Health and Well-being Across the Life Course:
   Protocol for an Evidence Map
SO JMIR RESEARCH PROTOCOLS
LA English
DT Article
DE artificial intelligence; conversational agent; chatbot; virtual
   assistant; relational agent; virtual humans; e-coach; intervention;
   health; well-being
ID GOOGLE SCHOLAR; REVIEWS; BIAS; RISK; WEB
AB Background: Conversational agents, which we defined as computer programs that are designed to simulate two-way human conversation by using language and are potentially supplemented with nonlanguage modalities, offer promising avenues for health interventions for different populations across the life course. There is a lack of open-access and user-friendly resources for identifying research trends and gaps and pinpointing expertise across international centers.
   Objective: Our aim is to provide an overview of all relevant evidence on conversational agents for health and well-being across the life course. Specifically, our objectives are to identify, categorize, and synthesize-through visual formats and a searchable database-primary studies and reviews in this research field.
   Methods: An evidence map was selected as the type of literature review to be conducted, as it optimally corresponded to our aim. We systematically searched 8 databases (MEDLINE; CINAHL; Web of Science; Scopus; the Cochrane, ACM, IEEE, and Joanna Briggs Institute databases; and Google Scholar). We will perform backward citation searching on all included studies. The first stage of a double-stage screening procedure, which was based on abstracts and titles only, was conducted by using predetermined eligibility criteria for primary studies and reviews. An operational screening procedure was developed for streamlined and consistent screening across the team. Double data extraction will be performed with previously piloted data collection forms. We will appraise systematic reviews by using A Measurement Tool to Assess Systematic Reviews (AMSTAR) 2. Primary studies and reviews will be assessed separately in the analysis. Data will be synthesized through descriptive statistics, bivariate statistics, and subgroup analysis (if appropriate) and through high-level maps such as scatter and bubble charts. The development of the searchable database will be informed by the research questions and data extraction forms.
   Results: As of April 2021, the literature search in the eight databases was concluded, yielding a total of 16,351 records. The first stage of screening, which was based on abstracts and titles only, resulted in the selection of 1282 records of primary studies and 151 records of reviews. These will be subjected to second-stage screening. A glossary with operational definitions for supporting the study selection and data extraction stages was drafted. The anticipated completion date is October 2021.
   Conclusions: Our wider definition of a conversational agent and the broad scope of our evidence map will explicate trends and gaps in this field of research. Additionally, our evidence map and searchable database of studies will help researchers to avoid fragmented research efforts and wasteful redundancies. Finally, as part of the Harnessing the Power of Conversational e-Coaches for Health and Well-being Through Swiss-Portuguese Collaboration project, our work will also inform the development of an international taxonomy on conversational agents for health and well-being, thereby contributing to terminology standardization and categorization.
C1 [Guerreiro, Mara Pereira; Henriques, Helga Rafael; Felix, Isa Brito] Nursing Res Innovat & Dev Ctr Lisbon, Nursing Sch Lisbon, Ave Prof Egas Moniz, Lisbon, Portugal.
   [Guerreiro, Mara Pereira] Inst Univ Egas Moniz, Ctr Invest Interdisciplinar Egas Moniz, Monte De Caparica, Portugal.
   [Angelini, Leonardo; El Kamali, Mira; Abou Khaled, Omar; Caon, Maurizio; Daher, Karl; Mugellini, Elena] Univ Appl Sci & Arts Western Switzerland, Fribourg, Switzerland.
   [Baixinho, Cristina] CiTechare, Leiria, Portugal.
   [Balsa, Joao; Carmo, Maria Beatriz; Claudio, Ana Paula] Univ Lisbon, Fac Ciencias, LASIGE, Lisbon, Portugal.
   [Alexandre, Bruno] Nursing Sch Lisbon, Lisbon, Portugal.
   [Padinha, Mafalda] Inst Univ Egas Moniz, Monte De Caparica, Portugal.
RP Guerreiro, MP (corresponding author), Nursing Res Innovat & Dev Ctr Lisbon, Nursing Sch Lisbon, Ave Prof Egas Moniz, Lisbon, Portugal.
EM mara.guerreiro@esel.pt
RI Henriques, Helga/ADP-1384-2022; KHALED, Omar ABOU/O-6389-2019; Félix,
   Isa Brito/AAZ-2624-2020; Lavareda Baixinho, Cristina/H-7607-2019; Carmo,
   Maria Beatriz/B-4003-2016; Claudio, Ana Paula/L-6809-2017
OI Henriques, Helga/0000-0003-2946-4485; KHALED, Omar
   ABOU/0000-0002-0178-9037; Félix, Isa Brito/0000-0001-8186-9506; Pereira
   Guerreiro, Mara/0000-0001-8192-6080; Lavareda Baixinho,
   Cristina/0000-0001-7417-1732; Carmo, Maria Beatriz/0000-0002-4768-9517;
   Claudio, Ana Paula/0000-0002-4594-8087; El Kamali,
   Mira/0000-0003-2895-6867
FU Haute Ecole Specialisee de Suisse occidentale (University of Applied
   Sciences and Arts Western Switzerland); Conselho Coordenador dos
   Institutos Superiores Politecnicos (Portuguese Polytechnics Coordinating
   Council)
FX This study is part of the Harnessing the Power of Conversational
   e-Coaches for Health and Well-being Through Swiss-Portuguese
   Collaboration project, which was awarded a grant for joint
   Swiss-Portuguese academic projects and funded by the Haute Ecole
   Specialisee de Suisse occidentale (University of Applied Sciences and
   Arts Western Switzerland) and the Conselho Coordenador dos Institutos
   Superiores Politecnicos (Portuguese Polytechnics Coordinating Council).
   The sponsors did not have any role in the design, execution, and
   reporting of the study.
CR Agarwal S, 2016, BMJ-BRIT MED J, V352, DOI 10.1136/bmj.i1174
   Angelini L, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P620, DOI 10.1145/3316782.3322763
   [Anonymous], NONCOMMUNICABLE DIS
   [Anonymous], INT CLASSIFICATION H
   [Anonymous], 2017, BLUEPRINT DIGITAL TR
   Bar-Ilan J., 2018, FRONT RES METR ANAL, V3, P1, DOI 10.3389/frma.2018.00006
   Bibault JE, 2019, CLIN TRANSL RAD ONCO, V16, P55, DOI 10.1016/j.ctro.2019.04.002
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bittner E., 2019, P 52 HAW INT C SYST
   Bramer WM, 2018, J MED LIBR ASSOC, V106, P531, DOI 10.5195/jmla.2018.283
   Briscoe S, 2020, RES SYNTH METHODS, V11, P169, DOI 10.1002/jrsm.1355
   Burden David, 2019, VIRTUAL HUMANS TODAY
   Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158
   Chattopadhyay D, 2020, J MED INTERNET RES, V22, DOI 10.2196/18839
   de Antonio A, 2001, 3 INT WORKSH INT VIR, DOI [10.1007/3-540-44812-8, DOI 10.1007/3-540-44812-8]
   de Cock C, 2020, JMIR RES PROTOC, V9, DOI 10.2196/16934
   Diederich S, 2019, HUMAN PRACTICE DIGIT, P1100
   Drucker AM, 2016, J INVEST DERMATOL, V136, pE109, DOI 10.1016/j.jid.2016.08.021
   El Kamali M, 2020, CUI 20 2 C CONV US I, P1, DOI [10.1145/3405755.3406167, DOI 10.1145/3405755.3406167]
   El Kamali M, 2020, IEEE ACCESS, V8, P101884, DOI 10.1109/ACCESS.2020.2996404
   El Kamali M, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC'18 ADJUNCT), P1656, DOI 10.1145/3267305.3274188
   Eysenbach G, 2011, J MED INTERNET RES, V13, DOI 10.2196/jmir.1923
   Felix IB, 2019, FRONT PHARMACOL, V10, DOI 10.3389/fphar.2019.00680
   Garousi V, 2019, INFORM SOFTWARE TECH, V106, P101, DOI 10.1016/j.infsof.2018.09.006
   Gates M, 2020, J CLIN EPIDEMIOL, V125, P9, DOI 10.1016/j.jclinepi.2020.04.026
   Guerreiro MP, 2020, EXPLORING ROLE ICTS
   Gusenbauer M, 2020, RES SYNTH METHODS, V11, P181, DOI 10.1002/jrsm.1378
   Haddaway NR, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138237
   Haustein S, WHEN IS ARTICLE ACTU
   Hoermann S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7023
   Kelly MP, 2016, PUBLIC HEALTH, V136, P109, DOI 10.1016/j.puhe.2016.03.030
   Kocaballi AB, 2019, J MED INTERNET RES, V21, DOI 10.2196/15360
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lefebvre C, 2019, COCHRANE HDB SYSTEMA, DOI DOI 10.1002/9781119536604.CH4
   Ma TT, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312853
   Martin-Martin A, 2018, SCIENTOMETRICS, V116, P2175, DOI 10.1007/s11192-018-2820-9
   Miake-Lye IM, 2016, SYST REV-LONDON, V5, DOI 10.1186/s13643-016-0204-x
   Moed HF, 2016, J INFORMETR, V10, P533, DOI 10.1016/j.joi.2016.04.017
   Nyberg ST, 2020, JAMA INTERN MED, V180, P760, DOI 10.1001/jamainternmed.2020.0618
   Ouzzani M, 2016, SYST REV-LONDON, V5, DOI 10.1186/s13643-016-0384-4
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI 10.1136/bmj.n71
   Pereira J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1237-1
   Pieper D, 2019, J CLIN EPIDEMIOL, V108, P26, DOI 10.1016/j.jclinepi.2018.12.004
   Poole D. L., 2017, ARTIF INTELL, V2nd
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Rinaldi G, 2020, DIABETES RES CLIN PR, V162, DOI 10.1016/j.diabres.2020.108084
   Schachner T, 2020, J MED INTERNET RES, V22, DOI 10.2196/20701
   Shea BJ, 2017, BMJ-BRIT MED J, V358, DOI 10.1136/bmj.j4008
   Tropea P, 2019, J MED INTERNET RES, V21, DOI 10.2196/12805
   Tugwell P, 2020, BMJ-BRIT MED J, V370, DOI 10.1136/bmj.m2864
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   White H, 2020, CAMPBELL SYST REV, V16, DOI 10.1002/cl2.1125
   Xing ZP, 2019, J MED INTERNET RES, V21, DOI 10.2196/14672
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
NR 55
TC 2
Z9 2
U1 1
U2 2
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 1929-0748
J9 JMIR RES PROTOC
JI JMIR RES. Protoc.
PD SEP
PY 2021
VL 10
IS 9
AR e26680
DI 10.2196/26680
PG 11
WC Health Care Sciences & Services; Public, Environmental & Occupational
   Health
WE Emerging Sources Citation Index (ESCI)
SC Health Care Sciences & Services; Public, Environmental & Occupational
   Health
GA WQ7UH
UT WOS:000714017100002
PM 34533460
OA Green Submitted, gold, Green Published
DA 2022-08-02
ER

PT C
AU Gratch, J
AF Gratch, Jonathan
BE Wachsmuth, I
   Knoblich, G
TI True emotion vs. social intentions in nonverbal communication: Towards a
   synthesis for embodied conversational agents
SO MODELLING COMMUNICATION WITH ROBOTS AND VIRTUAL HUMANS
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 2nd ZiF-Research-Group International Workshop on Embodied Communication
   in Humans and Machines
CY APR 05-08, 2006
CL Bielefeld, GERMANY
SP ZiF Res Grp
DE emotion; nonverbal behavior; virtual humans; cognitive modeling
ID INDIVIDUAL-DIFFERENCES; RESPONSES
AB Does a facial expression convey privileged information about a person's mental state or is it a communicative act, divorced from "true" beliefs, desires and intentions? This question is often cast as a dichotomy between competing theoretical perspectives. Theorists like Ekman argue for the primacy of emotion as a determinant of nonverbal behavior: emotions "leak" and only indirectly serve social ends. In contrast, theorists such as Fridlund argue for the primacy of social ends in determining nonverbal displays. This dichotomy has worked to divide virtual character research. Whereas there have been advances in modeling emotion, this work is often seen as irrelevant to the generation of communicative behavior. In this chapter, I review current findings on the interpersonal function of emotion. I'll discuss recent developments in Social Appraisal theory as a way to bridge this dichotomy and our attempts to model these functions within the context of embodied conversational agents.
C1 Univ So Calif, Los Angeles, CA 90089 USA.
RP Gratch, J (corresponding author), Univ So Calif, Los Angeles, CA 90089 USA.
EM gratch@ict.usc.edu
CR AGRE P, 1987, NATL C ART INT
   Austin J.L., 1962, THINGS WORDS
   Barrett Karen Caplovitz, 1995, P25
   Bartlett Marian Stewart, 2006, 7 INT C AUT FAC GEST
   BLANCHARD A, 2006, 6 INT WORKSH EP ROB
   Breazeal C, 2002, AUTON ROBOT, V12, P83, DOI 10.1023/A:1013215010749
   Brosig J, 2002, J ECON BEHAV ORGAN, V47, P275, DOI 10.1016/S0167-2681(01)00211-6
   Brown Penelope, 1987, POLITENESS SOME UNIV
   BURLESON W, 2006, THESIS MIT BOSTON
   Cassell J, 2000, EMBODIED CONVERSATIONAL AGENTS, P29
   CHOVIL N, 1991, J NONVERBAL BEHAV, V15, P163, DOI 10.1007/BF01672218
   CLORE GL, 2006, AFFECTIVE INFLUENCES, P26
   Dimberg U, 1996, MOTIV EMOTION, V20, P149, DOI 10.1007/BF02253869
   DOLS JMF, 1997, PSYCHOL FACIAL EXPRE
   DUNN J, 1995, COGNITION EMOTION, V9, P187, DOI 10.1080/02699939508409008
   EDER RA, 1990, CHILD DEV, V61, P849, DOI 10.1111/j.1467-8624.1990.tb02827.x
   Eisenberg N, 1989, New Dir Child Dev, P107
   Ekman P., 1972, NEBRASKA S MOTIVATIO, P207, DOI DOI 10.1037/0022-3514.53.4.712
   Elliott C., 1999, Artificial intelligence today. Recent trends and developments, P195
   Emde R. N., 1976, MONOGRAPH, V37
   Fogel A, 1993, DEV RELATIONSHIPS OR
   Frank R., 2004, FEELINGS EMOTIONS, P422, DOI [10.1017/cbo9780511806582.024, DOI 10.1017/CBO9780511806582.024, 10.1017/CBO9780511806582.024]
   Frank R. H., 1988, PASSIONS REASON STRA
   FRANK RH, 1993, ETHOL SOCIOBIOL, V14, P247, DOI 10.1016/0162-3095(93)90020-I
   Fridlund A.J., 1994, HUMAN FACIAL EXPRESS
   Gratch J., 2004, COGN SYST RES, V5, P269
   GRATCH J, 2006, LNCS LNAI, V4133
   Gratch J, 2007, 7 INT C INT VIRT AG
   GRATCH J, 2001, 5 INT C AUT AG
   Harris Paul L, 1989, CHILDREN EMOTION
   HAVILAND JM, 1987, DEV PSYCHOL, V23, P97, DOI 10.1037/0012-1649.23.1.97
   HEYLEN D, 2005, AISB 2005
   IZARD CE, 1977, HUMAN EMOTION
   JONDOTTIR GR, 2007, INTELLIGENT VIRTUAL
   Keltner D, 1999, COGNITION EMOTION, V13, P505, DOI 10.1080/026999399379168
   Klauer KC, 2003, PSYCHOLOGY OF EVALUATION, P7
   KRAMER NC, 2005, P S AG WANT LIK ART
   Leary MR, 1996, J PERS, V64, P619, DOI 10.1111/j.1467-6494.1996.tb00524.x
   Lester J. C., 1998, INT J ARTIFICIAL INT, V10, P278
   Lisetti CL, 2002, APPL ARTIF INTELL, V16, P577, DOI 10.1080/08839510290030408
   LUTZ C, 1986, ANNU REV ANTHROPOL, V15, P405, DOI 10.1146/annurev.an.15.100186.002201
   Macedo S, 2006, PRIMATES AND PHILOSOPHERS: HOW MORALITY EVOLVED, P1
   Manstead A.S.R., 2005, EMOTION SOCIAL RELAT
   Manstead A.S.R., 1999, SOCIAL CONTEXT NONVE, P287
   MAO W, 2006, 5 INT JOINT C AUT AG
   MAO W, 2004, 3 INT JOINT C AUT AG
   Marsella S, 2004, COG TECH, P317
   Marsella S., 2003, 2 INT JOINT C AUT AG
   MARTINOVSKI B, 2005, COGNITIVE SCI
   MORENCY LP, 2005, 7 INT C MULT INT TOR
   Park B, 2005, PERS SOC PSYCHOL REV, V9, P108, DOI 10.1207/s15327957pspr0902_2
   Parkinson B., 2001, APPRAISAL PROCESSES, P173
   Phillips ML, 2004, BRAIN, V127, P1691, DOI 10.1093/brain/awh254
   Poggi I., 2000, Affective Interactions. Towards a New Generation of Computer Interfaces (Lecture Notes in Artificial Intelligence Vol.1814), P182
   Reilly W. S., 1996, BELIEVABLE SOCIAL EM
   RICKEL J, 2002, IEEE INTELLIGENT JUL, P32
   Scherer K.R., 2001, AFFECTIVE SCI
   SCHEUTZ M, 2001, IAT 2001
   Shannon C.E., 1948, MATH THEORY COMMUNIC
   Shaver K. G., 1985, ATTRIBUTION BLAME CA
   Simon H.A., 1969, SCI ARTIFICIAL
   Smith C.A., 1990, HDB PERSONALITY THEO, P609, DOI DOI 10.1016/0191-8869(91)90043-B.
   SMITH CA, 2006, AFFECTIVE INFLUENCES
   Spoor JR, 2004, GROUP PROCESS INTERG, V7, P398, DOI 10.1177/1368430204046145
   Suchman LucyA., 1987, PLANS SITUATED ACTIO
   SWARTOUT W, 2006, AIL MAGAZINE, V27
   TANGNEY JP, 1990, J PERS SOC PSYCHOL, V59, P102, DOI 10.1037/0022-3514.59.1.102
   TIEDENS LZ, 2001, COGNITIVE PROCESSING, V25
   WANG N, 2005, INTELLIGENT USER INT
   Ward N, 2000, J PRAGMATICS, V32, P1177, DOI 10.1016/S0378-2166(99)00109-5
   Weiner B, 2001, INTENTIONS INTENTION
   Zak PJ, 2004, PHILOS T R SOC B, V359, P1737, DOI 10.1098/rstb.2004.1544
NR 72
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-540-79036-5
J9 LECT NOTES ARTIF INT
PY 2008
VL 4930
BP 181
EP 197
PG 17
WC Computer Science, Artificial Intelligence; Robotics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Robotics
GA BHP49
UT WOS:000255181500010
DA 2022-08-02
ER

PT C
AU Xiao, J
   Stasko, J
   Catrambone, R
AF Xiao, Jun
   Stasko, John
   Catrambone, Richard
GP ACM
TI The Role of Choice and Customization on Users' Interaction with Embodied
   Conversational Agents: Effects on Perception and Performance
SO CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2
LA English
DT Proceedings Paper
CT Conference on Human Factors in Computing Systems
CY APR 28-MAY 03, 2007
CL San Jose, CA
SP SIGCHI, Assoc Comp Machinery
DE Embodied conversational agents; interface assistants; empirical
   evaluation; qualitative analysis; controlled experiment;
   personalization; customization
AB We performed an empirical study exploring people's interactions with an embodied conversational agent (ECA) while performing two tasks. Conditions varied with respect to 1) whether participants were allowed to choose an agent and its characteristics and 2) the putative quality or appropriateness of the agent for the tasks. For both tasks, selection combined with the illusion of further customization significantly improved participants' overall subjective impressions of the ECAs while putative quality had little or no effect. Additionally, performance data revealed that the ECA's motivation and persuasion effects were significantly enhanced when participants chose agents to use. We found that user expectations about and perceptions of the interaction between themselves and an ECA depended very much on the individual's preconceived notions and preferences of various ECA characteristics and might deviate greatly from the models that ECA designers intend to portray.
C1 [Xiao, Jun; Stasko, John] Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA.
RP Xiao, J (corresponding author), Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA.
EM junxiao@cc.gatech.edu; stasko@cc.gatech.edu; rc7@prism.gatech.edu
RI Catrambone, Richard/B-6925-2008
OI Catrambone, Richard/0000-0002-7334-7406
CR Bickmore T. W., 2003, RELATIONAL AGENTS EF
   Brosnan MJ, 1998, J COMPUT ASSIST LEAR, V14, P223, DOI 10.1046/j.1365-2729.1998.143059.x
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   CATRAMBONE R, P COGSCI 2002, P166
   CORDOVA D, J ED PSYCHOL, V88, P715
   COWELL AJ, P IVA 2003, P301
   MCBREEN H, 2001, P INT C AUT AG WORKS, P83
   NASS C, P CHI 2000, P329
   XIAO J, 2004, P AAMAS 04 NEW YORK, P178
NR 9
TC 8
Z9 8
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-59593-593-9
PY 2007
BP 1293
EP 1302
PG 10
WC Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BJT07
UT WOS:000267123300148
DA 2022-08-02
ER

PT C
AU Sieinska, W
   Gunson, N
   Walsh, C
   Dondrup, C
   Lemon, O
AF Sieinska, Weronika
   Gunson, Nancie
   Walsh, Christopher
   Dondrup, Christian
   Lemon, Oliver
GP Assoc Computat Linguist
TI Conversational Agents for Intelligent Buildings
SO SIGDIAL 2020: 21ST ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON
   DISCOURSE AND DIALOGUE (SIGDIAL 2020)
LA English
DT Proceedings Paper
CT 21st Annual Meeting of the
   Special-Interest-Group-on-Discourse-and-Dialogue (SIGDIAL)
CY JUL 01-03, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist, Special Interest Grp Discourse & Dialogue, Apple, Rasa Technologies, Honda Res Inst, Toshiba Res Europe
AB We will demonstrate a deployed conversational AI system that acts as a host of a smart-building on a university campus. The system combines open-domain social conversation with task-based conversation regarding navigation in the building, live resource updates (e.g. available computers) and events in the building. We are able to demonstrate the system on several platforms: Google Home devices, Android phones, and a Furhat robot.
C1 [Sieinska, Weronika; Gunson, Nancie; Walsh, Christopher; Dondrup, Christian; Lemon, Oliver] Heriot Watt Univ, Sch Math & Comp Sci, Edinburgh EH14 4AS, Midlothian, Scotland.
RP Sieinska, W (corresponding author), Heriot Watt Univ, Sch Math & Comp Sci, Edinburgh EH14 4AS, Midlothian, Scotland.
EM w.sieinska@hw.ac.uk; n.gunson@hw.ac.uk; c.walsh.l@research.gla.ac.uk;
   c.dondrup@hw.ac.uk; o.lemon@hw.ac.uk
OI Lemon, Oliver/0000-0001-9497-4743
FU EPSRC Impact Acceleration Award (IAA); EU [871245]
FX This work has been partially funded by an EPSRC Impact Acceleration
   Award (IAA) and by the EU H2020 program under grant agreement no. 871245
   (SPRING)<SUP>5</SUP>.
CR Khashe S, 2019, INT J HUM-COMPUT INT, V35, P1545, DOI 10.1080/10447318.2018.1555346
   Lemon Oliver, 2018, P 12 INT C DISTR SMA
   Papaioannou I, 2017, IEEE ROMAN, P593, DOI 10.1109/ROMAN.2017.8172363
   Papaioannou Ioannis, 2017, ALEXA PRIZE P
   Papaioannou Ioannis, 2017, ALEXA PRIZE P
   Papaioannou Ioannis, 2017, NIPS 2017 CONV AI WO
   Pecune F, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P1241
   Phani-Teja Singamaneni, 2019, MUMMER SOCIALLY INTE
   Rieser, 2018, ALEXA PRIZE P
NR 9
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-952148-02-6
PY 2020
BP 45
EP 48
PG 4
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Linguistics
GA BS2VG
UT WOS:000706995200005
DA 2022-08-02
ER

PT B
AU Amores, JG
   Manchon, P
   Perez, G
AF Gabriel Amores, J.
   Manchon, Pilar
   Perez, Guillermo
BA PerezMarin, D
   PascualNieto, I
BF PerezMarin, D
   PascualNieto, I
TI Humanizing Conversational Agents: Indisys Practical Case Study in
   eHealth
SO CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND
   EFFECTIVE PRACTICES
LA English
DT Article; Book Chapter
AB This chapter describes an eHealth human-like conversational agent called Maria embedded in the Web page of the Health Department of the Junta de Andaluc a in Spain. Although this implementation is based on a strong theoretical background, a more practical approach has been preferred for the real-world case hereby described. Maria has been designed to perform several major tasks: she can arrange a doctor's appointment, reply to queries pertaining to many varied subdomains, and navigate through the Web page. One of Maria's most remarkable features is the successful application of advanced design and humanizing techniques which endow her with unusual skills and an enticing personality. Maria has been developed by Intelligent Dialogue Systems (Indisys) within a larger scale Web development project conducted by Sadiel SA.
C1 [Manchon, Pilar] SRI Int, Dept Artificial Intelligence, Spoken Dialogue Syst Grp, Menlo Pk, CA 94025 USA.
RP Amores, JG (corresponding author), Univ Seville, Dept English Linguist, Seville, Spain.
CR ALBRECHT K, 2005, SOCIAL INTELLIGENCE
   Amores G, 2006, PROCES LENG NAT, P215
   Amores J. G., 2010, GESTION DIALOGO MULT
   Bickmore T., 2003, THESIS MIT
   Bos J., 2000, P GOET 4 WORKSH SEM
   Bresnan J., 1982, MENTAL REPRESENTATIO
   Canas J. J., 2003, ERGONOMIA COGNITIVA, V227
   Canas J.J., 2001, ERGONOMIA COGNITIVA
   Cantor N., 1979, ADV EXPT SOCIAL PSYC, V12, P3, DOI [DOI 10.1016/S0065-2601(08)60258-0, 10.1016/S0065-2601(08)60258-0]
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   Cassell J., 1998, PRAGMAT COGN, V6
   Cassell J., 2000, AI MAG, V12, P67
   Cassell J., 2000, EMBODIED CONVERSATIO
   Charniak E., 2005, P 43 ANN M ASS COMP, P173, DOI DOI 10.3115/1219840.1219862
   Collins M., 2003, COMPUT LINGUIST, V31, P175
   De Angeli A., 2001, P INT C AFF HUM FACT, P257
   Delgado RLC, 2005, SPOKEN, MULTILINGUAL AND MULTIMODAL DIALOGUE SYSTEMS: DEVELOPMENT AND ASSESSMENT, P1, DOI 10.1002/0470021578
   Dybkjaer L, 2004, SPEECH COMMUN, V43, P33, DOI 10.1016/j.specom.2004.02.001
   Ekman P., 1977, FACIAL ACTION CODING
   Fiske S. T., 1991, SOCIAL COGNITION
   GARDNER H, 1993, MULTIPLE INTELLIGENC
   Gardner H., 1999, INTELLIGENCE REFRAME
   Gardner Howard, 2011, FRAMES MIND THEORY M
   Gasson S, 2003, J INF TECHNOL THEORY, V5, P29
   Gattass M., 2002, SCIENTIA, V13, P1
   Georg G, 2008, LECT NOTES COMPUT SC, V5208, P380
   Goleman D, 1995, EMOTIONAL INTELLIGEN
   Grosz B. J., 1986, Computational Linguistics, V12, P175
   Henderson J., 2005, P INT JOINT C ART IN
   Iivari J., 2006, P 39 HAW INT C SYST
   Isbister K, 2000, INT J HUM-COMPUT ST, V53, P251, DOI 10.1006/ijhc.2000.0368
   Jacobs J., 2010, KEY CONSIDERATIONS V
   JOKINEN K., 2010, SPOKEN DIALOGUE SYST
   Jurafsky D., 2009, SPEECH LANGUAGE PROC
   Larsson S., 2000, Natural Language Engineering, P323, DOI 10.1017/S1351324900002539
   Larsson S., 2002, THESIS GOTHENBURG U
   Lester J, 2004, PRACTICAL HDB INTERN
   Long J., 1987, PSYCHOL WORK HARMOND
   Mairesse, 2007, ACL, P496
   Manchon P., 2006, G AMORES G PEREZ
   Manchon P., 2007, P 9 INT C MULT INT N
   Manchon P., 2009, THESIS U SEVILLE SPA
   Manning C. D., 1999, FDN STAT NATURAL LAN
   Mao J., 2001, P 2001 C CTR ADV STU
   Mao JY, 2005, COMMUN ACM, V48, P105, DOI 10.1145/1047671.1047677
   McTear M. F., 2004, SPOKEN DIALOGUE TECH
   NORMAN, 2022, DESIGN EVERYDAY THIN
   Norman D., 2004, HCD HARMFUL CLARIFIC
   NORMAN DA, 1998, INVISIBLE COMPUTER
   Oviatt S, 2003, P IEEE, V91, P1457, DOI 10.1109/JPROC.2003.817127
   Oviatt S., 2004, P 6 INT C MULT INT, P129, DOI DOI 10.1145/1027933.1027957
   Pelachaud C, 2002, KNOWL ENG REV, V17, P181, DOI 10.1017/S0269888902000218
   Pelachaud C., 2007, LECT NOTES COMPUTER
   Perez G., 2009, THESIS U POLITECNICA
   PERVIN LA, 1997, PERSONALITY THEORY R
   Prendinger H., 2008, LECT NOTES COMPUTER
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Riezler S, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P271
   Robinson S, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P1125
   Ruttkay Z., 2009, LECT NOTES COMPUTER
   Schmidt CTA, 2005, MIND MACH, V15, P195, DOI 10.1007/s11023-005-4734-6
   Schulman Daniel, 2009, P 4 INT C PERS TECHN, P25
   Searle John R., 1969, SPEECH ACTS
   Thomas F., 1981, ILLUSION LIFE DISNEY
   Turing AM., 1950, J MIND ASS, V59, P433, DOI [10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Williams JD, 2007, IEEE T AUDIO SPEECH, V15, P2116, DOI 10.1109/TASL.2007.902050
   Zipf G. K., 1949, HUMAN BEHAV PRINCIPL
   [No title captured]
NR 69
TC 0
Z9 0
U1 1
U2 1
PU IGI GLOBAL
PI HERSEY
PA 701 E CHOCOLATE AVE, STE 200, HERSEY, PA 17033-1240 USA
BN 978-1-60960-618-3; 978-1-60960-617-6
PY 2011
BP 312
EP 334
DI 10.4018/978-1-60960-617-6.ch014
D2 10.4018/978-1-60960-617-6
PG 23
WC Computer Science, Artificial Intelligence
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BZX29
UT WOS:000303201400015
DA 2022-08-02
ER

PT C
AU Spitale, M
   Silleresi, S
   Cosentino, G
   Panzeri, F
   Garzotto, F
AF Spitale, Micol
   Silleresi, Silvia
   Cosentino, Giulia
   Panzeri, Francesca
   Garzotto, Franca
GP ACM
TI "Whom would you like to talk with?" Exploring Conversational Agents for
   Children's Linguistic Assessment
SO PROCEEDINGS OF IDC 2020
LA English
DT Proceedings Paper
CT ACM Interaction Design and Children (IDC) Conference
CY JUN 17-24, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery, Google, iREAD, Elsevier, NSF
DE Speech Therapy; Linguistic Assessment; Children Perception;
   Conversational Agent
ID AUTISM SPECTRUM DISORDERS; LANGUAGE IMPAIRMENT; INTELLIGENCE; ROBOTS
AB The dramatic increment of communication impairments among children increases the demand for intensive, highly accessible and low-cost interventions as well as new assessment and therapeutic tools. Our research aims at exploring the use of Conversational Agents (CAs) to support linguistic assessment and training among children with language impairment. One of the open research issues in this arena concerns the identification of the most appropriate form of "embodiment" of the CA for children to interact with. To this end, we evaluated the linguistic performance of 14 neuro-typical children and 3 children with language impairment comparing different CAs - physical object and virtual character - with "traditional" human interaction. Based on our analysis, we identify insights for the design of CA: the physicality does influence the performance of linguistic tasks for children with linguistic impairment. In addition, children seem to show a preference for the physical CA and perceived it as smarter than the virtual one.
C1 [Spitale, Micol] Politecn Milan, IBM Italy, Milan, Italy.
   [Silleresi, Silvia; Cosentino, Giulia; Garzotto, Franca] Politecn Milan, Milan, Italy.
   [Panzeri, Francesca] Univ Milano Bicocca, Milan, Italy.
RP Spitale, M (corresponding author), Politecn Milan, IBM Italy, Milan, Italy.
EM micol.spitale@polimi.it; silvia.silleresi@polimi.it;
   giulia.cosentino@polimi.it; francesca.panzeri@unimib.it;
   franca.garzotto@polimi.it
OI Panzeri, Francesca/0000-0001-7668-7556; Silleresi,
   Silvia/0000-0001-6733-8733
CR [Anonymous], 2011, INVESTIGATING ROLE L
   Aresti-Bartolome N, 2015, BIO-MED MATER ENG, V26, pS811, DOI 10.3233/BME-151373
   Bartneck C, 2009, INT J SOC ROBOT, V1, P71, DOI 10.1007/s12369-008-0001-3
   Boerma T, 2016, INT J LANG COMM DIS, V51, P626, DOI 10.1111/1460-6984.12234
   Botting N., 2002, CHILD LANG TEACH THE, V18, P1
   Botting Nicola, 2003, CLASSIFICATION DEV L, P35
   Boucher J, 2003, INT J PEDIATR OTORHI, V67, pS159, DOI 10.1016/j.ijporl.2003.08.016
   Cabibihan JJ, 2013, INT J SOC ROBOT, V5, P593, DOI 10.1007/s12369-013-0202-2
   CARPENTER PA, 1990, PSYCHOL REV, V97, P404, DOI 10.1037/0033-295X.97.3.404
   Cassell J., 1999, P SIGCHI C HUM FACT, P520, DOI DOI 10.1145/302979.303150
   Cheng Y, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P337, DOI 10.1145/3202185.3202749
   Cole Ron, 1999, MATISSE ESCA SOCRATE
   Conti-Ramsden G, 2001, J CHILD PSYCHOL PSYC, V42, P741, DOI 10.1111/1469-7610.00770
   Crawford JR, 2010, COGN NEUROPSYCHOL, V27, P245, DOI 10.1080/02643294.2010.513967
   Deng E., 2019, FDN TRENDS ROBOT, V7, P251, DOI [10.1561/2300000056, DOI 10.1561/2300000056]
   Diehl JJ, 2012, RES AUTISM SPECT DIS, V6, P249, DOI 10.1016/j.rasd.2011.05.006
   Druga S, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P595, DOI 10.1145/3078072.3084330
   Eigsti IM, 2011, RES AUTISM SPECT DIS, V5, P681, DOI 10.1016/j.rasd.2010.09.001
   Epstein SA, 2009, CHILD LANG TEACH THE, V25, P285, DOI 10.1177/0265659009339819
   Finkelstein Samantha, 2013, P WORKSH CULT AW TEC
   Geurts HM, 2008, J AUTISM DEV DISORD, V38, P1931, DOI 10.1007/s10803-008-0587-1
   Hasni-Mokhtar N, 2011, PROCEDIA SOCIAL BEHA, V18, P163, DOI DOI 10.1016/J.SBSPRO.2011.05.024
   Hedenius M, 2011, RES DEV DISABIL, V32, P2362, DOI 10.1016/j.ridd.2011.07.026
   Kozima H, 2009, INT J SOC ROBOT, V1, P3, DOI 10.1007/s12369-008-0009-8
   Lovato SB, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P301, DOI 10.1145/3311927.3323150
   Mack N, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P482, DOI 10.1145/3311927.3325336
   Massaro Dominic W, 2006, 9 INT C SPOK LANG PR
   Matsuyama Y., 2016, P 17 ANN M SPEC INT, P224
   Pantoja LS, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P314, DOI 10.1145/3311927.3323151
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Raven J, 2003, HANDBOOK OF NONVERBAL ASSESSMENT, P223
   Reilly S, 2014, INT J LANG COMM DIS, V49, P416, DOI 10.1111/1460-6984.12102
   ResearchAndMarket, 2019, GLOB CONV AI MARK FO
   Riches NG, 2012, INT J LANG COMM DIS, V47, P499, DOI 10.1111/j.1460-6984.2012.00158.x
   Scassellati B, 2012, ANNU REV BIOMED ENG, V14, P275, DOI 10.1146/annurev-bioeng-071811-150036
   Silleresi S, 2018, LANG ACQUIS LANG DIS, V62, P235, DOI 10.1075/lald.62.11sil
   Strand S., 2016, FRONT EDUC, V1, DOI [10.3389/feduc.2016.00002, DOI 10.3389/FEDUC.2016.00002]
   TAGERFLUSBERG H, 1981, J AUTISM DEV DISORD, V11, P45, DOI 10.1007/BF01531340
   Tapus Adriana, 2007, GRAND CHALLENGES SOC
   Tartaro A., 2007, UNIVERSAL USABILITLY, V231, P62
   Tartaro Andrea, 2006, P COMB WORKSH LANG E
   Wainer J., 2006, ROMAN 2006 THE15TH I, P117, DOI [DOI 10.1109/ROMAN.2006.314404, 10.1109/ROMAN.2006.314404]
   WHO, 2022, ICD 11
   Wik P, 2009, SPEECH COMMUN, V51, P1024, DOI 10.1016/j.specom.2009.05.006
   Williams R., 2019, P 56 ANN DES AUT C 2, P447
   Williams R, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P625, DOI 10.1145/3202185.3210788
   Wittke K, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00532
   Zampini L, 2013, EUR J DEV PSYCHOL, V10, P563, DOI 10.1080/17405629.2013.766130
   Zampini Laura, 2017, BPA APPL PSYCHOL B, V65, P279
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
   Zhao R, 2016, LECT NOTES ARTIF INT, V10011, P218, DOI 10.1007/978-3-319-47665-0_20
NR 51
TC 2
Z9 2
U1 0
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-7981-6
PY 2020
BP 262
EP 272
DI 10.1145/3392063.3394421
PG 11
WC Computer Science, Interdisciplinary Applications; Education &
   Educational Research; Education, Scientific Disciplines
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Education & Educational Research
GA BR9HN
UT WOS:000675620600022
DA 2022-08-02
ER

PT C
AU Maya, V
   Lamolle, M
   Pelachaud, C
AF Maya, V
   Lamolle, M
   Pelachaud, C
BE LopezdeMantaras, R
   Saitta, L
TI Embodied conversational agents and influences
SO ECAI 2004: 16TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE,
   PROCEEDINGS
SE Frontiers in Artificial Intelligence and Applications
LA English
DT Proceedings Paper
CT 16th European Conference on Artificial Intelligence
CY AUG 22-27, 2004
CL Valencia, SPAIN
SP European Coordinating Comm Artificial Intelligence, Asoc Espanola Inteligencia Artificial, Assoc Catalana Intelligencia Artificial, Univ Politecn Valencia, Grp Tecnol Informat
AB In view of creating Embodied Conversational Agent (ECA) able to display individualized behaviors, we propose a taxonomy and a computational model of the influences, factors such as context environment, personality and culture may induce. Influences act not only on the type of the signals an agent conveys but also on the expressivity of the signals. Thus, to individualize ECAs, we consider not only the influences acting on the agent but also the notion of expressivity.
C1 Univ Paris 08, LINC, Paris, France.
RP Maya, V (corresponding author), Univ Paris 08, LINC, Paris, France.
CR Brislin R., 1993, UNDERSTANDING CULTUR
   De Carolis B, 2004, COG TECH, P65
   DECAROLIS B, 2002, P AAAMAS 0I WORKSH B
   DEROSIS F, IN PRESS INT J HUMAN
   PIWEK P, 2002, EMBODIED CONVERSATIO
   Prendinger H, 2002, APPL ARTIF INTELL, V16, P519, DOI 10.1080/08839510290030381
NR 6
TC 0
Z9 0
U1 0
U2 1
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 0922-6389
EI 1879-8314
BN 1-58603-452-9
J9 FRONT ARTIF INTEL AP
PY 2004
VL 110
BP 1057
EP 1058
PG 2
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BBH24
UT WOS:000225505100238
DA 2022-08-02
ER

PT C
AU Perez-Soler, S
   Guerra, E
   de Lara, J
AF Perez-Soler, Sara
   Guerra, Esther
   de Lara, Juan
BA Bousse, E
BF Bousse, E
BE Burgueno, L
   Pretschner, A
   Voss, S
   Chaudron, M
   Kienzle, J
   Volter, M
   Gerard, S
   Zahedi, M
   Rensink, A
   Polack, F
   Engels, G
   Kappel, G
TI Flexible modelling using conversational agents
SO 2019 ACM/IEEE 22ND INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING
   LANGUAGES AND SYSTEMS COMPANION (MODELS-C 2019)
LA English
DT Proceedings Paper
CT ACM/IEEE 22nd International Conference on Model Driven Engineering
   Languages and Systems Companion (MODELS-C)
CY SEP 15-20, 2019
CL Munich, GERMANY
SP IEEE, Assoc Comp Machinery, IEEE Comp Soc
DE Flexible Modelling; Conversational Agent; Natural Language Processing;
   Chatbots
AB The advances in natural language processing and the wide use of social networks have boosted the proliferation of chatbots. These are software services typically embedded within a social network, and which can be addressed using conversation through natural language. Many chatbots exist with different purposes, e.g., to book all kind of services, to automate software engineering tasks, or for customer support.
   In previous work, we proposed the use of chatbots for domainspecific modelling within social networks. In this short paper, we report on the needs for flexible modelling required by modelling using conversation. In particular, we propose a process of metamodel relaxation to make modelling more flexible, followed by correction steps to make the model conforming to its metamodel. The paper shows how this process is integrated within our conversational modelling framework, and illustrates the approach with an example.
C1 [Perez-Soler, Sara; Guerra, Esther; de Lara, Juan] Univ Autonoma Madrid, Comp Sci Dept, Madrid, Spain.
RP Perez-Soler, S (corresponding author), Univ Autonoma Madrid, Comp Sci Dept, Madrid, Spain.
EM sara.perezs@uam.es; esther.guerra@uam.es; juan.delara@uam.es
RI Guerra, Esther/B-4977-2014
OI Guerra, Esther/0000-0002-2818-2278; Perez-Soler,
   Sara/0000-0002-4558-7111
FU R&D programme of the Madrid Region [S2018/TCS4314]; Spanish Ministry of
   Science [RTI2018-095255-B-100]
FX Work funded by the R&D programme of the Madrid Region (S2018/TCS4314)
   and the Spanish Ministry of Science (RTI2018-095255-B-100).
CR Arora C, 2016, 19TH ACM/IEEE INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS (MODELS'16), P250, DOI 10.1145/2976767.2976769
   Clarizia Fabio, 2018, Cyberspace Safety and Security. 10th International Symposium, CSS 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11161), P291, DOI 10.1007/978-3-030-01689-0_23
   Dalpiaz F, 2018, IEEE SOFTWARE, V35, P115, DOI 10.1109/MS.2018.3571242
   Guerra E, 2018, 21ST ACM/IEEE INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS (MODELS 2018), P23, DOI 10.1145/3239372.3239376
   Lopes J., 2018, MODELS WORKSH, P762
   Markopoulos P., 2017, ACM T COMPUT-HUM INT, V24
   Perez-Soler S, 2019, J OBJECT TECHNOL, V18, DOI 10.5381/jot.2019.18.2.a5
   Piyush N, 2016, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON SYSTEM MODELING & ADVANCEMENT IN RESEARCH TRENDS (SMART-2016), P322, DOI 10.1109/SYSMART.2016.7894543
   Schmidt DC, 2006, COMPUTER, V39, P25, DOI 10.1109/MC.2006.58
   Singh J, 2019, J PHYS CONF SER, V1228, DOI 10.1088/1742-6596/1228/1/012060
   Soares F, 2015, 30TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, VOLS I AND II, P1350, DOI 10.1145/2695664.2695724
   Soares MD, 2011, J SYST SOFTWARE, V84, P328, DOI 10.1016/j.jss.2010.10.020
   Steinberg D., 2008, EMF ECLIPSE MODELING
   Vaquero-Melchor D, 2017, 2017 ACM/IEEE 20TH INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS (MODELS 2017), P75, DOI 10.1109/MODELS.2017.13
   Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496
   Zolotas A, 2019, SOFTW SYST MODEL, V18, P345, DOI 10.1007/s10270-018-0658-5
NR 16
TC 2
Z9 2
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
BN 978-1-7281-5125-0
PY 2019
BP 478
EP 482
DI 10.1109/MODELS-C.2019.00076
PG 5
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BO6PT
UT WOS:000521634200065
DA 2022-08-02
ER

PT B
AU Andre, E
   Pelachaud, C
AF Andre, Elisabeth
   Pelachaud, Catherine
BE Chen, F
   Jokinen, K
TI Interacting with Embodied Conversational Agents
SO SPEECH TECHNOLOGY: THEORY AND APPLICATIONS
LA English
DT Article; Book Chapter
ID MODEL; DYNAMICS; BEHAVIOR
C1 [Andre, Elisabeth] Univ Augsburg, Augsburg, Germany.
   [Pelachaud, Catherine] Univ Paris 08, IUT Montreuil, LINC, F-93526 St Denis 02, France.
RP Andre, E (corresponding author), Univ Augsburg, Augsburg, Germany.
EM andre@informatik.uni-augsburg.de;
   catherina.pelachaud@telecom-paristech.fr
RI Andre, Elisabeth/AAW-4960-2021
CR ALBRECHT I, 2005, VIRTUAL REALITY SPEC, V8
   Andre E, 2005, TEXT SPEECH LANG TEC, V27, P143
   Andre E, 1999, APPL ARTIF INTELL, V13, P415, DOI 10.1080/088395199117333
   Andre E, 2000, EMBODIED CONVERSATIONAL AGENTS, P220
   Andre Elisabeth, 2005, P 4 INT JOINT C AUT, DOI DOI 10.1145/1082473.1082615
   [Anonymous], 2003, AAMAS 03, P725
   [Anonymous], 2003, P SIGCHI C HUM FACT, DOI [10.1145/642611.642662, DOI 10.1145/642611.642662]
   [Anonymous], 1988, COGNITIVE STRUCTURE, DOI DOI 10.1017/CBO9780511571299
   Bales R.F., 1951, INTERACTION PROCESS
   Ball G, 2000, EMBODIED CONVERSATIONAL AGENTS, P189
   BARONCOHEN S, 1994, CAH PSYCHOL COGN, V13, P513
   BATLINER A, 2005, VERBMOBIL FDN SPEECH, P122
   Bickmore T, 2005, ADV NATURAL MULTIMOD
   Brown Penelope, 1987, POLITENESS SOME UNIV
   BRUDERLIN A, 1995, P 22 ANN C COMP GRAP, P97, DOI DOI 10.1145/218380.218421
   BUI TD, 2004, THESIS U TWENTE ENSC
   Buisine S, 2004, HUM COM INT, V7, P217
   BUISINE S, 2006, 6 INT C INT VIRT AG
   Cassell J, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P106
   CASSELL J, 2006, SISTINE GAP HIST PHI
   CASSELL J, 2001, BEAT BEHAV EXPRESSIO, P477
   Cassell J., 1999, EMBODIMENT CONVERSAT, P520
   CAVE C, 1996, P ICSLP 96 4 INT C S
   Chi D, 2000, COMP GRAPH, P173
   CHOVIL N, 1991, J NONVERBAL BEHAV, V15, P141, DOI 10.1007/BF01672216
   Cowell AJ, 2003, LECT NOTES ARTIF INT, V2792, P301
   De Carolis B, 2004, COG TECH, P65
   de Rosis F, 2003, INT J HUM-COMPUT ST, V59, P81, DOI 10.1016/S1071-5819(03)00020-X
   DECAROLIS B, 2002, EMBODIED CONVERSATIO
   EGGES A, 2005, V CROWDS 05 6A1S SWI, P31
   Ekman P., 1975, UNMASKING FACE GUIDE
   EKMAN P, 2003, FACE REVEALED
   GALLAHER PE, 1992, J PERS SOC PSYCHOL, V63, P133, DOI 10.1037/0022-3514.63.1.133
   GUSTAFSON J, 1999, P EUR 99 BUD HUNG
   HARTMANN B, 2005, GEST WORKSH VANN
   HEYLEN D, 2005, AISB SOC PRES CUES S
   Isbister K., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P57
   Jan D, 2005, LECT NOTES ARTIF INT, V3661, P65
   Jenkins, 1971, PERCEPTION LANGUAGE, P150
   Johnson L., 2005, P 12 INT C ART INT E
   Johnson WL, 2004, LECT NOTES COMPUT SC, V3068, P254
   KAISER S, 2006, P 19 INT C COMP AN S
   KENDON A, 1974, NONVERBAL COMMUNICAT
   Khullar SC, 2001, AUTON AGENT MULTI-AG, V4, P9, DOI 10.1023/A:1010010528443
   KIPP M, 2005, THESIS BOCA RATON
   Knapp M.L., 1997, NONVERBAL COMMUNICAT, V4th ed
   Kopp S, 2005, LECT NOTES ARTIF INT, V3661, P329
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   Kopp S., 2003, KI, V17, P11
   Krahmer E, 2004, BROWS TRUST EVALUATI
   Laban R., 1974, EFFORT EC BODY MOVEM
   Larsson S., 2000, Natural Language Engineering, P323, DOI 10.1017/S1351324900002539
   Laurel B, 1993, COMPUTERS THEATRE
   Lee J, 2002, NEUROMOL MED, V2, P29
   Maatman RM, 2005, LECT NOTES ARTIF INT, V3661, P25
   Martin JC, 2005, LECT NOTES ARTIF INT, V3661, P405
   MARTIN JC, 2006, INT J HUMANOID ROBOT, V3
   McNeill D., 1992, HAND MIND WHAT GESTU
   Nakano YI, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P553
   Nass C, 2000, COMMUN ACM, V43, P36, DOI 10.1145/348941.348976
   Noma T, 2000, IEEE COMPUT GRAPH, V20, P79, DOI 10.1109/38.851755
   OCHS M, 2005, 1 INT C AFF COMP INT
   Paiva A, 2004, P 3 INT JOINT C AUT, P194
   Pandzic I.S., 2002, MPEG4 FACIAL ANIMATI
   Pelachaud C, 2003, LECT NOTES ARTIF INT, V2650, P300
   PELACHAUD C, 2005, BRAV NEW TOP SESS SI
   PELACHAUD C, 2002, AAMAS 02, P758
   Perlin K., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P205
   Peters C, 2005, LECT NOTES ARTIF INT, V3661, P215
   Ploog D., 1979, HUMAN ETHOLOGY CLAIM, P169, DOI DOI 10.1007/978-1-4020-2783-33
   Plutchnik R, 1980, EMOTION PSYCHOEVOLUT
   Poggi I., 2003, GESTURES MEANING USE
   Prada R, 2005, LECT NOTES ARTIF INT, V3661, P317
   PRENDINGER H, 2001, AGENTS 01, P270
   Pynadath DV, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1181
   Rehm M, 2005, LECT NOTES ARTIF INT, V3661, P241
   REHM M, 2006, ENG APPROACHES CONVE
   REHM M, 2005, LETS COME TOGETHER S, P124
   Rich C, 1998, USER MODEL USER-ADAP, V8, P315, DOI 10.1023/A:1008204020038
   Rickel J, 2002, LECT NOTES COMPUT SC, V2363, P542
   Rickel J, 1999, APPL ARTIF INTELL, V13, P343, DOI 10.1080/088395199117315
   Rist T., 2003, IUI 03. 2003 International Conference on Intelligent User Interfaces, P158, DOI 10.1145/604045.604071
   Ruttkay Z, 2003, COMPUT GRAPH FORUM, V22, P49, DOI 10.1111/1467-8659.t01-1-00645
   Ruttkay Z., 2004, BROWS TRUST EVALUATI
   Scherer K.R., 2000, INTRO SOCIAL PSYCHOL, V3rd ed., P151
   SCHLOSBERG H, 1952, J EXP PSYCHOL, V44, P229, DOI 10.1037/h0055778
   Sidner CL, 2005, ARTIF INTELL, V166, P140, DOI 10.1016/j.artint.2005.03.005
   Stocky T., 2002, IUI 02. 2002 International Conference on Intelligent User Interfaces, P224
   Stone M, 2004, ACM T GRAPHIC, V23, P506, DOI 10.1145/1015706.1015753
   Tanguy E, 2006, INT J HUM ROBOT, V3, P293, DOI 10.1142/S0219843606000758
   Traum D., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P766
   TSAPATSOULIS N, 2002, MPEG4 FACIAL ANIMATI
   Vinayagamoorthy V, 2004, COMPUT GRAPH FORUM, V23, P1, DOI 10.1111/j.1467-8659.2004.00001.x
   WAHLSTER W, 2003, SYMMETRIC MULTIMODAL, P1
   WALKER MA, 1997, 1 INT C AUT AG MAR D, P96
   WALLBOTT HG, 1986, J PERS SOC PSYCHOL, V51, P690, DOI 10.1037/0022-3514.51.4.690
   Wehrle T, 2000, J PERS SOC PSYCHOL, V78, P105, DOI 10.1037/0022-3514.78.1.105
   WEHRLE T, 1996, GENEVA APPRAIS UNPUB
   WEIZENBAUM J, 1967, COMMUN ACM, V10, P474, DOI 10.1145/363534.363545
   Whissel  C., 1989, MEASUREMENT EMOTIONS, V4
   [No title captured]
NR 102
TC 20
Z9 20
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA 233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES
BN 978-0-387-73818-5
PY 2010
BP 123
EP 149
DI 10.1007/978-0-387-73819-2_8
D2 10.1007/978-0-387-73819-2
PG 27
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Book Citation Index – Science (BKCI-S)
SC Computer Science; Engineering
GA BQC24
UT WOS:000280656100008
DA 2022-08-02
ER

PT J
AU Rampioni, M
   Stara, V
   Felici, E
   Rossi, L
   Paolini, S
AF Rampioni, Margherita
   Stara, Vera
   Felici, Elisa
   Rossi, Lorena
   Paolini, Susy
TI Embodied Conversational Agents for Patients With Dementia: Thematic
   Literature Analysis
SO JMIR MHEALTH AND UHEALTH
LA English
DT Review
DE dementia; patient with dementia; older adults with dementia; embodied
   conversational agent; virtual personal assistant; virtual agent; virtual
   companion; design for older adults; patients; elderly; virtual; personal
   assistant; cognitive; cognitive impairment
ID PERSON-CENTERED CARE; DECISION-MAKING; PEOPLE; TECHNOLOGY; INTERVENTIONS
AB Background: As the world's population rapidly ages, the number of older adults with cognitive impairment will also increase. Several studies have identified numerous complex needs of people with dementia, which assistive technologies still fail to support. Recent trends have led to an increasing focus on the use of embodied conversational agents (ECAs) as virtual entities able to interact with a person through natural and familiar verbal and nonverbal communication. The use of ECAs could improve the accessibility and acceptance of assistive technologies matching those high-level needs that are not well covered to date. Objective: The aim of this thematic literature analysis was to map current studies in the field of designing ECAs for patients with dementia in order to identify the existing research trend and possible gaps that need to be covered in the near future. The review questions in this study were as follows: (1) what research frameworks are used to study the interaction between patients with dementia and ECAs? (2) what are the findings? and (3) what are the barriers reported in these studies? Methods: Separate literature searches were conducted in PubMed, Web of Science, Scopus, and Embase databases by using specific umbrella phrases to target the population (patients with dementia) and the technology-based intervention (embodied conversational agent). Studies that met the inclusion criteria were appraised through the Mixed Methods Appraisal Tool and then discussed in a thematic analysis. Results: The search process identified 115 records from the databases and study references. After duplicates (n=45) were removed, 70 papers remained for the initial screening. A total of 7 studies were finally included in the qualitative synthesis. A thematic analysis of the reviewed studies identified major themes and subthemes: the research frameworks used to gather users' perspectives on ECAs (theme 1), the insights shared by the 7 studies as well as the value of user involvement in the development phases and the challenge of matching the system functionalities with the users' needs (theme 2), and the main methodological and technical problems faced by each study team (theme 3). Conclusions: Our thematic literature analysis shows that the field of ECAs is novel and poorly discussed in the scientific community and that more sophisticated study designs and proofs of efficacy of the approach are required. Therefore, by analyzing the main topic of the narrative review, this study underscores the challenge of synchronizing and harmonizing knowledge, efforts, and challenges in the dementia care field and its person-centered paradigm through the user-centered design approach. Enabling strict collaboration between interdisciplinary research networks, medical scientists, technology developers, patients, and their formal and informal caregivers is still a great challenge in the field of technologies for older adults.
C1 [Rampioni, Margherita; Stara, Vera; Felici, Elisa; Rossi, Lorena] IRCCS INRCA Natl Inst Hlth & Sci Aging, Model Care & New Technol, Via Santa Margherita 5, I-60124 Ancona, Italy.
   [Paolini, Susy] IRCCS INRCA Natl Inst Hlth & Sci Aging, Unit Neurol, Ancona, Italy.
RP Stara, V (corresponding author), IRCCS INRCA Natl Inst Hlth & Sci Aging, Model Care & New Technol, Via Santa Margherita 5, I-60124 Ancona, Italy.
EM v.stara@inrca.it
RI Rampioni, Margherita/AHB-0175-2022; Stara, Vera/J-5954-2016; Felici,
   Elisa/K-8561-2016
OI Stara, Vera/0000-0001-7536-7606; Paolini, Susy/0000-0003-3364-7102;
   Rampioni, Margherita/0000-0001-9235-9923; Rossi,
   Lorena/0000-0002-5688-105X; Felici, Elisa/0000-0002-1665-9155
FU EU Active and Assisted Living Program [AAL-call-2016-102]; Italian
   Ministry of Health
FX This study is cofunded by the EU Active and Assisted Living Program
   (reference AAL-call-2016-102) and partially supported by Ricerca
   Corrente funding from the Italian Ministry of Health.
CR [Anonymous], 2020, ALZHEIMERS DEMENT, V16, P391, DOI 10.1002/alz.12068
   [Anonymous], 1982, COGNITION ENV FUNCTI
   [Anonymous], GLOBAL DEMENTIA OBSE
   [Anonymous], 2010, 9241210 ISO
   [Anonymous], 2016, WHO CLIN CONS HLTH A
   [Anonymous], DEM PUBL HLTH PRIOR
   [Anonymous], WORLD REPORT AGEING
   [Anonymous], 2018, MIXED METHOD APPRAIS
   Arrighi HM, 2013, INT PSYCHOGERIATR, V25, P929, DOI 10.1017/S1041610212002360
   Bickmore T, 2010, APPL ARTIF INTELL, V24, P648, DOI 10.1080/08839514.2010.492259
   Bickmore TW, 2013, J AM GERIATR SOC, V61, P1676, DOI 10.1111/jgs.12449
   Board M, 2012, DEMENTIA CARE NURSIN
   Boger J, 2013, BMC GERIATR, V13, DOI 10.1186/1471-2318-13-63
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]
   Burmeister OK, 2016, ETHICS INF TECHNOL, V18, P185, DOI 10.1007/s10676-016-9404-2
   Cadieux MA, 2013, AM J ALZHEIMERS DIS, V28, P723, DOI 10.1177/1533317513500840
   Cahill S., 2007, TECHNOLOGY DISABILIT, V19, P133, DOI [10.3233/tad-2007-192-310, DOI 10.3233/TAD-2007-192-310]
   Carrasco E, 2008, LECT NOTES COMPUT SC, V5105, P38, DOI 10.1007/978-3-540-70540-6_5
   Carrillo MC, 2009, ALZHEIMERS DEMENT, V5, P479, DOI 10.1016/j.jalz.2009.09.003
   Chenoweth L, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212686
   Chittaro L, 2005, 2005 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P245, DOI 10.1109/CW.2005.86
   de Carvalho I. A, 2017, OPERATIONALISING CON, P31
   de Jong M, 2018, P 4 EAI INT C SMART
   Eklund K, 2009, HEALTH SOC CARE COMM, V17, P447, DOI 10.1111/j.1365-2524.2009.00844.x
   Evans J., 2015, HUMAN COMPUTER INTER, V9170, DOI [DOI 10.1007/978-3-319-20916-6_38, 10.1007/978-3-319-20916-6_38]
   Fagel S, 2013, P 6 INT C ADV COMP H, P184
   Fange AM, 2017, TRIALS, V18, DOI 10.1186/s13063-017-1796-8
   Fazio S, 2018, GERONTOLOGIST, V58, pS10, DOI 10.1093/geront/gnx122
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Holthe T, 2018, CLIN INTERV AGING, V13, P863, DOI 10.2147/CIA.S154717
   Huang H, 2012, P 11 INT C COGN INF, P22
   Irving P, 2015, GENERATIONS, V39, P72
   Kim SK, 2017, CLIN INTERV AGING, V12, P381, DOI 10.2147/CIA.S117637
   Kitwood T, 1997, AGING MENT HEALTH, V1, P13, DOI 10.1080/13607869757344
   Konig Alexandra, 2017, J Rehabil Assist Technol Eng, V4, p2055668316685038, DOI 10.1177/2055668316685038
   Koo BM, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/15122
   Kramer LL, 2020, J MED INTERNET RES, V22, DOI 10.2196/14058
   Livingston G, 2017, LANCET, V390, P2673, DOI 10.1016/S0140-6736(17)31363-6
   Lorenz K, 2019, DEMENTIA-LONDON, V18, P725, DOI 10.1177/1471301217691617
   Low LF, 2011, BMC HEALTH SERV RES, V11, DOI 10.1186/1472-6963-11-93
   Luria M, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P633, DOI 10.1145/3322276.3322340
   Maiden N, 2013, COMMUN ACM, V56, P60, DOI 10.1145/2500495
   Maslow AH, 1970, MOTIVATION PERSONALI
   Meiland Franka, 2017, JMIR Rehabil Assist Technol, V4, pe1, DOI 10.2196/rehab.6376
   Miller LM, 2016, DEMENTIA-LONDON, V15, P1141, DOI 10.1177/1471301214555542
   Milte R, 2016, ARCH GERONTOL GERIAT, V63, P9, DOI 10.1016/j.archger.2015.11.007
   Moher D, 2009, PHYS THER, V89, P873, DOI 10.1093/ptj/89.9.873
   Morandell MM, 2008, LECT NOTES COMPUT SC, V5298, P391, DOI 10.1007/978-3-540-89350-9_27
   Murray CJL, 2013, NEW ENGL J MED, V369, P448, DOI 10.1056/NEJMra1201534
   Norman DonaldA., 1998, DESIGN EVERYDAY THIN
   Ortiz A, 2006, P 9 ERCIM WORKSH US, P99
   Pfeifer Vardoulakis Laura, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P289, DOI 10.1007/978-3-642-33197-8_30
   Ploeg Jenny, 2018, JMIR Aging, V1, pe2, DOI 10.2196/aging.8475
   Pluye P, 2009, INT J NURS STUD, V46, P529, DOI 10.1016/j.ijnurstu.2009.01.009
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   REISBERG B, 1982, AM J PSYCHIAT, V139, P1136
   Ring L, 2013, INT CONF AFFECT, P61, DOI 10.1109/ACII.2013.17
   Shibusawa Sayumi, 2013, Cross-Cultural Design. Cultural Differences in Everyday Life. 5th International Conference, CCD 2013. Held as Part of HCI International 2013. Proceedings: LNCS 8024, P147, DOI 10.1007/978-3-642-39137-8_17
   Stara V, 2020, ADV INTELL SYST COMP, V957, P270, DOI 10.1007/978-3-030-20451-8_27
   Teipel S, 2016, ALZHEIMERS DEMENT, V12, P695, DOI 10.1016/j.jalz.2015.11.003
   Tsiourti C, 2016, P SAI INT SYST C INT, P196, DOI 10.1007/978-3-319-69266-1_10
   Vichitvanichphong S, 2014, P ANN HICSS, P2706, DOI 10.1109/HICSS.2014.341
   von Kutzleben M, 2012, AGING MENT HEALTH, V16, P378, DOI 10.1080/13607863.2011.614594
   Wang GB, 2019, MATURITAS, V127, P55, DOI 10.1016/j.maturitas.2019.06.003
   Wargnier P., 2018, TECHNOL DISABIL, V30, P105, DOI 10.3233/TAD-180189
   Wargnier P, 2015, 2015 3RD IEEE VR INTERNATIONAL WORKSHOP ON VIRTUAL AND AUGMENTED ASSISTIVE TECHNOLOGY (VAAT), P23, DOI 10.1109/VAAT.2015.7155406
   Whitlatch CJ, 2009, GENERATIONS, V33, P66
   Woo JA, 2019, CURR GERIATR REP, V8, P67, DOI 10.1007/s13670-019-0276-2
   Yaghoubzadeh Ramin, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P79, DOI 10.1007/978-3-642-40415-3_7
   Yasuda K, 2013, P 27 ANN C JAP SOC A
   Zancanaro Massimo, 2013, Your Virtual Butler. The Making-of: LNCS 7407, P70, DOI 10.1007/978-3-642-37346-6_7
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
   Zhang H, 2016, INT J INF TECHNOL
NR 73
TC 6
Z9 6
U1 7
U2 8
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 2291-5222
J9 JMIR MHEALTH UHEALTH
JI JMIR mHealth uHealth
PD JUL
PY 2021
VL 9
IS 7
AR e25381
DI 10.2196/25381
PG 15
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA UK8XQ
UT WOS:000692249000010
PM 34269686
OA gold, Green Published
DA 2022-08-02
ER

PT J
AU Darcy, A
   Robinson, A
   Wicks, P
AF Darcy, Alison
   Robinson, Athena
   Wicks, Paul
TI Conversational Agents in Health Care
SO JAMA-JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION
LA English
DT Letter
C1 [Darcy, Alison; Robinson, Athena; Wicks, Paul] Woebot Hlth, 650 Fifth St,Ste 303, San Francisco, CA 94107 USA.
RP Wicks, P (corresponding author), Woebot Hlth, 650 Fifth St,Ste 303, San Francisco, CA 94107 USA.
EM paul@wicksdigitalhealth.com
RI Wicks, Paul/C-6128-2011
OI Wicks, Paul/0000-0002-2293-9284
CR Chambers D, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2018-027743
   McGreevey JD, 2020, JAMA-J AM MED ASSOC, V324, P552, DOI 10.1001/jama.2020.2724
   Semigran HL, 2015, BMJ-BRIT MED J, V351, DOI 10.1136/bmj.h3480
   Whicher, 2019, AI HLTH CARE HOPE HY
NR 4
TC 2
Z9 2
U1 2
U2 5
PU AMER MEDICAL ASSOC
PI CHICAGO
PA 330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA
SN 0098-7484
EI 1538-3598
J9 JAMA-J AM MED ASSOC
JI JAMA-J. Am. Med. Assoc.
PD DEC 15
PY 2020
VL 324
IS 23
BP 2444
EP 2444
DI 10.1001/jama.2020.21509
PG 1
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA PG8IH
UT WOS:000599972000024
PM 33320217
DA 2022-08-02
ER

PT C
AU Brandao, C
   Reis, LP
   Rocha, AP
AF Brandao, Cesar
   Reis, Luis Paulo
   Rocha, Ana Paula
BE Rocha, A
   Reis, LP
   Cota, MP
   Painho, M
   Neto, MC
TI Evaluation of Embodied Conversational Agents
SO PROCEEDINGS OF THE 2013 8TH IBERIAN CONFERENCE ON INFORMATION SYSTEMS
   AND TECHNOLOGIES (CISTI 2013)
SE Iberian Conference on Information Systems and Technologies
LA English
DT Proceedings Paper
CT 8th Iberian Conference on Information Systems and Technologies (CISTI)
CY JUN 19-22, 2013
CL Lisboa, PORTUGAL
DE Artificial Inteligence; Turing Test; Embodied Conversational Agentes;
   Imitation Game
ID ELIZA
AB This paper proposes a platform which allows to evaluate the performance of an Embodied Conversational Agent and the influence of several distinct multimedia elements. Using the "Imitation Game" as described by Alan Turing as a starting point and motivation, the platform allows the configuration of several features which influence the Virtual environment. Through a series of user tests and surveys that are performed using the platform, it is possible to gather data that helps measure the efficiency of each feature.
C1 [Brandao, Cesar] Univ Porto, FEUP Fac Engn, Rua Campo Alegre 823, P-4100 Oporto, Portugal.
   [Reis, Luis Paulo] EEUM, DSI, Dep Sistemas Informacao, P-4719 Braga, Portugal.
   [Reis, Luis Paulo] Univ Porto, LIACC, Ciencia Computadores, Porto, Portugal.
   [Rocha, Ana Paula] Univ Porto, LIACC, Ciencia Computadores, Porto, Portugal.
   [Rocha, Ana Paula] Univ Porto, FEUP, DEI, Porto, Portugal.
RP Brandao, C (corresponding author), Univ Porto, FEUP Fac Engn, Rua Campo Alegre 823, P-4100 Oporto, Portugal.
EM mm08018@fe.up.pt; lpreis@dsi.uminho.pt; arocha@fe.up.pt
RI Reis, Luis Paulo/C-5751-2008
OI Reis, Luis Paulo/0000-0002-4709-1718; Rocha, Ana
   Paula/0000-0002-8129-9758
CR ABREU PH, 2012, PERFORMANCE ANAL SOC, V16, P47
   [Anonymous], 1990, COGNITIVE STRUCTURE
   Beun RJ, 2003, LECT NOTES ARTIF INT, V2792, P315
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   Cho Alvin K., 2007, EMOTIONAL DOMAIN CON
   Colby K., 1975, ARTIF INTELL, V2, P1
   Epstein Robert, 2008, PARSING TURING TEST
   Faria Brigida Monica, 2010, 2010 IEEE Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM 2010), P344, DOI 10.1109/ICCIS.2010.5518540
   FARIA BM, 2009, 4 C IB SIST TECN INF, P197
   Faria BM, 2012, ICAART: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 1, P171, DOI 10.5220/0003749701710179
   Fitrianie S, 2003, LECT NOTES ARTIF INT, V2807, P394
   Galvao AM, 2004, LECT NOTES ARTIF INT, V3315, P963
   Graesser A.C., 2003, P ART INT ED
   Graesser A.C, 2001, AUTOTUTOR INT J ARTI, V12, P257
   King William Joseph, 1996, P CHI
   Koda Tomoko, 1996, 5 IEEE INT WORKSH RO
   Kshirsagar S., 2002, P 2 INT S SMART GRAP
   Lester J.C., 1997, HUM FACT COMP SYST C
   Louwerse M., 2002, 2002 FALL S
   Moore R., 2002, EMILE USING CHATBOT
   Paul Ekman, 2005, WHAT FACE REVEALS BA
   Person N.K., 2001, AUTOTUTOR INT J ARTI, V12, P23
   Portela J, 2010, ICEIS 2010: PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS, VOL 2: ARTIFICIAL INTELLIGENCE AND DECISION SUPPORT SYSTEMS, P244
   Prize Loebner, LOEBNER PRIZE ARTIFI
   Schumaker RP, 2007, DECIS SUPPORT SYST, V43, P1419, DOI 10.1016/j.dss.2006.04.007
   Schumaker RP, 2006, INT J HUM-COMPUT ST, V64, P1132, DOI 10.1016/j.ijhcs.2006.06.008
   Shieber Stuart M., 1993, COMMUN ACM, V37, P70
   Takeuchi A., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P450
   Teofilo Luis F, 2011, P 6 IB C INF SYST TE
   Turing A.M., 1950, COMPUTING MACHINERY, P23
   Vrajitoru Dana, 2006, NPCS CHATTERBOTS PER, P142
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
NR 32
TC 0
Z9 0
U1 1
U2 7
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2166-0727
J9 IBER CONF INF SYST
PY 2013
PG 6
WC Computer Science, Information Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BB7LW
UT WOS:000345737600035
DA 2022-08-02
ER

PT C
AU Doumanis, I
   Smith, S
AF Doumanis, Ioannis
   Smith, Serengul
BE Botia, JA
   Charitos, D
TI An Empirical Study on the Effects of Embodied Conversational Agents on
   User Retention Performance and Perception in a Simulated Mobile
   Environment
SO WORKSHOP PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT
   ENVIRONMENTS
SE Ambient Intelligence and Smart Environments
LA English
DT Proceedings Paper
CT 9th International Conference on Intelligent Environments (IE)
CY JUL 16-19, 2013
CL Athens, GREECE
SP IEEE, IEEE Comp Soc, Natl Tech Univ Athens, Hellen Open Univ, Univ Thessaly, Univ Athens, IEEE Syst, Man & Cybernet Soc Tech Comm, Taylor & Francis Grp, IOS Press, EAI
DE Embodied conversational agents; human-centered computing; mobile tour
   guides; information systems
AB The paper presents a user study designed to examine the impact of the presence of a multimodal ECA on the user's ability to retain content of cultural value with variable degree of difficulty (i.e., technical and simple content). The study was conducted in the lab, using a high resolution panorama representing four locations in an archaeological attraction. The content participants perceived differed both in terms of complexity and length. Participants interacted with an ECA-based system and then with a non-ECA system that provided content about popular locations in the attraction. Results indicate that participants who used the system with the ECA retained content of variable difficulty more consistently, than those who used the system without the ECA. However, we also found that if text is added as an additional output modality to an ECA-based information system it can positively impact the perception of the technical content, which can potentially lead to enhanced retention of technical content.
C1 [Doumanis, Ioannis; Smith, Serengul] Middlesex Univ, London NW4 4BT, England.
RP Doumanis, I (corresponding author), Middlesex Univ, London NW4 4BT, England.
EM ioannis.doumanis@lsst.ac
CR Apple Inc, 2013, SIRI PERS ASS
   Baylor AL, 2008, LECT NOTES COMPUT SC, V5208, P208
   Hollan J., 2000, ACM Transactions on Computer-Human Interaction, V7, P174, DOI 10.1145/353485.353487
   Likert R., 1932, ARCH PSYCHOL, V22, P55
   Lim MY, 2007, LECT NOTES ARTIF INT, V4722, P317
   MacDorman K. F., 2010, IUPUI RES DAY APR 9
   MIKSATKO J, 2010, P 10 INT C INT VIRT, V6356, P475
   Nemetz F., 1998, PRINCIPLED MULTIMEDI
NR 8
TC 2
Z9 2
U1 0
U2 1
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1875-4163
BN 978-1-61499-286-8; 978-1-61499-285-1
J9 AMB INTELL SMART ENV
PY 2013
VL 17
BP 431
EP 442
DI 10.3233/978-1-61499-286-8-431
PG 12
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BD3WK
UT WOS:000360240400048
DA 2022-08-02
ER

PT C
AU Fast, E
   Chen, BB
   Mendelsohn, J
   Bassen, J
   Bernstein, MS
AF Fast, Ethan
   Chen, Binbin
   Mendelsohn, Julia
   Bassen, Jonathan
   Bernstein, Michael S.
GP ACM
TI Iris: A Conversational Agent for Complex Tasks
SO PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING
   SYSTEMS (CHI 2018)
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 21-26, 2018
CL Montreal, CANADA
SP Assoc Comp Machinery, ACM SIGCHI
DE conversational agents; data science
AB Today, most conversational agents are limited to simple tasks supported by standalone commands, such as getting directions or scheduling an appointment. To support more complex tasks, agents must be able to generalize from and combine the commands they already understand. This paper presents a new approach to designing conversational agents inspired by linguistic theory, where agents can execute complex requests interactively by combining commands through nested conversations. We demonstrate this approach in Iris, an agent that can perform open-ended data science tasks such as lexical analysis and predictive modeling. To power Iris, we have created a domain-specific language that transforms Python functions into combinable automata and regulates their combinations through a type system. Running a user study to examine the strengths and limitations of our approach, we find that data scientists completed a modeling task 2.6 times faster with Iris than with Jupyter Notebook.
C1 [Fast, Ethan; Chen, Binbin; Mendelsohn, Julia; Bassen, Jonathan; Bernstein, Michael S.] Stanford Univ, Stanford, CA 94305 USA.
RP Fast, E (corresponding author), Stanford Univ, Stanford, CA 94305 USA.
EM ethan.fast@cs.stanford.edu; bchen45@stanford.edu; jmendels@stanford.edu;
   jbassen@stanford.edu; msb@cs.stanford.edu
OI Bernstein, Michael/0000-0001-8020-9434
CR Adar E., 2014, P 27 ANN ACM S US IN
   Allen J., 2007, COLLABORATIVE TASK L
   Anderson E., 1936, ANN MISSOURI BOT GAR
   Berant J., 2013, EMNLP
   Bohus D., 2009, COMPUTER SPEECH LANG
   Cranshaw J., 2017, CHI
   Fast, 2016, EMNLP
   Fast E., 2016, P 29 ANN S US INT SO
   Fast E., 2014, P 32 ANN ACM C HUM F
   Fast E., 2016, P 2016 CHI C HUM FAC
   Fourney A., 2011, P 24 ANN ACM S US IN
   Gao T., 2015, P 28 ANN ACM S US IN
   Gee J., 2014, INTRO DISCOURSE ANAL, V4th ed
   Hartmann B., 2010, P SIGCHI C HUM FACT
   Hauswald Johann, 2015, P 20 INT C ARCH SUPP
   Hutchby Ian, 2008, CONVERSATION ANAL
   John Rogers Jeffrey Leo, 2017, CIDR
   Kandel S., 2011, P SIGCHI C HUM FACT
   Kandel S., 2012, IEEE T VISUALIZATION
   Kery Mary Beth, 2017, CHI
   Klemmer S.R., 2000, P 13 ANN ACM S US IN
   Laput G.P., 2013, P SIGCHI C HUM FACT
   Lasecki W., 2013, P 15 INT ACM SIGACCE
   Lasecki Walter S., 2013, P 26 ANN ACM S US IN
   Li Toby Jia-Jun, 2017, CHI 17
   Little G., 2007, P 22 IEEE ACM INT C
   Lupkowski Pawel., 2013, IWCS 2013 INT WORKSH
   Maes P., 1994, CACM
   Maloney J., 2010, T COMPUT ED
   Nass Clifford, 2005, WIRED SPEECH VOICE A
   Ng V., 2010, P 48 ANN M ASS COMP
   Patel K., 2010, P 23 ANN ACM S US IN
   Pennebaker JW, 2001, LINGUISTIC INQUIRY W
   Porcheron M., 2016, CHI
   Reinhart T., 1976, SYNTACTIC DOMAIN ANA
   Rong X., 2016, P 29 ANN S US INT SO
   Searle John R., 1969, SPEECH ACTS
   Serban I. V., 2015, ARXIV150704808
   Setlur V., 2016, P 29 ANN S US INT SO
   Suhm B., 2001, ACM T COMPUTER HUMAN
   Sun M., 2016, P 21 INT C INT US IN
   Talbot J., 2009, P SIGCHI C HUM FACT
   Wang S., 2016, CORR
   Weizenbaum J., 1966, COMMUNICATIONS ACM
   Winograd T., 1986, INTELLECT BOOKS
   Winograd T., 1987, HUMAN COMPUTER INTER
   Xu G., 2017, ALMOND ARCHITECTURE
   [No title captured]
NR 48
TC 25
Z9 25
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5620-6
PY 2018
DI 10.1145/3173574.3174047
PG 12
WC Computer Science, Cybernetics; Computer Science, Information Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BO2ZO
UT WOS:000509673105074
DA 2022-08-02
ER

PT J
AU Prakash, AV
   Das, S
AF Prakash, Ashish Viswanath
   Das, Saini
TI Intelligent Conversational Agents in Mental Healthcare Services: A
   Thematic Analysis of User Perceptions
SO PACIFIC ASIA JOURNAL OF THE ASSOCIATION FOR INFORMATION SYSTEMS
LA English
DT Article
DE Artificial Intelligence; Thematic Analysis; Mental Health Chatbots;
   Technology Adoption; Privacy Calculus; Anthropomorphism
ID INFORMATION-TECHNOLOGY; ARTIFICIAL-INTELLIGENCE; PRIVACY CALCULUS;
   UNIFIED THEORY; ADOPTION; ACCEPTANCE; TRUST; CHATBOT; WILLINGNESS;
   ASSISTANTS
AB Background: The emerging Artificial Intelligence (AI) based Conversational Agents (CA) capable of delivering evidence-based psychotherapy presents a unique opportunity to solve longstanding issues such as social stigma and demand-supply imbalance associated with traditional mental health care services. However, the emerging literature points to several socio-ethical challenges which may act as inhibitors to the adoption in the minds of the consumers. We also observe a paucity of research focusing on determinants of adoption and use of AI-based CAs in mental healthcare. In this setting, this study aims to understand the factors influencing the adoption and use of Intelligent CAs in mental healthcare by examining the perceptions of actual users.
   Method: The study followed a qualitative approach based on netnography and used a rigorous iterative thematic analysis of publicly available user reviews of popular mental health chatbots to develop a comprehensive framework of factors influencing the user's decision to adopt mental healthcare CA.
   Results: We developed a comprehensive thematic map comprising of four main themes, namely, perceived risk, perceived benefits, trust, and perceived anthropomorphism, along with its 12 constituent subthemes that provides a visualization of the factors that govern the user's adoption and use of mental healthcare CA.
   Conclusions: Insights from our research could guide future research on mental healthcare CA use behavior. Additionally, it could also aid designers in framing better design decisions that meet consumer expectations. Our research could also guide healthcare policymakers and regulators in integrating this technology into formal healthcare delivery systems.
C1 [Prakash, Ashish Viswanath; Das, Saini] Indian Inst Technol Kharagpur, Kharagpur, W Bengal, India.
RP Prakash, AV (corresponding author), Indian Inst Technol Kharagpur, Kharagpur, W Bengal, India.
EM ashish.viswanath@iitkgp.ac.in; saini@vgsom.iitkgp.ac.in
RI PRAKASH, ASHISH VISWANATH/J-3486-2014
OI PRAKASH, ASHISH VISWANATH/0000-0002-7468-9723
CR Abu Shawar BA and Atwell ES, 2007, J LANG TECHNOL COMPU, V22, P29
   Alalwan AA, 2017, INT J INFORM MANAGE, V37, P99, DOI 10.1016/j.ijinfomgt.2017.01.002
   Anand O, 2017, PAC ASIA J ASSOC INF, V9, P43
   Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Bakker D, 2016, JMIR MENT HEALTH, V3, DOI 10.2196/mental.4984
   Barak A, 2008, J TECHNOL HUMAN SERV, V26, P109, DOI 10.1080/15228830802094429
   Bartneck C, 2009, INT J SOC ROBOT, V1, P71, DOI 10.1007/s12369-008-0001-3
   Bendig E., 2019, VERHALTENSTHERAPIE, P1, DOI [10.1159/000501812, DOI 10.1159/000501812]
   Bhugra D, 2017, LANCET PSYCHIAT, V4, P775, DOI 10.1016/S2215-0366(17)30333-4
   Bird T, 2018, BEHAV COGN PSYCHOTH, V46, P570, DOI 10.1017/S1352465817000820
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]
   Brown P, 2009, J MENT HEALTH, V18, P449, DOI 10.3109/09638230903111122
   Buxman K, 1991, J Psychosoc Nurs Ment Health Serv, V29, P15
   CHUNG M, 2018, J BUSINESS RES
   Connolly SL, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/10748
   D'Alfonso S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00796
   Darcy A., 2017, WHY WE NEED MENTAL H
   Davidson J., 2008, RES TRUST HLTH, P45
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   DAVIS FD, 1992, J APPL SOC PSYCHOL, V22, P1111, DOI 10.1111/j.1559-1816.1992.tb00945.x
   De Choudhury M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2098, DOI 10.1145/2858036.2858207
   Dinev T., 2006, E SERV J, V4, P25, DOI DOI 10.2979/ESJ.2006.4.3.25
   Donkin L, 2013, J MED INTERNET RES, V15, P67, DOI 10.2196/jmir.2771
   Duarte P, 2019, J BUS RES, V102, P140, DOI 10.1016/j.jbusres.2019.05.022
   Elson J. S., 2018, P 51 HAW INT C SYST
   Epley N, 2008, SOC COGNITION, V26, P143, DOI 10.1521/soco.2008.26.2.143
   Epley N, 2007, PSYCHOL REV, V114, P864, DOI 10.1037/0033-295X.114.4.864
   Featherman MS, 2003, INT J HUM-COMPUT ST, V59, P451, DOI 10.1016/S1071-5819(03)00111-3
   Fereday J., 2006, INT J QUAL METH, V5, P80, DOI [10.1177/160940690600500107, DOI 10.1177/160940690600500107]
   Firth J, 2015, JMIR MHEALTH UHEALTH, V3, P36, DOI 10.2196/mhealth.4930
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Fulmer R, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/mental.9782
   Gaffney H, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/14166
   Gao YW, 2015, IND MANAGE DATA SYST, V115, P1704, DOI 10.1108/IMDS-03-2015-0087
   Gilbody S, 2015, BMJ-BRIT MED J, V351, DOI 10.1136/bmj.h5627
   Ginn Stephen, 2012, BMJ, V344, pe1302, DOI 10.1136/bmj.e1302
   Go E, 2019, COMPUT HUM BEHAV, V97, P304, DOI 10.1016/j.chb.2019.01.020
   Goulding C, 2000, ADV CONSUM RES, V27, P261
   Gulliver A, 2010, BMC PSYCHIATRY, V10, DOI 10.1186/1471-244X-10-113
   Gursoy D, 2019, INT J INFORM MANAGE, V49, P157, DOI 10.1016/j.ijinfomgt.2019.03.008
   Han S, 2018, IND MANAGE DATA SYST, V118, P618, DOI 10.1108/IMDS-05-2017-0214
   Hengstler M, 2016, TECHNOL FORECAST SOC, V105, P105, DOI 10.1016/j.techfore.2015.12.014
   Hill J, 2015, COMPUT HUM BEHAV, V49, P245, DOI 10.1016/j.chb.2015.02.026
   Ho CC, 2017, INT J SOC ROBOT, V9, P129, DOI 10.1007/s12369-016-0380-9
   Hollis C, 2018, LANCET PSYCHIAT, V5, P845, DOI 10.1016/S2215-0366(18)30296-7
   Hoque R, 2017, INT J MED INFORM, V101, P75, DOI 10.1016/j.ijmedinf.2017.02.002
   Hruschka D.J., 2004, FIELD METHOD, V16, P307, DOI [10.1177/1525822X04266540, DOI 10.1177/1525822X04266540]
   Huang Hsiao-Ying, 2017, JMIR Mhealth Uhealth, V5, pe83, DOI 10.2196/mhealth.6827
   Huang J, 2015, LECT NOTES COMPUT SC, V9085, P133, DOI 10.1007/978-3-319-19156-0_14
   Kari T, 2016, P 20 PAC AS C INF SY
   Kazdin AE, 2013, CLIN PSYCHOL SCI, V1, P170, DOI 10.1177/2167702612463566
   Kim D, 2019, COMPUT HUM BEHAV, V92, P273, DOI 10.1016/j.chb.2018.11.022
   Kozinets RV, 2002, J MARKETING RES, V39, P61, DOI 10.1509/jmkr.39.1.61.18935
   Kretzschmar K, 2019, BIOMED INFORM INSIGH, V11, DOI 10.1177/1178222619829083
   Lankton NK, 2015, J ASSOC INF SYST, V16, P880, DOI 10.17705/1jais.00411
   Li H, 2016, INT J MED INFORM, V88, P8, DOI 10.1016/j.ijmedinf.2015.12.010
   Li X, 2008, J STRATEGIC INF SYST, V17, P39, DOI 10.1016/j.jsis.2008.01.001
   Lipschitz J, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/11334
   Lozano R, 2012, LANCET, V380, P2095, DOI 10.1016/S0140-6736(12)61728-0
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   Luo X, 2010, DECIS SUPPORT SYST, V49, P222, DOI 10.1016/j.dss.2010.02.008
   MacDorman KF, 2017, COGNITION, V161, P132, DOI 10.1016/j.cognition.2017.01.009
   Madan K, 2018, ASIA PAC J MARKET LO, V30, P139, DOI 10.1108/APJML-02-2017-0023
   Martinez-Martin N, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/mental.9423
   Matt C, 2019, PAC ASIA J ASSOC INF, V11, P108, DOI 10.17705/1pais.11105
   McCarthy J, 2007, ARTIF INTELL, V171, P1174, DOI 10.1016/j.artint.2007.10.009
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   McKnight D.H., 2011, ACM T MANAG INFORM S, V2, DOI [10.1145/1985347.1985353, DOI 10.1145/1985347.1985353]
   Melian-Gonzalez S., 2019, CURRENT ISSUES TOURI, P1
   Merry Sally N, 2012, BMJ, V344, pe2598, DOI 10.1136/bmj.e2598
   Microsoft Corporation, 2018, FUT COMP ART INT ITS
   Miner AS, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00746
   Miner AS, 2017, JAMA-J AM MED ASSOC, V318, P1217, DOI 10.1001/jama.2017.14151
   Mohr DC, 2017, PSYCHIAT SERV, V68, P427, DOI 10.1176/appi.ps.201600541
   Molteni M., 2017, WIRED
   Moore GC, 1991, INFORM SYST RES, V2, P192, DOI 10.1287/isre.2.3.192
   Mora-Ripoll R, 2010, ALTERN THER HEALTH M, V16, P56
   Morris RR, 2018, J MED INTERNET RES, V20, DOI 10.2196/10148
   Nambisan P, 2011, J AM MED INFORM ASSN, V18, P298, DOI 10.1136/amiajnl-2010-000058
   Naslund JA, 2017, LANCET PSYCHIAT, V4, P486, DOI 10.1016/S2215-0366(17)30096-2
   Nienhuis JB, 2018, PSYCHOTHER RES, V28, P593, DOI 10.1080/10503307.2016.1204023
   Novak J.D., 2006, FLORIDA I HUMAN MACH
   Nowell LS, 2017, INT J QUAL METH, V16, DOI 10.1177/1609406917733847
   Paiva A, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2912150
   Payne EM, 2018, J RES INTERACT MARK, V12, P328, DOI 10.1108/JRIM-07-2018-0087
   Ravoniarison A, 2019, J RES INTERACT MARK, V13, P62, DOI 10.1108/JRIM-06-2016-0060
   Saffarizadeh K., 2017, P 2017 INT C INF SYS
   Saldana J., 2015, CODING MANUAL QUALIT
   Sarikaya R, 2017, IEEE SIGNAL PROC MAG, V34, P67, DOI 10.1109/MSP.2016.2617341
   Schroeder J, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P472
   Schueller SM, 2018, J MED INTERNET RES, V20, DOI 10.2196/10141
   Schuetzler RM, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P283
   Seeger A.-M., 2018, P 39 INT C INF SYST
   Sheehan B. T., 2018, THESIS
   Shenton A. K., 2004, ED INF, V22, P63, DOI DOI 10.3233/EFI-2004-22201
   Shum HY, 2018, FRONT INFORM TECH EL, V19, P10, DOI 10.1631/FITEE.1700826
   Siau K., 2018, CUTTER BUSINESS TECH, V31, P47
   Smith HJ, 2011, MIS QUART, V35, P989
   Sollner M, 2016, EUR J INFORM SYST, V25, P274, DOI 10.1057/ejis.2015.17
   Stawarz K, 2018, J MED INTERNET RES, V20, DOI 10.2196/10120
   Ta V, 2020, J MED INTERNET RES, V22, DOI 10.2196/16235
   Tarhini A, 2017, J INT EDUC BUS, V10, P164, DOI 10.1108/JIEB-09-2016-0032
   Tegmark M., 2017, LIFE 3 0 BEING HUMAN, DOI 10.1080/24701475.2019.1565556
   Torous J, 2014, JMIR MHEALTH UHEALTH, V2, DOI 10.2196/mhealth.2994
   Trivedi J, 2019, J INTERNET COMMER, V18, P91, DOI 10.1080/15332861.2019.1567188
   van Doorn J, 2017, J SERV RES-US, V20, P43, DOI 10.1177/1094670516679272
   Vasa R., 2012, P 24 AUSTR COMPUTER, P241, DOI [10.1145/2414536.2414577, DOI 10.1145/2414536.2414577]
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Venkatesh V, 2016, J ASSOC INF SYST, V17, P328, DOI 10.17705/1jais.00428
   Venkatesh V, 2012, MIS QUART, V36, P157
   Vigo D, 2016, LANCET PSYCHIAT, V3, P171, DOI 10.1016/S2215-0366(15)00505-2
   Wang WH, 2017, COMPUT HUM BEHAV, V68, P334, DOI 10.1016/j.chb.2016.11.022
   Wang YS, 2017, INTERNET RES, V27, P905, DOI 10.1108/IntR-04-2016-0111
   Waytz A, 2010, PERSPECT PSYCHOL SCI, V5, P219, DOI 10.1177/1745691610369336
   Weisbaum H, 2018, NBC NEWS
   Whiteford HA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116820
   WHO, 2018, MEMBER STATE PROFILE
   World Health Organization, 2017, DEPR OTH COMM MENT D
   Yang CC, 2010, PAC ASIA J ASSOC INF, V2, P73
   Yang ZL, 2004, INT J SERV IND MANAG, V15, P302, DOI 10.1108/09564230410540953
   Yuan SP, 2015, TELEMED E-HEALTH, V21, P735, DOI 10.1089/tmj.2014.0148
   Zaidan S, 2016, JMIR MHEALTH UHEALTH, V4, DOI 10.2196/mhealth.5406
   Zarouali B, 2018, CYBERPSYCH BEH SOC N, V21, P491, DOI 10.1089/cyber.2017.0518
NR 123
TC 15
Z9 15
U1 9
U2 50
PU ASSOC INFORMATION SYSTEMS
PI ATLANTA
PA GEORGIA STATE UNIV, 35 BROAD STREET, STE 916-917, ATLANTA, GA 30303 USA
SN 1943-7536
EI 1943-7544
J9 PAC ASIA J ASSOC INF
JI Pac. Asia J. Assoc. Inf. Syst.
PD JUN
PY 2020
VL 12
IS 2
BP 1
EP 34
DI 10.17705/1pais.12201
PG 34
WC Information Science & Library Science
WE Emerging Sources Citation Index (ESCI)
SC Information Science & Library Science
GA MH2HM
UT WOS:000546552800001
DA 2022-08-02
ER

PT C
AU Zubatiy, T
   Vickers, KL
   Mathur, N
   Mynatt, ED
AF Zubatiy, Tamara
   Vickers, Kayci L.
   Mathur, Niharika
   Mynatt, Elizabeth D.
GP ASSOC COMP MACHINERY
TI Empowering Dyads of Older Adults With Mild Cognitive Impairment And
   Their Care Partners Using Conversational Agents
SO CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN
   COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems
CY MAY 08-13, 2021
CL ELECTR NETWORK
SP ACM SIGCHI, Assoc Comp Machinery, Bloomberg, Facebook, Google, Kyocera, Microsoft, Monash Univ, Verizon Media
DE Audio/Video; Individuals with Disabilities & Assistive Technologies;
   Older Adults; Home; Health - Wellbeing; Ambient Devices / Internet of
   Things; Field Study; Smart Environments / Connected Home
ID ASSESSMENT MOCA
AB Conversational agents (CAs) such as Google Home or Alexa offer empowering opportunities for dyads composed of older adults with mild cognitive impairment (MCI) and their care partners. CAs support coordination and planning between the two, and can amplify the support that the care partner needs to provide. In this study, we observed how ten such dyads interacted with a Google Home over 10 weeks. We logged and analyzed 3,878 total interactions, interviewed the dyads to better understand their experiences, and also surveyed their individual preferences and priorities for automated assistance in the home. We found that CAs empowered both the people who had MCI, and their care partners. We observed that the utility of the CA in the day-to-day lives of users largely depended on how much the care partner scaffolded promising functionality, setting it up and contextualizing it for specific needs and desires.
C1 [Zubatiy, Tamara; Mathur, Niharika] Georgia Inst Technol, Sch Interact Comp, Atlanta, GA 30332 USA.
   [Vickers, Kayci L.] Emory Univ, Sch Med, Neurol, Atlanta, GA USA.
   [Mynatt, Elizabeth D.] Georgia Inst Technol, Inst People & Technol, Atlanta, GA 30332 USA.
RP Zubatiy, T (corresponding author), Georgia Inst Technol, Sch Interact Comp, Atlanta, GA 30332 USA.
EM tzubatiy3@gatech.edu; kayci.lynne.vickers@emory.edu;
   nmathur35@gatech.edu; mynatt@gatech.edu
FU Cox Enterprises
FX We would like to thank the members, care partners, and staff at the
   Cognitive Empowerment Program (CEP) for their support in bringing this
   study to life. We thank Jennifer DuBose for helping recruit research
   participants, and Matt Doiron for terrific tech support. Thank you to
   Brian Jones and Kunal Dhodapkar for beta testing, brainstorming and
   inspiration for the future directions of this work, and to Annie Anton
   for advising the privacy impact assessment described in this paper. The
   Cognitive Empowerment Program is made possible thanks to the generosity
   of the James M. Cox Foundation and support from Cox Enterprises.
CR Abdi N, 2019, PROCEEDINGS OF THE FIFTEENTH SYMPOSIUM ON USABLE PRIVACY AND SECURITY (SOUPS 2019), P451
   Abdolrahmani A, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P249, DOI 10.1145/3234695.3236344
   [Anonymous], 2000, BMC PUBLIC HEALTH, V14, P408, DOI [DOI 10.1186/1471-2458-11-647, 10.1186/1471-2458-14, DOI 10.1186/1471-2458-14]
   Baldauf M., 2018, P 20 INT C HUM COMP, P119, DOI [10.1145/3236112. 3236128, DOI 10.1145/3236112.3236128]
   Beneteau E, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376344
   Beneteau E, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300473
   Bentley Frank, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3264901
   Bradley J, 2020, RESEARCH MULTILING, V3, P1
   Bruce JM, 2008, DEMENT GERIATR COGN, V25, P385, DOI 10.1159/000122587
   Carroll C., 2017, P 2017 CHI C HUM FAC, P46, DOI [10.1145/3027063.3049266, DOI 10.1145/3027063.3049266]
   Carroll John, 2020, TALK TALK HUMAN CONV
   Carson N, 2018, INT J GERIATR PSYCH, V33, P379, DOI 10.1002/gps.4756
   Clarke Roger, 2009, Computer Law and Security Report, V25, P123, DOI 10.1016/j.clsr.2009.02.002
   Cuadra Andrea, 2020, USING INTELLIGENT VO
   Czaja S. J., 2016, DESIGNING TRAINING I
   de Oliveira Luis Carlos Rubino, 2015, ENVIROINFO ICT SUSTA
   Fisk Arthur D., 2018, DESIGNING OLDER ADUL, DOI [DOI 10.1201/9781420080681, 10.1201/9781420080681]
   Ford M, 2019, PERS UBIQUIT COMPUT, V23, P67, DOI 10.1007/s00779-018-1174-x
   Gauthier S, 2006, LANCET, V367, P1262, DOI 10.1016/S0140-6736(06)68542-5
   Goldstein FC, 2014, J GERIATR PSYCH NEUR, V27, P199, DOI 10.1177/0891988714524630
   Hutchinson Hilary, 2003, P SIGCHI C HUM FACT, P17, DOI [10.1145/642611.642616, DOI 10.1145/642611.642616]
   Johnson Janet, 2020, VOICE BASED CONVERSA
   Johnson RA, 2015, INT PSYCHOGERIATR, V27, P1635, DOI 10.1017/S1041610215000848
   Kientz J. A., 2008, CHI 08 HUM FACT COMP, P3675, DOI DOI 10.1145/1358628.1358911
   Kim SYH, 2011, NAT REV NEUROL, V7, P410, DOI 10.1038/nrneurol.2011.76
   Lau Josephine, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274371
   MacLeod A, 2016, INTERNATIONAL POLITICS AND THE NORTHERN IRELAND CONFLICT: THE USA, DIPLOMACY AND THE TROUBLES, P10
   Malek-Ahmadi M, 2015, AGING NEUROPSYCHOL C, V22, P755, DOI 10.1080/13825585.2015.1041449
   Milani Sadaf Arefi, 2018, Alzheimers Dement (Amst), V10, P773, DOI 10.1016/j.dadm.2018.09.003
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Ortman JM, 2014, AGING NATION OLDER P
   Petersen RC, 2004, J INTERN MED, V256, P183, DOI 10.1111/j.1365-2796.2004.01388.x
   Porcheron M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174214
   Pradhan Alisha, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359316
   Pradhan A, 2018, PORTL INT CONF MANAG, DOI 10.1145/3173574.3174033
   Sayago S, 2019, PROCEEDINGS OF THE 1ST INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES (CUI 2019), DOI 10.1145/3342775.3342803
   Schneider H, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173818
   Smarr CA, 2014, INT J SOC ROBOT, V6, P229, DOI 10.1007/s12369-013-0220-0
   Voicebot.ai, 2019, VOICE ASSISTANT DEMO
   Zubatiy Tamara, 2020, EMPOWERING OLDER ADU
NR 40
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8096-6
PY 2021
DI 10.1145/3411764.3445124
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7AU
UT WOS:000758168001024
DA 2022-08-02
ER

PT J
AU Kramer, LL
   ter Stal, S
   Mulder, BC
   de Vet, E
   van Velsen, L
AF Kramer, Lean L.
   ter Stal, Silke
   Mulder, Bob C.
   de Vet, Emely
   van Velsen, Lex
TI Developing Embodied Conversational Agents for Coaching People in a
   Healthy Lifestyle: Scoping Review
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Review
DE embodied conversational agent; virtual agent; lifestyle; health
   behavior; eHealth; chatbots
ID EXERCISE COACH; INTERVENTION; REQUIREMENTS; TRIAL
AB Background: Embodied conversational agents (ECAs) are animated computer characters that simulate face-to-face counseling. Owing to their capacity to establish and maintain an empathic relationship, they are deemed to be a promising tool for starting and maintaining a healthy lifestyle.
   Objective: This review aimed to identify the current practices in designing and evaluating ECAs for coaching people in a healthy lifestyle and provide an overview of their efficacy (on behavioral, knowledge, and motivational parameters) and use (on usability, usage, and user satisfaction parameters).
   Methods: We used the Arksey and O'Malley framework to conduct a scoping review. PsycINFO, Medical Literature Analysis and Retrieval System Online, and Scopus were searched with a combination of terms related to ECA and lifestyle. Initially, 1789 unique studies were identified; 20 studies were included.
   Results: Most often, ECAs targeted physical activity (n=16) and had the appearance of a middle-aged African American woman (n=13). Multiple behavior change techniques (median=3) and theories or principles (median=3) were applied, but their interpretation and application were usually not reported. ECAs seemed to be designed for the end user rather than with the end user. Stakeholders were usually not involved. A total of 7 out of 15 studies reported better efficacy outcomes for the intervention group, and 5 out of 8 studies reported better use-related outcomes, as compared with the control group.
   Conclusions: ECAs are a promising tool for persuasive communication in the health domain This review provided valuable insights into the current developmental processes, and it recommends the use of human-centered, stakeholder-inclusive design approaches, along with reporting on the design activities in a systematic and comprehensive manner. The gaps in knowledge were identified on the working mechanisms of intervention components and the right timing and frequency of coaching.
C1 [Kramer, Lean L.; de Vet, Emely] Wageningen Univ & Res, Consumpt & Hlth Lifestyles, POB 8130, NL-6700 EW Wageningen, Netherlands.
   [Kramer, Lean L.; Mulder, Bob C.] Wageningen Univ & Res, Strateg Commun, Wageningen, Netherlands.
   [ter Stal, Silke; van Velsen, Lex] Roessingh Res & Dev, eHlth Cluster, Enschede, Netherlands.
   [ter Stal, Silke] Univ Twente, Fac Elect Engn Math & Comp Sci, Enschede, Netherlands.
RP Kramer, LL (corresponding author), Wageningen Univ & Res, Consumpt & Hlth Lifestyles, POB 8130, NL-6700 EW Wageningen, Netherlands.
EM lean.kramer@wur.nl
RI Mulder, Bob/ABD-5003-2020; van Velsen, Lex/AAS-4524-2020; Mulder,
   Bob/GLV-5738-2022; de Vet, Emely/B-4896-2014
OI Mulder, Bob/0000-0003-0357-1370; van Velsen, Lex/0000-0003-0599-8706;
   Mulder, Bob/0000-0003-0357-1370; ter Stal, Silke/0000-0001-9458-717X; de
   Vet, Emely/0000-0002-4452-2367; Kramer, Lean L/0000-0002-1409-2853
FU Netherlands Association for Health Research and Development (ZonMw):
   ZonMw Create Health program [40-44300-98-110]
FX This study is the first step in an overarching project (PACO) that aims
   to gain fundamental insights into the acceptance, working mechanisms,
   and persuasiveness of ECAs in the context of health behavior change.
   PACO is funded by The Netherlands Association for Health Research and
   Development (ZonMw): ZonMw Create Health program grant number
   40-44300-98-110.
CR Arksey H., 2005, INT J SOC RES METHOD, V8, P19, DOI [DOI 10.1080/1364557032000119616, 10.1080/1364557032000119616]
   Baylor AL, 2009, PHILOS T R SOC B, V364, P3559, DOI 10.1098/rstb.2009.0148
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore T, 2010, APPL ARTIF INTELL, V24, P648, DOI 10.1080/08839514.2010.492259
   Bickmore TW, 2013, J AM GERIATR SOC, V61, P1676, DOI 10.1111/jgs.12449
   Bickmore TW, 2013, PATIENT EDUC COUNS, V92, P142, DOI 10.1016/j.pec.2013.05.011
   Bickmore TW, 2010, J HEALTH COMMUN, V15, P197, DOI 10.1080/10810730.2010.499991
   Bickmore TW, 2005, INTERACT COMPUT, V17, P711, DOI 10.1016/j.intcom.2005.09.002
   Blanson Henkemans Olivier A, 2009, Technol Health Care, V17, P253, DOI 10.3233/THC-2009-0545
   Brandt CJ, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.9791
   Brinkman W.P., 2016, P WORKSH GRAPH ROB E P WORKSH GRAPH ROB E
   Collins LM, 2014, AM J PREV MED, V47, P498, DOI 10.1016/j.amepre.2014.06.021
   Ellis T, 2013, AM J PHYS MED REHAB, V92, P472, DOI 10.1097/PHM.0b013e31828cd466
   Friederichs S, 2014, J MED INTERNET RES, V16, DOI 10.2196/jmir.2974
   Friederichs SAH, 2015, HEALTH PROMOT INT, V30, P803, DOI 10.1093/heapro/dat069
   Gardiner P, 2013, AM J HEALTH PROMOT, V27, pES11, DOI 10.4278/ajhp.1200113-QUAN-18
   Gardiner PM, 2017, PATIENT EDUC COUNS, V100, P1720, DOI 10.1016/j.pec.2017.04.015
   Harte Richard, 2017, JMIR Hum Factors, V4, pe8, DOI 10.2196/humanfactors.5443
   Hudlicka E, 2013, PATIENT EDUC COUNS, V92, P160, DOI 10.1016/j.pec.2013.05.007
   Jack B, 2015, J AM BOARD FAM MED, V28, P441, DOI 10.3122/jabfm.2015.04.140327
   Johnson WL, 2016, INT J ARTIF INTELL E, V26, P25, DOI 10.1007/s40593-015-0065-9
   Kazemi DM, 2018, ADDICT RES THEORY, V26, P377, DOI 10.1080/16066359.2017.1420783
   King AC, 2017, CONTEMP CLIN TRIALS, V61, P115, DOI 10.1016/j.cct.2017.07.020
   King AC, 2013, J HEALTH COMMUN, V18, P1449, DOI 10.1080/10810730.2013.798374
   Klaassen R, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020402
   Klaassen R, 2013, J MULTIMODAL USER IN, V7, P247, DOI 10.1007/s12193-013-0125-0
   Kohl LF, 2013, J MED INTERNET RES, V15, P71, DOI 10.2196/jmir.2665
   Michie S, 2013, ANN BEHAV MED, V46, P81, DOI 10.1007/s12160-013-9486-6
   Mummah SA, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5927
   op den Akker HJA, 2016, INTEL SYST REF LIBR, V106, P121, DOI 10.1007/978-3-319-31053-4_8
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Ruttkay Z., 2006, BROWS TRUST EVALUATI, VVolume 7
   Sieverink Floor, 2017, JMIR Res Protoc, V6, pe156, DOI 10.2196/resprot.6452
   Sillice MA, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.7640
   van Gemert-Pijnen JEWC, 2011, J MED INTERNET RES, V13, DOI 10.2196/jmir.1672
   van Gemert-Pijnen L., 2018, EHEALTH RES THEORY D
   van Velsen L, 2015, HEALTH INFORM J, V21, P24, DOI 10.1177/1460458213496419
   Van Velsen L, 2013, JMIR RES PROTOC, V2, DOI 10.2196/resprot.2547
   Vos T, 2017, LANCET, V390, P1211, DOI 10.1016/S0140-6736(17)32154-2
   Watson A, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.1629
   World Health Organization, 2010, MED DEV MAN MISM OUT
NR 42
TC 29
Z9 30
U1 3
U2 15
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD FEB 5
PY 2020
VL 22
IS 2
AR e14058
DI 10.2196/14058
PG 11
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA KI2NM
UT WOS:000511186400001
PM 32022693
OA Green Published, Green Submitted, gold, Green Accepted
DA 2022-08-02
ER

PT C
AU Cerrato, L
   Ekeklint, S
AF Cerrato, L
   Ekeklint, S
BE Ruttkay, Z
   Pelachaud, C
TI Evaluating users' reactions to human-like interfaces - Prosodic and
   paralinguistic features as new measures of user satisfaction
SO FROM BROWS TO TRUST: EVALUATING EMBODIED CONVERSATIONAL AGENTS
SE Human-Computer Interaction Series
LA English
DT Proceedings Paper
CT Workshop on Embodied Conversational Agents held at the 2002 AAMAS
   Conference
CY MAR, 2003
CL Montreal, CANADA
DE conversational agents; evaluation; multimodal interface; non-verbal
   behaviour; communicative gestures; prosodic cues
AB An increasing number of dialogue systems are deployed to provide public services in our everyday lives. They are becoming more service-minded and several of them provide different channels for interaction. The rationale is to make automatic services available in new environments and more attractive to use. From a developer perspective, this affects the complexity of the requirements elicitation activity, as new combinations and variations in end-user interaction need to be considered. The aim of our investigation is to propose new, parameters and metrics to evaluate multimodal dialogue systems endowed with embodied conversational agents (ECAs). These new metrics focus on the users, rather than on the system. Our assumption is that the intentional use of prosodic variation and the production of communicative non-verbal behaviour by users can give an indication of their attitude towards the system and might also help to evaluate the users' overall experience of the interaction. To test our hypothesis we carried out analyses on different Swedish corpora of interactions between users and multimodal dialogue systems. We analysed the prosodic variation in the way the users ended their interactions with the system and we observed the production of non-verbal communicative expressions by users. Our study supports the idea that the observation of users' prosodic variation and production of communicative non-verbal behaviour during the interaction with dialogue systems could be used as an indication of whether or not the users are satisfied with the system performance.
EM loredana@speech.kth.se; sek@msi.vxu.se
CR Bell L., 1999, P EUR 99 BUD, P1143
   BELL L, 1999, P IDS 99 KLOST IRS G, P81
   BESKOW J, IN PRESS SPOKEN MULT
   BESKOW J, 2003, THESIS KTH STOCKHOLM
   CARLSON R, 1996, ACTA U CAROLINAE PHI, V1, P39
   Cave C, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P2175, DOI 10.1109/ICSLP.1996.607235
   Cerrato L., 2003, P AVSP, P251
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DAMASIO A, 1994, AR DESCARTES ERROR E
   DANIELI M, 1995, AAAI SPRING S EMP ME, P34
   EDLUND J, 2002, P ISCA WORKSH MULT M, P181
   FABRI M, 2000, P WORKSH EMB CONV AG
   GLASS JR, 1999, P 1999 IEEE ASRU WOR, P430
   Graf HP, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P396, DOI 10.1109/AFGR.2002.1004186
   GUSTAFSON J, 1999, P EUROSPEECH, P1151
   Gustafson J., 2000, P INT C SPOK LANG PR, P134
   HJALMARSSON A, 2002, THESIS KTH STOCKHOLM
   HOOK K, 2002, P WORKSH EMB CONV AG
   Kipp M, 2001, P 7 EUR C SPEECH COM
   Laban R., 1976, LANGUAGE MOVEMENT GU
   Lippmann RP, 1997, SPEECH COMMUN, V22, P1, DOI 10.1016/S0167-6393(97)00021-6
   Massaro D.W., 2000, P ISCA WORKSH SPEECH, P114
   MASSARO DW, 1998, WORKSH EMB CONV CHAR, P287
   McTear MF, 2002, ACM COMPUT SURV, V34, P90, DOI 10.1145/505282.505285
   MITCHELL J, 2000, P ISCA WORKSH SPEECH, P98
   MONTERO JM, 2002, IMPROVEMENTS SPEECH, V258, P246
   NASS C, 1996, UNPUB SOCIAL RESPONS
   NORDSTRAND M, 2003, P AVSP 03 S JORIOZ F, P233
   Pelachaud C, 1996, COGNITIVE SCI, V20, P1
   Picard R. W., 1997, AFFECTIVE COMPUTING
   POGGI I, 1999, P IWAI 99 SIEN IT, P182
   Sanders GA, 2000, EMBODIED CONVERSATIONAL AGENTS, P346
   SCHEGLOFF EA, 1977, SEMIOTICA, V8, P298
   SJOLANDER K, 2000, P ICSLP 2000 BEIJ CH, V4, P464
   Thorisson K. R., 1997, Proceedings of the First International Conference on Autonomous Agents, P536, DOI 10.1145/267658.267823
   WALKER MA, 2001, P HUM LANG TECHN C 0, P66
   [No title captured]
NR 37
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS
SN 1571-5035
EI 2524-4477
BN 1-4020-2729-X
J9 HUM-COMPUT INT-SPRIN
PY 2004
VL 7
BP 101
EP 124
PG 24
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BBP07
UT WOS:000226830500004
DA 2022-08-02
ER

PT J
AU Li, ZY
   Rau, PLP
AF Li, Ziyang
   Rau, Pei-Luen Patrick
TI Talking with an IoT-CA: Effects of the Use of Internet of Things
   Conversational Agents on Face-to-Face Conversations
SO INTERACTING WITH COMPUTERS
LA English
DT Article
DE natural language interfaces; intelligent agents; ubiquitous computing
ID LEISURE-ACTIVITY PATTERNS; MERE PRESENCE HYPOTHESIS;
   MARITAL-SATISFACTION; SELF-DISCLOSURE; COMMUNICATION TECHNOLOGY; MEDIA
   USE; CLOSENESS; CONNECT; PHONES; TIME
AB Internet of things conversational agents (IoT-CAs) are making human-computer interactions ubiquitous. In this study, we experimentally examined the effects of IoT-CA use on face-to-face conversations between close partners. A total of 136 participants (68 close relationship dyads) participated in the experiment. We prepared an IoT chat environment and provided chat topics for each dyad. The dyads were randomly assigned into one of two IoT-CA use pattern groups (joint use: two persons using an IoT-CA together; individual use: one person using an IoT-CA alone) and three interaction conditions (no IoT-CA use, conversation content-relevant IoT-CA use, conversation content-irrelevant IoT-CA use). The results showed that compared with no IoT-CA use, IoT-CA use did not have negative effects on conversation experiences but produced feelings of greater closeness to the IoT-CA in the partners. Furthermore, joint IoT-CA use in the content-relevant condition (IoT-CA made comments relevant to interpersonal interactions) helped increase interpersonal self-disclosure.
   RESEARCH HIGHLIGHTS
   Internet of things conversational agents (IoT-CAs) are becoming integral parts of our homes and daily routines.
   IoT-CA use does not have negative effects on face-to-face conversation experience.
   People might be accustomed to technological device use in face-to-face conversations.
   Information transparency brought by voice interface might decrease negative effects of technology use on interpersonal conversations.
C1 [Li, Ziyang] China Acad Ind Internet, Beijing 100102, Peoples R China.
   [Li, Ziyang; Rau, Pei-Luen Patrick] Tsinghua Univ, Dept Ind Engn, Beijing 100084, Peoples R China.
RP Rau, PLP (corresponding author), Tsinghua Univ, Dept Ind Engn, Beijing 100084, Peoples R China.
EM rpl@mail.tsinghua.edu.cn
FU National Natural Science Foundation of China [71942005]
FX National Natural Science Foundation of China (71942005).
CR Ahlstrom M, 2012, J LEISURE RES, V44, P1
   Allred RJ, 2017, COMMUN STUD, V68, P22, DOI 10.1080/10510974.2016.1241292
   Altman I., 1973, SOCIAL PENETRATION D
   Annis D. H, 2007, DYADIC DATA ANAL
   [Anonymous], 2011, ALONE TOGERTHER
   [Anonymous], 2014, INTERCOOPERATIVE COL, DOI DOI 10.1007/978-3-642-35016-01
   ARON A, 1992, J PERS SOC PSYCHOL, V63, P596, DOI 10.1037/0022-3514.63.4.596
   Avelar D., 2015, THESIS FRANKLIN MARS
   Baumann A., 2016, M EUR C INF SYST ECI
   BERSCHEID E, 1989, J PERS SOC PSYCHOL, V57, P792, DOI 10.1037/0022-3514.57.5.792
   Bickmore T, 2009, LECT NOTES ARTIF INT, V5773, P6
   Birnbaum GE, 2016, COMPUT HUM BEHAV, V63, P416, DOI 10.1016/j.chb.2016.05.064
   Borgia E, 2014, COMPUT COMMUN, V54, P1, DOI 10.1016/j.comcom.2014.09.008
   Campbell WK, 2000, J RES PERS, V34, P329, DOI 10.1006/jrpe.2000.2282
   Canalys Newsroom, 2019, CANALYS NEWSROOM
   Carbonell X, 2013, PRINCIPLES OF ADDICTION: COMPREHENSIVE ADDICTIVE BEHAVIORS AND DISORDERS, VOL 1, P901, DOI 10.1016/B978-0-12-398336-7.00091-7
   Conti M, 2012, PERVASIVE MOB COMPUT, V8, P2, DOI 10.1016/j.pmcj.2011.10.001
   Coyne SM, 2014, J ADOLESCENT RES, V29, P663, DOI 10.1177/0743558414538316
   Crowley JP, 2018, COMMUN STUD, V69, P283, DOI 10.1080/10510974.2018.1467941
   DAVIS MH, 1983, J PERS SOC PSYCHOL, V44, P113, DOI 10.1037/0022-3514.44.1.113
   Derlega V. J, 2013, COMMUNICATION INTIMA
   Devitt K, 2009, CHILD SOC, V23, P189, DOI 10.1111/j.1099-0860.2008.00166.x
   Finkel EJ, 2017, ANNU REV PSYCHOL, V68, P383, DOI 10.1146/annurev-psych-010416-044038
   Forgays DK, 2014, COMPUT HUM BEHAV, V31, P314, DOI 10.1016/j.chb.2013.10.053
   Gergen KJ, 2002, PERPETUAL CONTACT: MOBILE COMMUNICATION, PRIVATE TALK, PUBLIC PERFORMANCE, P227
   Gil D, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16071069
   Hassan QF, 2018, INTERNET OF THINGS A TO Z: TECHNOLOGIES AND APPLICATIONS, P1
   Hecht ML., 1978, HUM COMMUN RES, V4, P253, DOI DOI 10.1111/J.1468-2958.1978.TB00614.X
   HOLMAN TB, 1988, J MARRIAGE FAM, V50, P69, DOI 10.2307/352428
   Johnson HA, 2006, MARRIAGE FAM REV, V40, P69, DOI 10.1300/J002v40n01_05
   Kang SH, 2011, STUD HEALTH TECHNOL, V167, P143, DOI 10.3233/978-1-60750-766-6-143
   Karadag E, 2015, J BEHAV ADDICT, V4, P60, DOI 10.1556/2006.4.2015.005
   Li ZY, 2019, INTERACT COMPUT, V31, P13, DOI 10.1093/iwc/iwz002
   Li ZY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091887
   McDaniel BT, 2016, PSYCHOL POP MEDIA CU, V5, P85, DOI 10.1037/ppm0000065
   Misra S, 2016, ENVIRON BEHAV, V48, P275, DOI 10.1177/0013916514539755
   Moon Y, 2003, J CONSUM PSYCHOL, V13, P125, DOI 10.1207/153276603768344843
   Mumford Lewis, 2010, TECHNICS CIVILIZATIO
   Nass Clifford, 2005, WIRED SPEECH VOICE A
   Newman P, 2019, 3 4 US SMART SPEAKER
   Noda K, 2018, DISABIL REHABIL-ASSI, V13, P674, DOI 10.1080/17483107.2017.1369589
   ORTHNER D.K., 1991, BENEFITS LEISURE, P289
   ORTHNER DK, 1975, J MARRIAGE FAM, V37, P91, DOI 10.2307/351033
   Padilla-Walker LM, 2012, FAM RELAT, V61, P426, DOI 10.1111/j.1741-3729.2012.00710.x
   Pelikan HRM, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4921, DOI 10.1145/2858036.2858478
   Porcheron M, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P207, DOI 10.1145/2998181.2998298
   Porcheron M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174214
   Przybylski AK, 2013, J SOC PERS RELAT, V30, P237, DOI 10.1177/0265407512453827
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Roberts JA, 2016, COMPUT HUM BEHAV, V54, P134, DOI 10.1016/j.chb.2015.07.058
   Rosen C., 2004, NEW ATLANTIS, V6, P26
   Rossouw P. J., 2014, INT J NEUROPSYCHOTHE, V2, P44, DOI DOI 10.12744/IJNPT.2014.0044-0099
   Sedikides C., 1999, REPRESENT R SOC PSYC, V23, P1
   Sprecher S, 2016, COMPUT HUM BEHAV, V62, P423, DOI 10.1016/j.chb.2016.03.090
   Sprecher S, 2013, J SOC PERS RELAT, V30, P497, DOI 10.1177/0265407512459033
   Storch SL, 2019, MOB MEDIA COMMUN, V7, P248, DOI 10.1177/2050157918811369
   Turner P, 2013, COGN TECHNOL WORK, V15, P403, DOI 10.1007/s10111-012-0231-x
   Voicebot, 2019, US SMART SPEAK OWN R
NR 58
TC 0
Z9 0
U1 4
U2 4
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 0953-5438
EI 1873-7951
J9 INTERACT COMPUT
JI Interact. Comput.
PD MAY
PY 2021
VL 33
IS 3
BP 238
EP 249
DI 10.1093/iwc/iwab024
EA OCT 2021
PG 12
WC Computer Science, Cybernetics; Ergonomics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA XA6JH
UT WOS:000720750000002
OA Bronze
DA 2022-08-02
ER

PT J
AU Bickmore, TW
   Utami, D
   Matsuyama, R
   Paasche-Orlow, MK
AF Bickmore, Timothy W.
   Utami, Dina
   Matsuyama, Robin
   Paasche-Orlow, Michael K.
TI Improving Access to Online Health Information With Conversational
   Agents: A Randomized Controlled Experiment
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Article
DE embodied conversational agent; search user interface; information
   retrieval user interface; Web search; health literacy; relational agent;
   computer literacy; search engine; Internet
ID OF-LIFE; LITERACY; SEARCH; IMPACT; USABILITY; STYLE
AB Background: Conventional Web-based search engines may be unusable by individuals with low health literacy for finding health-related information, thus precluding their use by this population. Objective: We describe a conversational search engine interface designed to allow individuals with low health and computer literacy identify and learn about clinical trials on the Internet.
   Methods: A randomized trial involving 89 participants compared the conversational search engine interface (n=43) to the existing conventional keyword-and facet-based search engine interface ( n=46) for the National Cancer Institute Clinical Trials database. Each participant performed 2 tasks: finding a clinical trial for themselves and finding a trial that met prespecified criteria.
   Results: Results indicated that all participants were more satisfied with the conversational interface based on 7-point self-reported satisfaction ratings (task 1: mean 4.9, SD 1.8 vs mean 3.2, SD 1.8, P <.001; task 2: mean 4.8, SD 1.9 vs mean 3.2, SD 1.7, P<.001) compared to the conventional Web form-based interface. All participants also rated the trials they found as better meeting their search criteria, based on 7-point self-reported scales (task 1: mean 3.7, SD 1.6 vs mean 2.7, SD 1.8, P=.01; task 2: mean 4.8, SD 1.7 vs mean 3.4, SD 1.9, P<.01). Participants with low health literacy failed to find any trials that satisfied the prespecified criteria for task 2 using the conventional search engine interface, whereas 36% (5/14) were successful at this task using the conversational interface (P=.05).
   Conclusions: Conversational agents can be used to improve accessibility to Web-based searches in general and clinical trials in particular, and can help decrease recruitment bias against disadvantaged populations.
C1 [Bickmore, Timothy W.; Utami, Dina] Northeastern Univ, Coll Comp & Informat Sci, Boston, MA 02115 USA.
   [Matsuyama, Robin] Virginia Commonwealth Univ, Richmond, VA USA.
   [Paasche-Orlow, Michael K.] Boston Med Ctr, Boston, MA USA.
RP Bickmore, TW (corresponding author), Northeastern Univ, Coll Comp & Informat Sci, 360 Huntington Ave,910-177, Boston, MA 02115 USA.
EM bickmore@ccs.neu.edu
RI Paasche-Orlow, Michael/ABF-7919-2020
OI Paasche-Orlow, Michael/0000-0002-9276-7190
FU NIH National Cancer Institute [R01CA158219]; NATIONAL CANCER INSTITUTE
   [R01CA158219] Funding Source: NIH RePORTER
FX Thanks to Barbara Barry, Ramesh Manuvinakurike, Juan Fernandez, Lazlo
   Ring, and Maryam Aziz with their help developing the system. This work
   was funded by NIH National Cancer Institute grant R01CA158219.
CR Agree EM, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.3352
   Allam A, 2014, J MED INTERNET RES, V16, P237, DOI 10.2196/jmir.2642
   [Anonymous], 2014, BASICS QUALITATIVE R
   Atkinson NL, 2008, CONTEMP CLIN TRIALS, V29, P555, DOI 10.1016/j.cct.2008.01.007
   Aula A, 2005, 1 MONDAY, V10, P100
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T, 2009, LECT NOTES ARTIF INT, V5773, P425, DOI 10.1007/978-3-642-04380-2_46
   Bickmore TW, 2010, J HEALTH COMMUN, V15, P197, DOI 10.1080/10810730.2010.499991
   Bickmore TW, 2009, PATIENT EDUC COUNS, V75, P315, DOI 10.1016/j.pec.2009.02.007
   Bickmore TW, 2005, INTERACT COMPUT, V17, P711, DOI 10.1016/j.intcom.2005.09.002
   Bol N, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.4164
   Cassell J., 2000, EMBODIED CONVERSATIO
   Davis T C, 1993, Fam Med, V25, P391
   Diviani N, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.4018
   Fox S., 2013, TRACKING FOR HLTH
   Ghaddar SF, 2012, J SCHOOL HEALTH, V82, P28, DOI 10.1111/j.1746-1561.2011.00664.x
   Hearst M., 2009, SEARCH USER INTERFAC
   Institute of Medicine, 2004, HLTH LITERACY PRESCR
   Komlodi A, 2011, ANN S HUM COMP INT I
   Lincoln A, 2006, J GEN INTERN MED, V21, P818, DOI 10.1111/j.1525-1497.2006.00533.x
   Mackert M, 2009, TELEMED J E-HEALTH, V15, P672, DOI 10.1089/tmj.2009.0012
   Mancuso CA, 2006, J GEN INTERN MED, V21, P813, DOI 10.1111/j.1525-1497.2006.00528.x
   Meppelink CS, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.3979
   National Cancer Institute, HLTH INF NAT TRENDS
   National Cancer Institute, 2014, FIND NCI SUPP CLIN T
   Nurnberger, 2012, P S HUM COMP INT INF, P1, DOI [10.1145/2391224.2391225, DOI 10.1145/2391224.2391225]
   Paasche-Orlow MK, 2007, AM J HEALTH BEHAV, V31, pS19
   Paasche-Orlow MK, 2005, J GEN INTERN MED, V20, P175, DOI 10.1111/j.1525-1497.2005.40245.x
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Reiter E., 2000, BUILDING NATURAL LAN
   Sudore RL, 2006, J GEN INTERN MED, V21, P806, DOI 10.1111/j.1525-1497.2006.00539.x
   Lindau ST, 2006, J GEN INTERN MED, V21, P829, DOI 10.1111/j.1525-1497.2006.00534.x
   Utami D, 2014, J HEALTH COMMUN, V19, P190, DOI 10.1080/10810730.2014.938842
   van Dijk JAGM, 2006, POETICS, V34, P221, DOI 10.1016/j.poetic.2006.05.004
   Volandes AE, 2008, J PALLIAT MED, V11, P754, DOI 10.1089/jpm.2007.0224
   Wang C, 2015, GENET MED, V17, P822, DOI 10.1038/gim.2014.198
   Zhang X, 2012, P ANN S HUM COMP INT
NR 37
TC 59
Z9 60
U1 5
U2 21
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 59 WINNERS CIRCLE, TORONTO, ON M4L 3Y7, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD JAN
PY 2016
VL 18
IS 1
AR e1
DI 10.2196/jmir.5239
PG 12
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA DA7IP
UT WOS:000367978100026
PM 26728964
OA gold, Green Published
DA 2022-08-02
ER

PT J
AU Tegos, S
   Demetriadis, S
   Papadopoulos, PM
   Weinberger, A
AF Tegos, Stergios
   Demetriadis, Stavros
   Papadopoulos, Pantelis M.
   Weinberger, Armin
TI Conversational agents for academically productive talk: a comparison of
   directed and undirected agent interventions
SO INTERNATIONAL JOURNAL OF COMPUTER-SUPPORTED COLLABORATIVE LEARNING
LA English
DT Article
DE Conversational agent; Academically productive talk; Computer-supported
   collaborative learning; Peer dialogue
ID COLLABORATION; FRAMEWORK; DIALOGUE; SCRIPTS
AB Conversational agents that draw on the framework of academically productive talk (APT) have been lately shown to be effective in helping learners sustain productive forms of peer dialogue in diverse learning settings. Yet, literature suggests that more research is required on how learners respond to and benefit from such flexible agents in order to fine-tune the design of automated APT intervention modes and, thus, enhance agent pedagogical efficacy. Building on this line of research, this work explores the impact of a configurable APT agent that prompts peers to build on prior knowledge and logically connect their contributions to important domain concepts discussed in class. A total of 96 computer science students engaged in a dialogue-based activity in the context of a Human-Computer Interaction (HCI) university course. During the activity, students worked online in dyads to accomplish a learning task. The study compares three conditions: students who collaborated without any agent interference (control), students who received undirected agent interventions that addressed both peers in the dyad (U treatment), and students who received directed agent interventions addressing a particular learner instead of the dyad (D treatment). The results suggest that although both agent intervention methods can improve students' learning outcomes and dyad in-task performance, the directed one is more effective than the undirected one in enhancing individual domain knowledge acquisition and explicit reasoning. Furthermore, findings show that the positive effect of the agent on dyad performance is mediated by the frequency of students' contributions displaying explicit reasoning, while most students perceive agent involvement favorably.
C1 [Tegos, Stergios; Demetriadis, Stavros] Aristotle Univ Thessaloniki, Sch Informat, Thessaloniki, Greece.
   [Papadopoulos, Pantelis M.] Aarhus Univ, Ctr Teaching Dev & Digital Media, Aarhus, Denmark.
   [Weinberger, Armin] Univ Saarland, Dept Educ Technol, Saarbrucken, Germany.
RP Tegos, S (corresponding author), Aristotle Univ Thessaloniki, Sch Informat, Thessaloniki, Greece.
EM stegos@csd.auth.gr; sdemetri@csd.auth.gr; pmpapad@tdm.au.dk;
   a.weinberger@mx.uni-saarland.de
RI Demetriadis, Stavros/Z-3200-2019
OI Demetriadis, Stavros/0000-0002-1561-6372; Papadopoulos,
   Pantelis/0000-0002-1527-5483
CR Adamson D., 2013, SEE WORLD GRAIN SAND, V1, P10
   Adamson D., 2013, ART INT ED AIED 2013, P51
   Adamson D, 2014, INT J ARTIF INTELL E, V24, P92, DOI 10.1007/s40593-013-0012-6
   Asterhan CSC, 2016, EDUC PSYCHOL-US, V51, P164, DOI 10.1080/00461520.2016.1155458
   Boeije H, 2002, QUAL QUANT, V36, P391, DOI 10.1023/A:1020909529486
   Brandom Robert, 1998, MAKING IT EXPLICIT R
   Cafaro A, 2016, AAMAS'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P911
   Chi MTH, 2009, TOP COGN SCI, V1, P73, DOI 10.1111/j.1756-8765.2008.01005.x
   Dillenbourg P, 2007, J COMPUT ASSIST LEAR, V23, P1, DOI 10.1111/j.1365-2729.2007.00191.x
   DUNN OJ, 1964, TECHNOMETRICS, V6, P241, DOI 10.2307/1266041
   Dyke G, 2013, IEEE T LEARN TECHNOL, V6, P240, DOI 10.1109/TLT.2013.25
   Fischer F, 2007, COMPUT-SUPP COLLAB L, V6, P1, DOI 10.1007/978-0-387-36949-5
   Fischer F, 2013, EDUC PSYCHOL-US, V48, P56, DOI 10.1080/00461520.2012.748005
   Goodman BA, 2005, USER MODEL USER-ADAP, V15, P85, DOI 10.1007/s11257-004-5269-x
   Gulz A, 2011, CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND EFFECTIVE PRACTICES, P128, DOI 10.4018/978-1-60960-617-6.ch006
   Harrer A, 2006, USER MODEL USER-ADAP, V16, P175, DOI 10.1007/s11257-006-9007-4
   Hayes A.F., 2018, INTRO MEDIATION MODE, V2
   Hmelo-Silver C. E., 2013, PRODUCTIVE MULTIVOCA, P561
   Howley I., 2013, PRODUCTIVE MULTIVOCA, P477, DOI [10.1007/978-1-4614-8960-3_26, DOI 10.1007/978-1-4614-8960-3_26]
   Huitt W., 2011, ED PSYCHOL INTERACTI
   Kumar R, 2011, IEEE T LEARN TECHNOL, V4, P21, DOI 10.1109/TLT.2010.41
   Liu CC, 2008, COMPUT EDUC, V50, P627, DOI 10.1016/j.compedu.2006.07.002
   Ludvigsen S, 2010, INT ENCY ED, V5, P290, DOI DOI 10.1016/B978-0-08-044894-7.00493-0
   Magnisalis I, 2011, IEEE T LEARN TECHNOL, V4, P5, DOI 10.1109/TLT.2011.2
   Michaels S., 2010, ACCOUNTABLE TALK SOU
   Michaels S., 2013, SOCIALIZING INTELLIG
   Michaels S, 2008, STUD PHILOS EDUC, V27, P283, DOI 10.1007/s11217-007-9071-1
   Noroozi O, 2013, INT J COMP-SUPP COLL, V8, P189, DOI 10.1007/s11412-012-9162-z
   Oehl M., 2010, E COLLABORATIVE KNOW, P54
   Papadopoulos PM, 2013, J COMPUT ASSIST LEAR, V29, P383, DOI 10.1111/jcal.12014
   Preece J., 2015, INTERACTION DESIGN H
   Resnick L., 2010, INNOVATIONS ED PSYCH, P163
   Rus V, 2013, AI MAG, V34, P42, DOI 10.1609/aimag.v34i3.2485
   Sionti M., 2012, ED TECHNOLOGIES TEAC, P28
   Slavin R., 1992, INTERACTION COOPERAT, P145
   Sohmer R., 2009, TRANSFORMATION KNOWL, P105
   Stahl G., 2015, SOCIALIZING INTELLIG, P213
   Stahl G., 2011, THEORIES TEAM COGNIT
   Stahl G, 2014, INT J COMP-SUPP COLL, V9, P117, DOI 10.1007/s11412-014-9194-7
   Tegos S., ED TECHNOLO IN PRESS
   Tegos S, 2016, THESIS
   Tegos S, 2015, COMPUT EDUC, V87, P309, DOI 10.1016/j.compedu.2015.07.014
   Tegos S, 2014, IEEE INT CONF ADV LE, P72, DOI 10.1109/ICALT.2014.31
   Vogel F, 2017, EDUC PSYCHOL REV, V29, P477, DOI 10.1007/s10648-016-9361-7
   Webb NM, 2009, BRIT J EDUC PSYCHOL, V79, P1, DOI 10.1348/000709908X380772
   Weinberger A, 2006, COMPUT EDUC, V46, P71, DOI 10.1016/j.compedu.2005.04.003
   Weinberger A, 2007, LEARN INSTR, V17, P416, DOI 10.1016/j.learninstruc.2007.03.007
   Weinberger A, 2011, NORD J DIGIT LIT, V6, P189
   Wolf M. K., 2005, ACCOUNTABLE TALK REA
NR 49
TC 18
Z9 18
U1 2
U2 41
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1556-1607
EI 1556-1615
J9 INT J COMP-SUPP COLL
JI Int. J. Comp.-Support. Collab. Learn.
PD DEC
PY 2016
VL 11
IS 4
BP 417
EP 440
DI 10.1007/s11412-016-9246-2
PG 24
WC Education & Educational Research; Information Science & Library Science
WE Social Science Citation Index (SSCI)
SC Education & Educational Research; Information Science & Library Science
GA EE0KX
UT WOS:000389264900003
OA Green Submitted
DA 2022-08-02
ER

PT J
AU Beinema, T
   Op den Akker, H
   Hermens, HJ
   van Velsen, L
AF Beinema, Tessa
   Op den Akker, Harm
   Hermens, Hermie J.
   van Velsen, Lex
TI What to Discuss?-A Blueprint Topic Model for Health Coaching Dialogues
   With Conversational Agents
SO INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION
LA English
DT Article; Early Access
ID BEHAVIOR-CHANGE; WORKING ALLIANCE; VIRTUAL COACH; INTERVENTIONS;
   SYSTEMS; DESIGN; ENGAGEMENT; STRATEGIES; MOTIVATION; TAXONOMY
AB Conversational agents (CAs) are often included as virtual coaches in eHealth applications. Tailoring conversations with these coaches to the individual user can increase the effectiveness of the coaching. An improvement for this tailoring process could be to (automatically) tailor the conversation at the topic level. In this article, we describe the design and evaluation of a blueprint topic model for use in the implementation of such topic selection. First, we constructed a topic model by extracting actions from the literature that a CA as coach could perform. We divided these actions in groups and labeled them with topics. We included literature from the behavioral psychology, relational agents and persuasive technology domains. Second, we evaluated this topic model through an online closed card sort study with health coaching experts. The constructed topic model contains 30 topics and 115 actions. Overall, the sorting of actions into topics was validated by the 11 experts participating in the card sort. Cards with actions that were sorted incorrectly mostly missed an immediacy indicator in their description (e.g., the difference between "you could plan regular walks" as opposed to "let's plan a walk") and/or were based on behavior change techniques that were difficult to translate to a conversation. The blueprint topic model presented in this article is an important step towards more intelligent virtual coaches. Future research should focus on the implementation of automatic topic selection. Furthermore, tailoring of coaching dialogues with CAs in multiple steps could be further investigated, for example, from the technical or user interaction perspective.
C1 [Beinema, Tessa; Op den Akker, Harm; Hermens, Hermie J.; van Velsen, Lex] Roessingh Res & Dev, AeHlth Grp, Enschede, Netherlands.
   [Beinema, Tessa; Op den Akker, Harm; Hermens, Hermie J.; van Velsen, Lex] Univ Twente, Fac EEMCS, Biomed Signals & Syst Grp, Enschede, Netherlands.
   [Op den Akker, Harm] Innovat Sprint, Brussels, Belgium.
RP Beinema, T (corresponding author), Univ Twente, Fac EEMCS, Biomed Signals & Syst Grp, Enschede, Netherlands.
EM t.c.beinema@utwente.nl
RI Beinema, Tessa/AAH-8905-2021
OI Beinema, Tessa/0000-0003-3513-0641; Hermens, Hermie/0000-0002-3065-3876;
   van Velsen, Lex/0000-0003-0599-8706; op den Akker,
   Harm/0000-0001-6312-6063
FU European Union's Horizon 2020 research and innovation programme [769553]
FX This work was supported by the European Union's Horizon 2020 research
   and innovation programme under Grant Agreement #769553 (Council of
   Coaches).
CR Abdullah A, 2018, J EPIDEMIOL GLOB HEA, V8, P225, DOI 10.2991/j.jegh.2018.08.104
   Andersson Gerhard, 2009, Cognitive Behaviour Therapy, V38, P55, DOI 10.1080/16506070902916400
   Beinema T., 2021, IVA 21 P 21 ACM INT, P1724
   Beinema T, 2021, THESIS U TWENTE, DOI [10.3990/1.9789036552608, DOI 10.3990/1.9789036552608]
   Beinema T., OPEN RES EUROPE, V2, P115, DOI [10.12688/openreseurope.14279.1, DOI 10.12688/OPENRESEUROPE.14279.1]
   Beinema T, 2022, INTERNET INTERV, V27, DOI 10.1016/j.invent.2022.100502
   Beinema T, 2021, COMPUT HUM BEHAV, V121, DOI 10.1016/j.chb.2021.106787
   Benitez-Guijarro A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010108
   Beun Robbert Jan, 2016, Persuasive Technology. 11th International Conference, PERSUASIVE 2016. Proceedings: LNCS 9638, P276, DOI 10.1007/978-3-319-31510-2_24
   Beun R.J., 2014, COGNITIVE 2014 6 INT, P14
   Beun RJ, 2017, PERS UBIQUIT COMPUT, V21, P661, DOI 10.1007/s00779-017-1021-5
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T., 2008, P INT JOINT C AUT AG, V3, P1217
   Bickmore T., 2010, HLTH INFORMATICS PAT, P181
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore T, 2006, J BIOMED INFORM, V39, P556, DOI 10.1016/j.jbi.2005.12.004
   Bickmore T, 2018, HUM-COMPUT INT-SPRIN, P33, DOI 10.1007/978-3-319-95579-7_3
   Bickmore T, 2010, APPL ARTIF INTELL, V24, P648, DOI 10.1080/08839514.2010.492259
   Bickmore TW, 2013, J AM GERIATR SOC, V61, P1676, DOI 10.1111/jgs.12449
   Bickmore TW, 2013, PATIENT EDUC COUNS, V92, P142, DOI 10.1016/j.pec.2013.05.011
   Bickmore TW, 2011, J BIOMED INFORM, V44, P183, DOI 10.1016/j.jbi.2010.12.006
   Brinkman W.-P, 2016, P WORKSH GRAPH ROB E, P117
   Buimer Hendrik P, 2017, JMIR Rehabil Assist Technol, V4, pe12, DOI 10.2196/rehab.6294
   Callejas Z., 2014, INT WORKSH AMB ASS L, P5966
   Castonguay LG, 2006, PSYCHOTHERAPY, V43, P271, DOI 10.1037/0033-3204.43.3.271
   Chalaguine L.A., 2019, P INT C TOOLS ARTIFI
   de Vries R., 2016, P 2016 CHI C HUMAN F
   de Vries RAJ, 2017, PERS UBIQUIT COMPUT, V21, P675, DOI 10.1007/s00779-017-1025-1
   DeSmet A, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/15707
   Edwards EA, 2016, BMJ OPEN, V6, DOI 10.1136/bmjopen-2016-012447
   Fadhil A, 2019, METHOD INFORM MED, V58, P9, DOI 10.1055/s-0039-1688757
   Fan HY, 2006, J ORG COMP ELECT COM, V16, P179, DOI 10.1207/s15327744joce1603&4_2
   Fitrianie S, 2015, PROCEDIA COMPUT SCI, V63, P236, DOI 10.1016/j.procs.2015.08.339
   Fogg BJ., 2002, UBIQUITY, P89, DOI DOI 10.1145/764008.763957
   Folstad A., 2017, INTERACTIONS, V24, P38, DOI [10.1145/3085558, DOI 10.1145/3085558]
   Gardiner PM, 2017, PATIENT EDUC COUNS, V100, P1720, DOI 10.1016/j.pec.2017.04.015
   Glas N, 2018, INT J HUM-COMPUT ST, V120, P107, DOI 10.1016/j.ijhcs.2018.07.007
   Gross C, 2021, J MED INTERNET RES, V23, DOI 10.2196/26643
   Gupta I., 2018, P 2018 IEEE INT C HE
   HORVATH AO, 1989, J COUNS PSYCHOL, V36, P223, DOI 10.1037/0022-0167.36.2.223
   Hurmuz MZM, 2020, JMIR RES PROTOC, V9, DOI 10.2196/16641
   JANZ NK, 1984, HEALTH EDUC QUART, V11, P1, DOI 10.1177/109019818401100101
   Jofre N, 2018, COMM COM INF SC, V790, P122, DOI 10.1007/978-3-319-75214-3_12
   Kaptein M, 2012, ACM T INTERACT INTEL, V2, DOI 10.1145/2209310.2209313
   King AC, 2017, CONTEMP CLIN TRIALS, V61, P115, DOI 10.1016/j.cct.2017.07.020
   Klein M, 2013, IEEE PERVAS COMPUT, V12, P22, DOI 10.1109/MPRV.2013.41
   Kramer NC, 2010, LECT NOTES ARTIF INT, V6356, P468, DOI 10.1007/978-3-642-15892-6_50
   Kramer LL, 2020, J MED INTERNET RES, V22, DOI 10.2196/14058
   Krebs P, 2010, PREV MED, V51, P214, DOI 10.1016/j.ypmed.2010.06.004
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Locke EA, 2002, AM PSYCHOL, V57, P705, DOI 10.1037//0003-066X.57.9.705
   McTear M., 2016, CONVERSATIONAL INTER, P379
   Michie S, 2013, ANN BEHAV MED, V46, P81, DOI 10.1007/s12160-013-9486-6
   Miltenberger R., 2008, BEHAV MODIF
   Montenegro C, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3030052
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nijland N., 2011, THESIS U TWENTE
   Norman P., 2005, PREDICTING HLTH BEHA, P81
   Oinas-Kukkonen H, 2009, COMMUN ASSOC INF SYS, V24, P485
   Olafsson S, 2019, INT CONF PER COMP, P31, DOI 10.1145/3329189.3329202
   op den Akker HJA, 2016, INTEL SYST REF LIBR, V106, P121, DOI 10.1007/978-3-319-31053-4_8
   Op den Akker H, 2018, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES FOR AGEING WELL AND E-HEALTH (ICT4AWE), P219, DOI 10.5220/0006787702190226
   op den Akker H, 2014, USER MODEL USER-ADAP, V24, P351, DOI 10.1007/s11257-014-9146-y
   Perski O, 2017, TRANSL BEHAV MED, V7, DOI 10.1007/s13142-016-0453-1
   Proven By Users LLC, 2021, PROVEN USERS CARD SO
   Richards D, 2018, IEEE J BIOMED HEALTH, V22, P1699, DOI 10.1109/JBHI.2017.2782210
   Riou M, 2015, DISCOURS, DOI 10.4000/discours.8997
   Ruttkay Z., 2008, IVA 08 P 8 INT C INT, DOI [10.1007/978-3-540-85483-8_41, DOI 10.1007/978-3-540-85483-8_41]
   Ryan K, 2019, DIGIT HEALTH, V5, DOI 10.1177/2055207619826685
   Schulman D., 2009, P 4 INT C PERS TECHN, V350
   Schwarzer R, 2011, REHABIL PSYCHOL, V56, P161, DOI 10.1037/a0024509
   Sebastian J, 2017, COMPUT HUM BEHAV, V73, P479, DOI 10.1016/j.chb.2017.03.071
   Smith C, 2011, PRESENCE-VIRTUAL AUG, V20, P395, DOI 10.1162/PRES_a_00063
   Snaith M., 2018, DIALOGUE GAME MULTIP, V305
   Snaith M., 2020, MODULAR PLATFORM ARG
   Starr J., 2008, COACHING MANUAL DEFI
   ter Stal S, 2020, JMIR HUM FACTORS, V7, DOI 10.2196/19987
   Uribe J., 2011, 2011 IEEE 13 INT C E, P1520
   van Velsen L, 2020, JMIR RES PROTOC, V9, DOI 10.2196/19344
   van Velsen L, 2019, J MED INTERNET RES, V21, DOI 10.2196/11759
   Wangberg Silje C, 2008, Patient Prefer Adherence, V2, P57
   Watson A, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.1629
   Yasavur U., 2013, LECT NOTES COMPUTER, V8108, P92105
   Zhang Z., 2018, P 18 INT C INTELLIGE, P113118
NR 84
TC 0
Z9 0
U1 0
U2 0
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 1044-7318
EI 1532-7590
J9 INT J HUM-COMPUT INT
JI Int. J. Hum.-Comput. Interact.
DI 10.1080/10447318.2022.2041884
EA MAY 2022
PG 19
WC Computer Science, Cybernetics; Ergonomics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 1B9EM
UT WOS:000792733600001
OA hybrid
DA 2022-08-02
ER

PT C
AU Kopp, S
   Stocksmeier, T
   Gibbon, D
AF Kopp, Stefan
   Stocksmeier, Thorsten
   Gibbon, Dafydd
BE Pelachaud, C
   Martin, JC
   Andre, E
   Chollet, G
   Karpouzis, K
   Pele, D
TI Incremental multimodal feedback for conversational agents
SO INTELLIGENT VIRTUAL AGENTS, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 7th International Conference on Intelligent Virtual Agents
CY SEP 17-19, 2007
CL Paris, FRANCE
SP &ftgroup France Telecom, European Project IST FP6 Callas, Springer, Assoc Advancement Artificial Intelligence, Eurograph, FP6 IST Humaine Network Excellence, ACM SIGCHI, ACM SIGART, Univ Paris 8, LIMSI-CNRS, Univ Augsburg, ENST, Natl Tech Univ Athens, France Telecom
AB Just like humans, conversational computer systems should not listen silently to their input and then respond. Instead, they should enforce the speaker-listener link by attending actively and giving feedback on an utterance while perceiving it. Most existing systems produce direct feedback responses to decisive (e.g. prosodic) cues. We present a framework that conceives of feedback as a more complex system, resulting from the interplay of conventionalized responses to eliciting speaker events and the multimodal behavior that signals how internal states of the listener evolve. A model for producing such incremental feedback, based on multi-layered processes for perceiving, understanding, and evaluating input, is described.
C1 [Kopp, Stefan; Stocksmeier, Thorsten; Gibbon, Dafydd] Univ Bielefeld, Fac Linguist & Literature, Fac Technol, Artificial Intelligence Grp, D-33594 Bielefeld, Germany.
RP Kopp, S (corresponding author), Univ Bielefeld, Fac Linguist & Literature, Fac Technol, Artificial Intelligence Grp, D-33594 Bielefeld, Germany.
EM skopp@techfak.uni-bielefeld.de; tstocksm@techfak.uni-bielefeld.de;
   gibbon@uni-bielefeld.de
RI Gibbon, Dafydd/O-7404-2016
OI Gibbon, Dafydd/0000-0002-9825-5516
CR Allwood J., 1992, Journal of Semantics, V9, P1, DOI 10.1093/jos/9.1.1
   ALLWOOD J, 2003, 1 NORD S MULT COMM C, P7
   Cassell J., 1999, P SIGCHI C HUM FACT, P520, DOI DOI 10.1145/302979.303150
   Cathcart N, 2003, EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P51
   CLARK HH, 1989, COGNITIVE SCI, V13, P259, DOI 10.1016/0364-0213(89)90008-6
   FUJIE S, 2004, P INT C AUT ROB AG
   Graesser AC, 2004, BEHAV RES METH INS C, V36, P180, DOI 10.3758/BF03195563
   Gratch J, 2006, LECT NOTES ARTIF INT, V4133, P14
   Kopp S, 2005, LECT NOTES ARTIF INT, V3661, P329
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   KOPP S, MODELING COMMUNICATI
   SCHMID H, 1995, IMPROVEMENT PART SPE
   STOCKSMEIER T, 2007, P INTERSPEECH 2007
   TAKEUCHI M, 2004, P INT C SPEECH PROS, P529
   Thorisson K.R, 1996, SCH ARCHITECTURE PLA
   WARD N, 2000, PROSODIC FEATURES CU
   Yngve VH., 1970, 6 REG M CHIC LING SO, P567
NR 17
TC 14
Z9 14
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-540-74996-7
J9 LECT NOTES ARTIF INT
PY 2007
VL 4722
BP 139
EP +
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BGR56
UT WOS:000250108100013
DA 2022-08-02
ER

PT B
AU PerezMarin, D
   PascualNieto, I
AF PerezMarin, D
   PascualNieto, I
TI Conversational Agents and Natural Language Interaction: Techniques and
   Effective Practices
SO CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND
   EFFECTIVE PRACTICES
LA English
DT Book
RI Pérez-Marín, Diana/ABF-6641-2021
OI Pérez-Marín, Diana/0000-0003-3390-0251
NR 0
TC 27
Z9 28
U1 0
U2 0
PU IGI GLOBAL
PI HERSEY
PA 701 E CHOCOLATE AVE, STE 200, HERSEY, PA 17033-1240 USA
BN 978-1-60960-618-3
PY 2011
BP 1
EP 456
DI 10.4018/978-1-60960-617-6
PG 476
WC Computer Science, Artificial Intelligence
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BZX29
UT WOS:000303201400020
DA 2022-08-02
ER

PT J
AU Nelekar, S
   Abdulrahman, A
   Gupta, M
   Richards, D
AF Nelekar, Shreeya
   Abdulrahman, Amal
   Gupta, Manik
   Richards, Deborah
TI Effectiveness of embodied conversational agents for managing academic
   stress at an Indian University (ARU) during COVID-19
SO BRITISH JOURNAL OF EDUCATIONAL TECHNOLOGY
LA English
DT Article
DE artificial intelligence; behavior change; embodied conversational
   agents; human-machine interface; learner attitudes/perceptions; stress
   management; undergraduate education; virtual assistant
ID WORKING ALLIANCE; SCHOOL STUDENTS; PERFORMANCE; PEOPLE
AB Stress has become one of the major reasons for many mental health related issues among students of all age groups, which has resulted in devastating personal losses including suicide. Societal and familial pressure to succeed is high, particularly in developing countries where education is highly valued as a key enabler. As part of stress management during the COVID-19 pandemic, demand for online intelligent virtual advisors has risen and, consequently, the need for personalised explanation that is culturally sensitive to the user's context is essential to improve the user's understanding of and trust in the recommendations provided by the virtual advisor. This paper presents the mAnaging stRess at University embodied conversational agent (ECA) that has been adapted for Indian university students from an explainable agent that was found to help Western students reduce their stress by providing study tips with explanations based on the student's beliefs and/or goals. We conducted a research study with sixty students which measured the impact of providing three different patterns of tailored explanations (belief-based, goal-based, and belief and goal-based explanation) on the students' intentions to change the recommended behaviours and the relationship built with the ECA. The experimental results indicate that there was stress reduction across all student groups provided with different types of explanations. Further, the students showed trust and a good working alliance with the conversational agent, along with an intention to change behaviour across all types of explanations. However, it was observed that the user context played an important role in behaviour change intention and hence explanations could be tailored further, making them culturally more relevant to Indian students.
C1 [Nelekar, Shreeya; Gupta, Manik] BITS Pilani, Dept Comp Sci & Informat Syst, Hyderabad Campus, Hyderabad 500078, Telangana, India.
   [Abdulrahman, Amal; Richards, Deborah] Macquarie Univ, Dept Comp, Sydney, NSW, Australia.
RP Gupta, M (corresponding author), BITS Pilani, Dept Comp Sci & Informat Syst, Hyderabad Campus, Hyderabad 500078, Telangana, India.
EM manik@hyderabad.bits-pilani.ac.in
OI Richards, Deborah/0000-0002-7363-1511; Abdulrahman,
   Amal/0000-0001-5360-0833; GUPTA, MANIK/0000-0002-4977-4299
FU International Macquarie University Research Training Program (iMQRTP)
   scholarship
FX International Macquarie University Research Training Program (iMQRTP)
   scholarship
CR Abdulrahman A.., 2021, P 20 INT C AUT AG MU, P68
   Abdulrahman A, 2021, J MULTIMODAL USER IN, V15, P189, DOI 10.1007/s12193-020-00359-3
   Abdulrahman A, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P247, DOI 10.1145/3308532.3329413
   Almalki Manal, 2020, Acta Inform Med, V28, P241, DOI 10.5455/aim.2020.28.241-247
   Anjomshoae S, 2019, AAMAS '19: PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P1078
   Bennett JK, 2011, PATIENT EDUC COUNS, V85, P53, DOI 10.1016/j.pec.2010.08.005
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bratman Michael, 1987, INTENTION PLANS PRAC
   Broekens J, 2010, LECT NOTES ARTIF INT, V6251, P28, DOI 10.1007/978-3-642-16178-0_5
   Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158
   Chen JY, 2020, J MED INTERNET RES, V22, DOI 10.2196/21476
   Core M, 2006, SIMUL-T SOC MOD SIM, V82, P685, DOI 10.1177/0037549706075542
   de Cock C, 2020, JMIR RES PROTOC, V9, DOI 10.2196/16934
   De Nieva J.O., 2020, 6 INT ACM IN COOP HC, P1, DOI [10.1145/3431656.3431657, DOI 10.1145/3431656.3431657]
   Deb S, 2014, ASIAN EDUC DEV STUD, V3, P118, DOI 10.1108/AEDS-02-2013-0007
   Dekker I, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01063
   DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061
   Dias Joao, 2014, Emotion Modeling. Towards Pragmatic Computational Models of Affective Processes. LNCS 8750, P44, DOI 10.1007/978-3-319-12973-0_3
   Fishbein M, 2011, PREDICTING AND CHANGING BEHAVIOR: THE REASONED ACTION APPROACH, P1
   Gaffney H, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/14166
   Glass Alyssa, 2008, 13th International Conference on Intelligent User Interfaces. IUI 2008, P227, DOI 10.1145/1378773.1378804
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1
   Harman K, 2014, PHYSIOTHER CAN, V66, P82, DOI 10.3138/ptc.2012-56BC
   Hatcher RL, 2006, PSYCHOTHER RES, V16, P12, DOI 10.1080/10503300500352500
   Inac Y, 2021, AFR HEALTH SCI, V21, P123, DOI 10.4314/ahs.v21i1.17
   Kim Y, 2013, J EDUC PSYCHOL, V105, P1164, DOI 10.1037/a0031027
   Kocaballi AB, 2019, J MED INTERNET RES, V21, DOI 10.2196/15360
   Kumar S., 2013, J PHYS ED SPORTS MAN, V4, P5, DOI [https://doi.org/10.5897/JPESM12.001, DOI 10.5897/JPESM12.001]
   Kumaraswamy N., 2013, INT REV SOC SCI HUMA, V5, P135, DOI DOI 10.24941/IJCR.33132.12.2018
   Levin-Zamir D, 2016, GLOB HEALTH PROMOT, V23, P5, DOI 10.1177/1757975914548200
   Lisetti C.L., 2012, SIGHIT RECORD, V2, P28, DOI [10.1145/2180796.2180820, DOI 10.1145/2180796.2180820]
   Lucas GM, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00051
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   Luxton DD, 2020, B WORLD HEALTH ORGAN, V98, P285, DOI 10.2471/BLT.19.237636
   Majumdar P, 2020, CHRONOBIOL INT, V37, P1191, DOI 10.1080/07420528.2020.1786107
   Malle B.F.., 2005, FOLK THEORY MIND CON
   Martinez-Miranda J, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0784-6
   MAYER RC, 1995, ACAD MANAGE REV, V20, P709, DOI 10.2307/258792
   Mayer RC, 1999, J APPL PSYCHOL, V84, P123, DOI 10.1037/0021-9010.84.1.123
   Moreno R, 2006, CONTEMP EDUC PSYCHOL, V31, P186, DOI 10.1016/j.cedpsych.2005.05.002
   Nandi Madhumita, 2012, Indian J Med Sci, V66, P1
   NCRB-India, 2019, ACCIDENTAL DEATHS SU
   Neerincx MA, 2018, LECT NOTES ARTIF INT, V10906, P204, DOI 10.1007/978-3-319-91122-9_18
   Plant EA, 2009, COMPUT EDUC, V53, P209, DOI 10.1016/j.compedu.2009.01.013
   Ranjbartabar H., 2019, Advances in Information Systems Development. Designing Digitalization. Lecture Notes in Information Systems and Organisation (LNISO 34), P227, DOI 10.1007/978-3-030-22993-1_13
   Reddy K. J., 2018, BIOMED PHARMACOL J, V11, P531, DOI [10.13005/bpj/1404, DOI 10.13005/bpj/1404]
   Rheu M, 2021, INT J HUM-COMPUT INT, V37, P81, DOI 10.1080/10447318.2020.1807710
   Richards D, 2019, BRIT J EDUC TECHNOL, V50, P2885, DOI 10.1111/bjet.12863
   ter Stal S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102409
   Torjesen I, 2020, BMJ-BRIT MED J, V369, DOI 10.1136/bmj.m1994
   Verma G., 2020, INT J PSYCHOSOCIAL R, V24, P2702
   Wheeler SC, 2005, J CONSUM RES, V31, P787, DOI 10.1086/426613
   Zilcha-Mano S, 2017, AM PSYCHOL, V72, P311, DOI 10.1037/a0040435
NR 53
TC 0
Z9 0
U1 7
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0007-1013
EI 1467-8535
J9 BRIT J EDUC TECHNOL
JI Br. J. Educ. Technol.
PD MAY
PY 2022
VL 53
IS 3
BP 491
EP 511
DI 10.1111/bjet.13174
PG 21
WC Education & Educational Research
WE Social Science Citation Index (SSCI)
SC Education & Educational Research
GA 0O1FW
UT WOS:000783276000005
DA 2022-08-02
ER

PT C
AU Case, JE
   Twyman, NW
AF Case, J. Eric
   Twyman, Nathan W.
BE Bui, TX
   Sprague, RH
TI Embodied Conversational Agents: Social or Nonsocial?
SO 2015 48TH HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS)
SE Proceedings of the Annual Hawaii International Conference on System
   Sciences
LA English
DT Proceedings Paper
CT 48th Annual Hawaii International Conference on System Sciences (HICSS)
CY JAN 05-08, 2015
CL Kauai, HI
SP IEEE Comp Soc, Univ Hawaii, Shidler Coll Business, Univ Hawaii, Dept EE, Univ Hawaii, Informat Sci Program, ONR, AFOSR, Natl Sci Fdn, IEEE Syst Sci & Cybernet Soc, ACM, SIAM, IEEE Hawaii Sect, IEEE Control Syst Soc, IEEE Grp Informat Theory, IEEE Grp Automat Control, ARO, Reg Med Program Hawaii, Univ Hawaii, Coll Business Adm, Nasdaq
ID TRUST; HALF; FACE
AB Since the advent of radio, we are accustomed to hearing disembodied human voices from devices. If system designers use an embodied conversational agent (ECA) as the interface to their system, they select either a human or a synthetic voice. One prior research study shows that pairing a synthetic face with a natural voice is problematic for users. Another study showed users perceive high-quality synthetic voices as nearly equal to professional voice talent. The incongruence between the verbal and nonverbal channels of an ECA has a negative effect on ECA users. This study will demonstrate that task type (low affect-infusion vs. high affect-infusion) has an unexplored impact on the social requirements of an ECA, and that cognitive effort and trust may provide greater perceived value for high affect-infusion tasks.
C1 [Case, J. Eric] Univ Arizona, Tucson, AZ 85721 USA.
   [Twyman, Nathan W.] Missouri Univ Sci & Technol, Rolla, MO USA.
RP Case, JE (corresponding author), Univ Arizona, Tucson, AZ 85721 USA.
EM ecase@arizona.edu; nathantwyman@gmail.com
CR [Anonymous], 2003, P SIGCHI C HUM FACT, DOI [10.1145/642611.642662, DOI 10.1145/642611.642662]
   Apple Inc, 2013, IOS AB SIR
   ASCH SE, 1946, J ABNORM SOC PSYCH, V41, P258, DOI 10.1037/h0055756
   Bailenson JN, 2001, PRESENCE-TELEOP VIRT, V10, P583, DOI 10.1162/105474601753272844
   Blau P. M., 1964, EXCHANGE POWER SOCIA
   Cassell J, 2000, COMMUN ACM, V43, P50, DOI 10.1145/355112.355123
   Cassell J, 2001, AI MAG, V22, P67
   Cassell J., 1999, P SIGCHI C HUM FACT, P520, DOI DOI 10.1145/302979.303150
   FORGAS JP, 1995, PSYCHOL BULL, V117, P39, DOI 10.1037/0033-2909.117.1.39
   Georgila K., 2012, LREC
   GIFFIN K, 1967, PSYCHOL BULL, V68, P104, DOI 10.1037/h0024833
   Gong L, 2007, HUM COMMUN RES, V33, P163, DOI 10.1111/j.1468-2958.2007.00295.x
   Jankel A., 1985, MAX HEADROOM
   Kubrick S., 1968, SPACE ODYSSEY FILM
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1093/ct/14.1.27
   MACLEOD CM, 1991, PSYCHOL BULL, V109, P163, DOI 10.1037/0033-2909.109.2.163
   McGurk  H., 1976, HEARING LIPS SEEING
   McKnight DH, 2002, INFORM SYST RES, V13, P334, DOI 10.1287/isre.13.3.334.81
   Mitchell WJ, 2011, I-PERCEPTION, V2, P10, DOI 10.1068/i0415
   Nass C, 1996, INT J HUM-COMPUT ST, V45, P669, DOI 10.1006/ijhc.1996.0073
   NASS C, 1995, INT J HUM-COMPUT ST, V43, P223, DOI 10.1006/ijhc.1995.1042
   Nass C, 2000, EMBODIED CONVERSATIONAL AGENTS, P374
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nunez A., 2007, AUTOBLOG
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Roeckelein J.E., 2006, ELSEVIERS DICT PSYCH
   Yvkoff L., 2011, CNET CAR TECH
NR 27
TC 0
Z9 0
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 1060-3425
BN 978-1-4799-7367-5
J9 P ANN HICSS
PY 2015
BP 491
EP 496
DI 10.1109/HICSS.2015.65
PG 6
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Operations Research & Management Science
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Operations Research & Management Science
GA BE0LK
UT WOS:000366264100056
DA 2022-08-02
ER

PT J
AU Allen, J
   Galescu, L
   Teng, CM
   Perera, I
AF Allen, James
   Galescu, Lucian
   Teng, Choh Man
   Perera, Ian
TI Conversational Agents for Complex Collaborative Tasks
SO AI MAGAZINE
LA English
DT Article
ID INTERFACE; SYSTEMS
AB Dialogue is a very active area o f research currently, both in developing new computational techniques for robust dialogue systems and in the active fielding of commercial conversational assistants such as Apple's Sin and Amazon's Alexa. This article argues that, while current techniques can be used to design effective dialogue-based systems for very simple tasks, they are unlikely to generalize to conversational interfaces that enhance human ability to solve complex tasks by interacting with artificial intelligence reasoning and modeling systems. We explore some of the challenges of tackling such complex tasks and describe a dialogue model designed to meet these challenges. We illustrate our approach with examples of several implemented systems that use this framework.
C1 [Allen, James] Univ Rochester, Comp Sci, Rochester, NY 14627 USA.
   [Allen, James; Galescu, Lucian; Teng, Choh Man; Perera, Ian] IHMC, Pensacola, FL 32502 USA.
RP Allen, J (corresponding author), Univ Rochester, Comp Sci, Rochester, NY 14627 USA.; Allen, J (corresponding author), IHMC, Pensacola, FL 32502 USA.
EM jallen@ihmc.us; lgalescu@ihmc.us; cmteng@ihmc.us; iperera@ihmc.us
FU Defense Advanced Research Projects Agency (Army Research Office)
   [W911NF-14-1-0391, W911NF-15-1-0542, W911NF-17-1-0047]
FX This research was supported by the Defense Advanced Research Projects
   Agency (Army Research Office contracts W911NF-14-1-0391,
   W911NF-15-1-0542, W911NF-17-1-0047,andW911NF-18-1-0464).
CR Allen J., 2000, Natural Language Engineering, P213, DOI 10.1017/S135132490000245X
   Allen J., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P774
   Allen J., 2019, ADV COGNITIVE SYSTEM, V7, P195
   Allen J., 2019, MODELING WORLDS SYST
   Allen J. F., 2017, COMPUTATIONAL CONSTR
   Allen JF, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P4776
   ALLEN JF, 1980, ARTIF INTELL, V15, P143, DOI 10.1016/0004-3702(80)90042-9
   [Anonymous], 2020, ADV COGNITIVE SYSTEM
   Banarescu L., 2013, P 7 LING ANN WORKSH, P178
   Blaylock N., 2005, P 6 SIGDIAL WORKSH D, P200
   Bohus D, 2009, COMPUT SPEECH LANG, V23, P332, DOI 10.1016/j.csl.2008.10.001
   Bos Johan, 2002, THESIS
   Chu-Carroll J, 1998, COMPUT LINGUIST, V24, P355
   Cohen P. R., 1990, INTENTIONS COMMUNICA
   Copestake A., 2005, RES LANGUAGE COMPUTA, V3, P281, DOI DOI 10.1007/S11168-006-6327-9
   Fellbaum C, 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   FERGUSON G, 1998, P NAT C ART INT
   Ferguson G, 2007, AI MAG, V28, P23
   Galescu Lucian, THESIS
   GHALLAB M, 2004, AUTOMATED PLANNING T
   Goddeau D., 1996, P ICSLP
   Grosz B., 1974, P I EL EL ENG IEEE S
   Grosz B. J., 1986, Computational Linguistics, V12, P175
   Grosz BJ, 1996, ARTIF INTELL, V86, P269, DOI 10.1016/0004-3702(95)00103-4
   Gyori BM, 2017, MOL SYST BIOL, V13, DOI 10.15252/msb.20177651
   Hatfield-Dodds S., 2015, AUSTR NATL OUTLOOK 2
   Hinkelman E., 1989, ANN M ASS COMP LING
   Hutchens M., 2020, INT C HUM COMP INT H
   Kautz H. A., 1986, 5 NAT C ART INT ASS
   Kim K., 2008, P 9 SIGDIAL WORKSH D, P120
   Kim S., 2018, P 16 ANN C N AM CHAP, P86
   Koller A, 2003, EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P195
   Larsson S., 2000, Natural Language Engineering, P323, DOI 10.1017/S1351324900002539
   Lemon O., 2002, P SPEC INT GROUP DIS
   LI J. J., 2019, OPER RES MANAGE SCI, V2019, P8
   LITMAN DJ, 1987, COGNITIVE SCI, V11, P163, DOI 10.1207/s15516709cog1102_4
   Liu B, 2016, INTERSPEECH, P685, DOI 10.21437/Interspeech.2016-1352
   LOCHBAUM KE, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P485
   Manshadi M, 2018, COMPUT LINGUIST, V44, P39, DOI 10.1162/COLI_a_00307
   Mrksic N, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P794
   Nouri E., 2018, NEURIPS NIPS 2 NIPS
   Perera I, 2018, 19TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2018), P89
   Perera I, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5103
   Perera Ian, HIS RES INTERESTS IN
   Pulman S., 1997, 7 COMP LING NETH CLI
   Quick D., 2017, P 43 INT COMP MUS C, P52
   Rich C, 1998, USER MODEL USER-ADAP, V8, P315, DOI 10.1023/A:1008204020038
   Rich C., 2012, INTELLIGENT VIRTUAL, V7502
   Rickel J., 1998, Proceedings of the Second International Conference on Autonomous Agents, P332, DOI 10.1145/280765.280851
   Serban I. V., 2016, P 30 ASS ADV ART INT
   Valenzuela-Escarcega Marco A, 2018, LARGE SCALE AUTOMATE
   Wang Y., 2018, P 2018 C N AM CHAPT
   Wang Z., 2013, P 14 ANN M SPEC INT
   Wen TH, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P438
   Williams Jason, 2016, DIALOGUE DISCOURSE, V7, P4
   Young S, 2013, P IEEE, V101, P1160, DOI 10.1109/JPROC.2012.2225812
   Zhang XZ, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P2016, DOI 10.1109/ICIT.2016.7475077
   Zue V, 2000, IEEE T SPEECH AUDI P, V8, P85, DOI 10.1109/89.817460
NR 58
TC 1
Z9 1
U1 1
U2 6
PU AMER ASSOC ARTIFICIAL INTELL
PI MENLO PK
PA 445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA
SN 0738-4602
J9 AI MAG
JI AI Mag.
PD WIN
PY 2020
VL 41
IS 4
BP 54
EP 78
PG 25
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA PU3PC
UT WOS:000609216300004
DA 2022-08-02
ER

PT C
AU Morveli-Espinoza, M
   Puyol-Gruart, J
AF Morveli-Espinoza, Mariela
   Puyol-Gruart, Josep
BE Sandri, S
   SanchezMarre, M
   Cortes, U
TI Anytime Reasoning Mechanism for Conversational Agents
SO ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT
SE Frontiers in Artificial Intelligence and Applications
LA English
DT Proceedings Paper
CT 12th International Conference of the
   Catalan-Association-for-Artificial-Intelligence (CCIA)
CY OCT 21-23, 2009
CL Cardona, SPAIN
SP Catalan Assoc Artificial Intelligence, Univ Politecnica Catalunya, Gobierno Espana, Ministerio Ciencia & Innovac, la Caixa, ISOCO, Strands, Yahoo Res
DE anytime algorithms; progressive reasoning; multi-agent systems; partial
   deduction; multiple-valued logic
ID DEDUCTION
AB When an agent receives a query from another agent, it tries to satisfy it by building an answer based on its current knowledge. Depending on the available time or the urgency of the requirement the agent can produce answers with different levels of quality. Answers can contain the best one, a provisional one because it can be improved later, or a conditional answer because the agent ignores some information needed to build the answer. Agents always depend on the availability of information obtained from perception or from the communication with other agents. We assume that in the real world normally is better to receive an answer with poor quality than no answer. The answer can be good enough for the receiver or the receiver can spend more time to wait for a better answer. Autonomy implies taking the best decision with the available information, avoiding blocking situations and no action. In this paper, we propose an architecture for deliberative agents using anytime like reasoning to produce better answers as time increases.
C1 [Morveli-Espinoza, Mariela; Puyol-Gruart, Josep] CSIC, Spanish Sci Res Council, Artificial Intelligence Res Inst IIIA, Madrid, Spain.
RP Puyol-Gruart, J (corresponding author), Artificial Intelligence Res Inst IIIA, Campus UAB, Bellaterra 08193, Spain.
EM puyol@iiia.csic.es
RI Puyol-Gruart, Josep/H-2474-2015
OI Puyol-Gruart, Josep/0000-0002-7264-8645; Morveli Espinoza,
   Mariela/0000-0002-7376-2271
CR Barbuceanu M, 2000, LECT NOTES ARTIF INT, V1916, P220
   Jaumard B, 2009, INT J APPROX REASON, V50, P92, DOI 10.1016/j.ijar.2008.03.005
   Morveli-Espinoza M, 2008, FRONT ARTIF INTEL AP, V184, P60, DOI 10.3233/978-1-58603-925-7-60
   Mouaddib AI, 2000, J EXP THEOR ARTIF IN, V12, P101, DOI 10.1080/095281300146344
   MOUADDIB AI, 1995, P 14 INT JOINT C ART, P775
   PUYOL J, 1992, P 10 EUR C ART INT E, P144
   Puyol-Gruart J, 1998, INT J APPROX REASON, V18, P107, DOI 10.1016/S0888-613X(97)10006-8
   PUYOLGRUART J, 1997, MATHWARE SOFT COMPUT, V4, P299
   Rago F, 2006, LECT NOTES ARTIF INT, V2955, P46
   RUSSELL SJ, 1991, P 12 INT JOINT C ART, P212
   Schlobach S., 2007, P WORKSH NEW FORMS R, P60
   SHOHAM Y, 1993, ARTIF INTELL, V60, P51, DOI 10.1016/0004-3702(93)90034-9
   Verberne Alan, 2000, CONSTRAINT PROPAGATI, P323
   Zilberstein S, 1996, AI MAG, V17, P73
   [No title captured]
NR 15
TC 0
Z9 0
U1 0
U2 0
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 0922-6389
EI 1879-8314
BN 978-1-60750-465-8; 978-1-60750-061-2
J9 FRONT ARTIF INTEL AP
PY 2009
VL 202
BP 215
EP 223
DI 10.3233/978-1-60750-061-2-215
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BC1ER
UT WOS:000350047900025
DA 2022-08-02
ER

PT C
AU Van Brummelen, J
AF Van Brummelen, Jessica
BE Smith, J
   Bogart, CA
   Good, J
   Fleming, SD
TI Conversational Agents to Democratize Artificial Intelligence
SO 2019 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING
   (VL/HCC 2019)
SE Symposium on Visual Languages and Human Centric Computing VL HCC
LA English
DT Proceedings Paper
CT IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)
CY OCT 14-18, 2019
CL Memphis, TN
SP IEEE
C1 [Van Brummelen, Jessica] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA.
RP Van Brummelen, J (corresponding author), MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA.
EM jess@csail.mit.edu
FU Alexa Graduate Fellowship
FX This work was supported by an Alexa Graduate Fellowship.
CR Brennan K., 2012, P 2012 ANN M AM ED R, V1, P25
   KITAEV N, 2018, ACL
   Metatla Oussama, 2019, P CHI HUM FACT COMP
   Nowogrodzki A, 2018, NATURE, V559, P141, DOI 10.1038/d41586-018-05588-x
   Pulido-Prieto O, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3109481
   Rosenblatt L, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P417, DOI 10.1145/3132525.3134824
   Van Brummelen J., 2019, THESIS
   Wagner A, 2015, INT J INF TECHNOL SY, V8, P47, DOI 10.4018/IJITSA.2015070104
NR 8
TC 5
Z9 5
U1 0
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1943-6092
BN 978-1-7281-0810-0
J9 S VIS LANG HUM CEN C
PY 2019
BP 239
EP 240
PG 2
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP7EB
UT WOS:000561703800037
DA 2022-08-02
ER

PT C
AU Cassell, J
AF Cassell, Justine
GP ISCA-INST SPEECH COMMUNICATION ASSOC
TI Modeling Rapport in Embodied Conversational Agents
SO INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH
   COMMUNICATION ASSOCIATION 2008, VOLS 1-5
LA English
DT Proceedings Paper
CT 9th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2008)
CY SEP 22-26, 2008
CL Brisbane, AUSTRALIA
C1 Northwestern Univ, Ctr Technol & Social Behav, Evanston, IL 60208 USA.
RP Cassell, J (corresponding author), Northwestern Univ, Ctr Technol & Social Behav, Evanston, IL 60208 USA.
EM justine@northwestern.edu
CR Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Cassell J., 2002, USER MODELING ADAPTI, V12, P1, DOI [10.1023/A:1013337427135, DOI 10.1023/A:1013337427135]
   CASSELL J, 2007, P WORKSH EMB NAT LAN
   Cassell J, 2008, WILEY SER SURV METH, P161
   GRATCH J, 2006, P 5 INT C INT VIRT A
   Lacobelli F, 2007, LECT NOTES ARTIF INT, V4722, P57
   STRONKS B, 2002, P EMB CONV AG LETS S, P91
   Tartaro A., 2007, UNIVERSAL USABILITY, P231
NR 8
TC 2
Z9 2
U1 0
U2 0
PU ISCA-INT SPEECH COMMUNICATION ASSOC
PI BAIXAS
PA C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE
BN 978-1-61567-378-0
PY 2008
BP 18
EP 19
PG 2
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BOM81
UT WOS:000277026100004
DA 2022-08-02
ER

PT S
AU Heller, B
   Procter, M
   Rose, C
AF Heller, Bob
   Procter, Mike
   Rose, Corbin
BE Gregory, S
   Lee, MJW
   Dalgarno, B
   Tynan, B
TI CONVERSATIONAL AGENTS IN SECOND LIFE Freudbot
SO LEARNING IN VIRTUAL WORLDS: RESEARCH AND APPLICATIONS
SE Issues in Distance Education
LA English
DT Article; Book Chapter
ID PEDAGOGICAL AGENTS
C1 [Heller, Bob] Athabasca Univ, Ctr Psychol, Athabasca, AB, Canada.
   [Procter, Mike] Athabasca Univ, Developing Software Res Animated Conversat Agents, Athabasca, AB, Canada.
RP Heller, B (corresponding author), Athabasca Univ, Ctr Psychol, Athabasca, AB, Canada.
CR Annand D, 2011, INT REV RES OPEN DIS, V12, P40, DOI 10.19173/irrodl.v12i5.924
   Burden DJH, 2009, KNOWL-BASED SYST, V22, P540, DOI 10.1016/j.knosys.2008.10.001
   Cassell J, 2000, EMBODIED CONVERSATIONAL AGENTS, P29
   Cassell J., 2000, EMBODIED CONVERSATIO
   Clark R. E., 2005, Journal of Educational Computing Research, V32, P209, DOI 10.2190/7LRM-3BR2-44GW-9QQY
   Danforth D. R., 2009, J VIRTUAL WORLDS, V2
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   Garrison D. R., 1999, Internet and Higher Education, V2, P87, DOI 10.1016/S1096-7516(00)00016-6
   Gulz A, 2006, INT J HUM-COMPUT ST, V64, P322, DOI 10.1016/j.ijhcs.2005.08.006
   Gulz A., 2004, INT J ARTIFICIAL INT, V14, P313
   Heller Bob Mike, 2005, EDMEDIA INNOVATE LEA, P3913
   Heller R, 2009, International Journal of Web-Based Learning and Teaching Technologies, V4, P54, DOI 10.4018/jwltt.2009010104
   Kerly A, 2009, APPLICATIONS AND INNOVATIONS IN INTELLIGENT SYSTEMS XVI, P169
   Lowenthal P.R., 2010, SOCIAL COMPUTING CON, P113
   McQuiggan SW, 2010, EDUC TECHNOL SOC, V13, P40
   Mori M, 1970, ENERGY, V7, P33, DOI DOI 10.1109/MRA.2012.2192811
   Payr S, 2003, APPL ARTIF INTELL, V17, P1, DOI [10.1080/713827053, 10.1080/08839510390169729]
   Rickel J., 2001, Intelligent Virtual Agents. Third International Workshop, IVA 2001. Proceedings (Lecture Notes in Artificial Intelligence Vol.2190), P15
   Short J. A., 1976, SOCIAL PSYCHOL TELEC
   Veletsianos G, 2008, BRIT J EDUC TECHNOL, V39, P969, DOI 10.1111/j.1467-8535.2007.00797.x
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   [No title captured]
NR 22
TC 0
Z9 0
U1 0
U2 0
PU ATHABASCA UNIV PRESS
PI ATHABASCA
PA 1 UNIVERSITY DR, ATHABASCA, AB T9S 3A3, CANADA
SN 1919-4382
BN 978-1-77199-134-6; 978-1-77199-133-9
J9 ISS ONLINE EDUC
PY 2016
BP 153
EP 165
D2 10.15215/aupress/9781771991339.01
PG 13
WC Education & Educational Research
WE Book Citation Index – Social Sciences & Humanities (BKCI-SSH)
SC Education & Educational Research
GA BH3FW
UT WOS:000399612500009
OA Green Accepted, hybrid, Green Published
DA 2022-08-02
ER

PT C
AU Okamoto, M
AF Okamoto, M
GP IEEE COMPUTER SOCIETY
   IEEE COMPUTER SOCIETY
TI Incremental PDFA learning for conversational agents
SO IEEE WORKSHOP ON KNOWLEDGE MEDIA NETWORKING, PROCEEDINGS
LA English
DT Proceedings Paper
CT IEEE Workshop on Knowledge Media Networking
CY JUL 10-12, 2002
CL KYOTO, JAPAN
SP IEEE Comp Soc, Learning Technol Task Force
AB When finite-state machines are used for dialogue models of a conversational agent, learning algorithms which learn probabilistic finite-state automata with the state merging method are useful. However these algorithms should learn the whole data,every time the number of example dialogues increases. Therefore, the learning cost is large when we construct dialogue models gradually.
   We proposed a learning method which decreases the number of compatibility checks by caching the merging information, and evaluated it and the perplexities of learned models. From the comparison among the dialogue models, the method which caches only the compatibility-changed states reduced the total number of compatibility checks by 13%. We also applied the algorithm to an actual conversational agent.
C1 Kyoto Univ, Dept Social Informat, Sakyo Ku, Kyoto 6068501, Japan.
RP Okamoto, M (corresponding author), Kyoto Univ, Dept Social Informat, Sakyo Ku, Yoshida Hommachi, Kyoto 6068501, Japan.
EM okamoto@kuis.kyoto-u.ac.jp
CR Alexandersson J, 1995, SEVENTH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P188
   Carrasco RC, 1997, RAIRO-INF THEOR APPL, V31, P437, DOI 10.1051/ita/1997310504371
   CARRASCO RC, 1999, LECT NOTES ARTIF INT, V862, P139
   Fraser N. M., 1991, Computer Speech and Language, V5, P81, DOI 10.1016/0885-2308(91)90019-M
   Ishida T, 2002, COMMUN ACM, V45, P76, DOI 10.1145/514236.514238
   Okamoto M, 2001, LECT NOTES ARTIF INT, V2182, P20
   Stent A., 1999, P 37 ANN M ASS COMP, P183
   Thollard F., 2000, P 17 INT C MACH LEAR, P975
NR 8
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
BN 0-7695-1778-1
PY 2002
BP 161
EP 166
DI 10.1109/KMN.2002.1115179
PG 6
WC Computer Science, Information Systems; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA BV75A
UT WOS:000179944800025
DA 2022-08-02
ER

PT C
AU Adolphs, P
   Benz, A
   Castello, NB
   Cheng, XW
   Kluwer, T
   Krifka, M
   Strekalova, A
   Uszkoreit, H
   Xu, FY
AF Adolphs, Peter
   Benz, Anton
   Castello, Nuria Bertomeu
   Cheng, Xiwen
   Kluewer, Tina
   Krifka, Manfred
   Strekalova, Alexandra
   Uszkoreit, Hans
   Xu, Feiyu
BE Bach, J
   Edelkamp, S
TI Conversational Agents in a Virtual Worldcru
SO KI 2011: ADVANCES IN ARTIFICIAL INTELLIGENCE
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 34th Annual German Conference on Artificial Intelligence (KI 2011)
CY OCT 04-07, 2011
CL Berlin, GERMANY
AB This paper presents a system that builds on theoretical and experimental insights from linguistic pragmatics, uses novel techniques from computational linguistics and combines them with robust baseline technologies to provide intelligent Non Player Characters (NPCs), which naturally act and talk in a virtual world. Current NPCs still lack the necessary linguistic knowledge and methods to apply them to the numerous conversational application areas in virtual worlds. The system presented in this paper manages two NPCs, a barkeeper and a furniture sales agent, which highly depend on conversational abilities.
C1 [Adolphs, Peter; Cheng, Xiwen; Kluewer, Tina; Uszkoreit, Hans; Xu, Feiyu] Deutsch Forschungszentrum Kunstliche Intelligenz, GmbH, Alt Moabit 91C, D-10559 Berlin, Germany.
   [Benz, Anton; Castello, Nuria Bertomeu; Krifka, Manfred; Strekalova, Alexandra] Zentrum Allgemeine Sprachwissenschaft, D-10117 Berlin, Germany.
RP Adolphs, P (corresponding author), Deutsch Forschungszentrum Kunstliche Intelligenz, GmbH, Alt Moabit 91C, D-10559 Berlin, Germany.
FU KomParse; ProFIT programme of the Federal State of Berlin; EFRE
   programme of the European Union [FKZ: 01IW08003]; German Ministry for
   Education and Research (BMBF, FKZ) [01IW08003]
FX The research reported in this paper is supported from the project
   KomParse, funded by the ProFIT programme of the Federal State of Berlin,
   cofunded by the EFRE programme of the European Union. The research work
   in the areas of information extraction and question answering is
   additionally supported through a grant to the project TAKE, funded by
   the German Ministry for Education and Research (BMBF, FKZ: 01IW08003)
   and the German DFG Cluster of Excellence on Multimodal Computing and
   Interaction. Many thanks go to the supporting company Metaversum.
CR Adolphs P, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Bertomeu N., 2009, P 1 INT C CORP LING, P723
   Bickmore T, 2005, TEXT SPEECH LANG TEC, V30, P23
   Cavazza M., 2010, 11 ANN M SPEC INT GR, P277
   Clark H.H, 1996, USING LANGUAGE
   Crook N., 2009, P SIGDIAL 2009 C 10, P341
   Elmagarmid AK, 2007, IEEE T KNOWL DATA EN, V19, P1, DOI 10.1109/TKDE.2007.250581
   Gardenfors P., 2009, CONCEPTUAL SPACES GE
   Gustafson J, 2005, LECT NOTES ARTIF INT, V3661, P37
   Hill All W., 2003, KYNSTLICH INTELLIGEN, V17, P32
   Keeney R., 1993, DECISIONS MULTIPLE O
   Kenny P, 2008, LECT NOTES COMPUT SC, V5208, P394
   Kluwer T., 2010, P 23 INT C COMP LING
   Kopp S, 2005, LECT NOTES ARTIF INT, V3661, P329
   Narayanan S, 2002, IEEE T SPEECH AUDI P, V10, P65, DOI 10.1109/89.985544
   Stolcke A, 2000, COMPUT LINGUIST, V26, P339, DOI 10.1162/089120100561737
   Verbree A. T., 2006, 1 INT IEEE WORKSH SP
   Xu F., 2010, P 23 INT C COMP LING
   Xu F., 2007, P ACL 2007 45 ANN M
   Zender H., 2007, AAAI SPRING S MENL P, P62
NR 20
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-24454-4
J9 LECT NOTES ARTIF INT
PY 2011
VL 7006
BP 38
EP +
PG 3
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BAS35
UT WOS:000305357000004
DA 2022-08-02
ER

PT S
AU Pelachaud, C
   Bilvi, M
AF Pelachaud, C
   Bilvi, M
BE Rist, T
   Aylett, R
   Ballin, D
   Rickel, J
TI Modelling gaze behavior for conversational agents
SO INTELLIGENT VIRTUAL AGENTS
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 4th International Workshop on Intelligent Virtual Agents
CY SEP 15-17, 2003
CL KLOSTER IRSEE, GERMANY
SP EU 5th Framework VICTEC Project, SIGMEDIA, DFKI, BTexact Technologies, Univ Augsburg, Dept Multimedia Concepts & Applicat
AB In this paper we propose an eye gaze model for an embodied conversational agent that embeds information on communicative functions as well as on statistical information of gaze patterns. This latter information has been derived from the analytic studies of an annotated video-corpus of conversation dyads. We aim at generating different gaze behaviors to stimulate several personalized gaze habits of an embodied conversational agent.
C1 Univ Paris 08, IUT Montreuil, F-93526 St Denis 02, France.
   Univ Rome, Dept Comp & Syst Sci, Rome, Italy.
RP Pelachaud, C (corresponding author), Univ Paris 08, IUT Montreuil, F-93526 St Denis 02, France.
EM c.pelachaud@iut.univ-paris8.fr
CR Ball G, 2000, EMBODIED CONVERSATIONAL AGENTS, P189
   BESKOW J, 1997, P ESCA WORKSH AUD VI, P149
   CAPPELLA J, 2001, STABILITY CHANGE REL
   Cassell J., 1994, P 21 ANN C COMP GRAP, P413, DOI DOI 10.1145/192161.192272
   Cassell J, 1999, MACHINE CONVERSATION
   Cassell J., 1999, P SIGCHI C HUM FACT, P520, DOI DOI 10.1145/302979.303150
   CHOPRAKHULLAR S, 1999, AUT AG C SEATTL WA
   COLBURN RA, 2000, MSRTR200081 MICR COR
   FUKAYAMA A, 2002, CHI 2002, V4, P1
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   Lester JC, 2000, EMBODIED CONVERSATIONAL AGENTS, P123
   LUNDEBERG M, 1999, P ESCA WORKSH AUD VI
   PELACHAUD C, 2002, P AAMAS, V2
   Poggi I, 2000, AI COMMUN, V13, P169
   POGGI I, 2002, MEANING USE
   Thorisson KR, 2002, TEXT SPEECH LANG TEC, V19, P173
   THORISSON KR, 1997, COMPUTER ANIMATION 9
   WATERS K, 1996, 965 CRL DIG EQ CORP
NR 18
TC 18
Z9 18
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-20003-7
J9 LECT NOTES ARTIF INT
PY 2003
VL 2792
BP 93
EP 100
PG 8
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BX96B
UT WOS:000187008600016
DA 2022-08-02
ER

PT C
AU Bevacqua, E
   Pammi, S
   Hyniewska, SJ
   Schroder, M
   Pelachaud, C
AF Bevacqua, Elisabetta
   Pammi, Sathish
   Hyniewska, Sylwia Julia
   Schroeder, Marc
   Pelachaud, Catherine
BE Allbeck, J
   Badler, N
   Bickmore, T
   Pelachaud, C
   Safonova, A
TI Multimodal Backchannels for Embodied Conversational Agents
SO INTELLIGENT VIRTUAL AGENTS, IVA 2010
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 10th International Conference on Intelligent Virtual Agents (IVA)
CY SEP 20-22, 2010
CL Philadelphia, PA
SP Univ Penn, SIG Ctr Comp Graph
ID FEEDBACK
AB One of the most desirable characteristics of an Embodied Conversational Agent (ECA) is the capability of interacting with users in a human-like manner. While listening to a user, an ECA should be able to provide backchannel signals through visual and acoustic modalities. In this work we propose an improvement of our previous system to generate multimodal backchannel signals on visual and acoustic modalities. A perceptual study has been performed to understand how context-free multimodal backchannels are interpreted by users.
C1 [Bevacqua, Elisabetta; Hyniewska, Sylwia Julia; Pelachaud, Catherine] Telecom ParisTech, CNRS, LTCI, 37-39 Rue Dareau, F-75014 Paris, France.
   [Pammi, Sathish; Schroeder, Marc] DFKI GmbH Language Technol Lab, D-66123 Saarbrucken, Germany.
RP Bevacqua, E (corresponding author), Telecom ParisTech, CNRS, LTCI, 37-39 Rue Dareau, F-75014 Paris, France.
RI Hyniewska, Sylwia/C-1858-2015
OI Hyniewska, Sylwia/0000-0002-5241-3961
FU STREP SEMAINE [IST-211486]
FX This work has been funded by the STREP SEMAINE project IST-211486
CR Bevacqua E., 2007, P AISB 07 ANN CONV W, P147
   Cassell J, 1999, EMBODIMENT CONVERSAT
   Gardner R, 1998, APPL LINGUIST, V19, P204, DOI 10.1093/applin/19.2.204
   Gratch J, 2007, LECT NOTES ARTIF INT, V4722, P125
   Heylen D, 2007, LECT NOTES ARTIF INT, V4722, P147
   J. Allwood, 1993, SEMANTICS, V9
   Kopp S, 2008, LECT NOTES ARTIF INT, V4930, P18
   Morency L.-P., 2009, AUTONOMOUS AGENTS MU
   Niewiadomski R., 2009, AAMAS 2009 AUT AG MU
   Poggi Isabella, 2007, MIND HANDS FACE BODY
   Schroder M., 2003, International Journal of Speech Technology, V6, P365, DOI 10.1023/A:1025708916924
   Schroder M., 2009, P BLIZZ CHALL 2009
   Schroder M, 2010, ADV HUM-COMPUT INTER, V2010, DOI 10.1155/2010/319406
   Thorisson K. R., 1996, THESIS
   Yngve VH., 1970, 6 REG M CHIC LING SO, P567
NR 15
TC 24
Z9 24
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-15891-9
J9 LECT NOTES ARTIF INT
PY 2010
VL 6356
BP 194
EP 200
PG 7
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BDB32
UT WOS:000312453400021
DA 2022-08-02
ER

PT C
AU Gris, I
   Rivera, DA
   Rayon, A
   Camacho, A
   Novick, D
AF Gris, Ivan
   Rivera, Diego A.
   Rayon, Alex
   Camacho, Adriana
   Novick, David
BE Nakano, YI
   Andre, E
   Nishida, T
   Busso, C
   Pelachaud, C
TI Young Merlin: An Embodied Conversational Agent in Virtual Reality
SO ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON
   MULTIMODAL INTERACTION
LA English
DT Proceedings Paper
CT 18th ACM International Conference on Multimodal Interaction (ICMI)
CY NOV 12-16, 2016
CL Tokyo, JAPAN
SP ACM, ACM SIGCHI, Openstream, Microsoft, Disney Res, Voicebox Technologies, Honda Research Inst
DE Embodied Conversational Agents
AB This paper describes a system for embodied conversational agents developed by Inmerssion and one of the applications-Young Merlin: Trial by Fire -built with this system. In the Merlin application, the ECA and a human interact with speech in virtual reality. The goal of this application is to provide engaging VR experiences that build rapport through storytelling and verbal interactions. The agent is fully automated, and his attitude towards the user changes over time depending on the interaction. The conversational system was built through a declarative approach that supports animations, markup language, and gesture recognition. Future versions of Merlin will implement multi-character dialogs, additional actions, and extended interaction time.
C1 [Gris, Ivan; Rivera, Diego A.; Rayon, Alex; Camacho, Adriana; Novick, David] Inmerssion, 5914 Mira Hermosa Dr, El Paso, TX 79912 USA.
RP Gris, I (corresponding author), Inmerssion, 5914 Mira Hermosa Dr, El Paso, TX 79912 USA.
EM ivan@inmerssion.com; diego@inmerssion.com; alex@inmerssion.com;
   caro@inmerssion.com; david@inmerssion.com
CR Gris Ivan, 2015, Virtual, Augmented and Mixed Reality. 7th International Conference, VAMR 2015, held as part of HCI International 2015. Proceedings: LNCS 9179, P197, DOI 10.1007/978-3-319-21067-4_21
   Novick David, 2015, Virtual, Augmented and Mixed Reality. 7th International Conference, VAMR 2015, held as part of HCI International 2015. Proceedings: LNCS 9179, P206, DOI 10.1007/978-3-319-21067-4_22
   Novick D, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P383, DOI 10.1145/2818346.2823302
NR 3
TC 5
Z9 5
U1 1
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-4556-9
PY 2016
BP 425
EP 426
DI 10.1145/2993148.2998534
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BG6HQ
UT WOS:000390299900076
DA 2022-08-02
ER

PT C
AU Acer, UG
   Van den Broeck, M
   Kawsar, F
AF Acer, Utku Gunay
   Van den Broeck, Marc
   Kawsar, Fahim
GP Assoc Comp Machinery
TI The City as a Personal Assistant
SO UBICOMP/ISWC'19 ADJUNCT: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL JOINT
   CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE
   2019 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS
LA English
DT Proceedings Paper
CT ACM International Joint Conference on Pervasive and Ubiquitous Computing
   (UbiComp) / ACM International Symposium on Wearable Computers (ISWC)
CY SEP 09-13, 2019
CL London, ENGLAND
SP Assoc Comp Machinery, ACM SIGCHI, Nokia Bell Labs, Google, Huawei, Emteq, Facebook Real Labs, Snap Inc, ACM SIGMOBILE
DE conversational agents; location based services
AB Conversational agents are increasingly becoming digital partners in our everyday computational experiences. Although rich, and fresh in content, they are oblivious to users' locality beyond geospatial weather and traffic conditions. We introduce conversational agents that are hyper-local, embedded deeply into the urban infrastructure providing rich, purposeful, detail, and in some cases playful information relevant to a neighborhood. These agents are spatially constrained, and one can only interact with them once she is in close vicinity at street-level granularity. In other words, the city provides personal, stateful, spontaneous service to its citizens through the agents installed in urban landmarks. Drawing lessons from two user studies, we identify the requirements for this system. We then discuss the architecture of these agents that leverage covert communication channels and machine learning algorithms that run on the edge and wearable devices to offer meaningful conversational experience in urban settings.
C1 [Acer, Utku Gunay; Van den Broeck, Marc; Kawsar, Fahim] Nokia Bell Labs, Murray Hill, NJ 07974 USA.
   [Kawsar, Fahim] Delft Univ Technol, Delft, Netherlands.
RP Acer, UG (corresponding author), Nokia Bell Labs, Murray Hill, NJ 07974 USA.
OI Acer, Utku Gunay/0000-0001-7222-2145
CR Acer UG, 2017, PROCEEDINGS OF THE 14TH EAI INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS SYSTEMS: COMPUTING, NETWORKING AND SERVICES (MOBIQUITOUS 2017), P353, DOI 10.1145/3144457.3144492
   Acer Utku Gunay, 2019, P 2019 ACM INT JOINT
   [Anonymous], 2010, NORDICHI
   Camps-Mur D, 2013, IEEE WIREL COMMUN, V20, P96, DOI 10.1109/MWC.2013.6549288
   Dhar S, 2011, COMMUN ACM, V54, P121, DOI 10.1145/1941487.1941515
   Eriksson J, 2008, MOBISYS'08: PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P29
   Gupta Vishal, 2012, INT J MOBILE NETWORK, V2, DOI [10.5121/ijmnct.2012.2403, DOI 10.5121/IJMNCT.2012.2403]
   Hristova Desislava, 2012, WS1204 AAAI, P14
   Kawsar F, 2018, IEEE PERVAS COMPUT, V17, P83, DOI 10.1109/MPRV.2018.03367740
   Kumar M, 2006, POCKETSPHINX FREE RE, V1, DOI [10.1109/ICASSP.2006.1659988, DOI 10.1109/ICASSP.2006.1659988]
   Kupper A, 2005, LOCATION-BASED SERVICES: FUNDAMENTALS AND OPERATION, P1, DOI 10.1002/0470092335
   Page LC, 2017, AERA OPEN, V3, DOI 10.1177/2332858417749220
   Parise S, 2016, BUS HORIZONS, V59, P411, DOI 10.1016/j.bushor.2016.03.004
   Piyush N, 2016, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON SYSTEM MODELING & ADVANCEMENT IN RESEARCH TRENDS (SMART-2016), P322, DOI 10.1109/SYSMART.2016.7894543
   Tielman ML, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0771-y
NR 15
TC 1
Z9 1
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6869-8
PY 2019
BP 1102
EP 1106
DI 10.1145/3341162.3350847
PG 5
WC Computer Science, Cybernetics; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BO1MK
UT WOS:000501543800233
DA 2022-08-02
ER

PT C
AU Zhang, YX
   Calyam, P
   Joshi, T
   Nair, S
   Xu, D
AF Zhang, Yuanxun
   Calyam, Prasad
   Joshi, Trupti
   Nair, Satish
   Xu, Dong
BE Abe, N
   Liu, H
   Pu, C
   Hu, X
   Ahmed, N
   Qiao, M
   Song, Y
   Kossmann, D
   Liu, B
   Lee, K
   Tang, J
   He, J
   Saltz, J
TI Domain-specific Topic Model for Knowledge Discovery through
   Conversational Agents in Data Intensive Scientific Communities
SO 2018 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)
SE IEEE International Conference on Big Data
LA English
DT Proceedings Paper
CT IEEE International Conference on Big Data (Big Data)
CY DEC 10-13, 2018
CL Seattle, WA
SP IEEE, IEEE Comp Soc, Expedia Grp, Baidu, Squirrel AI Learning, Ankura, Springer
DE Topic Model; Theoretical Model for Big Data; Latent Dirichlet
   Allocation; Multi-disciplinary Knowledge Discovery; Computation and Data
   Intensive Applications
AB Machine learning techniques underlying Big Data analytics have the potential to benefit data intensive communities in e.g., bioinformatics and neuroscience domain sciences. Today's innovative advances in these domain communities are increasingly built upon multi-disciplinary knowledge discovery and cross-domain collaborations. Consequently, shortened time to knowledge discovery is a challenge when investigating new methods, developing new tools, or integrating datasets. The challenge for a domain scientist particularly lies in the actions to obtain guidance through query of massive information from diverse text corpus comprising of a wide-ranging set of topics. In this paper, we propose a novel "domain-specific topic model" (DSTM) that can drive conversational agents for users to discover latent knowledge patterns about relationships among research topics, tools and datasets from exemplar scientific domains. The goal of DSTM is to perform data mining to obtain meaningful guidance via a chatbot for domain scientists to choose the relevant tools or datasets pertinent to solving a computational and data intensive research problem at hand. Our DSTM is a Bayesian hierarchical model that extends the Latent Dirichlet Allocation (LDA) model and uses a Markov chain Monte Carlo algorithm to infer latent patterns within a specific domain in an unsupervised manner. We apply our DSTM to large collections of data from bioinformatics and neuroscience domains that include hundreds of papers from reputed journal archives, hundreds of tools and datasets. Through evaluation experiments with a perplexity metric, we show that our model has better generalization performance within a domain for discovering highly specific latent topics.
C1 [Zhang, Yuanxun; Calyam, Prasad; Joshi, Trupti; Nair, Satish; Xu, Dong] Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65211 USA.
RP Zhang, YX (corresponding author), Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65211 USA.
EM yzd3b@mail.missouri.edu; calyamp@missouri.edu;
   joshitr@health.missouri.edu; nairs@missouri.edu; xudong@missouri.edu
RI Zhang, Yuanxun/W-3719-2019
FU National Science Foundation [OAC-1730655]
FX This material is based upon work supported by the National Science
   Foundation under award number OAC-1730655. Any opinions, findings, and
   conclusions or recommendations expressed in this publication are those
   of the author(s) and do not necessarily reflect the views of the
   National Science Foundation.
CR Blei D. M., 2006, ICML, P113, DOI DOI 10.1145/1143844.1143859
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Carnevale NT, 2006, NEURON BOOK
   Davison Andrew P, 2008, Front Neuroinform, V2, P11, DOI 10.3389/neuro.11.011.2008
   Deelman E., 2005, Scientific Programming, V13, P219
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Flaherty P, 2005, BIOINFORMATICS, V21, P3286, DOI 10.1093/bioinformatics/bti515
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Hoffman M., 2010, ADV NEURAL INFORM PR, V23, P856, DOI DOI 10.1073/PNAS.0307750100
   Lafferty JD, 2006, ADV NEURAL INFORM PR, V18, P147
   Liu Y, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1227-y
   Migliore M, 2003, NEUROINFORMATICS, V1, P135, DOI 10.1385/NI:1:1:135
   Mimno D, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P500
   Rosen-Zvi M., 2004, P 20 C UNC ART INT, P487, DOI DOI 10.1016/J.NIMA.2010.11.062
   Sun H, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1486, DOI 10.1145/2623330.2623722
   Tang Jie, 2012, P 18 ACM SIGKDD INT, P1285, DOI DOI 10.1145/2339530.2339730
   Wang C., 2011, P 17 ACM SIGKDD INT, V9, P448, DOI DOI 10.1145/2020408.2020480
NR 17
TC 3
Z9 3
U1 0
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2639-1589
BN 978-1-5386-5035-6
J9 IEEE INT CONF BIG DA
PY 2018
BP 4886
EP 4895
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BM7WO
UT WOS:000468499304143
DA 2022-08-02
ER

PT C
AU Buisine, S
   Aoussat, A
   Martin, JC
AF Buisine, Stephanie
   Aoussat, Ameziane
   Martin, Jean-Claude
BE Pelachaud, C
   Martin, JC
   Andre, E
   Chollet, G
   Karpouzis, K
   Pele, D
TI Embodied creative agents: A preliminary social-cognitive framework
SO INTELLIGENT VIRTUAL AGENTS, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 7th International Conference on Intelligent Virtual Agents
CY SEP 17-19, 2007
CL Paris, FRANCE
SP &ftgroup France Telecom, European Project IST FP6 Callas, Springer, Assoc Advancement Artificial Intelligence, Eurograph, FP6 IST Humaine Network Excellence, ACM SIGCHI, ACM SIGART, Univ Paris 8, LIMSI-CNRS, Univ Augsburg, ENST, Natl Tech Univ Athens, France Telecom
DE embodied conversational agents; creativity; brainstorming; facilitator;
   expressivity; personality
ID IDEA GENERATION; PERFORMANCE; PERSONALITY; FACE; PRODUCTIVITY;
   STIMULATION; PARTNERS; BLOCKING
AB The goal of this paper is to open discussion about industrial creativity as a potential application field for Embodied Conversational Agents. We introduce the domain of creativity and especially focus on a collective creativity tool, the brainstorming: we present the related research in Psychology which has identified several key cognitive and social mechanisms that influence brainstorming process and outcome. However, some dimensions remain unexplored, such as the influence of the partners' personality or the facilitator's personality on idea generation. We propose to explore these issues, among others, using Embodied Conversational Agents. The idea seems original given that Embodied Agents were never included into brainstorming computer tools. We draw some hypotheses and a research program, and conclude on the potential benefits for the knowledge on creativity process on the one hand, and for the field of Embodied Conversational Agents on the other hand.
C1 [Buisine, Stephanie; Aoussat, Ameziane] ENSAM LCPI, 151 Bd Hop, F-75013 Paris, France.
   [Martin, Jean-Claude] CNRS, LIMSI, F-91403 Orsay, France.
RP Buisine, S (corresponding author), ENSAM LCPI, 151 Bd Hop, F-75013 Paris, France.
EM stephanie.buisine@paris.ensam.fr
CR ANDRE E, 1999, WORKSH AFF INT GEN I, P136
   [Anonymous], 2005, P 4 INT JOINT C AUT, DOI DOI 10.1145/1082473.1082478
   BARTIS S, 1988, PERS SOC PSYCHOL B, V14, P242, DOI 10.1177/0146167288142003
   Beun RJ, 2003, LECT NOTES ARTIF INT, V2792, P315
   Bevacqua E, 2004, COMPUT ANIMAT VIRT W, V15, P297, DOI 10.1002/cav.32
   Bolin AU, 2006, J BUS PSYCHOL, V20, P565, DOI 10.1007/s10869-005-9000-7
   Bonnardel N, 2006, CREATIVITE CONCEPTIO
   BOUCHARD TJ, 1969, J APPL PSYCHOL, V53, P1, DOI 10.1037/h0026747
   Brown VR, 2002, CURR DIR PSYCHOL SCI, V11, P208, DOI 10.1111/1467-8721.00202
   Buisine S, 2006, LECT NOTES ARTIF INT, V4133, P93
   Burleson W, 2005, INT J HUM-COMPUT ST, V63, P436, DOI 10.1016/j.ijhcs.2005.04.007
   CAMACHO LM, 1995, J PERS SOC PSYCHOL, V68, P1071, DOI 10.1037/0022-3514.68.6.1071
   Candy L., 2003, INTERACTIONS, V10, P44, DOI DOI 10.1145/838830.838833
   COOPER B, 2001, ED TECHNOLOGY SOC, V4
   Csikszentmihalyi M., 1996, CREATIVITY FLOW PSYC
   de Rosis F, 2003, INT J HUM-COMPUT ST, V59, P81, DOI 10.1016/S1071-5819(03)00020-X
   DENNIS AR, 1993, J APPL PSYCHOL, V78, P531, DOI 10.1037/0021-9010.78.4.531
   DENNIS AR, 2002, TR1161 KELL SCH BUS
   DeRosa DM, 2007, COMPUT HUM BEHAV, V23, P1549, DOI 10.1016/j.chb.2005.07.003
   DIEHL M, 1987, J PERS SOC PSYCHOL, V53, P497, DOI 10.1037/0022-3514.53.3.497
   DITKOFF M, 2004, 10 PERSONAS BRAINSTO
   Dugosh KL, 2000, J PERS SOC PSYCHOL, V79, P722, DOI 10.1037/0022-3514.79.5.722
   Dugosh KL, 2005, J EXP SOC PSYCHOL, V41, P313, DOI 10.1016/j.jesp.2004.05.009
   ELLIS CA, 1991, COMMUN ACM, V34, P38
   FAROOQ U, 2005, ACM CROSSROADS, V12, P6
   Feist G J, 1998, Pers Soc Psychol Rev, V2, P290, DOI 10.1207/s15327957pspr0204_5
   FURNHAM A, 1995, PERS INDIV DIFFER, V19, P73, DOI 10.1016/0191-8869(95)00009-U
   GALLUPE RB, 1994, J APPL PSYCHOL, V79, P77, DOI 10.1037/0021-9010.79.1.77
   GALLUPE RB, 1991, J APPL PSYCHOL, V76, P137, DOI 10.1037/0021-9010.76.1.137
   GILLIES M, 2003, LNCS LNAI, V2792
   Goncalo JA, 2006, ORGAN BEHAV HUM DEC, V100, P96, DOI 10.1016/j.obhdp.2005.11.003
   HARKINS SG, 1985, PERS SOC PSYCHOL B, V11, P457, DOI 10.1177/0146167285114011
   HYMES CM, 1992, UNBLOCKING BRAINSTOR, P99
   Isaksen S., 2000, CREATIVE APPROACHES
   Kerr DS, 2004, GROUP DECIS NEGOT, V13, P381, DOI 10.1023/B:GRUP.0000042960.38411.52
   Kim Y, 2006, ETR&D-EDUC TECH RES, V54, P569, DOI 10.1007/s11423-006-0637-3
   Kramer TJ, 2001, SMALL GR RES, V32, P533, DOI 10.1177/104649640103200502
   KSHIRSAGAR S, 2002, SMARTGRAPH 02, P107
   Lubart T, 2005, INT J HUM-COMPUT ST, V63, P365, DOI 10.1016/j.ijhcs.2005.04.002
   Martin JC, 2006, INT J HUM ROBOT, V3, P269, DOI 10.1142/S0219843606000825
   MAYA V, 2004, AISB 04
   Michinov N, 2005, COMPUT HUM BEHAV, V21, P11, DOI 10.1016/j.chb.2004.02.004
   Moreno R, 2001, COGNITION INSTRUCT, V19, P177, DOI 10.1207/S1532690XCI1902_02
   Nijstad BA, 2003, J EXP SOC PSYCHOL, V39, P531, DOI 10.1016/S0022-1031(03)00040-4
   Nijstad BA, 2002, J EXP SOC PSYCHOL, V38, P535, DOI 10.1016/S0022-1031(02)00500-0
   Nishimoto K, 1996, KNOWL-BASED SYST, V9, P377, DOI 10.1016/S0950-7051(96)01050-7
   Noot H, 2003, LECT NOTES ARTIF INT, V2915, P324
   Offner AK, 1996, SMALL GR RES, V27, P283, DOI 10.1177/1046496496272005
   Osborn A. F, 1953, APPL IMAGINATION PRI
   Oxley NL, 1996, J SOC BEHAV PERS, V11, P633
   PARNES SJ, 1959, J EDUC PSYCHOL, V80, P176
   PAULUS PB, 1993, J PERS SOC PSYCHOL, V64, P575, DOI 10.1037/0022-3514.64.4.575
   PAULUS PB, 2006, THEORY RES PRACTICE, V10, P206
   Rist T, 2004, COG TECH, P377
   Rothenberg A, 1993, PSYCHOL INQ, V4, P217
   ROUSSEAU D, 1998, SOCIAL PSYCHOL MODEL, P165
   Roy MC, 1996, SMALL GR RES, V27, P215, DOI 10.1177/1046496496272002
   Ryokai K, 2003, J COMPUT ASSIST LEAR, V19, P195, DOI 10.1046/j.0266-4909.2003.00020.x
   Sandercock J, 2006, LECT NOTES ARTIF INT, V4133, P357
   Shneiderman B, 2006, INT J HUM-COMPUT INT, V20, P61, DOI 10.1207/s15327590ijhc2002_1
   Shneiderman B., 2000, ACM Transactions on Computer-Human Interaction, V7, P114, DOI 10.1145/344949.345077
   STERNBERG RJ, 1998, CREATING PERSONALITI
   TRAPPL R, 1997, CREATING PERSONALITI
   TURNER WM, 1965, PSYCHOL REP, V17, P753, DOI 10.2466/pr0.1965.17.3.753
   VALACICH JS, 2004, ORG BEHAV HUMAN DECI, V57, P448
   van Mulken S, 1998, PEOPLE AND COMPUTER XIII, PROCEEDINGS, P53
   VanGundy A. B, 2008, 101 ACTIVITIES TEACH, V1st
   Vinayagamoorthy V., 2006, EUROGRAPHICS STATE A
   Wallgren MK, 1998, J CREATIVE BEHAV, V32, P134, DOI 10.1002/j.2162-6057.1998.tb00811.x
   WEISSKOPFJOELSON E, 1961, J APPL PSYCHOL, V45, P45, DOI 10.1037/h0042157
NR 70
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-540-74996-7
J9 LECT NOTES ARTIF INT
PY 2007
VL 4722
BP 304
EP +
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BGR56
UT WOS:000250108100028
DA 2022-08-02
ER

PT C
AU Varghese, E
   Pillai, MTR
AF Varghese, Enza
   Pillai, M. T. Rajappan
GP IEEE
TI A STANDALONE GENERATIVE CONVERSATIONAL INTERFACE USING DEEP LEARNING
SO PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE
   COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT)
LA English
DT Proceedings Paper
CT International Conference on Inventive Communication and Computational
   Technologies (ICICCT)
CY APR 20-21, 2018
CL Coimbatore, INDIA
SP IEEE, Ranganathan Engn Coll
DE Conversational agents; Chatbots; Generative framework; Closed domain
AB Conversational agents is an intuitive agent that conduct by means of text and audio mode. In the modern era, conversational agents with generative based have fast notoriety in all areas. The development of conversational agents has opened up new space of the client engagement and better approaches for working together as conversational trade. It is a most valuable innovation that supplanting the customary models and making applications and sites inessential. The most fascinating element of the bots is that they gain from the past interactions and become more brilliant over the time. The working of conversational models is in two ways and they are rule based and smart machine based. Rule based models take after predefined rules to do tasks and smart machine-based models are self-learning and utilize machine learning to do work Today generally all the developed generative conversational interfaces are utilizing deep learning. The principle objective of the proposed framework is to actualize a generative conversational interface by using deep learning. Furthermore, the suggested framework comes about on, the formation of responses based on the dynamic knowledge base and the current input in a closed domain.
C1 [Varghese, Enza; Pillai, M. T. Rajappan] Jyothi Engn Coll, Dept CSE, Trichur, India.
RP Varghese, E (corresponding author), Jyothi Engn Coll, Dept CSE, Trichur, India.
CR John A.K., 2017, LECT NOTES COMPUTER
   Martens James, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P479, DOI 10.1007/978-3-642-35289-8_27
   Mesnil G, 2015, IEEE-ACM T AUDIO SPE, V23, P530, DOI 10.1109/TASLP.2014.2383614
   Mikolov T., 2012, IEEE SLT
   Pichponreay L, 2016, INT CONF UBIQ FUTUR, P1002, DOI 10.1109/ICUFN.2016.7536948
   Ryu PM, 2014, INFORM PROCESS MANAG, V50, P683, DOI 10.1016/j.ipm.2014.04.007
   Schuller B., 2013, COMPUTATIONAL PARALI
   Searle JR, 2013, SPEECH ACT THEORY PR
   Sutskever I., 2014, ADV NEURAL INFORM PR
   Varghese Enza, 2017, INT J ADV RES SCI EN, V06
   Wallace R. S., 2009, PARSING TURING TEST, P181, DOI DOI 10.1007/978-1-4020-6710-5_13
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wu Y, 2008, IFIP INT C NETW PARA, P242, DOI 10.1109/NPC.2008.24
NR 13
TC 2
Z9 2
U1 0
U2 5
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-5386-1974-2
PY 2018
BP 1915
EP 1920
PG 6
WC Computer Science, Theory & Methods; Engineering, Electrical &
   Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BL8FP
UT WOS:000456251700379
DA 2022-08-02
ER

PT B
AU Perez-Marin, D
   Pascual-Nieto, I
AF Perez-Marin, Diana
   Pascual-Nieto, Ismael
BA PerezMarin, D
   PascualNieto, I
BF PerezMarin, D
   PascualNieto, I
TI Conversational Agents and Natural Language Interaction: Techniques and
   Effective Practices Preface
SO CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND
   EFFECTIVE PRACTICES
LA English
DT Editorial Material; Book Chapter
C1 [Perez-Marin, Diana] Univ Rey Juan Carlos, Fac Comp Sci, Dept Comp Languages & Syst 1, Mostoles, Spain.
   [Pascual-Nieto, Ismael] Univ Autonoma Madrid, Dept Comp Sci, E-28049 Madrid, Spain.
   [Pascual-Nieto, Ismael] UNED Spain, ADENU Artificial Intelligence Grp, Madrid, Spain.
RP Perez-Marin, D (corresponding author), Univ Rey Juan Carlos, Fac Comp Sci, Dept Comp Languages & Syst 1, Mostoles, Spain.
RI Pérez-Marín, Diana/ABF-6641-2021
OI Pérez-Marín, Diana/0000-0003-3390-0251
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IGI GLOBAL
PI HERSEY
PA 701 E CHOCOLATE AVE, STE 200, HERSEY, PA 17033-1240 USA
BN 978-1-60960-618-3
PY 2011
BP XIV
EP XVII
D2 10.4018/978-1-60960-617-6
PG 4
WC Computer Science, Artificial Intelligence
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BZX29
UT WOS:000303201400001
DA 2022-08-02
ER

PT C
AU Bittner, EAC
   Oeste-Reiss, S
   Leimeister, JM
AF Bittner, Eva A. C.
   Oeste-Reiss, Sarah
   Leimeister, Jan Marco
BE Bui, TX
TI Where is the Bot in our Team? Toward a Taxonomy of Design Option
   Combinations for Conversational Agents in Collaborative Work
SO PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM
   SCIENCES
LA English
DT Proceedings Paper
CT 52ndHawaii International Conference on System Sciences (HICSS)
CY JAN 08-11, 2019
CL HI
ID FRAMEWORK; SUPPORT
AB With rapid progress in machine learning, language technologies and artificial intelligence, conversational agents (CAs) gain rising attention in research and practice as potential non-human teammates, facilitators or experts in collaborative work. However, designers of CAs in collaboration still struggle with a lack of comprehensive understanding of the vast variety of design options in the dynamic field. We address this gap with a taxonomy to help researchers and designers understand the design space and the interrelations of different design options and recognize useful design option combinations for their CAs. We present the iterative development of a taxonomy for the design of CAs grounded in state of the art literature and validated with domain experts. We identify recurring design option combinations and white spots from the classified objects that will inform further research and development efforts.
C1 [Bittner, Eva A. C.] Univ Hamburg, Hamburg, Germany.
   [Oeste-Reiss, Sarah] Kassel Univ, Kassel, Germany.
   [Leimeister, Jan Marco] Univ St Gallen, St Gallen, Switzerland.
RP Bittner, EAC (corresponding author), Univ Hamburg, Hamburg, Germany.
EM bittner@informatik.uni-hamburg.de; oeste-reiss@uni-kassel.de;
   JanMarco.Leimeister@unisg.ch
CR Abu Shawar BA and Atwell ES, 2007, J LANG TECHNOL COMPU, V22, P29
   Allen J., 2002, 1 INT JOINT C AUT AG
   Bickmore TW, 2010, INTERACT COMPUT, V22, P276, DOI 10.1016/j.intcom.2010.02.001
   Bradesko L, 2017, ACM T INFORM SYST, V35, DOI 10.1145/3086686
   Briggs R. O., 2018, HAW INT C SYST SCI H
   Briggs RO, 2013, J MANAGE INFORM SYST, V29, P159, DOI 10.2753/MIS0742-1222290406
   Chaves AP, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173765
   Corti K, 2016, COMPUT HUM BEHAV, V58, P431, DOI 10.1016/j.chb.2015.12.039
   Dale R, 2016, NAT LANG ENG, V22, P811, DOI 10.1017/S1351324916000243
   De Angeli A, 2008, INTERACT COMPUT, V20, P302, DOI 10.1016/j.intcom.2008.02.004
   DEVREEDE GJ, 2005, 38 HAW INT C SYST SC
   Dohsaka K., 2009, SIGDIAL 2009 C
   Dyke G, 2013, IEEE T LEARN TECHNOL, V6, P240, DOI 10.1109/TLT.2013.25
   Eisman EM, 2012, EXPERT SYST APPL, V39, P3135, DOI 10.1016/j.eswa.2011.08.177
   Gregor S, 2006, MIS QUART, V30, P611
   Hasler BS, 2013, COMPUT HUM BEHAV, V29, P1608, DOI 10.1016/j.chb.2013.01.004
   Hayashi Y., 2013, 2013 IEEE RO MAN
   Hill J, 2015, COMPUT HUM BEHAV, V49, P245, DOI 10.1016/j.chb.2015.02.026
   Hubal RC, 2008, COMPUT HUM BEHAV, V24, P1104, DOI 10.1016/j.chb.2007.03.010
   Kolfschoten GL, 2006, INT J HUM-COMPUT ST, V64, P611, DOI 10.1016/j.ijhcs.2006.02.002
   Kumar R., 2010, HUM LANG TECHN 2010
   Kumar R, 2014, ACM T INTERACT INTEL, V3, DOI 10.1145/2499672
   Lieberman H., 1997, ACM SIGCHI C HUM FAC
   Louvet JB, 2017, PROCEDIA COMPUT SCI, V112, P377, DOI 10.1016/j.procs.2017.08.218
   Mell J., 2015, INT 2015 C AUT AG MU
   Nickerson RC, 2013, EUR J INFORM SYST, V22, P336, DOI 10.1057/ejis.2012.26
   Nunamaker JF, 2014, ADV MANAG INFORM SYS, P1
   Petter S, 2010, DATA BASE ADV INF SY, V41, P9, DOI 10.1145/1851175.1851177
   Porcheron M., 2015, 2015 INT C AUT AG MU
   Portela M., 2017, 18 INT C HUM COMP IN
   Prendinger H., 2002, AAMAS 02
   Rehm M, 2008, INTERACT COMPUT, V20, P311, DOI 10.1016/j.intcom.2008.02.005
   Rich C., 2002, AAMAS 02
   Roda C, 2003, INTERACT COMPUT, V15, P57, DOI 10.1016/S0953-5438(02)00029-2
   Tegos S., 2012, 4 INT C INT NETW COL
   Tegos S., 2012, 12 INT C ADV LEARN T
   Tegos S., 2014, 14 INT C ADV LEARN T
   Tegos S, 2015, COMPUT EDUC, V87, P309, DOI 10.1016/j.compedu.2015.07.014
   Tegos S, 2014, 2014 INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKING AND COLLABORATIVE SYSTEMS (INCOS), P176, DOI 10.1109/INCoS.2014.66
   Traumer F., 2017, INT C INF SYST
   Turunen M, 2011, COMPUT SPEECH LANG, V25, P192, DOI 10.1016/j.csl.2010.04.004
   Uthus D.C., 2013, ARTIFICIAL INTELLIGE
   von der Putten AM, 2010, COMPUT HUM BEHAV, V26, P1641, DOI 10.1016/j.chb.2010.06.012
   Xu A., 2017, CHI C HUM FACT COMP
   Xu K, 2017, COMPUT HUM BEHAV, V74, P152, DOI 10.1016/j.chb.2017.04.043
   Zadrozny W, 2000, COMMUN ACM, V43, P116, DOI 10.1145/345124.345164
NR 46
TC 3
Z9 3
U1 1
U2 2
PU HICSS
PI Honolulu
PA Dept IT Mgmt, Shidler College of Business, Univ Hawaii at Manoa 2404
   Maile Way D307, Honolulu, Hawaii, UNITED STATES
BN 978-0-9981331-2-6
PY 2019
BP 284
EP 293
PG 10
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ9KL
UT WOS:000625294900036
DA 2022-08-02
ER

PT J
AU Vaidyam, AN
   Linggonegoro, D
   Torous, J
AF Vaidyam, Aditya Nrusimha
   Linggonegoro, Danny
   Torous, John
TI Changes to the Psychiatric Chatbot Landscape: A Systematic Review of
   Conversational Agents in Serious Mental Illness: Changements du paysage
   psychiatrique des chatbots: une revue systematique des agents
   conversationnels dans la maladie mentale serieuse
SO CANADIAN JOURNAL OF PSYCHIATRY-REVUE CANADIENNE DE PSYCHIATRIE
LA English
DT Review
DE conversational agent; chatbot; mental health; serious mental illness;
   psychiatry
ID VIRTUAL AGENT; HEALTH
AB Objective:
   The need for digital tools in mental health is clear, with insufficient access to mental health services. Conversational agents, also known as chatbots or voice assistants, are digital tools capable of holding natural language conversations. Since our last review in 2018, many new conversational agents and research have emerged, and we aimed to reassess the conversational agent landscape in this updated systematic review.
   Methods:
   A systematic literature search was conducted in January 2020 using the PubMed, Embase, PsychINFO, and Cochrane databases. Studies included were those that involved a conversational agent assessing serious mental illness: major depressive disorder, schizophrenia spectrum disorders, bipolar disorder, or anxiety disorder.
   Results:
   Of the 247 references identified from selected databases, 7 studies met inclusion criteria. Overall, there were generally positive experiences with conversational agents in regard to diagnostic quality, therapeutic efficacy, or acceptability. There continues to be, however, a lack of standard measures that allow ease of comparison of studies in this space. There were several populations that lacked representation such as the pediatric population and those with schizophrenia or bipolar disorder. While comparing 2018 to 2020 research offers useful insight into changes and growth, the high degree of heterogeneity between all studies in this space makes direct comparison challenging.
   Conclusions:
   This review revealed few but generally positive outcomes regarding conversational agents' diagnostic quality, therapeutic efficacy, and acceptability, which may augment mental health care. Despite this increase in research activity, there continues to be a lack of standard measures for evaluating conversational agents as well as several neglected populations. We recommend that the standardization of conversational agent studies should include patient adherence and engagement, therapeutic efficacy, and clinician perspectives.
C1 [Vaidyam, Aditya Nrusimha; Linggonegoro, Danny; Torous, John] Harvard Med Sch, Beth Israel Deaconess Med Ctr, Boston, MA 02115 USA.
RP Torous, J (corresponding author), Beth Israel Deaconess Med Ctr, 330 Brookline Ave, Boston, MA 02215 USA.
EM jtorous@bidmc.harvard.edu
OI Vaidyam, Aditya/0000-0002-2900-4561
FU NIMH NIH HHS [K23 MH116130] Funding Source: Medline
CR Adekunle L, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.m7
   [Anonymous], 2020, SMART AUD REP
   [Anonymous], 2020, DEPRESSION
   Bendig E., 2019, VERHALTENSTHERAPIE, P1, DOI [10.1159/000501812, DOI 10.1159/000501812]
   Bickmore TW, 2018, J MED INTERNET RES, V20, DOI 10.2196/11510
   Bickmore TW, 2010, INTERACT COMPUT, V22, P289, DOI 10.1016/j.intcom.2009.12.001
   Bickmore TW, 2010, INTERACT COMPUT, V22, P276, DOI 10.1016/j.intcom.2010.02.001
   Dieleman JL, 2016, JAMA-J AM MED ASSOC, V316, P2627, DOI 10.1001/jama.2016.16885
   Doraiswamy PM, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101753
   Feldman Mitchell J, 2012, J Grad Med Educ, V4, P227, DOI 10.4300/JGME-D-11-00180.1
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Flowers L., 2017, INSIGHT ISSUES, V125, P1119
   Fulmer R, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/mental.9782
   Gaffney H, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/14166
   Gardiner PM, 2017, PATIENT EDUC COUNS, V100, P1720, DOI 10.1016/j.pec.2017.04.015
   Inkster B, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/12106
   Jungmann Stefanie Maria, 2019, JMIR Form Res, V3, pe13863, DOI 10.2196/13863
   Kessler RC, 2005, ARCH GEN PSYCHIAT, V62, P593, DOI 10.1001/archpsyc.62.6.593
   Kocaballi AB, 2020, J MED INTERNET RES, V22, DOI 10.2196/15823
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lucas GM, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00051
   Ly KH, 2017, INTERNET INTERV, V10, P39, DOI 10.1016/j.invent.2017.10.002
   Martinez-Miranda J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1387-1
   Miner AS, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00746
   Miner AS, 2017, JAMA-J AM MED ASSOC, V318, P1217, DOI 10.1001/jama.2017.14151
   Miner AS, 2016, JAMA INTERN MED, V176, P619, DOI 10.1001/jamainternmed.2016.0400
   Pew Research Center, 2020, VOIC ASS US 46 AM MO
   Philip P, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-019-0213-y
   Philip P, 2017, SCI REP-UK, V7, DOI 10.1038/srep42656
   Provoost S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01065
   Shinozaki T, 2015, COMPUTING, V97, P3, DOI 10.1007/s00607-013-0352-y
   Smith AC, 2020, J TELEMED TELECARE, V26, P309, DOI 10.1177/1357633X20916567
   Suganuma S, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/10454
   Tielman ML, 2017, TECHNOL HEALTH CARE, V25, P1081, DOI 10.3233/THC-170899
   Tielman ML, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0771-y
   Torous J, 2020, JMIR MENT HEALTH, V7, DOI 10.2196/18848
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   Wainberg ML, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0780-z
NR 38
TC 4
Z9 4
U1 7
U2 15
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0706-7437
EI 1497-0015
J9 CAN J PSYCHIAT
JI Can. J. Psychiat.-Rev. Can. Psychiat.
PD APR
PY 2021
VL 66
IS 4
BP 339
EP 348
DI 10.1177/0706743720966429
EA OCT 2020
PG 10
WC Psychiatry
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychiatry
GA RM9UM
UT WOS:000649140400001
PM 33063526
OA Green Published, Bronze
DA 2022-08-02
ER

PT C
AU Lee, M
   Lee, S
AF Lee, Minha
   Lee, Sangsu
GP ACM
TI "I Don't Know Exactly but I Know a Litle": Exploring Beter Responses of
   Conversational Agents with Insufficient Information
SO EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN
   COMPUTING SYSTEMS (CHI'21)
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems
CY MAY 08-13, 2021
CL ELECTR NETWORK
SP ACM SIGCHI, Assoc Comp Machinery, Bloomberg, Facebook, Google, Kyocera, Microsoft, Monash Univ, Verizon Media
DE conversational agent(CA); conversational system; voice user
   interface(VUI); usability; user experience; inference; related
   information
AB Despite the increasing presence of conversational agents (CAs) in our daily lives, the lack of information and technology behind them prevents CAs from answering many questions. One of the most typical problems facing conversational user interfaces today is that they often disappoint people by giving the same answer (e.g., "I don't know"). In this work, we focused on situations in which CAs do not provide a proper answer because of a lack of information. Under these situations, we aimed to find more effective answer strategies for CAs to provide people better user experiences. We tested four different response strategies using different degrees of inferences and information as ground. We found differences in usability and user experience depending on how CAs respond. Our results will help designers understand how people feel about the way CAs respond and create better CA responses in situations where it is difficult to provide accurate answers.
C1 [Lee, Minha; Lee, Sangsu] Korea Adv Inst Sci & Technol, Dept Ind Design, Daejeon, South Korea.
RP Lee, M (corresponding author), Korea Adv Inst Sci & Technol, Dept Ind Design, Daejeon, South Korea.
EM minha.lee@kaist.ac.kr; sangsu.lee@kaist.ac.kr
CR Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Bentley Frank, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3264901
   Bohus D., 2008, P 6 SIGDIAL WORKSHOP, P123
   Brooke J., 1996, USABILITY EVAL IND, V189, P4
   Cho M, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P1557, DOI 10.1145/3322276.3322332
   DAHLBACK N, 1993, KNOWL-BASED SYST, V6, P258, DOI 10.1016/0950-7051(93)90017-N
   Engelhardt PE, 2006, J MEM LANG, V54, P554, DOI 10.1016/j.jml.2005.12.009
   Ghosh D, 2018, PROCEEDINGS OF CHINESE CHI 2018: SIXTH INTERNATIONAL SYMPOSIUM OF CHINESE CHI (CHINESE CHI 2018), P11, DOI 10.1145/3202667.3204844
   HIRST G, 1994, SPEECH COMMUN, V15, P213, DOI 10.1016/0167-6393(94)90073-6
   Horvitz E., 1997, USER MODELING, P441
   Jeong J., 2015, INT C HUM COMP INT, P284, DOI DOI 10.1007/978-3-319-20916-6_27
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Murad C, 2019, PROCEEDINGS OF THE 1ST INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES (CUI 2019), DOI 10.1145/3342775.3342795
   Paek T., 2000, P 16 C UNC ART INT S, P455
   Sanders G.A., 2002, 7 INT C SPOK LANG PR
   Vtyurina A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173782
NR 16
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8095-9
PY 2021
DI 10.1145/3411763.3451812
PG 5
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7DM
UT WOS:000759178502122
DA 2022-08-02
ER

PT C
AU Kimani, E
   Rowan, K
   McDuff, D
   Czerwinski, M
   Mark, G
AF Kimani, Everlyne
   Rowan, Kael
   McDuff, Daniel
   Czerwinski, Mary
   Mark, Gloria
GP IEEE
TI A Conversational Agent in Support of Productivity and Wellbeing at Work
SO 2019 8TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT
   INTERACTION (ACII)
SE International Conference on Affective Computing and Intelligent
   Interaction
LA English
DT Proceedings Paper
CT 8th International Conference on Affective Computing and Intelligent
   Interaction (ACII)
CY SEP 03-06, 2019
CL Cambridge, ENGLAND
DE Conversational agents; personal digital assistants; workplace;
   productivity; personality; sensing
AB Conversational agents have the potential to support users in many tasks. However, support for productivity and well-being in the workplace has received little attention. We present the first design of a conversational system that supports information workers with multiple work-related goals, informed by a survey of the current and potential use of conversational agents in the workplace. The goals of this research include the evaluation of using an agent for scheduling and prioritizing tasks, switching tasks, providing break reminders, dealing with social media distractions and for end of the day reflection on tasks accomplished. We deployed a chat-based intelligent agent, named Amber, in a field study with 24 information workers over the course of 6 days. We present our preliminary findings from the field study and discuss implications for the design of future workplace conversational agents
C1 [Kimani, Everlyne] Northeastern Univ, Khoury Coll Comp Sci, Boston, MA 02115 USA.
   [Rowan, Kael; McDuff, Daniel; Czerwinski, Mary] Microsoft Res, Redmond, WA USA.
   [Mark, Gloria] Univ Calif Irvine, Dept Informat, Irvine, CA USA.
RP Kimani, E (corresponding author), Northeastern Univ, Khoury Coll Comp Sci, Boston, MA 02115 USA.
EM kimani15@ccs.neu.edu; kael.rowan@microsoft.com; damcduff@microsoft.com;
   marycz@microsoft.com; gmark@uci.edu
CR [Anonymous], 2004, P 2004 C HUMAN FACTO, DOI DOI 10.1145/985692.985707
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Brooks S, 2015, COMPUT HUM BEHAV, V46, P26, DOI 10.1016/j.chb.2014.12.053
   Cambo SA, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3595, DOI 10.1145/3025453.3026021
   Cohen J, 2017, ROUTLEDGE HBK PHILOS, P235
   Cranshaw J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2382, DOI 10.1145/3025453.3025780
   CZERWINSKI M, 2004, P SIGCHI C HUM FACT, P175, DOI DOI 10.1145/985692.985715
   Faulring A, 2010, IUI 2010, P61
   Fong T, 2003, SPR TRA ADV ROBOT, V6, P255
   Gil Yolanda, 2008, 13th International Conference on Intelligent User Interfaces. IUI 2008, DOI 10.1145/1378773.1378822
   Gross JJ, 2003, J PERS SOC PSYCHOL, V85, P348, DOI 10.1037/0022-3514.85.2.348
   Hassib M, 2017, 16TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2017), P305, DOI 10.1145/3152832.3152865
   Henry JD, 2005, BRIT J CLIN PSYCHOL, V44, P227, DOI 10.1348/014466505X29657
   Kaptelinin V., 2007, DESKTOP METAPHOR DES, V1
   Karasek R, 1998, J Occup Health Psychol, V3, P322, DOI 10.1037/1076-8998.3.4.322
   Kocielnik R, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P881, DOI 10.1145/3196709.3196784
   Li JY, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P275, DOI 10.1145/3025171.3025206
   Lutchyn Y, 2015, INT CONF AFFECT, P119, DOI 10.1109/ACII.2015.7344560
   Mark G., 2018, CHI 18
   Mark G., 2014, P 17 ACM C COMP SUPP, P1082, DOI DOI 10.1145/2531602.2531673
   Mark G, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT), P928, DOI 10.1145/3123024.3124558
   Mark G, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1739, DOI [10.1145/2858036.2858202, 10.1145/2858036.2858437, 10.1145/2858036.2858262]
   Mark G, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P903, DOI 10.1145/2675133.2675221
   McCrae R.R., 1999, HDB PERSONALITY, P139
   McDuff D., 2012, P SIGCHI C HUM FACT, P849, DOI DOI 10.1145/2207676.2208525
   McDuff Daniel, 2019, ARXIV190312133
   Robertson G., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P494
   Shamekhi A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173965
   Smit BW, 2016, J OCCUP ORGAN PSYCH, V89, P493, DOI 10.1111/joop.12137
   Sonnentag S, 2016, J OCCUP HEALTH PSYCH, V21, P379, DOI 10.1037/ocp0000020
   Storey MA, 2016, FSE'16: PROCEEDINGS OF THE 2016 24TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON FOUNDATIONS OF SOFTWARE ENGINEERING, P928, DOI 10.1145/2950290.2983989
   Wang H. J., 2015, ACTIVITY PLATFORM
   Whelan E, 2018, MIT SLOAN MANAGE REV, V59, P7
   Whittaker S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1729, DOI 10.1145/2858036.2858193
   Williams A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173662
NR 35
TC 2
Z9 2
U1 2
U2 4
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2156-8103
BN 978-1-7281-3888-6
J9 INT CONF AFFECT
PY 2019
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BO6TZ
UT WOS:000522220800065
DA 2022-08-02
ER

PT C
AU Mazuel, L
   Sabouret, N
AF Mazuel, Laurent
   Sabouret, Nicolas
BE Nishida, T
   Klusch, M
   Sycara, K
   Yokoo, M
   Liu, J
   Wah, B
   Cheung, W
   Cheung, YM
TI Generic command interpretation algorithms for conversational agents
SO 2006 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON INTELLIGENT AGENT
   TECHNOLOGY, PROCEEDINGS
LA English
DT Proceedings Paper
CT IEEE/WIC/ACM International Conference on Intelligent Agent Technology
CY DEC 18-22, 2006
CL Hong Kong, PEOPLES R CHINA
SP IEEE Comp Soc, Web Intelligence Consortium, ACM, Hong Kong Baptist Univ, IEEE, Microsoft Labs, Salford Syst
AB This paper focuses on the human-machine communication within the framework of intelligent agents. We propose a generic architecture provided with a natural language (NL) algorithm for command interpretation that can be adapted to different agent's domains. Our NL architecture only depends on the agent's code and its domain ontology. We consider two classical approaches for NL command interpretation: the top-down approach, which relies on the agent's model syntactical constraints, and the bottom-up approach which relies on the set of the agent's possible actions. We propose to combine both approaches in a bottom-up based algorithm that makes use of agent's constraints. We propose a comparative evaluation of these three algorithms.
C1 [Mazuel, Laurent; Sabouret, Nicolas] Lab Informat Paris 6, Paris, France.
RP Mazuel, L (corresponding author), Lab Informat Paris 6, Paris, France.
EM laurent.mazuel@lip6.fr; nicolas.sabouret@lip6.fr
CR ABRILIAN S, 2002, INT WORKSH LIF AN AG, P3
   ALLEN J, 1996, ACL, P62
   BATEMAN JA, 1997, NAT LANG ENG, V3, P15
   Bickmore TW, 2004, COMMUN ACM, V47, P38, DOI 10.1145/975817.975842
   Botella B., 2002, Technique et Science Informatiques, V21, P1163
   Budanitsky A, 2006, COMPUT LINGUIST, V32, P13, DOI 10.1162/coli.2006.32.1.13
   CASSEL J, 2000, EMBODIED CONVERSATIO
   CHARIFDJEBBAR Y, 2006, P 2 INT C INT ENV IE, P275
   Dzikovska MO, 2003, P IJCAI 03 WORKSH KN
   Ferber J, 1999, MULTIAGENT SYSTEMS
   *FIPA, 2002, FIPA ACL MESS STRUCT
   Garate A., 2005, P 2005 JOINT C SMART, P241, DOI DOI 10.1145/1107548.1107609
   MAES P, 1994, COMMUN ACM, V37, P31
   MILWARD D, 2000, ACL, P133
   Milward D., 2003, PROC 3 WORKSHOP KNOW, P9
   Paraiso EC, 2004, FRONT ARTIF INTEL AP, V110, P971
   PAUROBALLY S, 2005, W3C WORKSH FRAM SEM
   Pelachaud C, 2003, LECT NOTES ARTIF INT, V2792, P93
   Sabouret N, 2002, LECT NOTES ARTIF INT, V2296, P273
   SABOURET N, 2005, 1ST P WORKSH AG CONV, P13
   Sabouret Nicolas, 2001, P COMM SENS 2001, P217
   Sadek D., 1997, IJCAI 2, P1030
   Seneff S., 1992, Computational Linguistics, V18, P61
   SHAPIRO S, 2000, SNEPS LOGIC NATURAL, P175
   Smith M.K., 2004, OWL WEB ONTOLOGY LAN
   Winograd T., 1972, UNDERSTANDING NATURA
NR 26
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
BN 978-0-7695-2748-2
PY 2006
BP 146
EP +
DI 10.1109/IAT.2006.70
PG 2
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BFZ53
UT WOS:000245650000025
DA 2022-08-02
ER

PT C
AU Van Brummelen, J
   Tabunshchyk, V
   Heng, T
AF Van Brummelen, Jessica
   Tabunshchyk, Viktoriya
   Heng, Tommy
GP ASSOC COMP MACHINERY
TI "Alexa, Can I Program You?": Student Perceptions of Conversational
   Artificial Intelligence Before and After Programming Alexa
SO IDC '21: PROCEEDINGS OF INTERACTION DESIGN AND CHILDREN 2021
LA English
DT Proceedings Paper
CT 20th ACM Interaction Design and Children (IDC) Conference
CY JUN 24-30, 2021
CL ELECTR NETWORK
SP Assoc Comp Machinery, Natl & Kapodistrian Univ Athens, LUMS, BRIDGES, EUGAIN, NSF
DE child-agent interaction; conversational agents; pedagogical agent
   design; persona; AI education
ID AGENTS; CHILDREN
AB Growing up in an artificial intelligence-filled world, with Siri and Amazon Alexa often within arm's-or speech's-reach, could have significant impact on children. Conversational agents could influence how students anthropomorphize computer systems or develop a theory of mind. Previous research has explored how conversational agents are used and perceived by children within and outside of learning contexts. This study investigates how middle and high school students' perceptions of Alexa change through programming their own conversational agents in week-long AI education workshops. Specifically, we investigate the workshops' influence on student perceptions of Alexa's intelligence, friendliness, aliveness, safeness, trustworthiness, human-likeness, and feelings of closeness. We found that students felt Alexa was more intelligent and felt closer to Alexa after the workshops. We also found strong correlations between students' perceptions of Alexa's friendliness and trustworthiness, and safeness and trustworthiness. We recommend designers carefully consider personification, transparency, playfulness and utility when designing conversational agents for learning contexts.
C1 [Van Brummelen, Jessica; Tabunshchyk, Viktoriya; Heng, Tommy] MIT, Cambridge, MA 02139 USA.
RP Van Brummelen, J (corresponding author), MIT, Cambridge, MA 02139 USA.
EM jess@csail.mit.edu; vikt@mit.edu; theng@mit.edu
FU AFE program; Hong Kong Jockey Club Charities Trust
FX We thank the teachers and students, volunteer facilitators, MIT App
   Inventor team, Personal Robots Group, and Amazon Future Engineer (AFE)
   members who made theworkshops possible. Special thanks to Hal Abelson
   and Hilah Barbot. This work was funded by the AFE program and Hong Kong
   Jockey Club Charities Trust.
CR Adler RF, 2016, COMPUT HUM BEHAV, V57, P75, DOI 10.1016/j.chb.2015.12.011
   Al-Yagon M, 2004, J SPEC EDUC, V38, P111, DOI 10.1177/00224669040380020501
   Ali Safinah, 2019, P IJCAI 2019
   Baylor A. L., 2003, Journal of Educational Computing Research, V28, P373, DOI 10.2190/V0WQ-NWGN-JB54-FAT4
   Beun RJ, 2003, LECT NOTES ARTIF INT, V2792, P315
   Birch SH, 1997, J SCHOOL PSYCHOL, V35, P61, DOI 10.1016/S0022-4405(96)00029-5
   Bologna Caroline, 2021, LAVVIO
   Cohen J., 1988, STAT POWER ANAL BEHA, V2nd ed.
   Corti K, 2016, COMPUT HUM BEHAV, V58, P431, DOI 10.1016/j.chb.2015.12.039
   Damon W, 2004, ANN AM ACAD POLIT SS, V591, P13, DOI 10.1177/0002716203260092
   Dincer S, 2017, COMPUT EDUC, V111, P74, DOI 10.1016/j.compedu.2017.04.005
   DiPaola D, 2020, PROCEEDINGS OF IDC 2020, P1, DOI 10.1145/3392063.3394396
   Druga S, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P595, DOI 10.1145/3078072.3084330
   Druga S, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P231, DOI 10.1145/3202185.3202741
   Duit Reinders, 2009, DIAKSES PADA TANGGAL, V26
   Dunning D, 2011, ADV EXP SOC PSYCHOL, V44, P247, DOI 10.1016/B978-0-12-385522-0.00005-6
   Gachter S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129478
   Glisczinski D, 2018, J TRANSFORM EDUC, V16, P175, DOI 10.1177/1541344618777367
   Guadamuz Andres, 2017, INTELLECTUAL PROPERT, V2, P20
   Hu Q, 2021, INT J INFORM MANAGE, V56, DOI 10.1016/j.ijinfomgt.2020.102250
   Jaeger CB, 2019, COGN RES, V4, DOI 10.1186/s41235-019-0163-6
   Jaeger CB, 2016, J HUM-ROBOT INTERACT, V5, P3, DOI 10.5898/JHRI.5.3.Jaeger
   Kahn KM, 2018, AI PROGRAMMING CHILD, P11082
   Kahn PH, 2012, DEV PSYCHOL, V48, P303, DOI 10.1037/a0027033
   KREILKAMP T, 1984, AM BEHAV SCI, V27, P771, DOI 10.1177/000276484027006008
   Kuperman Asi, 2012, Interdisciplinary Journal of e-Learning and Learning Objects, V8, P137
   Large David R., 2019, Proceedings of the 20th Congress of the International Ergonomics Association (IEA 2018). Volume VI: Transport Ergonomics and Human Factors (TEHF), Aerospace Human Factors and Ergonomics. Advances in Intelligent Systems and Computing (823), P3, DOI 10.1007/978-3-319-96074-6_1
   Leelawong Krittaya, 2008, INT J ARTIFICIAL INT, V18, P181
   Levin DT, 2013, ACMIEEE INT CONF HUM, P373, DOI 10.1109/HRI.2013.6483612
   Levy ST, 2008, INT J TECHNOL DES ED, V18, P337, DOI 10.1007/s10798-007-9032-6
   Lin P, 2020, AAAI CONF ARTIF INTE, V34, P13438
   Long DR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376727
   Lovato SB, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P301, DOI 10.1145/3311927.3323150
   Meschtscherjakov A, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3170614
   Michaelis JE, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P71, DOI 10.1145/3311927.3323154
   Morales-Urrutia E. K., 2020, INNOVATIVE PERSPECTI, P66
   Papert S, 1991, CONSTRUCTIONISM
   Perez-Marin D, 2013, BEHAV INFORM TECHNOL, V32, P955, DOI 10.1080/0144929X.2012.687774
   Register Yim, 2020, ICER '20. Proceedings of the 2020 ACM Conference on International Computing Education Research, P67, DOI 10.1145/3372782.3406252
   Research and Markets, 2019, GLOB CONV AI MARK FO
   Rice Louis, 2009, J ED BUILT ENV, V4, P94, DOI [10.11120/jebe.2009.04020094, DOI 10.1112/0JEBE.2009.04020094]
   Rodriguez-Garcia Juan David, 2021, EVALUATION ONLINE IN
   Roselli D, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P539, DOI 10.1145/3308560.3317590
   SCAIFE M, 1995, BRIT J DEV PSYCHOL, V13, P367, DOI 10.1111/j.2044-835X.1995.tb00686.x
   Schobel Sofia, 2019, 40 INT C INF SYST
   Schuetzler RM, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P283
   Shank DB, 2014, INT J HUM-COMPUT ST, V72, P747, DOI 10.1016/j.ijhcs.2014.05.002
   Sherin B, 2013, J LEARN SCI, V22, P600, DOI 10.1080/10508406.2013.836654
   Skinner Rebecca R, 2019, R45977 CRS
   Sparks Hannah, 2019, MOM BUSTS 9 YEAR OLD
   Spektor-Precel K., 2015, P 14 INT C INT DES C, P311, DOI DOI 10.1145/2771839.2771904
   Spitale M, 2020, PROCEEDINGS OF IDC 2020, P262, DOI 10.1145/3392063.3394421
   Touretzky D, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P9795
   Van Brummelen J., 2019, THESIS MIT CAMBRIDGE
   Van Brummelen Jessica, 2021, P AAAI C ARTIFICIAL
   Wan XY, 2020, PROCEEDINGS OF IDC 2020, P23, DOI 10.1145/3392063.3394440
   Williams R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300677
   Wolber David, 2015, GETMOBILE MOBILE COM, V18, P53, DOI DOI 10.1145/2721914.2721935
   Wolter I, 2014, LEARN INDIVID DIFFER, V31, P59, DOI 10.1016/j.lindif.2013.12.008
   Wooldridge Michael, 2021, CHRONICLE
   Xu Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376416
   Zimmermann-Niefield A, 2020, PROCEEDINGS OF IDC 2020, P63, DOI 10.1145/3392063.3394438
NR 62
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8452-0
PY 2021
BP 305
EP 313
DI 10.1145/3459990.3460730
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7UZ
UT WOS:000767988500031
OA Bronze, Green Submitted
DA 2022-08-02
ER

PT C
AU Kunc, L
   Kleindienst, J
AF Kunc, Ladislav
   Kleindienst, Jan
BE Matousek, V
   Mautner, P
TI ECAF: Authoring language for embodied conversational agents
SO TEXT, SPEECH AND DIALOGUE, PROCEEDINGS
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 10th International Conference on Text, Speech, and Dialogue
CY SEP 03-07, 2007
CL Pilsen, CZECH REPUBLIC
AB Embodied Conversational Agent (ECA) is the user interface metaphor that allows to naturally communicate information during human-computer interaction in synergic modality dimensions, including voice, gesture, emotion, text, etc. Due to its anthropological representation and the ability to express human-like behavior, ECAs are becoming popular interface front-ends for dialog and conversational applications. One important prerequisite for efficient authoring of such ECA-based applications is the existence of a suitable programming language that exploits the expressive possibilities of multimodally blended messages conveyed to the user. In this paper, we present an architecture and interaction language ECAF, which we used for authoring several ECA-based applications. We also provide the feedback from usability testing we carried for user acceptance of several multimodal blending strategies.
C1 [Kunc, Ladislav] Czech Tech Univ, FEE, Dept Comp Sci & Engn, Tech 2, Prague 16627 6, Czech Republic.
   [Kleindienst, Jan] IBM Ceska RepublikaPraha, Prague 14800, Czech Republic.
RP Kunc, L (corresponding author), Czech Tech Univ, FEE, Dept Comp Sci & Engn, Tech 2, Prague 16627 6, Czech Republic.
CR FLEURY P, CONNECTING COMPUTERS
   GEDALIA P, EXPRESSION TOOLKIT O
   *HUMANML, HUM MARK LANG
   *IBM, 2005, EMB VIA VOIC MULT SO
   ISHIZUKA M, 2000, ACHIEVING HUMAN LIKE, P50
   NOT E, 2005, P ICMI05 TRENTO ITAL, P200
   PERLIN K, 1985, COMPUT GRAPH, V3, P287
   PIWEK P, 2003, AAMAS WORKSH 2002 LN, V2631
   SEGAL M, 1993, OPENGL GRAPHICS SYST
NR 9
TC 7
Z9 7
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 978-3-540-74627-0
J9 LECT NOTES ARTIF INT
PY 2007
VL 4629
BP 206
EP +
PG 2
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BGY32
UT WOS:000251315900027
DA 2022-08-02
ER

PT J
AU Nijholt, A
AF Nijholt, A
TI Embodied conversational agents: "A little humor too"
SO IEEE INTELLIGENT SYSTEMS
LA English
DT Editorial Material
C1 Univ Twente, Dept Comp Sci, NL-7500 AE Enschede, Netherlands.
RP Nijholt, A (corresponding author), Univ Twente, Dept Comp Sci, POB 217, NL-7500 AE Enschede, Netherlands.
EM anijholt@cs.utwente.nl
CR Cann A, 1997, HUMOR, V10, P77, DOI 10.1515/humr.1997.10.1.77
   COWIE R, 2000, P ISCA WORKSH SPEECH, P11
   Lappin S., 1994, Computational Linguistics, V20, P535
   Prendinger H., 2004, LIFE LIKE CHARACTERS
   Reeves B., 1996, MEDIA EQUATION PEOPL
   RITCHIE G, 1999, P AISB S ART INT CRE, P69
   Tannen D., 1984, CONVERSATIONAL STYLE
NR 7
TC 4
Z9 4
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1541-1672
EI 1941-1294
J9 IEEE INTELL SYST
JI IEEE Intell. Syst.
PD MAR-APR
PY 2006
VL 21
IS 2
BP 62
EP 64
PG 3
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 029ZY
UT WOS:000236604100017
DA 2022-08-02
ER

PT C
AU Leonhardt, M
AF Leonhardt, Michelle
GP AAAI
TI Enhancing Affective Communication in Embodied Conversational Agents
SO PROCEEDINGS OF THE TWENTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL
   INTELLIGENCE (AAAI-10)
LA English
DT Proceedings Paper
CT 24th AAAI Conference on Artificial Intelligence (AAAI)
CY JUL 11-15, 2010
CL Atlanta, GA
SP Assoc Advancement Artificial Intelligence
C1 [Leonhardt, Michelle] Univ Fed Rio Grande do Sul, POB 15064, BR-91501970 Porto Alegre, RS, Brazil.
RP Leonhardt, M (corresponding author), Univ Fed Rio Grande do Sul, POB 15064, BR-91501970 Porto Alegre, RS, Brazil.
CR Isbister K, 2004, HUM-COMPUT INT-SPRIN, V7, P3
   Jaques P., 2009, P COL C BRAZ INRIA 2, P195
   Pesty S., 2005, P 4 INT CENTR E EUR, P31
   RAO AS, 1991, P INT C PRINC KNOWL
NR 4
TC 0
Z9 0
U1 0
U2 0
PU ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE
PI PALO ALTO
PA 2275 E BAYSHORE RD, STE 160, PALO ALTO, CA 94303 USA
BN 978-1-57735-463-5
PY 2010
BP 1986
EP 1987
PG 2
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BG7ZA
UT WOS:000392059700340
DA 2022-08-02
ER

PT J
AU McGreevey, JD
   Hanson, CW
   Koppel, R
AF McGreevey, John D., III
   Hanson, C. William, III
   Koppel, Ross
TI Conversational Agents in Health Care In Reply
SO JAMA-JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION
LA English
DT Letter
C1 [McGreevey, John D., III; Hanson, C. William, III] Univ Penn, Perelman Sch Med, Univ Penn Hlth Syst, Philadelphia, PA 19104 USA.
   [Koppel, Ross] Univ Penn, Perelman Sch Med, Dept Sociol, Philadelphia, PA 19104 USA.
RP McGreevey, JD (corresponding author), Univ Penn Hlth Syst, 3400 Spruce St, Philadelphia, PA 19104 USA.
EM john.mcgreevey@pennmedicine.upenn.edu
RI McGreevey, John/AAC-2844-2022
CR Chambers D, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2018-027743
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Matheny ME., 2019, HLTH CARE HOPE HYPE
   McGreevey JD, 2020, JAMA-J AM MED ASSOC, V324, P552, DOI 10.1001/jama.2020.2724
   Semigran HL, 2015, BMJ-BRIT MED J, V351, DOI 10.1136/bmj.h3480
NR 5
TC 0
Z9 0
U1 0
U2 0
PU AMER MEDICAL ASSOC
PI CHICAGO
PA 330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA
SN 0098-7484
EI 1538-3598
J9 JAMA-J AM MED ASSOC
JI JAMA-J. Am. Med. Assoc.
PD DEC 15
PY 2020
VL 324
IS 23
BP 2444
EP 2445
DI 10.1001/jama.2020.21518
PG 3
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA PG8IH
UT WOS:000599972000025
PM 33320218
DA 2022-08-02
ER

PT J
AU Harms, JG
   Kucherbaev, P
   Bozzon, A
   Houben, GJ
AF Harms, Jan-Gerrit
   Kucherbaev, Pavel
   Bozzon, Alessandro
   Houben, Geert-Jan
TI Approaches for Dialog Management in Conversational Agents
SO IEEE INTERNET COMPUTING
LA English
DT Article
AB Dialog agents, like digital assistants and automated chat interfaces (e.g., chatbots), are becoming more and more popular as users adapt to conversing with their devices as they do with humans. In this paper, we present approaches and available tools for dialog management (DM), a component of dialog agents that handles dialog context and decides the next action for the agent to take. In this paper, we establish an overview of the field of DM, compare approaches and state-of-the-art tools in industry and research work on a set of dimensions, and identify directions for further research work.
C1 [Harms, Jan-Gerrit; Kucherbaev, Pavel; Bozzon, Alessandro] Delft Univ Technol, Web Informat Syst Grp, Delft, Netherlands.
   [Houben, Geert-Jan] Delft Univ Technol, Delft, Netherlands.
RP Harms, JG (corresponding author), Delft Univ Technol, Web Informat Syst Grp, Delft, Netherlands.
EM jan.gerrit.harms@gmail.com; pavel.kucherbaev@gmail.com;
   a.bozzon@tudelft.nl; g.j.p.m.houben@tudelft.nl
RI Houben, Geert-Jan/C-3934-2008
OI Houben, Geert-Jan/0000-0001-6827-9739; Bozzon,
   Alessandro/0000-0002-3300-2913
FU Amsterdam Institute for Advanced Metropolitan Solutions; AMS Social Bot
   grant
FX This work was supported by the Amsterdam Institute for Advanced
   Metropolitan Solutions with the AMS Social Bot grant.
CR Bocklisch T., 2017, RASA OPEN SOURCE LAN, P1
   Bordes A., 2016, ARXIV PREPRINT ARXIV
   COLBY KM, 1972, ARTIF INTELL, V3, P199, DOI 10.1016/0004-3702(72)90049-5
   Jurafksy D., 2017, SPEECH LANGUAGE PROC
   Kucherbaev P, 2018, IEEE INTERNET COMPUT, V22, P36, DOI 10.1109/MIC.2018.252095348
   Lison P, 2015, COMPUT SPEECH LANG, V34, P232, DOI 10.1016/j.csl.2015.01.001
   McTear  M., 2016, CONVERSATIONAL INTER, DOI [10.1007/978-3-319-32967-3_1, DOI 10.1007/978-3-319-32967-3_1]
   Traum DR, 2003, TEXT SPEECH LANG TEC, V22, P325
   Ultes S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P73, DOI 10.18653/v1/P17-4013
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Williams JD, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P665, DOI 10.18653/v1/P17-1062
   Young S, 2013, P IEEE, V101, P1160, DOI 10.1109/JPROC.2012.2225812
   2017, COMPUT SPEECH LANG, V45, P552, DOI DOI 10.1016/J.CSL.2016.09.003
NR 13
TC 21
Z9 21
U1 1
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1089-7801
EI 1941-0131
J9 IEEE INTERNET COMPUT
JI IEEE Internet Comput.
PD MAR-APR
PY 2019
VL 23
IS 2
SI SI
BP 13
EP 22
DI 10.1109/MIC.2018.2881519
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HV7UJ
UT WOS:000466185800002
OA Green Published
DA 2022-08-02
ER

PT C
AU Griol, D
   Callejas, Z
AF Griol, David
   Callejas, Zoraida
GP IEEE
TI Mobile Conversational Agents for stroke rehabilitation therapy
SO 2019 IEEE 32ND INTERNATIONAL SYMPOSIUM ON COMPUTER-BASED MEDICAL SYSTEMS
   (CBMS)
SE IEEE International Symposium on Computer-Based Medical Systems
LA English
DT Proceedings Paper
CT 32nd IEEE International Symposium on Computer-Based Medical Systems
   (IEEE CBMS)
CY JUN 05-07, 2019
CL Inst Maimonides Investigac Biomedica Cordoba, Cordoba, SPAIN
SP IEEE, IEEE Comp Soc, Univ Campus Bio Medico Roma, Hosp Univ Reina Sofia, Grupo Solutia, Grupo FIBRATEL, Tech Comm Computat Life Sci, IMIBIC
HO Inst Maimonides Investigac Biomedica Cordoba
DE Ambient Assisted Living; M-health; Stroke; Conversational interfaces;
   Mobile devices; Multimodal interaction
ID HEALTH DIALOG
AB Mobile health (m-Health) has emerged as a rapidly developing area that is transforming clinical research and health care on a global scale. In this paper, we describe a conversational app for the therapy of stroke rehabilitation. The main objective of the conversational app is to help recovering cognitive abilities of patients by means of a set of proposed exercises, which are divided into 8 categories focused on specific abilities. These categories have been defined after a detailed review of the guidelines for rehabilitation and training therapies. In addition, the application integrates a multimodal conversational interface to facilitate human-computer interaction, which has been specially designed for the elderly and patients with motor or visual or disabilities. The exercises provided by the application can be easily adapted to the specific users' requirements and preferences by means of the incorporation, deletion or modification of routines stored into a specific database isolated from the logic of the application.
C1 [Griol, David] Univ Carlos III Madrid, Dept Comp Sci, Leganes, Spain.
   [Callejas, Zoraida] Univ Granada, CITIC UGR, Dept Languages & Comp Syst, Granada, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Leganes, Spain.
EM dgriol@inf.uc3m.es; zoraida@ugr.es
RI Callejas, Zoraida/AAX-4634-2020
OI Callejas, Zoraida/0000-0001-8891-5237
FU European Union [823907]; Spanish Ministry of Economy, Industry and
   Competitiveness through the CAVIAR (MINECO) project
   [TEC2017-84593-C2-1-R]
FX This research has received funding from the European Union's Horizon
   2020 research and innovation programme under grant agreement No. 823907
   (MENHIR project) and from the Spanish Ministry of Economy, Industry and
   Competitiveness through the CAVIAR (MINECO, TEC2017-84593-C2-1-R)
   project.
CR Bickmore T, 2006, J BIOMED INFORM, V39, P556, DOI 10.1016/j.jbi.2005.12.004
   Bickmore TW, 2010, INTERACT COMPUT, V22, P276, DOI 10.1016/j.intcom.2010.02.001
   Delichatsios HK, 2001, AM J HEALTH PROMOT, V15, P215, DOI 10.4278/0890-1171-15.4.215
   Hassenzahl M, 2003, MENSCH COMPUTER, V2003, P187, DOI DOI 10.1007/978-3-322-80058-9_19
   Hone K., 2014, TECH REP
   Hudlicka E, 2013, PATIENT EDUC COUNS, V92, P160, DOI 10.1016/j.pec.2013.05.007
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Leite Iolanda, 2012, Advances in User Modeling. UMAP 2011 Workshops. Revised Selected Papers, P135, DOI 10.1007/978-3-642-28509-7_14
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   Migneault JP, 2006, J BIOMED INFORM, V39, P468, DOI 10.1016/j.jbi.2006.02.009
   Payr S, 2010, 2010 IEEE RO-MAN, P476, DOI 10.1109/ROMAN.2010.5598625
   Pfeifer L., 2010, P INT VIRT AG, P4698
   Rodriguez MTS, 2018, NEUROLOGIA, V33, P313, DOI 10.1016/j.nrl.2015.10.005
   Saz O, 2009, SPEECH COMMUN, V51, P948, DOI 10.1016/j.specom.2009.04.006
   VILLARRUBIA G, 2014, P IBER AMIA 14, V14, P767
NR 15
TC 1
Z9 1
U1 0
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2372-9198
BN 978-1-7281-2286-1
J9 COMP MED SY
PY 2019
BP 513
EP 518
DI 10.1109/CBMS.2019.00104
PG 6
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Engineering, Biomedical
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BO1SY
UT WOS:000502356600095
OA Green Accepted
DA 2022-08-02
ER

PT B
AU Milne, M
   Luerssen, M
   Lewis, T
   Leibbrandt, R
   Powers, D
AF Milne, Marissa
   Luerssen, Martin
   Lewis, Trent
   Leibbrandt, Richard
   Powers, David
BE Mohammadi, MR
TI Embodied Conversational Agents for Education in Autism
SO COMPREHENSIVE BOOK ON AUTISM SPECTRUM DISORDERS
LA English
DT Article; Book Chapter
ID SOCIAL-SKILLS INTERVENTIONS; HIGH-FUNCTIONING AUTISM; SPECTRUM
   DISORDERS; ASPERGER-SYNDROME; CHILDREN; SELF; ARCHITECTURE; EMOTIONS;
   STUDENTS; STORIES
C1 [Milne, Marissa; Luerssen, Martin; Lewis, Trent; Leibbrandt, Richard; Powers, David] Flinders Univ S Australia, Adelaide, SA, Australia.
RP Milne, M (corresponding author), Flinders Univ S Australia, Adelaide, SA, Australia.
RI Lewis, Trent/AAI-4260-2020
CR American Psychiatric Association, 2000, DIAGN STAT MAN MENT, V4th, DOI [10.1176/appi.books.9780890423349, DOI 10.1176/APPI.BOOKS.9780890423349]
   Anderson J. R., 1990, ADAPTIVE CHARACTER T
   [Anonymous], 1988, COGNITIVE STRUCTURE, DOI DOI 10.1017/CBO9780511571299
   Beaumont R, 2008, J CHILD PSYCHOL PSYC, V49, P743, DOI 10.1111/j.1469-7610.2008.01920.x
   BELLACK AS, 1983, BEHAV RES THER, V21, P29, DOI 10.1016/0005-7967(83)90123-7
   Biswas G., 2009, P 17 INT C COMP ED H
   Black P, 2009, EDUC ASSESS EVAL ACC, V21, P5, DOI 10.1007/s11092-008-9068-5
   Blair K., 2007, Educational Technology, V47, P56
   Bosseler A, 2003, J AUTISM DEV DISORD, V33, P653, DOI 10.1023/B:JADD.0000006002.82367.4f
   Brown DJ, 2001, PRESENCE-VIRTUAL AUG, V10, P401, DOI 10.1162/1054746011470253
   Cassell J, 2001, AI MAG, V22, P67
   Chi MTH, 2001, COGNITIVE SCI, V25, P471, DOI 10.1016/S0364-0213(01)00044-1
   Cline BE, 2010, EXPERT SYST APPL, V37, P2282, DOI 10.1016/j.eswa.2009.07.044
   Conati C, 2002, APPL ARTIF INTELL, V16, P555, DOI 10.1080/08839510290030390
   Crisp V, 2008, COMPUT EDUC, V50, P1509, DOI 10.1016/j.compedu.2007.02.004
   Davis M, 2005, ASSIST TECHNOL RES S, V16, P353
   Gao S., 2007, 2007 8 INT C EL PACK, P1
   Garcia-Winner M., 2002, ASSESSMENT EFFECTIVE, V27, P73, DOI [10.1177/073724770202700110, DOI 10.1177/073724770202700110]
   Gillis JM, 2011, RES AUTISM SPECT DIS, V5, P351, DOI 10.1016/j.rasd.2010.04.019
   Graesser A. C., 1999, Cognitive Systems Research, V1, P35, DOI 10.1016/S1389-0417(99)00005-4
   Gresham FM, 2010, SCHOOL PSYCHOL REV, V39, P364
   Hailpern J., 2007, SIGACCESS ACCESSIBIL, V89, P47, DOI DOI 10.1145/1328567.1328576
   Harrison S. H., 2004, P 1 INT C CONC MAPP, V2, P211
   Herrera G, 2008, AUTISM, V12, P143, DOI 10.1177/1362361307086657
   Howlin P., 1999, TEACHING CHILDREN AU
   Hu XM, 2010, 2010 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY AND SECURITY INFORMATICS (IITSI 2010), P250, DOI 10.1109/IITSI.2010.76
   Inspiration Software, 2011, KIDSP 8 3 11
   Jackson GT, 2010, TOP COGN SCI, V2, P127, DOI 10.1111/j.1756-8765.2009.01068.x
   Jarrold W. L., 2007, P AG BAS SYST HUM LE
   Keenan M., 2005, PARENTS ED AUTISM TH
   Kerr S. J., 2002, Virtual Environments 2002. Eurographics Workshop Proceedings, P81
   Kinchin IM, 2000, EDUC RES-UK, V42, P43, DOI 10.1080/001318800363908
   Kort B, 2001, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P43, DOI 10.1109/ICALT.2001.943850
   Land R., 2010, THRESHOLD CONCEPTS T, P61
   Laushey KM, 2009, J AUTISM DEV DISORD, V39, P1435, DOI 10.1007/s10803-009-0757-9
   LESLIE AM, 1987, PSYCHOL REV, V94, P412, DOI 10.1037/0033-295X.94.4.412
   Limoges E, 2005, BRAIN, V128, P1049, DOI 10.1093/brain/awh425
   Lorimer PA, 2002, J POSIT BEHAV INTERV, V4, P53, DOI 10.1177/109830070200400109
   Luckie D., 2004, INTRO C TOOLS CONCEP, P261
   Luerssen M, 2010, LECT NOTES ARTIF INT, V6464, P486, DOI 10.1007/978-3-642-17432-2_49
   Marcus A, 2009, J APPL BEHAV ANAL, V42, P335, DOI 10.1901/jaba.2009.42-335
   MARTIN J, 1995, INT J HUM-COMPUT ST, V42, P575, DOI 10.1006/ijhc.1995.1025
   Massaro D., 2004, P 37 HAW INT C SYST, P1
   McNamara DS, 2004, BEHAV RES METH INS C, V36, P222, DOI 10.3758/BF03195567
   Milne M., 2010, 2010 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2010.5596584
   Mitchell P., 2000, P 3 INT C DIS VIRT R, P163
   Mitrovic A, 2001, LECT NOTES ARTIF INT, V2109, P247
   Mostow J, 2005, PROJECT LISTEN READI
   Owens G, 2008, J AUTISM DEV DISORD, V38, P1944, DOI 10.1007/s10803-008-0590-6
   Panerai S, 2002, J INTELL DISABIL RES, V46, P318, DOI 10.1046/j.1365-2788.2002.00388.x
   Park U, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P238, DOI 10.1109/ICALT.2008.125
   Putnam C, 2008, P 10 INT ACM SIGACCE, P3, DOI [DOI 10.1145/1414471.1414475, 10.1145/1414471.1414475.]
   Quill KA, 1997, J AUTISM DEV DISORD, V27, P697, DOI 10.1023/A:1025806900162
   Quirmbach LM, 2009, J AUTISM DEV DISORD, V39, P299, DOI 10.1007/s10803-008-0628-9
   Rapin I, 2008, PEDIATR CLIN N AM, V55, P1129, DOI 10.1016/j.pcl.2008.07.005
   Reichow B, 2010, J AUTISM DEV DISORD, V40, P149, DOI 10.1007/s10803-009-0842-0
   Reynhout G, 2006, J AUTISM DEV DISORD, V36, P445, DOI 10.1007/s10803-006-0086-1
   Ritter S, 2007, PSYCHON B REV, V14, P249, DOI 10.3758/BF03194060
   Roberts V, 2007, BRIT J SPEC EDUC, V34, P127, DOI 10.1111/j.1467-8578.2007.00468.x
   Robison JL, 2009, FRONT ARTIF INTEL AP, V200, P25, DOI 10.3233/978-1-60750-028-5-25
   Sansosti FJ, 2010, PSYCHOL SCHOOLS, V47, P257, DOI 10.1002/pits.20469
   Sansosti FJ, 2008, J POSIT BEHAV INTERV, V10, P162, DOI 10.1177/1098300708316259
   Schuller B, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/942617
   Sehaba K, 2005, LECT NOTES COMPUT SC, V3711, P422
   Shane HC, 2009, PERSPECTIVES AUGMENT, V18, P130
   Sherer M, 2001, BEHAV MODIF, V25, P140, DOI 10.1177/0145445501251008
   Shute V, 2003, EDUC PSYCHOL-US, V38, P105, DOI 10.1207/S15326985EP3802_5
   Silver M, 2001, AUTISM, V5, P299, DOI 10.1177/1362361301005003007
   Tartaro A., 2006, P 17 EUR C ART INT, P642, DOI [10.1145/1240866.1240881, DOI 10.1145/1240866.1240881]
   Tartaro A., 2008, P INT C LEARN SCI UT
   Wellman HM, 2002, AUTISM, V6, P343, DOI 10.1177/1362361302006004003
   White SW, 2007, J AUTISM DEV DISORD, V37, P1858, DOI 10.1007/s10803-006-0320-x
   Wilkins J., 2010, THESIS LOUISIANA STA
   Wittwer J, 2010, EDUC PSYCHOL REV, V22, P9, DOI 10.1007/s10648-010-9118-7
   Woods S., 2009, ENVIRONMENTS, V5, P68
   Woolf BP, 2010, LECT NOTES COMPUT SC, V6094, P327
NR 76
TC 3
Z9 3
U1 0
U2 3
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-494-8
PY 2011
BP 387
EP 412
D2 10.5772/975
PG 26
WC Psychology, Developmental; Psychiatry
WE Book Citation Index – Social Sciences & Humanities (BKCI-SSH); Book Citation Index – Science (BKCI-S)
SC Psychology; Psychiatry
GA BG1KH
UT WOS:000386854200023
DA 2022-08-02
ER

PT S
AU Kopp, S
   Bergmann, K
AF Kopp, Stefan
   Bergmann, Kirsten
BE Zacarias, M
   Oliveira, JVD
TI Individualized Gesture Production in Embodied Conversational Agents
SO HUMAN-COMPUTER INTERACTION: THE AGENCY PERSPECTIVE
SE Studies in Computational Intelligence
LA English
DT Article; Book Chapter
ID MODEL
AB Gesturing behavior is subject to great variations across situations, individuals, or cultures. These variations make gestures hard for systematic studies and modeling attempts. However, gesture research on real humans and modeling approaches with virtual agents have made significant progress in the last years. In this chapter we discuss the state of research and present results from an extensive empirical study on human iconic gestures in direction giving dialogues. It is described how machine learning methods can be employed to extract different speakers' gesturing style and to generate individualized language and gestures in ECAs. Evaluations show that human observers rate virtual agents better in terms of competence, human-likeness, or likability when a consistent individual gesture style is produced.
C1 [Kopp, Stefan] Univ Bielefeld, Sociable Agents Grp, CITEC, Fac Technol, Bielefeld, Germany.
RP Kopp, S (corresponding author), Univ Bielefeld, Sociable Agents Grp, CITEC, Fac Technol, Bielefeld, Germany.
EM skopp@techfak.uni-bielefeld.de; kbergman@techfak.uni-bielefeld.de
RI Kopp, Stefan/K-3456-2013
OI Kopp, Stefan/0000-0002-4047-9277
CR [Anonymous], 2007, GESTURE
   Ball G, 2000, EMBODIED CONVERSATIONAL AGENTS, P189
   Bavelas J.B., 2002, GESTURE, V2, P1
   Bavelas J, 2008, J MEM LANG, V58, P495, DOI 10.1016/j.jml.2007.02.004
   Bente G, 2010, CONSCIOUS COGN, V19, P762, DOI 10.1016/j.concog.2010.06.006
   Bergmann K, 2010, LECT NOTES ARTIF INT, V6356, P104, DOI 10.1007/978-3-642-15892-6_11
   Bergmann K, 2010, APPL ARTIF INTELL, V24, P530, DOI 10.1080/08839514.2010.492162
   Bergmann K, 2009, LECT NOTES ARTIF INT, V5773, P76
   CASSELL J, 1994, PROCEEDINGS OF THE SIXTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P153
   Cassell J, 2007, CONVERSATIONAL INFOR, P133, DOI DOI 10.1002/9780470512470.CH8
   Chi D, 2000, COMP GRAPH, P173
   Foster ME, 2007, LANG RESOUR EVAL, V41, P305, DOI 10.1007/s10579-007-9055-3
   Hartmann B, 2006, LECT NOTES ARTIF INT, V3881, P188
   Howard R.A., 2005, DECIS ANAL, V2, P127, DOI DOI 10.1287/DECA.1050.0020
   Kendon A., 2004, GESTURE VISIBLE ACTI
   Kimbara I., 2006, GESTURE, V6, P39, DOI [10.1075/gest.6.1.03kim, DOI 10.1075/GEST.6.1.03KIM]
   Kita S., 2000, LANGUAGE GESTURE, P162
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   Kopp S, 2010, SPEECH COMMUN, V52, P587, DOI 10.1016/j.specom.2010.02.007
   Kopp S, 2008, INT J SEMANT COMPUT, V2, P115, DOI 10.1142/S1793351X08000361
   LAURITZEN SL, 1995, COMPUT STAT DATA AN, V19, P191, DOI 10.1016/0167-9473(93)E0056-A
   Madsen AL, 2005, INT J ARTIF INTELL T, V14, P507, DOI 10.1142/S0218213005002235
   McNeill D, 2005, GESTURE THOUGHT
   Melinger A., 2004, GESTURE, V4, P119, DOI DOI 10.1075/GEST.4.2.02MEL
   Muller Cornelia, 1998, REDEBEGLEITENDE GEST
   Nass C, 2000, EMBODIED CONVERSATIONAL AGENTS, P374
   Neff M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330516
   Ruttkay Z, 2007, LECT NOTES COMPUT SC, V4775, P23
   STECK H, 1999, P 2 WORKSH DAT MIN D
   Stone M, 2004, ACM T GRAPHIC, V23, P506, DOI 10.1145/1015706.1015753
   Stone M, 2003, COMPUT INTELL-US, V19, P311
   Streeck J, 2008, GESTURE, V8, P285, DOI 10.1075/gest.8.3.02str
   [No title captured]
NR 33
TC 6
Z9 6
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 1860-949X
EI 1860-9503
BN 978-3-642-25690-5
J9 STUD COMPUT INTELL
PY 2012
VL 396
BP 287
EP 301
D2 10.1007/978-3-642-25691-2
PG 15
WC Computer Science, Artificial Intelligence
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BCA59
UT WOS:000309482200013
DA 2022-08-02
ER

PT C
AU Ahmadvand, A
   Sahijwani, H
   Agichtein, E
AF Ahmadvand, Ali
   Sahijwani, Harshita
   Agichtein, Eugene
GP Assoc Comp Machinery
TI Would you Like to Talk about Sports Now? Towards Contextual Topic
   Suggestion for Open-Domain Conversational Agents
SO CHIIR'20: PROCEEDINGS OF THE 2020 CONFERENCE ON HUMAN INFORMATION
   INTERACTION AND RETRIEVAL
LA English
DT Proceedings Paper
CT 5th ACM SIGIR Conference on Human Information Interaction and Retrieval
   (CHIIR)
CY AUG 13-14, 2020
CL ELECTR NETWORK
SP ACM Special Interest Grp Informat Retrieval, ACM SIGCHI, Assoc Comp Machinery
AB To hold a true conversation, an intelligent agent should be able to occasionally take initiative and recommend the next natural conversation topic. This is a challenging task. A topic suggested by the agent should be relevant to the person, appropriate for the conversation context, and the agent should have something interesting to say about it. Thus, a scripted, or one-size-fits-all, popularity-based topic suggestion is doomed to fail. Instead, we explore different methods for a personalized, contextual topic suggestion for open-domain conversations. We formalize the Conversational Topic Suggestion problem (CTS) to more clearly identify the assumptions and requirements. We also explore three possible approaches to solve this problem: (1) model-based sequential topic suggestion to capture the conversation context (CTS-Seq), (2) Collaborative Filtering-based suggestion to capture previous successful conversations from similar users (CTS-CF), and (3) a hybrid approach combining both conversation context and collaborative filtering. To evaluate the effectiveness of these methods, we use real conversations collected as part of the Amazon Alexa Prize 2018 Conversational AI challenge. The results are promising: the CTS-Seq model suggests topics with 23% higher accuracy than the baseline, and incorporating collaborative filtering signals into a hybrid CTS-Seq-CF model further improves recommendation accuracy by 12%. Together, our proposed models, experiments, and analysis significantly advance the study of open-domain conversational agents, and suggest promising directions for future improvements.
C1 [Ahmadvand, Ali; Sahijwani, Harshita; Agichtein, Eugene] Emory Univ, Comp Sci Dept, Atlanta, GA 30322 USA.
RP Ahmadvand, A (corresponding author), Emory Univ, Comp Sci Dept, Atlanta, GA 30322 USA.
EM ali.ahmadvand@emory.edu; hsahijw@emory.edu; eugene.agichtein@emory.edu
RI Sahijwani, Harshita/AAR-8864-2021
FU Amazon Alexa Prize 2018
FX We gratefully acknowledge the financial and computing support from the
   Amazon Alexa Prize 2018.
CR Ahmadvand Ali, 2018, ALEXA PRIZE P
   [Anonymous], 2014, P C EMP METH NAT LAN
   Anu Venkatesh, 2018, 31 C NEUR INF PROC S
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Blunsom P., 2013, P 2013 WORKSH CONT V
   Cer D., ARXIV180311175
   Chen JL, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1185
   Chiu J. P., 2016, NAMED ENTITY RECOGNI, V4, P357, DOI 10.1162/tacl_a_00104
   Choi JI, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1281, DOI 10.1145/3357384.3358047
   Christakopoulou K, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P815, DOI 10.1145/2939672.2939746
   Conneau A., 2016, ARXIV160601781
   DAS Abhinandan, 2007, P 16 INT C WORLD WID, V16, P271, DOI DOI 10.1145/1242572.1242610
   Dinan E., 2018, WIZARD WIKIPEDIA KNO
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Gao X., 2015, 29 AAAI C ART INT
   Harshita Sahijwani, 2020, P 2020 C HUM INF INT
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Khatri C., 2018, ABSTRACTIVE EXTRACTI
   Khatri Chandra, 2018, ADV STATE ART OPEN D
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Lafferty J. D., 2001, P 18 INT C MACH LEAR
   Lee J. Y., 2016, ARXIV160303827
   Li L., 2010, P 19 INT C WORLD WID, P661, DOI DOI 10.1145/1772690.1772758
   Li Raymond, 2018, ADV NEURAL INFORM PR, P9748
   Lops P, 2011, RECOMMENDER SYSTEMS HANDBOOK, P73, DOI 10.1007/978-0-387-85820-3_3
   Melville P, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P187
   Mendes P. N., 2011, P 7 INT C SEM SYST, P1, DOI DOI 10.1145/2063518.2063519
   Fonte FAM, 2009, J UNIVERS COMPUT SCI, V15, P1486
   Mnih A., 2007, ADV NEURAL INFORM PR, V1, P2, DOI DOI 10.1145/1390156.1390267
   Morris RR, 2018, J MED INTERNET RES, V20, DOI 10.2196/10148
   Nabiha Asghar, 2016, ARXIV161203929
   Palmer Martha, 2013, ONTONOTES RELEASE 5
   Phelan O., 2009, RECSYS 09 P 3 ACM C, P385, DOI [10.1145/1639714.1639794, DOI 10.1145/1639714.1639794]
   Radlinski F, 2017, CHIIR'17: PROCEEDINGS OF THE 2017 CONFERENCE HUMAN INFORMATION INTERACTION AND RETRIEVAL, P117, DOI 10.1145/3020165.3020183
   Ram A., 2018, ABS180103604 CORR
   Ricci F., RECOMMENDER SYSTEMS
   Su P.-H., 2018, P NAACL 2018 TUT ABS, P27
   Sun YM, 2018, ACM/SIGIR PROCEEDINGS 2018, P235, DOI 10.1145/3209978.3210002
   Thomas P, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P42, DOI 10.1145/3176349.3176388
   Tomasello M., 2010, ORIGINS HUMAN COMMUN
   Wang HW, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1835, DOI 10.1145/3178876.3186175
   Wen Tsung-Hsien, P EACL
   Williams Jason D., 2016, END END LSTM BASED D
   Yan R, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4525
   Yan R, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P685, DOI 10.1145/3077136.3080843
   Yang XS, 2017, INT CONF ACOUST SPEE, P5690, DOI 10.1109/ICASSP.2017.7953246
   Ye ZX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P235
   Zhang X, 2015, ARXIV150201710
NR 49
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6892-6
PY 2020
BP 83
EP 92
DI 10.1145/3343413.3377974
PG 10
WC Computer Science, Cybernetics; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ7EB
UT WOS:000614660700011
DA 2022-08-02
ER

PT C
AU Alattas, A
   Teepe, GW
   Leidenberger, K
   Fleisch, E
   Car, LT
   Salamanca-Sanabria, A
   Kowatsch, T
AF Alattas, Aishah
   Teepe, Gisbert W.
   Leidenberger, Konstantin
   Fleisch, Elgar
   Car, Lorraine Tudor
   Salamanca-Sanabria, Alicia
   Kowatsch, Tobias
BE Pesquita, C
   Fred, A
   Gamboa, H
TI To What Scale Are Conversational Agents Used by Top-funded Companies
   Offering Digital Mental Health Services for Depression?
SO HEALTHINF: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON
   BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES - VOL. 5: HEALTHINF
LA English
DT Proceedings Paper
CT 14th International Joint Conference on Biomedical Engineering Systems
   and Technologies (BIOSTEC) / 14th Int Conf on Bio-inspired Systems and
   Signal Processing (BIOSIGNALS) / 14th Int Conf on Biomedical Electronics
   and Devices (BIODEVICES)
CY FEB 11-13, 2021
CL ELECTR NETWORK
DE Conversational Agent; Depression; Mental Health; Venture Capital;
   Top-funded
ID PROGRAM
AB There is strong support in the literature for the use of conversational agents (CAs) in digital mental healthcare along with a recent increase in funding within digital mental health, indicating the fast growth of the industry. However, it is unknown to what extent CAs are leveraged in these digital interventions for depression. The aim of this study is to therefore explore the scale of CA use in top-funded digital mental health companies targeting depression and describe what purposes they are used for. Companies were identified through searching venture capital databases and screened for the presence and purpose of use of CAs in their interventions for depression. It was found that only 7 out of the 29 top-funded companies used a CA in their intervention. The most common purpose of CA use was education, followed by assistance, training and onboarding. None of the interventions used CAs for elderly assistance, diagnosis or prevention. These results indicate that the industry uptake of CAs in digital interventions for depression within top-funded companies is low. Future work can look into using CAs in areas which this analysis found they are not currently used such as in tailoring to different target populations and in preventing depression.
C1 [Alattas, Aishah; Fleisch, Elgar; Salamanca-Sanabria, Alicia; Kowatsch, Tobias] Singapore ETH Ctr, Future Hlth Technol, Campus Res Excellence & Technol Enterprise CREATE, Singapore, Singapore.
   [Teepe, Gisbert W.; Fleisch, Elgar; Kowatsch, Tobias] Swiss Fed Inst Technol, Dept Management Technol & Econ D MTEC, Zurich, Switzerland.
   [Leidenberger, Konstantin; Fleisch, Elgar; Kowatsch, Tobias] Univ St Gallen, Inst Technol Management ITEM, St Gallen, Switzerland.
   [Car, Lorraine Tudor] Nanyang Technol Univ Singapore, Lee Kong Chian Sch Med, Family Med & Primary Care, Singapore, Singapore.
   [Car, Lorraine Tudor] Imperial Coll London, Sch Publ Hlth, Dept Primary Care & Publ Hlth, London, England.
RP Alattas, A (corresponding author), Singapore ETH Ctr, Future Hlth Technol, Campus Res Excellence & Technol Enterprise CREATE, Singapore, Singapore.
CR Abd-alrazaq AA, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103978
   Akker H. O. D., 2020, INT J HUM-COMPUT ST, V138
   Albert PR, 2015, J PSYCHIATR NEUROSCI, V40, P219, DOI 10.1503/jpn.150205
   Beck J.S., 2011, COGNITIVE BEHAV THER, V2nd, pxix
   Berube C., 2020, VOICE BASED CONVERSA
   Bickmore TW, 2010, INTERACT COMPUT, V22, P276, DOI 10.1016/j.intcom.2010.02.001
   Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158
   CB Insights, 2020, STAT HEALTHC Q3 20 R
   Cheung AH, 2018, PEDIATRICS, V141, DOI 10.1542/peds.2017-4082
   Collins LM, 2007, AM J PREV MED, V32, pS112, DOI 10.1016/j.amepre.2007.01.022
   Gaffney H, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/14166
   Haroz EE, 2017, SOC SCI MED, V183, P151, DOI 10.1016/j.socscimed.2016.12.030
   Hekler E, 2020, ANN BEHAV MED, V54, P805, DOI 10.1093/abm/kaaa018
   James SL, 2018, LANCET, V392, P1789, DOI 10.1016/s0140-6736(18)32279-7
   Kornfield R., 2020, P 2020 CHI C HUM FAC
   Liu QQ, 2020, J PSYCHIATR RES, V126, P134, DOI 10.1016/j.jpsychires.2019.08.002
   Loncar-Turukalo T, 2019, J MED INTERNET RES, V21, DOI 10.2196/14017
   Lopez A, 2019, CURR PSYCHIAT REP, V21, DOI 10.1007/s11920-019-1055-7
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   Miner A., 2016, P 4 INT C HUM AG INT
   Miner AS, 2017, JAMA-J AM MED ASSOC, V318, P1217, DOI 10.1001/jama.2017.14151
   Ormel J, 2019, WORLD PSYCHIATRY, V18, P111, DOI 10.1002/wps.20580
   Parkar Shubhangi R, 2015, Mens Sana Monogr, V13, P91, DOI 10.4103/0973-1229.153311
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Retterath A., 2020, BENCHMARKING VENTURE
   Schachner T, 2020, J MED INTERNET RES, V22, DOI 10.2196/20701
   Scholten MR, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7351
   Schuetzler RM, 2018, DECIS SUPPORT SYST, V114, P94, DOI 10.1016/j.dss.2018.08.011
   Shah R. N., 2020, RISE VENTURE CAPITAL
   Teasdale J., 2018, MINDFULNESS BASED CO
   Twomey C, 2017, PSYCHIAT RES, V256, P371, DOI 10.1016/j.psychres.2017.06.081
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   Vergunst FK, 2013, PSYCHIAT RES, V207, P143, DOI 10.1016/j.psychres.2013.03.022
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
NR 35
TC 1
Z9 1
U1 1
U2 4
PU SCITEPRESS
PI SETUBAL
PA AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL
BN 978-989-758-490-9
PY 2021
BP 801
EP 808
DI 10.5220/0010413308010808
PG 8
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR6TR
UT WOS:000664063000090
OA hybrid, Green Published
DA 2022-08-02
ER

PT C
AU Griol, D
   Molina, JM
AF Griol, David
   Manuel Molina, Jose
BE Onieva, E
   Santos, I
   Osaba, E
   Quintian, H
   Corchado, E
TI Modeling Users Emotional State for an Enhanced Human-Machine Interaction
SO HYBRID ARTIFICIAL INTELLIGENT SYSTEMS (HAIS 2015)
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 10th International Conference on Hybrid Artificial Intelligence Systems
   (HAIS)
CY JUN 22-24, 2015
CL Bilbao, SPAIN
SP IEEE Spanish Sect, IEEE Syst Man & Cybernet Spanish Chapter, Univ Salamanca, Univ Deusto, DeustoTech, Int Federat Computat Log
DE Conversational agents; Spoken interaction; User modeling; Emotion
   recognition; Adaptation
ID SPEECH; RECOGNITION
AB Spoken conversational agents have been proposed to enable a more natural and intuitive interaction with the environment and human-computer interfaces. In this paper, we propose a framework to model the user's emotional state during the dialog and adapt the dialog model dynamically, thus developing more efficient, adapted, and usable conversational agents. We have evaluated our proposal developing a user-adapted agent that facilitates touristic information, and provide a detailed discussion of the positive influence of our proposal in the success of the interaction, the information and services provided, as well as the perceived quality.
C1 [Griol, David; Manuel Molina, Jose] Univ Carlos III Madrid, Dept Comp Sci, Leganes 28911, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Avda Univ 30, Leganes 28911, Spain.
EM david.griol@uc3m.es; josemanuel.molina@uc3m.es
RI Griol, David/L-1258-2014; Molina, JOSE/B-1956-2008
OI Griol, David/0000-0001-6266-5321; Molina, JOSE/0000-0002-7484-7357
CR Acosta J, 2009, P 10 ANN C INT SPEEC, P1587
   Ai H., 2007, P 8 SIGDIAL WORKSH D, P124
   Andru E, 2004, P 9 INT C INT US INT, P85
   [Anonymous], 2005, DATA MINING PRACTICA
   Batliner A, 2011, COMPUT SPEECH LANG, V25, P4, DOI 10.1016/j.csl.2009.12.003
   Batliner Anton, 2006, P 1 INT LANG TECHN C, P246
   Bickmore Timothy, 2004, AAAI FALL S DIAL SYS, P275
   Boril H, 2010, IEEE T AUDIO SPEECH, V18, P1379, DOI 10.1109/TASL.2009.2034770
   Bui TH, 2009, NAT LANG ENG, V15, P273, DOI 10.1017/S1351324908005032
   Burkhardt F, 2009, P INT C AFF COMP INT, P1, DOI DOI 10.1109/ACII.2009.5349498
   Callejas Z, 2008, SPEECH COMMUN, V50, P416, DOI 10.1016/j.specom.2008.01.001
   Griol D, 2012, ADV INTEL SOFT COMPU, V151, P161
   Hansen JHL, 1996, SPEECH COMMUN, V20, P151, DOI 10.1016/S0167-6393(96)00050-7
   Kartakis S, 2010, COMPUT IND, V61, P318, DOI 10.1016/j.compind.2009.12.002
   Khalifa O., 2007, INT J COMPUT SCI, V2, P285
   Litman DJ, 2006, SPEECH COMMUN, V48, P559, DOI 10.1016/j.specom.2005.09.008
   Marreiros G, 2010, IEEE INTELL SYST, V25, P31, DOI 10.1109/MIS.2010.46
   Morrison D, 2007, SPEECH COMMUN, V49, P98, DOI 10.1016/j.specom.2006.11.004
   Osland P.O., 2006, P INT C CONV SERV ME, P1
   Pieraccini R, 2012, VOICE IN THE MACHINE: BUILDING COMPUTERS THAT UNDERSTAND SPEECH, P1
   Pittermann J, 2010, INT J SPEECH TECHNOL, V13, P49, DOI 10.1007/s10772-010-9068-y
   Riccardi G, 2005, LECT NOTES COMPUT SC, V3814, P144
   Santos R, 2011, IEEE INTELL SYST, V26, P58, DOI 10.1109/MIS.2011.92
   Schatzmann J., 2005, P 6 SIGDIAL WORKSH D, P45
   Schuller B, 2011, SPEECH COMMUN, V53, P1062, DOI 10.1016/j.specom.2011.01.011
   Strauss PM, 2010, PROACTIVE SPOKEN DIALOGUE INTERACTION IN MULTI-PARTY ENVIRONMENTS, P1, DOI 10.1007/978-1-4419-5992-8
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Wilks Y, 2011, COMPUT SPEECH LANG, V25, P128, DOI 10.1016/j.csl.2010.03.001
   Will T., 2012, SIMPLE GUIDE IBM SPS
   Williams JD, 2007, COMPUT SPEECH LANG, V21, P393, DOI 10.1016/j.csl.2006.06.008
NR 30
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-319-19644-2; 978-3-319-19643-5
J9 LECT NOTES ARTIF INT
PY 2015
VL 9121
BP 357
EP 368
DI 10.1007/978-3-319-19644-2_30
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BD7YD
UT WOS:000363689900030
DA 2022-08-02
ER

PT C
AU Lejeune, G
   Rioult, F
   Cremilleux, B
AF Lejeune, Gael
   Rioult, Francois
   Cremilleux, Bruno
GP Int Speech Commun Assoc
TI Highlighting Psychological Features for Predicting Child Interjections
   During Story Telling
SO 17TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2016), VOLS 1-5: UNDERSTANDING SPEECH
   PROCESSING IN HUMANS AND MACHINES
SE Interspeech
LA English
DT Proceedings Paper
CT 17th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2016)
CY SEP 08-12, 2016
CL San Francisco, CA
SP apple, amazon alexa, Google, Microsoft, ebay, facebook, YAHOO JAPAN, Baidu Res, IBM Res, CIRRUS LOGIC, DATATANG, NUANCE, Speechocean Ltd, Yandex, Raytheon Technol
DE Conversational Agents; Event Prediction; Knowledge Discovery; Emotion
   Modelling
AB Conversational agents are more and more investigated by the community but their ability to keep the user committed in the interaction is limited. Predicting the behavior of children in a human-machine interaction setting is a key issue for the success of narrative conversational agents. In this paper, we investigate solutions to evaluate the child's commitment in the story and to detect when the child is likely to react during the story. We show that the conversational agent cannot solely count on questions and requests for attention to stimulate the child. We assess how (1) psychological features allow to improve the prediction of children interjections and how (2) exploiting these features with Pattern Mining techniques offers better results. Experiments show that psychological features improves the predictions and furthermore help to produce robust dialog models.
C1 [Lejeune, Gael; Rioult, Francois; Cremilleux, Bruno] Normandie Univ, UNICAEN, ENSICAEN, CNRS,GREYC, F-14000 Caen, France.
RP Lejeune, G (corresponding author), Normandie Univ, UNICAEN, ENSICAEN, CNRS,GREYC, F-14000 Caen, France.
EM gael.lejeune@unicaen.fr; francois.rioult@unicaen.fr;
   bruno.cremilleux@unicaen.fr
FU ANR (French Research National Agency) [NARECA ANR-13-CORD-0015, HYBRIDE
   ANR-11-BS002-002]
FX This work is supported by the ANR (French Research National Agency)
   funded projects NARECA ANR-13-CORD-0015 and HYBRIDE ANR-11-BS002-002.
CR Baillie-de Byl P, 2004, EDUC TECHNOL SOC, V7, P29
   Boisseleau W, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1653
   Brixtel R., 2015, RECENT ADV NATURAL L, P63
   Broekens J., 2009, GERONTECHNOLOGY, V8
   Bunt H., 2009, AAMAS 2009 WORKSH ST, P13
   Bunt H, 2011, COMPUT SPEECH LANG, V25, P222, DOI 10.1016/j.csl.2010.04.006
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   Deng L, 2013, INT CONF ACOUST SPEE, P8604, DOI 10.1109/ICASSP.2013.6639345
   Griol D., 2005, 10 SPEECH COMP C SPE, P203
   Griol D, 2008, SPEECH COMMUN, V50, P666, DOI 10.1016/j.specom.2008.04.001
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   Liscombe J., 2005, P INT 2005
   Litman D., 2009, SIGDIAL 09, P286
   Pauchet A., 2013, Proceedings of the 5th International Conference on Agents and Artificial Intelligence. ICAART 2013, P527
   Pelachaud C, 2009, PHILOS T R SOC B, V364, P3539, DOI 10.1098/rstb.2009.0186
   Salfner F, 2010, ACM COMPUT SURV, V42, DOI 10.1145/1670679.1670680
   Schroder M, 2010, ADV HUM-COMPUT INTER, V2010, DOI 10.1155/2010/319406
   Su P., 2015, CORR
   Swartout W, 2006, AI MAG, V27, P96
   Ukkonen E, 2009, THEOR COMPUT SCI, V410, P4341, DOI 10.1016/j.tcs.2009.07.015
   Varges S., 2009, P 10 SIGDIAL C, P156
   Ward N., 2015, AAAI SPRING SERIES
   Zhao Tiancheng, 2015, P 16 ANN M SPEC INT, P42
NR 23
TC 0
Z9 0
U1 0
U2 1
PU ISCA-INT SPEECH COMMUNICATION ASSOC
PI BAIXAS
PA C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE
SN 2308-457X
BN 978-1-5108-3313-5
J9 INTERSPEECH
PY 2016
BP 2056
EP 2059
DI 10.21437/Interspeech.2016-527
PG 4
WC Acoustics; Computer Science, Artificial Intelligence; Engineering,
   Electrical & Electronic; Linguistics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Acoustics; Computer Science; Engineering; Linguistics
GA BI2LY
UT WOS:000409394401113
OA Green Published
DA 2022-08-02
ER

PT J
AU Kowatsch, T
   Schachner, T
   Harperink, S
   Barata, F
   Dittler, U
   Xiao, G
   Stanger, C
   Wangenheim, FV
   Fleisch, E
   Oswald, H
   Moller, A
AF Kowatsch, Tobias
   Schachner, Theresa
   Harperink, Samira
   Barata, Filipe
   Dittler, Ullrich
   Xiao, Grace
   Stanger, Catherine
   Wangenheim, Florian, V
   Fleisch, Elgar
   Oswald, Helmut
   Moeller, Alexander
TI Conversational Agents as Mediating Social Actors in Chronic Disease
   Management Involving Health Care Professionals, Patients, and Family
   Members: Multisite Single-Arm Feasibility Study
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Article
DE digital health intervention; intervention design; mHealth; eHealth;
   chatbot; conversational agent; chronic diseases; asthma; feasibility
   study
ID OBSTRUCTIVE PULMONARY-DISEASE; PREDIABETES TREATMENT SUPPORT;
   INFORMATION-TECHNOLOGY; WORKING ALLIANCE; PEDIATRIC OBESITY;
   SELF-MANAGEMENT; USER ACCEPTANCE; ASTHMA CONTROL; CHILDREN; ADHERENCE
AB Background: Successful management of chronic diseases requires a trustful collaboration between health care professionals, patients, and family members. Scalable conversational agents, designed to assist health care professionals, may play a significant role in supporting this collaboration in a scalable way by reaching out to the everyday lives of patients and their family members. However, to date, it remains unclear whether conversational agents, in such a role, would be accepted and whether they can support this multistakeholder collaboration.
   Objective: With asthma in children representing a relevant target of chronic disease management, this study had the following objectives: (1) to describe the design of MAX, a conversational agent-delivered asthma intervention that supports health care professionals targeting child-parent teams in their everyday lives; and (2) to assess the (a) reach of MAX, (b) conversational agent-patient working alliance, (c) acceptance of MAX, (d) intervention completion rate, (e) cognitive and behavioral outcomes, and (f) human effort and responsiveness of health care professionals in primary and secondary care settings.
   Methods: MAX was designed to increase cognitive skills (ie, knowledge about asthma) and behavioral skills (ie, inhalation technique) in 10-15-year-olds with asthma, and enables support by a health professional and a family member. To this end, three design goals guided the development: (1) to build a conversational agent-patient working alliance; (2) to offer hybrid (humanand conversational agent-supported) ubiquitous coaching; and (3) to provide an intervention with high experiential value. An interdisciplinary team of computer scientists, asthma experts, and young patients with their parents developed the intervention collaboratively. The conversational agent communicates with health care professionals via email, with patients via a mobile chat app, and with a family member via SMS text messaging. A single-arm feasibility study in primary and secondary care settings was performed to assess MAX.
   Results: Results indicated an overall positive evaluation of MAX with respect to its reach (49.5%, 49/99 of recruited and eligible patient-family member teams participated), a strong patient-conversational agent working alliance, and high acceptance by all relevant stakeholders. Moreover, MAX led to improved cognitive and behavioral skills and an intervention completion rate of 75.5%. Family members supported the patients in 269 out of 275 (97.8%) coaching sessions. Most of the conversational turns (99.5%) were conducted between patients and the conversational agent as opposed to between patients and health care professionals, thus indicating the scalability of MAX. In addition, it took health care professionals less than 4 minutes to assess the inhalation technique and 3 days to deliver related feedback to the patients. Several suggestions for improvement were made.
   Conclusions: This study provides the first evidence that conversational agents, designed as mediating social actors involving health care professionals, patients, and family members, are not only accepted in such a "team player" role but also show potential to improve health-relevant outcomes in chronic disease management.
C1 [Kowatsch, Tobias; Schachner, Theresa; Harperink, Samira; Barata, Filipe; Wangenheim, Florian, V; Fleisch, Elgar] Swiss Fed Inst Technol, Dept Management Technol & Econ, Ctr Digital Hlth Intervent, Weinbergstr 56-58, CH-8092 Zurich, Switzerland.
   [Kowatsch, Tobias; Wangenheim, Florian, V; Fleisch, Elgar] Singapore ETH Ctr, Future Hlth Technol Programme, Campus Res Excellence & Technol Enterprise, Singapore, Singapore.
   [Kowatsch, Tobias; Fleisch, Elgar] Univ St Gallen, Inst Technol Management, Ctr Digital Hlth Intervent, St Gallen, Switzerland.
   [Dittler, Ullrich] Hsch Furtwangen Univ, Fak Digitale Medien, Campus Furtwangen, Furtwangen, Germany.
   [Xiao, Grace] Johns Hopkins Univ, Johns Hopkins Univ Sch Med, Baltimore, MD USA.
   [Stanger, Catherine] Dartmouth Coll, Ctr Technol & Behav Hlth, Geisel Sch Med, Hanover, NH USA.
   [Oswald, Helmut] Cantonal Hosp Winterthur, Dept Child & Adolescent Hlth, Winterthur, Switzerland.
   [Moeller, Alexander] Univ Childrens Hosp Zurich, Div Resp Med & Childhood Res Ctr, Zurich, Switzerland.
RP Kowatsch, T (corresponding author), Swiss Fed Inst Technol, Dept Management Technol & Econ, Ctr Digital Hlth Intervent, Weinbergstr 56-58, CH-8092 Zurich, Switzerland.
EM tkowatsch@ethz.ch
RI Barata, Filipe/AAB-7802-2021
OI Barata, Filipe/0000-0002-3905-2380; Oswald, Helmut/0000-0001-9585-4532;
   Schachner, Theresa/0000-0002-5505-8811; Dittler,
   Ullrich/0000-0003-1272-1107; Xiao, Grace/0000-0001-5402-9421; Harperink,
   Samira/0000-0003-0583-8948; Fleisch, Elgar/0000-0002-4842-1117
FU Swiss health insurer CSS; CSS; Swiss Lung Association
FX TK, TS, SH, FB, EF, and FW are affiliated with the Centre for Digital
   Health Interventions (CDHI), a joint initiative of the Department of
   Management, Technology and Economics at ETH Zurich, and the Institute of
   Technology Management at the University of St. Gallen, which is funded
   in part by the Swiss health insurer CSS. The MAX intervention and study
   were cofunded by CSS and the Swiss Lung Association. TK is also
   cofounder of Pathmate Technologies, a university spin-off company that
   creates and delivers digital clinical pathways and has used the open
   source MobileCoach platform for that purpose. Pathmate Technologies
   received funding from the Swiss Lung Association to develop the MAX app
   and the web-based MAX interface for health care professionals based on
   the MobileCoach software. The developed generic software modules were
   made open source in the latest version of MobileCoach by the CDHI.
   Neither CSS nor the Swiss Lung Association or Pathmate Technologies was
   involved in any aspect of data analysis or manuscript preparation. None
   of the health care professionals was involved in the data analysis in
   any aspect. Neither CSS nor Pathmate Technologies was involved in the
   study design. All other authors report no conflicts of interest.
CR AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   Alpert JM, 2017, PATIENT EDUC COUNS, V100, P1852, DOI 10.1016/j.pec.2017.04.019
   [Anonymous], ASTHM FACT SHEET
   [Anonymous], MAX CONV AG CHILDR A
   ARON A, 1992, J PERS SOC PSYCHOL, V63, P596, DOI 10.1037/0022-3514.63.4.596
   Barata F, 2019, 2019 IEEE INT C HEAL, DOI 10.1109/ICHI.2019.8904554
   Barata F, 2020, J MED INTERNET RES, V22, DOI 10.2196/18082
   Barlow JH, 2004, CHILD CARE HLTH DEV, V30, P637, DOI 10.1111/j.1365-2214.2004.00474.x
   Barrios RJ, 2006, ARCH PATHOL LAB MED, V130, P447
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore TW, 2012, J HEALTH COMMUN, V17, P23, DOI 10.1080/10810730.2012.712626
   Bickmore TW, 2010, INTERACT COMPUT, V22, P289, DOI 10.1016/j.intcom.2009.12.001
   Birkhauer J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0170988
   Blake KV, 2017, CURR OPIN PULM MED, V23, P62, DOI 10.1097/MCP.0000000000000334
   Boateng G, 2020, 2020 ACM CHI C HUM F
   Brand PLP, 2005, CURR MED RES OPIN, V21, pS27, DOI 10.1185/030079905X61767
   Brigden A, 2020, J MED INTERNET RES, V22, DOI 10.2196/16924
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158
   Cassell J., 2000, EMBODIED CONVERSATIO
   Chan AHY, 2015, LANCET RESP MED, V3, P210, DOI 10.1016/S2213-2600(15)00008-9
   Chang C, 2012, CLIN REV ALLERG IMMU, V43, P98, DOI 10.1007/s12016-011-8261-3
   de Benedictis D, 2017, PEDIATR PULM, V52, P129, DOI 10.1002/ppul.23498
   Deci EL, 2017, ANNU REV ORGAN PSYCH, V4, P19, DOI 10.1146/annurev-orgpsych-032516-113108
   DeWalt DA, 2004, J GEN INTERN MED, V19, P1228, DOI 10.1111/j.1525-1497.2004.40153.x
   DiMatteo MR, 2004, PATIENT EDUC COUNS, V55, P339, DOI 10.1016/j.pec.2003.04.003
   Eder W, 2006, NEW ENGL J MED, V355, P2226, DOI 10.1056/NEJMra054308
   Falkenstrom F, 2015, PSYCHOL ASSESSMENT, V27, P169, DOI 10.1037/pas0000038
   Filler A, 2015, WIREL TELECOMM SYMP
   Fluckiger C, 2018, PSYCHOTHERAPY, V55, P316, DOI 10.1037/pst0000172
   Frey U, 2008, LANCET, V372, P1088, DOI 10.1016/S0140-6736(08)61450-6
   Giraud V, 2002, EUR RESPIR J, V19, P246, DOI 10.1183/09031936.02.00218402
   Grossman B, 2017, J BIOMED INFORM, V67, P51, DOI 10.1016/j.jbi.2017.02.003
   Harris K, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2018-025867
   Haug S, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/16937
   Haug S, 2017, JMIR MHEALTH UHEALTH, V5, DOI 10.2196/mhealth.8474
   Haug S, 2017, J CONSULT CLIN PSYCH, V85, P147, DOI 10.1037/ccp0000138
   Haug S, 2015, J BEHAV ADDICT, V4, P299, DOI 10.1556/2006.4.2015.037
   Haughney J, 2008, RESP MED, V102, P1681, DOI 10.1016/j.rmed.2008.08.003
   Hauser-Ulrich S, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/15806
   Hill-Briggs F, 2003, ANN BEHAV MED, V25, P182, DOI 10.1207/S15324796ABM2503_04
   Hirai K, 2016, ANN ALLERG ASTHMA IM, V117, P169, DOI 10.1016/j.anai.2016.06.007
   HORVATH AO, 1989, J COUNS PSYCHOL, V36, P223, DOI 10.1037/0022-0167.36.2.223
   Huckvale K, 2015, BMC MED, V13, DOI 10.1186/s12916-015-0303-x
   Jaffee EG, 2017, J HOSP MED, V12, P969, DOI 10.12788/jhm.2848
   Kamis A, 2008, MIS QUART, V32, P159
   Keim-Malpass J, 2015, BMC PEDIATR, V15, DOI 10.1186/s12887-015-0412-x
   Kenyon CC, 2016, JMIR RES PROTOC, V5, DOI 10.2196/resprot.5362
   King P, 1999, COMMUN ACM, V42, P31, DOI 10.1145/301353.301398
   Klok T, 2015, PEDIAT ALLERG IMM-UK, V26, P197, DOI 10.1111/pai.12362
   Kocaballi AB, 2019, J MED INTERNET RES, V21, DOI 10.2196/15360
   Kolb D.A., 1984, EXPERIENCE SOURCE LE
   Kowatsch T, 2017, PERS EMB AG BEH CHAN
   Kowatsch T, 2017, LECT NOTES COMPUT SC, V10243, P485, DOI 10.1007/978-3-319-59144-5_36
   Kramer JN, 2020, ANN BEHAV MED, V54, P518, DOI 10.1093/abm/kaaa002
   Kramer JN, 2019, JMIR RES PROTOC, V8, DOI 10.2196/11540
   Kugler, 2018, OPTIMIZATION BEHAV B
   Kunzler F, 2019, P ACM INTERACTIVE MO, V3, P1
   Kuprys-Lipinska I, 2020, CLIN TRANSL ALLERGY, V10, DOI 10.1186/s13601-020-00316-z
   Kvedar JC, 2016, NAT BIOTECHNOL, V34, P239, DOI 10.1038/nbt.3495
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lavorini F, 2008, RESP MED, V102, P593, DOI 10.1016/j.rmed.2007.11.003
   Lindquist LA, 2012, J GEN INTERN MED, V27, P173, DOI 10.1007/s11606-011-1886-3
   Liu D, 2017, MIS QUART, V41, P1011
   Luscher J, 2019, JMIR RES PROTOC, V8, DOI 10.2196/13685
   Ma TT, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312853
   Mackey LM, 2016, MED DECIS MAKING, V36, P741, DOI 10.1177/0272989X16638330
   Marsden PA, 2016, CHEST, V149, P1460, DOI 10.1016/j.chest.2016.02.676
   Michie S, 2011, PSYCHOL HEALTH, V26, P1479, DOI 10.1080/08870446.2010.540664
   Miles C, 2017, NPJ PRIM CARE RESP M, V27, DOI 10.1038/s41533-017-0056-4
   Morton RW, 2017, THORAX, V72, P347, DOI 10.1136/thoraxjnl-2015-208171
   Mosnaim G, 2015, J ALLER CL IMM-PRACT, V3, P288, DOI 10.1016/j.jaip.2014.10.011
   Nahum-Shani I, 2018, ANN BEHAV MED, V52, P446, DOI 10.1007/s12160-016-9830-8
   Nahum-Shani I, 2015, HEALTH PSYCHOL, V34, P1209, DOI 10.1037/hea0000306
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   NIELSEN J, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P206
   Nunes Carlos, 2017, Asthma Res Pract, V3, P1, DOI 10.1186/s40733-016-0029-3
   Patadia MO, 2014, OTOLARYNG CLIN N AM, V47, P23, DOI 10.1016/j.otc.2013.10.001
   Perski O, 2019, DIGIT HEALTH, V5, DOI 10.1177/2055207619880676
   Potter PC, 2010, ALLERGY ASTHMA IMMUN, V2, P1, DOI 10.4168/aair.2010.2.1.1
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Ramsey RR, 2020, J ALLER CL IMM-PRACT, V8, P1284, DOI 10.1016/j.jaip.2019.12.013
   Rideout V, 2016, J CHILD MEDIA, V10, P138, DOI 10.1080/17482798.2016.1129808
   Ryan RM, 2017, SELF-DETERMINATION THEORY: BASIC PSYCHOLOGICAL NEEDS IN MOTIVATION, DEVELOPMENT, AND WELLNESS, P1, DOI 10.1521/978.14625/28806
   Sanchez-Morillo D, 2016, CHRON RESP DIS, V13, P264, DOI 10.1177/1479972316642365
   Sanchez-Morillo D, 2015, INFORM HEALTH SOC CA, V40, P1, DOI 10.3109/17538157.2013.872114
   Sanders C, 2012, BMC HEALTH SERV RES, V12, DOI 10.1186/1472-6963-12-220
   Schachner T, 2020, J MED INTERNET RES, V22, DOI 10.2196/20701
   Schnyder M., 2014, THESIS
   Schnyder MA, 2012, SPURENSUCHE FERIENLA
   Searle A, 2017, NPJ PRIM CARE RESP M, V27, DOI 10.1038/s41533-017-0053-7
   Stephens TN, 2019, TRANSL BEHAV MED, V9, P440, DOI 10.1093/tbm/ibz043
   Stieger M, 2020, EUR J PERSONALITY, V34, P345, DOI 10.1002/per.2267
   Stukus DR, 2018, ANN ALLERG ASTHMA IM, V120, P395, DOI 10.1016/j.anai.2018.02.006
   ter Stal S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102409
   Thom DH, 2004, HEALTH AFFAIR, V23, P124, DOI 10.1377/hlthaff.23.4.124
   Thompson D, 2019, TRANSL BEHAV MED, V9, P448, DOI 10.1093/tbm/ibz065
   Tinschert P, 2017, JMIR MHEALTH UHEALTH, V5, DOI 10.2196/mhealth.7177
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   van der Heijden H, 2004, MIS QUART, V28, P695, DOI 10.2307/25148660
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Venkatesh V, 2012, MIS QUART, V36, P157
   Voruganti T, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7987
   Wade SL, 2000, J DEV BEHAV PEDIATR, V21, P340, DOI 10.1097/00004703-200010000-00004
   Walia M, 2006, PEDIATR PULM, V41, P1082, DOI 10.1002/ppul.20498
   Wang KY, 2014, J CLIN NURS, V23, P2031, DOI 10.1111/jocn.12434
   Zarouali B, 2018, CYBERPSYCH BEH SOC N, V21, P491, DOI 10.1089/cyber.2017.0518
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
NR 109
TC 5
Z9 5
U1 4
U2 25
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD FEB 17
PY 2021
VL 23
IS 2
AR e25060
DI 10.2196/25060
PG 26
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA QI4YI
UT WOS:000618984600007
PM 33484114
OA Green Published, Green Accepted, gold
DA 2022-08-02
ER

PT C
AU Lessio, N
   Morris, A
AF Lessio, Nadine
   Morris, Alexis
GP IEEE
TI Toward Design Archetypes for Conversational Agent Personality
SO 2020 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)
SE IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings
LA English
DT Proceedings Paper
CT IEEE International Conference on Systems, Man, and Cybernetics (SMC)
CY OCT 11-14, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Syst Man & Cybernet Soc, IEEE Brain, Intheon, Guger Technologies
DE Conversational Agents; Human-Like Agents; Archetypes; Personality
AB Conversational agents (CAs), often referred to as chatbots, are being widely deployed within existing commercial frameworks and online service websites. As society moves further into incorporating data rich systems, like the internet of things (IoT), into daily life, it is expected that conversational agents will take on an increasingly important role to help users manage these complex systems. In this, the concept of personality is becoming increasingly important, as we seek for more human-friendly ways to interact with these CAs. In this work a conceptual framework is proposed that considers how existing standard psychological and persona models could be mapped to different kinds of CA functionality outside of strictly dialogue. As CAs become more diverse in their abilities, and more integrated with different kinds of systems, it is important to consider how function can be impacted by the design of agent personality, whether intentionally designed or not. Based on this framework, derived archetype classes of CAs are presented as starting points that can hopefully aid designers, developers, and the curious, into thinking about how to work toward better CA personality development.
C1 [Lessio, Nadine; Morris, Alexis] OCAD Univ, Adapt Context Environm Lab, Toronto, ON, Canada.
RP Lessio, N (corresponding author), OCAD Univ, Adapt Context Environm Lab, Toronto, ON, Canada.
EM nlessio@faculty.ocadu.ca; amorris@faculty.ocadu.ca
OI Lessio, Nadine/0000-0001-6852-4124
FU Tricouncil of Canada under the Canada Research Chairs program
FX This work gratefully acknowledges funding from the Tricouncil of Canada
   under the Canada Research Chairs program.
CR Ackerman C. E., 2020, BIG 5 PERSONALITY TR
   Adiwardana D., 2020, HUMAN LIKE OPENDOMAI, DOI DOI 10.3390/healthcare7020056
   Allbeck J, 2002, EMBODIED CONVERSATIO, V2, P15
   Biundo S, 2017, COGN TECHNOL, P1, DOI 10.1007/978-3-319-43665-4_1
   Bosker B., 2017, SIRI RISING INSIDE S
   Dale R, 2016, NAT LANG ENG, V22, P811, DOI 10.1017/S1351324916000243
   Dam R. F., PERSONAS SIMPLE INTR
   Diederich S, 2019, HUMAN PRACTICE DIGIT, P1100
   Diener E., 2019, GEN PSYCHOL REQUIRED, P278
   Fischer U, 2012, PROC INT CONF DATA, P1245, DOI 10.1109/ICDE.2012.117
   Georgeson J., 2016, ARXIV160904879
   Gnewuch U., 2017, P 38 INT C INFORM SY
   Hoffer R., 2016, TROUBLE BOTS PARENTS
   Jurado E., 2019, P 14 INT C FDN DIG G, P1
   Maunz S., 2017, IT HAS HAVE SOUL CHA
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   Nass C., 2010, MAN WHO LIED HIS LAP
   Nimavat K., 2017, IJSRD INT J SCI RES
   Radford A., 2019, OPENAI BLOG, V1, P9
   Rodrigues A., 2016, HIST SMARTERCHILD
   Shum HY, 2018, FRONT INFORM TECH EL, V19, P10, DOI 10.1631/FITEE.1700826
   Vlahos J., 2018, INSIDE AMAZONS BATTL
   Wei C, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING (ICMLC 2018), P369, DOI 10.1145/3195106.3195169
   Wooldridge M., 2009, INTRO MULTIAGENT SYS
   Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI [10.1162/coli_a_00368, 10.1162/COLI_a_00368]
NR 25
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1062-922X
BN 978-1-7281-8526-2
J9 IEEE SYS MAN CYBERN
PY 2020
BP 3221
EP 3228
PG 8
WC Computer Science, Cybernetics; Computer Science, Information Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS1DD
UT WOS:000687430603040
DA 2022-08-02
ER

PT C
AU Foster, ME
AF Foster, Mary Ellen
BE Stephanidis, C
TI Enhancing human-computer interaction with embodied conversational agents
SO Universal Access in Human-Computer Interaction: Ambient Interaction, Pt
   2, Proceedings
SE LECTURE NOTES IN COMPUTER SCIENCE
LA English
DT Proceedings Paper
CT 4th International Conference on Universal Access in Human-Computer
   Interaction held at the HCI International 2007
CY JUL 22-27, 2007
CL Beijing, PEOPLES R CHINA
SP ICS FORTH, Human Comp Interact Lab
ID DIALOGUE; LANGUAGE
AB We survey recent research in which the impact of an embodied conversational agent on human-computer interaction has been assessed through a human evaluation. In some cases, the evaluation involved comparing different versions of the agent against itself in the context of a full interactive system; in others, it measured the effect on user perception of spoken output of specific aspects of the embodied agent's behaviour. In almost all of the studies, an embodied agent that displays appropriate non-verbal behaviour was found to enhance the interaction.
C1 Tech Univ Munich, Dept Informat, Robot & Embedded Syst Grp, D-85748 Garching, Germany.
RP Foster, ME (corresponding author), Tech Univ Munich, Dept Informat, Robot & Embedded Syst Grp, Boltzmannstr 3, D-85748 Garching, Germany.
RI Foster, Mary Ellen/K-6248-2013
OI Foster, Mary Ellen/0000-0002-1228-7657
CR Andre Elisabeth, 2005, P 4 INT JOINT C AUT, DOI DOI 10.1145/1082473.1082615
   Bavelas JB, 2000, J LANG SOC PSYCHOL, V19, P163, DOI 10.1177/0261927X00019002001
   Berry D., 2004, FINAL EVALUATION REP
   Bickmore T, 2005, ADV NATURAL MULTIMOD
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   BUISINE S, EVALUATION INDIVIDUA, P217
   CASSELL J, HUMAN CONSERVATION S, P29
   Cassell J., 2000, EMBODIED CONVERSATIO
   de Ruyter B, 2005, INTERACT COMPUT, V17, P522, DOI 10.1016/j.intcom.2005.03.003
   DeCarlo D, 2004, COMPUT ANIMAT VIRT W, V15, P27, DOI [10.1002/cav.5, 10.1002/cav.3]
   DeRuiter J, 2000, LANGUAGE GESTURE, P248
   Dybkjaer L, 2004, SPEECH COMMUN, V43, P33, DOI 10.1016/j.specom.2004.02.001
   FOSTER ME, 2007, THESIS U EDINBURGH S
   Kendon A., 2004, GESTURE VISIBLE ACTI
   MARSI E, 2007, P WORKSH MULT GEN MO
   PELACHAUD C, 2004, BROWS TRUST EVALUATI
   POGGI I, PERFORMATIVE FACIAL, P154
   Prendinger H, 2005, INT J HUM-COMPUT ST, V62, P231, DOI 10.1016/j.ijhcs.2004.11.009
   PRENDINGER H, 2005, P 7 INT C MULT INT I, P108
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Rehm M, 2005, LECT NOTES ARTIF INT, V3661, P241
   RUTTKAY Z, 2006, EVALUATING EMBODIED
   Sidner CL, 2005, ARTIF INTELL, V166, P140, DOI 10.1016/j.artint.2005.03.005
   SWERTS M, IN PRESS PERCEPTION
   WHITE M, 2005, P HCI INT 2005 THEM
NR 25
TC 16
Z9 16
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 978-3-540-73280-8
J9 LECT NOTES COMPUT SC
PY 2007
VL 4555
BP 828
EP 837
PN 2
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BGL79
UT WOS:000248235800091
DA 2022-08-02
ER

PT C
AU Nakhal, B
   Querrec, R
AF Nakhal, Bilal
   Querrec, Ronan
GP IEEE
TI Cognitive Embodied Conversational Agents in Virtual Learning Environment
SO 2017 29TH INTERNATIONAL CONFERENCE ON MICROELECTRONICS (ICM)
SE International Conference on Microelectronics-ICM
LA English
DT Proceedings Paper
CT 29th International Conference on Microelectronics (ICM)
CY DEC 10-13, 2017
CL Beirut, LEBANON
SP Arts Sci & Technol Univ London, IEEE Reg 8, IEEE Lebanon Sect, IEEE EMB Lebanon Sect, IEEE CAS
DE Virtual Learning Environment; Cognitive Architecture; Embodied
   Conversational Agent; Procedure; Pedagogical; Knowledge base;
   Communicative Intention; Communicative Behavior
AB In this work, we propose a model for building Virtual Learning Environment (VLE) where intelligent virtual agents play the role of tutors and are expected to help a human user to follow a procedural scenario with predefined learning outcomes. Our model provides the agents with a cognitive architecture to make sound reasoning on its knowledge base. The agent is materialized in front of the user as an Embodied Conversational Agent (ECA) that communicates and interacts with her/him in a credible human-like manner. Our implemented model is then tested in a concrete pedagogical scenario for learning blood analysis procedures in a biomedical laboratory.
C1 [Nakhal, Bilal] CRiTC Arts Sci & Technol Univ Lebanon AUL, Beirut, Lebanon.
   [Nakhal, Bilal; Querrec, Ronan] ENIB, Lab STICC, IHSEV CERV, Brest, France.
RP Nakhal, B (corresponding author), CRiTC Arts Sci & Technol Univ Lebanon AUL, Beirut, Lebanon.; Nakhal, B (corresponding author), ENIB, Lab STICC, IHSEV CERV, Brest, France.
EM bilal.nakhal@aul.edu.lb; querrec@enib.fr
CR Atkinson R., 2002, J ED PSYCHOL
   Cafaro A., 2014, INTELLIGENT VIRTUAL
   Cassell J., 2000, EMBODIED CONVERSATIO
   Courgeon M., 2008, P 1 WORKSH AFFECTIVE, P20
   Dillenbourg P., 2002, P 3 HELL C INF COMM, P3
   GERBAUD S, 2008, VR, P225
   Guerra-Hernandez A, 2004, LECT NOTES ARTIF INT, V3259, P218
   Hoareau C., 2013, ICLTC 13
   Huber T., 2017, SURG ENDOSC, P1
   Kenny P., 2007, P I ITSEC, V174
   Le Corre F., PEDAGOGICAL SCENARIO
   Pelachaud C, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS'15), P5
   Poslad S., 2000, Proceedings of the Fifth International Conference on the Practical Application of Intelligent Agent and Multi Agent Technology, P355
   Querrec R, 2011, STUD COMPUT INTELL, V369, P81
   Rickel J., 1997, P AN INT AG MAK THEM, P71
   Vilhjalmsson H., 2007, INTELLIGENT VIRTUAL
   Webster R, 2016, INTERACT LEARN ENVIR, V24, P1319, DOI 10.1080/10494820.2014.994533
NR 17
TC 0
Z9 0
U1 2
U2 4
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2159-1679
BN 978-1-5386-4049-4
J9 INT C MICROELECTRON
PY 2017
BP 310
EP 313
PG 4
WC Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA BJ8AL
UT WOS:000427882000076
DA 2022-08-02
ER

PT S
AU Corradini, A
   Fredriksson, M
   Mehta, M
   Konigsmann, J
   Bernsen, NO
   Johannesson, L
AF Corradini, A
   Fredriksson, M
   Mehta, M
   Konigsmann, J
   Bernsen, NO
   Johannesson, L
BE Bubak, M
   VanAlbada, GD
   Sloot, PMA
   Dongarra, JJ
TI Towards believable behavior generation for embodied conversational
   agents
SO COMPUTATIONAL SCIENCE - ICCS 2004, PT 3, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 4th International Conference on Computational Science (ICCS 2004)
CY JUN 06-09, 2004
CL Cracow, POLAND
SP Hewlett-Packard, Intel, SGI, ATM, Sun Microsyst, IBM, Polish Airlines LOT, ACC CYFRONET AGH, Inst Comp Sci AGH, Polish Minist Sci Res & Informat Technol, Springer Verlag
AB This paper reports on the generation of coordinated multimodal output for the NICE (Natural Interactive Communication for Edutainment) system [1]. In its first prototype, the system allows for fun and experientially rich interaction between primarily 10 to 18 years old human users and 3D-embodied fairy tale author H.C. Andersen in his study. User input consists of domain-oriented spoken conversation combined with 2D input gesture, entered via a mouse-compatible device. The animated character can move about and interact with his environment as well as communicate with the user through spoken conversation and non-verbal gesture, body posture, facial expression and gaze. The described approach aims to make the virtual agent's appearance, voice, actions, and communicative behavior convey the impression of a character with human-like behavior, emotions, relevant domain knowledge, and a distinct personality. We propose an approach to multimodal output generation, which exploits a richly parameterized semantic instruction from the conversation manager and splits the instruction into synchronized text instructions to the text-to-speech synthesizer, and behavioral instructions to the animated character. Based on the implemented version of this approach, we are in the process of creating a behavior sub-system that combines the described multimodal output instructions with parameters representing the current emotional state of the character, producing animations that express emotional state through speech and non-verbal behavior.
C1 Univ So Denmark, Nat Interact Syst Lab, DK-5230 Odense M, Denmark.
   Liquid Media AB, S-11635 Stockholm, Sweden.
RP Corradini, A (corresponding author), Univ So Denmark, Nat Interact Syst Lab, DK-5230 Odense M, Denmark.
EM andrea@nis.sdu.dk; morgan@liquid.se; manish@nis.sdu.dk;
   jurgen@liquid.se; nob@nis.sdu.dk; lasse@liquid.se
RI mehta, manish/I-3873-2012
CR ARGYLE M, 1986, BODILY COMMUNICATION
   Bernsen N.O., 1998, DESIGNING INTERACTIV
   BERNSEN NO, 2004, P ACM INT WORKSH C A
   BESKOW J, 2004, SPOKEN MULTIMODAL HU
   Cassell J., 2000, EMBODIED CONVERSATIO
   EKMAN P, 1969, PSYCHIATR, V32, P88, DOI 10.1080/00332747.1969.11023575
   Fiske S. T., 1991, SOCIAL COGNITION
   Knapp M.L., 1978, NONVERBAL COMMUNICAT, V2nd ed.
   KODA T, 1996, P HUM COMP INT LOND, P239
   LOYALL AB, 1997, CMUCS97123
   Massaro DW, 1999, J SPEECH LANG HEAR R, V42, P21, DOI 10.1044/jslhr.4201.21
   MASSARO DW, 2003, 15 INT C PHON SCI BA
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Nass C, 2000, EMBODIED CONVERSATIONAL AGENTS, P374
   PELACHAUD C, 2002, 1 INT JOINT C AUT AG
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Reeves B., 1996, MEDIA EQUATION PEOPL
   [No title captured]
NR 18
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-22116-6
J9 LECT NOTES COMPUT SC
PY 2004
VL 3038
BP 946
EP 953
PG 8
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA BAG08
UT WOS:000222048900121
OA Bronze
DA 2022-08-02
ER

PT C
AU L'Abbate, M
   Thiel, U
   Kamps, T
AF L'Abbate, M
   Thiel, U
   Kamps, T
BE Skowron, A
   Barthes, JP
   Jain, L
   Sun, R
   MorizetMahoundeaux, P
   Liu, J
   Zhong, N
TI Can proactive behavior turn chatterbots into conversational agents?
SO 2005 IEEE/WIC/ACM International Conference on Intelligent Agent
   Technology, Proceedings
LA English
DT Proceedings Paper
CT International Conference on Intelligent Agent Technology
CY SEP 19-22, 2005
CL Compiegne Univ Technol, Compiegne, FRANCE
SP IEEE Comp Soc, Web Intelligence Consortium, Assoc Comp Machinery
HO Compiegne Univ Technol
AB Chatterbots are software systems interacting with their users by means of a natural language based conversation. Their knowledge base consists of a collection of rules, whose triggering depends on text patterns recognized within the user input. Even if they are an interesting and promising idea, recent statistics detected poor usage and a relatively short lifetime. This paper suggests an improvement of the chatterbot technology, based on the implementation of a more proactive dialogue behavior. A chatterbot enhanced with proactivity can be regarded as an intelligent conversational agent which is generally characterized by a more complex implementation approach but provides more efficient dialogue control through mixed-initiative strategies. By comparing chatterbots to finite state machines a formal definition of proactive chatterbots is reached and a standard implementation methodology is suggested Finally, a case study discussing an example implementation of a virtual risk management advisor is provided.
C1 Fraunhofer IPSI, Darmstadt, Germany.
RP L'Abbate, M (corresponding author), Fraunhofer IPSI, Darmstadt, Germany.
CR ALLEN J, 1999, IEEE INTELL SYST APP, V14, P17
   FERGUSON G, 1998, P NAT C AI MENL PARK
   Horvitz E, 1999, IEEE INTELL SYST APP, V14, P17
   LABBATE M, 2004, P DEX 04 DAT EXP SYS
   LOEBNER H, HOME PAGE LOEBNER PR
   LOUWERSE MM, 2002, ETIQUETTE HUMAN COMP, P71
   NEWELL A, 1961, LERNENDE AUTOMATEN, P109
   RAPAPORT WJ, 2004, ENCY LANGUAGE LINGUI
   WOOLDRIDGE M, 1995, KNOWL ENG REV, V10, P115, DOI 10.1017/S0269888900008122
NR 9
TC 5
Z9 5
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
BN 0-7695-2416-8
PY 2005
BP 173
EP 179
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BDI55
UT WOS:000233623100032
DA 2022-08-02
ER

PT C
AU Lee, YC
   Fu, WT
AF Lee, Yi-Chieh
   Fu, Wai-Tat
GP ACM
TI Supporting Peer Assessment in Education with Conversational Agents
SO PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER
   INTERFACES: COMPANION (IUI 2019)
LA English
DT Proceedings Paper
CT 24th International Conference on Intelligent User Interfaces (IUI)
CY MAR 17-20, 2019
CL Marina Del Rey, CA
SP Assoc Comp Machinery
DE chatbot; agent; education; peer assessment; grading
ID FEEDBACK
AB In this paper, we explored the potential of using a conversational chatbot interface to guide students to perform peer assessments. Our results show that our chatbot interface is in general successful in guiding graders, as reflected by students' grading consistencies across multiple assessments and correlated with teaching assistants' grading. Our results provide insights into how conversational interface can be used to support peer assessments.
C1 [Lee, Yi-Chieh; Fu, Wai-Tat] Univ Illinois, Champaign, IL 61801 USA.
RP Lee, YC (corresponding author), Univ Illinois, Champaign, IL 61801 USA.
EM ylee267@illinois.edu; wfu@illinois.edu
RI Lee, Yi-Chieh/AAG-8954-2021
CR Boud D., 2013, ENHANCING LEARNING S
   Fryer LK, 2017, COMPUT HUM BEHAV, V75, P461, DOI 10.1016/j.chb.2017.05.045
   Kulkarni Chinmay E., 2015, LEARNING SCALE LS 15
   Lin SSJ, 2001, J COMPUT ASSIST LEAR, V17, P420, DOI 10.1046/j.0266-4909.2001.00198.x
   Sadler DR, 2010, ASSESS EVAL HIGH EDU, V35, P535, DOI 10.1080/02602930903541015
NR 5
TC 2
Z9 2
U1 4
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6673-1
PY 2019
BP 7
EP 8
DI 10.1145/3308557.3308695
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP3BB
UT WOS:000546032800004
DA 2022-08-02
ER

PT C
AU Morales-Rodriguez, ML
   Gonzalez, JJ
   Juarez, RF
   Huacuja, HJF
   Flores, JAM
AF Lucila Morales-Rodriguez, Maria
   Gonzalez B, Juan Javier
   Juarez, Rogelio Florencia
   Fraire Huacuja, Hector J.
   Martinez Flores, Jose A.
BE Sidorov, G
   Aguirre, AH
   Garcia, CAR
TI Emotional Conversational Agents in Clinical Psychology and Psychiatry
SO ADVANCES IN ARTIFICIAL INTELLIGENCE, MICAI 2010, PT I
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 9th Mexican International Conference on Artificial Intelligence (MICAI)
CY NOV 08-13, 2010
CL Pachuca, MEXICO
SP Mexican Soc Artificial Intelligence, Univ Autonoma Estado Hidalgo, Inst Politecnico Nacl, Ctr Investigac Computac, Inst Nacl Astrofisica, Optica & Elect, Univ Nacl Autonoma Mexico, Univ Autonoma Mexico, Inst Tecnologico Estudios Superiores Monterrey, Ctr Investigac Matematicas
DE Conversational Agent; Personality; Emotions; Natural Language; AIME
AB This paper is based on a project at the University of Barcelona to develop the skills to diagnose the Generalized Anxiety Disorder (GAD) in students of psychology and psychiatry using a chatbot. The problem we address in this paper is to convert a chatbot in an emotional conversational agent capable of generating a believable and dynamic dialogue in natural language. For it, the dialogues convey traits of personality, emotions and its intensity. We propose to make an AIME language extension for the generation of believable dialogue, this extension will allow to create a more realistic scenario for the student to diagnose the condition simulated by the conversational agent. In order to measure the perception of the emotional state of the ECA expressed by the speech acts a survey was applied.
C1 [Lucila Morales-Rodriguez, Maria; Gonzalez B, Juan Javier; Juarez, Rogelio Florencia; Fraire Huacuja, Hector J.; Martinez Flores, Jose A.] Inst Tecnol Ciudad Madero, Div Estudios Posgrado & Invest, Ciudad Madero, Tamaulipas, Mexico.
RP Morales-Rodriguez, ML (corresponding author), Inst Tecnol Ciudad Madero, Div Estudios Posgrado & Invest, Ciudad Madero, Tamaulipas, Mexico.
EM lmoralesrdz@gmail.com; jjgonzalezbarbosa@hotmail.com;
   rogelio.florencia@live.com.mx; hfraire@prodigy.net.mx;
   jmtz05@yahoo.com.mx
OI Florencia, Rogelio/0000-0002-5208-6577
CR Cerezo E., 2007, AGENTES VIRTUALES 3D, VI3A
   Connie T., 2002, AS TECHN C MATH ATCM
   Ghasem-Aghaee N., 2009, SUMM COMP SIM C
   Gutierrez J., 2009, CGVR
   HUANG H, 2008, INT J MULTIAGENT GRI, V4
   Kopp S., 2006, VIRTUAL HUMAN MAX MO
   KSHIRSAGAR S, 2002, P 2 INT S SMART GRAP, P107
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   Morales-Rodriguez M.L., 2007, THESIS U P SABATIER
   Morales-Rodriguez M.L., 2009, CGVR 2009, P158
   WALLACE RS, 2000, DONT READ ME ALICE A
NR 11
TC 1
Z9 1
U1 1
U2 9
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 978-3-642-16760-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 6437
BP 458
EP 466
PG 9
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BHW96
UT WOS:000326886700040
DA 2022-08-02
ER

PT J
AU Lefevre, F
AF Lefevre, Fabrice
TI Conversational IA. Dialogue Systems, Conversational Agents, and Chatbots
SO TRAITEMENT AUTOMATIQUE DES LANGUES
LA French
DT Book Review
C1 [Lefevre, Fabrice] Avignon Univ, LIA, CERI, Avignon, France.
RP Lefevre, F (corresponding author), Avignon Univ, LIA, CERI, Avignon, France.
CR MCTEAR M, 2021, CONVERSATIONAL IA DI
NR 1
TC 0
Z9 0
U1 1
U2 1
PU ASSOC TRADUCTION AUTOMATIQUE LINGUISTIQUE APPLIQUEE
PI PARIS
PA 45 RUE ULM, CEDEX 5, PARIS, 75230, FRANCE
SN 1248-9433
EI 1965-0906
J9 TRAIT AUTOM LANG
JI Trait. Autom. Lang.
PY 2021
VL 62
IS 1
BP 68
EP 71
PG 4
WC Linguistics
WE Emerging Sources Citation Index (ESCI)
SC Linguistics
GA WJ2ZU
UT WOS:000708917800005
DA 2022-08-02
ER

PT J
AU Qamar, S
   Mujtaba, H
   Majeed, H
   Beg, MO
AF Qamar, Saira
   Mujtaba, Hasan
   Majeed, Hammad
   Beg, Mirza Omer
TI Relationship Identification Between Conversational Agents Using Emotion
   Analysis
SO COGNITIVE COMPUTATION
LA English
DT Article
DE Behavioral analysis; Dialogue systems; Social network analysis;
   Multi-agent interaction; Conversational interactions
AB Human relationships are influenced by the underlying emotions in their interactions. With the increasing use of social networks, relationships from textual data can also be inferred from online interactions. Such interactions result in massive amount of textual data which is available in the form of text messages, emails, and social media posts. Identification and analysis of human relationships are useful for numerous applications ranging from cybersecurity to public health. In this paper, we present a method called RIEA (Relationship Identification using Emotion Analysis), for identifying relationships between multiple intelligent agents by analyzing the conversation between them. The objective of our work is to combine concepts of cognitive psychology and natural language processing (NLP) to extract emotions and map them onto a set of relationships and analyze how relationships transform over time. We employ psychological models to label a large corpus of conversations and apply machine learning techniques to determine emotion-to-relationship mapping. We use four distinct association classes and four attachment styles using best-worst scaling method for classification. Combining the attachment and association styles given in research literature gives us the relationship combinations for our analysis. Additionally, this work studies the most common changes of behaviors and emotions and the corresponding transformations in human relationships. Our results show that RIEA can correctly detect interpersonal relationships with an accuracy of 85%. The evaluation shows that RIEA can accurately identify interpersonal relationships from conversations and can be extended for identifying more complex relationships. This study also highlights the effect of changes in emotional behavior in the development of relationships over time.
C1 [Qamar, Saira; Mujtaba, Hasan; Majeed, Hammad; Beg, Mirza Omer] Natl Univ Comp & Emerging Sci, AK Brohi Rd,H-11-4, Islamabad, Pakistan.
RP Beg, MO (corresponding author), Natl Univ Comp & Emerging Sci, AK Brohi Rd,H-11-4, Islamabad, Pakistan.
EM sairaqamar591@yahoo.com; hasan.mujtaba@nu.edu.pk;
   hammad.majeed@nu.edu.pk; omer.beg@nu.edu.pk
OI Beg, Mirza/0000-0001-5789-2933
CR Al-Ghadir AI, 2019, COGN COMPUT, V11, P71, DOI 10.1007/s12559-018-9592-7
   Awan MN, 2020, COMPUTER SPEECH LANG, V65, P101
   Bourgais M, 2017, MULTIAGENT BASED SIM, P89
   Bravo-Marquez F, 2016, 2016 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2016), P536, DOI [10.1109/WI.2016.0091, 10.1109/WI.2016.90]
   Cabrera-Diego LA, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105633
   Calefato F, 2017, INT CONF AFFECT, P79, DOI 10.1109/ACIIW.2017.8272591
   Collenette J, 2019, SPR PROC ADV ROBOT, V6, P559, DOI 10.1007/978-3-319-73008-0_39
   Danescu-Niculescu-Mizil C., 2011, P 2 WORKSH COGN MOD, P76
   Danisman T, 2008, FEELER EMOTION CLASS, P53
   DERIVERA J, 1986, MOTIV EMOTION, V10, P351, DOI 10.1007/BF00992109
   Flynn TN, 2014, HDB CHOICE MODELLING
   Fox J, 2015, CYBERPSYCH BEH SOC N, V18, P491, DOI 10.1089/cyber.2015.0123
   Gilovich T, 2012, SOCIAL PSYCHOL
   Ho Dung T., 2012, Knowledge Management and Acquisition for Intelligent Systems. Proceedings of the 12th Pacific Rim Knowledge Acquisition Workshop, PKAW 2012, P94, DOI 10.1007/978-3-642-32541-0_8
   Hortensius R, 2018, IEEE T COGN DEV SYST, V10, P852, DOI 10.1109/TCDS.2018.2826921
   Islam MR, 2018, 33RD ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P1536, DOI 10.1145/3167132.3167296
   Kao ECC, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P70, DOI 10.1109/ICIME.2009.113
   Khawaldeh H. A., 2018, PERFORMANCE INVESTIG, P1, DOI DOI 10.1109/ICSENG.2018.8638207
   Kolak J, 2013, ARXIV13036094
   Li YM, 2019, COGN COMPUT, V11, P459, DOI 10.1007/s12559-019-9624-y
   Lin J, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS'15), P1947
   Liu Z., 2019, P EMNLP IJCNLP 2019, P1297
   Ma YK, 2020, INFORM FUSION, V64, P50, DOI 10.1016/j.inffus.2020.06.011
   Majumder N, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P6818
   Mohammad S, 2018, P 11 INT C LANG RES
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Naeem B, 2020, J COMPUT SOC SCI, V3, P231, DOI 10.1007/s42001-020-00063-y
   Neviarouskaya A, 2007, LECT NOTES COMPUT SC, V4738, P218
   Plutchik Robert, 2003, EMOTIONS LIFE PERSPE
   Saunier J, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P645
   Shiota MN, 2004, REGULATION OF EMOTION, P127
   Singh D, 2017, AAMAS'17: PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P249
   Singh D, 2016, AUTON AGENT MULTI-AG, V30, P1050, DOI 10.1007/s10458-016-9332-x
   Smith E.R., 2014, SOC PSYCHOL-GERMANY, V4th
   Strapparava C., 2004, P 4 INT C LANG RES E, P1083
   Thelwall M, 2012, J AM SOC INF SCI TEC, V63, P163, DOI 10.1002/asi.21662
   Wang J, 2006, CLASSIFICATION IMBAL
   Wang Y, 2016, P 2016 C EMPIRICAL M, P606, DOI 10.18653/v1/D16-1058
   Wang ZH, 2020, ORTHOD WAVES, V79, P1, DOI 10.1080/13440241.2020.1733297
   Wu Z, 2020, P 58 ANN M ASS COMP, P5811, DOI [10.18653/v1/2020.acl-main.515, DOI 10.18653/V1/2020.ACL-MAIN.515]
   Yang HC, 2018, COGN COMPUT, V10, P1152, DOI 10.1007/s12559-018-9576-7
   Young T, 2020, NEUROCOMPUTING, V388, P102, DOI 10.1016/j.neucom.2019.12.126
NR 42
TC 4
Z9 4
U1 8
U2 21
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1866-9956
EI 1866-9964
J9 COGN COMPUT
JI Cogn. Comput.
PD MAY
PY 2021
VL 13
IS 3
BP 673
EP 687
DI 10.1007/s12559-020-09806-5
EA JAN 2021
PG 15
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA SB1BA
UT WOS:000604851700007
DA 2022-08-02
ER

PT J
AU Egges, A
   Kshirsagar, S
   Magnenat-Thalmann, N
AF Egges, A
   Kshirsagar, S
   Magnenat-Thalmann, N
TI Generic personality and emotion simulation for conversational agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE personality; emotion simulation; facial animation; artificial
   intelligence
AB This paper describes a generic model for personality, mood and emotion simulation for conversational virtual humans. We present a generic model for updating the parameters related to emotional behaviour, as well as a linear implementation of the generic update mechanisms. We explore how existing theories for appraisal can be integrated into the framework. Then we describe a prototype system that uses the described models in combination with a dialogue system and a talking head with synchronized speech and facial expressions. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Geneva, MIRALab, CH-1211 Geneva, Switzerland.
   Univ Montreal, Montreal, PQ H3C 3J7, Canada.
RP Egges, A (corresponding author), Univ Geneva, MIRALab, 24,Rue Gen Dufour, CH-1211 Geneva, Switzerland.
EM egges@miralab.unige.ch
RI Thalmann, Nadia/AAK-5195-2021
OI Thalmann, Nadia/0000-0002-1459-5960
CR ANDRE E, 1999, P INT WORKSH AFF INT
   [Anonymous], 1988, COGNITIVE STRUCTURE, DOI DOI 10.1017/CBO9780511571299
   [Anonymous], 1982, EMOTION HUMAN FACE
   BALL G, 1998, P WORKSH EMB CONV CH, P83
   Cohen M. M., 1993, Models and Techniques in Computer Animation, P139
   Costa P. T., 1992, PSYCHOL ASSESSMENT, V4, P5, DOI [10.1037/1040-3590.4.1.5, DOI 10.1037/1040-3590.4.1.5]
   EGGES A, 2003, 9 INT C MULT MOD
   Elliott C, 1992, THESIS NW U
   ELNASR M, 1999, P AUT AG 99
   Eysenck H. J., 1990, HDB PERSONALITY THEO, P244
   JOHNS M, 2001, 10 C COMP GEN FORC B
   Kshirsagar S, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P38, DOI 10.1109/CGI.2001.934656
   KSHIRSAGAR S, 2001, DEFORMABLE AVATARS, P33
   KSHIRSAGAR S, 2002, P 2 INT S SMART GRAP, P107
   MARSELLA S, 2002, P 1 INT JOINT C AUT
   MOFFAT D, 1995, LECT NOTES ARTIFICIA
   PIWEK P, 2002, ANNOTATED BIBLIO AFF
   VELASQUEZ JD, 1997, P AAAI 97, P10
NR 18
TC 86
Z9 92
U1 2
U2 16
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2004
VL 15
IS 1
BP 1
EP 13
DI 10.1002/cav.3
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 832EF
UT WOS:000222249300002
DA 2022-08-02
ER

PT S
AU Hartmann, B
   Mancini, M
   Pelachaud, C
AF Hartmann, Bjorn
   Mancini, Maurizio
   Pelachaud, Catherine
BE Gibet, S
   Courty, N
   Kamp, JF
TI Implementing expressive gesture synthesis for embodied conversational
   agents
SO GESTURE IN HUMAN-COMPUTER INTERACTION AND SIMULATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 6th International Workshop on Gesture in Human-Computer Interaction and
   Simulation
CY MAY 18-20, 2005
CL Berder Isl, FRANCE
AB We aim at creating an expressive Embodied Conversational Agent (ECA) and address the problem of synthesizing expressive agent gestures. In our previous work, we have described the gesture selection process. In this paper, we present a computational model of gesture quality. Once a certain gesture has been chosen for execution, how can we modify it to carry a desired expressive content while retaining its original semantics? We characterize bodily expressivity with a small set of dimensions derived from a review of psychology literature. We provide a detailed description of the implementation of these dimensions in our animation system, including our gesture modeling language. We also demonstrate animations with different expressivity settings in our existing ECA system. Finally, we describe two user studies that evaluate the appropriateness of our implementation for each dimension of expressivity as well as the potential of combining these dimensions to create expressive gestures that reflect communicative intent.
C1 Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
   Univ Paris 08, LIA, LINC, F-93100 Montreuil, France.
RP Hartmann, B (corresponding author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
EM bjoern@cs.stanford.edu; m.mancini@iut.univ-paris8.fr;
   c.pelachaud@iut.univ-paris8.fr
RI Mancini, Maurizio/D-9776-2015
OI Mancini, Maurizio/0000-0002-9933-8583
CR BLACK AW, FESTIVAL
   Cassell J., 2001, P SIGGRAPH 2001, P477, DOI 10. 1145/383259. 383315
   Chi D, 2000, COMP GRAPH, P173
   DECAROLIS B, 2004, LIFE LIKE CHARACTERS
   GALLAHER PE, 1992, J PERS SOC PSYCHOL, V63, P133, DOI 10.1037/0022-3514.63.1.133
   Gibet S., 2004, Gesture-Based Communication in Human-Computer Interaction. 5th International Gesture Workshop, GW 2003. Selected Revised Papers (Lecture Notes in Comput. Sci. Vol.2915), P1
   Hartmann B, 2002, COMP ANIM CONF PROC, P111, DOI 10.1109/CA.2002.1017516
   Kochanek D. H. U., 1984, Computers & Graphics, V18, P33
   KOPP S, 2004, J COMPUTER ANIMATION, V15
   Loyall A. B., 1997, Proceedings of the First International Conference on Autonomous Agents, P106, DOI 10.1145/267658.267681
   MARTELL C, 2003, FORM2 KINEMATIC GEST
   McNeill D., 1992, HAND MIND WHAT GESTU
   NEFF M, 2002, P 2002 ACM SIGGRAPH, P81
   Noot H, 2003, LECT NOTES ARTIF INT, V2915, P324
   TEPPER P, 2004, P WORKSHOP BALANCED
   TOLANI D, 1998, THESIS U PENNSYLVANI
   Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W
   WALLBOTT HG, 1986, J PERS SOC PSYCHOL, V51, P690, DOI 10.1037/0022-3514.51.4.690
NR 18
TC 52
Z9 52
U1 0
U2 3
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-32624-3
J9 LECT NOTES ARTIF INT
PY 2006
VL 3881
BP 188
EP 199
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BEE94
UT WOS:000237042600022
DA 2022-08-02
ER

PT J
AU Bickmore, TW
   Zhou, S
   Zhang, Z
   Paasche-Orlow, M
   Ahern, D
AF Bickmore, Timothy W.
   Zhou, Shuo
   Zhang, Zhe
   Paasche-Orlow, Michael
   Ahern, David
TI COMMUNICATING COMPLEX CANCER-RELATED PROTOCOLS USING CONVERSATIONAL
   AGENTS
SO ANNALS OF BEHAVIORAL MEDICINE
LA English
DT Meeting Abstract
C1 [Bickmore, Timothy W.; Zhou, Shuo; Zhang, Zhe] Northeastern Univ, Boston, MA 02115 USA.
   [Paasche-Orlow, Michael] Boston Med Ctr, Boston, MA USA.
   [Ahern, David] Brigham & Womens Hosp, Boston, MA 02115 USA.
EM bickmore@ccs.neu.edu; zhoushuo06@gmail.com; zessiez@gmail.com;
   david.ahern@nih.gov
RI Paasche-Orlow, Michael/ABF-7919-2020
OI Paasche-Orlow, Michael/0000-0002-9276-7190
NR 0
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0883-6612
EI 1532-4796
J9 ANN BEHAV MED
JI Ann. Behav. Med.
PD APR
PY 2015
VL 49
SU 1
MA 16
BP S64
EP S64
PG 1
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA DA5EH
UT WOS:000367825001249
DA 2022-08-02
ER

PT C
AU Zoric, G
   Smid, K
   Pandzic, IS
AF Zoric, G
   Smid, K
   Pandzic, IS
BE Tarumi, H
   Li, Y
   Yoshida, T
TI Automatic facial gesturing for conversational agents and avatars
SO PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON ACTIVE MEDIA
   TECHNOLOGY (AMT 2005)
LA English
DT Proceedings Paper
CT 3rd International Conference on Active Media Technology
CY MAY 19-21, 2005
CL Takamatsu, JAPAN
SP IEEE Syst, Man & Cybernet Soc, Informat Proc Soc Japan, Kagawa Univ
ID SPEECH
AB We present two methods for automatic facial gesturing of graphically embodied animated agents. In one case, conversational agent is driven by speech in automatic Lip Sync process. By analyzing speech input, lip movements are determined from the speech signal. Another method provides virtual speaker capable of reading plain English text and rendering it in a form of speech accompanied by the appropriate facial gestures. Proposed statistical model for generating virtual speaker's facial gestures, can be also applied as addition to lip synchronization process in order to obtain speech driven facial gesturing. In this case statistical model will be triggered with the input speech prosody instead of lexical analysis of the input text.
C1 Univ Zagreb, Fac Elect Engn & Comp, Dept Telecommun, HR-10000 Zagreb, Croatia.
RP Zoric, G (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Dept Telecommun, Unska 3, HR-10000 Zagreb, Croatia.
EM Goranka.Zoric@fer.hr; karlo.smid@ericsson.com; Igor.Pandzic@fer.hr
CR [Anonymous], 1996, BACKPROPAGATION ALGO
   AXELSSON A, 2003, THESIS LINKOPING U D
   Chen T, 1998, P IEEE, V86, P837, DOI 10.1109/5.664274
   DAVILA JJ, 1999, THESIS NEW YORK
   HADAR U, 1983, HUM MOVEMENT SCI, V2, P35, DOI 10.1016/0167-9457(83)90004-0
   Jones AJ., 1993, NEURAL COMPUT APPL, V1, P32, DOI [10.1007/BF01411373, DOI 10.1007/BF01411373]
   LEGOFF B, 1997, ESCA WORKSH AUD VIS, P145
   LEWIS JP, 1987, HUM FACT COMP SYST G, P143
   MCALLISTER DF, 1997, P SIGGRAPH 97
   Pandzic I.S., 2002, MPEG4 FACIAL ANIMATI
   Pelachaud C, 1996, COGNITIVE SCI, V20, P1
   RADMAN V, 2004, LEKSICKA ANAL TEKSTA
   Smid K, 2002, COMP ANIM CONF PROC, P240, DOI 10.1109/CA.2002.1017543
NR 13
TC 1
Z9 1
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 0-7803-9035-0
PY 2005
BP 505
EP 510
DI 10.1109/AMT.2005.1505411
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BCR76
UT WOS:000230959600113
DA 2022-08-02
ER

PT C
AU Hayashi, Y
AF Hayashi, Yugo
BE Micarelli, A
   Stamper, J
   Panourgia, K
TI Coordinating Knowledge Integration with Pedagogical Agents Effects of
   Agent Gaze Gestures and Dyad Synchronization
SO INTELLIGENT TUTORING SYSTEMS, ITS 2016
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 13th International Conference on Intelligent Tutoring Systems (ITS)
CY JUN 07-10, 2016
CL Zagreb, CROATIA
SP Inst Intelligent Syst, Natl Sci Fdn
DE Pedagogical Conversational Agents; Collaborative learning; Knowledge
   integration; Recurrence analysis
AB This study investigates how pedagogical conversational agents can facilitate learner-learner collaborative learning during a knowledge integration task. The study focuses on (1) how knowledge integration activity can be facilitated by using multiple Pedagogical Conversational Agents (PCAs) with gaze gestures and (2) how dyad coordination influences learners' perspective-changing processes and understanding. In a controlled experiment, dyads were accompanied by multiple PCAs programmed to facilitate learning. Two eye-trackers were used to detect the learner's learning process and coordination. The results show that learners who received facilitation from the PCAs about integrating different perspectives performed better on the task, and if they received gaze gestures, they tended to focus on the relationship of different knowledge as well. Recurrence analysis of gaze patterns show that those who performed well using PCAs synchronized their gaze.
C1 [Hayashi, Yugo] Ritsumeikan Univ, Coll Comprehens Psychol, 2-150 Iwakura Cho, Ibaraki, Osaka 5678570, Japan.
RP Hayashi, Y (corresponding author), Ritsumeikan Univ, Coll Comprehens Psychol, 2-150 Iwakura Cho, Ibaraki, Osaka 5678570, Japan.
EM y-hayashi@acm.org
CR Graesser A, 2010, EDUC PSYCHOL-US, V45, P234, DOI 10.1080/00461520.2010.515933
   Hayashi Yugo, 2012, Intelligent Tutoring Systems. Proceedings 11th International Conference (ITS 2012), P22, DOI 10.1007/978-3-642-30950-2_3
   Hayashi Y, 2014, LECT NOTES COMPUT SC, V8474, P114, DOI 10.1007/978-3-319-07221-0_14
   Holmes J, 2007, COMPUT EDUC, V48, P523, DOI 10.1016/j.compedu.2005.02.007
   Kumar R, 2011, IEEE T LEARN TECHNOL, V4, P21, DOI 10.1109/TLT.2010.41
   Richardson DC, 2007, PSYCHOL SCI, V18, P407, DOI 10.1111/j.1467-9280.2007.01914.x
   Roschelle J., 1992, J LEARN SCI, V2, P235, DOI DOI 10.1207/S15327809JLS0203_1
   Schneider B., 2014, INT J COMP-SUPP COLL, V4, P5
   Schwartz DL, 1995, J LEARN SCI, V4, P321, DOI 10.1207/s15327809jls0403_3
   TOMASELLO M, 1986, CHILD DEV, V57, P1454, DOI 10.1111/j.1467-8624.1986.tb00470.x
NR 10
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-319-39582-1; 978-3-319-39583-8
J9 LECT NOTES COMPUT SC
PY 2016
VL 9684
BP 254
EP 259
DI 10.1007/978-3-319-39583-8_26
PG 6
WC Computer Science, Interdisciplinary Applications; Education &
   Educational Research
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Education & Educational Research
GA BG5XP
UT WOS:000389805000026
DA 2022-08-02
ER

PT S
AU Nakano, YI
   Murayama, T
   Kawahara, D
   Kurohashi, S
   Nishida, T
AF Nakano, YI
   Murayama, T
   Kawahara, D
   Kurohashi, S
   Nishida, T
BE Palade, V
   Howlett, RJ
   Jain, L
TI Embodied conversational agents for presenting intellectual multimedia
   contents
SO KNOWLEDGE-BASED INTELLIGNET INFORMATION AND ENGINEERING SYSTEMS, PT 2,
   PROCEEDINGS
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
LA English
DT Article; Proceedings Paper
CT 7th International Conference on Knowledge-Based Intelligent Information
   and Engineering Systems (KES 2003)
CY SEP 03-05, 2003
CL UNIV OXFORD, OXFORD, ENGLAND
HO UNIV OXFORD
AB This paper presents an embodied conversational agent (ECA) that presents multimedia contents. The system takes plain text as input, and automatically generates a presentation featured with an animated agent. It selects and generates appropriate gestures and facial expressions for a humanoid agent according to linguistic information in the text. As a component of the ECA systems we also present an agent animation system, RISA, which can draw animations of natural human behaviors on web-based applications.
C1 Res Inst Sci & Technol Soc, Minato Ku, Tokyo 1056218, Japan.
   Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo Ku, Tokyo 1138656, Japan.
RP Nakano, YI (corresponding author), Res Inst Sci & Technol Soc, Minato Ku, Atago Green Hills MORI Tower 18F,2-5-1 Atago, Tokyo 1056218, Japan.
CR Cassell J, 2001, SIGGRAPH 01
   Fukuhara T, 2003, INTERNET BASED INTEL, P227
   GARU M, SIG CHI C HUM FACT C
   Grosz B. J., 1986, Computational Linguistics, V12, P175
   Halliday M. A. K., 1973, EXPLORATIONS FUNCTIO
   KUBOTA H, 2002, 7 PAC RIM INT C ART
   Kurohashi S., 1994, Computational Linguistics, V20, P507
   McNeill D., 1992, HAND MIND WHAT GESTU
   Nakanishi H, 1999, IEEE MULTIMEDIA, V6, P20, DOI 10.1109/93.771370
NR 9
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-40804-5
J9 LECT NOTES ARTIF INT
PY 2003
VL 2774
BP 1030
EP 1036
PG 7
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BX81U
UT WOS:000186518100141
DA 2022-08-02
ER

PT J
AU ter Stal, S
   Tabak, M
   op den Akker, H
   Beinema, T
   Hermens, H
AF ter Stal, Silke
   Tabak, Monique
   op den Akker, Harm
   Beinema, Tessa
   Hermens, Hermie
TI Who Do You Prefer? The Effect of Age, Gender and Role on Users' First
   Impressions of Embodied Conversational Agents in eHealth
SO INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION
LA English
DT Article
ID PEDAGOGICAL AGENTS; STEREOTYPE CONTENT; VISUAL PRESENCE; IMPACT;
   PERSONALITY; DESIGN; MODEL; COMPETENCE; APPEARANCE; WARMTH
AB Embodied conversational agents may be used to engage users in adopting eHealth applications. The aim of this research is to investigate which design features establish a positive first impression of an agent in this context. A set of eight static agent images, different in age, gender and role, were subjected to testing in an online questionnaire. Respondents (n = 155) selected their preferred design and rated the characteristics - friendliness, expertise, reliability, involvement and authority - and the likeliness of following the agent's advice for all designs. In addition, focus groups (n = 13) were conducted for detailed understandings supporting these impressions. Our results show that, for both a general and elderly population, (1) people seem to prefer images of young, female agents over old, male agents, (2) the (a) age, (b) gender and (c) role of the agent image affect the perception of the agent's characteristics and the likeliness of following the agent's advice, and that (3) both the general and elderly population prefer an agent image that is similar in (a) age and (b) gender. A next step would be to investigate how the characteristics of the agent designs are perceived after interaction with the agent.
C1 [ter Stal, Silke; Tabak, Monique; op den Akker, Harm; Beinema, Tessa; Hermens, Hermie] Roessingh Res & Dev, eHlth Grp, Enschede, Netherlands.
   [ter Stal, Silke; Tabak, Monique; op den Akker, Harm; Beinema, Tessa; Hermens, Hermie] Univ Twente, Math & Comp Sci, Enschede, Netherlands.
RP ter Stal, S (corresponding author), Roessingh Res & Dev, Enschede, Netherlands.
EM s.terstal@rrd.nl
RI Beinema, Tessa/AAH-8905-2021; Beinema, Tessa/AGD-2961-2022
OI Beinema, Tessa/0000-0003-3513-0641; op den Akker,
   Harm/0000-0001-6312-6063; Hermens, Hermie/0000-0002-3065-3876; Tabak,
   Monique/0000-0001-5082-1112; ter Stal, Silke/0000-0001-9458-717X
FU European Commission's Horizon 2020 Research and Innovation Programme
   project GOAL [731656]; European Commission's Horizon 2020 Research and
   Innovation Programme project Council of Coaches [769553]
FX This work was supported by the European Commission's Horizon 2020
   Research and Innovation Programme projects GOAL [Grant Agreement Number
   731656] and Council of Coaches [Grant Agreement Number 769553].
CR Alsharbi B., 2017, P 9 INT C COMP AUT E, P11
   Andreoletti C, 2015, INT J AGING HUM DEV, V81, P27, DOI 10.1177/0091415015616395
   ASHMORE RD, 1980, SEX ROLES, V6, P501, DOI 10.1007/BF00287882
   Bailenson JN, 2008, J APPL SOC PSYCHOL, V38, P2673, DOI 10.1111/j.1559-1816.2008.00409.x
   Bar M, 2006, EMOTION, V6, P269, DOI 10.1037/1528-3542.6.2.269
   Baylor AL, 2004, LECT NOTES COMPUT SC, V3220, P592
   Baylor AL, 2009, PHILOS T R SOC B, V364, P3559, DOI 10.1098/rstb.2009.0148
   Bergmann Kirsten, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P126, DOI 10.1007/978-3-642-33197-8_13
   BERRY DS, 1986, PSYCHOL BULL, V100, P3, DOI 10.1037/0033-2909.100.1.3
   Bickmore TW, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1265
   Cafaro Angelo, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P67, DOI 10.1007/978-3-642-33197-8_7
   Cafaro A, 2016, ACM T COMPUT-HUM INT, V23, DOI 10.1145/2940325
   Clark H. H., 1991, PERSPECTIVES SOCIALL, V13, P127, DOI DOI 10.1037/10096-006
   Cowell AJ, 2003, LECT NOTES ARTIF INT, V2792, P301
   Cuddy AJC, 2008, ADV EXP SOC PSYCHOL, V40, P61, DOI 10.1016/S0065-2601(07)00002-0
   FEINGOLD A, 1994, PSYCHOL BULL, V116, P429, DOI 10.1037/0033-2909.116.3.429
   Fiske ST, 2002, J PERS SOC PSYCHOL, V82, P878, DOI 10.1037//0022-3514.82.6.878
   Fogg B., 2011, PERSUASIVE TECHNOLOG, P89, DOI [10.1016/B978-155860643-2/50007-X, DOI 10.1016/B978-155860643-2/50007-X]
   Forlizzi Jodi, 2007, P 2007 C DES PLEAS P, P209
   Guadagno RE, 2007, MEDIA PSYCHOL, V10, P1
   Kaptein M, 2012, ACM T INTERACT INTEL, V2, DOI 10.1145/2209310.2209313
   Kim Y, 2007, J COMPUT ASSIST LEAR, V23, P220, DOI 10.1111/j.1365-2729.2006.00210.x
   Kim Y., 2003, E LEARN 2003 WORLD C, P2237, DOI [10.1007/978-3-540-30139-4_56, DOI 10.1007/978-3-540-30139-4{\_}56]
   Kreps GL, 2010, PATIENT EDUC COUNS, V78, P329, DOI 10.1016/j.pec.2010.01.013
   Lee YH, 2018, CYBERPSYCH BEH SOC N, V21, P173, DOI 10.1089/cyber.2017.0451
   Mohr DC, 2011, J MED INTERNET RES, V13, DOI 10.2196/jmir.1602
   Nguyen H., 2009, P INT C ULTR TEL WOR, P7
   Nijland N., 2011, THESIS, DOI [10.3990/1.9789036531337, DOI 10.3990/1.9789036531337]
   Nunamaker JE, 2011, J MANAGE INFORM SYST, V28, P17, DOI 10.2753/MIS0742-1222280102
   Oinas-Kukkonen H, 2009, COMMUN ASSOC INF SYS, V24, P485
   Paap D, 2019, PHYSIOTHER THEOR PR, V35, P1292, DOI 10.1080/09593985.2018.1471112
   Parmar D, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P301, DOI 10.1145/3267851.3267915
   Pearson SD, 2000, J GEN INTERN MED, V15, P509, DOI 10.1046/j.1525-1497.2000.11002.x
   Pfeifer Vardoulakis Laura, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P289, DOI 10.1007/978-3-642-33197-8_30
   Pope C, 2006, QUALITATIVE RES HLTH, P1, DOI DOI 10.1002/9780470750841.CH1
   Ridd M, 2009, BRIT J GEN PRACT, V59, P268, DOI 10.3399/bjgp09X420248
   Rosenberg-Kima RB, 2008, COMPUT HUM BEHAV, V24, P2741, DOI 10.1016/j.chb.2008.03.017
   Ruttkay Z, 2004, HUM-COMPUT INT-SPRIN, V7, P27
   Silvervarg Annika, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P153, DOI 10.1007/978-3-642-33197-8_16
   Van Velsen L, 2016, BMC MED INFORM DECIS, V16, DOI 10.1186/s12911-016-0250-2
   Vartanian O, 2012, PERS INDIV DIFFER, V52, P250, DOI 10.1016/j.paid.2011.05.024
   Veletsianos G, 2010, COMPUT EDUC, V55, P576, DOI 10.1016/j.compedu.2010.02.019
   Wissen Arlette, 2016, Persuasive Technology. 11th International Conference, PERSUASIVE 2016. Proceedings: LNCS 9638, P263, DOI 10.1007/978-3-319-31510-2_23
   Zimmerman J, 2005, DES PLEAS PROD INT 2, P233, DOI [10.1184/R1/6470366.v1, DOI 10.1184/R1/6470366.V1]
NR 44
TC 12
Z9 12
U1 6
U2 25
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 1044-7318
EI 1532-7590
J9 INT J HUM-COMPUT INT
JI Int. J. Hum.-Comput. Interact.
PD MAY 27
PY 2020
VL 36
IS 9
BP 881
EP 892
DI 10.1080/10447318.2019.1699744
EA DEC 2019
PG 12
WC Computer Science, Cybernetics; Ergonomics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA LK7SU
UT WOS:000503352700001
OA hybrid, Green Published
DA 2022-08-02
ER

PT C
AU Kohli, B
   Choudhury, T
   Sharma, S
   Kumar, P
AF Kohli, Bhaumik
   Choudhury, Tanupriya
   Sharma, Shilpi
   Kumar, Praveen
BE Kavitha, C
   Kavitha, KS
   Kumar, TS
   Niranjan, SK
TI A Platform for Human-Chatbot Interaction Using Python
SO PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON GREEN COMPUTING
   AND INTERNET OF THINGS (ICGCIOT 2018)
LA English
DT Proceedings Paper
CT 2nd IEEE International Conference on Green Computing and Internet of
   Things (ICGCIoT)
CY AUG 16-18, 2018
CL Bangalore, INDIA
SP Global Acad Technol, Dept Comp Sci & Eng, IEEE, IEEE Bangalore Sect, IEEE Computat Intelligence Soc, Bangalore Sect, IEEE Women Engn, Bangalore Sect, IEEE Consumer Elect Soc
DE Conversational agents; Chatbots; plat:Prim interactions
AB Over recent years, we've seen various customs for conversational agents. Chatbot is a conventional agent which is capable to communicate with operators by using natural lanpages. As numerous chatbot platforms already exist, there are still some problems in buildim.,, data -driven system because a Ing,Fe amount of data is required for its development. Thus, this paper describes various such agents which depend upon natural expressions implemented in Python. Moreover, to provide a better platform, web connectivity is also provided to evaluate the chatbot on a web -based platform which will help in analysing HumanChatbot interactions.
C1 [Kohli, Bhaumik; Sharma, Shilpi; Kumar, Praveen] Amity Univ Uttar Pradesh, Noida, India.
   [Choudhury, Tanupriya] Univ Petr & Energy Studies, Dehra Dun, Uttar Pradesh, India.
RP Kohli, B (corresponding author), Amity Univ Uttar Pradesh, Noida, India.
EM kohlibhaumik1996@gmail.com; tchoudhury@amity.edu; ssharma22@amity.edu;
   pkumar3@amity.edu
RI Choudhury, Tanupriya/AAB-8947-2020; Kumar, Praveen/W-7884-2019
OI Choudhury, Tanupriya/0000-0002-9826-2759; Kumar,
   Praveen/0000-0002-9606-8960
CR [Anonymous], 2009, NATURAL LANGUAGE PRO
   Jia J., 2004, SOC INF TECHN TEACH, P1201
   Le Q. V., 2015, NEURAL CONVERSATIONA
   Lin Lue, 2016, HAI 2016 OCT
   Lue Lin, WOCHAT WORKSH COLL 6
   Pereira M. J., 2013, JUST CHAT PLATFORM P
   Wallace R. S., 2009, PARSING TURING TEST, P181, DOI DOI 10.1007/978-1-4020-6710-5_13
   Weizenbaum J., 1966, ELIZA COMPUTER PROGR
NR 8
TC 0
Z9 0
U1 0
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-5386-5657-0
PY 2018
BP 439
EP 444
PG 6
WC Computer Science, Theory & Methods; Green & Sustainable Science &
   Technology
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Science & Technology - Other Topics
GA BN5KN
UT WOS:000483465600076
DA 2022-08-02
ER

PT J
AU Ter Stal, S
   Jongbloed, G
   Tabak, M
AF Ter Stal, Silke
   Jongbloed, Gerbrich
   Tabak, Monique
TI Embodied Conversational Agents in eHealth: How Facial and Textual
   Expressions of Positive and Neutral Emotions Influence Perceptions of
   Mutual Understanding
SO INTERACTING WITH COMPUTERS
LA English
DT Article
DE embodied conversational agent; emotion; facial expressions; textual
   expressions; rapport; eHealth
ID IMPACT
AB Embodied conversational agents (ECAs) could engage users in eHealth by building mutual understanding (i.e. rapport) via emotional expressions. We compared an ECA's emotions expressed in text with an ECA's emotions in facial expressions on users' perceptions of rapport. We used a 2 x 2 design, combining a happy or neutral facial expression with a happy or neutral textual expression. Sixty-three participants (mean, 48 +/- 22 years) had a dialogue with an ECA on healthy living and rated multiple rapport items. Results show that participants' perceived rapport for an ECA with a happy facial expression and neutral textual expression and an ECA with a neutral facial expression and happy textual expression was significantly higher than the neutral value of the rapport scale (P = 0.049 and P = 0.008, respectively). Furthermore, results show no significant difference in overall rapport between the conditions (P = 0.062), but a happy textual expression for an ECA with a neutral facial expression shows higher ratings of the individual rapport items helpfulness (P = 0.019) and enjoyableness (P = 0.028). Future research should investigate users' rapport towards an ECA with different emotions in long-term interaction and how a user's age and personality and an ECA's animations affect rapport building. Optimizing rapport building between a user and an ECA could contribute to achieving long-term interaction with eHealth.
C1 [Ter Stal, Silke; Tabak, Monique] Roessingh Res & Dev, eHlth Grp, Roessinghsbleekweg 33b, NL-7522 AH Enschede, Netherlands.
   [Ter Stal, Silke; Tabak, Monique] Univ Twente, Fac Elect Engn Math & Comp Sci, Drienerlolaan 5, NL-7522 NB Enschede, Netherlands.
   [Jongbloed, Gerbrich] Univ Twente, Fac Behav Management & Social Sci, Drienerlolaan 5, NL-7522 NB Enschede, Netherlands.
RP Ter Stal, S (corresponding author), Roessingh Res & Dev, eHlth Grp, Roessinghsbleekweg 33b, NL-7522 AH Enschede, Netherlands.; Ter Stal, S (corresponding author), Univ Twente, Fac Elect Engn Math & Comp Sci, Drienerlolaan 5, NL-7522 NB Enschede, Netherlands.
EM s.terstal@utwente.nl
OI Tabak, Monique/0000-0001-5082-1112
CR Acosta JC, 2011, SPEECH COMMUN, V53, P1137, DOI 10.1016/j.specom.2010.11.006
   Amini Reza, 2014, Advancing the Impact of Design Science: Moving from Theory to Practice. 9th International Conference, DESRIST 2014. Proceedings: LNCS 8463, P433, DOI 10.1007/978-3-319-06701-8_40
   Beale R, 2009, INT J HUM-COMPUT ST, V67, P755, DOI 10.1016/j.ijhcs.2009.05.001
   Beer JM, 2015, INT J HUM-COMPUT ST, V75, P1, DOI 10.1016/j.ijhcs.2014.11.005
   Bevacqua E., 2007, P AISB 07 LANG SPEEC, P208
   Cerekovic A, 2017, IEEE T AFFECT COMPUT, V8, P382, DOI 10.1109/TAFFC.2016.2545650
   Cerekovic A, 2014, LECT NOTES COMPUT SC, V8749, P1, DOI 10.1007/978-3-319-11839-0_1
   Creed C, 2015, INTERACT COMPUT, V27, P172, DOI 10.1093/iwc/iwt064
   DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061
   Ekman Paul, 1978, FACIAL ACTION CODING
   Gratch J, 2007, LECT NOTES ARTIF INT, V4722, P125
   Gratch J, 2007, LECT NOTES COMPUT SC, V4552, P286
   Hancock JT, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P929
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI 10.1109/AFGR.2000.840611
   Kelders SM, 2012, J MED INTERNET RES, V14, P17, DOI 10.2196/jmir.2104
   Kim Y, 2007, J COMPUT ASSIST LEAR, V23, P220, DOI 10.1111/j.1365-2729.2006.00210.x
   Llorach G., 2019, WEB BASED EMBODIED C
   Loveys K, 2020, INT J SOC ROBOT, V12, P1293, DOI 10.1007/s12369-020-00680-7
   Moridis CN, 2012, IEEE T AFFECT COMPUT, V3, P260, DOI 10.1109/T-AFFC.2012.6
   Novick D, 2014, LECT NOTES COMPUT SC, V8511, P472, DOI 10.1007/978-3-319-07230-2_45
   Pelachaud C, 2009, SPEECH COMMUN, V51, P630, DOI 10.1016/j.specom.2008.04.009
   Ranjbartabar Hedieh, 2019, IEEE T AFFECTIVE COM
   Ruttkay Z, 2004, HUM-COMPUT INT-SPRIN, V7, P27
   Schroder M, 2012, IEEE T AFFECT COMPUT, V3, P165, DOI 10.1109/T-AFFC.2011.34
   Tickle-Degnen L, 1990, PSYCHOL INQ, V1, P285, DOI DOI 10.1207/S15327965PLI0104_
   WALTHER JB, 1992, COMMUN RES, V19, P52, DOI 10.1177/009365092019001003
NR 26
TC 0
Z9 0
U1 4
U2 5
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 0953-5438
EI 1873-7951
J9 INTERACT COMPUT
JI Interact. Comput.
PD MAR
PY 2021
VL 33
IS 2
BP 167
EP 176
DI 10.1093/iwc/iwab019
EA JUL 2021
PG 10
WC Computer Science, Cybernetics; Ergonomics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA UZ4AV
UT WOS:000702150400004
OA hybrid
DA 2022-08-02
ER

PT C
AU Kocielnik, R
   Avrahami, D
   Marlow, J
   Lu, D
   Hsieh, G
AF Kocielnik, Rafal
   Avrahami, Daniel
   Marlow, Jennifer
   Lu, Di
   Hsieh, Gary
GP Assoc Comp Machinery
TI Designing for Workplace Reflection: A Chat and Voice-Based
   Conversational Agent
SO DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS
   CONFERENCE
LA English
DT Proceedings Paper
CT Designing Interactive Systems (DIS) Conference
CY JUN 09-13, 2018
CL Hong Kong, HONG KONG
SP Assoc Comp Machinery, ACM SIGCHI
DE Conversational agents; bots; modalities; workspace activity reporting;
   reflection
AB Conversational agents stand to play an important role in supporting behavior change and well-being in many domains. With users able to interact with conversational agents through both text and voice, understanding how designing for these channels supports behavior change is important. To begin answering this question, we designed a conversational agent for the workplace that supports workers' activity journaling and self-learning through reflection. Our agent, named Robota, combines chat-based communication as a Slack Bot and voice interaction through a personal device using a custom Amazon Alexa Skill. Through a 3-week controlled deployment, we examine how voice-based and chat-based interaction affect workers' reflection and support self-learning. We demonstrate that, while many current technical limitations exist, adding dedicated mobile voice interaction separate from the already busy chat modality may further enable users to step back and reflect on their work. We conclude with discussion of the implications of our findings to design of workplace self-tracking systems specifically and to behavior-change systems in general.
C1 [Kocielnik, Rafal; Avrahami, Daniel; Marlow, Jennifer; Lu, Di] FXPAL, Palo Alto, CA 94304 USA.
   [Kocielnik, Rafal; Avrahami, Daniel; Hsieh, Gary] Univ Washington, HCDE, DUB Grp, Seattle, WA 98195 USA.
   [Lu, Di] Univ Pittsburgh, Pittsburgh, PA USA.
   [Marlow, Jennifer] Google, Mountain View, CA USA.
RP Kocielnik, R (corresponding author), FXPAL, Palo Alto, CA 94304 USA.; Kocielnik, R (corresponding author), Univ Washington, HCDE, DUB Grp, Seattle, WA 98195 USA.
EM rkoc@uw.edu; daniel@fxpal.com; jamarlow@google.com; di.lu@pitt.edu;
   garyhs@uw.edu
CR Agapie E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1072, DOI 10.1145/2858036.2858142
   Alrubail Rusul, SCAFFOLDING STUDENT
   Amabile TM, 2011, HARVARD BUS REV, V89, P70
   [Anonymous], 1988, LEARNING DOING GUIDE
   Anseel F, 2009, ORGAN BEHAV HUM DEC, V110, P23, DOI 10.1016/j.obhdp.2009.05.003
   Avrahami D, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P439, DOI 10.1145/3172944.3172962
   Bain JD., 1999, TEACH TEACH, V5, P51, DOI [10.1080/1354060990050104, DOI 10.1080/1354060990050104]
   Baruch Y, 2003, PERS REV, V32, P231, DOI 10.1108/00483480310460234
   Baumer Eric P. S., 2014, P 2014 C DES INT SYS, DOI DOI 10.1145/2598510.2598598
   Bickmore T, 2007, LECT NOTES COMPUT SC, V4744, P1
   Boud D, 2013, REFLECTION TURNING E
   Carrasco M., 2017, P 2017 CHI C EXT ABS, P2429
   Consolvo S, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P54
   Consolvo S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P405
   Cordeiro F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1159, DOI 10.1145/2702123.2702155
   Cranshaw J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2382, DOI 10.1145/3025453.3025780
   Dhillon B, 2011, LECT NOTES COMPUT SC, V6947, P392, DOI 10.1007/978-3-642-23771-3_29
   Epstein DA, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5632, DOI 10.1145/2858036.2858044
   Eraut M., 2004, STUDIES CONTINUING E, V26, P247, DOI DOI 10.1080/158037042000225245
   Faulring A, 2010, IUI 2010, P61
   Gil Yolanda, 2008, 13th International Conference on Intelligent User Interfaces. IUI 2008, DOI 10.1145/1378773.1378822
   Gustafson K., 1999, ISSUES DIFFICULTIES
   Hanington B., 2012, UNIVERSAL METHODS DE
   HATTON N, 1995, TEACH TEACH EDUC, V11, P33, DOI 10.1016/0742-051X(94)00012-U
   Hewitson Tom, 2017, MEDIUM
   Hsieh G, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P164, DOI 10.1145/1409635.1409657
   Hutchinson B., 1997, ED ACTION RES, V5, P283
   Jia Y, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2001, DOI 10.1145/2858036.2858515
   Kale P, 2007, STRATEGIC MANAGE J, V28, P981, DOI 10.1002/smj.616
   Kang J, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P229, DOI 10.1145/3109859.3109873
   Kinnafick FE, 2014, QUAL HEALTH RES, V24, P706, DOI 10.1177/1049732314528811
   Klopfenstein LC, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P555, DOI 10.1145/3064663.3064672
   Kocielnik R., 2017, P 20 ACM C COMP SUPP
   Kocielnik R, 2013, COMP MED SY, P53, DOI 10.1109/CBMS.2013.6627764
   Kocielnik R, 2013, INT CONF PER COMP, P184, DOI 10.4108/icst.pervasivehealth.2013.251934
   Kocielnik Rafal, 2012, ED DATA MINING
   Krogstie B. R., 2012, 2012 IEEE 12th International Conference on Advanced Learning Technologies (ICALT), P151, DOI 10.1109/ICALT.2012.107
   Li JY, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P275, DOI 10.1145/3025171.3025206
   Liao QV, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P264, DOI 10.1145/2901790.2901842
   Loo R., 2002, TEAM PERFORMANCE MAN, V8, P134, DOI DOI 10.1108/13527590210442258
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Luria M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P580, DOI 10.1145/3025453.3025786
   McGregor M, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P2208, DOI 10.1145/2998181.2998335
   Miller S, 2005, REFLECT PRACT, V6, P367, DOI 10.1080/14623940500220129
   Moon J. A, 2013, REFLECTION LEARNING
   NEUWIRTH CM, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P51
   Oh S, 2017, INT SOC DESIGN CONF, P173, DOI 10.1109/ISOCC.2017.8368846
   Ohlin F, 2015, P 20 INT C INT US IN, P263, DOI [10.1145/2678025.2701378, DOI 10.1145/2678025.2701378]
   Oraby S, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P343, DOI 10.1145/3025171.3025191
   Pammer Viktoria, 2015, Design for Teaching and Learning in a Networked World. 10th European Conference on Technology-Enhanced Learning, EC-TEL 2015. Proceedings: LNCS 9307, P467, DOI 10.1007/978-3-319-24258-3_41
   Peters Rifca, 2017, P 22 INT C INT US IN, P401
   Ploderer B, 2014, PERS UBIQUIT COMPUT, V18, P1667, DOI 10.1007/s00779-014-0779-y
   Pope M, 2000, CAREER DEV Q, V48, P194, DOI 10.1002/j.2161-0045.2000.tb00286.x
   Rooksby J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P284, DOI 10.1145/2858036.2858055
   Schon DA., 1983, REFLECTIVE PRACTITIO
   Scott Kevin, 2016, CHATBOTS MAGAZINE
   Seo Eunji  Jinny, 2017, CHATBOTS MAGAZINE
   Sherin M., 2002, P SITE 2002 SOC INFO, P2532
   Staats, 2015, LEARNING THINKING OV
   Staats Bradley., 2014, LEARNING THINKING RE
   Stillman Jessica, 2013, COMMUNICATION
   Storey MA, 2016, FSE'16: PROCEEDINGS OF THE 2016 24TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON FOUNDATIONS OF SOFTWARE ENGINEERING, P928, DOI 10.1145/2950290.2983989
   Tannenbaum A., 2013, SOCIAL PSYCHOL WORK
   TAYLOR SE, 1991, PSYCHOL BULL, V110, P67, DOI 10.1037/0033-2909.110.1.67
   Whittaker S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1729, DOI 10.1145/2858036.2858193
   Xu Anbang, 2017, P SIGCHI C HUM FACT
   Yen Y.-C.G., 2017, P 2017 ACM SIGCHI C, P158, DOI [10.1145/3059454, DOI 10.1145/3059454.3059468]
   Yoon D, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P195, DOI 10.1145/2818048.2819951
   Zollo M, 2002, ORGAN SCI, V13, P339, DOI 10.1287/orsc.13.3.339.2780
NR 70
TC 19
Z9 19
U1 1
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5198-0
PY 2018
BP 881
EP 894
DI 10.1145/3196709.3196784
PG 14
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BN3BA
UT WOS:000478673400075
DA 2022-08-02
ER

PT J
AU Diederich, S
   Brendel, AB
   Morana, S
   Kolbe, L
AF Diederich, Stephan
   Brendel, Alfred Benedikt
   Morana, Stefan
   Kolbe, Lutz
TI On the Design of and Interaction with Conversational Agents: An
   Organizing and Assessing Review of Human-Computer Interaction Research
SO JOURNAL OF THE ASSOCIATION FOR INFORMATION SYSTEMS
LA English
DT Review
DE Conversational Agent; Chatbot; Digital Assistant; Virtual Human; Robot;
   Organizing Review; Assessing Review; Human-Computer Interaction
ID HUMAN-ROBOT INTERACTION; VIRTUAL AGENTS; INFORMATION-SYSTEMS;
   PEDAGOGICAL AGENTS; NATURAL-LANGUAGE; SELF-DISCLOSURE; MENTAL-HEALTH;
   ARTIFICIAL-INTELLIGENCE; RESEARCH-PERSPECTIVES; INTERACTION STYLE
AB Conversational agents (CAs), described as software with which humans interact through natural language, have increasingly attracted interest in both academia and practice because of improved capabilities driven by advances in artificial intelligence and, specifically, natural language processing. CAs are used in contexts such as people's private lives, education, and healthcare, as well as in organizations to innovate or automate tasks-for example, in marketing, sales, or customer service. In addition to these application contexts, CAs take on different forms in terms of their embodiment, the communication mode, and their (often human-like) design. Despite their popularity, many CAs are unable to fulfill expectations, and fostering a positive user experience is challenging. To better understand how CAs can be designed to fulfill their intended purpose and how humans interact with them, a number of studies focusing on human-computer interaction have been carried out in recent years, which have contributed to our understanding of this technology. However, currently, a structured overview of this research is lacking, thus impeding the systematic identification of research gaps and knowledge on which future studies can build. To address this issue, we conducted an organizing and assessing review of 262 studies, applying a sociotechnical lens to analyze CA research regarding user interaction, context, agent design, as well as CA perceptions and outcomes. This study contributes an overview of the status quo of CA research, identifies four research streams through cluster analysis, and proposes a research agenda comprising six avenues and sixteen directions to move the field forward.
C1 [Diederich, Stephan; Kolbe, Lutz] Univ Gottingen, Chair Informat Management, Gottingen, Germany.
   [Brendel, Alfred Benedikt] Tech Univ Dresden, Business Informat Syst Esp Intelligent Syst & Ser, Dresden, Germany.
   [Morana, Stefan] Saarland Univ, Digital Transformat & Informat Syst, Saarbrucken, Germany.
RP Diederich, S (corresponding author), Univ Gottingen, Chair Informat Management, Gottingen, Germany.
EM diederich@icloud.com; alfred_benedikt.brendel@tu-dresden.de;
   stefan.morana@uin-saarland.de; lkolbe@uni-goettingen.de
CR Abul M., 2018, PROC HAWAII INT CONF
   Adam M., 2019, P 27 EUR C INF SYST
   Adler RF, 2016, COMPUT HUM BEHAV, V57, P75, DOI 10.1016/j.chb.2015.12.011
   Al-Natour S., 2009, PROC INT CONF INFORM
   Al-Natour S, 2006, J ASSOC INF SYST, V7, P821, DOI 10.17705/1jais.00110
   Al-Natour S, 2009, J ASSOC INF SYST, V10, P661
   Anabuki M., 2000, P ACM CHI C HUM FACT, DOI 10.1145/633292.633299
   [Anonymous], 2018, MIS QUART
   Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Ashktorab Z, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300484
   Baier D., 2018, 39 INT C INF SYST IC
   Bandara W, 2015, COMMUN ASSOC INF SYS, V37, P154
   Banker RD, 2004, MANAGE SCI, V50, P281, DOI 10.1287/mnsc.1040.0206
   Banks J, 2018, COMPUT HUM BEHAV
   BARIFF ML, 1982, DATA BASE, V14, P19
   Beale R, 2009, INT J HUM-COMPUT ST, V67, P755, DOI 10.1016/j.ijhcs.2009.05.001
   Belbin RM., 2010, MANAGEMENT TEAMS WHY, DOI [10.4324/9780080963594, DOI 10.4324/9780080963594]
   Belk RW, 2013, J CONSUM RES, V40, P477, DOI 10.1086/671052
   BELK RW, 1988, J CONSUM RES, V15, P139, DOI 10.1086/209154
   Bell S, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3313072
   Ben Mimoun MS, 2012, J RETAIL CONSUM SERV, V19, P605, DOI 10.1016/j.jretconser.2012.07.006
   Benbasat I., 2005, J ASSOC INF SYST, V6, P72, DOI [10.17705/1jais.00065, DOI 10.17705/1JAIS.00065]
   Benlian A, 2020, INFORM SYST J, V30, P1010, DOI 10.1111/isj.12243
   Berdichevsky D, 1999, COMMUN ACM, V42, P51, DOI 10.1145/301353.301410
   Berg MM, 2015, LECT NOTES COMPUT SC, V9103, P144, DOI 10.1007/978-3-319-19581-0_12
   Berger, 2018, INT C INF SYST ISCI, P1
   Bertacchini F, 2017, COMPUT HUM BEHAV, V77, P382, DOI 10.1016/j.chb.2017.02.064
   Bhattacherjee A., 2012, SOCIAL SCI RES PRINC
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore T, 2005, TEXT SPEECH LANG TEC, V30, P23
   Bittner E., 2019, P 52 HAW INT C SYST
   Bittner EAC, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P227
   Bogardus ES, 1947, SOCIOMETRY, V10, P306, DOI 10.2307/2785570
   Braun M, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3313051
   Brocke J.V., 2009, ECIS 2009 P, P161
   Brynjolfsson E, 2016, 2 MACHINE AGE WORK P
   Burgoon J., 1995, INTERPERSONAL ADAPTA
   Burgoon JK, 2016, INT J HUM-COMPUT ST, V91, P24, DOI 10.1016/j.ijhcs.2016.02.002
   Burmester M, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312821
   Burton N, 2019, 25TH AMERICAS CONFERENCE ON INFORMATION SYSTEMS (AMCIS 2019)
   BYRNE D, 1969, J EXP RES PERS, V3, P179
   BYRNE D, 1967, J PERS SOC PSYCHOL, V5, P82, DOI 10.1037/h0021198
   Byrne D., 1971, ATTRACTION PARADIGM
   Cafaro A, 2016, ACM T COMPUT-HUM INT, V23, DOI 10.1145/2940325
   Candello H, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300320
   CARD SK, 1980, COMMUN ACM, V23, P396, DOI 10.1145/358886.358895
   Cardona D. R., 2019, P AM C INF SYST
   Carlotto T, 2016, INT J HUM-COMPUT ST, V95, P15, DOI 10.1016/j.ijhcs.2016.06.001
   Carroll J. M, 2020, ENCY HUMAN COMPUTER, V2nd
   Carter M, 2013, STRATEGY, ADOPTION, AND COMPETITIVE ADVANTAGE OF MOBILE SERVICES IN THE GLOBAL ECONOMY, P150, DOI 10.4018/978-1-4666-1939-5.ch008
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   Cassell J., 1999, P ACM CHI C HUM FACT
   Chattaraman V, 2019, COMPUT HUM BEHAV, V90, P315, DOI 10.1016/j.chb.2018.08.048
   Chaves AP, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173765
   Cho E, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300488
   Clark L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300705
   Comendador Benilda Eleonor V., 2015, Journal of Automation and Control Engineering, V3, P137, DOI 10.12720/joace.3.2.137-140
   Constantin A, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312811
   Cooper H. M., 1988, KNOWLEDGE SOC, V1, P104, DOI 10.1007/BF03177550
   Corti K, 2016, COMPUT HUM BEHAV, V58, P431, DOI 10.1016/j.chb.2015.12.039
   Coupland N., 1991, CONTEXTS ACCOMMODATI, P1, DOI [10.1017/CBO9780511663673, DOI 10.1017/CBO9780511663673.001]
   Cowan BR, 2015, INT J HUM-COMPUT ST, V83, P27, DOI 10.1016/j.ijhcs.2015.05.008
   Cowell AJ, 2005, INT J HUM-COMPUT ST, V62, P281, DOI 10.1016/j.ijhcs.2004.11.008
   Crockett K, 2017, INT J HUM-COMPUT ST, V97, P98, DOI 10.1016/j.ijhcs.2016.08.005
   Dale R, 2016, NAT LANG ENG, V22, P811, DOI 10.1017/S1351324916000243
   Davenport TH, 2016, MIT SLOAN MANAGE REV, V57, P21
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   de Rosis F, 2003, INT J HUM-COMPUT ST, V59, P81, DOI 10.1016/S1071-5819(03)00020-X
   Dennis A., 2001, COMMUNICATIONS, V7, P1
   Derrick DC, 2014, COMPUT HUM BEHAV, V33, P39, DOI 10.1016/j.chb.2013.12.027
   Desideri L, 2019, COMPUT HUM BEHAV, V90, P331, DOI 10.1016/j.chb.2018.08.013
   Diederich S., 2019, P EUR C INF SYST
   Diederich S., 2021, AIS T HUMAN COMPUTER, V13, P82
   Diederich S, 2020, BUS INFORM SYST ENG+, V62, P193, DOI 10.1007/s12599-020-00639-y
   Dolata M, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P105
   Duan W, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188600
   Ducheneaut N, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1151
   Elson JS, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P430
   Epley N, 2007, PSYCHOL REV, V114, P864, DOI 10.1037/0033-295X.114.4.864
   Fadhil A., 2017, ADJ PUBL 25 C US MOD, P408, DOI [10.1145/3099023.3099112, DOI 10.1145/3099023.3099112]
   Fast E., 2017, P ACM CHI C HUM FACT
   Feine J., 2019, CHATBOT RES DESIGN, P79
   Feine J., 2019, P 14 INT C WIRTSCH W
   Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009
   Floridi L, 2019, NAT MACH INTELL, V1, P261, DOI 10.1038/s42256-019-0055-y
   Folstad A., 2017, INTERACTIONS, V24, P38, DOI [10.1145/3085558, DOI 10.1145/3085558]
   Forlizzi Jodi, 2007, P 2007 C DES PLEAS P, P209
   Fryer LK, 2017, COMPUT HUM BEHAV, V75, P461, DOI 10.1016/j.chb.2017.05.045
   Fung, 2017, P CHI C HUM FACT COM, P2255
   Gambino A, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312916
   Gefen D., 2003, E SERVICE, V2, P7, DOI [DOI 10.2979/ESJ.2003.2.2.7, https://doi.org/10.2979/esj.2003.2.2.7]
   GERLACH JH, 1991, MIS QUART, V15, P527, DOI 10.2307/249456
   Gnewuch U, 2018, 26 EUR C INF SYST EC
   Gnewuch U., 2017, P 38 INT C INFORM SY
   Go E, 2019, COMPUT HUM BEHAV, V97, P304, DOI 10.1016/j.chb.2019.01.020
   Goasduff L., 2019, CHATBOTS WILL APPEAL
   Gong L, 2008, COMPUT HUM BEHAV, V24, P1494, DOI 10.1016/j.chb.2007.05.007
   GOODHUE DL, 1995, MIS QUART, V19, P213, DOI 10.2307/249689
   Graesser AC, 2001, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P460, DOI 10.1109/ICALT.2001.943979
   Graesser A, 2010, EDUC PSYCHOL-US, V45, P234, DOI 10.1080/00461520.2010.515933
   Graesser AC, 2017, COMPUT HUM BEHAV, V76, P607, DOI 10.1016/j.chb.2017.03.041
   Graesser AC, 2014, CURR DIR PSYCHOL SCI, V23, P374, DOI 10.1177/0963721414540680
   Gregor S, 2020, J ASSOC INF SYST, V21, P1622, DOI 10.17705/1jais.00649
   GRICE HP, 1975, SYNTAX SEMANTICS, V3, DOI DOI 10.1111/J.1365-2664.2006.01229.X
   Groom V., 2008, P 4 ACM IEEE INT C H
   Grudin J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300439
   Gulz A, 2006, INT J HUM-COMPUT ST, V64, P322, DOI 10.1016/j.ijhcs.2005.08.006
   Hanus MD, 2015, INT J HUM-COMPUT ST, V84, P33, DOI 10.1016/j.ijhcs.2015.07.004
   Harjunen VJ, 2018, COMPUT HUM BEHAV, V87, P384, DOI 10.1016/j.chb.2018.06.012
   Hayashi Y, 2013, P ACM CHI C HUM FACT
   Heinrich L. J., 2011, BUS INFORM SYST ENG+
   Herborn K, 2020, COMPUT HUM BEHAV, V104, DOI 10.1016/j.chb.2018.07.035
   Hill J, 2015, COMPUT HUM BEHAV, V49, P245, DOI 10.1016/j.chb.2015.02.026
   Hleg A., 2019, B1049
   Hobert S., 2019, P 14 INT C WIRTSCH, P301
   Hobert S., 2019, 40 INT C INF SYST MU, P1
   Hong JW, 2019, COMPUT HUM BEHAV, V100, P79, DOI 10.1016/j.chb.2019.06.012
   Hsu P., 2017, P CHI C EXT ABSTR HU
   Hu T., 2018, P IEEE INT C COMM IC, P1
   Huang C.-M, 2012, P ACM CHI C HUM FACT
   Huang MH, 2018, J SERV RES-US, V21, P155, DOI 10.1177/1094670517752459
   Hubal RC, 2008, COMPUT HUM BEHAV, V24, P1104, DOI 10.1016/j.chb.2007.03.010
   Hwang G, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312915
   Hyde J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1719, DOI 10.1145/2702123.2702465
   Ipsoft, 2020, AM ACT SEL STOR ORG
   Jain M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174042
   Jeong Y, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312913
   Jin SAA, 2010, COMPUT HUM BEHAV, V26, P443, DOI 10.1016/j.chb.2009.12.003
   Johnson K., 2018, FACEBOOK MESSENGER H
   Johnson WL, 2000, INT J ARTIFICIAL INT, V11, P47
   Jucks R, 2018, ADV HUM-COMPUT INTER, V2018, DOI 10.1155/2018/8406187
   Jung H, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1109/CLEOE-EQEC.2019.8871790, 10.1145/3290607.3312979]
   Kanaoka T, 2015, 2015 P 33 ANN ACM C, P1445, DOI [10.1145/2702613.2732924, DOI 10.1145/2702613.2732924]
   Kim D, 2018, P PAC AS C INF SYST
   Kim KJ, 2013, COMPUT HUM BEHAV, V29, P1799, DOI 10.1016/j.chb.2013.02.009
   Kim Y, 2014, INT J HUM-COMPUT ST, V72, P783, DOI 10.1016/j.ijhcs.2014.05.005
   Kim Y, 2013, COMPUT HUM BEHAV, V29, P1091, DOI 10.1016/j.chb.2012.10.001
   Knijnenburg BP, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2963106
   Kocaballi AB, 2019, J MED INTERNET RES, V21, DOI 10.2196/15360
   Kowalski J, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312973
   Kozlowski SWJ, 2018, PERSPECT PSYCHOL SCI, V13, P205, DOI 10.1177/1745691617697078
   Kramer NC, 2018, INT J HUM-COMPUT ST, V109, P112, DOI 10.1016/j.ijhcs.2017.09.001
   Kramer N, 2013, INT J HUM-COMPUT ST, V71, P335, DOI 10.1016/j.ijhcs.2012.09.006
   Kumar R, 2018, P ACM CHI C HUM FACT
   Lahoual D, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299053
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Larsen KR, 2016, MIS QUART, V40, P529, DOI 10.25300/MISQ/2016/40.3.01
   Laumer S, 2019, P 27 EUR C INF SYST
   Le Bigot L, 2006, COMPUT HUM BEHAV, V22, P467, DOI 10.1016/j.chb.2004.10.006
   Lechler R., 2019, P EUR C INF SYST
   Lee C., 2004, P ACM CHI C HUM FACT
   Lee KM, 2006, INT J HUM-COMPUT ST, V64, P962, DOI 10.1016/j.ijhcs.2006.05.002
   Lee M. K., 2012, P ACM CHI C HUM FACT
   Lee SY, 2017, INT J HUM-COMPUT ST, V103, P95, DOI 10.1016/j.ijhcs.2017.02.005
   Lehto T., 2017, AIS T HUMAN COMPUTER, V7, P126
   Leidner DE, 2018, J ASSOC INF SYST, V19, P552, DOI 10.17705/1jais.00501
   Leite I, 2013, INT J HUM-COMPUT ST, V71, P250, DOI 10.1016/j.ijhcs.2012.09.005
   Lembcke T. B., 2019, P 27 EUR C INF SYST
   Li, 2005, J ASSOC INF SYST, V6, P227, DOI [10.17705/1jais.00070, DOI 10.17705/1JAIS.00070]
   Li DH, 2006, DECISION SCI, V37, P427, DOI 10.1111/j.1540-5414.2006.00133.x
   Li J, 2015, INT J HUM-COMPUT ST, V77, P23, DOI 10.1016/j.ijhcs.2015.01.001
   Liao QV, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173577
   Looije R, 2010, INT J HUM-COMPUT ST, V68, P386, DOI 10.1016/j.ijhcs.2009.08.007
   Louwerse MM, 2009, APPL COGNITIVE PSYCH, V23, P1244, DOI 10.1002/acp.1527
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Luxton DD, 2020, B WORLD HEALTH ORGAN, V98, P285, DOI 10.2471/BLT.19.237636
   Maedche A., 2019, BUSINESS INFORM SYST, P1
   Malone TW, 2018, MIT SLOAN MANAGE REV, V59, P34
   Massaro Dominic W., 1999, HUMAN PERFORMANCE ER, V2nd, P173
   Matsushita M, 2004, INT J HUM-COMPUT ST, V60, P469, DOI 10.1016/j.ijhcs.2003.11.004
   Mavridis P, 2019, ACM UMAP '19: PROCEEDINGS OF THE 27TH ACM CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION, P243, DOI 10.1145/3320435.3320439
   McAfee A., 2017, MACHINE PLATFORM CRO
   McGreevey JD, 2020, JAMA-J AM MED ASSOC, V324, P552, DOI 10.1001/jama.2020.2724
   McQuiggan SW, 2007, INT J HUM-COMPUT ST, V65, P348, DOI 10.1016/j.ijhcs.2006.11.015
   McTear M.F., 2017, LECT NOTES COMPUTER, P38, DOI [https://doi.org/10.1007/978-3-319-69365-1_3, DOI 10.1007/978-3-319-69365-1_3]
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   Meier P., 2019, PROC INT CONF INFORM
   Meyer von Wolff R., 2019, P AM C INF SYST
   Miner A., 2016, P 4 INT C HUM AG INT, P123, DOI DOI 10.1145/2974804.2974820
   Miner AS, 2016, JAMA INTERN MED, V176, P619, DOI 10.1001/jamainternmed.2016.0400
   Moon Y, 2000, J CONSUM RES, V26, P323, DOI 10.1086/209566
   Morana S., 2020, P EUR C INF SYST
   Morana S., 2019, 40 INT C INF SYST, P1
   Moreno R., 2012, CAMBRIDGE HDB MULTIM, P507
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Morton H, 2012, ADV HUM-COMPUT INTER, V2012, DOI 10.1155/2012/389523
   Mou Y, 2017, COMPUT HUM BEHAV, V72, P432, DOI 10.1016/j.chb.2017.02.067
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   NextIT, 2018, HELP RAILR SERV COND
   Nguyen QN, 2017, AMCIS 2017 PROCEEDINGS
   Niewiadomski R, 2010, INT J HUM-COMPUT ST, V68, P851, DOI 10.1016/j.ijhcs.2010.07.004
   Nunamaker JE, 2011, J MANAGE INFORM SYST, V28, P17, DOI 10.2753/MIS0742-1222280102
   O'Leary DE, 2019, INTELL SYST ACCOUNT, V26, P46, DOI 10.1002/isaf.1443
   Olson GM, 2003, ANNU REV PSYCHOL, V54, P491, DOI 10.1146/annurev.psych.54.101601.145044
   Oracle, 2016, CAN VIRT EXP REPL RE
   Otoo B. A., 2018, PROC INT CONF INFORM
   Pelachaud C., 2017, P 1 ACM SIGCH INT WO, P22, DOI [10.1145/3139491.3139498, DOI 10.1145/3139491.3139498]
   Pereira A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1449, DOI 10.1145/2556288.2557180
   Perez S, 2016, TECHCRUNCH
   Pfeuffer N., 2019, PROC INT CONF INFORM
   Pickard MD, 2016, COMPUT HUM BEHAV, V65, P23, DOI 10.1016/j.chb.2016.08.004
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169
   Porcheron M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174214
   Powers A, 2006, P 1 ACM SIGCHISIGART, P218, DOI [10.1145/1121241.1121280, DOI 10.1145/1121241.1121280]
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   PUNJ G, 1983, J MARKETING RES, V20, P134, DOI 10.2307/3151680
   Purington A, 2017, 2017 CHI C HUM FACT, DOI [10.1145/3027063.3053246, DOI 10.1145/3027063.3053246]
   Qiu LY, 2010, INT J HUM-COMPUT ST, V68, P669, DOI 10.1016/j.ijhcs.2010.05.005
   Qiu LY, 2009, J MANAGE INFORM SYST, V25, P145, DOI 10.2753/MIS0742-1222250405
   Quynh N., 2018, P AM C INF SYST
   Racheva A., 2019, P AM C INF SYST
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Reinecke K, 2013, MIS QUART, V37, P427, DOI 10.25300/MISQ/2013/37.2.06
   Rosenberg-Kima RB, 2008, COMPUT HUM BEHAV, V24, P2741, DOI 10.1016/j.chb.2008.03.017
   Rosenthal-von der Putten AM, 2019, COMPUT HUM BEHAV, V90, P397, DOI 10.1016/j.chb.2018.08.047
   Rosenthal-von der Putten AM, 2014, COMPUT HUM BEHAV, V36, P422, DOI 10.1016/j.chb.2014.03.066
   Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68
   Saerbeck M, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1613
   Saffarizadeh K., 2017, PROC INT CONF INFORM
   Sakamoto D, 2005, INT J HUM-COMPUT ST, V62, P247, DOI 10.1016/j.ijhcs.2004.11.001
   Sangseok Y., 2019, PROC INT CONF INFORM
   Schlesinger A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173889
   Schroeder J, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P472
   Schuetz S, 2020, J ASSOC INF SYST, V21, P460, DOI 10.17705/1jais.00608
   Schuetzler RM, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P283
   Schunemann Rogerio, 2014, ISRN Microbiol, V2014, P135675, DOI 10.1155/2014/135675
   Sebastian J, 2017, COMPUT HUM BEHAV, V73, P479, DOI 10.1016/j.chb.2017.03.071
   Seeber I, 2020, INFORM MANAGE-AMSTER, V57, DOI 10.1016/j.im.2019.103174
   Seeber I, 2020, INTERNET RES, V30, P1, DOI 10.1108/INTR-12-2019-0503
   Seeger A.-M., 2018, PROC INT CONF INFORM
   Seeger A.-M., 2017, P 16 ANN PREICIS WOR
   Seering J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300680
   Seymour M, 2017, PROCEEDINGS OF THE 50TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P547
   Seymour M, 2018, J ASSOC INF SYST, V19, P953, DOI 10.17705/1jais.00515
   Shah H, 2016, COMPUT HUM BEHAV, V58, P278, DOI 10.1016/j.chb.2016.01.004
   Shamekhi A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173965
   Sohn S, 2019, PROC INT CONF INFORM
   Sollner M., 2020, WI2020 ZENTRALE TRAC, P99
   Son Y., 2018, P 39 INT C INFORM SY
   Stieglitz S., 2018, INT C INF SYST
   Stock R., 2019, PROC INT CONF INFORM
   Stock R. M., 2018, PROC INT CONF INFORM
   Stock RM, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P1056
   Stoeckli E, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P2016
   Strait M., 2015, P ACM CHI C HUM FACT
   Strassmann C, 2018, ADV HUM-COMPUT INTER, V2018, DOI 10.1155/2018/2589542
   Strohmann T., 2018, P PAC AS C INF SYST, P3580
   Sugumaran V., 2001, P AM C INF SYST
   Szafir Daniel, 2012, P SIGCHI C HUM FACT, P11, DOI 10.1145/2207676.2207679
   Tavanapour N., 2019, P EUR C INF SYST
   Tickle-Degnen L, 1990, PSYCHOL INQ, V1, P285, DOI DOI 10.1207/S15327965PLI0104_
   Tinwell A, 2014, COMPUT HUM BEHAV, V36, P286, DOI 10.1016/j.chb.2014.03.073
   Toxtli C, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173632
   Truong A., 2016, PARENTS ARE WORRIED
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   Van den Broeck E, 2019, COMPUT HUM BEHAV, V98, P150, DOI 10.1016/j.chb.2019.04.009
   van der Meij H, 2013, COMPUT HUM BEHAV, V29, P845, DOI 10.1016/j.chb.2012.10.018
   van Vugt HC, 2010, ACM T COMPUT-HUM INT, V17, DOI 10.1145/1746259.1746261
   Veletsianos G., 2014, HDB RES ED COMMUNICA, P759, DOI [DOI 10.1007/978-1-4614-3185-5_61, 10.1007/978-1-4614-3185-5_61]
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Vertegaal R., 2001, P ACM CHI C HUM FACT
   Vertegaal R., 2000, P ACM CHI C HUM FACT
   Vogel-Meijer K., 2018, KLM MAKING AIRLINE C
   Vtyurina A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173782
   Wagner K., 2019, PROC INT CONF INFORM
   Wakefield J., 2016, WOULD YOU WANT TALK
   Wang N, 2008, INT J HUM-COMPUT ST, V66, P98, DOI 10.1016/j.ijhcs.2007.09.003
   Ward N, 2003, INT J HUM-COMPUT ST, V59, P603, DOI 10.1016/S1071-5819(03)00085-5
   Watanabe M., 2015, P 33 ANN ACM C HUM F, P781
   Webster J, 2002, MIS QUART, V26, pXIII
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   WELCH C, 2018, VERGE
   Wik P, 2009, SPEECH COMMUN, V51, P1024, DOI 10.1016/j.specom.2009.05.006
   Winkler R., 2019, P ACM CHI C HUM FACT
   Winkler R., 2019, PROC INT CONF INFORM
   Wolff R. M. Von, 2019, PROC HAWAII INT CONF
   Wunderlich N.V., 2017, P 38 INT C INFORM SY, P1
   Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496
   Xu K, 2017, COMPUT HUM BEHAV, V74, P152, DOI 10.1016/j.chb.2017.04.043
   Xu Q., 2013, SIGCHI C HUM FACT CO, P2233
   Yamada S., 2013, P ACM CHI C HUM FACT
   Yokotani K, 2018, COMPUT HUM BEHAV, V85, P135, DOI 10.1016/j.chb.2018.03.045
   You S, 2018, J ASSOC INF SYST, V19, P377, DOI 10.17705/1jais.00496
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
   Zhang P, 2004, COMPUT HUM BEHAV, V20, P125, DOI 10.1016/j.chb.2003.10.011
   Zhang P., 2008, AIS T HUMAN COMPUTER, V1, P55
   Zhang P., 2002, COMMUN ASSOC INF SYS, V9, P344
   Zhang YX, 2019, COMPUT HUM BEHAV, V98, P140, DOI 10.1016/j.chb.2019.04.008
NR 288
TC 9
Z9 9
U1 45
U2 45
PU ASSOC INFORMATION SYSTEMS
PI ATLANTA
PA GEORGIA STATE UNIV, 35 BROAD STREET, STE 916-917, ATLANTA, GA 30303 USA
SN 1536-9323
EI 1558-3457
J9 J ASSOC INF SYST
JI J. Assoc. Inf. Syst.
PY 2022
VL 23
IS 1
BP 96
EP 138
DI 10.17705/1jais.00724
PG 43
WC Computer Science, Information Systems; Information Science & Library
   Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Information Science & Library Science
GA YH0GO
UT WOS:000742855500003
DA 2022-08-02
ER

PT C
AU Chen, XT
   Ma, L
   Jia, MH
   Han, YJ
   Mi, JQ
   Xu, M
AF Chen, Xiantao
   Ma, Liang
   Jia, Menghua
   Han, Yajuan
   Mi, Jiaqi
   Xu, Meng
BE Kurosu, M
TI How to Evaluate a Good Conversation? An Evaluation Framework for Chat
   Experience in Smart Home
SO HUMAN-COMPUTER INTERACTION: THEORY, METHODS AND TOOLS, HCII 2021, PT I
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 23rd International Conference on Human-Computer Interaction (HCII)
CY JUL 24-29, 2021
CL ELECTR NETWORK
DE Smart conversational agents; Chat-oriented dialogue; Evaluation metrics;
   Smart speaker; Smart home
AB With the development of artificial intelligence technology, more and more smart devices equipped with smart conversational agents, which can engage in chat or free conversation with human. However, the human-machine chat is still in the early stage of development, and there is a lack of effective methods to evaluate chat experience. In this study we proposed a framework to evaluate chat experience with smart conversational agents in smart home. Firstly, we collected evaluation metrics, and then applied them in the first user test and optimized the metrics and constructed an evaluation system. Finally, we carried out the second user test to validate the evaluation system with SEM. The results indicated that the evaluation system had good reliability, validity and internal consistency, which can be used to evaluate the user experience of smart conversational agents' chat-oriented dialogue.
C1 [Chen, Xiantao; Jia, Menghua; Han, Yajuan; Mi, Jiaqi; Xu, Meng] Baidu AI User Experience Dept, Beijing, Peoples R China.
   [Ma, Liang] Heilongjian Bayi Agr Univ, Coll Engn, Daqing, Peoples R China.
RP Chen, XT (corresponding author), Baidu AI User Experience Dept, Beijing, Peoples R China.
EM chenxiantao@baidu.com
CR Banchs R. E., 2012, P ACL 2012 SYST DEM, P37
   Bang J, 2015, INT CONF BIG DATA, P238, DOI 10.1109/35021BIGCOMP.2015.7072837
   Bickmore T., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P396
   Bordes A., 2017, P ICLR
   Busemann S., 1997, P 5 C APPL NLP, P25
   Deriu J, 2021, ARTIF INTELL REV, V54, P755, DOI 10.1007/s10462-020-09866-x
   Duplessis GD, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2728
   Gandhe S., 2007, INTERSPEECH, P2201
   GRICE HP, 1975, SYNTAX SEMANTICS, V3, DOI DOI 10.1111/J.1365-2664.2006.01229.X
   Hassenzahl Marc, 2003, FUNOLOGY USABILITY E, V3, P31, DOI DOI 10.1007/1-4020-2967-5_4
   Leech Geoffrey, 1983, PRINCIPLES PRAGMATIC
   Liu Chia-Wei, 2016, ARXIV160308023
   Papineni K., 2002, P 2 INT C HUMAN LANG, P132
   Radziwill NM, 2017, EVALUATING QUALITY C, P1
   Seneff S., 2000, P ANLP NAACL WORKSH, P11, DOI DOI 10.3115/1117562.1117565
   Serban I.V., 2015, COMPUT SCI, V33, P6078
   Shawar B. A., 2007, P WORKSH BRIDG GAP A, P89, DOI [10.3115/1556328.1556341, DOI 10.3115/1556328.1556341]
   Stallard D, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, P68
   Wilcock G, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P73, DOI 10.1145/2522848.2531753
   Yu ZX, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND INTELLIGENT CONTROL (ISIC 2015), P108
   Yu Zhou, 2016, SIGDIAL, P404, DOI 10.18653/v1/W16-3649
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
   Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI [10.1162/coli_a_00368, 10.1162/COLI_a_00368]
NR 23
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-78462-1; 978-3-030-78461-4
J9 LECT NOTES COMPUT SC
PY 2021
VL 12762
BP 351
EP 362
DI 10.1007/978-3-030-78462-1_27
PG 12
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Software Engineering; Computer Science,
   Theory & Methods; Ergonomics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Engineering
GA BS7RL
UT WOS:000766308000027
DA 2022-08-02
ER

PT J
AU Grimes, GM
   Schuetzler, RM
   Giboney, JS
AF Grimes, Mark G.
   Schuetzler, Ryan M.
   Giboney, Justin Scott
TI Mental models and expectation violations in conversational AI
   interactions
SO DECISION SUPPORT SYSTEMS
LA English
DT Article
DE Conversational AI; Chatbots; Conversational agents; Engagement
AB Artificial Intelligence is increasingly becoming integrated in many aspects of human life. One particular AI comes in the form of conversational agents (CAs) such as Siri, Alexa, and chatbots used for customer service on websites and other information systems. It is widely accepted that humans treat systems as social actors. Leveraging this bias, companies sometimes attempt to masquerade a CA as a human customer service representative. In addition to the ethical and legal questions around this practice, the benefits and drawbacks of a CA pretending to be human are unclear due to a lack of study. While more human-like interactions can improve outcomes, when users find out that the CA is not human, they may have a negative reaction that may cause reputation harm in the company. In this research we use Expectation Violation Theory to explain what happens when users have high or low expectations of a conversation. We conducted an experiment with 175 participants where some participants were told they were interacting with a CA while others were told they were interacting with a human. We further divided the groups so that some participants interacted with a CA with low conversational capability while others interacted with a CA with high conversational capability. The results show that expectations formed by the user before the interaction change how the user evaluates the CA beyond the actual performance of the CA. These findings provide guidance to developers not just of conversational agents, but also for other technologies where users may be uncertain of a system?s capabilities.
C1 [Grimes, Mark G.] Univ Houston, CT Bauer Coll Business, Houston, TX 77004 USA.
   [Schuetzler, Ryan M.; Giboney, Justin Scott] Brigham Young Univ, Provo, UT 84602 USA.
RP Grimes, GM (corresponding author), Univ Houston, CT Bauer Coll Business, Houston, TX 77004 USA.
EM gmgrimes@bauer.uh.edu; ryan.schuetzler@byu.edu; justin_giboney@byu.edu
OI Schuetzler, Ryan/0000-0002-5807-2168
CR Appel J, 2012, ADV HUM-COMPUT INTER, V2012, DOI 10.1155/2012/324694
   Avgerou C, 2013, J ASSOC INF SYST, V14, P420
   Bhattacherjee, 2017, COMMUN ASSOC INF SYS, V40, P502, DOI [https://doi.org/10.17705/1CAIS.04023, DOI 10.17705/1CAIS.04023]
   Biber G.D., 2002, LEECH LONGMAN STUDEN
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Bottles K., 2011, WILL PATIENTS TRUST
   Brown SA, 2008, ORGAN BEHAV HUM DEC, V105, P52, DOI 10.1016/j.obhdp.2006.09.008
   Brown SA, 2014, MIS QUART, V38, P729, DOI 10.25300/MISQ/2014/38.3.05
   Budiu Raluca, 2019, MENTAL MODELS INTELL
   BURGOON JK, 1988, COMMUN MONOGR, V55, P58, DOI 10.1080/03637758809376158
   BURGOON JK, 1989, J NONVERBAL BEHAV, V13, P97
   Burgoon JK., 1993, J LANG SOC PSYCHOL, V12, P30, DOI [10.1177/0261927X93121003, DOI 10.1177/0261927X93121003]
   Burgoon JK, 2016, INT J HUM-COMPUT ST, V91, P24, DOI 10.1016/j.ijhcs.2016.02.002
   Chetupalli SR, 2018, NATL CONF COMMUN
   Chih-Hsiung Tu, 2002, American Journal of Distance Education, V16, P131, DOI 10.1207/S15389286AJDE1603_2
   Devashish Mamgain, 2020, CHATBOT HUMAN HANDOF
   Diresta Renee, 2019, WIRED
   Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009
   Floyd K., 2007, NONVERBAL COMMUN REA
   Gershgorn D., 2018, QUARTZ
   Giboney JS, 2015, DECIS SUPPORT SYST, V72, P1, DOI 10.1016/j.dss.2015.02.005
   Gnewuch U., 2018, 26 EUR C INF SYST DI
   Goode S, 2017, MIS QUART, V41, P703
   GRICE HP, 1975, SYNTAX SEMANTICS, V3, DOI DOI 10.1111/J.1365-2664.2006.01229.X
   Grimes M, 2019, DECIS SUPPORT SYST, V119, P23, DOI 10.1016/j.dss.2019.02.010
   Grudin J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300439
   Guadagno RE, 2007, MEDIA PSYCHOL, V10, P1
   Gudykunst W.B., 2005, THEORIZING INTERCULT, P149, DOI 10.1002/9781119168058.ch3
   Heerink M, 2010, VIRTUAL REAL-LONDON, V14, P77, DOI 10.1007/s10055-009-0142-1
   Heinzl A, 2018, INT C INF SYST 2018, P1
   Holtgraves TM, 2007, COMPUT HUM BEHAV, V23, P2163, DOI 10.1016/j.chb.2006.02.017
   Howcroft D, 2010, J ASSOC INF SYST, V11, P122
   Hsu Jeremy, 2019, SCI AM
   Jensen ML, 2011, J MANAGE INFORM SYST, V28, P201, DOI 10.2753/MIS0742-1222280107
   KELLEY DL, 1991, HUM COMMUN RES, V18, P40, DOI 10.1111/j.1468-2958.1991.tb00528.x
   Kirakowski J, 2007, LECT NOTES COMPUT SC, V4552, P376
   Kobori Y, 2018, J UROLOGY, V199, pE189, DOI 10.1016/j.juro.2018.02.516
   Koufaris M, 2002, INFORM SYST RES, V13, P205, DOI 10.1287/isre.13.2.205.83
   Lee T, 2019, INTELLIGENT CAREER A
   Leviathan Yaniv., 2018, GOOGLE DUPLEX AI SYS
   Liu GHW, 2015, J ASSOC INF SYST, V16, P707, DOI 10.17705/1jais.00404
   Long LN, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN SECURITY AND DEFENSE APPLICATIONS, P69, DOI 10.1109/CISDA.2007.368137
   Lopatovska Irene, 2018, Proceedings of the Association for Information Science and Technology, V55, DOI 10.1002/pra2.2018.14505501034
   Luo XM, 2019, MARKET SCI, V38, P937, DOI 10.1287/mksc.2019.1192
   Morana S, 2017, DECIS SUPPORT SYST, V97, P31, DOI 10.1016/j.dss.2017.03.003
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Nass C, 1999, J APPL SOC PSYCHOL, V29, P1093, DOI 10.1111/j.1559-1816.1999.tb00142.x
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nguyen M.-H., 2020, BUSINESS INSIDER
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Nunamaker JE, 2011, J MANAGE INFORM SYST, V28, P17, DOI 10.2753/MIS0742-1222280102
   Park S, 2019, J MED INTERNET RES, V21, DOI 10.2196/12231
   Phillips E., 2011, P HUMAN FACTORS ERGO, DOI [10.1177/1071181311551310, DOI 10.1177/1071181311551310]
   Purington A, 2017, 2017 CHI C HUM FACT, DOI [10.1145/3027063.3053246, DOI 10.1145/3027063.3053246]
   Qiu LY, 2009, J MANAGE INFORM SYST, V25, P145, DOI 10.2753/MIS0742-1222250405
   Raza MQ, 2015, RENEW SUST ENERG REV, V50, P1352, DOI 10.1016/j.rser.2015.04.065
   Rzepka C., 2018, ICIS 2018 P
   Schuetzler RM, 2020, J MANAGE INFORM SYST, V37, P875, DOI 10.1080/07421222.2020.1790204
   Schuetzler RM, 2019, COMPUT HUM BEHAV, V97, P250, DOI 10.1016/j.chb.2019.03.033
   Schuetzler RM, 2018, DECIS SUPPORT SYST, V114, P94, DOI 10.1016/j.dss.2018.08.011
   Schumaker RP, 2007, DECIS SUPPORT SYST, V43, P1419, DOI 10.1016/j.dss.2006.04.007
   Shihab E, 2020, CHALLENGES CHATBOT D, DOI [10.1145/3379597.3387472, DOI 10.1145/3379597.3387472]
   SIMON HA, 1976, COGNITIVE PSYCHOL, V8, P165, DOI 10.1016/0010-0285(76)90022-0
   Steelman ZR, 2014, MIS QUART, V38, P355, DOI 10.25300/MISQ/2014/38.2.02
   Strohmann T., 2019, AIS T HUMAN COMPUTER, V11, P54, DOI [https://doi.org/10.17705/1thci.00113, DOI 10.17705/1THCI.00113]
   Subramaniam S, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P597
   Sundar SS, 2016, COMMUN RES, V43, P595, DOI 10.1177/0093650214534962
   SZAJNA B, 1993, MIS QUART, V17, P493, DOI 10.2307/249589
   Vaezi R, 2016, COMMUN ASSOC INF SYS, V38, P501, DOI 10.17705/1CAIS.03827
   Venkatesh V, 2000, MANAGE SCI, V46, P186, DOI 10.1287/mnsc.46.2.186.11926
   Wang SH, 2004, COGNITION, V93, P167, DOI 10.1016/j.cognition.2003.09.012
   Wilcox B., 2017, CHATSCRIPT
   Wise L., 2018, SOC MEDIA WEEK
   Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496
NR 74
TC 5
Z9 5
U1 19
U2 58
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-9236
EI 1873-5797
J9 DECIS SUPPORT SYST
JI Decis. Support Syst.
PD MAY
PY 2021
VL 144
AR 113515
DI 10.1016/j.dss.2021.113515
EA MAR 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Operations Research & Management Science
GA RF5GI
UT WOS:000634866300004
DA 2022-08-02
ER

PT J
AU Luo, B
   Lau, RYK
   Li, CP
   Si, YW
AF Luo, Bei
   Lau, Raymond Y. K.
   Li, Chunping
   Si, Yain-Whar
TI A critical review of state-of-the-art chatbot designs and applications
SO WILEY INTERDISCIPLINARY REVIEWS-DATA MINING AND KNOWLEDGE DISCOVERY
LA English
DT Review
DE Chatbot applications; Chatbots; conversational agents; deep learning;
   machine learning
ID ACADEMICALLY PRODUCTIVE TALK; CONVERSATIONAL AGENTS; USER ACCEPTANCE;
   LANGUAGE; NETWORKS
AB Chatbots are intelligent conversational agents that can interact with users through natural languages. As chatbots can perform a variety of tasks, many companies have committed numerous resources to develop and deploy chatbots to enhance various business processes. However, we lack an up-to-date critical review that thoroughly examines both state-of-the-art technologies and innovative applications of chatbots. In this review, we not only critically analyze the various computational approaches used to develop state-of-the-art chatbots, but also thoroughly review the usability and applications of chatbots for various business sectors. We also identify gaps in chatbot-related studies and propose new research directions to address the shortcomings of existing studies and applications. Our review advances both academic research and practical business applications of state-of-the-art chatbots. We provide guidance for practitioners to fully realize the business value of chatbots and assist in making sensible decisions related to the development and deployment of chatbots in various business contexts. Researchers interested in the design and development of chatbots can also gain useful insights from our critical review and identify fruitful research topics and future research directions based on the research gaps discussed herein. This article is categorized under: Technologies > Machine Learning Application Areas > Business and Industry
C1 [Luo, Bei; Lau, Raymond Y. K.] City Univ Hong Kong, Dept Informat Syst, Kowloon, Tat Chee Ave, Hong Kong, Peoples R China.
   [Li, Chunping] Tsinghua Univ, Sch Software, Beijing, Peoples R China.
   [Si, Yain-Whar] Univ Macau, Fac Sci & Technol, Macau, Peoples R China.
RP Lau, RYK (corresponding author), City Univ Hong Kong, Dept Informat Syst, Kowloon, Tat Chee Ave, Hong Kong, Peoples R China.
EM raylau@cityu.edu.hk
RI Si, Yain-Whar/AAN-7946-2020
OI Si, Yain-Whar/0000-0001-8468-6182; LUO, Bei/0000-0001-8393-6506; Lau,
   Raymond/0000-0002-5751-4550
FU Research Grants Council of the Hong Kong Special Administrative Region,
   China [CityU 11507219]; City University of Hong Kong SRG [7005196]
FX Our research work was partly supported by a grant from the Research
   Grants Council of the Hong Kong Special Administrative Region, China
   (Project: CityU 11507219), and a grant from the City University of Hong
   Kong SRG (Project: 7005196).
CR Abd-Alrazaq A, 2020, J MED INTERNET RES, V22, DOI 10.2196/18301
   Abdul-Kader SA, 2017, PROCEEDINGS OF THE 2017 INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P863, DOI 10.1109/IntelliSys.2017.8324231
   Abdul-Kader SA, 2015, INT J ADV COMPUT SC, V6, P72
   Abu Shawar B, 2017, COMPUT SIST, V21, P615, DOI [10.13053/CyS-21-4-2868, 10.13053/cys-21-4-2868]
   ABUSHAWAR B, 2015, COMPUTACI N SISTEMAS, V19, P1, DOI DOI 10.13053/CYS-19-4-2326
   Ahmadvand A, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1273, DOI 10.1145/3331184.3331375
   Akkiraju R, 2018, TOUCH YOUR HEART TON, DOI [10.1097/00003727-199507000-00013, DOI 10.1097/00003727-199507000-00013]
   Altinok D, 2018, ONTOLOGY BASED DIALO
   [Anonymous], 2015, P 16 ANN M SPEC INT
   Arsovski S, 2020, APPL INTELL, V50, P2040, DOI 10.1007/s10489-019-01621-2
   Arsovski S, 2019, EXPERT SYST APPL, V137, P343, DOI 10.1016/j.eswa.2019.07.014
   Bahdanau D., 2014, 3 INT C LEARN REPR I, P1
   Beketov M, 2018, J ASSET MANAG, V19, P363, DOI 10.1057/s41260-018-0092-9
   Belfin RV, 2019, INT CONF ADVAN COMPU, P717, DOI 10.1109/ICACCS.2019.8728499
   Ben Mimoun MS, 2012, J RETAIL CONSUM SERV, V19, P605, DOI 10.1016/j.jretconser.2012.07.006
   Bendig E, 2019, VERHALTENSTHERAPIE, V29, P266, DOI 10.1159/000499492
   Bengio, 2018, DEEP REINFORCEMENT L, P1
   Bibault JE, 2019, J MED INTERNET RES, V21, DOI 10.2196/15787
   Bocklisch T., 2017, RASA OPEN SOURCE LAN, P1
   Bozic J, 2018, LECT NOTES COMPUT SC, V11146, P33, DOI 10.1007/978-3-319-99927-2_3
   Bradesko L., 2012, P SLOV LANG TECHN SO, P34
   Marietto MDB, 2014, LECT NOTES COMPUT SC, V8610, P513, DOI 10.1007/978-3-319-09912-5_43
   Bunk T., 2020, 200409936 CORR, V2004
   Caballe S, 2019, LECT NOTE DATA ENG, V23, P384, DOI 10.1007/978-3-319-98557-2_35
   Cho K, 2014, ARXIV14061078, V2014, P1724, DOI DOI 10.3115/V1/D14-1179
   Chung J., 2014, P NIPS WORKSH DEEP L, P1
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Cuayahuitl H, 2019, NEUROCOMPUTING, V366, P118, DOI 10.1016/j.neucom.2019.08.007
   Cui L, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P97, DOI 10.18653/v1/P17-4017
   Cyr D, 2006, INFORM MANAGE-AMSTER, V43, P950, DOI 10.1016/j.im.2006.08.009
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   de Gennaro M, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.03061
   Deryugina OV, 2010, SCI TECH INF PROCESS, V37, P143, DOI 10.3103/S0147688210020097
   Devlin J., 2018, ARXIV
   Doherty D, 2019, WEB INTELL, V17, P327, DOI 10.3233/WEB-190422
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Fadhil A, 2019, METHOD INFORM MED, V58, P9, DOI 10.1055/s-0039-1688757
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Folstad A, 2018, LECT NOTES COMPUT SC, V11193, P194, DOI 10.1007/978-3-030-01437-7_16
   Fryer LK, 2017, COMPUT HUM BEHAV, V75, P461, DOI 10.1016/j.chb.2017.05.045
   Galvao AM, 2004, LECT NOTES ARTIF INT, V3315, P963
   Gao, 2020, SOLOIST BUILDING TAS
   Gardiner PM, 2017, PATIENT EDUC COUNS, V100, P1720, DOI 10.1016/j.pec.2017.04.015
   Ghosh Charulata, 2020, HCI for Cybersecurity, Privacy and Trust. Second International Conference, HCI-CPT 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12210), P381, DOI 10.1007/978-3-030-50309-3_25
   Goo C.W., 2018, P 2018 C N AM CHAPTE, V2, P753
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Greer S, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/15018
   Guo H, 2015, HIGHLIGHT THEOR CHEM, V8, P1
   Handoyo E, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, COMPUTER, AND ELECTRICAL ENGINEERING (ICITACEE), P325, DOI 10.1109/ICITACEE.2018.8576921
   Haristiani N, 2019, J ENG SCI TECHNOL, V14, P3158
   Hauser-Ulrich S, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/15806
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hongshen Chen, 2017, ACM SIGKDD Explorations Newsletter, V19, P25, DOI 10.1145/3166054.3166058
   Huang CY, 2018, IN C IND ENG ENG MAN, P1791, DOI 10.1109/IEEM.2018.8607399
   Jonell, 2019, P INT JOINT C AUT AG, V4, P2420
   Jusoh, 2019, P 10 INT C EL COMP A, P2018, DOI [10.1109/ECAI.2018.8679045, DOI 10.1109/ECAI.2018.8679045]
   Kadariya D, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP 2019), P138, DOI [10.1109/SMARTCOMP.2019.00043, 10.1109/smartcomp.2019.00043]
   Kadous MW, 2004, LECT NOTES ARTIF INT, V3157, P644
   Kasinathan V, 2017, IEEE CONF OPEN SYST, P32, DOI 10.1109/ICOS.2017.8280270
   Katchapakirin K, 2018, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON ADVANCES IN INFORMATION TECHNOLOGY (IAIT2018), DOI 10.1145/3291280.3291787
   Kimani Everlyne, 2019, 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII). Proceedings, P332, DOI 10.1109/ACII.2019.8925488
   Kocaballi AB, 2020, J MED INTERNET RES, V22, DOI 10.2196/15823
   Krassmann AL, 2019, IEEE GLOB ENG EDUC C, P322, DOI 10.1109/EDUCON.2019.8725064
   Kuramoto I, 2018, HAI'18: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT INTERACTION, P114, DOI 10.1145/3284432.3284457
   Kvale Knut, 2020, Chatbot Research and Design. Third International Workshop, CONVERSATIONS 2019. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 11970), P187, DOI 10.1007/978-3-030-39540-7_13
   Lai S.-T., 2018, P INT C BROADB WIR C, P561, DOI [10.1007/978-3-030-02613-4_50, DOI 10.1007/978-3-030-02613-4_50]
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Latham AM, 2010, IEEE INT CONF FUZZY
   Lau Josephine, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274371
   Le, 2014, ADV NEURAL INFORM PR, P3104
   Lee MC, 2020, MULTIMED TOOLS APPL, V79, P19629, DOI 10.1007/s11042-020-08841-6
   Lokman AS, 2011, COMM COM INF SC, V180, P470
   Luxton DD, 2020, B WORLD HEALTH ORGAN, V98, P285, DOI 10.2471/BLT.19.237636
   Macedo P, 2019, PROCEDIA COMPUT SCI, V160, P402, DOI 10.1016/j.procs.2019.11.074
   Madhu D, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P243, DOI 10.1109/ICICCT.2017.7975195
   Mao GW, 2019, IEEE ACCESS, V7, P111736, DOI 10.1109/ACCESS.2019.2934149
   Martinez-Miranda J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1387-1
   Mathur S, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4761
   Mikolov T., 2013, P 1 INT C LEARN REPR, DOI DOI 10.5555/2999792.2999959
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Moore RJ, 2018, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-3-319-95579-7
   Mrksic N, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1777, DOI 10.18653/v1/P17-1163
   Mujeeb S, 2017, INT J ADV COMPUT SC, V8, P209
   Nadarzynski T, 2019, DIGIT HEALTH, V5, DOI [10.1177/2055207619871808, 10.1177/2055207619827193]
   Nagarhalli TP, 2020, INT CONF ADVAN COMPU, P706, DOI 10.1109/ICACCS48705.2020.9074420
   Nazir A, 2019, INT J ADV COMPUT SC, V10, P546
   Neves AMM, 2006, PROC INT C TOOLS ART, P225
   Nordheim CB, 2019, INTERACT COMPUT, V31, P317, DOI 10.1093/iwc/iwz022
   Nuruzzaman M, 2018, INT CONF E BUS ENG, P54, DOI 10.1109/ICEBE.2018.00019
   Okuda T, 2018, FUJITSU SCI TECH J, V54, P4
   Palanica A, 2019, J MED INTERNET RES, V21, DOI 10.2196/12887
   Park S, 2019, J MED INTERNET RES, V21, DOI 10.2196/12231
   Peng B., 2020, FEW SHOT NATURAL LAN, P172
   Marin DP, 2015, INT J ONLINE PEDAGOG, V5, P23, DOI 10.4018/IJOPCD.2015040103
   Perez-Marin D, 2013, INT J INF COMMUN TEC, V9, P94, DOI 10.4018/ijicte.2013100107
   Perski O, 2019, DIGIT HEALTH, V5, DOI 10.1177/2055207619880676
   Philip P, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-019-0213-y
   Pirrone R, 2008, MOB INF SYST, V4, P195, DOI 10.1155/2008/636924
   Ponathil A, 2020, J GENET COUNS, V29, P1081, DOI 10.1002/jgc4.1239
   Prasomphan S, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA), P517, DOI 10.1109/ICCCBDA.2019.8725745
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Pudner K, 2007, LECT NOTES ENG COMP, P305
   Ramesh K, 2017, COMM COM INF SC, V750, P336, DOI 10.1007/978-981-10-6544-6_31
   Robert, 2019, WORKSH ID CHALL OPP
   Rosruen N, 2018, 2018 3RD TECHNOLOGY INNOVATION MANAGEMENT AND ENGINEERING SCIENCE INTERNATIONAL CONFERENCE (TIMES-ICON)
   Ruan S, 2019, L@S '19: PROCEEDINGS OF THE SIXTH (2019) ACM CONFERENCE ON LEARNING @ SCALE, DOI 10.1145/3330430.3333643
   Schuetzler RM, 2020, J MANAGE INFORM SYST, V37, P875, DOI 10.1080/07421222.2020.1790204
   Shamekhi A, 2017, LECT NOTES COMPUT SC, V10171, P55, DOI 10.1007/978-3-319-55134-0_5
   Shao Y, 2017, P 2017 C EMP METH NA, P2210, DOI [10.18653/v1/d17-1235, DOI 10.18653/V1/D17-1235]
   Sharma B, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P627, DOI 10.1109/ICICCT.2018.8472986
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Smestad Tuva Lunde, 2018, PERSONALITY MATTERS
   Stiller B., 2020, SECBOT BUSINESS DRIV, DOI [10.23919/CNSM50824.2020.9269037, DOI 10.23919/CNSM50824.2020.9269037]
   Suganuma S, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/10454
   Sun X, 2018, 2018 FIRST ASIAN CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION (ACII ASIA)
   Sweeney ME, 2020, INFORM TECHNOL LIBR, V39, P1, DOI 10.6017/ital.v39i4.12363
   Ta V, 2020, J MED INTERNET RES, V22, DOI 10.2196/16235
   Tegos S, 2017, EDUC TECHNOL SOC, V20, P99
   Tegos S, 2016, INT J COMP-SUPP COLL, V11, P417, DOI 10.1007/s11412-016-9246-2
   Tegos S, 2015, COMPUT EDUC, V87, P309, DOI 10.1016/j.compedu.2015.07.014
   Tegos S, 2014, 2014 INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKING AND COLLABORATIVE SYSTEMS (INCOS), P176, DOI 10.1109/INCoS.2014.66
   van der Heijden H, 2004, MIS QUART, V28, P695, DOI 10.2307/25148660
   van Heerden Alastair, 2017, 2017 International Conference on the Frontiers and Advances in Data Science (FADS). Proceedings, P80, DOI 10.1109/FADS.2017.8253198
   Tran VK, 2018, COMM COM INF SC, V781, P63, DOI 10.1007/978-981-10-8438-6_6
   Wallace, 2003, ELEMENTS AIML STYLE, DOI 10.1.1.693.3664.
   Wanner L, 2017, LECT NOTES ARTIF INT, V10349, P284, DOI 10.1007/978-3-319-59930-4_23
   Wiak S, 2010, LECT NOTES ARTIF INT, V6114, P689, DOI 10.1007/978-3-642-13232-2_85
   Williams Jason, 2016, DIALOGUE DISCOURSE, V7, P4
   Wu Y, 2019, COMPUT LINGUIST, V45, P163, DOI [10.1162/coli_a_00345, 10.1162/COLI_a_00345]
   Wu Y, 2018, NEUROCOMPUTING, V316, P251, DOI 10.1016/j.neucom.2018.07.073
   Wu Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P496, DOI 10.18653/v1/P17-1046
   Xiao Z, 2019, PROCEEDINGS OF IUI 2019, P437, DOI 10.1145/3301275.3302264
   Xue ZJ, 2018, INT CONF DAT MIN WOR, P1423, DOI 10.1109/ICDMW.2018.00202
   Yang XH, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1353
   Yang XJ, 2019, CURR EYE RES, V44, P716, DOI 10.1080/02713683.2019.1584321
   Yen C, 2021, BEHAV INFORM TECHNOL, V40, P1177, DOI 10.1080/0144929X.2020.1743362
   Yin Z, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2131, DOI 10.1145/3097983.3098148
   Yue Song, 2016, 2016 Power Systems Computation Conference (PSCC), P1, DOI 10.1109/PSCC.2016.7540963
   Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054
   Zhao GG, 2019, INFORMATION, V10, DOI 10.3390/info10020063
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
NR 142
TC 2
Z9 2
U1 13
U2 27
PU WILEY PERIODICALS, INC
PI SAN FRANCISCO
PA ONE MONTGOMERY ST, SUITE 1200, SAN FRANCISCO, CA 94104 USA
SN 1942-4787
EI 1942-4795
J9 WIRES DATA MIN KNOWL
JI Wiley Interdiscip. Rev.-Data Mining Knowl. Discov.
PD JAN
PY 2022
VL 12
IS 1
AR e1434
DI 10.1002/widm.1434
EA OCT 2021
PG 26
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YF7TC
UT WOS:000710412200001
DA 2022-08-02
ER

PT J
AU Kretzschmar, K
   Tyroll, H
   Pavarini, G
   Manzini, A
   Singh, I
   Sharudin, A
   Pavlov, B
   Davis, C
   Mooney, D
   Kibble, E
   Tuckwell, G
   Lewis, G
   Heelas, J
   Dixon, J
   Bransby-Meehan, J
   Katz, J
   Seeney, L
   Lee, A
   Allegri, M
   Beard, M
   Aithani, N
   Lumbis, N
   Walker, N
   Macfarlane, P
   Bonnett, S
   Martin, S
   Speakman, S
AF Kretzschmar, Kira
   Tyroll, Holly
   Pavarini, Gabriela
   Manzini, Arianna
   Singh, Ilina
   Sharudin, Aysha
   Pavlov, Boris
   Davis, Charlie
   Mooney, Daniel
   Kibble, Eleyna
   Tuckwell, George
   Lewis, Grace
   Heelas, Jasmine
   Dixon, James
   Bransby-Meehan, Jessica
   Katz, Jessica
   Seeney, Laura
   Lee, Angela
   Allegri, Martino
   Beard, Maud
   Aithani, Nav
   Lumbis, Nellie
   Walker, Niahm
   Macfarlane, Poppy
   Bonnett, Samantha
   Martin, Sophie
   Speakman, Sophie
CA NeurOx Young Peoples Advisory Grp
TI Can Your Phone Be Your Therapist? Young People's Ethical Perspectives on
   the Use of Fully Automated Conversational Agents (Chatbots) in Mental
   Health Support
SO BIOMEDICAL INFORMATICS INSIGHTS
LA English
DT Article
DE Chatbots; apps; therapy; mental health; artificial intelligence;
   human-computer interaction; conversational agent; young people; digital
   mental health; youth mental health
ID COGNITIVE-BEHAVIORAL THERAPY; HELP-SEEKING; PRIMARY-CARE; DEPRESSION;
   INTERNET; ANXIETY; PREVALENCE; CHILDREN; ADOLESCENTS; ENGAGEMENT
AB Over the last decade, there has been an explosion of digital interventions that aim to either supplement or replace face-to-face mental health services. More recently. a number of automated conversational agents have also been made available. which respond to users in ways that mirror a real-life interaction. What are the social and ethical concerns that arise from these advances? In this article. we discuss, from a young person's perspective, the strengths and limitations of using chatbots in mental health support. We also outline what we consider to be minimum ethical standards for these platforms. including issues surrounding privacy and confidentiality. efficacy. and safety. and review three existing platforms (Woebot. Joy. and Wysa) according to our proposed framework. It is our hope that this article will stimulate ethical debate among app developers. practitioners. young people. and other stakeholders. and inspire ethically responsible practice in digital mental health.
C1 [Kretzschmar, Kira; Tyroll, Holly] Univ Oxford, Dept Pychiatry, Oxford Neurosci Eth & Soc Young Peoples Advisory, Oxford, England.
   [Pavarini, Gabriela; Manzini, Arianna; Singh, Ilina] Univ Oxford, Dept Psychiat & Wellcome Ctr Eth & Humanities, Oxford, England.
RP Pavarini, G (corresponding author), Univ Oxford, Dept Psychiat, Warneford Hosp, Oxford OX3 7JX, England.
EM gabriela.pavarini@psych.ox.ac.uk
RI Cuscó, Xavier Garcia/S-7576-2019
OI Cuscó, Xavier Garcia/0000-0001-7199-6931; Singh,
   Ilina/0000-0003-4497-3587; Manzini, Arianna/0000-0001-7710-8974;
   Pavarini, Gabriela/0000-0001-5574-4021
FU Wellcome Trust [104825/Z/14/Z, 203329/Z/16/Z]; NIHR Oxford Health
   Biomedical Research Centre [IS-BRC-1215-20005]; Wellcome Centre for
   Ethics and Humanities - Wellcome Trust [203132/Z/16/Z]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by the Wellcome Trust (104825/Z/14/Z). A.M. is, in
   addition, supported by a Wellcome Trust studentship (203329/Z/16/Z) and
   I.S. is, in addition, supported by the NIHR Oxford Health Biomedical
   Research Centre (IS-BRC-1215-20005) and the Wellcome Centre for Ethics
   and Humanities, which is supported by core funding from the Wellcome
   Trust (203132/Z/16/Z).
CR Adelman CB, 2014, J CLIN PSYCHIAT, V75, pE695, DOI 10.4088/JCP.13r08894
   Anderson JK, 2017, CHILD YOUTH SERV REV, V77, P164, DOI 10.1016/j.childyouth.2017.04.017
   Andersson Gerhard, 2009, Cognitive Behaviour Therapy, V38, P196, DOI 10.1080/16506070903318960
   Arnberg FK, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098118
   Baker DA, 2016, CYBERPSYCH BEH SOC N, V19, P638, DOI 10.1089/cyber.2016.0206
   Bakker D, 2016, JMIR MENT HEALTH, V3, DOI 10.2196/mental.4984
   Baumel A, 2016, JMIR MENT HEALTH, V3, DOI 10.2196/mental.5335
   Berger M, 2005, SOC SCI MED, V61, P1821, DOI 10.1016/j.socscimed.2005.03.025
   Burns JM, 2010, MED J AUSTRALIA, V192, pS22, DOI 10.5694/j.1326-5377.2010.tb03688.x
   Christensen H, 2011, EARLY INTERV PSYCHIA, V5, P58, DOI 10.1111/j.1751-7893.2010.00242.x
   Christensen H, 2009, J MED INTERNET RES, V11, DOI 10.2196/jmir.1194
   De-Sola GJ, 2016, FRONT PSYCHIATRY, V7, P175, DOI DOI 10.3389/FPSYT.2016.00175
   Debatin B, 2009, J COMPUT-MEDIAT COMM, V15, P83, DOI 10.1111/j.1083-6101.2009.01494.x
   Demirci K, 2015, J BEHAV ADDICT, V4, P85, DOI 10.1556/2006.4.2015.010
   Demyttenaere K, 2004, JAMA-J AM MED ASSOC, V291, P2581, DOI 10.1001/jama.291.21.2581
   Department of Health, 2017, FRAMEWORK MENTAL HLT
   DUBOW EF, 1990, J CLIN CHILD PSYCHOL, V19, P44, DOI 10.1207/s15374424jccp1901_6
   Ebert DD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119895
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Grist R, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7332
   Gulliver A, 2010, BMC PSYCHIATRY, V10, DOI 10.1186/1471-244X-10-113
   Hamm MP, 2015, JAMA PEDIATR, V169, P770, DOI 10.1001/jamapediatrics.2015.0944
   Inkster B, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/12106
   Kessler D, 2009, LANCET, V374, P628, DOI 10.1016/S0140-6736(09)61257-5
   Kessler RC, 2007, CURR OPIN PSYCHIATR, V20, P359, DOI 10.1097/YCO.0b013e32816ebc8c
   Khan L, INVESTING CHILDRENS
   Kreitmair KV, 2017, NAT BIOTECHNOL, V35, P617, DOI 10.1038/nbt.3887
   Laugharne R, 2006, SOC PSYCH PSYCH EPID, V41, P843, DOI 10.1007/s00127-006-0123-6
   Ledford H, 2014, NATURE, V515, P182, DOI 10.1038/515182a
   Leykin Yan, 2014, Internet Interv, V1, P175
   Livingstone S., 2006, COMPUTERS PHONES INT, P128
   Livingstone S., 2004, UK CHILDREN GO ONLIN
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   Ludden GDS, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.4201
   Ly KH, 2017, INTERNET INTERV, V10, P39, DOI 10.1016/j.invent.2017.10.002
   McCrone P, 2004, BRIT J PSYCHIAT, V185, P55, DOI 10.1192/bjp.185.1.55
   Parker L, 2017, BMC MED INFORM DECIS, V17, DOI 10.1186/s12911-017-0535-0
   Patel V, 2007, LANCET, V369, P1302, DOI 10.1016/S0140-6736(07)60368-7
   Pollock K., 2010, EVALUATION SAMARITAN
   Rickwood D, 2005, ADV MENT HEALTH, V4, P218, DOI 10.5172/jamh.4.3.218
   Rickwood DJ, 2007, MED J AUSTRALIA, V187, pS35, DOI 10.5694/j.1326-5377.2007.tb01334.x
   RICKWOOD DJ, 1994, SOC SCI MED, V39, P563, DOI 10.1016/0277-9536(94)90099-X
   Sachan D, 2018, LANCET PSYCHIAT, V5, P547, DOI 10.1016/S2215-0366(18)30230-X
   Smith DH, 2002, J AM ACAD CHILD PSY, V41, P367, DOI 10.1097/00004583-200204000-00007
   Sunyaev A, 2015, J AM MED INFORM ASSN, V22, pE28, DOI 10.1136/amiajnl-2013-002605
   Vos T, 2015, LANCET, V386, P743, DOI 10.1016/S0140-6736(15)60692-4
   Wallach E., THE POLITIC
   Wartella E, 2016, J CHILD MEDIA, V10, P13, DOI 10.1080/17482798.2015.1124796
   WEST JS, 1991, SCH COUNSELOR, V39, P77
   Wilson CJ, 2001, J EDUC PSYCHOL CONS, V12, P345, DOI 10.1207/S1532768XJEPC1204_03
NR 50
TC 48
Z9 48
U1 3
U2 42
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
EI 1178-2226
J9 BIOMED INFORM INSIGH
JI Biomed. Inform. Insights
PD MAR 5
PY 2019
VL 11
AR 1178222619829083
DI 10.1177/1178222619829083
PG 9
WC Medical Informatics
WE Emerging Sources Citation Index (ESCI)
SC Medical Informatics
GA HP9HX
UT WOS:000462004900001
PM 30858710
OA Green Published, gold
DA 2022-08-02
ER

PT J
AU Li, HY
   Graesser, AC
AF Li, Haiying
   Graesser, Arthur C.
TI The impact of conversational agents' language on summary writing
SO JOURNAL OF RESEARCH ON TECHNOLOGY IN EDUCATION
LA English
DT Article
DE Formality; summary writing; academic language; conversational language;
   agent
AB This study investigated how computer agents' language style affects summary writing in an Intelligent Tutoring System, called CSAL AutoTutor. Participants interacted with two computer agents in one of three language styles: (1) a formal language style, (2) an informal language style, and (3) a mixed language style. Primary results indicated that participants improved the quality of summary writing, spent less time writing summaries, and had lower syntactic complexity but more non-narrative summaries on posttest than pretest. However, this difference was not affected by the discourse formality that agents used during instruction. Results also showed participants rated peer summaries more accurately for cause/effect texts in the formal and mixed conditions, but generated summaries with lower referential cohesion in the informal condition on posttest than pretest.
C1 [Li, Haiying] Iowa State Univ, Off Enrollment Res & Analyt, Ames, IA USA.
   [Graesser, Arthur C.] Univ Memphis, Dept Psychol, Memphis, TN 38152 USA.
   [Graesser, Arthur C.] Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.
RP Li, HY (corresponding author), 361 Carver,411 Morrill Rd, Ames, IA 50011 USA.
EM haiyingl@iastate.edu
CR Christian D., 2003, WHAT TEACHERS NEED K, P7
   Clark H.H, 1996, USING LANGUAGE
   Cohen J., 1998, STAT POWER ANAL BEHA, V2nd, DOI [10.4324/9780203771587, DOI 10.4324/9780203771587]
   Denton P, 2013, POWER OUR WORDS TEAC
   EDWARDS AL, 1951, AM J PSYCHOL, V64, P598, DOI 10.2307/1418200
   Galloway EP, 2015, READ WRIT, V28, P797, DOI 10.1007/s11145-015-9550-7
   Gamez PB, 2015, DEV PSYCHOL, V51, P447, DOI 10.1037/a0038868
   Gamez PB, 2012, CHILD DEV, V83, P1316, DOI 10.1111/j.1467-8624.2012.01776.x
   Ginns P, 2013, EDUC PSYCHOL REV, V25, P445, DOI 10.1007/s10648-013-9228-0
   Graesser A.C., 2014, OXFORD HDB LANGUAGE, P491
   Graesser AC, 2014, ELEM SCHOOL J, V115, P210, DOI 10.1086/678293
   Graesser AC, 2014, CURR DIR PSYCHOL SCI, V23, P374, DOI 10.1177/0963721414540680
   Graesser AC, 2011, TOP COGN SCI, V3, P371, DOI 10.1111/j.1756-8765.2010.01081.x
   Haiying Li, 2020, Artificial Intelligence in Education. 21st International Conference, AIED 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science. (LNAI 12163), P321, DOI 10.1007/978-3-030-52237-7_26
   Hebert M, 2016, J EDUC PSYCHOL, V108, P609, DOI 10.1037/edu0000082
   Kalinowski E, 2019, AERA OPEN, V5, DOI 10.1177/2332858419828691
   Li H., 2019, DEEP COMPREHENSION M, P166
   Li H., 2018, POLICY INSIGHTS BEHA, V5, P171, DOI [10.1177/2372732218790017, DOI 10.1177/2372732218790017]
   Li HY, 2017, LECT NOTES ARTIF INT, V10331, P188, DOI 10.1007/978-3-319-61425-0_16
   Li HY, 2015, LECT NOTES ARTIF INT, V9112, P694, DOI 10.1007/978-3-319-19773-9_94
   Lin LJ, 2020, COMPUT EDUC, V143, DOI 10.1016/j.compedu.2019.103658
   Lucero A, 2014, J EARLY CHILD LIT, V14, P534, DOI 10.1177/1468798413512848
   Meyer BJF, 2003, TOP LANG DISORD, V23, P204, DOI 10.1097/00011363-200307000-00007
   Meyer BJF, 2001, J EDUC PSYCHOL, V93, P141, DOI 10.1037//0022-0663.93.1.141
   Meyer BJF, 2018, READ WRIT, V31, P1937, DOI 10.1007/s11145-018-9871-4
   Meyer BJF, 2011, J EDUC PSYCHOL, V103, P140, DOI 10.1037/a0021606
   Moreno R, 2004, J EDUC PSYCHOL, V96, P165, DOI 10.1037/0022-0663.96.1.165
   Moreno R, 2000, J EDUC PSYCHOL, V92, P724, DOI 10.1037//0022-0663.92.4.724
   Paivio A., 2017, NEUROPSYCHOLOGY VISU, P203
   Reichelt M, 2014, COMPUT HUM BEHAV, V35, P199, DOI 10.1016/j.chb.2014.03.005
   Riehemann J, 2018, J COMPUT ASSIST LEAR, V34, P713, DOI 10.1111/jcal.12278
   Searby M., 1997, ASSESS EVAL HIGH EDU, V22, P371, DOI DOI 10.1080/0260293970220402
   SHRAUGER JS, 1981, PSYCHOL BULL, V90, P322, DOI 10.1037/0033-2909.90.2.322
   Snow C., 2009, CAMBRIDGE HDB LITERA, P112
   Snow R., 2008, CHEAP FAST BUT IS IT
   Wijekumar K, 2013, COMPUT EDUC, V68, P366, DOI 10.1016/j.compedu.2013.05.021
NR 36
TC 2
Z9 2
U1 1
U2 9
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1539-1523
EI 1945-0818
J9 J RES TECHNOL EDUC
JI J. Res. Technol. Educ.
PD JAN 2
PY 2021
VL 53
IS 1
SI SI
BP 44
EP 66
DI 10.1080/15391523.2020.1826022
PG 23
WC Education & Educational Research
WE Social Science Citation Index (SSCI)
SC Education & Educational Research
GA QQ1RS
UT WOS:000624304600004
DA 2022-08-02
ER

PT J
AU Luxton, DD
AF Luxton, David D.
TI Ethical implications of conversational agents in global public health
SO BULLETIN OF THE WORLD HEALTH ORGANIZATION
LA English
DT Editorial Material
C1 [Luxton, David D.] Univ Washington, Dept Psychiat & Behav Sci, Sch Med, 1959 NE Pacific St, Seattle, WA 98195 USA.
RP Luxton, DD (corresponding author), Univ Washington, Dept Psychiat & Behav Sci, Sch Med, 1959 NE Pacific St, Seattle, WA 98195 USA.
EM ddluxton@uw.edu
CR [Anonymous], 2010, TEL OPPO DEV MEMB ST
   Bickmore TW, 2010, INTERACT COMPUT, V22, P289, DOI 10.1016/j.intcom.2009.12.001
   Gianfrancesco MA, 2018, JAMA INTERN MED, V178, P1544, DOI 10.1001/jamainternmed.2018.3763
   Hudlicka E., 2015, ARTIFICIAL INTELLIGE
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Luxton D, 2021, INNOVATIONS GLOBAL M, P489
   Luxton D., 2015, ARTIFICIAL INTELLIGE
   Luxton DD, 2014, ARTIF INTELL MED, V62, P1, DOI 10.1016/j.artmed.2014.06.004
   Rizzoa AA, 2011, STUD HEALTH TECHNOL, V163, P503, DOI 10.3233/978-1-60750-706-2-503
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   WHO's Mental Health Atlas, 2017, 2017 HIGHL GLOB SHOR
NR 11
TC 15
Z9 15
U1 1
U2 4
PU WORLD HEALTH ORGANIZATION
PI GENEVA 27
PA MARKETING AND DISSEMINATION, CH-1211 GENEVA 27, SWITZERLAND
SN 0042-9686
EI 1564-0604
J9 B WORLD HEALTH ORGAN
JI Bull. World Health Organ.
PD APR
PY 2020
VL 98
IS 4
BP 285
EP 287
DI 10.2471/BLT.19.237636
PG 3
WC Public, Environmental & Occupational Health
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Public, Environmental & Occupational Health
GA KZ3SB
UT WOS:000523183600024
PM 32284654
OA Green Published
DA 2022-08-02
ER

PT C
AU Satyanarayana, V
   Shankar, S
   Sruthi, V
   Das, B
AF Satyanarayana, Vibha
   Shankar, Shruthi
   Sruthi, V
   Das, Bhaskarjyoti
GP IEEE
TI A Study of Artificial Social Intelligence in Conversational Agents
SO PROCEEDINGS OF THE 2018 3RD INTERNATIONAL CONFERENCE ON INVENTIVE
   COMPUTATION TECHNOLOGIES (ICICT 2018)
LA English
DT Proceedings Paper
CT 3rd International Conference on Inventive Computation Technologies
   (ICICT)
CY NOV 15-16, 2018
CL Coimbatore, INDIA
SP IEEE, RVS Tech Campus
AB The main goal of Artificial Intelligence (AI) is to make a machine as intelligent as a human. While AI has advanced significantly over the past years, with its ability surpassing humans in several fields, the one thing that it still lacks is social awareness i.e. have the social skills of a human, a sense of what is appropriate and what isn't and make decisions based on that. These are highly subjective and there is no single set of rules to determine them. With the use of AI increasing at such a high rate that AI has become a part of people's everyday lives it is absolutely necessary for AI systems to know what is socially acceptable. In this paper, we have conducted a thorough and systematic study of the current state of the art for implementing social and emotional intelligence into a conversational agent.
C1 [Satyanarayana, Vibha; Shankar, Shruthi; Sruthi, V; Das, Bhaskarjyoti] PES Univ, Dept Comp Sci, Bangalore, Karnataka, India.
RP Satyanarayana, V (corresponding author), PES Univ, Dept Comp Sci, Bangalore, Karnataka, India.
EM vib.satya@gmail.com; shruthi.shankar2512@gmail.com; vsruthi98@gmail.com;
   bhaskatjyoti01@gmail.com
OI Das, Bhaskarjyoti/0000-0003-1225-9354
CR Al Masum S. M., INTEGRATING NATURAL
   Al Masum S.M., 2007, P INT C NAT LANG PRO, P147
   [Anonymous], 1988, COGNITIVE STRUCTURE, DOI DOI 10.1017/CBO9780511571299
   Baeriswyl M., 2018, IJCAI 18
   Crowder J., 2012, P 3 ANN INT MULT INF
   Dautenhahn K, 1995, ROBOT AUTON SYST, V16, P333, DOI 10.1016/0921-8890(95)00054-2
   Fang H., 2018, ARXIV180410202
   Guo P., SNOWBOT EMPIRICAL ST
   Hinrichs H., WHICH TEXT MINING TE
   Hirat R., 2015, INT B MATH RES, V2, P180
   Honghao W., BUILDING CHATBOT EMO
   Hu TR, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173989
   Kim S., 2012, ICWSM
   Li J., 2016, ARXIV160306155
   Ma CL, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON ACTIVE MEDIA TECHNOLOGY (AMT 2005), P546
   Mo K., 2016, ARXIV161002891
   Mohammad Saif, 2010, P NAACL HLT 2010 WOR
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Qiu MH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P498, DOI 10.18653/v1/P17-2079
   Shum HY, 2018, FRONT INFORM TECH EL, V19, P10, DOI 10.1631/FITEE.1700826
   Sutskever I., 2014, ADV NEURAL INFORM PR, P3104
   Thombare S. A., 2017, EMOTION EXTRACTION M
   Wu L, 2018, C EMP METH NAT LANG, DOI [10.18653/v1/D18-1397, DOI 10.18653/V1/D18-1397]
   Zhou H., 2017, ARXIV170401074
NR 24
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-5386-4985-5
PY 2018
BP 545
EP 550
PG 6
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ6AT
UT WOS:000610379500061
DA 2022-08-02
ER

PT J
AU Berka, J
   Balata, J
   Jonker, CM
   Mikovec, Z
   van Riemsdijk, MB
   Tielman, ML
AF Berka, Jakub
   Balata, Jan
   Jonker, Catholijn M.
   Mikovec, Zdenek
   van Riemsdijk, M. Birna
   Tielman, Myrthe L.
TI Misalignment in Semantic User Model Elicitation via Conversational
   Agents: A Case Study in Navigation Support for Visually Impaired People
SO INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION
LA English
DT Article; Early Access
ID SHARED MENTAL MODELS; BLIND
AB Disabled people can benefit greatly from assistive digital technologies. However, this increased human-machine symbiosis makes it important that systems are personalized and transparent to users. Existing work often uses data-oriented approaches. However, these approaches lack transparency and make it hard to influence the system's behavior. In this paper, we use knowledge-based techniques for personalization, introducing the concept of Semantic User Models for representing the behavior, values and capabilities of users. To allow the system to construct such a user model, we investigate the use of a conversational agent which can elicit the relevant information from users through dialogue. A conversational interface is essential for our case study of navigation support for visually impaired people, but in general, has the potential to enhance transparency as users know what the system represents about them. For such a dialogue to be effective, it is crucial that the user understands what the conversational agent is asking, i.e., that misalignments that decrease the transparency are avoided or resolved. In this paper, we investigate whether we can use a conversational agent for Semantic User Model elicitation, which types of misalignments can occur in this process and how they are related, and how misalignments can be reduced. We investigate this in two (iterative) qualitative studies (n = 7 & n = 8) with visually impaired people in which a personalized user model for navigation support is elicited via a dialogue with a conversational agent. Our results show four hierarchically structured levels of human-agent misalignment. We identify several design solutions for reducing misalignments, which point to the need for restricting the generic user model to what is needed in the domain under consideration. With this research, we lay a foundation for conversational agents capable of eliciting Semantic User Models.
C1 [Berka, Jakub; Balata, Jan; Mikovec, Zdenek] Czech Tech Univ, Dept Comp Graph & Interact, Prague, Czech Republic.
   [Jonker, Catholijn M.; Tielman, Myrthe L.] Delft Univ Technol, Dept Intelligent Syst, Delft, Netherlands.
   [Jonker, Catholijn M.] Leiden Univ, Dept Media & Interact, Leiden, Netherlands.
   [van Riemsdijk, M. Birna] Univ Twente, Dept Human Media Interact, Enschede, Netherlands.
RP Tielman, ML (corresponding author), Delft Univ Technol, Van Mourik Broekmanweg 6, NL-2628 XE Delft, Netherlands.
EM m.l.tielman@tudelft.nl
OI Tielman, Myrthe/0000-0002-7826-5821; Balata, Jan/0000-0002-9795-0832;
   van Riemsdijk, M. Birna/0000-0001-9089-5271
FU Netherlands Organisation for Scientific Research (NWO) [639.022.416];
   projects Navigation of handicapped people [SGS19/178/OHK3/3T/13];
   Research Center for Informatics [CZ.02.1.01/0.0/0.0/16_019/0000765]
FX This work is part of the research program CoreSAEP, with project number
   639.022.416, which is financed by the Netherlands Organisation for
   Scientific Research (NWO). This research has been supported by projects
   Navigation of handicapped people funded by grant no.
   SGS19/178/OHK3/3T/13 and Research Center for Informatics (reg. n.
   CZ.02.1.01/0.0/0.0/16_019/0000765).
CR Abdulrahman A, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P176, DOI 10.1145/3308532.3329444
   Ahmetovic D, 2019, 16TH INTERNATIONAL WEB FOR ALL CONFERENCE (WEB4ALL), DOI 10.1145/3315002.3317561
   Azenkot S, 2013, P 15 INT ACM SIGACCE, P1, DOI DOI 10.1145/2513383.2513440
   Azenkot S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3247
   Balata J, 2018, HUM-COMPUT INT-SPRIN, P61, DOI 10.1007/978-3-319-95579-7_4
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Berka J.J., 2020, 4TU.ResearchData, DOI 10.4121/12901496.v1
   Brachman R., 2004, KNOWLEDGE REPRESENTA
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Bujacz M, 2008, 2008 Conference on Human System Interactions, P888, DOI 10.1109/HSI.2008.4581561
   Campbell N., 2020, TEMPORAL STRUCTURE M, V164
   CONVERSE SA, 1991, PROCEEDINGS OF THE HUMAN FACTORS SOCIETY 35TH ANNUAL MEETING, VOL 2, P1417
   Cranefield S, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P178
   Dignum V, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4698
   Emarketer, 2017, AL SAY WHAT VOIC EN
   Esfandiari-Baiat G., 2020, TEMPORAL STRUCTURE M, V164
   Fan XC, 2011, IEEE T SYST MAN CY B, V41, P354, DOI 10.1109/TSMCB.2010.2053705
   Faria J., 2010, WAC 2010, P1
   Faulkner TK, 2018, ACMIEEE INT CONF HUM, P149, DOI 10.1145/3173386.3177066
   Friedman B, 2006, ADV MANAG INFORM SYS, V5, P348
   Georgiou T, 2017, USER MODEL USER-ADAP, V27, P267, DOI 10.1007/s11257-017-9192-3
   Golledge R.G., 1999, WAYFINDING BEHAV COG
   GOLLEDGE RG, 1993, T I BRIT GEOGR, V18, P63, DOI 10.2307/623069
   Guerreiro J, 2018, 15TH INTERNATIONAL WEB FOR ALL CONFERENCE (W4A) 2018, DOI 10.1145/3192714.3192829
   Haller H, 2017, PROCEEDINGS OF THE 2017 9TH IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT DATA ACQUISITION AND ADVANCED COMPUTING SYSTEMS: TECHNOLOGY AND APPLICATIONS (IDAACS), VOL 2, P804, DOI 10.1109/IDAACS.2017.8095199
   Harbers M, 2011, THESIS
   IEEE, 2017, ETH AL DES VIS PRIOR
   Kayal A, 2018, ACM T INTERNET TECHN, V18, DOI 10.1145/3158371
   Kliess MS, 2019, LECT NOTES ARTIF INT, V11873, P354, DOI 10.1007/978-3-030-33792-6_22
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Luttich K, 2005, LECT NOTES COMPUT SC, V3423, P106
   Menekse M, 2019, INT J STEM EDUC, V6, DOI 10.1186/s40594-019-0160-9
   Nam CS, 2012, INT J HUM-COMPUT INT, V28, P784, DOI 10.1080/10447318.2012.661357
   Ohn-Bar Eshed, 2018, Proc ACM Interact Mob Wearable Ubiquitous Technol, V2, DOI 10.1145/3264941
   Palani HP, 2020, INT J HUM-COMPUT INT, V36, P1393, DOI 10.1080/10447318.2020.1752464
   Palanica A, 2019, INT J SOC ROBOT, V11, P359, DOI 10.1007/s12369-018-0504-5
   Pasotti P., 2017, WORKSH COGN KNOWL AC
   Pasotti P., 2016, EUR C ART INT RESEAR
   Porcheron M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174214
   Scheutz M, 2017, J COGN ENG DECIS MAK, V11, P203, DOI 10.1177/1555343416682891
   SCHWARTZ SH, 1992, ADV EXP SOC PSYCHOL, V25, P1, DOI 10.1016/s0065-2601(08)60281-6
   Sciuto A, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P857, DOI 10.1145/3196709.3196772
   Serramia M., 2018, INT C AUT AG MULT SY
   Stephanidis C, 2019, INT J HUM-COMPUT INT, V35, P1229, DOI 10.1080/10447318.2019.1619259
   Tielman M., 2018, MRC 10 INT WORKSH MO
   Tuttle D.W., 2004, SELF ESTEEM ADJUSTIN
   V?lkel T., 2008, P 10 INT ACM SIGACCE, P185, DOI [DOI 10.1145/1414471.1414506, 10.1145/1414471.1414506]
   van de Poel vd., 2015, HDB ETHICS VALUES TE, P89
   van de Poel vd., 2013, PHILOS ENG REFLECTIO
   van Riemsdijk v., 2015, INT C AUT AG MULT SY
   Verhagen R., 2021, EXTRAAMAS SPRINGERS
   Vtyurina A, 2019, PROCEEDINGS OF THE 2019 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL (CHIIR'19), P429, DOI 10.1145/3295750.3298976
   Wald M, 2021, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.571955
   White R.W., 2009, P 2009 INT C INCL DE
   WHO, 2009, ICD UPD REV PLATF CH
   WYCHERLEY RJ, 1970, ERGONOMICS, V13, P181, DOI 10.1080/00140137008931131
   Yamaoka Masaki, 2015, 2015 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA). Proceedings, P223, DOI 10.1109/APSIPA.2015.7415511
NR 58
TC 0
Z9 0
U1 1
U2 1
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 1044-7318
EI 1532-7590
J9 INT J HUM-COMPUT INT
JI Int. J. Hum.-Comput. Interact.
DI 10.1080/10447318.2022.2059925
EA APR 2022
PG 17
WC Computer Science, Cybernetics; Ergonomics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 0V5GQ
UT WOS:000788372000001
OA Green Published, hybrid
DA 2022-08-02
ER

PT C
AU Wechsung, I
   Weiss, B
   Kuhnel, C
   Ehrenbrink, P
   Moller, S
AF Wechsung, Ina
   Weiss, Benjamin
   Kuehnel, Christine
   Ehrenbrink, Patrick
   Moeller, Sebastian
BE Bimbot, F
   Cerisara, C
   Fougeron, C
   Gravier, G
   Lamel, L
   Pellegrino, F
   Perrier, P
TI Development and Validation of the Conversational Agents Scale (CAS)
SO 14TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION
   ASSOCIATION (INTERSPEECH 2013), VOLS 1-5
SE Interspeech
LA English
DT Proceedings Paper
CT 14th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2013)
CY AUG 25-29, 2013
CL Lyon, FRANCE
SP Int Speech Commun Assoc, europa org, amazon, Microsoft, Google, TcL SYTRAL, European Language Resources Assoc, ouaero, imaginove, VOCAPIA res, acapela, speech ocean, ALDEBARAN, orange, vecsys, IBM Res, Raytheon BBN Technol, voxygen
DE evaluation; anthropomorphic interfaces; user centered design
AB The gulf between user and system can be minimized by adapting the system to the user's natural characteristics. So-called anthropomorphic interfaces represent one strategy of such an adaption as they are assumed to provide a more human-like and therefore more natural interaction. However, regarding the evaluation of anthropomorphic interfaces, the well-known and empirically tested instruments are the to educational contexts. Hence, this paper describes the first steps towards the development of an evaluation instrument applicable to a wide range of such interfaces.
C1 [Wechsung, Ina; Weiss, Benjamin; Ehrenbrink, Patrick; Moeller, Sebastian] TU Berlin, Qual & Usabil Lab, Deutsch Telekom Innovat Labs, Berlin, Germany.
   [Kuehnel, Christine] Potsdam Inst Climate Impact Res, Potsdam, Germany.
RP Wechsung, I (corresponding author), TU Berlin, Qual & Usabil Lab, Deutsch Telekom Innovat Labs, Berlin, Germany.
EM Ina.Wechsung@telekom.de; BWeiss@telekom.de;
   christine.kuehnel@pik-potsdam.de; Patrick.Ehrenbrink@telekom.de;
   Sebastian.Moeller@telekom.de
RI Ehrenbrink, Patrick/AAC-7185-2022
OI Ehrenbrink, Patrick/0000-0002-7234-9426
CR Adcock A. B., 2005, J INTERACTIVE LEARNI, V16, P195
   Amelang M, 2006, DIFFERENTIELLE PSYCH
   Baylor A., 2003, EDMEDIA INNOVAE LEAR, P448
   Buhner M., 2011, EINFUHRUNG TEST FRAG
   Burnham D., 2008, P INT C AUD VIS SPEE, P127
   Dutoit T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1393, DOI 10.1109/ICSLP.1996.607874
   Fagel S, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2325
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Hassenzahl M, 2010, HUM-COMPUT INTERACT, V25, P235, DOI 10.1080/07370024.2010.500139
   Hornburg C., 1996, MARKETING ZFP, V18, P5, DOI [DOI 10.15358/0344-1369-1996-1, 10.15358/0344-1369-1996-1-5]
   Jokinen K., 2009, UNIVERSAL ACCESS HDB, P495
   Krosnick JA, 1997, WILEY SER PROB STAT, P141
   Larsen L. B, 2003, EUROSPEECH 2003 8 EU, P1945
   Moosbrugger H., 2008, TESTTHEORIE FRAGEBOG
   Norman D.A., 1988, PSYCHOL EVERYDAY THI
   Ruge M., 2011, STIMMUNGEN ERWARTUNG
   Ruttkay Z, 2004, HUM-COMPUT INT-SPRIN, V7, P27
   Ruttkay Z., 2004, BROWS TRUST EVALUATI
   Schroder M., 2003, International Journal of Speech Technology, V6, P365, DOI 10.1023/A:1025708916924
   Wechsung I., P IWSDS 2012 INT WOR, P125
   Weiss B, 2010, SPEECH COMMUN, V52, P481, DOI 10.1016/j.specom.2010.02.011
NR 21
TC 1
Z9 1
U1 0
U2 0
PU ISCA-INT SPEECH COMMUNICATION ASSOC
PI BAIXAS
PA C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE
SN 2308-457X
BN 978-1-62993-443-3
J9 INTERSPEECH
PY 2013
BP 1105
EP 1109
PG 5
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BH0HX
UT WOS:000395050000234
DA 2022-08-02
ER

PT C
AU Lipi, AA
   Yamaoka, Y
   Rehm, M
   Nakano, YI
AF Lipi, Afia Akhter
   Yamaoka, Yuji
   Rehm, Matthias
   Nakano, Yukiko I.
BE Prendinger, H
   Lester, J
   Ishizuka, M
TI Enculturating Conversational Agents Based on a Comparative Corpus Study
SO INTELLIGENT VIRTUAL AGENTS, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 8th International Conference on Intelligent Virtual Agents
CY SEP 01-03, 2008
CL Tokyo, JAPAN
SP Assoc Advancement Artificial Intelligence, European Assoc Comp Graph, ACM SIGART, ACM SIGCHI
C1 [Lipi, Afia Akhter; Yamaoka, Yuji] Tokyo Univ Agr & Technol, Dept Comp & Informat Sci, Fuchu, Tokyo 183, Japan.
   [Yamaoka, Yuji] Augsburg Univ, Inst Comp Sci, Augsburg, Germany.
   [Nakano, Yukiko I.] Seikei Univ, Dept Comp & Informat Sci, Musashino, Tokyo, Japan.
RP Lipi, AA (corresponding author), Tokyo Univ Agr & Technol, Dept Comp & Informat Sci, Fuchu, Tokyo 183, Japan.
EM 50007646211@st.tuat.ac.jp; 50007646208@st.tuat.ac.jp;
   rehm@informatik.uni-augsburg.de; y.nakano@st.seikei.ac.jp
FU German Research Foundation (DFG) [RE 2619/2-1]; Japan Society for the
   Promotion of Science (JSPS) [19500104]
FX This work is funded by the German Research Foundation (DFG) under
   research grant RE 2619/2-1 (CUBE-G) and the Japan Society for the
   Promotion of Science (JSPS) under a Grant-in-Aid for Scientific Research
   (C) (19500104).
CR Bull P. E, 1987, POSTURE GESTURE, V16
   Duncan S., 1974, LANG SOC, V3, P161, DOI [https://doi.org/10.1017/S0047404500004322, DOI 10.1016/j.tics.2009.04.005]
   REHM M, 2008, P WORKSH ENC CONV IN
NR 3
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-540-85482-1
J9 LECT NOTES COMPUT SC
PY 2008
VL 5208
BP 465
EP +
PG 2
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BIM69
UT WOS:000260883100046
DA 2022-08-02
ER

PT J
AU Cassell, J
AF Cassell, J
TI Embodied conversational agents - Representation and intelligence in user
   interfaces
SO AI MAGAZINE
LA English
DT Article
ID FEEDBACK; GESTURES; HAND
AB How do we decide how to represent an intelligent system in its interface, and how do we decide how the interface represents information about the world and about its own workings to a user? This article addresses these questions by examining the interaction between representation and intelligence in user interfaces. The rubric representation covers at least three topics in this context: (1) how a computational system is represented in its user interface, (2) how the interface conveys its representations of information and the world to human users, and (3) how the system's internal representation affects the human user's interaction with the system. I argue that each of these kinds of representation (of the system, information and the world, the interaction) is key to how users make the kind of attributions of intelligence that facilitate their interactions with intelligent systems. In this vein, it makes sense to represent a systmem as a human in those cases where social collaborative behavior is key and for the system to represent its knowledge to humans in multiple ways on multiple modalities. I demonstrate these claims by discussing issues of representation and intelligence in an embodied conversational agent-an interface in which the system is represented as a person, information is conveyed to human users by multiple modalities such as voice and hand gestures, and the internal representation is modality independent and both propositional and nonpropositional.
C1 MIT, Media Lab, Gesture & Narrat Language Res Grp, Cambridge, MA 02139 USA.
RP Cassell, J (corresponding author), MIT, Media Lab, Gesture & Narrat Language Res Grp, Cambridge, MA 02139 USA.
EM justine@media.mit.edu
RI Cassell, Justine/B-7123-2009
CR ANDRE E, 1997, IJCAI 97 WORKSH AN I
   Astington J. W., 1988, DEV THEORIES MIND
   AZARBAYEJANI A, 1996, IMAGE COM 96
   BATES E, 1983, CHILDRENS LANGUAGE, P59
   BRENNAN SE, 1995, KNOWL-BASED SYST, V8, P143, DOI 10.1016/0950-7051(95)98376-H
   Brooks RA, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P961
   CAMPBELL L, 2001, THESIS MIT
   Cassell J, 2000, COMMUN ACM, V43, P50, DOI 10.1145/355112.355123
   Cassell J., 1999, Autonomous Agents and Multi-Agent Systems, V2, P45, DOI 10.1023/A:1010027123541
   Cassell J, 1999, APPL ARTIF INTELL, V13, P519, DOI 10.1080/088395199117360
   CASSELL J, 2000, ACM SIGCHI C HUM FAC
   CASSELL J, 2002, IN PRESS USER MODELI
   Cassell J., 1999, PRAGMAT COGNIT, V7, P1, DOI 10.1075/pc.7.1.03cas
   CASSELL J, 2000, 1 INT LANG GEN C 12
   Don A., 1992, P SIGCHI C HUM FACT, V2, P67
   Duncan S., 1974, LANG SOC, V3, P161, DOI [https://doi.org/10.1017/S0047404500004322, DOI 10.1016/j.tics.2009.04.005]
   Elliott C, 1998, AI MAG, V19, P13
   FEINER SK, 1991, COMPUTER, V24, P33, DOI 10.1109/2.97249
   GOLDINMEADOW S, 1993, PSYCHOL REV, V100, P279, DOI 10.1037/0033-295X.100.2.279
   KRAUSS RM, 1991, J PERS SOC PSYCHOL, V61, P743, DOI 10.1037/0022-3514.61.5.743
   Laurel Brenda, 1990, ART HUMAN COMPUTER I
   LESTER JC, 1997, AUT AG 97 5 FEBR MAR
   Maybury M., 1998, Research and Advanced Technology for Digital Libraries. Second European Conference, ECDL'98. Proceedings, P1
   MCNEILL D, 1992, HAND MIND GESTURES R
   Piaget J, 1936, ORIGINS INTELLIGENCE
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Rickel J, 1999, APPL ARTIF INTELL, V13, P343, DOI 10.1080/088395199117315
   RISKIN J, 1999, HIST SCI SOC 1999 AN
   Rogers W. T., 1978, HUM COMMUN RES, V5, P54, DOI DOI 10.1111/J.1468-2958.1978.TB00622.X
   ROSENSCHEIN SJ, 1986, P C THEOR ASP REAS K, P83
   ROWLING JK, 2000, H POTTER CHAMBER SEC
   SHNEIDERMAN B, 1977, EDUCOM REV, V32, P4
   Smith J., 2000, THESIS MIT
   TAKEUCHI A, 1993, P ACM IFIP INTERCHI, P187
   THOMPSON LA, 1986, J EXP CHILD PSYCHOL, V42, P144, DOI 10.1016/0022-0965(86)90020-2
   TREVARTHEN C, 1986, LANGUAGE TOPICS ESSA, P177
   WAHLSTER W, 1991, P 5 EUR CHAPT ASS CO
   YAN H, 2000, THESIS MIT
NR 38
TC 118
Z9 119
U1 2
U2 14
PU AMER ASSOC ARTIFICIAL INTELL
PI MENLO PK
PA 445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA
SN 0738-4602
J9 AI MAG
JI AI Mag.
PD WIN
PY 2001
VL 22
IS 4
BP 67
EP 83
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 633MX
UT WOS:000180288000006
DA 2022-08-02
ER

PT J
AU Axelsson, A
   Buschmeier, H
   Skantze, G
AF Axelsson, Agnes
   Buschmeier, Hendrik
   Skantze, Gabriel
TI Modeling Feedback in Interaction With Conversational Agents-A Review
SO FRONTIERS IN COMPUTER SCIENCE
LA English
DT Review
DE feedback; grounding; spoken dialogue; multimodal signals; human-agent
   interaction; review
ID TURN-TAKING; HEAD GESTURES; RECOGNITION; FEATURES; SPEECH; GAZE;
   GENERATION; ATTENTION; RESPONSES; MOVEMENT
AB Intelligent agents interacting with humans through conversation (such as a robot, embodied conversational agent, or chatbot) need to receive feedback from the human to make sure that its communicative acts have the intended consequences. At the same time, the human interacting with the agent will also seek feedback, in order to ensure that her communicative acts have the intended consequences. In this review article, we give an overview of past and current research on how intelligent agents should be able to both give meaningful feedback toward humans, as well as understanding feedback given by the users. The review covers feedback across different modalities (e.g., speech, head gestures, gaze, and facial expression), different forms of feedback (e.g., backchannels, clarification requests), and models for allowing the agent to assess the user's level of understanding and adapt its behavior accordingly. Finally, we analyse some shortcomings of current approaches to modeling feedback, and identify important directions for future research.
C1 [Axelsson, Agnes; Skantze, Gabriel] KTH Royal Inst & Technol, Div Speech Mus & Hearing TMH, Stockholm, Sweden.
   [Buschmeier, Hendrik] Bielefeld Univ, Fac Linguist & Literary Studies, Bielefeld, Germany.
RP Buschmeier, H (corresponding author), Bielefeld Univ, Fac Linguist & Literary Studies, Bielefeld, Germany.
EM hbuschme@uni-bielefeld.de
FU Swedish Foundation for Strategic Research (SSF) project Co-Adaptive
   Human-Robot Interactive Systems (COIN); German Research Foundation (DFG)
   in the Collaborative Research Center [TRR 318/1 2021, 438445824]; German
   Research Foundation (DFG); Open Access Publication Fund of Bielefeld
   University
FX Funding AA and GS were supported by the Swedish Foundation for Strategic
   Research (SSF) project Co-Adaptive Human-Robot Interactive Systems
   (COIN). HB was supported by the German Research Foundation (DFG) in the
   Collaborative Research Center TRR 318/1 2021 Constructing Explainability
   (438445824). We also acknowledge the financial support of the German
   Research Foundation (DFG) and the Open Access Publication Fund of
   Bielefeld University for the article processing charge.
CR AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   Al Moubayed S, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P3749, DOI 10.1109/ROBOT.2009.5152572
   Allen J., 1997, DAMSL DIALOGUE ACT M
   Allwood J., 1992, Journal of Semantics, V9, P1, DOI 10.1093/jos/9.1.1
   Allwood J., 1988, SVENSKANS BESKRIVNIN, V1, P89
   Allwood J., 2003, P 1 NORDIC S MULTIMO, P7
   Allwood J, 2007, LANG RESOUR EVAL, V41, P255, DOI 10.1007/s10579-007-9056-2
   Axelsson A, 2022, FRONT COMP SCI-SWITZ, V3, DOI 10.3389/fcomp.2021.741148
   Axelsson N, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423884
   Axelsson N, 2019, 20TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2019), P345
   Barres BG, 2013, TECHNOLOGIES FOR INCLUSIVE EDUCATION: BEYOND TRADITIONAL INTEGRATION APPROACHES, P1, DOI 10.4018/978-1-4666-2530-3
   Baur T, 2016, HUM-COMPUT INT-SPRIN, P181, DOI 10.1007/978-3-319-31413-6_10
   Bavelas JB, 2000, J PERS SOC PSYCHOL, V79, P941, DOI 10.1037/0022-3514.79.6.941
   BAVELAS JB, 1992, DISCOURSE PROCESS, V15, P469, DOI 10.1080/01638539209544823
   BAVELAS JB, 1995, PERS SOC PSYCHOL B, V21, P394, DOI 10.1177/0146167295214010
   Bavelas JB, 2002, J COMMUN, V52, P566, DOI 10.1111/j.1460-2466.2002.tb02562.x
   Benotti L., 2021, P 16 C EUROPEAN CHAP, P515, DOI [10.18653/v1/2021.eacl-main.41, DOI 10.18653/V1/2021.EACL-MAIN.41]
   Bevacqua E., 2009, COMPUTATIONAL MODEL
   Bevacqua E., 2007, P AISB 07 ANN CONVEN
   Bevacqua E, 2008, LECT NOTES COMPUT SC, V5208, P262
   Bevacqua E, 2014, COVERBAL SYNCHRONY IN HUMAN-MACHINE INTERACTION, P243
   Bohus D, 2005, 2005 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), P272
   Bohus D., 2007, ERROR AWARENESS RECO
   Bohus D., 2009, SIGDIAL 09 P SIGDIAL, P225, DOI [10.3115/1708376.1708409, DOI 10.3115/1708376.1708409]
   Boyd A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P66
   BRENNAN SE, 1995, KNOWL-BASED SYST, V8, P143, DOI 10.1016/0950-7051(95)98376-H
   Brunner M.-L., 2021, RES CORPUS LINGUIST, V10, P63, DOI [10.32714/ricl.09.01.05, DOI 10.32714/RICL.09.01.05]
   Buschmeier H., 2014, P 18 WORKSHOP SEMANT, P17
   Buschmeier H., 2018, ATTENTIVE SPEAKING L
   Buschmeier H., 2012, SEMDIAL 2012 P 16 WO, P12
   Buschmeier H, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P1213
   Cafaro A, 2014, LECT NOTES ARTIF INT, V8637, P81, DOI 10.1007/978-3-319-09767-1_11
   Cassell J, 2001, AI MAG, V22, P67
   Cassell J, 1999, APPL ARTIF INTELL, V13, P519, DOI 10.1080/088395199117360
   Cathcart N, 2003, EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P51
   Cerrato L., 2005, P 2 NORDIC C MULTIMO, P137
   Chiba Y, 2017, ASIAPAC SIGN INFO PR, P428, DOI 10.1109/APSIPA.2017.8282069
   Clark HerbertH, 1996, USING LANGUAGE, DOI [10.1017/CBO9780511620539, DOI 10.1017/CBO9780511620539, DOI 10.1007/s11097-014-9404-9]
   Clark HH, 2004, J MEM LANG, V50, P62, DOI 10.1016/j.jml.2003.08.004
   CLARK HH, 1989, COGNITIVE SCI, V13, P259, DOI 10.1016/0364-0213(89)90008-6
   Comas J, 2020, IEEE INT CONF AUTOMA, P93, DOI 10.1109/FG47880.2020.00001
   Core M.G., 1997, P AAAI FALL S COMMUN
   Crook P, 2017, INTERSPEECH, P1706, DOI 10.21437/Interspeech.2017-161
   de Kok I., 2012, P INTERDISCIPLINARY, P15
   de Kok I., 2013, LISTENING HEADS
   de Kok I, 2011, LECT NOTES COMPUT SC, V6456, P362, DOI 10.1007/978-3-642-18184-9_32
   DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061
   DITTMANN AT, 1967, J PERS SOC PSYCHOL, V6, P341, DOI 10.1037/h0024739
   Edlund J., 2005, P INTERSPEECH 2005, P2389, DOI [10.21437/Interspeech.2005-43, DOI 10.21437/INTERSPEECH.2005-43]
   Edlund J, 2008, SPEECH COMMUN, V50, P630, DOI 10.1016/j.specom.2008.04.002
   EKMAN P, 1993, AM PSYCHOL, V48, P384, DOI 10.1037/0003-066X.48.4.384
   Eshghi A., 2015, P 11 INT C COMP SEM, P261
   Frischen A, 2007, PSYCHOL BULL, V133, P694, DOI 10.1037/0033-2909.133.4.694
   Fujimoto D.T., 2007, B OSAKA JOGAKUIN COL, V37, P35
   Galati A, 2010, J MEM LANG, V62, P35, DOI 10.1016/j.jml.2009.09.002
   GOODWIN C, 1986, HUM STUD, V9, P205, DOI 10.1007/BF00148127
   Gratch J, 2007, LECT NOTES ARTIF INT, V4722, P125
   Gratch J, 2006, LECT NOTES ARTIF INT, V4133, P14
   Gravano A., 2007, P 45 ANN M ASS COMPU, P800
   Gravano A, 2012, COMPUT LINGUIST, V38, P1, DOI 10.1162/COLI_a_00083
   Gravano A, 2011, COMPUT SPEECH LANG, V25, P601, DOI 10.1016/j.csl.2010.10.003
   Guntz T., 2017, P 1 WORKSHOP BEHAV E
   Gustafson J., 2010, P DISS LPSS JOINT WO
   HADAR U, 1985, J NONVERBAL BEHAV, V9, P214, DOI 10.1007/BF00986881
   Hanna N, 2019, ALGORITHMS, V12, DOI 10.3390/a12040079
   Hee E., 2017, 5 EUROPEAN 8 NORDIC
   Heldner M., 2013, P NORDIC PROSODY 11, P137
   Heldner M, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P3054
   Heylen D, 2008, LECT NOTES COMPUT SC, V5208, P270
   Heylen D, 2008, LECT NOTES ARTIF INT, V4930, P241
   Heylen D, 2007, LECT NOTES ARTIF INT, V4722, P147
   Heylen D, 2006, INT J HUM ROBOT, V3, P241, DOI 10.1142/S0219843606000746
   Hjalmarsson A., 2012, P IVA 2012 WORKSHOP
   Howes C, 2021, J LOGIC LANG INFORM, V30, P331, DOI 10.1007/s10849-020-09328-1
   Huang L., 2012, P INTERDISCIPLINARY, P31
   Huang L., 2010, P 9 INT C AUTONOMOUS, P1265
   Huang LX, 2010, LECT NOTES ARTIF INT, V6356, P159, DOI 10.1007/978-3-642-15892-6_17
   Hussain N., 2019, P INTERSPEECH 2019, P4445, DOI [10.21437/Interspeech.2019-2521, DOI 10.21437/INTERSPEECH.2019-2521]
   Inden B, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P181, DOI 10.1145/2522848.2522890
   Ishi CT, 2014, SPEECH COMMUN, V57, P233, DOI 10.1016/j.specom.2013.06.008
   Johansson M, 2016, LECT NOTES ARTIF INT, V9979, P940, DOI 10.1007/978-3-319-47437-3_92
   Jokinen K., 2013, J TIIS, V3, P1, DOI 10.1145/2499474.2499481
   Jonsdottir G.R., 2007, P 7 INT C INTELLIGEN, P154, DOI [10.1007/978-3-540-74997-4_15, DOI 10.1007/978-3-540-74997-4_15]
   Jurafsky D., 1998, P ACL COLING 1998 WO, P114
   Kawahara T, 2016, INTERSPEECH, P2890, DOI 10.21437/Interspeech.2016-118
   KENDON A, 1967, ACTA PSYCHOL, V26, P22, DOI 10.1016/0001-6918(67)90005-4
   Keysar B, 1997, DISCOURSE PROCESS, V24, P253, DOI 10.1080/01638539709545015
   Khosla R., 2012, P 20 ACM INT C MULT, P1173
   Kleckova J., 2005, P 4 WSEASIASME INT C, P280
   Koiso H, 1998, LANG SPEECH, V41, P295, DOI 10.1177/002383099804100404
   Kontogiorgos D, 2021, J MULTIMODAL USER IN, V15, P239, DOI 10.1007/s12193-021-00366-y
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   Kopp S, 2008, LECT NOTES ARTIF INT, V4930, P18
   Kopp S, 2007, LECT NOTES ARTIF INT, V4722, P139
   Kopp S, 2006, LECT NOTES ARTIF INT, V4133, P205
   KRAUSS RM, 1966, J PERS SOC PSYCHOL, V4, P343, DOI 10.1037/h0023705
   Kulic D, 2007, IEEE T ROBOT, V23, P991, DOI 10.1109/TRO.2007.904899
   Laban Guy, 2021, Paladyn, Journal of Behavioral Robotics, V12, P136, DOI 10.1515/pjbr-2021-0011
   Lai C, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1413
   Larson S., 2019, P 2019 C EMP METH NA
   Larsson S., 2003, P 7 WORKSHOP SEMANTI, P75
   Lee J, 2010, IEEE T MULTIMEDIA, V12, P552, DOI 10.1109/TMM.2010.2051874
   Li Y, 2020, AAAI CONF ARTIF INTE, V34, P8293
   Lisetti C. L., 1998, FLAIRS-98. Proceedings of the Eleventh International Florida Artificial Intelligence Research Symposium Conference, P328
   Lisetti C. L., 2000, PRAGMAT COGN, V8, P185, DOI DOI 10.1075/PC.8.1.09LIS
   Liu B, 2017, INT CONF ACOUST SPEE, P5715, DOI 10.1109/ICASSP.2017.7953251
   Liu Yang, 2017, P 2017 C EMP METH NA, P2170
   Ma Y., 2020, P AAAI 20 8 DIALOG S
   Malisz Z, 2016, LANG RESOUR EVAL, V50, P411, DOI 10.1007/s10579-016-9355-6
   Marechal Catherine, 2019, High-Performance Modelling and Simulation for Big Data Applications: Selected Results of the COST Action IC1406 cHiPSet. Lecture Notes in Computer Science (LNCS 11400), P307, DOI 10.1007/978-3-030-16272-6_11
   McClave EZ, 2000, J PRAGMATICS, V32, P855, DOI 10.1016/S0378-2166(99)00079-X
   Meena R, 2014, COMPUT SPEECH LANG, V28, P903, DOI 10.1016/j.csl.2014.02.002
   Misu T., 2011, P PARALINGUISTIC INF, P77, DOI [10.1007/978-1-4614-1335-6_10, DOI 10.1007/978-1-4614-1335-6_10]
   Misu T., 2011, P 12 ANN M SPECIAL I, P259
   Morency L.-P., 2005, P 7 INT C MULTIMODAL, P18, DOI DOI 10.1145/1088463.1088470
   Morency LP, 2007, ARTIF INTELL, V171, P568, DOI 10.1016/j.artint.2007.04.003
   Morency LP, 2010, AUTON AGENT MULTI-AG, V20, P70, DOI 10.1007/s10458-009-9092-y
   Mueller M., 2015, P 17 INT C HCI INT, P259, DOI [10.1007/978-3-319-20916-6_31, DOI 10.1007/978-3-319-20916-6_31]
   Mutlu B., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P61
   Nakano YI, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P553
   Norman D.A., 1990, DESIGN EVERYDAY THIN
   Novick DG, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1888, DOI 10.1109/ICSLP.1996.608001
   Oertel C, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P21, DOI 10.1145/2993148.2993188
   Ortega D, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P247
   Ouyang YW, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P34
   Paggio P., 2017, P 6 WORKSHOP VISION, P40, DOI [10.18653/v1/W17-2006, DOI 10.18653/V1/W17-2006]
   Paggio P., 2020, P LREC2020 WORKSHOP, P15
   Pammi S., 2011, SYNTHESIS LISTENER V
   Petukhova V., 2009, P GESPIN GESTURE SPE
   Pichl J., 2020, CORR ABS201103261
   Poggi I, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2570
   Poppe R, 2013, AUTON AGENT MULTI-AG, V27, P235, DOI 10.1007/s10458-013-9219-z
   Porhet C., 2017, P 19 ACM INT C MULTI, P473, DOI [10.1145/3136755.3136816, DOI 10.1145/3136755.3136816]
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Prepin K., 2013, P 35 ANN M COGNITIVE, P1163
   Purohit H, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P222, DOI 10.1109/SmartCity.2015.75
   Purver M., 2004, THEORY USE CLARIFICA
   Qian Y, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P569, DOI 10.1109/ASRU.2017.8268987
   Qin LB, 2020, AAAI CONF ARTIF INTE, V34, P8665
   Reidsma D, 2011, J MULTIMODAL USER IN, V4, P97, DOI 10.1007/s12193-011-0060-x
   Rieser V, 2011, THEOR APPL NAT LANG, P1, DOI 10.1007/978-3-642-24942-6
   Rodriguez K.J., 2004, P 8 WORKSHOP SEMANTI, P101
   Ruede R, 2019, LECT NOTES ELECTR EN, V510, P247, DOI 10.1007/978-3-319-92108-2_25
   SACKS H, 1974, LANGUAGE, V50, P696, DOI 10.2307/412243
   Sanghvi J, 2011, ACMIEEE INT CONF HUM, P305, DOI 10.1145/1957656.1957781
   Sch?ps T., 2017, 2017 INT C COMP TECH, P1, DOI DOI 10.1109/COMPANION.2017.8287073
   Schroder M, 2012, IEEE T AFFECT COMPUT, V3, P165, DOI 10.1109/T-AFFC.2011.34
   Schwarz J, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3443, DOI 10.1145/2556288.2556989
   Searle John R., 1969, SPEECH ACTS
   Shi H., 2017, DIALOGUES SOCIAL ROB, P451, DOI [10.1007/978-981-10-2585-3_37, DOI 10.1007/978-981-10-2585-3_37]
   Shimojima A, 1998, PROCEEDINGS OF THE TWENTIETH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P951
   Shriberg E, 1998, LANG SPEECH, V41, P443, DOI 10.1177/002383099804100410
   Shu L, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072074
   Sidner C. L., 2006, 1st Annual Conference on Human-Robot Interaction, P290
   Skantze G., 2007, ERROR HANDLING SPOKE
   Skantze G., 2009, P 12 C EUROPEAN CHAP, P745, DOI [10.3115/1609067.1609150, DOI 10.3115/1609067.1609150]
   Skantze G, 2021, COMPUT SPEECH LANG, V67, DOI 10.1016/j.csl.2020.101178
   Skantze G, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P67, DOI 10.1145/2818346.2820749
   Skantze G, 2014, SPEECH COMMUN, V65, P50, DOI 10.1016/j.specom.2014.05.005
   Skantze G, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2002
   Stocksmeier T., 2007, P INTERSPEECH 2007, P1290, DOI [10.21437/Interspeech.2007-232, DOI 10.21437/INTERSPEECH.2007-232]
   Thiebaux M., 2008, P 7 INT C AUTONOMOUS, V1, P151
   Tickle-Degnen L, 1990, PSYCHOL INQ, V1, P285, DOI DOI 10.1207/S15327965PLI0104_
   Traum D., 1992, COMPUT INTELL, V8, P575, DOI DOI 10.1111/J.1467-8640.1992.TB00380.X
   Traum D.R., 1994, TECHNICAL REPORT
   Truong K.P., 2011, P INTERSPEECH 2011, P2973, DOI [10.21437/Interspeech.2011-744, DOI 10.21437/INTERSPEECH.2011-744]
   Tzirakis P, 2021, INFORM FUSION, V68, P46, DOI 10.1016/j.inffus.2020.10.011
   Tzirakis P, 2017, IEEE J-STSP, V11, P1301, DOI 10.1109/JSTSP.2017.2764438
   van Welbergen H, 2010, J MULTIMODAL USER IN, V3, P271, DOI 10.1007/s12193-010-0051-3
   Vilhjalmsson H, 2007, LECT NOTES ARTIF INT, V4722, P99
   Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007
   Visser T, 2014, J MULTIMODAL USER IN, V8, P61, DOI 10.1007/s12193-013-0147-7
   Wallers A, 2006, LECT NOTES ARTIF INT, V4021, P183
   Wang ZY, 2013, AUTON AGENT MULTI-AG, V27, P218, DOI 10.1007/s10458-012-9215-8
   Ward N, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1728, DOI 10.1109/ICSLP.1996.607961
   Ward N., 2006, PRAG COG, V14, P129, DOI DOI 10.1075/PC.14.1.08WAR
   Ward NG, 2016, AI MAG, V37, P7
   Wiener N., 1948, CYBERNETICS CONTROL
   Williams JD, 2014, AI MAG, V35, P121, DOI 10.1609/aimag.v35i4.2558
   Wlodarczak M., 2012, P INTERDISCIPLINARY, P93
   Xu PY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1448
   Yankelovich N., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P369
   Yngve VH., 1970, 6 REG M CHIC LING SO, P567
   Yu Ding, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P217, DOI 10.1007/978-3-642-40415-3_19
   Yuya Chiba, 2016, IAENG International Journal of Computer Science, V43, P1
   Zacharatos H, 2014, IEEE COMPUT GRAPH, V34, P35, DOI 10.1109/MCG.2014.106
   Zhang J., 2020, P 9 JOINT C LEXICAL, P154
   Zhiyang Wang, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P216, DOI 10.1007/978-3-642-23974-8_24
   Zhou, 2018, HDB MULTIMODAL MULTI, V2, P287, DOI DOI 10.1145/3107990.3108002
NR 189
TC 0
Z9 0
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2624-9898
J9 FRONT COMP SCI-SWITZ
JI Front. Comput. Sci.-Switz
PD MAR 15
PY 2022
VL 4
AR 744574
DI 10.3389/fcomp.2022.744574
PG 21
WC Computer Science, Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 0H6CZ
UT WOS:000778821100001
OA Green Published, gold
DA 2022-08-02
ER

PT C
AU Turunen, M
   Hakulinen, J
   Smith, C
   Charlton, D
   Zhang, L
   Cavazza, M
AF Turunen, Markku
   Hakulinen, Jaakko
   Smith, Cameron
   Charlton, Daniel
   Zhang, Li
   Cavazza, Marc
GP ISCA-INST SPEECH COMMUNICATION ASSOC
TI Physically Embodied Conversational Agents as Health and Fitness
   Companions
SO INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH
   COMMUNICATION ASSOCIATION 2008, VOLS 1-5
LA English
DT Proceedings Paper
CT 9th Annual Conference of the
   International-Speech-Communication-Association (INTERSPEECH 2008)
CY SEP 22-26, 2008
CL Brisbane, AUSTRALIA
DE spoken dialogue systems; multimodality; software architectures; physical
   agent interfaces
ID ARCHITECTURE
AB We present a physical multimodal conversational Companion in the area of health and fitness. Conversational spoken dialogues using physical agents provide a potential interface for applications which are aimed at motivating and supporting users. Open source software called jNabServer, which enables spoken and multimodal interaction with Nabaztag/tag wireless rabbits, is presented together with other software architecture solutions applied in the development of the Companion. We also present how the Companion manages interaction with the combination of a dialogue manager and a cognitive model.
C1 [Turunen, Markku; Hakulinen, Jaakko] Univ Tampere, Tampere Unit Comp Human Interact, Speech Based & Pervas Interact Grp, Tampere, Finland.
   [Smith, Cameron; Charlton, Daniel; Zhang, Li; Cavazza, Marc] Univ Teesside, Sch Comp, Middlesbrough, Cleveland, England.
RP Turunen, M (corresponding author), Univ Tampere, Tampere Unit Comp Human Interact, Speech Based & Pervas Interact Grp, Tampere, Finland.
EM mturunen@cs.uta.fi; jh@cs.uta.fi; c.g.smith@tees.ac.uk;
   d.charlton@tees.ac.uk; l.zhang@tees.ac.uk; m.o.cavazza@tees.ac.uk
RI Hakulinen, Jaakko/ABG-1291-2020
OI Hakulinen, Jaakko/0000-0001-8054-7265; Cavazza,
   Marc/0000-0001-6113-9696; Turunen, Markku/0000-0001-7395-0769
FU EU [IST-34434]
FX This work is supported by the EU-funded COMPANIONS-project (IST-34434).
   Nabaztag (TM) is a trademark of Violet (TM), who is thanked for
   authorizing the development of the "NabServer" software.
CR Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bohus D, 2003, RAVENCLAW DIALOG MAN
   CAVAZZA M, 2008, P AAMAS08
   Core M. G., 1997, AAAI FALL S COMM ACT
   Dybkjaer L, 2004, SPEECH COMMUN, V43, P33, DOI 10.1016/j.specom.2004.02.001
   KAINULAINEN A, 2005, P 10 INT C SPEECH CO, P231
   Marti Stefan, 2005, P 18 ANN ACM S US IN, P231, DOI [10.1145/1095034.1095073, DOI 10.1145/1095034.1095073]
   Martin DL, 1999, APPL ARTIF INTELL, V13, P91, DOI 10.1080/088395199117504
   MCTEAR M, 2004, P WORKSH ROB AD INF
   Rudnicky A, 1999, IEEE AUT SPEECH REC, P1
   SENEFF S, 1998, P ICSLP98
   Turunen M, 2005, IBM SYST J, V44, P485, DOI 10.1147/sj.443.0485
   WILKS U, 2007, SCIENCE         1109
NR 13
TC 2
Z9 2
U1 0
U2 0
PU ISCA-INT SPEECH COMMUNICATION ASSOC
PI BAIXAS
PA C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS,
   BAIXAS, F-66390, FRANCE
BN 978-1-61567-378-0
PY 2008
BP 2466
EP +
PG 2
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BOM81
UT WOS:000277026101195
DA 2022-08-02
ER

PT C
AU Leray, D
   Sansonnet, JP
AF Leray, David
   Sansonnet, Jean-Paul
BE Butz, CJ
   Nguyen, NT
   Takama, Y
   Cheung, W
   Cheung, YM
TI Ordinary user oriented model construction for Assisting Conversational
   Agents
SO 2006 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND
   INTELLIGENT AGENT TECHNOLOGY, WORKSHOPS PROCEEDINGS
LA English
DT Proceedings Paper
CT IEEE/WIC/ACM International Conference on Web Intelligence and
   Intelligent Agent Technology (WI-IAT 2006)
CY DEC 18-22, 2006
CL Hong Kong, PEOPLES R CHINA
SP IEEE, WIC, ACM
AB In this paper, we defend the idea of integrating the actual cognitive features of novice users in the creation process of the applications to significantly increase the quality of the function of assistance. First we present a framework dedicated to the recording of novice user natural language utterances in assisting situations. Then we propose a first analysis of the collected corpus in terms of the perceptual features appearing in the linguistic referential expressions.
C1 [Leray, David; Sansonnet, Jean-Paul] LIMSI, CNRS, BP133, F-91403 Orsay, France.
RP Leray, D (corresponding author), LIMSI, CNRS, BP133, F-91403 Orsay, France.
CR [Anonymous], 1977, THEORY AFFORDANCES
   BUISINE S, 2003, P WORKSH ECCI AAMAS
   CAPOBIANCO A, 2003, INTERACT 03, P65
   CARENINI G, 1993, INT WORKSH INT US IN, P175
   Cassell J., 2000, EMBODIED CONVERSATIO
   KITTREDGE RI, 2003, OXFORD HDB COMPUTATI, pCH23
   Lester J. C., 1997, CHI 97
   MAES P, 1994, COMMUNICATIONS ACM, V37
   MARION C, WHAT IS INTERACTION
   Sansonnet JP, 2005, LECT NOTES ARTIF INT, V3661, P111
   SANSONNET JP, 2006, IVA 06 MARINA DEL RE
NR 11
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
BN 978-0-7695-2749-9
PY 2006
BP 355
EP +
DI 10.1109/WI-IATW.2006.101
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BFU08
UT WOS:000244608000079
DA 2022-08-02
ER

PT C
AU Bello, MJG
AF Bello, Manases Jesus Galindo
BE Munoz, VM
   Ferguson, D
   Helfert, M
   Pahl, C
TI Cloud-based Conversational Agents for User Acquisition and Engagement
SO CLOSER: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON CLOUD
   COMPUTING AND SERVICES SCIENCE
LA English
DT Proceedings Paper
CT 9th International Conference on Cloud Computing and Services Science
   (CLOSER)
CY MAY 02-04, 2019
CL Heraklion, GREECE
DE Dialog Systems; Chatbots; Cloud Computing; Artificial Intelligence;
   Natural Language Processing
AB The benefits of cloud computing have driven different companies from diverse sectors to migrate their products and services to the cloud. In the last decade many businesses have adopted web and mobile applications to offer better customer service as well as used social networks for advertisements and marketing campaigns aiming to acquire, engage and retain their customers. This paper presents a case study combining the areas of chatbots, cloud computing and customer service, acquisition and engagement targeting the gastronomy industry; it evaluates and compares the implementation of a chatbot as a cloud-native application (Platform as a Service) versus one built utilizing an authoring tool (Software as a Service); and it demonstrates how a gastronomic business could attract with ease new customers by interacting with them using chatbots embedded into instant messaging apps.
C1 [Bello, Manases Jesus Galindo] Software AG, Cumuloc LoT Core R&D, Berlin, Germany.
RP Bello, MJG (corresponding author), Software AG, Cumuloc LoT Core R&D, Berlin, Germany.
CR Abu Shawar BA and Atwell ES, 2007, J LANG TECHNOL COMPU, V22, P29
   Bello MJG, 2018, INT CONF SOFTW ENG, P32, DOI 10.1109/ICSESS.2018.8663862
   Brandtzaeg P., 2017, LECT NOTES COMPUTER
   Braun A., 2003, CHATBOTS CUSTOMER CO
   Fadhil A., 2018, CAN CHATBOT DETERMIN
   Galindo Bello M. J., 2018, DISCRETIONARY ADOPTI
   Maslowska E, 2016, J MARKET MANAG-UK, V32, P469, DOI 10.1080/0267257X.2015.1134628
   Oracle, 2018, CLOUD PRED
   PARASURAMAN A, 1991, SLOAN MANAGE REV, V32, P39
   Rising R., 1978, AM MATH MONTHLY, V85
   Shevat A., 2017, DESIGNING BOTS CREAT
   Turing AM., 1950, J MIND ASS, V59, P433, DOI [10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   von Wangenheim F, 2007, J ACAD MARKET SCI, V35, P233, DOI 10.1007/s11747-007-0037-1
   Vries L., 2017, J MARKETING, V81
NR 14
TC 1
Z9 1
U1 0
U2 2
PU SCITEPRESS
PI SETUBAL
PA AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL
BN 978-989-758-365-0
PY 2019
BP 528
EP 534
DI 10.5220/0007766105280534
PG 7
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP9YQ
UT WOS:000571051500058
OA hybrid, Green Submitted
DA 2022-08-02
ER

PT J
AU Robe, P
   Kuttal, SK
AF Robe, Peter
   Kuttal, Sandeep Kaur
TI Designing PairBuddy-A Conversational Agent for Pair Programming
SO ACM TRANSACTIONS ON COMPUTER-HUMAN INTERACTION
LA English
DT Article
DE Conversational agents; pair programming; user centered design; Wizard of
   Oz
ID INTELLIGENT TUTORING SYSTEMS; DECISION-MAKING; SOCIAL PRESENCE;
   FEEDBACK; GENDER; IMPACT; PERFORMANCE; DELAY; METAANALYSIS; CREATIVITY
AB From automated customer support to virtual assistants, conversational agents have transformed everyday interactions, yet despite phenomenal progress, no agent exists for programming tasks. To understand the design space of such an agent, we prototyped PairBuddy-an interactive pair programming partner-based on research from conversational agents, software engineering, education, human-robot interactions, psychology, and artificial intelligence. We iterated PairBuddy's design using a series of Wizard-of-Oz studies. Our pilot study of six programmers showed promising results and provided insights toward PairBuddy's interface design. Our second study of 14 programmers was positively praised across all skill levels. PairBuddy's active application of soft skills-adaptability, motivation, and social presence-as a navigator increased participants' confidence and trust, while its technical skills-code contributions, just-in-time feedback, and creativity support-as a driver helped participants realize their own solutions. PairBuddy takes the first step towards an Alexa-like programming partner.
C1 [Robe, Peter; Kuttal, Sandeep Kaur] Univ Tulsa, Tulsa, OK 74104 USA.
RP Robe, P (corresponding author), Univ Tulsa, Tulsa, OK 74104 USA.
EM pjr144@utulsa.edu; sandeepkuttal@utulsa.edu
FU National Science Foundation (CAREER) [2046205]
FX This material is based upon work supported by the National Science
   Foundation (CAREER) under award number 2046205. Any opinions, findings,
   and conclusions or recommendations expressed in this material are those
   of the authors and do not necessarily reflect the view of the NSF. We
   would like to thank David Magar, Jarow Myers, Sam Gurka, Katherine
   Kwasny, and Bali Ong for help with the studies; David Piorkowski and
   Rachel Bellamy for their feedback; and Courtney Spivey for editing.
CR 2021 JetBrains, US
   Abbas Tahir, 2020, P AAAI C HUMAN COMPU, V8, P3
   Abowd Gregory D., 1992, INTERACT COMPUT, V4, P317, DOI [10.1016/0953-5438(92)90021-7, DOI 10.1016/0953-5438(92)90021-7]
   Adiwardana D., 2020, HUMAN LIKE OPENDOMAI, DOI DOI 10.3390/healthcare7020056
   Ahmadvand A, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1273, DOI 10.1145/3331184.3331375
   Ai-Chang M, 2004, IEEE INTELL SYST, V19, P8, DOI 10.1109/MIS.2004.1265878
   Aiken Milam, 1995, GROUP DECISION SUPPO, V16, P38
   Al-Ani B, 2009, INT CONF GLOBAL SOFT, P121, DOI 10.1109/ICGSE.2009.20
   ALAVI M, 1994, MIS QUART, V18, P159, DOI 10.2307/249763
   Ali S, 2010, IEEE T SOFTWARE ENG, V36, P742, DOI 10.1109/TSE.2009.52
   Amabile TM, 2016, RES ORGAN BEHAV, V36, P157, DOI 10.1016/j.riob.2016.10.001
   Amershi S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300233
   [Anonymous], 1957, ACTIVE LISTENING
   [Anonymous], SOCIAL MEDIA WEBSITE
   [Anonymous], 2020, TWEET COD GEN GPT 3
   [Anonymous], 2020, YOUTUBE VID SHOW GEN
   [Anonymous], BING QA
   [Anonymous], 2017, 247652017E ISOIECIEE, P1, DOI [DOI 10.1109/IEEESTD.2017.8016712, 10.1109/IEEESTD.2017.8016712]
   [Anonymous], 2010, MAKING SOFTWARE WHAT
   [Anonymous], Software Application
   [Anonymous], 2022, ORACLE DIGITAL ASSIS
   [Anonymous], 2020, MAIN STUDY SUPPORTIN
   [Anonymous], 1987, PEOPLEWARE PRODUCTIV
   [Anonymous], 2018, 26515 ISOIECIEEE, P1, DOI [10.1109/IEEESTD.2018.8584455, DOI 10.1109/IEEESTD.2018.8584455]
   [Anonymous], Freelancing Platform
   [Anonymous], Google Assistant
   [Anonymous], AMAZON ALEXA
   [Anonymous], 2021, VISUAL STUDIO
   [Anonymous], APPLE SIRI
   [Anonymous], IBM WATSON ASSISTANT
   [Anonymous], 2020, PILOT STUDY SUPPORTI
   Arazy Ofer, 2015, AIS T HUMAN COMPUTER, V7, P43
   Armstrong Michael, 2012, ARMSTRONGS HDB REWAR, V12
   Ashktorab Z, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300484
   Baylor AL, 2009, COMPUT HUM BEHAV, V25, P450, DOI 10.1016/j.chb.2008.10.008
   Behrend T, 2012, COMPUT HUM BEHAV, V28, P2128, DOI 10.1016/j.chb.2012.06.017
   Belshee A, 2005, AGILE 2005, Proceedings, P125, DOI 10.1109/ADC.2005.37
   Bente G, 2008, HUM COMMUN RES, V34, P287, DOI 10.1111/j.1468-2958.2008.00322.x
   Berland Edelman and Inc, 2010, CREAT ED WHY IT MATT
   Bickmore T., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P396
   Bohus D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P637
   BRACKBILL Y, 1963, J EXP PSYCHOL, V66, P57, DOI 10.1037/h0043368
   Bradley Jay, 2010, P 24 BCS INT SPEC GR, P117
   Brahnam S, 2012, INTERACT COMPUT, V24, P139, DOI 10.1016/j.intcom.2012.05.001
   Brandtzaeg PB, 2017, LECT NOTES COMPUT SC, V10673, P377, DOI 10.1007/978-3-319-70284-1_30
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]
   Brown T.B., 2020, ADV NEURAL INF PROCE
   Brown T, 2009, BUS WEEK, P54
   Bui T. X., 1987, COOP GROUP DECISION
   Burnett M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2586, DOI 10.1145/2858036.2858274
   Burnett M, 2016, INTERACT COMPUT, V28, P760, DOI 10.1093/iwc/iwv046
   Burri R., 2018, THESIS KTH
   Cassell J, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P106
   Celepkolu M, 2018, SIGCSE'18: PROCEEDINGS OF THE 49TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P771
   Cerasoli CP, 2014, PSYCHOL BULL, V140, P980, DOI 10.1037/a0035661
   Cha HJ, 2006, LECT NOTES COMPUT SC, V4053, P513
   Charness G, 2012, J ECON BEHAV ORGAN, V83, P50, DOI 10.1016/j.jebo.2011.06.007
   Chen JYC, 2014, IEEE T HUM-MACH SYST, V44, P13, DOI 10.1109/THMS.2013.2293535
   Choi KS, 2013, P ANN HICSS, P4817, DOI 10.1109/HICSS.2013.209
   Chou TL, 2019, NLPIR 2019: 2019 3RD INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND INFORMATION RETRIEVAL, P87, DOI 10.1145/3342827.3342844
   Cohn M, 2019, 20TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2019), P293
   Contreras JM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0069684
   Cooper S., 2000, J COMPUTING SCI COLL, V15, P107
   Crow Tyne, 2018, P 20 AUSTR COMP ED C, P53
   CYTRON R, 1991, ACM T PROGR LANG SYS, V13, P451, DOI 10.1145/115372.115320
   da Silva Fabio Q B, 2010, Proceedings of the 2010 Fifth IEEE International Conference Global Software Engineering (ICGSE 2010), P87, DOI 10.1109/ICGSE.2010.18
   Dahlback N., 1993, P 1 INT C INTELLIGEN, P193, DOI DOI 10.1145/169891.169968
   Day Melissa, 2019, 2019 IEEE First International Conference on Cognitive Machine Intelligence (CogMI). Proceedings, P71, DOI 10.1109/CogMI48466.2019.00018
   de la Barra CL, 2007, LECT NOTES COMPUT SC, V4799, P415
   de Vries H, 2017, PROC CVPR IEEE, P4466, DOI 10.1109/CVPR.2017.475
   Deci EL, 2017, ANNU REV ORGAN PSYCH, V4, P19, DOI 10.1146/annurev-orgpsych-032516-113108
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   DESANCTIS G, 1987, MANAGE SCI, V33, P589, DOI 10.1287/mnsc.33.5.589
   DeVault David, 2014, SIMSENSEI KIOSK
   Devlin J., 2018, ARXIV
   Eclipse, 2019, ECL IDE
   Eclipse, 2020, US
   Elghondakly R, 2015, 2015 IEEE SEVENTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INFORMATION SYSTEMS (ICICIS), P607, DOI 10.1109/IntelCIS.2015.7397285
   Evens Martha, 2006, ONE ON ONE TUTORING
   Festante Raoul, 2007, INTRO THEORY GENDER
   Fischer C, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00137
   Fogarty J., 2005, ACM Transactions on Computer-Human Interaction, V12, P119, DOI 10.1145/1057237.1057243
   Foroughi CK, 2014, HUM FACTORS, V56, P1262, DOI 10.1177/0018720814531786
   Fraser G, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON SOFTWARE TESTING, VERIFICATION AND VALIDATION (ICST 2013), P362, DOI 10.1109/ICST.2013.51
   Fraser Gordon, 2012, IEEE T SOFTWARE ENG, V39, P276
   Gallis Hans, 2002, P WORKSHOP PAIR PROG
   Gao JF, 2018, ACM/SIGIR PROCEEDINGS 2018, P1371, DOI 10.1145/3209978.3210183
   Geller T, 2008, IEEE COMPUT GRAPH, V28, P11, DOI 10.1109/MCG.2008.79
   GenderMag, 2019, US
   George S, 2019, PROCEEDINGS OF THE 1ST INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES (CUI 2019), DOI 10.1145/3342775.3342807
   Gerdes A, 2017, INT J ARTIF INTELL E, V27, P65, DOI 10.1007/s40593-015-0080-x
   GitHub, 2020, US
   Gonzalez-Franco M, 2020, IEEE T VIS COMPUT GR, V26, P2023, DOI 10.1109/TVCG.2020.2973075
   Gray P., 1987, Decision Support Systems, V3, P233, DOI 10.1016/0167-9236(87)90178-3
   Green Paul, 1985, UUCS2015019
   Grimm P., 2010, WILEY INT ENCY MARKE, DOI [10.1002/9781444316568.wiem02057, DOI 10.1002/9781444316568.WIEM02057]
   GTTS, 2019, GOOGL TEXT SPEECH PY
   Haeuslschmid R, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P319, DOI 10.1145/3025171.3025198
   Han KW, 2010, IEEE T EDUC, V53, P318, DOI 10.1109/TE.2009.2019121
   Han Qinghong, 2020, NONAUTOREGRESSIVE NE
   Hanks BF, 2004, LECT NOTES COMPUT SC, V3134, P81
   Hardin B., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P165
   Hasegawa Dai, 2010, P 2010 AAAI FALL S S
   Hassanein K, 2007, INT J HUM-COMPUT ST, V65, P689, DOI 10.1016/j.ijhcs.2006.11.018
   Hattie J, 2007, REV EDUC RES, V77, P81, DOI 10.3102/003465430298487
   Hattie John, 1999, COMMUNICATION 0802, P21
   Hill Charles, 2017, SUM ITS PARTS INVEST
   Huang XT, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P660
   Humble N, 2019, PROCEEDINGS OF THE EUROPEAN CONFERENCE ON THE IMPACT OF ARTIFICIAL INTELLIGENCE AND ROBOTICS (ECIAIR 2019), P157, DOI 10.34190/ECIAIR.19.007
   Irani L., 2004, SIGCSE Bulletin, V36, P195
   Isaksen SG, 2004, J CREATIVE BEHAV, V38, P75, DOI 10.1002/j.2162-6057.2004.tb01234.x
   Jain Mohit, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3287048
   Jain M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P895, DOI 10.1145/3196709.3196735
   JamesWilson, 1988, HDB HUMAN COMPUTER I, P859, DOI DOI 10.1016/B978-0-444-70536-5.50044-0
   Jernigan W, 2015, PROCEEDINGS 2015 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING (VL/HCC), P235, DOI 10.1109/VLHCC.2015.7357222
   Jernigan W, 2017, J VISUAL LANG COMPUT, V39, P51, DOI 10.1016/j.jvlc.2017.04.005
   Jones DL, 2013, S VIS LANG HUM CEN C, P103, DOI 10.1109/VLHCC.2013.6645252
   Jordan PW, 2007, FRONT ARTIF INTEL AP, V158, P43
   Joshi A., 2015, BRIT J APPL SCI TECH, V7, P396, DOI [10.9734/BJAST/2015/14975, DOI 10.9734/BJAST/2015/14975]
   Kacewicz E, 2014, J LANG SOC PSYCHOL, V33, P125, DOI 10.1177/0261927X13502654
   Kahn P. H., 2008, P 3 ACM IEEE INT C H, P97, DOI [10.1145/1349822.1349836, DOI 10.1145/1349822.1349836]
   Katira N., 2004, SIGCSE Bulletin, V36, P7
   Kavitha RK, 2015, EDUC INF TECHNOL, V20, P319, DOI 10.1007/s10639-013-9285-5
   Kearsley Greg P., 1987, ARTIF INTELL
   Keivanloo I, 2014, 36TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2014), P664, DOI 10.1145/2568225.2568292
   Kessler R, 2002, PAIR PROGRAMMING ILL
   Kim K, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P946, DOI 10.1145/3180155.3180187
   Kim S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P567
   Kitchenham BA, 2002, IEEE T SOFTWARE ENG, V28, P721, DOI 10.1109/TSE.2002.1027796
   Klopfenstein LC, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P555, DOI 10.1145/3064663.3064672
   Kluger AN, 1996, PSYCHOL BULL, V119, P254, DOI 10.1037/0033-2909.119.2.254
   Ko A, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1569
   Ko Andrew J., 2004, P SIGCHI C HUM FACT, P151, DOI [10.1145/985692.985712, DOI 10.1145/985692.985712]
   KULIK JA, 1988, REV EDUC RES, V58, P79, DOI 10.3102/00346543058001079
   Kulik JA, 2016, REV EDUC RES, V86, P42, DOI 10.3102/0034654315581420
   Kuttal SK, 2020, S VIS LANG HUM CEN C
   Kuttal SK, 2019, S VIS LANG HUM CEN C, P75, DOI 10.1109/VLHCC.2019.8818790
   Kwasny Kate, 2021, TRADE OFFS SUBSTITUT
   Lahiri Shuvendu K., 2012, Computer Aided Verification. Proceedings 24th International Conference, CAV 2012, P712, DOI 10.1007/978-3-642-31424-7_54
   Landauer T. K., 1987, SIGCHI Bulletin, P333
   Lane HC, 2005, COMPUT SCI EDUC, V15, P183, DOI 10.1080/08993400500224286
   Le Hung, 2020, P INT C LEARNING REP
   Levine Marvin, 1988, EFFECTIVE PROBLEM SO
   Lewis C., 1982, RC9265 IBM
   Li SF, 2010, LANG LEARN, V60, P309, DOI 10.1111/j.1467-9922.2010.00561.x
   Li Toby Jia-Jun, 2020, CHI 2020 WORKSHOP AR
   Limayem M, 2006, DECIS SUPPORT SYST, V42, P945, DOI 10.1016/j.dss.2005.08.004
   Liu D., 2007, P 22 IEEE ACM INT C, P234
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4487
   Liu ZQ, 2004, INT J ENG EDUC, V20, P801
   Long J, 2009, J INF TECHNOL EDUC-R, V8, P229
   Lopatovska I, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P265, DOI 10.1145/3176349.3176868
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Ma WT, 2014, J EDUC PSYCHOL, V106, P901, DOI 10.1037/a0037123
   Makonin Stephen, 2016, 2016 49th Hawaii International Conference on System Sciences (HICSS). Proceedings, P1427, DOI 10.1109/HICSS.2016.181
   Maloney D, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY COMPANION EXTENDED ABSTRACTS (CHI PLAY 2018), P39, DOI 10.1145/3270316.3270599
   Marcus A, 2005, PROG COMPREHEN, P33, DOI 10.1109/WPC.2005.33
   Marinho M, 2019, INT SYMP EMP SOFTWAR, P202
   Marlow J., 2013, P 2013 C COMP SUPP C, P145, DOI DOI 10.1145/2441776.2441794
   Matsushima A, 2019, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT INTERACTION (HAI'19), P262, DOI 10.1145/3349537.3352786
   McDowell C, 2003, PROC INT CONF SOFTW, P602, DOI 10.1109/ICSE.2003.1201243
   McDowell C., 2002, SIGCSE Bulletin, V34, P38
   McMinn P, 2004, SOFTW TEST VERIF REL, V14, P105, DOI 10.1002/stvr.294
   Medel P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE'17), P411, DOI 10.1145/3017680.3017794
   Meiliana, 2017, PROCEDIA COMPUT SCI, V116, P629, DOI 10.1016/j.procs.2017.10.029
   Melnik G., 2002, Extreme Programming and Agile Methods - XP/Agile Universe 2002 Second XP Universe and First Agile Universe Conference. Proceedings (Lecture Notes in Computer Science Vol.2418), P241
   Memeti S, 2018, J COMPUT SCI-NETH, V26, P275, DOI 10.1016/j.jocs.2018.01.001
   Mendez C, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P1004, DOI 10.1145/3180155.3180241
   Miller Casey, 2001, HDB NONSEXIST WRITIN
   Movshovitz-Attias Dana, 2013, 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P886
   Murphy-Hill Emerson, 2007, P 1 WORKSHOP REFACTO, P61
   Naiakshina A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376791
   NEDERHOF AJ, 1985, EUR J SOC PSYCHOL, V15, P263, DOI 10.1002/ejsp.2420150303
   Nesbit JC, 2014, IEEE INT CONF ADV LE, P99, DOI 10.1109/ICALT.2014.38
   Ng M, 2020, 2020 IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (EUROS&PW 2020), P190, DOI 10.1109/EuroSPW51379.2020.00034
   Le NT, 2013, STUD COMPUT INTELL, V479, P267, DOI 10.1007/978-3-319-00293-4_20
   Le NT, 2016, SYSTEMS, V4, DOI 10.3390/systems4020022
   Nielsen J., 1990, SIGCHI Bulletin, P249
   Niu HR, 2017, EMPIR SOFTW ENG, V22, P259, DOI 10.1007/s10664-015-9421-5
   Noll John, 2010, ACM INROADS, V1, P66, DOI DOI 10.1145/1835428.1835445
   Novick David, 1997, P AAAI SPRING S COMP
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Osborn A. F, 1957, APPL IMAGINATION PRI
   Pacheco Carlos, 2007, P COMP 22 ACM SIGPLA
   Page-Jones M., 1988, PRACTICAL GUIDE STRU, V2Nd
   Palmieri D. W., 2002, KNOWLEDGE MANAGEMENT
   Pillay N., 2003, SIGCSE Bulletin, V35, P78
   Polya George, 2004, SOLVE IT NEW ASPECT, V85
   Poole Marshall Scott, 1988, P 1988 ACM C COMPUTE
   POOLE MS, 1993, COMMUN RES, V20, P176, DOI 10.1177/009365093020002002
   Qiu SH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376403
   Queiros Ricardo Alexandre Peixoto, 2012, P 17 ACM ANN C INN T, P192
   Raghothaman M, 2016, PROC INT CONF SOFTW, P357, DOI 10.1145/2884781.2884808
   Raheja Vipul, 2019, INPR 2019 C N AM CHA, V1, P3727
   Rane Prerana Pradeepkumar, 2017, THESIS VIRGINIA TECH
   Reinertsen JL, 2000, BRIT MED J, V320, P730, DOI 10.1136/bmj.320.7237.730
   Reiter E., 2000, BUILDING NATURAL LAN
   Ren Liliang, 2019, P C EMP METH NAT LAN, P1876, DOI 10.18653/v1/D19-1196
   Robe P, 2020, S VIS LANG HUM CEN C
   Rodriguez FJ, 2017, PROCEEDINGS OF THE 2017 ACM SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE'17), P507, DOI 10.1145/3017680.3017748
   Rojas Jose Miguel, 2015, Search-Based Software Engineering. 7th International Symposium, SSBSE 2015. Proceedings: LNCS 9275, P93, DOI 10.1007/978-3-319-22183-0_7
   Rolim R, 2017, PROC INT CONF SOFTW, P404, DOI 10.1109/ICSE.2017.44
   Ruan Sherry, 2018, PROC ACM INTERACT MO, V1, DOI [10.1145/3161187, DOI 10.1145/3161187]
   Ruvalcaba Omar, 2016, P 47 ACM TECHN S COM, P90, DOI 10.1145/2839509.2844558
   Salinger Stephan, 2010, SAROS ECLIPSE PLUGIN, P48
   SAMBAMURTHY V, 1994, DECISION SCI, V25, P215, DOI 10.1111/j.1540-5915.1994.tb01840.x
   Sarma A, 2016, INT CONF GLOBAL SOFT, P1, DOI 10.1109/ICGSE.2016.35
   Savage T., 2010, 2010 32nd International Conference on Software Engineering (ICSE), P255, DOI 10.1145/1810295.1810345
   SCHROTH ML, 1993, CONTEMP EDUC PSYCHOL, V18, P15, DOI 10.1006/ceps.1993.1003
   Seaman CB, 1999, IEEE T SOFTWARE ENG, V25, P557, DOI 10.1109/32.799955
   Seo Y.-H., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI [10.17485/ijst/2016/v9i46/107837, DOI 10.17485/ijst/2016/v9i46/107837]
   Seymour M, 2017, PROCEEDINGS OF THE 50TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P547
   Shekhar A, 2018, PROCEEDINGS OF THE 4TH CONFERENCE ON GENDER & IT (GENDERIT '18), P191, DOI 10.1145/3196839.3196869
   Sheremetov L, 2002, COMPUT EDUC, V39, P161, DOI 10.1016/S0360-1315(02)00030-1
   SHNEIDERMAN B, 1982, COMMUN ACM, V25, P610, DOI 10.1145/358628.358639
   Sihang Qiu, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3392837
   Smith G., 2010, P 5 INT C FDN DIG GA, P209, DOI DOI 10.1145/1822348.1822376
   Social Bot, MITS
   Social Bot, CLEV
   Social Bot, SAP CONV AI
   Social Bot, 2020, CHATB STAT
   Spieler Jorg, 2021, UCDETECTOR
   Sproull L, 1996, HUM-COMPUT INTERACT, V11, P97, DOI 10.1207/s15327051hci1102_1
   StackOverflow, 2020, US
   Steenbergen-Hu S, 2014, J EDUC PSYCHOL, V106, P331, DOI 10.1037/a0034752
   Steenbergen-Hu S, 2013, J EDUC PSYCHOL, V105, P970, DOI 10.1037/a0032447
   Storey Margaret-Anne, 2013, P C COMP SUPP COORP, P103
   Strauss A.L., 1998, BASICS QUALITATIVE R, V2nd ed.
   STRUTZEL E, 1968, NURS RES, V17, P364
   STURGES PT, 1972, J EDUC PSYCHOL, V63, P32, DOI 10.1037/h0032158
   SWINDELL LK, 1993, CONTEMP EDUC PSYCHOL, V18, P363, DOI 10.1006/ceps.1993.1026
   Tak-Wai Chan, 1996, Journal of Artificial Intelligence in Education, V7, P125
   Takanobu R, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P625
   Tannen D. F., 1987, PSYCHOLINGUISTIC MOD, P251
   Toader DC, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12010256
   Uresti J. Ramirez, 2004, INT J ARTIFICIAL INT, V14, P193
   Uresti JAR, 2000, LECT NOTES COMPUT SC, V1839, P103
   van der Struijk S, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P159, DOI 10.1145/3267851.3267918
   van Mulken S, 1998, PEOPLE AND COMPUTER XIII, PROCEEDINGS, P53
   van Mulken S., 1999, Human-Computer Interaction: Ergonomics and User Interfaces. Proceedings of HCI International '99 (8th International Conference on Human-Computer Interaction), P152
   VanLehn K, 2007, COGNITIVE SCI, V31, P3, DOI 10.1080/03640210709336984
   VanLehn K, 2011, EDUC PSYCHOL-US, V46, P197, DOI 10.1080/00461520.2011.611369
   Varma R, 2010, COMPUT SCI EDUC, V20, P301, DOI 10.1080/08993408.2010.527697
   Vermeulen N, 2008, COGNITION, V109, P287, DOI 10.1016/j.cognition.2008.09.004
   Vizcaino A., 2005, INT J ARTIFICIAL INT, V15, P3
   VOGEL D, 1990, INFORM MANAGE, V18, P15, DOI 10.1016/0378-7206(90)90060-U
   Vorvoreanu M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300283
   Waern Y, 1996, COMPUT HUM BEHAV, V12, P17, DOI 10.1016/0747-5632(95)00016-X
   Wagner T., 2012, CREATING INNOVATORS
   Wargnier P, 2016, IEEE INT CONF SERIOU
   WATSON RT, 1988, MIS QUART, V12, P463, DOI 10.2307/249214
   Werner L., 2004, J ED RESOURCES COMPU, V4, P1, DOI 10.1145/1060071.1060072
   Wickelgren WA, 1974, SOLVE PROBLEMS ELEME
   Williams AC, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P81, DOI 10.1145/3332165.3347932
   Williams L, 2003, 2003 INTERNATIONAL SYMPOSIUM ON EMPIRICAL SOFTWARE ENGINEERING, PROCEEDINGS, P143, DOI 10.1109/ISESE.2003.1237973
   Williams L., 2002, COMPUTER SCI ED, V12, P197, DOI DOI 10.1076/CSED.12.3.197.8618
   Williams L. A., 2000, 13 C SOFTW ENG ED TR, P59, DOI [10.1109/CSEE.2000.827023, DOI 10.1109/CSEE.2000.827023]
   Williams Laurie, 2001, COSTS BENEFITS PAIR, P223
   Witten Ian H., 1996, P WORKSHOP MACHINE L, V96, P51
   Woolf Beverly Park, 2008, BUILDING INTELLIGENT
   Wu Qingyang, 2021, P 16 C EUROPEAN CHAP, P1292, DOI [10.18653/v1/2021.eacl-main.110, DOI 10.18653/V1/2021.EACL-MAIN.110]
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yannakakis G. N., 2014, MIXED INITIATIVE COC
   Yee N, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1
   Zalake M, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P329, DOI 10.1145/3267851.3267863
   Zhang JP, 2018, 19TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2018), P140
   Zhang YC, 2020, AAAI CONF ARTIF INTE, V34, P9604
   Zhao Y., 2012, WORLD CLASS LEARNERS
   Zhi R., 2019, P 12 INT C ED DATA M
   Zhou C, 2018, 2018 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING (VL/HCC), P319, DOI 10.1109/VLHCC.2018.8506577
   Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI [10.1162/coli_a_00368, 10.1162/COLI_a_00368]
   Zhu Su, 2020, P FIND ASS COMP LING, P766, DOI 10.18653/v1/2020.findings-emnlp.68
   Zieris F., 2014, P 8 ACM IEEE INT S E, DOI [10.1145/2652524.2652529, DOI 10.1145/2652524.2652529]
NR 273
TC 0
Z9 0
U1 6
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 1073-0516
EI 1557-7325
J9 ACM T COMPUT-HUM INT
JI ACM Trans. Comput.-Hum. Interact.
PD AUG
PY 2022
VL 29
IS 4
AR 34
DI 10.1145/3498326
PG 44
WC Computer Science, Cybernetics; Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 1G5NK
UT WOS:000795894400007
DA 2022-08-02
ER

PT J
AU Almajano, P
   Sanchez, ML
   Rodriguez, I
   Mayas, E
AF Almajano, P.
   Sanchez, M. L.
   Rodriguez, I.
   Mayas, E.
TI Including Conversational Agents into Structured Hybrid 3D Virtual
   Environments
SO IEEE LATIN AMERICA TRANSACTIONS
LA Portuguese
DT Article; Proceedings Paper
CT IEEE Latin-America Conference on Communications (LATINCOM)
CY NOV 24-26, 2013
CL Santiago, CHILE
SP IEEE Commun Soc, Inst Elect & Elect Engineers
DE 3D Virtual Worlds; Human-Computer Interaction; AIML
AB Structured Hybrid 3D Virtual Environments are 3D virtual spaces where staff (organisational) software agents support human users in their task achievement. These systems are characterized by: i) being hybrid, so that humans and software agents can interact; and ii) being structured and task oriented, so that interactions are regulated by a subjacent Organisation Centered Multi Agent System (OCMAS) - an Electronic Institution (EI). The contribution of this paper is to include task-oriented conversational staff bots (i. e. the embodiment of staff agents in the 3D environment) that communicate with users by using natural language. With this aim, we extend the Artificial Intelligence Mark-up Language (AIML) with special tags to enable complex task-oriented conversations whose flow needs to consider both the states of the conversation and the ontology related to the task. We evaluate the usability of our conversational proposal and compare it to a previous command-based interaction system. Results show the conversational approach presents a higher user satisfaction than the command-based one. Moreover, in average, it also performs better in terms of efficiency, effectiveness and errors.
C1 [Almajano, P.] Univ Barcelona, CSIC, IIIA, E-08007 Barcelona, Spain.
   [Sanchez, M. L.; Rodriguez, I.; Mayas, E.] Univ Barcelona, E-08007 Barcelona, Spain.
RP Almajano, P (corresponding author), Univ Barcelona, CSIC, IIIA, E-08007 Barcelona, Spain.
EM palmajano@iiia.csic.es
RI Rodriguez, Inmaculada/H-9298-2015
OI Rodriguez, Inmaculada/0000-0001-5931-7713
CR Almajano P, 2013, GRAPP 13 BARC SPAIN, P288
   Bowman DA, 2002, PRESENCE-TELEOP VIRT, V11, P404, DOI 10.1162/105474602760204309
   Esteva Marc, 2004, AAMAS 04, P236
   Ferber J, 2004, LECT NOTES COMPUT SC, V2935, P214
   GALVAO AM, 2004, PERSONA AIML ARCHITE, P1266
   Graesser AC, 2005, IEEE T EDUC, V48, P612, DOI 10.1109/TE.2005.856149
   Kluwer T, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3535
   Mikic FA, 2009, 2009 EAEEIE ANNUAL CONFERENCE, P177
   Mori K., 2003, IUI 03. 2003 International Conference on Intelligent User Interfaces, P270
   Searle J.R., 1969, SPEECH ACTS ESSAY PH, V626
   Trescak T, 2013, ENG APPL ARTIF INTEL, V26, P51, DOI 10.1016/j.engappai.2012.09.016
   Wallace RS, 2009, PARSING TURING TEST, P181, DOI DOI 10.1007/978-1-4020-6710-5_13
   Wang FY, 2002, IEEE INTELL SYST, V17, P72, DOI 10.1109/MIS.2002.1134364
NR 13
TC 4
Z9 4
U1 0
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1548-0992
J9 IEEE LAT AM T
JI IEEE Latin Am. Trans.
PD FEB
PY 2015
VL 13
IS 2
SI SI
BP 523
EP 531
DI 10.1109/TLA.2015.7055574
PG 9
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA CD9HK
UT WOS:000351408700023
OA Green Accepted
DA 2022-08-02
ER

PT J
AU Yalcin, ON
   DiPaola, S
AF Yalcin, Ozge Nilay
   DiPaola, Steve
TI A computational model of empathy for interactive agents
SO BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES
LA English
DT Article
DE Empathy; Affective computing; Conversational agents
ID EMOTION
AB Empathy has been defined in the scientific literature as the capacity to relate another's emotional state and assigned to a broad spectrum of cognitive and behavioral abilities. Advances in neuroscience, psychology and ethology made it possible to refine the defined functions of empathy to reach a working definition and a model of empathy. Recently, cognitive science and artificial intelligence communities made attempts to model empathy in artificial agents, which can provide means to test these models and hypotheses. A computational model of empathy not only would help to advance the technological artifacts to be more socially compatible, but also understand the empathy mechanisms, test theories, and address the ethics and morality problems the Artificial Intelligence (AI) community is facing today. In this paper, we will review the empathy research from various fields, gather the requirements for empathic capacity and construct a model of empathy that is suitable for interactive conversational agents.
C1 [Yalcin, Ozge Nilay; DiPaola, Steve] Simon Fraser Univ, 250-13450 102 Ave, Surrey, BC, Canada.
RP Yalcin, ON (corresponding author), Simon Fraser Univ, 250-13450 102 Ave, Surrey, BC, Canada.
EM oyalcin@sfu.ca; sdipaola@sfu.ca
OI Yalcin, Ozge Nilay/0000-0002-8898-0466
CR [Anonymous], 1988, COGNITIVE STRUCTURE, DOI DOI 10.1017/CBO9780511571299
   Arnold  M., 1960, EMOTION PERSONALITY
   Bar-On R., 2004, SOCIAL NEUROSCIENCE, V223
   BATES J, 1994, COMMUN ACM, V37, P122, DOI 10.1145/176789.176803
   Batson CD, 2009, SOCIAL NEUROSCIENCE OF EMPATHY, P3
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Boukricha H, 2013, INT CONF AFFECT, P1, DOI 10.1109/ACII.2013.7
   BOWER GH, 1981, AM PSYCHOL, V36, P129, DOI 10.1037/0003-066X.36.2.129
   Brave S, 2005, INT J HUM-COMPUT ST, V62, P161, DOI 10.1016/j.ijhcs.2004.11.002
   Burleson W., 2004, WORKSH SOC EM INT LE
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Cassell J, 2000, EMBODIED CONVERSATIONAL AGENTS, P29
   Clavel C., 2013, WORKSH AFF SOC SIGN
   Clavel C, 2016, IEEE T AFFECT COMPUT, V7, P74, DOI 10.1109/TAFFC.2015.2444846
   Coplan Amy, 2011, EMPATHY PHILOS PSYCH
   Costa P. T., 1992, REVISED NEO PERSONAL
   D'mello S., 2013, ACM T INTERACT INTEL, V2, P1
   Damasio A., 2006, DESCARTES ERROR
   Davis M.H., 1994, EMPATHY SOCIAL PSYCH
   de Vignemont F, 2006, TRENDS COGN SCI, V10, P435, DOI 10.1016/j.tics.2006.08.008
   de Waal FBM, 2007, ADV CONSC RES, V68, P49
   de Waal FBM, 2017, NAT REV NEUROSCI, V18, P498, DOI 10.1038/nrn.2017.72
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Ekman P., 2004, LANGUAGE KNOWLEDGE R, P39, DOI DOI 10.1007/978-1-4020-2783-3_3
   El-Nasr MS, 2000, AUTON AGENT MULTI-AG, V3, P219, DOI 10.1023/A:1010030809960
   Gateman D., 2006, EMOTIONAL INTELLIGEN
   Goldman A. I., 2012, OXFORD HDB, V1, DOI [10.1093/oxfordhb/9780195309799.001, DOI 10.1093/OXFORDHB/9780195309799.001]
   Gratch J., 2004, COGN SYST RES, V5, P269
   Hoffman M. L., 2001, EMPATHY MORAL DEV IM
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Jaques PA, 2007, COMPUT EDUC, V49, P360, DOI 10.1016/j.compedu.2005.09.002
   Jokinen K., 2009, CONSTRUCTIVE DIALOGU
   Jokinen K., 2009, SYNTH LECT HUMAN LAN, V2, P1
   Jokinen Kristiina, 2003, P WORKSH ONT MULT US, P730
   Lazarus, 1991, EMOTION ADAPTATION
   Leiberg S, 2006, PROG BRAIN RES, V156, P419, DOI 10.1016/S0079-6123(06)56023-6
   Leite I, 2014, INT J SOC ROBOT, V6, P329, DOI 10.1007/s12369-014-0227-1
   Lester, 2008, P 7 INT JOINT C AUT, V1, P167
   Li J., 2016, ARXIV160306155
   Looije R, 2010, INT J HUM-COMPUT ST, V68, P386, DOI 10.1016/j.ijhcs.2009.08.007
   Mairesse F, 2010, USER MODEL USER-ADAP, V20, P227, DOI 10.1007/s11257-010-9076-2
   Marsella SC, 2009, COGN SYST RES, V10, P70, DOI 10.1016/j.cogsys.2008.03.005
   Mikolov T., 2013, ARXIV, V1301, P3781
   MINSKY M, 1991, ARTIF INTELL, V48, P371, DOI 10.1016/0004-3702(91)90036-J
   Moridis CN, 2012, IEEE T AFFECT COMPUT, V3, P260, DOI 10.1109/T-AFFC.2012.6
   OMDAHL BL, 1995, COGNITIVE APPRAISAL
   Osgood C. E., 1975, CROSS CULTURAL UNIVE, V1
   Paiva A, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2912150
   PANTIC M, 2005, P 13 ANN ACM INT C M, P669
   Pecune F., 2013, EUMAS 2013
   Pentland A, 2005, COMPUTER, V38, P33, DOI 10.1109/MC.2005.104
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Picard R. W., 2014, OXFORD HDB AFFECTIVE, V11
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169
   Prendinger H, 2005, APPL ARTIF INTELL, V19, P267, DOI 10.1080/08839510590910174
   Preston SD, 2002, BEHAV BRAIN SCI, V25, P1, DOI 10.1017/S0140525X02000018
   Rishe N, 2013, ACM TMIS, V4, P1, DOI [10.1145/2544103, DOI 10.1145/2544103]
   Salovey P., 1990, IMAGIN COGN PERSONAL, V9, P185, DOI [10.2190/DUGG-P24E-52WK-6CDG, DOI 10.2190/DUGG-P24E-52WK-6CDG]
   Scherer K. R., 2010, BLUEPRINT AFFECTIVE, V1, P1
   SCHERER KR, 1982, SOC SCI INFORM, V21, P555, DOI 10.1177/053901882021004004
   Scherer KR., 2010, BLUEPRINT AFFECTIVE, P3
   Smith, 2011, EMPATHY PHILOS PSYCH
   Traum D. R., 1993, AAAI SPRING S REAS M, P143
   Traum D, 2017, ROUT HANDB LINGUIST, P143
   Vinciarelli A, 2012, IEEE T AFFECT COMPUT, V3, P69, DOI 10.1109/T-AFFC.2011.27
   WAHLSTER W, 1989, USER MODELS DIALOG S
   Wang P. Y., 2007, IEEE INTELLIGENT SYS, V22
   Wilks Y, 2011, COMPUT SPEECH LANG, V25, P128, DOI 10.1016/j.csl.2010.03.001
NR 70
TC 14
Z9 15
U1 8
U2 27
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 2212-683X
EI 2212-6848
J9 BIOL INSPIR COGN ARC
JI Biol. Inspired Cogn. Archit.
PD OCT
PY 2018
VL 26
BP 20
EP 25
DI 10.1016/j.bica.2018.07.010
PG 6
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Neurosciences & Neurology
GA HE6DP
UT WOS:000453493800002
DA 2022-08-02
ER

PT C
AU Brendel, AB
   Greve, M
   Diederich, S
   Buhrke, J
   Kolbe, LM
AF Brendel, Alfred Benedikt
   Greve, Maike
   Diederich, Stephan
   Buehrke, Johannes
   Kolbe, Lutz M.
GP Assoc Informat Syst
TI 'You are an Idiot!' - How Conversational Agent Communication Patterns
   Influence Frustration and Harassment
SO AMCIS 2020 PROCEEDINGS
LA English
DT Proceedings Paper
CT Conference of the Association-for-Information-Systems (AMCIS)
CY AUG 10-14, 2020
CL ELECTR NETWORK
SP Assoc Informat Syst
DE Conversational agents; harassment; communication pattern
AB Conversational Agents (CA) in the form of digital assistants on smartphones, chatbots on social media, or physical embodied systems are an increasingly often applied new form of user interfaces for digital systems. The human-like design of CAs (e.g., having names, greeting users, and using self-references) leads to users subconsciously reacting to them as they were interacting with a human. In recent research, it has been shown that this social component of interacting with a CA leads to various benefits, such as increased service satisfaction, enjoyment, and trust. However, numerous CAs were discontinued because of inadequate responses to user requests or only making errors because of the limited functionalities and knowledge of a CA, which can lead to frustration. Therefore, investigating the causes of frustration and other related emotions and reactions highly relevant. Against this background, this study investigates via an online experiment with 169 participants how different communication patterns influence user's perception, frustration, and harassment behavior of an error producing CA.
C1 [Brendel, Alfred Benedikt; Greve, Maike; Diederich, Stephan; Buehrke, Johannes; Kolbe, Lutz M.] Univ Goettingen, Gottingen, Germany.
RP Brendel, AB (corresponding author), Univ Goettingen, Gottingen, Germany.
EM abrende1@uni-goettingen.de; maike.greve@uni-goettingen.de;
   stephan.diederich@stud.uni-goettingen.de;
   johannes.buehrke@stud.uni-goettingen.de; lkolbe@uni-goettingen.de
CR Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Bartneck C, 2007, 2007 RO-MAN: 16TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1-3, P367
   Ben Mimoun MS, 2012, J RETAIL CONSUM SERV, V19, P605, DOI 10.1016/j.jretconser.2012.07.006
   Berkowitz L., 1989, PSYCHOL BULL, DOI [10.1037/0033-2909.106.1.59, DOI 10.1037/0033-2909.106.1.59)]
   Brahnam S, 2008, INTERACT COMPUT, V20, P287, DOI 10.1016/j.intcom.2008.02.001
   Brandtzaeg PB., 2018, INTERACTIONS, V25, P38, DOI 10.1145/3236669
   Caruana A, 2000, J BUS RES, V49, P57, DOI 10.1016/S0148-2963(98)00119-2
   Dennis A., 2001, COMMUNICATIONS, V7, P1
   Diederich S., 2020, BUSINESS INFORM SYST
   Diederich S., 2019, P INT C INF SYST ICI
   Diederich S., 2019, INT C WIRTSCH, P1
   DiStefano C., 2009, PRACTICAL ASSESSMENT, V14, DOI [10.7275/da8t-4g52, DOI 10.7275/DA8T-4G52]
   Folstad A., 2017, INTERACTIONS, V24, P38, DOI [10.1145/3085558, DOI 10.1145/3085558]
   Fox S., 1999, J ORGAN BEHAV, V20, DOI [10.1002/(sici)1099-1379(199911)20:6<915::aid-job918>3.3.co;2-y, DOI 10.1002/(SICI)1099-1379(199911)20:6<915::AID-JOB918>3.3.CO;2-Y).]
   Gnewuch U, 2018, 26 EUR C INF SYST EC
   Groom V, 2009, INT J HUM-COMPUT ST, V67, P842, DOI 10.1016/j.ijhcs.2009.07.001
   Holtgraves T, 2007, BEHAV RES METHODS, V39, P156, DOI 10.3758/BF03192855
   Jenkins M. C., 2007, LECT NOTES COMPUTER, V4552 LNCS, DOI [10.1007/978-3- 540-73110-8_9, DOI 10.1007/978-3-540-73110-8_9)]
   Karpman S., 1968, T ANAL B, V7, P39
   Kolbe L. M., 2019, P 27 EUR C INF SYST
   Lariviere B, 2017, J BUS RES, V79, P238, DOI 10.1016/j.jbusres.2017.03.008
   MacDorman KF, 2009, COMPUT HUM BEHAV, V25, P695, DOI 10.1016/j.chb.2008.12.026
   Marinova D, 2017, J SERV RES-US, V20, P29, DOI 10.1177/1094670516679273
   McKimm J., 2010, POSTGRAD MED J, DOI [10.1136/pgmj.2009.093310, DOI 10.1136/PGMJ.2009.093310)]
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Seeger J, 2018, 2018 GLOBAL INTERNET OF THINGS SUMMIT (GIOTS), P1
   Urbach N., 2010, J INF TECHNOL THEORY, V11, P5, DOI DOI 10.1037/0021-9010.90.4.710
   Verhagen T, 2014, J COMPUT-MEDIAT COMM, V19, P529, DOI 10.1111/jcc4.12066
NR 28
TC 0
Z9 0
U1 0
U2 2
PU ASSOC INFORMATION SYSTEMS
PI ATLANTA
PA P.O. BOX 2712, ATLANTA, GA 30301-2712 USA
BN 978-1-7336325-4-6
PY 2020
PG 10
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP6LR
UT WOS:000559924504007
DA 2022-08-02
ER

PT J
AU Bickmore, TW
AF Bickmore, Timothy W.
TI AUTOMATED SUPPORT FOR CANCER CLINICAL TRIALS USING CONVERSATIONAL AGENTS
SO ANNALS OF BEHAVIORAL MEDICINE
LA English
DT Meeting Abstract
EM bickmore@ccs.neu.edu
NR 0
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0883-6612
EI 1532-4796
J9 ANN BEHAV MED
JI Ann. Behav. Med.
PD APR
PY 2015
VL 49
SU 1
MA 16A
BP S64
EP S64
PG 1
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA DA5EH
UT WOS:000367825001250
DA 2022-08-02
ER

PT J
AU Rossen, B
   Lok, B
AF Rossen, Brent
   Lok, Benjamin
TI A crowdsourcing method to develop virtual human conversational agents
SO INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES
LA English
DT Article
DE Virtual humans; Agents and intelligent systems; Human-centered
   computing; Distributed knowledge acquisition; End-user programming
ID SIMULATED PATIENT; MODELS
AB Educators in medicine, psychology, and the military want to provide their students with interpersonal skills practice. Virtual humans offer structured learning of interview skills, can facilitate learning about unusual conditions, and are always available. However, the creation of virtual humans with the ability to understand and respond to natural language requires costly engineering by conversation knowledge engineers (generally computer scientists), and incurs logistical cost for acquiring domain knowledge from domain experts (educators). We address these problems using a novel crowdsourcing method entitled Human-centered Distributed Conversational Modeling. This method facilitates collaborative development of virtual humans by two groups of end-users: domain experts (educators) and domain novices (students). We implemented this method in a web-based authoring tool called Virtual People Factory. Using Virtual People Factory, medical and pharmacy educators are now creating natural language virtual patient interactions on their own. This article presents the theoretical background for Human-centered Distributed Conversational Modeling, the implementation of the Virtual People Factory authoring tool, and five case studies showing that Human-centered Distributed Conversational Modeling has addressed the logistical cost for acquiring knowledge. Published by Elsevier Ltd.
C1 [Rossen, Brent; Lok, Benjamin] Univ Florida, Gainesville, FL 32611 USA.
RP Rossen, B (corresponding author), Univ Florida, Gainesville, FL 32611 USA.
EM brossen@cise.ufl.edu; lok@cise.ufl.edu
RI Lok, Benjamin/AAW-6501-2021
FU University of Florida; National Science Foundation
FX Special thanks go to Dr. Carole Kimberlin and Dr. Diane Beck for their
   participation in the pharmacy study, and to Dr. Scott Lind, Dr. Adriana
   Foster, and Dr. Hevil Shah for their work on VH patients and their
   invaluable feedback on VPF. We also thank Dr. Aaron Kotranza, Dr. Regis
   Kopper, Dr. Andrew Raij, Dr. Kyle Johnsen, Joon Chauh, and Shiva Halan
   for their advice and assistance during VPF's development and the writing
   of this paper. This work was made possible by a University of Florida
   Alumni Fellowship and National Science Foundation Grants.
CR AAMODT A, 1994, AI COMMUN, V7, P39
   [Anonymous], 2003, KUNSTLICHE INTELLIGE, DOI DOI 10.1002/J.2162-6057.20041B01234.X
   Bearman M, 2001, MED EDUC, V35, P824, DOI 10.1046/j.1365-2923.2001.00999.x
   Benedict N., 2010, AM J PHARM EDUC, V74, P8
   Bergin RA, 2003, COMPUT EDUC, V40, P361, DOI 10.1016/S0360-1315(02)00167-7
   Cassell J, 2001, AI MAG, V22, P67
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Deladisma A., 2007, ASS SURG ED 2007 SUR
   Dickerson R., 2005, P INT C HUM COMP INT, P79
   Fall LH, 2005, ACAD MED, V80, P847, DOI 10.1097/00001888-200509000-00012
   Foster, 2010, EVALUATION MED STUDE
   Glass J, 2005, COMPUTER-AIDED DESIGN OF USER INTERFACES IV, P349, DOI 10.1007/1-4020-3304-4_28
   Huang G, 2007, ACAD MED, V82, P446, DOI 10.1097/ACM.0b013e31803e8a0a
   Hubal R C, 2000, Stud Health Technol Inform, V70, P133
   Jackson J., 2010, USF HLTH VIRTUAL STA
   Jacobelli F., 2007, ETHNIC IDENTITY ENGA
   Johnsen K., 2008, DESIGN VALIDATION VI, P146
   Johnsen K., 2007, VALIDITY VIRTUAL HUM
   Kenny P, 2007, BUILDING INTERACTIVE, V2007
   Kenny P., 2008, EV JUST VIRT PAT PTS
   LEUSKI A, 2006, P 7 SIGDIAL WORKSH D
   Lidwell W, 2003, UNIVERSAL PRINCIPLES
   Nantha Surkunalingam J.W., 2009, AM OST ASS NAT C
   Naveed Saleh M.D., 2010, ANN BEHAV SCI MED ED, V16, P29, DOI [10.1007/BF03355129, DOI 10.1007/BF03355129]
   Parsons TD, 2008, STUD HEALTH TECHNOL, V132, P357
   Raij AB, 2007, IEEE T VIS COMPUT GR, V13, P443, DOI 10.1109/TVCG.2007.1036
   Reiter E, 2003, J ARTIF INTELL RES, V18, P491, DOI 10.1613/jair.1176
   Rossen B., 2010, MYSQL AJAX DATABASE
   Ruttkay Z., 2004, EVALUATING EMBODIED
   Shah H., 2009, NAT C FAM MED RES ME
   Shah H., 2012, ACAD PSYCHI IN PRESS
   Shortliffe E.H., 1976, COMPUTER BASED MED C
   Singh P, 2002, LECT NOTES COMPUT SC, V2519, P1223
   Slater M, 1999, IEEE COMPUT GRAPH, V19, P6, DOI 10.1109/38.749116
   Traum D, 2008, LECT NOTES ARTIF INT, V4930, P296
   Triola M.M., 2007, AMIA ANN S AM MED IN
   Ullrich S, 2008, LECT NOTES COMPUT SC, V5208, P281
   Villaume WA, 2006, AM J PHARM EDUC, V70, DOI 10.5688/aj700233
   von Ahn L, 2004, P SIGCHI C HUM FACT, DOI DOI 10.1145/985692.985733
   WESTBERG J, 2001, FOSTERING REFLECTION
   Yedidia MJ, 2003, JAMA-J AM MED ASSOC, V290, P1157, DOI 10.1001/jama.290.9.1157
   Zanbaka C, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1561
NR 42
TC 30
Z9 31
U1 1
U2 36
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 1071-5819
EI 1095-9300
J9 INT J HUM-COMPUT ST
JI Int. J. Hum.-Comput. Stud.
PD APR
PY 2012
VL 70
IS 4
BP 301
EP 319
DI 10.1016/j.ijhcs.2011.11.004
PG 19
WC Computer Science, Cybernetics; Ergonomics; Psychology, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Psychology
GA 905YW
UT WOS:000301313100004
DA 2022-08-02
ER

PT C
AU Chaves, AP
   Gerosa, MA
AF Chaves, Ana Paula
   Gerosa, Marco Aurelio
GP ACM
TI Single or Multiple Conversational Agents? An Interactional Coherence
   Comparison
SO PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING
   SYSTEMS (CHI 2018)
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 21-26, 2018
CL Montreal, CANADA
SP Assoc Comp Machinery, ACM SIGCHI
DE Chatbot; Dialog agent; human-agent communication
ID ATTENTION; STATE
AB Chatbots focusing on a narrow domain of expertise are in great rise. As several tasks require multiple expertise, a designer may integrate multiple chatbots in the background or include them as interlocutors in a conversation. We investigated both scenarios by means of a Wizard of Oz experiment, in which participants talked to chatbots about visiting a destination. We analyzed the conversation content, users' speech, and reported impressions. We found no significant difference between single- and multi-chatbots scenarios. However, even with equivalent conversation structures, users reported more confusion in multi-chatbots interactions and adopted strategies to organize turn-taking. Our findings indicate that implementing a meta-chatbot may not be necessary, since similar conversation structures occur when interacting to multiple chatbots, but different interactional aspects must be considered for each scenario.
C1 [Chaves, Ana Paula] UTFPR CM, Campo Mourao, Brazil.
   [Chaves, Ana Paula; Gerosa, Marco Aurelio] No Arizona Univ, Flagstaff, AZ 86011 USA.
RP Chaves, AP (corresponding author), UTFPR CM, Campo Mourao, Brazil.; Chaves, AP (corresponding author), No Arizona Univ, Flagstaff, AZ 86011 USA.
EM acs549@nau.edu; Marco.Gerosa@nau.edu
RI Chaves, Ana Paula/AAJ-5650-2021
OI Chaves, Ana Paula/0000-0002-2307-3099; Gerosa, Marco/0000-0003-1399-7535
CR Aboluwarin Pelumi, 2016, CHATBOTS IGNITING DI
   Abu Shawar BA and Atwell ES, 2007, J LANG TECHNOL COMPU, V22, P29
   Anderson JF, 2010, LANGUAGE INTERNET, V7, P7
   [Anonymous], 2014, 2014 TRAVELERS ROAD
   Berglund T.O., 2009, LANGUAGE INTERNET, V6
   Bhatia Parminder, 2017, ARXIV170205512
   Candello Heloisa, 2017, Design, User Experience and Usability: Understanding Users and Contexts. 6th International Conference, DUXU 2017, held as part of HCI International 2017. Proceedings: LNCS 10290, P594, DOI 10.1007/978-3-319-58640-3_43
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   DAHLBACK N, 1993, KNOWL-BASED SYST, V6, P258, DOI 10.1016/0950-7051(93)90017-N
   Dale R, 2016, NAT LANG ENG, V22, P811, DOI 10.1017/S1351324916000243
   Daniel Nations, 2017, WHAT IS SIR CAN I US
   de Bayser Maira Gatti, 2017, ABS170501214 CORR
   Degbelo A, 2016, ISPRS INT J GEO-INF, V5, DOI 10.3390/ijgi5020016
   Driver J, 2001, BRIT J PSYCHOL, V92, P53, DOI 10.1348/000712601162103
   Fogg B, 2002, PERSUASIVE TECHNOLOG, DOI [10.1145/764008.763957, DOI 10.1145/764008.763957]
   Folstad A., 2017, INTERACTIONS, V24, P38, DOI [10.1145/3085558, DOI 10.1145/3085558]
   Fu TJ, 2008, J AM SOC INF SCI TEC, V59, P1195, DOI 10.1002/asi.20827
   Garrido P, 2017, COMPUT SCI INF SYST, V14, P1, DOI 10.2298/CSIS150410029G
   Gibson W, 2009, BRIT EDUC RES J, V35, P705, DOI 10.1080/01411920802688754
   Goertzel Ben, 2014, Journal of Artificial General Intelligence, V5, P1, DOI 10.2478/jagi-2014-0001
   Griol D, 2017, NEUROCOMPUTING
   Griol D, 2014, APPL INTELL, V40, P749, DOI 10.1007/s10489-013-0503-z
   Gustas Nicole, 2016, CHATBOTS NEXT BIG TH
   Hajdinjak M, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P112
   Heritage J., 1984, NEW BLACKWELL COMPAN, DOI [10.1002/9781444304992.ch15, DOI 10.1002/9781444304992.CH15]
   Herring Susan, 1999, J COMPUTER MEDIATED, V4
   Herring Susan C, 2006, P CHI 06
   Herring Susan C., 2003, NEW RES NEW MED INN, P47, DOI DOI 10.1002/BIP.10218
   Hill J, 2015, COMPUT HUM BEHAV, V49, P245, DOI 10.1016/j.chb.2015.02.026
   Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685
   Holmer T., 2008, LANGUAGE INTERNET, V5, P1
   Jennings RB, 2006, IEEE NETWORK, V20, P16, DOI 10.1109/MNET.2006.1668399
   Joshi A., 2015, WISDOM WORKSH KDD
   Kohrs C, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146250
   KUHMANN W, 1987, ERGONOMICS, V30, P933, DOI 10.1080/00140138708969789
   Lang T. C., 2000, Journal of Vacation Marketing, V6, P368, DOI 10.1177/135676670000600407
   Lee MK, 2010, 2010 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P31
   Linden Greg, 1997, P UM 97, P67
   Macias-Galindo Daniel, 2012, P 13 ANN C INT SPEEC
   Markopoulos P, 2009, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-1-84882-477-5
   Martin D., 2003, P 2003 INTR ACM SIGG, P40, DOI [10.1145/958160.958167, DOI 10.1145/958160.958167]
   Maturi Hareesh, 2016, METACHATBOT ENABLING
   Microsoft Research, 2014, ANT MOR CORT
   Mou Y, 2017, COMPUT HUM BEHAV, V72, P432, DOI 10.1016/j.chb.2017.02.067
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Noor AK, 2015, OPEN ENG, V5, P75, DOI 10.1515/eng-2015-0008
   Park JY, 2013, TOURISM MANAGE, V35, P1, DOI 10.1016/j.tourman.2012.05.004
   Pawlowska Aneta, 2016, WORLD SCI NEWS, V57, P106
   Porcheron Martin, 2017, ACM CSCW 17
   Raij AB, 2007, IEEE T VIS COMPUT GR, V13, P443, DOI 10.1109/TVCG.2007.1036
   Reeves Stuart, 2017, CONV AG COLL ACT WOR
   Sacks Harvey, 1995, LECT CONVERSATION
   Sacks Harvey, 1995, LECT CONVERSATION
   Sammut Claude, 2001, LINKOPING ELECT ARTI, V3, P7
   Schegloff Emanuel., 1990, CONVERSATIONAL ORG I, P51
   Scholl BJ, 2001, COGNITION, V80, P1, DOI 10.1016/S0010-0277(00)00152-9
   Shechtman N., 2003, P SIGCHI C HUM FACT, P281, DOI [DOI 10.1145/642611.642661, 10.1145/642611.642661]
   Sheffield Jenna, 2016, ULTIMATE TRAVEL BOT
   Sidnell J., 2011, CONVERSATION ANAL IN
   Stasko J, 2003, P INTERACT, P383, DOI 10.1.1.8.7309
   Statt Nick, 2016, WHY GOOGLES FANCY NE
   Szameitat AJ, 2009, INT J HUM-COMPUT ST, V67, P561, DOI 10.1016/j.ijhcs.2009.02.004
   Thies IM, 2017, LECT NOTES COMPUT SC, V10513, P441, DOI 10.1007/978-3-319-67744-6_28
   Traum D., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P766
   Trovato G, 2013, INT J HUM ROBOT, V10, DOI 10.1142/S0219843613500138
   Uthus DC, 2013, ARTIF INTELL, V199, P106, DOI 10.1016/j.artint.2013.02.004
   Vinciarelli A, 2015, COGN COMPUT, V7, P397, DOI 10.1007/s12559-015-9326-z
   Woodburn R., 1991, People and Computers VI. Proceedings of the HCI '91 Conference, P359
   Yu Zhou, 2016, P RE WOCHAT WORKSH L
NR 70
TC 23
Z9 23
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5620-6
PY 2018
DI 10.1145/3173574.3173765
PG 13
WC Computer Science, Cybernetics; Computer Science, Information Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BO2ZO
UT WOS:000509673102035
DA 2022-08-02
ER

PT J
AU Bickmore, TW
   Schulman, D
   Sidner, C
AF Bickmore, Timothy W.
   Schulman, Daniel
   Sidner, Candace
TI Automated interventions for multiple health behaviors using
   conversational agents
SO PATIENT EDUCATION AND COUNSELING
LA English
DT Article
DE Relational agent; Embodied conversational agent; Behavioral informatics;
   Dialog system; Health behavior change intervention; Physical activity
   promotion; Walking promotion; Diet promotion; Fruit and vegetable
   consumption promotion; Ontology
ID PHYSICAL-ACTIVITY QUESTIONNAIRE; CORONARY-HEART-DISEASE;
   CARDIOVASCULAR-DISEASE; EXERCISE BEHAVIOR; FRUIT; RISK; MEN;
   PERSPECTIVE; VEGETABLES; MORTALITY
AB Objective: An automated health counselor agent was designed to promote both physical activity and fruit and vegetable consumption through a series of simulated conversations with users on their home computers.
   Methods: The agent was evaluated in a 4-arm randomized trial of a two-month daily contact intervention comparing: (a) physical activity; (b) fruit and vegetable consumption; (c) both interventions; and (d) a non-intervention control. Physical activity was assessed using daily pedometer steps. Daily servings of fruit and vegetables were assessed using the NIH/NCI self-report Fruit and Vegetable Scan.
   Results: Participants in the physical activity intervention increased their walking on average compared to the control group, while those in the fruit and vegetable intervention and combined intervention decreased walking. Participants in the fruit and vegetable intervention group consumed significantly more servings per day compared to those in the control group, and those in the combined intervention reported consuming more compared to those in the control group.
   Conclusion: Automated health intervention software designed for efficient re-use is effective at changing health behavior.
   Practice implications: Automated health behavior change interventions can be designed to facilitate translation and adaptation across multiple behaviors. (C) 2013 Elsevier Ireland Ltd. All rights reserved.
C1 [Bickmore, Timothy W.; Schulman, Daniel] Northeastern Univ, Coll Comp & Informat Sci, Boston, MA 02115 USA.
   [Sidner, Candace] Worcester Polytech Inst, Dept Comp Sci, Worcester, MA 01609 USA.
RP Bickmore, TW (corresponding author), Northeastern Univ, Coll Comp & Informat Sci, 360 Huntington Ave,WVH202, Boston, MA 02115 USA.
EM bickmore@ccs.neu.edu
OI Schulman, Daniel/0000-0002-2287-7888
FU NIH National Library of Medicine [R21LM008995]; NATIONAL LIBRARY OF
   MEDICINE [R21LM008995] Funding Source: NIH RePORTER
FX This work was supported by a grant from the NIH National Library of
   Medicine (R21LM008995). The sponsors had no involvement in the study
   design, collection, analysis and interpretation of data, in the writing
   of the report, or in the decision to submit the paper for publication.
CR [Anonymous], 2015, INTRO QUALITATIVE RE
   [Anonymous], 2005, DIET GUID AM 2005
   Bandura A, 2001, ANNU REV PSYCHOL, V52, P1, DOI 10.1146/annurev.psych.52.1.1
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T, 2010, APPL ARTIF INTELL, V24, P648, DOI 10.1080/08839514.2010.492259
   Bickmore TW, 2011, J BIOMED INFORM, V44, P183, DOI 10.1016/j.jbi.2010.12.006
   Bouchard C, 1994, PHYS ACTIVITY HLTH I
   Chisholm D., 1975, BRIT COLUMBIA MED J, V17, P375
   Craig CL, 2003, MED SCI SPORT EXER, V35, P1381, DOI 10.1249/01.MSS.0000078924.61453.FB
   Gaziano J. Michael, 1995, Annals of Epidemiology, V5, P255, DOI 10.1016/1047-2797(94)00090-G
   GILLMAN MW, 1995, JAMA-J AM MED ASSOC, V273, P1113, DOI 10.1001/jama.273.14.1113
   Grosz B. J., 1986, Computational Linguistics, V12, P175
   Hagstromer M, 2006, PUBLIC HEALTH NUTR, V9, P755, DOI 10.1079/PHN2005898
   Joshipura KJ, 1999, JAMA-J AM MED ASSOC, V282, P1233, DOI 10.1001/jama.282.13.1233
   Key TJA, 1996, BMJ-BRIT MED J, V313, P775, DOI 10.1136/bmj.313.7060.775
   KNEKT P, 1994, AM J EPIDEMIOL, V139, P1180, DOI 10.1093/oxfordjournals.aje.a116964
   Krauss RM, 2000, STROKE, V31, P2751, DOI 10.1161/01.STR.31.11.2751
   LAPORTE RE, 1984, AM J EPIDEMIOL, V120, P507, DOI 10.1093/oxfordjournals.aje.a113911
   Li RW, 2000, AM J PUBLIC HEALTH, V90, P777, DOI 10.2105/AJPH.90.5.777
   MARCUS BH, 1992, RES Q EXERCISE SPORT, V63, P60, DOI 10.1080/02701367.1992.10607557
   MARCUS BH, 1994, MED SCI SPORT EXER, V26, P1400
   MCGINNIS JM, 1993, JAMA-J AM MED ASSOC, V270, P2207, DOI 10.1001/jama.270.18.2207
   Miller R., 2013, MOTIVATIONAL INTERVI, V3
   Ness AR, 1997, INT J EPIDEMIOL, V26, P1, DOI 10.1093/ije/26.1.1
   PATE RR, 1995, JAMA-J AM MED ASSOC, V273, P402, DOI 10.1001/jama.273.5.402
   Rimm EB, 1996, JAMA-J AM MED ASSOC, V275, P447, DOI 10.1001/jama.275.6.447
   Rosenfeld S, 2000, P 4 INT C DIET ASS M
   Shaw G, 2009, P INT VIRT AG C
   STEWART AL, 1993, GERONTOLOGIST, V33, P782, DOI 10.1093/geront/33.6.782
   *US DEP HHS, 1996, PHYS ACT HLTH REP SU
   US Department of Health and Human Services, 1998, SURG GEN REP NUTR HL
   Vinson C, 2011, TRANSL BEHAV MED, V1, P93, DOI 10.1007/s13142-010-0008-9
   YOUNG DR, 1993, AM J EPIDEMIOL, V138, P205, DOI 10.1093/oxfordjournals.aje.a116849
NR 33
TC 79
Z9 80
U1 2
U2 20
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0738-3991
J9 PATIENT EDUC COUNS
JI Patient Educ. Couns.
PD AUG
PY 2013
VL 92
IS 2
BP 142
EP 148
DI 10.1016/j.pec.2013.05.011
PG 7
WC Public, Environmental & Occupational Health; Social Sciences,
   Interdisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Public, Environmental & Occupational Health; Social Sciences - Other
   Topics
GA 210CE
UT WOS:000323806100002
PM 23763983
OA Green Accepted
DA 2022-08-02
ER

PT C
AU Baptista, G
   Rato, D
   Prada, R
AF Baptista, Goncalo
   Rato, Diogo
   Prada, Rui
BE Barbedo, I
   Barroso, B
   Legeren, B
   Roque, L
   Sousa, JP
TI Interviewing a Virtual Suspect: Conversational Game Characters Using
   Alexa
SO VIDEOGAME SCIENCES AND ARTS, VJ 2020
SE Communications in Computer and Information Science
LA English
DT Proceedings Paper
CT 12th International Conference on Videogame Sciences and Arts (VJ)
CY NOV 26-28, 2020
CL EsACT Mirandela, Polytechn Inst Braganca, ELECTR NETWORK
SP EsACT Mirandela, Polytechn Inst Braganca, Sch Publ Management, Commun & Tourism, Portuguese Soc Videogames Sci
HO EsACT Mirandela, Polytechn Inst Braganca
DE Conversational agents; Voice games; Interactive narrative
AB The video game industry is constantly innovating, with new mediums and ways for players to interact with the game environment. Voice interaction in games is an ever evolving field, especially with advances in Natural Language Processing. In that vein, there has been a increasing number of conversational agents with natural language interaction capabilities deployed into video games. In this paper, we improve the Virtual Suspect game with a natural language interaction using the tools provided by Amazon Alexa. We followed an iterative, user-centered approach when designing the new interaction, collecting feedback and data from three User Studies in order to improve the interaction with the Virtual Suspect. Our findings suggest that the usage of natural language to support the interaction with game characters can improve the player experience.
C1 [Baptista, Goncalo] Univ Lisbon, INESC ID, Lisbon, Portugal.
   Univ Lisbon, Inst Super Tecn, Lisbon, Portugal.
RP Baptista, G (corresponding author), Univ Lisbon, INESC ID, Lisbon, Portugal.
EM goncalo.baptista@tecnico.ulisboa.pt; diogo.rato@tecnico.ulisboa.pt;
   rui.prada@tecnico.ulisboa.pt
FU Fundaacao para a Ciencia e a Tecnologia (FCT) [UIDB/50021/2020]
FX This work was supported by national funds through Fundaacao para a
   Ciencia e a Tecnologia (FCT) with reference UIDB/50021/2020.
CR [Anonymous], 2015, USER EXPERIENCE QUES
   Bitan M, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P993
   Bruijnes M., 2014, AFFECTIVE AGENTS, P17
   Falk J, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P141, DOI 10.1145/3267851.3267892
   Hajdinjak M., 2004, Informatica, V28, P425
   Kenny I., 2005, P AISB 2005 S CONV I, P58
   Kiiski T., 2020, VOICE GAMES HIST VOI
   Mateas M, 2003, GAM DEV C, V2, P4
   Mccoy J., 2012, P INT C FDN DIG GAM, P235
   Morris Thomas William, 2002, ARTIF INTELL, P82
   Obsidian Entertainment, 2019, OUT WORLDS WIND PLAY
   Ocelot Society, 2016, EV PC DIG
   Ram A., 2018, ABS180103604 CORR
   Rato D., 2016, THESIS I SUPERIOR TE
   Rato D, 2017, AAMAS'17: PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P1711
   Samuel B, 2011, 7 ART INT INT DIG EN
   Schrepp M., 2018, MENSCH COMPUTER 2017, V17, P355
NR 17
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1865-0929
EI 1865-0937
BN 978-3-030-95305-8; 978-3-030-95304-1
J9 COMM COM INF SC
PY 2022
VL 1531
BP 98
EP 112
DI 10.1007/978-3-030-95305-8_8
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7CM
UT WOS:000758648400008
DA 2022-08-02
ER

PT J
AU Sucameli, I
AF Sucameli, Irene
TI Improving the level of trust in human-machine conversation
SO ADVANCED ROBOTICS
LA English
DT Article
DE Machine ethics; conversational agents; human&#8211; machine interaction;
   social AI
AB The aim of this paper is to contribute to the debate on ethics in AI focusing particularly on the social and ethical issues which emerge during human-conversational agent interaction. Those issues will be approached adopting both the perspective of the user and the one of the machine. In fact, it is often stressed the need to include the ethical component within system's design, which it is certainly necessary as will be discussed in the article. Nevertheless, conversational agents are tools, although they are capable of having a strong impact on the society; thus, the moral use of these social tools must be demanded to users as well. For this reason, it will be proposed a new set of ethical guidelines, called Mirror Ethics, based on the alignment of both parties involved in the conversation to a shared moral baseline. The adoption of these shared values will lead to the creation of a new ethical equilibrium between users and conversational agents, producing a social beneficial impact and increasing the level of trust within the human-machine interaction.
C1 [Sucameli, Irene] Univ Pisa, Dept Comp Sci, Pisa, Italy.
RP Sucameli, I (corresponding author), Univ Pisa, Dept Comp Sci, Pisa, Italy.
EM irene.sucameli@phd.unipi.it
NR 0
TC 1
Z9 1
U1 7
U2 12
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0169-1864
EI 1568-5535
J9 ADV ROBOTICS
JI Adv. Robot.
PD MAY 3
PY 2021
VL 35
IS 9
SI SI
BP 553
EP 560
DI 10.1080/01691864.2021.1884132
EA FEB 2021
PG 8
WC Robotics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Robotics
GA SD8HL
UT WOS:000618689100001
DA 2022-08-02
ER

PT C
AU Cassell, J
AF Cassell, Justine
BE Staphanidis, C
TI Social Practice: Becoming Enculturated in Human-Computer Interaction
SO UNIVERSAL ACCESS IN HUMAN-COMPUTER INTERACTION: APPLICATIONS AND
   SERVICES, PT III
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 5th International Conference on Universal Access in Human-Computer
   Interaction held at the HCI International 2009
CY JUL 19-24, 2009
CL San Diego, CA
DE Virtual Peers; Embodied Conversational Agents; Culture; Ethnicity
ID PERFORMANCE; DIALECT
AB We present a new approach to the design, development and evaluation of embodied conversational agents (ECAs) that allows them to index identity through Culturally and socially authentic verbal and non-verbal behaviors. This approach is illustrated with research we are carrying out with children who speak several dialects of American English, and the Subsequent implementation and first evaluation of a virtual peer based oil that research. Results Suggest that issues of identity in ECAs are more complicated than previous approaches might Suggest, and that ECAs themselves may play a role in understanding issues of identity and language use in ways that have promise for educational applications.
C1 Northwestern Univ, Ctr Technol & Social Behav, Evanston, IL 60208 USA.
RP Cassell, J (corresponding author), Northwestern Univ, Ctr Technol & Social Behav, Frances Searle 2-148,2240 Campus Dr, Evanston, IL 60208 USA.
EM justine@northwestern.edu
RI Cassell, Justine/B-7123-2009
CR Alvarez, 1995, SOCIOCULTURAL STUDIE
   Andersen E., 1990, SPEAKING STYLE SOCIO
   BAYLOR A, 2003, P ELEARN PHOEN AZ
   Cassell J, 2004, J APPL DEV PSYCHOL, V25, P75, DOI 10.1016/j.appdev.2003.11.003
   Cassell J, 2007, GENESIS REDUX ESSAYS, DOI 10.7208/chicago/9780226720838.003.0017
   Cassell J., 2000, EMBODIED CONVERSATIO
   Craig H. K., 2005, MALIK GOES SCH EXAMI
   Craig HK, 2004, LANG SPEECH HEAR SER, V35, P141, DOI 10.1044/0161-1461(2004/015)
   Cutler C., 2003, J LINGUIST ANTHROPOL, V13, P211, DOI [DOI 10.1525/JLIN.2003.13.2.211, 10.1525/jlin.2003.13.2.211]
   Green L.J., 2002, AFRICAN AM ENGLISH L
   Gutierrez K.D., 1999, MIND CULTURE ACTIVIT, V6, P286, DOI DOI 10.1080/10749039909524733
   HARTWELL P, 1980, RES TEACH ENGL, V14, P101
   Hofstede G., 1991, CULTURES ORG SOFTWAR
   Holland D., 1998, IDENTITY AGENCY CULT
   HUNT BC, 1974, READ RES QUART, V10, P103, DOI 10.2307/747087
   IRVINE JT, 1985, ANNU REV ANTHROPOL, V14, P557, DOI 10.1146/annurev.an.14.100185.003013
   Johnson K.R., 1976, INTERCULTURAL COMMUN, P259
   Lacobelli F, 2007, LECT NOTES ARTIF INT, V4722, P57
   Lee C.D., 2003, ED RES, V32, DOI [10.3102/0013189X032005006, DOI 10.3102/0013189X032005006]
   Maldonado H, 2004, AGENT CULTURE, P143
   Markus HR, 2008, AM PSYCHOL, V63, P651, DOI 10.1037/0003-066X.63.8.651
   MORENO KN, 2002, P 2002 AAAI FALL S E, P77
   Nass Clifford, 2005, WIRED SPEECH VOICE A
   Ogbu J, 2003, BLACK AM STUDENTS AF
   Rogoff B(., 2003, CULTURAL NATURE HUMA
   Ryokai K, 2003, J COMPUT ASSIST LEAR, V19, P195, DOI 10.1046/j.0266-4909.2003.00020.x
   SHWEDER RA, 1989, CULTURAL PSYCHOL CHI
   Wheeler R., 2006, CODE SWITCHING TEACH
NR 28
TC 15
Z9 15
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-02712-3
J9 LECT NOTES COMPUT SC
PY 2009
VL 5616
BP 303
EP 313
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BLN05
UT WOS:000270561000032
OA Bronze
DA 2022-08-02
ER

PT C
AU Modrzejewski, M
   Rokita, P
AF Modrzejewski, Mateusz
   Rokita, Przemyslaw
BE Chmielewski, LJ
   Kozera, R
   Orlowski, A
   Wojciechowski, K
   Bruckstein, AM
   Petkov, N
TI Graphical Interface Design for Chatbots for the Needs of Artificial
   Intelligence Support in Web and Mobile Applications
SO COMPUTER VISION AND GRAPHICS ( ICCVG 2018)
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT International Conference on Computer Vision and Graphics (ICCVG)
CY SEP 17-19, 2018
CL Warsaw, POLAND
SP Assoc Image Proc, Warsaw Univ Life Sci, Fac Appl Informat & Math, Polish Japanese Acad Informat Technol, W Pomeranian Univ Technol, Fac Comp Sci & Informat Technol, Springer, Lecture Notes Comp Sci
DE Conversational agents; Chatbots; Graphical interfaces AI; Graphics in
   business applications; Graphical design
AB The interest in the topic of conversational agents has been continuously rising for the past few years, as the technology itself has proved to have multiple practical applications. This paper discusses the design principles for graphical interfaces of conversational agents implemented for the needs of any branch of business that may benefit from the introduction of such solutions, including customer service, healthcare, sales and various types of services. Requirements are defined according to current trends in application design, including the use on mobile devices. The paper presents a survey on solutions fulfilling the mentioned requirements and discusses emerging issues. The paper also describes and proposes a reply scenario model suitable for the needs of implementing a flexible graphical interface for a modern chatbot-based system.
C1 [Modrzejewski, Mateusz; Rokita, Przemyslaw] Warsaw Univ Technol, Div Comp Graph, Inst Comp Sci, Fac Elect & Informat Technol, Nowowiejska 15-19, PL-00665 Warsaw, Poland.
RP Modrzejewski, M (corresponding author), Warsaw Univ Technol, Div Comp Graph, Inst Comp Sci, Fac Elect & Informat Technol, Nowowiejska 15-19, PL-00665 Warsaw, Poland.
EM M.Modrzejewski@ii.pw.edu.pl; P.Rokita@ii.pw.edu.pl
OI Rokita, Przemyslaw/0000-0002-4433-2133; Modrzejewski,
   Mateusz/0000-0002-6363-8584
CR Abashev A., PROGRAMMING TOOLS ME
   Abdul-Kader SA, 2015, INT J ADV COMPUT SC, V6, P72
   Amunwa J., LETS TALK TEXT CHATB
   [Anonymous], AIML language for Chatbots
   Ask J.A., 2016, STATE CHATBOTS
   Bradesko L., 2012, SURVEY CHATBOT SYSTE
   Candello H., DESIGNING USER EXPER
   Ghose S., IMPLEMENTATION TOPIC
   Honap S., DESIGNING SERVICE CH
   Kiat O.K., 2017, CHATBOTS MAGAZINE
   Kulawik A., MAKING CHATBOTS TALK
   Martin J., CHATBOTS MAGAZINE
   Meehan A., HELLO CHATBOT CAN WE
   Mohov S., TURNING CHATBOT NARR
   Radziwill N., EVALUATING QUALITY C
   Weissberg J., ONBOARDING SLACK
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wilcox B., WINNING LOEBNERS BRI
   Wilcox Bruce, 2011, FACADE PATTERN MATCH
   Wittgenstein L., 1961, TRACTATUS LOGICO PHI
NR 20
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-00692-1; 978-3-030-00691-4
J9 LECT NOTES COMPUT SC
PY 2018
VL 11114
BP 48
EP 56
DI 10.1007/978-3-030-00692-1_5
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Imaging Science &
   Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Imaging Science & Photographic Technology
GA BQ7CI
UT WOS:000614368800005
DA 2022-08-02
ER

PT C
AU Fadhil, A
   Schiavo, G
   Wang, YL
   Yilma, BA
AF Fadhil, Ahmed
   Schiavo, Gianluca
   Wang, Yunlong
   Yilma, Bereket A.
GP ACM
TI The Effect of Emojis when interacting with Conversational Interface
   Assisted Health Coaching System
SO PROCEEDINGS OF THE 12TH EAI INTERNATIONAL CONFERENCE ON PERVASIVE
   COMPUTING TECHNOLOGIES FOR HEALTHCARE (PERVASIVEHEALTH 2018)
SE International Conference on Pervasive Computing Technologies for
   Healthcare
LA English
DT Proceedings Paper
CT 12th EAI International Conference on Pervasive Computing Technologies
   for Healthcare (PervasiveHealth)
CY MAY 21-24, 2018
CL New York, NY
SP EAI
DE Conversational agents; health and wellbeing; chatbots; emojis; dialogue
   systems; information tracking
AB The recent rise of conversational interfaces have made it possible to integrate this technology into various domains, among which is health. Dialogue systems and conversational agents can bring a lot into healthcare to reduce cost, increase efficiency and provide continuing care, albeit its infancy and complexity about building natural dialogues. However, the design guidelines to design dialogues for conversational agents are usually based on common knowledge, and less frequently on empirical evidence. For example, the use of emojis in conversational agent dialogues is still a debated issue, and the added value of adding such graphical elements is mainly anecdotal. In this work, we present an empirical study comparing users feedback when interacting with chatbot applications that use different dialogue styles, i.e., plain text or text with emoji, when asking different health related questions. The analysis found that when participants had to score an interaction with a chatbot that asks personal questions on their mental wellbeing, they rated the interaction with higher scores with respect to enjoyment, attitude and confidence. Differently, participants rated with lower scores a chatbot that uses emojis when asking information on their physical wellbeing compared to a dialogue with plain text. We believe this work can contribute to the research on integrating conversational agents in the health and wellbeing context and can serve as a guidance in the design and development of interfaces for text-based dialogue systems.
C1 [Fadhil, Ahmed] Fdn Bruno Kessler FBK, ICT4G, Trento, Italy.
   [Schiavo, Gianluca] Fdn Bruno Kessler FBK, I3, Trento, Italy.
   [Wang, Yunlong] Univ Konstanz, HCI Grp, Constance, Germany.
   [Yilma, Bereket A.] Luxembourg Inst Sci & Technol, Luxembourg, Luxembourg.
RP Fadhil, A (corresponding author), Fdn Bruno Kessler FBK, ICT4G, Trento, Italy.
EM fadhil@fbk.eu; gschiavo@fbk.eu; yunlong.wang@uni.kn;
   bereket.yilma@list.lu
RI Wang, Yunlong/P-7747-2019; YILMA, Bereket Abera/AAE-3607-2021
OI Wang, Yunlong/0000-0003-0611-0078; YILMA, Bereket
   Abera/0000-0001-7210-9919
CR Abu Shawar B., 2003, P CORP LING 2003 C, P681, DOI DOI 10.13140/2.1.1455.7122
   Abu Shawar BA and Atwell ES, 2007, J LANG TECHNOL COMPU, V22, P29
   Al-Zubaide H., 2011, 2011 Fourth International Symposium on Innovation in Information & Communication Technology (ISIICT), P7, DOI 10.1109/ISIICT.2011.6149594
   Armstrong T, 2006, J PUBLIC HEALTH-HEID, V14, P66, DOI 10.1007/s10389-006-0024-x
   Crutzen R, 2011, J ADOLESCENT HEALTH, V48, P514, DOI 10.1016/j.jadohealth.2010.09.002
   Fadhil A., 2017, P 11 EAI INT C PERV, P261, DOI DOI 10.1145/3154862.3154914
   Fadhil A., 2018, PATIENT MONITORING C, P1
   Fadhil Ahmed, 2018, ARXIV PREPRINT ARXIV
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Graesser AC, 2001, AI MAG, V22, P39
   Herring SC, 2017, PROCEEDINGS OF THE 50TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P2185
   Hill J, 2015, COMPUT HUM BEHAV, V49, P245, DOI 10.1016/j.chb.2015.02.026
   Hogenboom A., 2013, P 28 ANN ACM S APPL, DOI [DOI 10.1145/2480362.2480498, 10.1145/2480362.2480498]
   Jia Jiyou, 2003, CS0310018 ARXIV
   KARAT CM, 2003, HUM FAC ER, P169
   KELLY R, 2015, EXPERIENCES TECHNOLO
   Klopfenstein LC, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P555, DOI 10.1145/3064663.3064672
   Lokman Abbas Saliimi, 2010, American Journal of Applied Sciences, V7, P1406, DOI 10.3844/ajassp.2010.1406.1411
   Looije R., 2008, J PHYS AGENTS JOPHA, V2, P13, DOI [10.14198/JoPha.2008.2.2.03, DOI 10.14198/JOPHA.2008.2.2.03]
   Lu X, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P770, DOI 10.1145/2971648.2971724
   MAYER RC, 1995, ACAD MANAGE REV, V20, P709, DOI 10.2307/258792
   Pohl H, 2017, ACM T COMPUT-HUM INT, V24, DOI 10.1145/3039685
   Romppel M, 2013, COMPR PSYCHIAT, V54, P406, DOI 10.1016/j.comppsych.2012.10.010
   Serban IV, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3776
   Skowron M, 2013, IEEE T AFFECT COMPUT, V4, P267, DOI 10.1109/T-AFFC.2013.16
   Wheeless L. R., 1976, HUMAN COMMUNICATION, V2, P338, DOI [DOI 10.1111/J.1468-2958.1976.TB00494.X, 10.1111/j.1468-2958.1976.tb00494.x]
   Xie R., 2016, ARXIV161204609
   Zhou R, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P748, DOI 10.1145/3025453.3025800
NR 28
TC 15
Z9 15
U1 4
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
SN 2153-1633
BN 978-1-4503-6450-8
J9 INT CONF PER COMP
PY 2018
BP 378
EP 383
DI 10.1145/3240925.3240965
PG 6
WC Computer Science, Interdisciplinary Applications; Health Care Sciences &
   Services; Medical Informatics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Health Care Sciences & Services; Medical Informatics
GA BQ7AM
UT WOS:000614057600051
OA Green Submitted
DA 2022-08-02
ER

PT C
AU Kloos, CD
   Alario-Hoyos, C
   Munoz-Merino, PJ
   Aguirre, CC
   Castro, NG
AF Delgado Kloos, Carlos
   Alario-Hoyos, Carlos
   Munoz-Merino, Pedro J.
   Catalan Aguirre, Cristina
   Gonzalez Castro, Nuria
BE Tatnall, A
   Mavengere, N
TI Principles for the Design of an Educational Voice Assistant for Learning
   Java
SO SUSTAINABLE ICT, EDUCATION AND LEARNING
SE IFIP Advances in Information and Communication Technology
LA English
DT Proceedings Paper
CT 1st IFIP WG 3.4 International Conference on Sustainable ICT, Education,
   and Learning
CY APR 25-27, 2019
CL State Univ Zanzibar, Zanzibar, TANZANIA
SP Int Federat Informat Proc Working Grp 3 4 Profess & Vocat Educ, Minist Educ & Culture, FinCEAL+ Bridges Program, Finnish Informat Proc Assoc, Tampere Univ, TAU Fdn, Int Federat Informat Proc Tech Comm 3
HO State Univ Zanzibar
DE Conversational agents; Voice assistants; VUI; MOOCs; Java teaching;
   Design decisions
AB Conversational agents, be they text- or voice-powered, are acquiring a level of maturity that makes them useful for natural and smart interactions. In this paper, we explore some design principles for voice-commanded assistants for educational use, in particular, of one designed to train Java concepts as a complement to a MOOC (Massive Open Online Course) about programming.
C1 [Delgado Kloos, Carlos; Alario-Hoyos, Carlos; Munoz-Merino, Pedro J.; Catalan Aguirre, Cristina; Gonzalez Castro, Nuria] Univ Carlos III Madrid, Av Univ 30, Madrid 28911, Spain.
RP Kloos, CD (corresponding author), Univ Carlos III Madrid, Av Univ 30, Madrid 28911, Spain.
EM cdk@it.uc3m.es; calario@it.uc3m.es; pedmume@it.uc3m.es;
   crcatala@pa.uc3m.es; nurigonz@db.uc3m.es
RI Alario-Hoyos, Carlos/AAC-2052-2019; Delgado Kloos, Carlos/C-2876-2011;
   Munoz-Merino, Pedro/E-1678-2011
OI Alario-Hoyos, Carlos/0000-0002-3082-0814; Delgado Kloos,
   Carlos/0000-0003-4093-3705; Munoz-Merino, Pedro/0000-0002-2552-4674
FU FEDER/Ministerio de Ciencia, Innovacio'ny Universidades - Agencia
   Estatal de Investigaci'on/Smartlet project [TIN2017-85179-C3-1-R];
   Madrid Regional Government (Comunidad de Madrid) [S2018/TCS-4307]; Fondo
   Social Europeo (FSE); Fondo Europeo de Desarrollo Regional (FEDER)
FX This work has been partially funded by FEDER/Ministerio de Ciencia,
   Innovacio'ny Universidades - Agencia Estatal de Investigaci'on/Smartlet
   project (TIN2017-85179-C3-1-R). In addition, this work has been
   partially funded by the e-Madrid-CM project with grant No.
   S2018/TCS-4307, which is funded by the Madrid Regional Government
   (Comunidad de Madrid), by the Fondo Social Europeo (FSE) and by the
   Fondo Europeo de Desarrollo Regional (FEDER).
CR Aguilar-Ibanez C., 2018, P 2018 15 INT C ELEC, P1
   Boyce S, 2007, EDUC TECHNOL SOC, V10, P275
   Brusilovsky P, 1996, USER MODEL USER-ADAP, V6, P87, DOI 10.1007/BF00143964
   Delgado Kloos Carlos, 2018, 2018 Learning With MOOCS (LWMOOCS). Proceedings, P27, DOI 10.1109/LWMOOCS.2018.8534591
   Demetriadis Stavros, 2018, 2018 Learning With MOOCS (LWMOOCS). Proceedings, P43, DOI 10.1109/LWMOOCS.2018.8534686
   Flecha R, 2000, SHARING WORDS THEORY
   Grice H. P., 1975, SYNTAX SEMANTICS, V3, P22
   John S, 2018, INT J INF ED TECHNOL, V4, P308
   Kloos C.D, INTRO PROGRAMACION J
   Kloos C.D., INTRO JAVA PROGRAMMI
   NIELSEN J., 1999, DESIGNING WEB USABIL
NR 11
TC 3
Z9 3
U1 1
U2 3
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1868-4238
EI 1868-422X
BN 978-3-030-28764-1; 978-3-030-28763-4
J9 IFIP ADV INF COMM TE
PY 2019
VL 564
BP 99
EP 106
DI 10.1007/978-3-030-28764-1_12
PG 8
WC Computer Science, Information Systems; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA BO2OY
UT WOS:000506818600012
OA Green Submitted
DA 2022-08-02
ER

PT C
AU De Gasperis, G
   Florio, N
AF De Gasperis, Giovanni
   Florio, Niva
BE Vittorini, P
   Gennari, R
   Marenzi, I
   DeLaPrieta, F
   Rodriguez, JMC
TI Learning to Read/Type a Second Language in a Chatbot Enhanced
   Environment
SO INTERNATIONAL WORKSHOP ON EVIDENCE-BASED TECHNOLOGY ENHANCED LEARNING
SE Advances in Intelligent and Soft Computing
LA English
DT Proceedings Paper
CT International workshop on Evidence-Based Technology Enhanced Learning
CY MAR 28-30, 2012
CL Salamanca, SPAIN
SP IEEE, Syst Man & Cybernet Soc, AEPIA, APPIA, CNRS, STELLAR
DE technology enhanced learning; conversational agents; AIML
ID DESIGN
AB Evidence based design methodology can be applied to second language learning by introducing tools and methods based on human machine conversational agents such as restricted chatbots. General purpose chatbots have been used as English tutors, where the learner tries to maintain a generic conversation; on the contrary the proposed tools, obtained by an AIML chatbot generator, are aimed at having a restricted conversation with learners, specifically crafted for the second language training. In the first case study, the obtainable conversation is inspired by the exercises that typically are in a foreign language text book: the chatbot can corrects learners in real time whenever the learner produces incorrect sentences. On the other case, learners have to ask questions to a FAQ-chatbot about a fable that learners should have read to demonstrate the plot of the story has been understood.
C1 [De Gasperis, Giovanni] Dipartimento Ingn & Sci Informaz Matemat, Via G Gronchi 18, I-67100COU Laquila, Italy.
   [Florio, Niva] Scuola Dottorato Ricerca Informat, Dipartimento Ingn & Sci Informaz Matemat, I-67100 Laquila, Italy.
RP De Gasperis, G (corresponding author), Dipartimento Ingn & Sci Informaz Matemat, Via G Gronchi 18, I-67100COU Laquila, Italy.
EM giovanni.degasperis@univaq.it; niva.florio@univaq.it
RI De Gasperis, Giovanni/C-3800-2011
OI De Gasperis, Giovanni/0000-0001-9521-4711
CR [Anonymous], 2009, ENGLISH TUTOR
   [Anonymous], 2011, ENGLISH TUTOR NONNAT
   Bennett C.L., 2001, USING VIRTUAL ENV HI
   Casamayor A., 2000, COMPUT EDUC, V53, P1147
   Chou CY, 2003, COMPUT EDUC, V40, P255, DOI 10.1016/S0360-1315(02)00130-6
   De Gasperis G., 2010, J E LEARNING KNOWLED, V2, P79
   De Pietro O., 2005, ADV TECHNOLOGY LEARN, DOI [10.2316/Journal.208.2005.1.208-0835, DOI 10.2316/JOURNAL.208.2005.1.208-0835]
   Eddy DM, 2005, HEALTH AFFAIR, V24, P9, DOI 10.1377/hlthaff.24.1.9
   Eynon R., 2009, P WEBSCI 2009 SOC ON
   Feng D., 2006, P INT C INT US INT I
   Fryer L, 2006, LANG LEARN TECHNOL, V10, P8
   Hannafin MJ, 1997, ETR&D-EDUC TECH RES, V45, P101, DOI 10.1007/BF02299733
   Ji J., 2004, P 15 ANN C SOC INF T, P1201
   Jiang X., 2010, 2 INT C ED TECHN COM, V3, P281
   Kerly A, 2007, KNOWL-BASED SYST, V20, P177, DOI 10.1016/j.knosys.2006.11.014
   Kerly A, 2009, APPLICATIONS AND INNOVATIONS IN INTELLIGENT SYSTEMS XVI, P169
   Konstantidinis A., 2008, 22 INT C ADV INF NET
   Liu M., 2002, J RES TECHNOLOGY ED, V34
   Smid K, 2002, COMP ANIM CONF PROC, P240, DOI 10.1109/CA.2002.1017543
   Tian J., 2007, WORKSH INT INF TECHN
   Veletsianos G, 2010, BRIT J EDUC TECHNOL, V41, P123, DOI 10.1111/j.1467-8535.2009.01027.x
   Vieira A.C., 2004, 7 INT C P INT TUT SY
   Wallace R., 2005, AIML 1 0 1 REFERENCE
   Wallace R. S., 2009, PARSING TURING TEST, P181, DOI DOI 10.1007/978-1-4020-6710-5_13
   Wang F, 2005, ETR&D-EDUC TECH RES, V53, P5, DOI 10.1007/BF02504682
NR 25
TC 1
Z9 1
U1 1
U2 12
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 1867-5662
BN 978-3-642-28800-5
J9 ADV INTEL SOFT COMPU
PY 2012
VL 152
BP 47
EP +
PG 3
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BCK70
UT WOS:000310488500006
DA 2022-08-02
ER

PT J
AU Abdulrahman, A
   Richards, D
AF Abdulrahman, Amal
   Richards, Deborah
TI In Search of Embodied Conversational and Explainable Agents for Health
   Behaviour Change and Adherence
SO MULTIMODAL TECHNOLOGIES AND INTERACTION
LA English
DT Review
DE health behaviour change; embodied conversational agents; explainable
   agents; working alliance
ID WORKING ALLIANCE; THERAPEUTIC ALLIANCE; PREDICTING STROKE;
   COMPUTER-PROGRAM; MENTAL-HEALTH; EXPERT SYSTEM; PSYCHOTHERAPY;
   INTERVENTIONS; FRAMEWORK; RESPONSES
AB Conversational agents offer promise to provide an alternative to costly and scarce access to human health providers. Particularly in the context of adherence to treatment advice and health behavior change, they can provide an ongoing coaching role to motivate and keep the health consumer on track. Due to the recognized importance of face-to-face communication and establishment of a therapist-patient working alliance as the biggest single predictor of adherence, our review focuses on embodied conversational agents (ECAs) and their use in health and well-being interventions. The article also introduces ECAs who provide explanations of their recommendations, known as explainable agents (XAs), as a way to build trust and enhance the working alliance towards improved behavior change. Of particular promise, is work in which XAs are able to engage in conversation to learn about their user and personalize their recommendations based on their knowledge of the user and then tailor their explanations to the beliefs and goals of the user to increase relevancy and motivation and address possible barriers to increase intention to perform the healthy behavior.
C1 [Abdulrahman, Amal; Richards, Deborah] Macquarie Univ, Dept Comp, Fac Sci & Engn, Sydney, NSW 2109, Australia.
RP Richards, D (corresponding author), Macquarie Univ, Dept Comp, Fac Sci & Engn, Sydney, NSW 2109, Australia.
EM amal.abdulrahman@students.mq.edu.au; deborah.richards@mq.edu.au
OI Abdulrahman, Amal/0000-0001-5360-0833; Richards,
   Deborah/0000-0002-7363-1511
FU International Macquarie University Research Training Program (iMQRTP)
   scholarship
FX This research was funded by an International Macquarie University
   Research Training Program (iMQRTP) scholarship.
CR Abdulrahman A.., 2021, P 20 INT C AUT AG MU, P68
   Abdulrahman A, 2021, J MULTIMODAL USER IN, V15, P189, DOI 10.1007/s12193-020-00359-3
   AIKINS JS, 1983, COMPUT BIOMED RES, V16, P199, DOI 10.1016/0010-4809(83)90021-6
   Amini R, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI 2013), P46, DOI 10.1109/ICHI.2013.13
   Anjomshoae S, 2019, AAMAS '19: PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P1078
   [Anonymous], 2007, P INT EXPL AW COMP E, V2007, P1
   Atkins L, 2006, EUR J CANCER, V42, P2271, DOI 10.1016/j.ejca.2006.03.004
   Bachelor A, 2013, CLIN PSYCHOL PSYCHOT, V20, P118, DOI 10.1002/cpp.792
   Badawy SM, 2017, JMIR MHEALTH UHEALTH, V5, DOI 10.2196/mhealth.8310
   Bailenson JN, 2005, PSYCHOL SCI, V16, P814, DOI 10.1111/j.1467-9280.2005.01619.x
   Belpaeme T, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aat5954
   Bennett JK, 2011, PATIENT EDUC COUNS, V85, P53, DOI 10.1016/j.pec.2010.08.005
   Berry DC, 2005, INT J HUM-COMPUT ST, V63, P304, DOI 10.1016/j.ijhcs.2005.03.006
   Bian YL, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P433, DOI 10.1145/2858036.2858351
   Bickmore T, 2005, PATIENT EDUC COUNS, V59, P21, DOI 10.1016/j.pec.2004.09.008
   Bickmore T, 2002, CHI 02 EXTENDED ABST
   Bickmore T., 2008, CHI 08 WORKSH TECH M
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore T, 2010, APPL ARTIF INTELL, V24, P648, DOI 10.1080/08839514.2010.492259
   Bickmore T, 2010, HARVARD REV PSYCHIAT, V18, P119, DOI 10.3109/10673221003707538
   Bickmore T, 2009, LECT NOTES ARTIF INT, V5773, P425, DOI 10.1007/978-3-642-04380-2_46
   Bickmore TW, 2013, PATIENT EDUC COUNS, V92, P142, DOI 10.1016/j.pec.2013.05.011
   Bickmore TW, 2011, J BIOMED INFORM, V44, P183, DOI 10.1016/j.jbi.2010.12.006
   Bickmore TW, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1265
   Bittner E., 2019, P 52 HAW INT C SYST
   Bordin E.S., 1979, PSYCHOTHER-THEOR RES, V16, P252
   Bordin E.S., ANN M SOC PSYCH RES
   Bratman Michael, 1987, INTENTION PLANS PRAC
   Cassell J, 2001, AI MAG, V22, P67
   Catty J, 2004, PSYCHOL PSYCHOTHER-T, V77, P255, DOI 10.1348/147608304323112528
   Christensen H, 2009, J MED INTERNET RES, V11, DOI 10.2196/jmir.1194
   CLANCEY WJ, 1983, ARTIF INTELL, V20, P215, DOI 10.1016/0004-3702(83)90008-5
   Clore GL, 2013, EMOT REV, V5, P335, DOI 10.1177/1754073913489751
   Colby K.M, 1975, BEHAV THER, V7, DOI [10.1016/s0005-7894(76)80257-2, DOI 10.1016/S0005-7894(76)80257-2]
   COLBY KM, 1995, PSYCHIATR SERV, V46, P1223
   Cole-Lewis Heather, 2019, JMIR Form Res, V3, pe14052, DOI 10.2196/14052
   Crutzen R, 2011, J ADOLESCENT HEALTH, V48, P514, DOI 10.1016/j.jadohealth.2010.09.002
   Darlington KW, 2011, SAGE OPEN, V1, DOI 10.1177/2158244011408618
   De Graaf MaartjeMA., 2017, 2017 AAAI FALL S SER, P19
   de Rosis F, 2003, INT J HUM-COMPUT ST, V59, P81, DOI 10.1016/S1071-5819(03)00020-X
   de Rosis F, 2006, J BIOMED INFORM, V39, P514, DOI 10.1016/j.jbi.2006.01.001
   Deng L, 2011, LECT NOTES COMPUT SC, V6897, P68, DOI 10.1007/978-3-642-23535-1_8
   Dennett D. C., 1987, INTENTIONAL STANCE
   Dennett D.C., 1981, REDUCTION TIME REALI, P37
   DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061
   Diederich S, 2019, HUMAN PRACTICE DIGIT, P1100
   Dorri A, 2018, IEEE ACCESS, V6, P28573, DOI 10.1109/ACCESS.2018.2831228
   Dzindolet MT, 2003, INT J HUM-COMPUT ST, V58, P697, DOI 10.1016/S1071-5819(03)00038-7
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Floridi L, 2018, MIND MACH, V28, P689, DOI 10.1007/s11023-018-9482-5
   Gage BF, 2001, JAMA-J AM MED ASSOC, V285, P2864, DOI 10.1001/jama.285.22.2864
   Glass Alyssa, 2008, 13th International Conference on Intelligent User Interfaces. IUI 2008, P227, DOI 10.1145/1378773.1378804
   Grassmann C, 2020, HUM RELAT, V73, P35, DOI 10.1177/0018726718819725
   Grosz B.J., 1988, PLANS DISCOURSE
   Grosz BJ, 1999, APPL LOG SER, V14, P227
   Grudin J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300439
   Hagger MS, 2006, PERS SOC PSYCHOL B, V32, P131, DOI 10.1177/0146167205279905
   Hamidi F, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173582
   Harbers Maaike, 2012, Web Intelligence and Agent Systems, V10, P331, DOI 10.3233/WIA-2012-0250
   Harbers M, 2010, Proceedings of the 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT 2010), P125, DOI 10.1109/WI-IAT.2010.115
   Harbers M, 2009, LECT NOTES ARTIF INT, V5773, P132
   Harman K, 2014, PHYSIOTHER CAN, V66, P82, DOI 10.3138/ptc.2012-56BC
   Herrera F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204494
   Heynsbergh N, 2018, BMC CANCER, V18, DOI 10.1186/s12885-018-4160-9
   Hillier L., 2018, EXPLORING NATURE THE
   Hilton DJ, 2010, EUR J SOC PSYCHOL, V40, P383, DOI 10.1002/ejsp.623
   HILTON DJ, 1990, PSYCHOL BULL, V107, P65, DOI 10.1037/0033-2909.107.1.65
   Hodgson T, 2017, J AM MED INFORM ASSN, V24, P1127, DOI 10.1093/jamia/ocx073
   Hojat M., 2007, EMPATHY PATIENT CARE
   Holter MTS, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5415
   HORVATH AO, 1991, J COUNS PSYCHOL, V38, P139, DOI 10.1037/0022-0167.38.2.139
   HORVATH AO, 1989, J COUNS PSYCHOL, V36, P223, DOI 10.1037/0022-0167.36.2.223
   Huber M, 2016, BMJ OPEN, V6, DOI 10.1136/bmjopen-2015-010091
   Hudlicka E, 2016, ARTIFICIAL INTELLIGENCE IN BEHAVIORAL AND MENTAL HEALTH CARE, P81, DOI 10.1016/B978-0-12-420248-1.00004-0
   Hurmuz MZM, 2020, JMIR RES PROTOC, V9, DOI 10.2196/16641
   Ireland D, 2016, STUD HEALTH TECHNOL, V227, P55, DOI 10.3233/978-1-61499-666-8-55
   Isbister K, 2000, INT J HUM-COMPUT ST, V53, P251, DOI 10.1006/ijhc.2000.0368
   Isbister K, 2004, HUM-COMPUT INT-SPRIN, V7, P3
   Isern D, 2016, J MED SYST, V40, DOI 10.1007/s10916-015-0376-2
   Kang SH, 2011, STUD HEALTH TECHNOL, V167, P143, DOI 10.3233/978-1-60750-766-6-143
   Kaplan B, 2003, INT J MED INFORM, V71, P33, DOI 10.1016/S1386-5056(03)00072-8
   Kaptein F, 2017, IEEE ROMAN, P676, DOI 10.1109/ROMAN.2017.8172376
   Keil FC, 2006, ANNU REV PSYCHOL, V57, P227, DOI 10.1146/annurev.psych.57.102904.190100
   Kelders SM, 2012, J MED INTERNET RES, V14, P17, DOI 10.2196/jmir.2104
   Kennedy CM, 2012, J MED INTERNET RES, V14, P116, DOI 10.2196/jmir.1893
   Klaassen R, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020402
   Krupnick JL, 1996, J CONSULT CLIN PSYCH, V64, P532, DOI 10.1037/0022-006X.64.3.532
   Kumar V, 2016, J ACAD MARKET SCI, V44, P24, DOI 10.1007/s11747-015-0426-9
   Langley P, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4762
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lehane E, 2007, INT J NURS STUD, V44, P1468, DOI 10.1016/j.ijnurstu.2006.07.010
   Leite I, 2011, LECT NOTES COMPUT SC, V6787, P446, DOI 10.1007/978-3-642-22362-4_48
   Leite I, 2010, LECT NOTES ARTIF INT, V6356, P315, DOI 10.1007/978-3-642-15892-6_32
   Letham B, 2015, ANN APPL STAT, V9, P1350, DOI 10.1214/15-AOAS848
   Lip GYH, 2010, CHEST, V137, P263, DOI 10.1378/chest.09-1584
   Lisetti C.L., 2012, SIGHIT RECORD, V2, P28, DOI [10.1145/2180796.2180820, DOI 10.1145/2180796.2180820]
   Lisetti C.L., 2012, P 25 INT FLAIRS C
   Lissetti C., 2008, 2008 AAAI 2008 SPRIN, P72
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   Mackie C, 2017, EVID-BASED MENT HEAL, V20, P118, DOI 10.1136/eb-2017-102764
   Malle B, 2012, APA, DOI [10.1093/acprof:oso/9780195307696.003.0010, DOI 10.1093/ACPROF:OSO/9780195307696.003.0010]
   Malle B F, 1999, Pers Soc Psychol Rev, V3, P23, DOI 10.1207/s15327957pspr0301_2
   Mathieu JE, 2000, J APPL PSYCHOL, V85, P273, DOI 10.1037//0021-9010.85.2.273
   MAYER RC, 1995, ACAD MANAGE REV, V20, P709, DOI 10.2307/258792
   McRorie M, 2012, IEEE T AFFECT COMPUT, V3, P311, DOI 10.1109/T-AFFC.2011.38
   Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007
   Miner AS, 2016, JAMA INTERN MED, V176, P619, DOI 10.1001/jamainternmed.2016.0400
   Ministry of Health Republic of Iraq, 2013, NAT STRAT PREV CONTR
   Morency LP, 2015, PROCEEDINGS OF THE TWENTY-NINTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4307
   Moulin B, 2002, ARTIF INTELL REV, V17, P169, DOI 10.1023/A:1015023512975
   Murali P., 2020, P 19 INT C AUT AG MU, P1940
   Nass C, 1999, J APPL SOC PSYCHOL, V29, P1093, DOI 10.1111/j.1559-1816.1999.tb00142.x
   Navarra AMD, 2017, AIDS BEHAV, V21, P3154, DOI 10.1007/s10461-017-1867-6
   Nutbeam D, 2008, SOC SCI MED, V67, P2072, DOI 10.1016/j.socscimed.2008.09.050
   O'Keefe D.J., 2004, READINGS PERSUASION, P31
   Olafsson S., 2020, AAMAS, P966
   Op den Akker H, 2018, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES FOR AGEING WELL AND E-HEALTH (ICT4AWE), P219, DOI 10.5220/0006787702190226
   Paiva A, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2912150
   Parasuraman R, 1997, HUM FACTORS, V39, P230, DOI 10.1518/001872097778543886
   Picard R.W., 2000, AFFECTIVE COMPUTING
   Pop-Eleches C, 2011, AIDS, V25, P825, DOI 10.1097/QAD.0b013e32834380c1
   Porra J, 2020, INFORM SYST FRONT, V22, P533, DOI 10.1007/s10796-019-09969-z
   Prochaska JO, 1997, AM J HEALTH PROMOT, V12, P38, DOI 10.4278/0890-1171-12.1.38
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Rheu M, 2021, INT J HUM-COMPUT INT, V37, P81, DOI 10.1080/10447318.2020.1807710
   Rich C, 2001, AI MAG, V22, P15
   Richards Deborah, 2016, Knowledge Management and Acquisition for Intelligent Systems. 14th Pacific Rim Knowledge Acquisition Workshop, PKAW 2016. Proceedings: LNCS 9806, P213, DOI 10.1007/978-3-319-42706-5_16
   Richards D, 2019, BRIT J EDUC TECHNOL, V50, P2885, DOI 10.1111/bjet.12863
   Richards D, 2018, IEEE J BIOMED HEALTH, V22, P1699, DOI 10.1109/JBHI.2017.2782210
   Rishe N, 2013, ACM TMIS, V4, P1, DOI [10.1145/2544103, DOI 10.1145/2544103]
   Rizk Y, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3303848
   Roberts S, 2017, BMC HEALTH SERV RES, V17, DOI 10.1186/s12913-017-2314-0
   Roitman H., 2010, P 1 ACM INT HLTH INF, P430, DOI DOI 10.1145/1882992.1883057
   Rueda S, 2006, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD001442.pub2
   Samek W., 2019, EXPLAINABLE INTERPRE, V11700
   Samek Wojciech, 2017, ARXIV170808296
   Schulman D., 2009, P 4 INT C PERS TECHN, P1
   Scott A.C., 1977, EXPLANATION CAPABILI
   Sherwood Gwen, 2002, Crit Care Nurs Clin North Am, V14, P333, DOI 10.1016/S0899-5885(02)00020-5
   Sieverink F, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.8578
   Smith A., 2015, SMARTPHONE USE 2015
   Swartout WR, 1985, COMPUTER ASSISTED ME, P254, DOI DOI 10.1007/978-1-4612-5108-8_15
   ter Stal S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102409
   Tremain H, 2020, JMIR MENT HEALTH, V7, DOI 10.2196/17204
   Utami D, 2017, LECT NOTES ARTIF INT, V10498, P441, DOI 10.1007/978-3-319-67401-8_55
   van den Bosch K, 2009, LECT NOTES COMPUT SC, V5620, P463, DOI 10.1007/978-3-642-02809-0_49
   Van Pinxteren MME, 2020, J SERV MANAGE, V31, P203, DOI 10.1108/JOSM-06-2019-0175
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wendt T, 2000, ST HEAL T, V77, P852
   Wheeler SC, 2005, J CONSUM RES, V31, P787, DOI 10.1086/426613
   Yee N, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1
   Zhou S, 2014, LECT NOTES ARTIF INT, V8637, P528, DOI 10.1007/978-3-319-09767-1_63
   Zierau Naim, 2020, INT C INF SYST ICIS, P1
NR 153
TC 0
Z9 0
U1 3
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2414-4088
J9 MULTIMODAL TECHNOLOG
JI Multimodal Technol. Interaction
PD SEP
PY 2021
VL 5
IS 9
AR 56
DI 10.3390/mti5090056
PG 20
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Information Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA UY8DP
UT WOS:000701748300001
OA gold, Green Published
DA 2022-08-02
ER

PT C
AU Han, HJ
   Mendu, S
   Jaworski, BK
   Owen, JE
   Abdullah, S
AF Han, Hee Jeong
   Mendu, Sanjana
   Jaworski, Beth K.
   Owen, Jason E.
   Abdullah, Saeed
GP ASSOC COMP MACHINERY
TI PTSDialogue: Designing a Conversational Agent to Support Individuals
   with Post-Traumatic Stress Disorder
SO UBICOMP/ISWC '21 ADJUNCT: PROCEEDINGS OF THE 2021 ACM INTERNATIONAL
   JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS
   OF THE 2021 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS
LA English
DT Proceedings Paper
CT ACM International Joint Conference on Pervasive and Ubiquitous Computing
   (UbiComp) / ACM International Symposium on Wearable Computers (ISWC)
CY SEP 21-26, 2021
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGCHI, ACM SIGMOBILE, Google, Intel, Microsoft, Stabilo, UVA Link Lab, Springer
DE conversational agents; chatbot; PTSD; user engagement
ID SMARTPHONE APP; VIRTUAL HUMANS; MENTAL-HEALTH; COACH; PTSD
AB Post-traumatic stress disorder (PTSD) is a serious public health issue. Approximately 8 million adults in the United States suffer from PTSD in any given year, and 7-8% of the U.S. population will have PTSD at some point in their lives. Recent studies have explored eHealth technologies to support persons living with PTSD. However, current approaches are often unable to sustain adherence, leading to sub-optimal clinical outcomes. Conversational agents (CAs) can help to improve longitudinal adherence by interactively engaging users and maintaining social presence. In this work, we present prototypes of PTSDialogue - a finite-state CA to deliver evidence-based strategies and support self-management for individuals living with PTSD. We also discuss the design requirements and process of adapting existing eHealth content to interactive dialogues. Furthermore, we detail design decisions to address safety and ethical concerns to develop a CA for a vulnerable population.
C1 [Han, Hee Jeong; Mendu, Sanjana; Abdullah, Saeed] Penn State Univ, State Coll, PA 16801 USA.
   [Jaworski, Beth K.; Owen, Jason E.] Natl Ctr PTSD, Menlo Pk, CA USA.
RP Han, HJ (corresponding author), Penn State Univ, State Coll, PA 16801 USA.
EM heejeonghan@psu.edu; sanjana.mendu@psu.edu; beth.jaworski@va.gov;
   jason.owen@va.gov; saeed@psu.edu
FU National Science Foundation [1850287]
FX This material is based upon work supported by the National Science
   Foundation under Grant No. 1850287.
CR Abdullah S, 2018, IEEE MULTIMEDIA, V25, P61, DOI 10.1109/MMUL.2018.011921236
   Abdullah S, 2016, J AM MED INFORM ASSN, V23, P538, DOI 10.1093/jamia/ocv200
   Anguera Joaquin A, 2016, BMJ Innov, V2, P14
   Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Bickmore T, 2003, P CHI 2003 WORKSH SU
   Bickmore TW, 2018, J MED INTERNET RES, V20, DOI 10.2196/11510
   Bickmore TW, 2010, INTERACT COMPUT, V22, P289, DOI 10.1016/j.intcom.2009.12.001
   Bickmore TW, 2010, INTERACT COMPUT, V22, P276, DOI 10.1016/j.intcom.2010.02.001
   Cassell J, 2001, AI MAG, V22, P67
   Chattaraman V, 2012, COMPUT HUM BEHAV, V28, P2055, DOI 10.1016/j.chb.2012.06.009
   Christensen H, 2009, J MED INTERNET RES, V11, DOI 10.2196/jmir.1194
   Congressional Budget Office, 2018, POSS HIGH SPEND PATH
   DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061
   Donkin L, 2011, J MED INTERNET RES, V13, DOI 10.2196/jmir.1772
   Firth J, 2017, WORLD PSYCHIATRY, V16, P287, DOI 10.1002/wps.20472
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Galea Sandro, 2014, TREATMENT POSTTRAUMA
   Hwang Youjin, APPLYING PERSONA USE
   Kang SH, 2010, COMPUT ANIMAT VIRT W, V21, P473, DOI 10.1002/cav.345
   Kocaballi AB, 2019, J MED INTERNET RES, V21, DOI 10.2196/15360
   Kuhn E, 2017, J CONSULT CLIN PSYCH, V85, P267, DOI 10.1037/ccp0000163
   Kuhn E, 2014, MIL MED, V179, P12, DOI 10.7205/MILMED-D-13-00271
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lucas GM, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00051
   Mohr DC, 2011, J MED INTERNET RES, V13, DOI 10.2196/jmir.1602
   Morie JF, 2009, STUD HEALTH TECHNOL, V144, P273, DOI 10.3233/978-1-60750-017-9-273
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   OConnell C, 2017, 23 USERS ABANDON APP
   Owen JE, 2015, JMIR MENT HEALTH, V2, DOI 10.2196/mental.3935
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Purington A, 2017, 2017 CHI C HUM FACT, DOI [10.1145/3027063.3053246, DOI 10.1145/3027063.3053246]
   React Native, 2018, FRAM BUILD NAT APPS
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Sayers J., 2001, B WORLD HEALTH ORGAN, V79, P1085
   Schroeder J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173972
   Spoont MR, 2010, PSYCHIAT SERV, V61, P58, DOI 10.1176/appi.ps.61.1.58
   Swartout W, 2013, AI MAG, V34, P13, DOI 10.1609/aimag.v34i4.2487
   Tanaka H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182151
   Tielman M, 2014, LECT NOTES ARTIF INT, V8637, P434, DOI 10.1007/978-3-319-09767-1_54
   Toader DC, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12010256
   Torous John, 2017, Clin Schizophr Relat Psychoses, DOI 10.3371/CSRP.JTPS.071317
   U.S. Department of Veterans Affairs, 2019, COMM IS PTSD AD
   Uddin Moin, 2020, BOTUI A JAVASCRIPT F
   Wainberg ML, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0780-z
   Wang R, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P886, DOI 10.1145/2971648.2971740
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wilks Yorick, 2010, P 2010 WORKSH COMP D, P13
NR 48
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-8461-2
PY 2021
BP 198
EP 203
DI 10.1145/3460418.3479332
PG 6
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BS4XS
UT WOS:000723951900062
DA 2022-08-02
ER

PT C
AU Benedetto, L
   Cremonesi, P
AF Benedetto, Luca
   Cremonesi, Paolo
BE Lamas, D
   Loizides, F
   Nacke, L
   Petrie, H
   Winckler, M
   Zaphiris, P
TI Rexy, A Configurable Application for Building Virtual Teaching
   Assistants
SO HUMAN-COMPUTER INTERACTION, INTERACT 2019, PT II
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 17th IFIP TC13 International Conference on Human-Computer Interaction
   (INTERACT)
CY SEP 02-06, 2019
CL Paphos, CYPRUS
SP Int Federat Informat Proc Tech Comm 13, Cyprus Univ Technol, Tallinn Univ, ACM, ACM SIGCHI, Res Ctr Interact Media Smart Syst & Emerging Technologies, Springer
DE Artificial intelligence; Conversational agents; Human-computer
   interaction; Virtual teaching assistants; NLP
ID ARTIFICIAL-INTELLIGENCE; CONVERSATIONS
AB In recent years, virtual assistants gained a pervasive role in many domains and education was not different from others. However, although some implementation of conversational agents for supporting students have already been presented, they were ad hoc systems, built for specific courses and impossible to generalize. Also, there is a lack of research about the effects that the development of systems capable of interacting with both the students and the professors would have. In this paper, we introduce Rexy, a configurable application that can be used to build virtual teaching assistants for diverse courses, and present the results of a user study carried out using it as a virtual teaching assistant for an on-site course held at Politecnico di Milano. The qualitative analysis of the usage that was made of the assistant and the results of a post study questionnaire the students were asked to fill showed that they see conversational agents as useful tools for helping them in their studies.
C1 [Benedetto, Luca; Cremonesi, Paolo] Politecn Milan, Milan, Italy.
RP Benedetto, L (corresponding author), Politecn Milan, Milan, Italy.
EM luca.benedetto@polimi.it; paolo.cremonesi@polimi.it
OI Benedetto, Luca/0000-0002-5113-4696
CR Abu Shawar BA and Atwell ES, 2007, J LANG TECHNOL COMPU, V22, P29
   Akcora Damla Ezgi, 2018, Artificial Intelligence in Education. 19th International Conference, AIED 2018. Proceedings: LNAI 10948, P14, DOI 10.1007/978-3-319-93846-2_3
   Benedetto L., 2019, ARXIV PREPRINT ARXIV
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   du Boulay B, 2016, IEEE INTELL SYST, V31, P76, DOI 10.1109/MIS.2016.93
   Eicher B., 2017, AAAI ACM C ART INT E, V7
   Ferrucci D, 2010, AI MAG, V31, P59, DOI 10.1609/aimag.v31i3.2303
   Goel A. K., 2016, J WATSON VIRTUAL TEA
   Hill J, 2015, COMPUT HUM BEHAV, V49, P245, DOI 10.1016/j.chb.2015.02.026
   Kerlyl A., 2007, APPL INNOVATIONS INT, P179
   Ramesh K, 2017, COMM COM INF SC, V750, P336, DOI 10.1007/978-981-10-6544-6_31
   So S, 2016, INTERNET HIGH EDUC, V31, P32, DOI 10.1016/j.iheduc.2016.06.001
   Sun Z, 2018, BRIT J EDUC TECHNOL, V49, P248, DOI 10.1111/bjet.12571
   Timmis S, 2012, COMPUT EDUC, V59, P3, DOI 10.1016/j.compedu.2011.09.026
   Ventura Matthew, 2018, Artificial Intelligence in Education. 19th International Conference, AIED 2018. Proceedings: LNAI 10948, P480, DOI 10.1007/978-3-319-93846-2_90
NR 15
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-29384-0; 978-3-030-29383-3
J9 LECT NOTES COMPUT SC
PY 2019
VL 11747
BP 233
EP 241
DI 10.1007/978-3-030-29384-0_15
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Interdisciplinary Applications; Computer
   Science, Theory & Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BS2JO
UT WOS:000702138200015
DA 2022-08-02
ER

PT C
AU Griol, D
   Patricio, MA
   Molina, JM
AF Griol, David
   Angel Patricio, Miguel
   Manuel Molina, Jose
BE Vicente, JMF
   AlvarezSanchez, JR
   Lopez, FD
   ToledoMoreo, FJ
   Adeli, H
TI The CALIMACO Multimodal System: Providing Enhanced Library Services
   Using Mobile Devices
SO BIOINSPIRED COMPUTATION IN ARTIFICIAL SYSTEMS, PT II
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 5th International Work-Conference on the Interplay Between Natural and
   Artificial Computation (IWINAC)
CY JUN 01-05, 2015
CL Elche, SPAIN
SP Spanish CYTED, Red Nacl Computac Nat Artificial & Apliquem Microones 21 s l
DE Conversational Agents; Digital Libraries; Assistants; Multimodal
   Interaction; Spoken Interaction; Mobile Devices; Android
AB Multimodal conversational agents have became a strong alternative to enhance educational systems with intelligent communicative capabilities. The combination of these systems with smart mobile devices have promoted in recent years more sophisticated human-machine interfaces that provide a more engaging and human-like relationship between users and the system. Among the different educational application domains, this combination allows developing enhanced digital libraries containing new types of multimedia contents, providing new interaction possibilities, and adapting this interaction taking into account the specific users requirements and preferences. In this paper we propose the practical application of multimodal conversational agents to develop advanced University Digital Libraries (UDL) adapted to the new interaction scenarios of mobile devices. Our proposal integrates features of Android APIs on a modular architecture that emphasizes interaction management to create robust applications, easily updated and adapted to the user.
C1 [Griol, David; Angel Patricio, Miguel; Manuel Molina, Jose] Univ Carlos III Madrid, Dept Comp Sci, Leganes 28911, Spain.
RP Griol, D (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Avda Univ 30, Leganes 28911, Spain.
EM david.griol@uc3m.es; miguelangel.patricio@uc3m.es;
   josemanuel.molina@uc3m.es
RI Patricio, Miguel A./AAZ-4876-2020; Griol, David/L-1258-2014; Molina,
   JOSE/B-1956-2008
OI Patricio, Miguel A./0000-0002-9304-826X; Griol,
   David/0000-0001-6266-5321; Molina, JOSE/0000-0002-7484-7357
CR CAVAZZA M, 2010, AAMAS, P01629
   Chen HL, 2012, LIBR INFORM SCI RES, V34, P220, DOI 10.1016/j.lisr.2011.12.001
   Fryer L, 2006, LANG LEARN TECHNOL, V10, P8
   Griol D, 2014, COMPUT SPEECH LANG, V28, P743, DOI 10.1016/j.csl.2013.09.002
   Griol D, 2012, J UNIVERS COMPUT SCI, V18, P2516
   Hassenzahl M., 2003, MENSCH COMPUTER 2003, P187, DOI DOI 10.1007/978-3-322-80058-9_19
   Hone K., 2001, P EUR
   Kerly A, 2008, KNOWL-BASED SYST, V21, P238, DOI 10.1016/j.knosys.2007.11.015
   McTear M., 2013, VOICE APPL DEV ANDRO
   Metze F, 2009, LECT NOTES COMPUT SC, V5611, P75, DOI 10.1007/978-3-642-02577-8_9
   Pieraccini R, 2012, VOICE IN THE MACHINE: BUILDING COMPUTERS THAT UNDERSTAND SPEECH, P1
   Pon-Barry Heather, 2006, INT J ARTIFICIAL INT, V16, P171
   R-Moreno MD, 2014, EXPERT SYST APPL, V41, P7904, DOI 10.1016/j.eswa.2014.06.047
   RODA C., 2001, P BOTSHOW 2001, P1
   Vassilakaki Evgenia, 2013, International Information and Library Review, V45, P3, DOI 10.1016/j.iilr.2013.07.002
   Wang YH, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P1023
NR 16
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-319-18833-1; 978-3-319-18832-4
J9 LECT NOTES COMPUT SC
PY 2015
VL 9108
BP 339
EP 348
DI 10.1007/978-3-319-18833-1_36
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods; Mathematical &
   Computational Biology; Robotics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Mathematical & Computational Biology; Robotics
GA BD6CG
UT WOS:000362031300036
DA 2022-08-02
ER

PT C
AU Pudner, K
   Crockett, K
   Bandar, Z
AF Pudner, Karen
   Crockett, Keeley
   Bandar, Zuhair
GP Int Assoc Engineers
TI An intelligent conversational agent approach to extracting queries from
   natural language
SO WORLD CONGRESS ON ENGINEERING 2007, VOLS 1 AND 2
SE Lecture Notes in Engineering and Computer Science
LA English
DT Proceedings Paper
CT World Congress on Engineering 2007
CY JUL 02-04, 2007
CL London, ENGLAND
SP Int Assoc Engineers
DE conversational agents; natural language; SQL
AB This paper is concerned with the application of a conversational agent and expert system to provide a natural language interface to a database. Typically, natural language database Interfaces (NLDI's) use grammatical and/or statistical parsing. Conversational agents take a different approach, capturing key elements of user input which then trigger pre-determined output templates. It is assumed that the type of natural language questions which could be asked of a specific relational database will contain a limited number of key words (attributes), which could be captured by a conversational agent, In the proposed system, once a conversational agent has identified all relevant attributes and their values, an expert system would then apply rule based reasoning on these attributes to construct an SQL query. The knowledge base of the expert system would contain information on the database structure (metadata) and on the different possible structures of SQL queries. This would result in a real time system, which could extract both database attributes and attribute values from the user input and automatically apply a rule based reasoning system to determine the answer the user's query.
C1 [Pudner, Karen; Crockett, Keeley; Bandar, Zuhair] Manchester Metropolitan Univ, Dept Comp & Math, Intelligent Syst Grp, Chester St, Manchester M1 5GD, Lancs, England.
RP Crockett, K (corresponding author), Manchester Metropolitan Univ, Dept Comp & Math, Intelligent Syst Grp, Chester St, Manchester M1 5GD, Lancs, England.
EM K.Crockett@mmu.ac.uk
CR ANDROUTSOPOULOS I, 1993, P 6 INT C IND ENG AP
   Bhootra R., 2004, THESIS VIRGINIA COMM
   BOWMAN J, 2001, PRACTICAL SQL HDB SQ
   CANNAN S, 1993, SQL STANDARD HDB, P8
   Colby K, 1975, ARTIFICIAL PARANOIA
   *ELFSOFT, ELF SOFTW DOC SER
   KNOWLES SA, 1993, NATURAL LANGUAGE DAT
   MAULDIN M, 1994, TINYMUDS TURING TEST
   Michie D., 2001, INFOCHAT SCRIPTERS M
   Popescu A.-M., 2003, IUI 03. 2003 International Conference on Intelligent User Interfaces, P149
   RITCHIE C, 2002, RELATIONAL DATABASE, P128
   Turing AM., 1950, J MIND ASS, V59, P433, DOI [10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   WALLACE M, 1984, COMMUNICATING DATABA
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
NR 14
TC 7
Z9 7
U1 0
U2 2
PU INT ASSOC ENGINEERS-IAENG
PI HONG KONG
PA UNIT 1, 1-F, 37-39 HUNG TO ROAD, KWUN TONG, HONG KONG, 00000, PEOPLES R
   CHINA
SN 2078-0958
BN 978-988-98671-5-7
J9 LECT NOTES ENG COMP
PY 2007
BP 305
EP +
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Engineering, Multidisciplinary; Engineering, Biomedical;
   Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BGT01
UT WOS:000250382600056
DA 2022-08-02
ER

PT C
AU Chaminade, T
   Rauchbauer, B
   Nazarian, B
   Bourhis, M
   Ochs, M
   Prevot, L
AF Chaminade, Thierry
   Rauchbauer, Birgit
   Nazarian, Bruno
   Bourhis, Morgane
   Ochs, Magalie
   Prevot, Laurent
GP ACM
TI Brain Neurophysiology to Objectify the Social Competence of
   Conversational Agents
SO HAI'18: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT
   INTERACTION
LA English
DT Proceedings Paper
CT 6th International Conference on Human-Agent Interaction (HAI)
CY DEC 15-18, 2018
CL Southampton, ENGLAND
SP Assoc Comp Machinery, ADK, Cocoro SB, THALES, Cognit Interact Design, DEEPCORE, Assoc Comp Machinery SIGCHI
DE Humanoid Robot; Social Interaction; Neurophysiology
AB We present an approach to objectify the social competence of artificial agents using human brain neurophysiology. Whole brain activity is recorded with functional Magnetic Resonance Imaging (fMRI) while participants discuss either with a human confederate or an artificial agent. This allows a direct comparison of local brain responses, including deep brain structures invisible to other neuroimaging techniques, as a function of the nature of the interlocutor. The present data (9 participants, artificial agent is the robotic conversational head Furhat controlled with a Wizard of Oz procedure) demonstrates the feasibility of this approach, and results confirm an increased activity in the hypothalamic region when interacting with a human compared to an artificial agent.
C1 [Chaminade, Thierry; Rauchbauer, Birgit; Nazarian, Bruno] Aix Marseille Univ, CNRS, Inst Neurosci Timone, Marseille, France.
   [Bourhis, Morgane] Aix Marseille Univ, Inst Neurosci Timone, Marseille, France.
   [Ochs, Magalie] Aix Marseille Univ, CNRS, Lab Informat & Syst, Marseille, France.
   [Prevot, Laurent] Aix Marseille Univ, CNRS, Lab Parole & Language, Marseille, France.
RP Chaminade, T (corresponding author), Aix Marseille Univ, CNRS, Inst Neurosci Timone, Marseille, France.
EM thierry.chaminade@univ-amu.fr; birgit.rauchbauer@univ-amu.fr;
   bruno.nazarian@univ-amu.fr; morgana.bourhis@univ-amu.fr;
   magalie.ochs@univ-amu.fr; laurent.prevot@univ-amu.fr
RI Chaminade, Thierry/AAF-6072-2020
OI Chaminade, Thierry/0000-0003-4952-1467; Prevot,
   Laurent/0000-0002-2463-2382
FU ILCB [ANR-16-CONV-0002]; BLRI [ANR-11-LABX-0036]; Excellence Initiative
   of Aix-Marseille University - A*Midex, a French "Investissements
   d'Avenir" programme [AAP-ID-17-46-170301-11.1]
FX Support from grants ANR-16-CONV-0002 (ILCB) and ANR-11-LABX-0036 (BLRI)
   and the Excellence Initiative of Aix-Marseille University - A*Midex, a
   French "Investissements d'Avenir" programme (AAP-ID-17-46-170301-11.1).
CR Al Moubayed Samer, 2012, Cognitive Behavioural Systems (COST 2012). International Training School. Revised Selected Papers, P114, DOI 10.1007/978-3-642-34584-5_9
   Bourhis B., PHIL T R SOC B
   Chaminade T., 2017, INTERACTION STUDIES, V18
   Chaminade T, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011577
   Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893
   Nomura T, 2006, INTERACT STUD, V7, P437, DOI 10.1075/is.7.3.14nom
   Wykowska A, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0375
NR 7
TC 0
Z9 0
U1 0
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5953-5
PY 2018
BP 333
EP 335
DI 10.1145/3284432.3287177
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BL9NS
UT WOS:000457793300048
OA Green Published
DA 2022-08-02
ER

PT B
AU Mlakar, I
   Kacic, Z
   Rojc, M
AF Mlakar, Izidor
   Kacic, Zdravko
   Rojc, Matej
BE Rojc, M
   Campbell, N
TI TTS-driven Synthetic Behavior Generation Model for Embodied
   Conversational Agents
SO COVERBAL SYNCHRONY IN HUMAN-MACHINE INTERACTION
LA English
DT Article; Book Chapter
ID MARKUP LANGUAGE; SPEECH; ANIMATION; GESTURES; EXPRESSION
C1 [Mlakar, Izidor] Roboti Cs Doo, Maribor 2000, Slovenia.
   [Kacic, Zdravko; Rojc, Matej] Univ Maribor, Fac Elect Engn & Comp Sci, SLO-2000 Maribor, Slovenia.
RP Mlakar, I (corresponding author), Roboti Cs Doo, Trzaska Cesta 23, Maribor 2000, Slovenia.
EM izidor.mlakar@revolutionary-robotics.com; kacic@uni-mb.si;
   matej.rojc@uni-mb.si
RI Rojc, Matej/AAY-8563-2020
OI Rojc, Matej/0000-0002-2840-968X
CR ALLWOOD J, 2001, GOTHENBURG PAPERS TH, V85, P1
   Allwood J., 2007, CURRENT TRENDS RES S, V2, P10
   Allwood J, 2007, LANG RESOUR EVAL, V41, P273, DOI 10.1007/s10579-007-9061-5
   [Anonymous], 2000, LANGUAGE GESTURE, DOI DOI 10.1017/CB09780511620850.017
   Barbieri F, 2009, BRAIN LANG, V110, P1, DOI 10.1016/j.bandl.2009.01.002
   Bavelas JB, 2000, J LANG SOC PSYCHOL, V19, P163, DOI 10.1177/0261927X00019002001
   Bergmann K., 2008, S AISB ANN CONV MULT, P61
   Breslow L. A., 2010, P COGNITIVE MODELING, P13
   Cassell J, 2001, COMP GRAPH, P477
   Cerekovic A, 2011, MULTIMED TOOLS APPL, V54, P143, DOI 10.1007/s11042-010-0530-2
   De Carolis B, 2004, COG TECH, P65
   de Melo CM, 2008, STUD COMPUT INTELL, V140, P133
   Deacon T., 2003, LANGUAGE EVOLUTION, P111
   Esposito A, 2011, LECT NOTES COMPUT SC, V6800, P252, DOI 10.1007/978-3-642-25775-9_25
   GALLAHER PE, 1992, J PERS SOC PSYCHOL, V63, P133, DOI 10.1037/0022-3514.63.1.133
   Grenfell M., 2011, BOURDIEU LANGUAGE LI
   Hadar U, 1999, J NEUROLINGUIST, V12, P1, DOI 10.1016/S0911-6044(99)00001-9
   Heylen D, 2008, LECT NOTES COMPUT SC, V5208, P270
   Hogrefe K, 2011, GESTURE STUD, V4, P75
   Holler J, 2011, J NONVERBAL BEHAV, V35, P133, DOI 10.1007/s10919-011-0105-6
   Jokinen K, 2009, LECT NOTES COMPUT SC, V5615, P537, DOI 10.1007/978-3-642-02710-9_60
   Kendon A., 2004, GESTURE VISIBLE ACTI
   Kendon Adam, 2000, LANGUAGE GESTURE, P47, DOI DOI 10.1017/CBO9780511620850.004
   Kipp M, 2001, P WORKSH MULT COMM C, P9
   Kita S., 1998, Gesture and Sign Language in Human-Computer Interaction. International Gesture Workshop Proceedings, P23, DOI 10.1007/BFb0052986
   Kita S, 2003, J MEM LANG, V48, P16, DOI 10.1016/S0749-596X(02)00505-3
   Kita S, 2009, LANG COGNITIVE PROC, V24, P761, DOI 10.1080/01690960802327971
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   Kopp S, 2002, COMP ANIM CONF PROC, P252, DOI 10.1109/CA.2002.1017547
   Kopp S, 2006, LECT NOTES ARTIF INT, V4133, P205
   Kransted A., 2002, P AAMAS WORKSH EMB C
   Krenn B, 2011, COGN TECHNOL, P389, DOI 10.1007/978-3-642-15184-2_20
   Kroger BJ, 2010, COGN PROCESS, V11, P187, DOI 10.1007/s10339-009-0351-2
   Lankes M, 2011, ENTERTAIN COMPUT, V2, P29, DOI 10.1016/j.entcom.2011.03.007
   Loehr DP, 2004, THESIS GEORGETOWN U
   Luke KK, 2012, DISCOURSE PROCESS, V49, P155, DOI 10.1080/0163853X.2012.664110
   Malcangi M., 2010, INT J COMPUT, V4, P61
   McNeill D., 1992, HAND MIND WHAT GESTU
   McNeill D, 2005, GESTURE THOUGHT
   Mlakar Izidor, 2012, WSEAS Transactions on Computers, V11, P216
   Mlakar I, 2011, LECT NOTES COMPUT SC, V6800, P185, DOI 10.1007/978-3-642-25775-9_19
   Ng-Thow-Hing Victor, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P4617, DOI 10.1109/IROS.2010.5654322
   Peirce C. S., 1994, COLLECTED PAPERS CS
   Pelachaud C, 2005, GEST WORKSH
   Pine KJ, 2007, DEVELOPMENTAL SCI, V10, P747, DOI 10.1111/j.1467-7687.2007.00610.x
   Poggi I, 2005, TEXT SPEECH LANG TEC, V27, P3, DOI 10.1007/1-4020-3051-7_1
   Quoc Anh Le, 2011, 2011 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2011), P134, DOI 10.1109/Humanoids.2011.6100857
   Rojc Matej, 2011, Speech and Language Technologies, P129
   Rojc M, 2007, SPEECH COMMUN, V49, P230, DOI 10.1016/j.specom.2007.01.007
   Romportl J., 2010, P SSW7 KYOT JAP, P120
   Sargin ME, 2006, 2006 IEEE International Conference on Multimedia and Expo - ICME 2006, Vols 1-5, Proceedings, P893, DOI 10.1109/ICME.2006.262663
   Schegloff Emanuel., 1985, STRUCTURES SOCIAL AC, P266
   Straube B, 2011, HUM BRAIN MAPP, V32, P520, DOI 10.1002/hbm.21041
   Tang H, 2008, IEEE T MULTIMEDIA, V10, P969, DOI 10.1109/TMM.2008.2001355
   Thiebaux M., 2008, P 7 INT C AUTONOMOUS, V1, P151
   van Oijen Joost, 2012, Agents for Educational Games and Simulations. International Workshop, AEGS 2011. Revised Papers, P22, DOI 10.1007/978-3-642-32326-3_2
   Vilhjalmsson H, 2007, LECT NOTES ARTIF INT, V4722, P99
   Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W
   Wang L., 2011, INTERSPEECH, P3307
   Zone G., 2008, P INT C AUD VIS SPEE
   Zschorn A., 2011, P AUSTR LANG TECHN A, P166
NR 61
TC 1
Z9 1
U1 0
U2 0
PU CRC PRESS-TAYLOR & FRANCIS GROUP
PI BOCA RATON
PA 6000 BROKEN SOUND PARKWAY NW, STE 300, BOCA RATON, FL 33487-2742 USA
BN 978-1-4665-9826-3; 978-1-4665-9825-6
PY 2014
BP 325
EP 359
PG 35
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Theory & Methods
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BC5KM
UT WOS:000353347800014
DA 2022-08-02
ER

PT J
AU Pilato, G
   Augello, A
   Gaglio, S
AF Pilato, Giovanni
   Augello, Agnese
   Gaglio, Salvatore
TI MODULAR KNOWLEDGE REPRESENTATION IN ADVISOR AGENTS FOR SITUATION
   AWARENESS
SO INTERNATIONAL JOURNAL OF SEMANTIC COMPUTING
LA English
DT Article
DE Situation awareness; conversational agents; decision support systems
AB A modular knowledge representation framework for conversational agents is presented. The approach has been realized to suit the situation awareness paradigm. The modularity of the framework makes possible the composition of specific modules that deal with particular features, simplifying both the chatbot design process and its smartness. As a proof of concepts we have developed a modular, situation awareness oriented, KB for a conversational agent, which plays the role of an advisor aimed at helping a user to be in charge of a virtual town, inspired to the SimCity series game. The agent makes an extensive use of semantic computing techniques and is able to perceive, comprehend and project consequences of actions in order to handle strategic decision under uncertainty conditions.
C1 [Pilato, Giovanni] Italian Natl Res Council Viale Sci, ICAR, Viale Scienze,Ed 11, I-90128 Palermo, Italy.
   [Augello, Agnese; Gaglio, Salvatore] Univ Palermo, DINFO, I-90128 Palermo, Italy.
RP Pilato, G (corresponding author), Italian Natl Res Council Viale Sci, ICAR, Viale Scienze,Ed 11, I-90128 Palermo, Italy.
EM giovanni.pilato@cnr.it; augello@dinfo.unipa.it; gaglio@unipa.it
RI Pilato, Giovanni/I-7516-2013; Augello, Agnese/AAX-7395-2020
OI Pilato, Giovanni/0000-0002-6254-2249; Augello,
   Agnese/0000-0001-6463-9151
FU Italian MIUR (Ministero dell'Istruzione, dell'Universita' e della
   Ricerca) within the FRASI "FRamework for Agent-based Semantic-aware
   Interoperability" project
FX This work has been partially supported by Italian MIUR (Ministero
   dell'Istruzione, dell'Universita' e della Ricerca) within the FRASI
   "FRamework for Agent-based Semantic-aware Interoperability" project. The
   authors would like to thank Mario Scriminaci for his partial
   contribution to the implementation phase.
CR Agostaro F, 2005, CAMP 2005: Seventh International Workshop on Computer Architecture for Machine Perception , Proceedings, P321
   Augello A., 2009, 3 IEEE INT C SEM COM
   Buford J., 2006, 9 INT C INF FUS 10 1, P1, DOI [10.1109/ICIF.2006.301781, DOI 10.1109/ICIF.2006.301781]
   Endsley M. R., 2000, SITUATION AWARENESS, P332
   Fenza G., 2010, INT C COMPL INT SOFT, P1057
   Kwang-Eun Ko, 2008, 2008 International Conference on Control, Automation and Systems (ICCAS), P2309, DOI 10.1109/ICCAS.2008.4694191
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211
   Lowe W., 2001, P 23 ANN C COGN SCI, P576
   Luo LB, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P360, DOI 10.1109/CW.2010.61
   Matheus CJ, 2003, FUSION 2003: PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE OF INFORMATION FUSION, VOLS 1 AND 2, P545
   Miguelanez E, 2011, IEEE T KNOWL DATA EN, V23, P759, DOI 10.1109/TKDE.2010.46
   RAO A, 1995, P 1 INT C MULT SYST
   Roman M., 2002, IEEE Pervasive Computing, V1, P74, DOI 10.1109/MPRV.2002.1158281
   Sahlgren M., 2006, WORD SPACE MODEL USI
   Smart P. R., 1 ANN C INT TECHN AL
   Wooldridge M, 2000, MULTIAGENT SYSTEMS M
   Yau SS, 2006, P INT COMP SOFTW APP, P503
   Yu QX, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P119
NR 19
TC 1
Z9 1
U1 0
U2 2
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 1793-351X
EI 1793-7108
J9 INT J SEMANT COMPUT
JI Int. J. Semant. Comput.
PD MAR
PY 2011
VL 5
IS 1
BP 33
EP 53
DI 10.1142/S1793351X11001158
PG 21
WC Computer Science, Artificial Intelligence
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA V10SV
UT WOS:000214231200002
DA 2022-08-02
ER

PT J
AU Rooein, D
   Bianchini, D
   Leotta, F
   Mecella, M
   Paolini, P
   Pernici, B
AF Rooein, Donya
   Bianchini, Devis
   Leotta, Francesco
   Mecella, Massimo
   Paolini, Paolo
   Pernici, Barbara
TI aCHAT-WF: Generating conversational agents for teaching business process
   models
SO SOFTWARE AND SYSTEMS MODELING
LA English
DT Article
DE Chatbot; Business process; BPMN; Digital transformation; Configuration
   driven; Educational conversational agent
AB This paper proposes a general approach for using conversational interfaces such as chatbots to offer adaptive learning of business processes in an environment involving different actors. Adaptivity concerns both the content being proposed, the sequence of learning items, and the way the conversation is conducted. The original approach allows the development of sustainable chatbots and empowers various non-technical actors (authors, teachers, publishers, and learners) to control the chatbot features directly. The aCHAT-WF framework (adaptive CHATbot for WorkFlows), proposed in this paper for managing conversational interfaces, conceptually represents all the aspects related to a conversation about business processes, with different facets for the user, the conversation flow, and the conversation contents, combining them to obtain a flexible interaction with the user. The paper focuses on the different preparation phases for instructional material based on Business Process Modeling Notation (BPMN) models, separating the different roles involved in the construction of a chatbot for teaching business processes and with the possibility of defining different styles for the interaction with the users. The proposed method is configuration-driven, to facilitate the separation of the different aspects of the control of the interaction and the delivery of contents.
C1 [Rooein, Donya] Politecn Milan, Informat Technol Engn, Milan, Italy.
   [Paolini, Paolo] Politecn Milan, HOCLAB, Milan, Italy.
   [Pernici, Barbara] Politecn Milan, Comp Engn, Milan, Italy.
   [Bianchini, Devis] Univ Brescia, Dept Informat Engn, Brescia, Italy.
   [Leotta, Francesco] Sapienza Univ Roma, Dept Comp Control & Management Engn, Rome, Italy.
   [Mecella, Massimo] Sapienza Univ Roma, Rome, Italy.
RP Rooein, D (corresponding author), Politecn Milan, Informat Technol Engn, Milan, Italy.
EM donya.rooein@polimi.it; devis.bianchini@unibs.it;
   leotta@diag.uniroma1.it; Mecella@diag.uniroma1.it;
   paolo.paolini@polimi.it; barbara.pernici@polimi.it
RI Pernici, Barbara/C-1035-2016
OI Pernici, Barbara/0000-0002-2034-9774
FU EIT Digital; EU H2020-RISE project FIRST; Smart4CPPS Lombardy Region
   project; EU H2020-WIDESPREAD project DESTINI; IBM
FX The work of Donya Rooein has been supported by EIT Digital and IBM. The
   work of Francesco Leotta and Massimo Mecella has been supported by the
   EU H2020-RISE project FIRST and the EU H2020-WIDESPREAD project DESTINI.
   The work of Devis Bianchini has been supported by Smart4CPPS Lombardy
   Region project. This work expresses the opinions of the authors and not
   necessarily those of the funding agencies and companies.
CR Al-Zubaide H., 2011, 2011 Fourth International Symposium on Innovation in Information & Communication Technology (ISIICT), P7, DOI 10.1109/ISIICT.2011.6149594
   Baeriswyl M., 2018, IJCAI 18
   Bicocchi N, 2019, J IND INF INTEGR, V15, P111, DOI 10.1016/j.jii.2019.02.001
   Burattin A, 2019, 17 INT C BUS PROC MA, P144
   Catarci, 2017, INT C WEB ENG, P156
   Catarci T, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES (IEEE ICWS 2019), P229, DOI 10.1109/ICWS.2019.00047
   Chandar P, 2017, LECT NOTES COMPUT SC, V10514, P381, DOI 10.1007/978-3-319-67684-5_23
   Dabbous A, 2019, IADIS INT J WWW INTE, V17
   Di Blas N, 2012, INT J ARTS TECHNOL, V5, P271
   Doan A, 2018, HILDA'18: PROCEEDINGS OF THE WORKSHOP ON HUMAN-IN-THE-LOOP DATA ANALYTICS, DOI 10.1145/3209900.3209913
   Frank AG, 2019, TECHNOL FORECAST SOC, V141, P341, DOI 10.1016/j.techfore.2019.01.014
   Heilman M, 2009, CMU
   Hermann M, 2016, P ANN HICSS, P3928, DOI 10.1109/HICSS.2016.488
   Holotescu C., 2016, MOOCBUDDY CHATBOT PE, V91, P94
   Kalia A. K., 2017, INT C SERV OR COMP, P53
   Lohse M, 2020, UK ROB AUT SYST C UK
   Lopez A, 2019, LECT NOTES COMPUT SC, V11483, P383, DOI 10.1007/978-3-030-21290-2_24
   Mantravadi S, 2020, LECT NOTES ARTIF INT, V12034, P189, DOI 10.1007/978-3-030-42058-1_16
   McTear M., 2018, STUDIENTEXTE SPRACHK, P175
   Moore RJ, 2018, HUM-COMPUT INT-SPRIN, P181, DOI 10.1007/978-3-319-95579-7_9
   Moormann J, 2012, KNOWL MANAG E-LEARN, V4, P390
   Paek T, 2008, SPEECH COMMUN, V50, P716, DOI 10.1016/j.specom.2008.03.010
   Pelagatti G., 2018, SOC INF TECHN TEACH, P110
   Pichponreay L, 2016, INT CONF UBIQ FUTUR, P1002, DOI 10.1109/ICUFN.2016.7536948
   Polyvyanyy A., 2015, HDB BUSINESS PROCESS, V1, P147, DOI DOI 10.1007/978-3-642-45100-37
   Rabelo RJ, 2018, IFIP ADV INF COMM TE, V536, P456, DOI 10.1007/978-3-319-99707-0_57
   Rahman AM, 2017, IEEE REG 10 HUMANIT, P75, DOI 10.1109/R10-HTC.2017.8288910
   Romero D, 2016, P INT C COMP IND ENG, P29
   Rooein Donya, 2020, Enterprise, Business-Process and Information Systems Modeling. 21st International Conference, BPMDS 2020, 25th International Conference, EMMSAD 2020. Held at CAiSE 2020. Proceedings. Lecture Notes in Business Information Processing (LNBIP 387), P70, DOI 10.1007/978-3-030-49418-6_5
   Tegos S., 2019, INT WORKSH CHATB RES, P245
   Visnjic I, 2019, J PROD INNOVAT MANAG, V36, P381, DOI 10.1111/jpim.12483
NR 31
TC 0
Z9 0
U1 5
U2 7
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1619-1366
EI 1619-1374
J9 SOFTW SYST MODEL
JI Softw. Syst. Model.
PD JUN
PY 2022
VL 21
IS 3
BP 891
EP 914
DI 10.1007/s10270-021-00925-7
EA OCT 2021
PG 24
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0U0DM
UT WOS:000704965600001
OA Green Published, hybrid
DA 2022-08-02
ER

PT J
AU Yamashita, K
   Kubota, H
   Nishida, T
AF Yamashita, Koji
   Kubota, Hidekazu
   Nishida, Toyoaki
TI Designing conversational agents: effect of conversational form on our
   comprehension
SO AI & SOCIETY
LA English
DT Article
DE Agents; Information providing; Conversational form Comprehension;
   Evaluative study
AB We have developed a broadcasting agent system, public opinion channel (POC) caster, which generates understandable conversational form from text-based documents. The POC caster circulates the opinions of community members by using conversational form in a broadcasting system on the Internet. We evaluated its transformation rules in two experiments. In experiment 1, we examined our transformation rules for conversational form in relation to sentence length. Twenty-four participants listened to two types of sentence (long sentences and short sentences) with conversational form or with single speech. In experiment 2, we investigated the relationship between conversational form and the user's knowledge level. Forty-two participants (21 with a high knowledge level and 21 with a low knowledge level) were selected for a knowledge task and listened to two kinds of sentence (sentences about a well-known topic or sentences about an unfamiliar topic). Our results indicate that the conversational form aided comprehension, especially for long sentences and when users had little knowledge about the topic. We explore possible explanations and implications of these results with regard to human cognition and text comprehension.
C1 [Yamashita, Koji] Natl Inst Informat & Commun Technol, Keihanna Human Infocommun Res Ctr, Soraku, 3-5 Hikaridai, Kyoto 6190289, Japan.
   [Kubota, Hidekazu; Nishida, Toyoaki] Kyoto Univ, Grad Sch Informat, Sakyo Ku, Kyoto 6068501, Japan.
RP Yamashita, K (corresponding author), Natl Inst Informat & Commun Technol, Keihanna Human Infocommun Res Ctr, Soraku, 3-5 Hikaridai, Kyoto 6190289, Japan.
EM koji@nict.go.jp
CR Ausubel D. P., 1963, PSYCHOL MEANINGFUL V
   AUSUBEL DP, 1978, REV EDUC RES, V48, P251, DOI 10.2307/1170083
   Azechi S, 2000, LECT NOTES COMPUT SC, V1765, P427
   BRANSFORD JD, 1972, J VERB LEARN VERB BE, V11, P717, DOI 10.1016/S0022-5371(72)80006-9
   BROMAGE BK, 1986, J EDUC PSYCHOL, V78, P271
   Cassell J, 2000, EMBODIED CONVERSATIONAL AGENTS, P29
   Fukuhara T, 2003, COMMUNITIES AND TECHNOLOGIES, P347
   KINTCH W, 1998, COMPREHENSION PARADI
   KUBOTA H, 2002, FRONTIERS ARTIFICI 2, V4, P1326
   Kubota H, 2002, T JAPANESE SOC ARTIF, V17, P313
   Mayer RE, 2003, J EDUC PSYCHOL, V95, P806, DOI 10.1037/0022-0663.95.4.806
   Moreno R, 2002, J EDUC PSYCHOL, V94, P598, DOI 10.1037//0022-0663.94.3.598
   Moreno R, 2001, COGNITION INSTRUCT, V19, P177, DOI 10.1207/S1532690XCI1902_02
   Nishida T, 1999, NEW GENERAT COMPUT, V17, P417, DOI 10.1007/BF03037247
   PITCHERT JW, 1977, J EDUC PSYCHOL, V69, P309
   Rickel J., 1998, Proceedings of the Second International Conference on Autonomous Agents, P332, DOI 10.1145/280765.280851
   van Dijk T. A., 1983, STRATEGIES DISCOURSE
   WADDILL PJ, 1988, J EDUC PSYCHOL, V80, P457, DOI 10.1037/0022-0663.80.4.457
NR 18
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0951-5666
EI 1435-5655
J9 AI SOC
JI AI Soc.
PD MAR
PY 2006
VL 20
IS 2
BP 125
EP 137
DI 10.1007/s00146-005-0011-8
PG 13
WC Computer Science, Artificial Intelligence
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA V64FE
UT WOS:000211086100002
DA 2022-08-02
ER

PT C
AU Weisz, JD
   Jain, M
   Joshi, NN
   Johnson, J
   Lange, I
AF Weisz, Justin D.
   Jain, Mohit
   Joshi, Narendra Nath
   Johnson, James
   Lange, Ingrid
GP Assoc Comp Machinery
TI BigBlueBot: Teaching Strategies for Successful Human-Agent Interactions
SO PROCEEDINGS OF IUI 2019
LA English
DT Proceedings Paper
CT 24th ACM International Conference on Intelligent User Interfaces (IUI)
CY MAR 16-20, 2019
CL Los Angeles, CA
SP Assoc Comp Machinery
DE Explainable AI; conversational agents; Mechanical Turk
AB Chatbots are becoming quite popular, with many brands developing conversational experiences using platforms such as IBM's Watson Assistant and Facebook Messenger. However, previous research reveals that users' expectations of what conversational agents can understand and do far outpace their actual technical capabilities. Our work seeks to bridge the gap between these expectations and reality by designing a fun learning experience with several goals: explaining how chatbots work by mapping utterances to a set of intents, teaching strategies for avoiding conversational breakdowns, and increasing desire to use chatbots by creating feelings of empathy toward them. Our experience, called BigBlueBot, consists of interactions with two chatbots in which breakdowns occur and the user (or chatbot) must recover using one or more repair strategies. In a Mechanical Turk evaluation (N=88), participants learned strategies for having successful human-agent interactions, reported feelings of empathy toward the chatbots, and expressed a desire to interact with chatbots in the future.
C1 [Weisz, Justin D.] IBM Res AI, Yorktown Hts, NY 10598 USA.
   [Jain, Mohit] IBM Res, Bangalore, Karnataka, India.
   [Joshi, Narendra Nath; Johnson, James; Lange, Ingrid] IBM Res AI, Cambridge, MA USA.
RP Weisz, JD (corresponding author), IBM Res AI, Yorktown Hts, NY 10598 USA.
EM jweisz@us.ibm.com; mohitjain@in.ibm.com; Narendra.Nath.Joshi@ibm.com;
   jmjohnson@us.ibm.com; Ingrid.Lange@ibm.com
OI Weisz, Justin/0000-0003-2228-2398
CR Abdul A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174156
   [Anonymous], 2014, EXPERIENTIAL LEARNIN
   Ashktorab Zahra, 2019, P 2019 CHI C HUM FAC
   Barocas Solon, 2018, FAT ML WORKSHOP SERI
   Bohus Dan, 2003, INTERSPEECH
   Chen ML, 2018, COMPANION OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'18), DOI 10.1145/3180308.3180362
   Clark Herbert H., 1991, PERSPECT SOC SHARED, P127, DOI DOI 10.1037/10096-006
   Elo S, 2008, J ADV NURS, V62, P107, DOI 10.1111/j.1365-2648.2007.04569.x
   Goodnow Jacqueline J., 1967, STUDY THINKING
   Grech M., 2017, CURRENT STATE CHATBO
   Gunning D., 2017, XAI
   IBM, 2018, WATS AI ASS
   IBM, 2018, BIGBLUEBOT
   Jain Mohit, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3287048
   Jain M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174042
   Jain M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P895, DOI 10.1145/3196709.3196735
   Janssen JH, 2012, J MULTIMODAL USER IN, V6, P143, DOI 10.1007/s12193-012-0097-5
   Jiang JP, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P506, DOI 10.1145/2736277.2741669
   Kwak S.S., 2013, 2013 IEEE ROMAN, P180, DOI DOI 10.1109/ROMAN.2013.6628441
   Lewis L.H., 1994, EXPERIENTIAL LEARNIN, DOI [DOI 10.1002/ACE.36719946203, 10.1002/ACE.36719946203]
   LIAO QV, 2016, P 2016 ACM C DES INT, P264, DOI DOI 10.1145/2901790.2901842
   Liao Vera Q., 2018, P 2018 CHI C HUM FAC, P13
   Licklider J. C. R., 1960, IRE T HUM FACT ELECT, P4
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Martin Carlos Garcia, 2014, FACTORS MIGHT AFFECT
   Novak JD, 2002, SCI EDUC, V86, P548, DOI 10.1002/sce.10032
   Paiva A, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2912150
   Porcheron M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174214
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Rosenfeld R., 2001, Interactions, V8, P34, DOI 10.1145/384076.384085
   Sandbank Tommy, 2018, C N AM CHAPTER ASS C, P1802, DOI [10.18653/v1/N18- 1163, DOI 10.18653/V1/N18-1163]
   SCIUTO A, 2018, P 2018 DES INT SYST, P857, DOI DOI 10.1145/3196709.3196772
   Scott P., 2007, HDB RES SCI ED, P31
   Seo SH, 2015, ACMIEEE INT CONF HUM, P125, DOI 10.1145/2696454.2696471
   Shneiderman B., 2016, INTERACTION, V23, P24, DOI [10.1145/2977645, DOI 10.1145/2977645]
   Skantze Gabriel, 2003, P ISCA TUT RES WORKS, P71
   Thies Indrani M, 2017, P INT C HUM COMP INT, P20
   Valerio Francisco AM, 2017, P 16 BRAZ S HUM FACT, P28
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Wen Tsung-Hsien, 2015, CORR
   Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496
   YANG L, 2013, P 2013 ACM INT JOINT, P93, DOI DOI 10.1145/2493432.2493489
   Yaniv D, 2012, REV GEN PSYCHOL, V16, P70, DOI 10.1037/a0026580
   Young S, 1996, IEEE SIGNAL PROC MAG, V13, P45, DOI 10.1109/79.536824
NR 44
TC 9
Z9 9
U1 5
U2 9
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6272-6
PY 2019
BP 448
EP 459
DI 10.1145/3301275.3302290
PG 12
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BN3ZO
UT WOS:000481595500048
DA 2022-08-02
ER

PT J
AU Cebrian, J
   Martinez, R
   Rodriguez, N
   D'Haro, LF
AF Cebrian, Javier
   Martinez, Ramon
   Rodriguez, Natalia
   Fernando D'Haro, Luis
TI Considerations on creating conversational agents for multiple
   environments and users
SO AI MAGAZINE
LA English
DT Article
ID SPEECH RECOGNITION; ADAPTATION; CHATBOTS; SYSTEMS
AB Advances in artificial intelligence algorithms and expansion of straightforward cloud-based platforms have enabled the adoption of conversational assistants by both, medium and large companies, to facilitate interaction between clients and employees. The interactions are possible through the use of ubiquitous devices (e.g., Amazon Echo, Apple HomePod, Google Nest), virtual assistants (e.g., Apple Siri, Google Assistant, Samsung Bixby, or Microsoft Cortana), chat windows on the corporate website, or social network applications (e.g. Facebook Messenger, Telegram, Slack, WeChat). Creating a useful, personalized conversational agent that is also robust and pop-ular is nonetheless challenging work. It requires picking the right algorithm, framework, and/or communication channel, but perhaps more importantly, con-sideration of the specific task, user needs, environment, available training data, budget, and a thoughtful design. In this paper, we will consider the elements necessary to create a conversational agent for different types of users, environments, and tasks. The elements will account for the limited amount of data available for specific tasks within a com-pany and for non-English languages. We are confident that we can provide a useful resource for the new practitioner developing an agent. We can point out novice problems/traps to avoid, create consciousness that the development of the technology is achievable despite comprehensive and significant challenges, and raise awareness about different ethical issues that may be associated with this technology. We have compiled our experience with deploying conversational sys-tems for daily use in multicultural, multilingual, and intergenerational settings. Additionally, we will give insight on how to scale the proposed solutions.
C1 [Cebrian, Javier; Martinez, Ramon; Rodriguez, Natalia] Saturn Labs, Madrid 28670, Spain.
   [Fernando D'Haro, Luis] Univ Politecn Madrid, ETSI Telecomunicac, Madrid, Spain.
RP Cebrian, J (corresponding author), Saturn Labs, Madrid 28670, Spain.; D'Haro, LF (corresponding author), Univ Politecn Madrid, ETSI Telecomunicac, Madrid, Spain.
EM javier@saturnolabs.com; luisfernando.dharo@upm.es
FU AMIC (MINECO) - European Union [TIN2017-85854-C4-4-R]; CAVIAR (MINECO) -
   European Union [TEC2017-84593-C2-1-R]
FX We specially thank the reviewers for their important and insightful
   comments to improve this paper. In addi-tion, we want to thank Erikka
   Baehring and Kheng Hui Yeo for their deep proof-reading and
   contributions to make this paper clear and suitable for a wider
   audience. This paper has been supported by the following projects: AMIC
   (MINECO, TIN2017-85854-C4-4-R) and CAVIAR (MINECO, TEC2017-84593-C2-1-R)
   partially funded by the European Union.
CR AISB, 2020, SOC STUD ART INT SIM
   Andor D, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2442
   [Anonymous], 2019, P INTERSPEECH, DOI 10.21437/Interspeech.2019-2680
   Arsovski S, 2018, INT J ADV COMPUT SC, V9, P402
   Bacchiani M., 2017, NEW ERA ROBUST SPEEC, P385, DOI DOI 10.1007/978-3-319-64680-0_18
   Barker J. P., 2017, NEW ERA ROBUST SPEEC, P327, DOI DOI 10.1007/978-3-319-64680-0_14
   Besacier L, 2014, SPEECH COMMUN, V56, P85, DOI 10.1016/j.specom.2013.07.008
   Brown T.B., 2020, ADV NEURAL INF PROCE
   Cahn J., 2017, THESIS CHATBOT
   Cheng Y., 2017, ARXIV171009282
   Chiu CC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4774, DOI 10.1109/ICASSP.2018.8462105
   Cohen M. H., 2004, VOICE USER INTERFACE
   Coughlan T., 2020, P 17 INT WEB ALL C, P1
   D'Haro LF, 2016, INTERSPEECH, P3469, DOI 10.21437/Interspeech.2016-299
   Dathathri S, 2020, INT C LEARN REPR
   Deriu J., 2019, ARXIV PREPRINT ARXIV
   Devlin J., 2018, ARXIV
   Di Prospero A., 2017, P 27 ANN INT C COMP, P76
   Dinan E., 2019, ARXIV PREPRINT ARXIV
   Donahue C, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5024, DOI 10.1109/ICASSP.2018.8462581
   Du Wenchao, 2018, P 2 INT WORKSH SEARC, P52
   Duijst Danielle, 2017, THESIS U AMSTERDAM
   El Shafey Laurent, 2019, INTERSPEECH, P396, DOI DOI 10.21437/INTERSPEECH.2019-1943
   Enge E., 2019, PERFICIENT DIGITAL
   Fadaee M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P567, DOI 10.18653/v1/P17-2090
   D'Haro LF, 2019, COMPUT SPEECH LANG, V55, P200, DOI 10.1016/j.csl.2018.12.004
   Folstad A., 2017, INTERACTIONS, V24, P38, DOI [10.1145/3085558, DOI 10.1145/3085558]
   Folstad Asbjorn, 2020, QUAL USER EXP, V5, P1, DOI [10.1007/s41233-020-00033-2, DOI 10.1007/S41233-020-00033-2]
   Gupta I, 2017, 2017 INTERNATIONAL CONFERENCE ON INFOCOM TECHNOLOGIES AND UNMANNED SYSTEMS (TRENDS AND FUTURE DIRECTIONS) (ICTUS), P157
   Gupta K, 2016, 2016 6th International Conference - Cloud System and Big Data Engineering (Confluence), P493, DOI 10.1109/CONFLUENCE.2016.7508170
   He J, 2017, IEEE DATA MINING, P147, DOI 10.1109/ICDM.2017.24
   Henderson M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5392
   Henderson Matthew, 2019, ARXIV PREPRINT ARXIV
   Henderson P, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P123, DOI 10.1145/3278721.3278777
   Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685
   Hongshen Chen, 2017, ACM SIGKDD Explorations Newsletter, V19, P25, DOI 10.1145/3166054.3166058
   Hou Y, 2018, P COLING, P1234
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/685404
   Ischen C., 2019, INT WORKSH CHATB RES, P34
   Jurafsky D., 2020, SPEECH LANGUAGE PROC, V3rd
   Kaczorowska-Spychalska D, 2019, MANAG-POL, V23, P251, DOI 10.2478/manment-2019-0015
   Kang Y., 2018, PROC C N AM CHAPTER, V3, P33
   Karjol P, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5049, DOI 10.1109/ICASSP.2018.8462649
   Katz S, 2019, CHATBOTS MAGAZINE
   Keskar N. S., 2019, CTRL CONDITIONAL TRA
   Kester Yuwono Steven, 2019, 9th International Workshop on Spoken Dialogue System Technology. Lecture Notes in Electrical Engineering (LNEE 579), P357, DOI 10.1007/978-981-13-9443-0_31
   Khoubrouy SA, 2016, IEEE SIGNAL PROC LET, V23, P1344, DOI 10.1109/LSP.2016.2592683
   Khouzaimi H, 2018, COMPUT SPEECH LANG, V47, P93, DOI 10.1016/j.csl.2017.07.006
   Ko T, 2017, INT CONF ACOUST SPEE, P5220, DOI 10.1109/ICASSP.2017.7953152
   Kocielnik R, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P881, DOI 10.1145/3196709.3196784
   Kong-Vega Naomi, 2019, 9th International Workshop on Spoken Dialogue System Technology. Lecture Notes in Electrical Engineering (LNEE 579), P371, DOI 10.1007/978-981-13-9443-0_32
   Kostelnik P., 2019, ACTA UNIV SIL MEND B, V67, P1541, DOI DOI 10.11118/actaun201967061541
   Kurachi Y, 2018, FUJITSU SCI TECH J, V54, P2
   Li K, 2018, INTERSPEECH, P3373, DOI 10.21437/Interspeech.2018-1413
   Li SS, 2019, INTERACT COMPUT, V31, P1, DOI 10.1093/iwc/iwz001
   Li XB, 2017, INFORM SYST RES, V28, P332, DOI 10.1287/isre.2016.0676
   Litman DJ, 1999, P 37 ANN M ASS COMP
   Liu H., 2019, P 28 INT C COMP LING, P4403
   Liu Xingkun, 2019, ABS190305566 ARXIV
   Lopez-Cozar R, 2014, LOQUENS, V1, DOI 10.3989/loquens.2014.012
   Mani A, 2020, INT CONF ACOUST SPEE, P6344, DOI 10.1109/ICASSP40776.2020.9053126
   McTear M. F., 2016, CONVERSATIONAL INTER, V6, P102
   Mehri S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P681
   Nuruzzaman M, 2018, INT CONF E BUS ENG, P54, DOI 10.1109/ICEBE.2018.00019
   Ondas S, 2018, INT CONF COGN INFO, P117, DOI 10.1109/CogInfoCom.2018.8639886
   Polino A., 2018, ARXIV180205668
   Ramesh K, 2017, COMM COM INF SC, V750, P336, DOI 10.1007/978-981-10-6544-6_31
   Ray A., 2018, INT C COMP NETW BIG, P156
   Reddy T., 2017, CODE ETHICS AI CHATB
   Ruan Sherry, 2018, PROC ACM INTERACT MO, V1, DOI [10.1145/3161187, DOI 10.1145/3161187]
   Ruane E., 2019, CONVERSATIONAL AI SO
   Ruder S., 2019, P 2019 C N AM CHAPT, DOI [10.18653/v1/N19-5004, 10.18653/v1/n19-5004]
   Saglam R. B., 2020, P 2 C CONV US INT, P1
   Samanta S, 2017, ARXIV170702812
   Sarkar D, 2018, DATA SCI BLOG
   Schultz T., 2006, MULTILINGUAL SPEECH, V1, P1
   See A, 2019, P 2019 C N AM CHAPT, V1, P1702, DOI DOI 10.18653/V1/N19-1170.HTTPS://WWW.ACLWEB.0RG/ANTH0L0GY/N19-1170
   Seki H, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2620
   Serban I.V., 2015, ARXIV151205742
   Serizel R, 2017, NAT LANG ENG, V23, P325, DOI 10.1017/S135132491600005X
   Shanbhag A, 2020, 5 CHATBOT CODE ETHIC
   Smestad T. L., 2018, THESIS NTNU
   Song YP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4382
   Sproat R, 2016, RNN APPROACHES TEXT
   Tammewar A., 2018, WORKSH 32 AAAI C ART
   Tao CY, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P722
   Vanian J., 2019, FORTUNE
   Vasserman L, 2016, IEEE W SP LANG TECH, P441, DOI 10.1109/SLT.2016.7846301
   Vaswani A, 2017, ADV NEUR IN, V30
   Wieting J., 2017, ARXIV PREPRINT ARXIV
   Wolf M. J., 2017, ACM SIGCAS Computers and Society, V47, P54, DOI 10.1145/3144592.3144598
   Worswick S, 2019, MITSUKU WINS LOEBNER
   Wu J., 2019, OPENAI BLOG TECH REP, V1, P1
   Ye Yuan, 2019, International Journal of Child-Computer Interaction, V21, P77, DOI 10.1016/j.ijcci.2019.04.005
   Young S, 2002, CUEDFINFENGTR433
   Zhang C., 2020, DEEP AM FM TOOLK AUT
NR 96
TC 0
Z9 0
U1 3
U2 3
PU AMER ASSOC ARTIFICIAL INTELL
PI MENLO PK
PA 445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA
SN 0738-4602
EI 2371-9621
J9 AI MAG
JI AI Mag.
PY 2021
VL 42
IS 2
BP 71
EP 86
DI 10.1609/aaai.12007
PG 16
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YL9FS
UT WOS:000746192100001
DA 2022-08-02
ER

PT J
AU May, R
   Denecke, K
AF May, Richard
   Denecke, Kerstin
TI Security, privacy, and healthcare-related conversational agents: a
   scoping review
SO INFORMATICS FOR HEALTH & SOCIAL CARE
LA English
DT Review
DE Healthcare; chatbots; conversational user interfaces; data security;
   data privacy
ID CHAT-BOT; MANAGEMENT
AB Health chatbots interview patients and collect health data. This process makes demands on data security and data privacy. To identify how and to what extent security and privacy are considered in current health chatbots. We conducted a scoping review by searching three bibliographic databases (PubMed, ACM Digital Library, IEEExplore) for papers reporting on chatbots in healthcare. We extracted which, how, and where data is stored by health chatbots and identified which external services have access to the data. Out of 1026 retrieved papers, we included 70 studies in the qualitative synthesis. Most papers report on chatbots that collect and process personal health data, usually in the context of mental health coaching applications. The majority did not provide any information regarding security or privacy aspects. We were able to determine limitations in literature and identified concrete challenges, including data access and usage of (third-party) services, data storage, data security methods, use case peculiarities and data privacy, as well as legal requirements. Data privacy and security in health chatbots are still underresearched and related information is underrepresented in scientific literature. By addressing the five key challenges in future, the transfer of theoretical solutions into practice can be facilitated.
C1 [May, Richard] Harz Univ Appl Sci, Fac Automat & Comp Sci, Wernigerode, Germany.
   [Denecke, Kerstin] Bern Univ Appl Sci, Inst Med Informat, Biel, Switzerland.
RP Denecke, K (corresponding author), Bern Univ Appl Sci, Biel, Switzerland.
EM kerstin.denecke@bfh.ch
OI May, Richard/0000-0001-7186-404X
CR Ahmad NS, 2018, IEEE CONF OPEN SYST, P76, DOI 10.1109/ICOS.2018.8632700
   Albrecht J., 2016, LAW REV, V2, p287 , DOI [DOI 10.21552/EDPL/2016/3/4, 10.21552/EDPL/2016/3/4]
   Amini R, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI 2013), P46, DOI 10.1109/ICHI.2013.13
   Arksey H., 2005, INT J SOC RES METHOD, V8, P19, DOI [DOI 10.1080/1364557032000119616, DOI 10.1002/pd.5102, 10.1080/1364557032000119616]
   Auriacombe M, 2018, DRUG ALCOHOL DEPEN, V193, P1, DOI 10.1016/j.drugalcdep.2018.08.025
   Avila-Tomas JF, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0972-z
   Ayoade G, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P15, DOI 10.1109/IRI.2018.00011
   Baptista S, 2020, DIABETES TECHNOL THE, V22, pA221
   Battineni G, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8020154
   Bharti Urmil, 2020, 2020 5th International Conference on Communication and Electronics Systems (ICCES). Proceedings, P870, DOI 10.1109/ICCES48766.2020.9137944
   Bhirud N, 2019, INT J SCI TECHNOL RE, V8, P225
   Bickmore TW, 2010, INTERACT COMPUT, V22, P289, DOI 10.1016/j.intcom.2009.12.001
   Brauch HG., 2011, COPING GLOBAL ENV CH, P61, DOI DOI 10.1007/978-3-642-17776-7_2
   Bruno Marietto M., 2013, ARXIV201313073091, DOI DOI 10.5121/IJCSES.2013.4301
   Chetlen A, 2019, J AM COLL RADIOL, V16, P1305, DOI 10.1016/j.jacr.2019.05.050
   Chowdhury MJM, 2018, IEEE TRUST BIG, P1348, DOI 10.1109/TrustCom/BigDataSE.2018.00186
   Cofre K, 2020, IBER CONF INF SYST
   Cooper A, 2018, STUD HEALTH TECHNOL, V252, P63, DOI 10.3233/978-1-61499-890-7-63
   Coss D., 2014, J INFORM SYSTEM SECU, V10, P21
   Costan Victor, 2016, IACR CIYPTOL EPRINT, V2016, P1, DOI DOI 10.1159/000088809
   Crutzen R, 2011, J ADOLESCENT HEALTH, V48, P514, DOI 10.1016/j.jadohealth.2010.09.002
   de Gennaro M, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.03061
   Denecke K, 2021, IEEE T EMERG TOP COM, V9, P1170, DOI 10.1109/TETC.2020.2974478
   Denecke K, 2019, STUD HEALTH TECHNOL, V264, P1164, DOI 10.3233/SHTI190409
   Denecke Kerstin, 2019, Stud Health Technol Inform, V259, P77
   Denecke K, 2018, METHOD INFORM MED, V57, P243, DOI 10.1055/s-0038-1675822
   Denecke K, 2018, DH '18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON DIGITAL HEALTH, P85, DOI 10.1145/3194658.3194670
   Fadhil A., 2017, P 11 EAI INT C PERV, P261, DOI DOI 10.1145/3154862.3154914
   Fadhil A, 2019, METHOD INFORM MED, V58, P9, DOI 10.1055/s-0039-1688757
   Flutura S, 2018, DH '18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON DIGITAL HEALTH, P65, DOI 10.1145/3194658.3194666
   Furht B, 2010, HANDBOOK OF CLOUD COMPUTING, P3, DOI 10.1007/978-1-4419-6524-0_1
   Gabrielli S, 2020, JMIR HUM FACTORS, V7, DOI 10.2196/16762
   Ghandeharioun Asma, 2019, 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII). Proceedings, P8, DOI 10.1109/ACII.2019.8925433
   Ghandeharioun A, 2019, INT CONF AFFECT
   Ghosh S, 2018, STUD HEALTH TECHNOL, V252, P51, DOI 10.3233/978-1-61499-890-7-51
   Greer S, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/15018
   Griol D, 2019, COMP MED SY, P513, DOI 10.1109/CBMS.2019.00104
   Hauser-Ulrich S, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/15806
   He Dongjing, 2014, AMIA Annu Symp Proc, V2014, P645
   Hess Gabriel Immanuel, 2019, Stud Health Technol Inform, V259, P101
   Holmes S, 2019, IEEE INT C BIOINFORM, P2845, DOI 10.1109/BIBM47256.2019.8983073
   Horii T, 2019, IEEE WORLD CONGR SER, P190, DOI 10.1109/SERVICES.2019.00052
   Huang CY, 2018, IN C IND ENG ENG MAN, P1791, DOI 10.1109/IEEM.2018.8607399
   Hussain S, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P698, DOI 10.1109/WAINA.2018.00170
   Ikegami Y, 2018, WORLD AUTOMAT CONG, P22, DOI 10.23919/WAC.2018.8430301
   Inkster B, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/12106
   Ireland D, 2016, STUD HEALTH TECHNOL, V227, P55, DOI 10.3233/978-1-61499-666-8-55
   Issom DZ, 2020, STUD HEALTH TECHNOL, V270, P1361, DOI 10.3233/SHTI200442
   Jack B, 2015, J AM BOARD FAM MED, V28, P441, DOI 10.3122/jabfm.2015.04.140327
   Judson TJ, 2020, J AM MED INFORM ASSN, V27, P1450, DOI 10.1093/jamia/ocaa130
   Jungmann SM., 2019, JMIR FORMATIVE RES, V3, P13863, DOI 10.2196/13863
   Kadariya D, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP 2019), P138, DOI [10.1109/SMARTCOMP.2019.00043, 10.1109/smartcomp.2019.00043]
   Kaufman LM, 2009, IEEE SECUR PRIV, V7, P61, DOI 10.1109/MSP.2009.87
   Kocielnik Rafal, 2019, AMIA Annu Symp Proc, V2019, P552
   Lee D, 2017, INT CONF BIG DATA, P437, DOI 10.1109/BIGCOMP.2017.7881752
   Liu W, 2018, CHIN AUTOM CONGR, P1
   Ly KH, 2017, INTERNET INTERV, V10, P39, DOI 10.1016/j.invent.2017.10.002
   Madhu D, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P243, DOI 10.1109/ICICCT.2017.7975195
   Maher CA, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/17558
   Martinez-Miranda J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1387-1
   Mathew Rohit Binu, 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P851, DOI 10.1109/ICOEI.2019.8862707
   May R., 2020, ADDRESSING GLOBAL CH
   Mense A., 2016, P MOD SIM MED S, P1, DOI DOI 10.22360/SPRINGSIM.2016.MSM.008
   Mercuri RT, 2004, COMMUN ACM, V47, P25, DOI 10.1145/1005817.1005840
   Moher David, 2009, Ann Intern Med, V151, P264, DOI 10.1136/bmj.b2535
   Morris RR, 2018, J MED INTERNET RES, V20, DOI 10.2196/10148
   Nikitina S, 2018, 2018 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON SOFTWARE ENGINEERING FOR COGNITIVE SERVICES (SE4COG), P52, DOI 10.1145/3195555.3195567
   Nurgalieva L, 2020, IEEE ACCESS, V8, P104247, DOI 10.1109/ACCESS.2020.2999934
   O'Loughlin K, 2019, INTERNET INTERV, V15, P110, DOI 10.1016/j.invent.2018.12.001
   Oh J, 2020, INT J MED INFORM, V140, DOI 10.1016/j.ijmedinf.2020.104171
   Oh KJ, 2017, IEEE INT CONF MOB DA, P371, DOI 10.1109/MDM.2017.64
   Park S, 2019, J MED INTERNET RES, V21, DOI 10.2196/12231
   Patil HK, 2014, IEEE INT CONGR BIG, P762, DOI 10.1109/BigData.Congress.2014.112
   Morera EP, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0513-6
   Piao M, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/15085
   Piau A, 2019, INT J MED INFORM, V128, P18, DOI 10.1016/j.ijmedinf.2019.05.013
   Preininger AM, 2020, JAMIA OPEN, V3, P225, DOI 10.1093/jamiaopen/ooaa009
   Rahman AM, 2017, IEEE REG 10 HUMANIT, P75, DOI 10.1109/R10-HTC.2017.8288910
   Rahman MM, 2021, INT J GEOTECH ENG, V15, P714, DOI 10.1080/19386362.2019.1576352
   Ralston Kennedy, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P1924, DOI 10.1109/ICMLA.2019.00309
   Ranavare SS., 2020, OUR HERIT, V68, P4806
   Roca S, 2020, J BIOMED INFORM, V102, DOI 10.1016/j.jbi.2019.103305
   Roman MK, 2020, J BIOMED INFORM, V107, DOI 10.1016/j.jbi.2020.103461
   Scholten MR, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01063
   Siangchin N, 2019, ICESI 19, P1, DOI DOI 10.1109/ICESI.2019.8863009
   Singh A., 2019, BUILDING ENTERPRISE, P281
   So R, 2020, J GAMBL STUD, V36, P1391, DOI 10.1007/s10899-020-09935-4
   Srivastava Prakhar, 2020, 2020 International Conference on Power Electronics & IoT Applications in Renewable Energy and its Control (PARC), P351, DOI 10.1109/PARC49193.2020.236624
   Stieger Mirjam, 2018, BMC Psychol, V6, P43, DOI 10.1186/s40359-018-0257-9
   Suganuma S, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/10454
   Swamy Pragna Mallikarjuna, 2019, 2019 1st International Conference on Advances in Information Technology (ICAIT). Proceedings, P39, DOI 10.1109/ICAIT47043.2019.8987301
   Telang PR, 2018, IEEE INTERNET COMPUT, V22, P54, DOI 10.1109/MIC.2018.2877827
   Tielman ML, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0771-y
   Tschanz M, 2017, STUD HEALTH TECHNOL, V236, P196, DOI 10.3233/978-1-61499-759-7-196
   ur Rehman A., 2017, BIG DATA MANAGEMENT, P71
   Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977
   van Lamsweerde A, 2001, FIFTH IEEE INTERNATIONAL SYMPOSIUM ON REQUIREMENTS ENGINEERING, PROCEEDINGS, P249
   Velmovitsky Pedro Elkind, 2019, 2019 8th Brazilian Conference on Intelligent Systems (BRACIS). Proceedings, P473, DOI 10.1109/BRACIS.2019.00089
   Wargnier P, 2016, IEEE INT CONF SERIOU
   Welch BM, 2020, JCO CLIN CANCER INFO, V4, P787, DOI 10.1200/CCI.20.00014
NR 100
TC 1
Z9 1
U1 3
U2 12
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 1753-8157
EI 1753-8165
J9 INFORM HEALTH SOC CA
JI Inform. Health Soc. Care
PD APR 3
PY 2022
VL 47
IS 2
BP 194
EP 210
DI 10.1080/17538157.2021.1983578
EA OCT 2021
PG 17
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA 1L2XQ
UT WOS:000705392100001
PM 34617857
DA 2022-08-02
ER

PT C
AU Doswell, JT
AF Doswell, Jayfus T.
BE Looi, CK
   McCalla, G
   Bredeweg, B
   Breuker, J
TI PECA: Pedagogical Embodied Conversational Agents in Mixed Reality
   Learning Environments
SO ARTIFICIAL INTELLIGENCE IN EDUCATION: SUPPORTING LEARNING THROUGH
   INTELLIGENT AND SOCIALLY INFORMED TECHNOLOGY
SE Frontiers in Artificial Intelligence and Applications
LA English
DT Proceedings Paper
CT 12th International Conference on Artificial Intelligence in Education
   (AI-Ed 2005)
CY JUL 18-22, 2005
CL Amsterdam, NETHERLANDS
SP Int Artificial Intelligence Educ Soc, European Coordinating Comm Artificial Intelligence Site, IOS Press, Amer Assoc Artificial Intelligence
C1 George Mason Univ, Fairfax, VA 22030 USA.
RP Doswell, JT (corresponding author), George Mason Univ, Fairfax, VA 22030 USA.
NR 0
TC 3
Z9 3
U1 0
U2 0
PU I O S PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 0922-6389
BN 978-1-58603-530-3
J9 FR ART INT
PY 2005
VL 125
BP 957
EP 957
PG 1
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BND66
UT WOS:000274235700166
DA 2022-08-02
ER

PT C
AU Morge, M
   Abdel-Naby, S
   Beaufils, B
AF Morge, Maxime
   Abdel-Naby, Sameh
   Beaufils, Bruno
BE McBurney, P
   Rahwan, I
   Parsons, S
TI Towards a Dialectical Approach for Conversational Agents in Selling
   Situations
SO ARGUMENTATION IN MULTI-AGENT SYSTEMS (ARGMAS)
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 7th International Workshop on Argumentation in Multi-Agent Systems
   (ArgMAS)
CY MAY 10, 2010
CL Toronto, CANADA
DE Argumentation; E-commerce; Agents; Language Processors
AB The use of virtual agents to intelligently interface with online customers of e-commerce businesses is remarkably increasing. Most of these virtual agents are designed to assist online customers while searching for information related to a specific product or service, while few agents are intended for promoting and selling a product or a service. Within the later type, our aim is to provide proactive agents that recommend a specific item and justify this recommendation to a customer based on his purchases history and his needs. In this paper, we propose a dialectical argumentation approach that would allow virtual agents that have sales goals to trigger persuasions with e-commerce's customers. Then, we illustrate the proposed idea through its integration with an example from real-life.
C1 [Morge, Maxime; Abdel-Naby, Sameh; Beaufils, Bruno] Univ Lille 1, Lab Informat Fondamentale Lille, F-59655 Villeneuve Dascq, France.
RP Morge, M (corresponding author), Univ Lille 1, Lab Informat Fondamentale Lille, Bat M3, F-59655 Villeneuve Dascq, France.
EM maxime.morge@lifl.fr; sameh.abdel-naby@lifl.fr; bruno.beaufils@lifl.fr
OI Beaufils, Bruno/0000-0001-6392-5105; MORGE, Maxime/0000-0003-2139-7150
CR Amgoud L., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P1
   Amgoud L, 2009, ARTIF INTELL, V173, P413, DOI 10.1016/j.artint.2008.11.006
   [Anonymous], 2003, P 2 INT JOINT C AUT
   Bench-Capon TJM, 2006, FRONT ARTIF INTEL AP, V144, P247
   Breiter P., 1992, THESIS U PARIS NORD
   Demetriou N., 2003, P 4 PANH S LOG
   DUNG PM, 1995, ARTIF INTELL, V77, P321, DOI 10.1016/0004-3702(94)00041-X
   Ferguson G, 2007, AI MAG, V28, P23
   Gaertner D., 2007, P WORKSH ARG NONM RE, P80
   Garcia AJ, 2004, THEOR PRACT LOG PROG, V4, P95, DOI 10.1017/S1471068403001674
   GROSZ BJ, 1990, INTENTIONS PLANS COM
   Hamblin CL, 1970, FALLACIES
   Hof R., 1998, BUSINESS WEEK   1005, P68
   Isbister K., 2002, P 1 INT JOINT C AUT
   Krabbe Erik C. W., 1995, COMMITMENT DIALOGUE
   MORGE M, 2008, LNCS LNAI, V4946, P114
   Morge M, 2010, LECT NOTES ARTIF INT, V6057, P114, DOI 10.1007/978-3-642-12805-9_7
   Palopoli L, 2006, AI COMMUN, V19, P95
   Poong Y, 2006, 2006 ICEC: Eighth International Conference on Electronic Commerce, Proceedings, P553
   Prakken H, 2006, KNOWL ENG REV, V21, P163, DOI 10.1017/S0269888906000865
   RAO AS, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P473
   Rich C, 2001, AI MAG, V22, P15
   Rist T, 2004, COG TECH, P377
   Roberts F, 2007, LECT NOTES ARTIF INT, V4722, P420
   Sadek D, 2005, MU S ART SOC SIM ORG, V15, P217, DOI 10.1007/0-387-26350-0_9
   WOOLDRIDGE M, 1995, KNOWL ENG REV, V10, P115, DOI 10.1017/S0269888900008122
NR 26
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-21939-9; 978-3-642-21940-5
J9 LECT NOTES ARTIF INT
PY 2011
VL 6614
BP 141
EP 158
PG 18
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BDD50
UT WOS:000312791800009
OA Green Submitted
DA 2022-08-02
ER

PT J
AU De Keyser, A
   Kocher, S
   Alkire, L
   Verbeeck, C
   Kandampully, J
AF De Keyser, Arne
   Koecher, Sarah
   Alkire (nee Nasr), Linda
   Verbeeck, Cedric
   Kandampully, Jay
TI Frontline Service Technology infusion: conceptual archetypes and future
   research directions
SO JOURNAL OF SERVICE MANAGEMENT
LA English
DT Article
DE Service encounter; Blockchain; Conversational agents; Extended reality;
   Organizational frontline; Technology infusion
ID HUMAN-COMPUTER INTERACTION; AUGMENTED REALITY; CUSTOMER SATISFACTION;
   ROBOTS; BLOCKCHAIN; FRAMEWORK; EXPERIENCE; CONSUMER; IMPACT;
   EXPECTATIONS
AB Purpose Smart technologies and connected objects are rapidly changing the organizational frontline. Yet, our understanding of how these technologies infuse service encounters remains limited. Therefore, the purpose of this paper is to update existing classifications of Frontline Service Technology (FST) infusion. Moreover, the authors discuss three promising smart and connected technologies - conversational agents, extended reality (XR) and blockchain technology - and their respective implications for customers, frontline employees and service organizations. Design/methodology/approach This paper uses a conceptual approach integrating existing work on FST infusion with artificial intelligence, robotics, XR and blockchain literature, while also building on insights gathered through expert interviews and focus group conversations with members of two service research centers. Findings The authors define FST and propose a set of FST infusion archetypes at the organizational frontline. Additionally, the authors develop future research directions focused on understanding how conversational agents, XR and blockchain technology will impact service. Originality/value This paper updates and extends existing classifications of FST, while paving the road for further work on FST infusion.
C1 [De Keyser, Arne] EDHEC Business Sch, Dept Mkt, Lille, France.
   [Koecher, Sarah] TU Dortmund Univ, Dept Mkt, Dortmund, Germany.
   [Alkire (nee Nasr), Linda] Texas State Univ, Mkt Dept, San Marcos, TX USA.
   [Verbeeck, Cedric] EDHEC Business Sch, Dept Management, Lille, France.
   [Kandampully, Jay] Ohio State Univ, Dept Consumer Sci, Columbus, OH 43210 USA.
RP De Keyser, A (corresponding author), EDHEC Business Sch, Dept Mkt, Lille, France.
EM arne.dekeyser@edhec.edu
RI De Keyser, Arne/AAQ-1058-2020; Alkire (nee Nasr), Linda/I-1030-2017
OI De Keyser, Arne/0000-0003-2517-9046; Alkire (nee Nasr),
   Linda/0000-0002-8184-5448; Kocher, Sarah/0000-0003-1561-1106
CR Admoni H, 2017, J HUM-ROBOT INTERACT, V6, P25, DOI 10.5898/JHRI.6.1.Admoni
   Ahearne M, 2008, MANAGE SCI, V54, P671, DOI 10.1287/mnsc.1070.0783
   Akaka MA, 2014, INF SYST E-BUS MANAG, V12, P367, DOI 10.1007/s10257-013-0220-5
   Andre Q., 2018, CUSTOMER NEEDS SOLUT, V5, P28, DOI 10.1007/s40547-017-0085-8
   [Anonymous], 2003, J SERV RES-US, DOI DOI 10.1177/1094670503257044
   Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Aung MM, 2014, FOOD CONTROL, V39, P172, DOI 10.1016/j.foodcont.2013.11.007
   Beck A, 2010, 2010 IEEE RO-MAN, P464, DOI 10.1109/ROMAN.2010.5598649
   Beck M, 2018, J RETAIL CONSUM SERV, V40, P279, DOI 10.1016/j.jretconser.2016.08.006
   Ben Mimoun MS, 2015, J RETAIL CONSUM SERV, V26, P70, DOI 10.1016/j.jretconser.2015.05.008
   Berke A, 2017, HARVARD BUSINESS REV
   Bernstein E. S., 2014, HARVARD BUSINESS REV
   Berry LL, 2002, J MARKETING, V66, P1, DOI 10.1509/jmkg.66.3.1.18505
   Bertram J, 2015, COMPUT HUM BEHAV, V43, P284, DOI 10.1016/j.chb.2014.10.032
   BITNER MJ, 1990, J MARKETING, V54, P71, DOI 10.2307/1252174
   Bolton R, 2009, J INTERACT MARK, V23, P91, DOI 10.1016/j.intmar.2008.11.002
   Bolton RN, 2018, J SERV MANAGE, V29, P776, DOI 10.1108/JOSM-04-2018-0113
   Bowen DE, 2016, HUM RESOUR MANAGE R, V26, P4, DOI 10.1016/j.hrmr.2015.09.002
   Brengman M., 2018, VIRTUAL REALITY
   Buvat J., 2018, CONVERSATIONAL COMME
   Caic M, 2018, J SERV MANAGE, V29, P178, DOI 10.1108/JOSM-07-2017-0179
   Callejas Z, 2014, INT J HUM-COMPUT ST, V72, P567, DOI 10.1016/j.ijhcs.2014.02.002
   Cameron D., 2018, CONNECT SCI, P1
   Castro-Gonzalez A, 2016, INT J HUM-COMPUT ST, V90, P27, DOI 10.1016/j.ijhcs.2016.02.004
   Chester J, 2017, FORBES
   Chowdhury IR, 2014, J SERV MARK, V28, P471, DOI 10.1108/JSM-04-2013-0095
   Coeckelbergh M, 2016, SCI ENG ETHICS, V22, P47, DOI 10.1007/s11948-015-9649-x
   Cunningham LF, 2008, SERV IND J, V28, P719, DOI 10.1080/02642060801988522
   Dabholkar PA, 1994, ADV SERV MARKET MAN, V3, P241
   De Keyser A, 2015, INT J RES MARK, V32, P453, DOI 10.1016/j.ijresmar.2015.09.005
   Deloitte, 2016, GLOB MOB CONS TRENDS
   Deloitte, 2018, TECH TRENDS 2018 SYM
   Ding X, 2007, INT J SERV IND MANAG, V18, P246, DOI 10.1108/09564230710751479
   Dong BB, 2015, J SERV RES-US, V18, P160, DOI 10.1177/1094670514551727
   Drescher C., 2017, INDEPENDENT
   Engelhardt MA, 2017, TECHNOL INNOV MANAG, V7, P22, DOI 10.22215/timreview/1111
   Fink Julia, 2012, Social Robotics. 4th International Conference (ICSR 2012). Proceedings, P199, DOI 10.1007/978-3-642-34103-8_20
   Fisk RP, 2018, J SERV MANAGE, V29, P834, DOI 10.1108/JOSM-05-2018-0121
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   Frey CB, 2017, TECHNOL FORECAST SOC, V114, P254, DOI 10.1016/j.techfore.2016.08.019
   Froehle CA, 2004, J OPER MANAG, V22, P1, DOI 10.1016/j.jom.2003.12.004
   Froehle CM, 2006, DECISION SCI, V37, P5, DOI 10.1111/j.1540-5414.2006.00108.x
   Ganapathy S., 2013, HUMAN FACTORS AUGMEN, P165
   Gatteschi V, 2018, IT PROF, V20, P62, DOI 10.1109/MITP.2018.021921652
   Giebelhausen M, 2014, J MARKETING, V78, P113, DOI 10.1509/jm.13.0056
   Green T, 2016, J SERV RES-US, V19, P477, DOI 10.1177/1094670516666674
   Grewal D, 2018, J MARKETING, V82, P102, DOI 10.1509/jm.17.0277
   Griol D, 2013, APPL ARTIF INTELL, V27, P759, DOI 10.1080/08839514.2013.835230
   Guttentag DA, 2010, TOURISM MANAGE, V31, P637, DOI 10.1016/j.tourman.2009.07.003
   Hazee S, 2017, J SERV RES-US, V20, P441, DOI 10.1177/1094670517712877
   Hilken T, 2018, J RES INTERACT MARK, V12, P509, DOI 10.1108/JRIM-01-2018-0023
   Hilken T, 2017, J ACAD MARKET SCI, V45, P884, DOI 10.1007/s11747-017-0541-x
   Hoffman DL, 2018, J CONSUM RES, V44, P1178, DOI 10.1093/jcr/ucx105
   Holz T, 2011, INT J HUM-COMPUT ST, V69, P251, DOI 10.1016/j.ijhcs.2010.10.001
   Holz T, 2009, INT J SOC ROBOT, V1, P83, DOI 10.1007/s12369-008-0002-2
   Homburg C, 2017, J ACAD MARKET SCI, V45, P377, DOI 10.1007/s11747-015-0460-7
   Huang MH, 2018, J SERV RES-US, V21, P155, DOI 10.1177/1094670517752459
   Huang MH, 2017, J ACAD MARKET SCI, V45, P906, DOI 10.1007/s11747-017-0545-6
   IBM, 2017, 10 REAS WHY AI POW A
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Kannan PK, 2017, INT J RES MARK, V34, P22, DOI 10.1016/j.ijresmar.2016.11.006
   Karray F, 2008, INT J SMART SENS INT, V1, P137, DOI 10.21307/ijssis-2017-283
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kimes SE, 2015, MIT SLOAN MANAGE REV, V57, P25
   Kramer NC, 2009, SOC PSYCHOL-GERMANY, V40, P26, DOI 10.1027/1864-9335.40.1.26
   Krishna A, 2012, J CONSUM PSYCHOL, V22, P332, DOI 10.1016/j.jcps.2011.08.003
   Kumar V, 2016, J ACAD MARKET SCI, V44, P24, DOI 10.1007/s11747-015-0426-9
   Lariviere B, 2017, J BUS RES, V79, P238, DOI 10.1016/j.jbusres.2017.03.008
   Li J, 2015, INT J HUM-COMPUT ST, V77, P23, DOI 10.1016/j.ijhcs.2015.01.001
   Marinova D, 2017, J SERV RES-US, V20, P29, DOI 10.1177/1094670516679273
   Martin KD, 2017, J MARKETING, V81, P36, DOI 10.1509/jm.15.0497
   Mathur MB, 2016, COGNITION, V146, P22, DOI 10.1016/j.cognition.2015.09.008
   Matzembacher DE, 2018, FOOD CONTROL, V92, P420, DOI 10.1016/j.foodcont.2018.05.014
   Mende M., 2017, WORKING PAPER SERIES, V17-125-10
   Meuter ML, 2000, J MARKETING, V64, P50, DOI 10.1509/jmkg.64.3.50.18024
   Microsoft, 2018, CAS STUD LESS LOW KI
   Microsoft, 2018, WHAT IS MIX REAL
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Morhart F, 2015, J CONSUM PSYCHOL, V25, P200, DOI 10.1016/j.jcps.2014.11.006
   Ng ICL, 2017, INT J RES MARK, V34, P3, DOI 10.1016/j.ijresmar.2016.11.003
   Novak T.P., 2018, J ACAD MARKETING SCI
   O'Neal S., 2018, COINTELEGRAPH
   Ostrom AL, 2015, J SERV RES-US, V18, P127, DOI 10.1177/1094670515576315
   Paluch S, 2014, J SERV MANAGE, V25, P639, DOI 10.1108/JOSM-07-2013-0195
   Paluch S, 2013, J SERV RES-US, V16, P415, DOI 10.1177/1094670513475870
   Panetta K., 2017, TOP TRENDS GARTNER H
   Parasuraman, 1996, FRONT SERV C NASHV T
   Parasuraman A., 2000, J SERV RES-US, V2, P307, DOI DOI 10.1177/109467050024001
   Rafaeli A, 2017, J SERV RES-US, V20, P91, DOI 10.1177/1094670516679275
   Rapp A, 2015, J RETAILING, V91, P358, DOI 10.1016/j.jretai.2014.12.007
   Rauschnabel PA, 2018, J BUS RES, V92, P374, DOI 10.1016/j.jbusres.2018.08.008
   Risius M, 2017, BUS INFORM SYST ENG+, V59, P385, DOI 10.1007/s12599-017-0506-0
   Rust RT, 2014, MARKET SCI, V33, P206, DOI 10.1287/mksc.2013.0836
   Savelyev A, 2018, COMPUT LAW SECUR REV, V34, P550, DOI 10.1016/j.clsr.2017.11.008
   Schepers J, 2012, J MARKETING, V76, P1, DOI 10.1509/jm.11.0112
   Schumann JH, 2012, TECHNOVATION, V32, P133, DOI 10.1016/j.technovation.2011.10.002
   Shankar V, 2016, J INTERACT MARK, V34, P37, DOI 10.1016/j.intmar.2016.03.002
   Shook E., 2018, REWORKING REVOLUTION
   Singh J, 2017, J SERV RES-US, V20, P3, DOI 10.1177/1094670516681513
   SOLOMON MR, 1985, J MARKETING, V49, P99, DOI 10.2307/1251180
   Spaid BI, 2014, J MARKET THEORY PRAC, V22, P73, DOI 10.2753/MTP1069-6679220105
   STRIVR, 2018, CAN WE MAK OUR TRAIN
   Tay BTC, 2016, COMPUT HUM BEHAV, V60, P19, DOI 10.1016/j.chb.2016.01.042
   Tuzovic S., 2018, SERVICE BUSINESS DEV, V1, P81, DOI DOI 10.1007/978-3-658-22426-4
   van Doorn J, 2017, J SERV RES-US, V20, P43, DOI 10.1177/1094670516679272
   Van Kerrebroeck H, 2017, COMPUT HUM BEHAV, V77, P437, DOI 10.1016/j.chb.2017.07.019
   Van Vaerenbergh Y, 2016, ACAD MANAGE PERSPECT, V30, P328, DOI 10.5465/amp.2014.0143
   Verhoef PC, 2017, J INTERACT MARK, V40, P1, DOI 10.1016/j.intmar.2017.06.001
   Walsh C., 2016, P 37 INT C INF SYST, P1
   Wilson HJ, 2017, MIT SLOAN MANAGE REV, V58, P14
   Wilson J., 2019, HARVARD BUS REV
   Wilson JR, 2017, LECT NOTES ARTIF INT, V10652, P334, DOI 10.1007/978-3-319-70022-9_33
   Wirtz J, 2018, J SERV MANAGE, V29, P907, DOI 10.1108/JOSM-04-2018-0119
   Wirtz J, 2018, J ACAD MARKET SCI, V46, P59, DOI 10.1007/s11747-017-0560-7
   Woodside J.M., 2017, J INT TECHNOLOGY INF, V26, P65
   Wu L, 2015, INT J HOSP MANAG, V51, P1, DOI 10.1016/j.ijhm.2015.08.010
   Wunderlich NV, 2015, J SERV MARK, V29, P442, DOI 10.1108/JSM-01-2015-0040
   Yadav MS, 2014, J MARKETING, V78, P20, DOI 10.1509/jm.12.0020
   Zlotowski J, 2015, INT J SOC ROBOT, V7, P347, DOI 10.1007/s12369-014-0267-6
   [No title captured]
NR 120
TC 111
Z9 111
U1 15
U2 153
PU EMERALD GROUP PUBLISHING LTD
PI BINGLEY
PA HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN 1757-5818
EI 1757-5826
J9 J SERV MANAGE
JI J. Serv. Manage.
PD JAN 14
PY 2019
VL 30
IS 1
BP 156
EP 183
DI 10.1108/JOSM-03-2018-0082
PG 28
WC Management
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA HL4CY
UT WOS:000458664200007
DA 2022-08-02
ER

PT J
AU Kuz, A
   Falco, M
   Giandini, R
AF Kuz, Antonieta
   Falco, Mariana
   Giandini, Roxana
TI Agent SocialMetric: A platform based on web technology for teaching
   environments and support of assessment of conflicts in the classroom
SO REVISTA COMPLUTENSE DE EDUCACION
LA Spanish
DT Article
DE Conversational agents; SNA; sociometry; teachers; classroom
AB Nowadays, numerous software tools are used to assist students and encourage learning in education. Through various investigations and as a result of ICTs development, it was feasible for us to create a web tool called Agent SocialMetric. It is based on the interlacing of Social Network Analysis (SNA) with Intelligent Conversational Agents (in our case, the Albert agent). The primary purpose of the tool is to assist teachers, showing the prevailing social climate in the classroom through Albert. In this article we show the fundamentals and motivations of the proposal together with a description of the methodology embedded in Agent SocialMetric. Circumscribing the application to a case study in the field of secondary education, it is possible to see attitudes, specific behaviors of peers and the positions of these students in the social network of the classroom, that influence bullying. Finally, we will provide conclusions and future work.
C1 [Kuz, Antonieta; Falco, Mariana] Univ Tecnol Nacl, Buenos Aires, DF, Argentina.
   [Giandini, Roxana] Univ Nacl La Plata, La Plata, Buenos Aires, Argentina.
RP Kuz, A (corresponding author), Univ Tecnol Nacl, Buenos Aires, DF, Argentina.
EM akuz@frlp.utn.edu.ar; mfalco@frlp.utn.edu.ar; giandini@info.unlp.edu.ar
CR Alzina RB, 2008, EDUCACION CIUDADANIA
   Andres M., 2004, DINAMICAS GRUPOS HAC, P56
   [Anonymous], AC ESC BULL
   Berlo D. K., 1999, ATENEO
   Cabanas J.M. Quintana, 2004, EDUCACION ESTA ENFER
   Calixto Gomez C.P., 2014, MODELO AULAS INFORM
   CASANOVA Ma. Antonia, 1991, SOCIOMETRIA AULA
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   Cava M.J., 2003, INFORMACIO PSICOL INFORMACIO PSICOL, V83, P60
   Duarte A., 2009, AVANCES SISTEMAS INF, V5
   Giret A., 2000, C LAT INF CLEI 2000
   Graells P., 1995, SOFTWARE ED GUIA US
   Hogg M., 2010, PSICOLOGIA SOCIAL
   Kuz A., 2013, HERRAMIENTAS SOCIOME
   Lewin Kurt, 1973, DINAMICA PERSONALIDA
   Litwin E., 2005, TECNOLOGIAS ED TIEMP
   Olweus D., 1998, CONDUCTAS ACOSO AMEN
   Pedrosa E., 2010, CICLOS FROMATIVOS, P50
   PerezMarin D, 2011, CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND EFFECTIVE PRACTICES, P1, DOI 10.4018/978-1-60960-617-6
   Pichon-Riviere E, 1999, EL PROCESO GRUPAL
   Rodriguez M. E. Uria, 1998, ESTRATEGIAS DIDACTIC
   Salmivalli C, 2010, AGGRESS VIOLENT BEH, V15, P112, DOI 10.1016/j.avb.2009.08.007
NR 22
TC 0
Z9 0
U1 2
U2 5
PU UNIV COMPLUTENSE MADRID, SERVICIO PUBLICACIONES
PI MADRID
PA CIUDAD UNIV, OBISPO TREJO 3, MADRID, 28040, SPAIN
SN 1130-2496
EI 1988-2793
J9 REV COMPLUT EDUC
JI Rev. Complut. Educ.
PY 2017
VL 28
IS 3
BP 929
EP 946
DI 10.5209/rev_RCED.2017.v28.n3.51366
PG 18
WC Education & Educational Research
WE Emerging Sources Citation Index (ESCI)
SC Education & Educational Research
GA FM9NT
UT WOS:000415598700016
OA Green Submitted, Green Published, gold
DA 2022-08-02
ER

PT S
AU Malcangi, M
   de Tintis, R
AF Malcangi, M
   de Tintis, R
BE Camurri, A
   Volpe, G
TI Audio based real-time speech animation of embodied conversational agents
SO GESTURE-BASED COMMUNICATION IN HUMAN-COMPUTER INTERACTION
SE Lecture Notes in Artificial Intelligence
LA English
DT Article; Proceedings Paper
CT 5th International Workshop on Gesture-Based Communication in
   Human-Computer Interaction
CY APR 15-17, 2003
CL Genoa, ITALY
SP Univ Genoa, InfoMus Lab
AB A framework dedicated to embodied agents facial animation based on speech analysis in presence of background noise is described. Target application areas are entertainment and mobile visual communication. This novel approach derives from the speech signal all the necessary information needed to drive 3-D facial models. Using both digital signal processing and soft computing (fuzzy logic and neural networks) methodologies, a very flexible and low-cost solution for the extraction of lips and facial-related information has been implemented. The main advantage of the speech-based approach is that it is not invasive, as speech is captured by means of a microphone and there is no physical contact with the subject (no use of magnetic sensors or optical markers). This gives additional flexibility to the application in that more applicability derives, if compared to other methodologies. First a speech-based lip driver system was developed in order to synchronize speech to lip movements, then the methodology was extended to some important facial movements so that a face-synching system could be modeled. The developed system is speaker and language independent, so also neural network training operations are not required.
C1 Univ Milan, DICo, I-20135 Milan, Italy.
   DSPengn, I-20122 Milan, Italy.
RP Malcangi, M (corresponding author), Univ Milan, DICo, Via Comelico 39, I-20135 Milan, Italy.
EM malcangi@dico.unimi.it; rdt@dspeng.com
CR CAO Y, 1995, 5 AUSTR REG CONV APR
   COHEN MM, 1993, MODELING COARTICULAT
   Junqua Jean-Claude, 1994, IEEE T SPEECH AUDIO, V2
   LOFQUIST A, 1990, SPEECH PRODUCTION SP
   MALCANGI M, 2002, 2002 INT WORKSH SYST
   MALCANGI M, 2002, 2 CONV TECN SCI MIMO
   MALCANGI M, 2000, 13 C MUS INF P AQ IT
   MARKOWITZ JA, 1996, USING SPEECH RECOGNI
   NITCHIE E, 1979, READ LIPS FUN PROFIT
   PARKE FI, 1996, COMPUTER FACIAL ANIM
   POGGI I, 2000, EMBODIED CONVERSATIO
NR 11
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-21072-5
J9 LECT NOTES ARTIF INT
PY 2003
VL 2915
BP 350
EP 360
PG 11
WC Computer Science, Artificial Intelligence; Imaging Science &
   Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA BY73W
UT WOS:000189451300032
DA 2022-08-02
ER

PT C
AU Mugoye, K
   Okoyo, H
   Mcoyowo, S
AF Mugoye, Kevin
   Okoyo, Henry
   Mcoyowo, Sylvester
GP IEEE
TI Smart-bot Technology: Conversational Agents Role in Maternal Healthcare
   Support
SO 2019 IST-AFRICA WEEK CONFERENCE (IST-AFRICA)
LA English
DT Proceedings Paper
CT IST-Africa Week Conference (IST-Africa)
CY MAY 08-10, 2019
CL Nairobi, KENYA
SP IST-Africa
DE chatbot; bot; digital health; intelligent agent; user experience;
   multiagent system; reinforcement learning
AB There is a need for a system that respond to various queries in real-time, to advice and inform expectant mothers during their pregnancy. Several smart services have been deployed, bundled with health information systems, and other digital services. While such solutions better services in the healthcare settings, they may not be available to the masses in the rural. Besides they rarely dispense this information precisely and or accurately. A new digital ecosystem, represented by chatbots seem to offer promising solution by embodying the function of a virtual healthcare expert, who is always available to provide information in the required precision. Powered by AI and machine learning algorithms, chatbots are forecasted to bring forth accuracy, precision and availability of information when used. This paper discusses the need to develop chatbots to be integrated in smart phones; intended to provide support to to-be mothers during their journey in pregnancy.
C1 [Mugoye, Kevin; Okoyo, Henry; Mcoyowo, Sylvester] Maseno Univ, Maseno, Kenya.
RP Mugoye, K (corresponding author), Maseno Univ, Maseno, Kenya.
EM keymug2002@gmail.com; okoyo.ho@gmail.com; oyowosilver@gmail.com
CR [Anonymous], GETT PREGN
   Bertalan D. M., 2018, MED FUTURIST, V29, P5
   Bordini R. H., 2007, PROGRAMMING MULTIAGE
   Fadhil A., 2018, PATIENT MONITORING
   Holzinger A., 2007, INT C UN ACC HUM COM
   Lemon O., 2007, P INT
   Parker C. J., 2009, HLTH COMMUNICATION N, P19
   Parvanta C., 2011, ESSENTIALS PUBLIC HL, P3
   Sennaar K., 2019, EMERJ ARTIFICIAL INT, V19, P2
   Weiss, 1999, MULTIAGENT SYSTEMS M
   WOOLDRIDGE M, 1995, KNOWL ENG REV, V10, P115, DOI 10.1017/S0269888900008122
NR 11
TC 2
Z9 2
U1 0
U2 5
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-905824-63-2
PY 2019
PG 7
WC Computer Science, Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BO0FQ
UT WOS:000490550800002
DA 2022-08-02
ER

PT C
AU Llorach, G
   Blat, J
AF Llorach, Gerard
   Blat, Josep
BE Beskow, J
   Peters, C
   Castellano, G
   OSullivan, C
   Leite, I
   Kopp, S
TI Say Hi to Eliza An Embodied Conversational Agent on the Web
SO INTELLIGENT VIRTUAL AGENTS, IVA 2017
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 17th International Conference on Intelligent Virtual Agents (IVA)
CY AUG 27-30, 2017
CL Swedish Natl Museum Sci & Technol, Stockholm, SWEDEN
SP KTH Royal Inst Technol
HO Swedish Natl Museum Sci & Technol
DE embodied conversational agents; web technologies; virtual characters
ID GENERATION
AB The creation and support of Embodied Conversational Agents (ECAs) has been quite challenging, as features required might not be straight-forward to implement and to integrate in a single application. Furthermore, ECAs as desktop applications present drawbacks for both developers and users; the former have to develop for each device and operating system and the latter must install additional software, limiting their widespread use. In this paper we demonstrate how recent advances in web technologies show promising steps towards capable web-based ECAs, through some off-the-shelf technologies, in particular, the Web Speech API, Web Audio API, WebGL and Web Workers. We describe their integration into a simple fully functional web-based 3D ECA accessible from any modern device, with special attention to our novel work in the creation and support of the embodiment aspects.
C1 [Llorach, Gerard; Blat, Josep] Univ Pompeu Fabra, Interact Technol Grp, Barcelona, Spain.
   [Llorach, Gerard] Carl von Ossietzky Univ Oldenburg, Med Phys, Oldenburg, Germany.
   [Llorach, Gerard] Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Oldenburg, Germany.
   [Llorach, Gerard] Horzentrum Oldenburg GmbH, Oldenburg, Germany.
RP Llorach, G (corresponding author), Univ Pompeu Fabra, Interact Technol Grp, Barcelona, Spain.; Llorach, G (corresponding author), Carl von Ossietzky Univ Oldenburg, Med Phys, Oldenburg, Germany.; Llorach, G (corresponding author), Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Oldenburg, Germany.; Llorach, G (corresponding author), Horzentrum Oldenburg GmbH, Oldenburg, Germany.
EM gerard.llorach@upf.edu; josep.blat@upf.edu
RI Blat, Josep/J-2178-2015
OI Blat, Josep/0000-0002-5308-475X
FU Spanish Ministry of Economy and Competitiveness [RESET
   TIN2014-53199-C3-3-R]; DFG [FOR1732]; European Commission
   [H2020-645012-RIA]; European Commission under the Marie Sklodowska-Curie
   grant [675324]
FX This research has been partially funded by the Spanish Ministry of
   Economy and Competitiveness (RESET TIN2014-53199-C3-3-R), by the DFG
   research grant FOR1732 and by the European Commission under the contract
   number H2020-645012-RIA (KRISTINA) and under the the Marie
   Sklodowska-Curie grant agreement No 675324 (ENRICH). Special thanks to
   Volker Hohmann and Sergio Sagayo for revisions and counseling and to
   Javi Agenjo for developing WebGLStudio and helping out with all the
   technical challenges.
CR Agenjo J, 2013, WEB3D 2013: 18TH INTERNATIONAL CONFERENCE ON 3D WEB TECHNOLOGY, P79
   Bickmore T, 2009, LECT NOTES COMPUTER, V5773
   Kopp S, 2006, LECT NOTES ARTIF INT, V4133, P205
   Leone G. R, 2011, AVSP, P123
   Llorach G, 2016, INT CONF GAMES VIRTU
   Romeo M, 2016, THESIS, P119
   Ruhland K, 2015, COMPUT GRAPH FORUM, V34, P299, DOI 10.1111/cgf.12603
   SACKS H, 1974, LANGUAGE, V50, P696, DOI 10.2307/412243
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Zatepyakin E, JAVASCRIPT COMPUTER
NR 10
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-319-67401-8; 978-3-319-67400-1
J9 LECT NOTES ARTIF INT
PY 2017
VL 10498
BP 255
EP 258
DI 10.1007/978-3-319-67401-8_34
PG 4
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BL7SK
UT WOS:000455400000034
OA Green Submitted
DA 2022-08-02
ER

PT J
AU Sezgin, E
   D'Arcy, S
AF Sezgin, Emre
   D'Arcy, Shona
TI Editorial: Voice Technology and Conversational Agents in Health Care
   Delivery
SO FRONTIERS IN PUBLIC HEALTH
LA English
DT Editorial Material
DE voice technology; chatbot; conversational agent (CA); healthcare;
   digital health (eHealth)
C1 [Sezgin, Emre] NORC Univ Chicago, Chicago, IL 60637 USA.
   [Sezgin, Emre] Nationwide Childrens Hosp, Columbus, OH 43205 USA.
   [D'Arcy, Shona] Kids Speech Labs, Dublin, Ireland.
RP Sezgin, E (corresponding author), NORC Univ Chicago, Chicago, IL 60637 USA.; Sezgin, E (corresponding author), Nationwide Childrens Hosp, Columbus, OH 43205 USA.
EM esezgin1@gmail.com
CR Alcantara A-M., 2021, SMART SPEAKERS GO WA
   Anthes E, 2020, NATURE, V586, P22, DOI 10.1038/d41586-020-02732-4
   Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158
   Comes S., 2021, CONVERSATIONAL INTER
   Robin Jessica, 2020, Digit Biomark, V4, P99, DOI 10.1159/000510820
   Sezgin E, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00332-0
   Sezgin E, 2020, TRANSL BEHAV MED, V10, P606, DOI 10.1093/tbm/ibz141
   van der Straten S., 2017, VOICE TECH LANDSCAPE
NR 8
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2296-2565
J9 FRONT PUBLIC HEALTH
JI Front. Public Health
PD MAY 30
PY 2022
VL 10
AR 887492
DI 10.3389/fpubh.2022.887492
PG 3
WC Public, Environmental & Occupational Health
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Public, Environmental & Occupational Health
GA 2D1IT
UT WOS:000811310300001
PM 35712270
OA gold, Green Published
DA 2022-08-02
ER

PT J
AU Xu, Y
   Wang, DK
   Collins, P
   Lee, H
   Warschauer, M
AF Xu, Ying
   Wang, Dakuo
   Collins, Penelope
   Lee, Hyelim
   Warschauer, Mark
TI Same benefits, different communication patterns: Comparing Children's
   reading with a conversational agent vs. a human partner
SO COMPUTERS & EDUCATION
LA English
DT Article
DE Conversational agents; Language development; Storybook reading;
   Communication; Young children
ID SOCIAL ROBOTS; COMPREHENSION; LANGUAGE; BEHAVIOR; PARENTS; SKILLS;
   INTERVENTION; QUESTIONS; CHATBOT
AB Storybook reading accompanied by adult-guided conversation provides a stimulating context for children's language development. Conversational agents powered by artificial intelligence, such as smart speakers, are prevalent in children's homes and have the potential to engage children in storybook reading as language partners. However, little research has explored the effectiveness of using conversational agents to support children's language development. This study examined how an automated conversational agent can read stories to children via a smart speaker while asking questions and providing contingent feedback. Using a randomized experiment among 90 children aged three to six years, this study compared these children's story comprehension and verbal engagement in storybook reading with a conversational agent versus an adult. The conversational agent's guided conversation was found to be as supportive in improving children's story comprehension as that provided by an adult language partner. At the same time, this study uncovered a number of differences in children's verbal engagement when interacting with a conversational agent versus with an adult. Specifically, children who read with the conversational agent responded to questions with better intelligibility, whereas those who read with an adult responded to questions with higher productivity, lexical diversity, and topical relevance. And the two groups responded to questions with a similar level of accuracy. In addition, questions requiring high cognitive demand amplified the differences in of verbal engagement between the conversational agent and adult partner. The study offers important implications for developing and researching conversational agent systems to support children's language development.
C1 [Xu, Ying; Collins, Penelope; Lee, Hyelim; Warschauer, Mark] Univ Calif Irvine, Sch Educ, Irvine, CA 92697 USA.
   [Wang, Dakuo] IBM Res AI, Cambridge, MA USA.
RP Xu, Y (corresponding author), Univ Calif Irvine, Sch Educ, Irvine, CA 92697 USA.
EM ying.xu@uci.edu
RI Wang, Dakuo/AAY-7314-2021; Collins, Penelope/AAV-1096-2020
OI Wang, Dakuo/0000-0001-9371-9441; Collins, Penelope/0000-0002-0818-3230;
   Lee, Hyelim/0000-0003-4721-6514
CR Admoni H, 2017, J HUM-ROBOT INTERACT, V6, P25, DOI 10.5898/JHRI.6.1.Admoni
   Aksan N, 2006, DEV PSYCHOL, V42, P833, DOI 10.1037/0012-1649.42.5.833
   Allen D, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P9845
   Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051
   Arnold D. H., 1994, ACCELERATING LANGUAG
   Bartneck C, 2007, AI SOC, V21, P217, DOI 10.1007/s00146-006-0052-7
   Belpaeme T, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aat5954
   Beneteau E, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376344
   Beneteau E, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300473
   Birbili M, 2009, J RES CHILD EDUC, V24, P18, DOI 10.1080/02568540903439359
   Blewitt P, 2009, J EDUC PSYCHOL, V101, P294, DOI 10.1037/a0013844
   Brush AJ, 2018, IEEE PERVAS COMPUT, V17, P82, DOI 10.1109/MPRV.2018.011591065
   Bus A. G., 2001, HDB EARLY LITERACY R, P171
   Cain K, 2000, READ WRIT, V13, P31, DOI 10.1023/A:1008051414854
   Callaghan MN, 2018, LEARN MEDIA TECHNOL, V43, P280, DOI 10.1080/17439884.2018.1498355
   Cambre Julia, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359325
   Chang CJ, 2016, APPL PSYCHOLINGUIST, V37, P387, DOI 10.1017/S0142716415000041
   Cheng Y, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P337, DOI 10.1145/3202185.3202749
   Chien C. W., 2013, ENGLISH TEACHING FOR, V51, P20
   Clark L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300705
   Cloud G., 2020, TECHNICAL REPORT
   Cohen J., 1988, STAT POWER ANAL BEHA, V2nd ed.
   Cooter KS, 2006, READ TEACH, V59, P698, DOI 10.1598/RT.59.7.9
   Davis HA, 2003, EDUC PSYCHOL-US, V38, P207, DOI 10.1207/S15326985EP3804_2
   de Graaf M, 2017, ACMIEEE INT CONF HUM, P224, DOI 10.1145/2909824.3020236
   Druga S, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P595, DOI 10.1145/3078072.3084330
   Dunn MJ, 2011, J PEDIATR PSYCHOL, V36, P565, DOI 10.1093/jpepsy/jsq062
   Fan M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1805, DOI 10.1145/3025453.3026048
   Farnia F, 2013, J RES READ, V36, P389, DOI 10.1111/jrir.12003
   Fink J, 2014, ACMIEEE INT CONF HUM, P439, DOI 10.1145/2559636.2559659
   Flipsen P, 2002, J SPEECH LANG HEAR R, V45, P100, DOI 10.1044/1092-4388(2002/008)
   Freed N. A., 2012, THESIS MIT
   Fryer LK, 2017, COMPUT HUM BEHAV, V75, P461, DOI 10.1016/j.chb.2017.05.045
   Funamoto A, 2015, INFANT MENT HEALTH J, V36, P3, DOI 10.1002/imhj.21481
   Garg Radhika, 2020, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V4, DOI 10.1145/3381002
   Garg R, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376631
   Gest SD, 2004, EARLY CHILD RES Q, V19, P319, DOI 10.1016/j.ecresq.2004.04.007
   Golinkoff RM, 2019, CHILD DEV, V90, P985, DOI 10.1111/cdev.13128
   Gordon G, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3951
   Groom V, 2008, ICINCO 2008: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, VOL RA-1, P323
   Grudin J., 2017, SYNTHESIS LECT HUMAN, V10, P1, DOI [10.2200/S00745ED1V01Y201612HCI035, DOI 10.2200/S00745ED1V01Y201612HCI035]
   Guo J., 2013, ENCY MICROFLUIDICS N, P1, DOI DOI 10.1007/978-1-4471-4784-8_2
   Hanson L., 1989, EDUC TECHNOL, V29, P15
   Heerink M., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P1045, DOI 10.1109/ROMAN.2012.6343887
   Hong ZW, 2016, EDUC TECHNOL SOC, V19, P337
   Hu TR, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173989
   Hyde J, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1787, DOI 10.1145/2556288.2557280
   Jacques R, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299034
   KAHLBAUGH PE, 1994, J NONVERBAL BEHAV, V18, P91, DOI 10.1007/BF02169080
   Kanero J, 2018, CHILD DEV PERSPECT, V12, P146, DOI 10.1111/cdep.12277
   Kendeou P, 2009, J EDUC PSYCHOL, V101, P765, DOI 10.1037/a0015956
   Kennedy J, 2016, ACMIEEE INT CONF HUM, P231, DOI 10.1109/HRI.2016.7451757
   Kennedy J, 2015, ACMIEEE INT CONF HUM, P67, DOI 10.1145/2696454.2696457
   Kim ES, 2013, J AUTISM DEV DISORD, V43, P1038, DOI 10.1007/s10803-012-1645-2
   Kim YS, 2014, READ WRIT, V27, P79, DOI 10.1007/s11145-013-9434-7
   Kim YSG, 2017, SCI STUD READ, V21, P310, DOI 10.1080/10888438.2017.1291643
   Kinsella B., 2020, NEARLY 90 MILLION US
   Kory J, 2014, IEEE ROMAN, P643, DOI 10.1109/ROMAN.2014.6926325
   Kory JM, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P71, DOI 10.1145/2522848.2531750
   Lee H., 2018, VOICE USER INTERFACE
   Lenhart J, 2018, EDUC PSYCHOL-UK, V38, P596, DOI 10.1080/01443410.2017.1363377
   Lever R, 2011, J EXP CHILD PSYCHOL, V108, P1, DOI 10.1016/j.jecp.2010.07.002
   Lin LJ, 2020, COMPUT EDUC, V143, DOI 10.1016/j.compedu.2019.103658
   Lovato Silvia, 2015, P 14 INT C INT DES C, P335, DOI [10.1145/2771839.2771910, DOI 10.1145/2771839.2771910]
   Lovato SB, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P301, DOI 10.1145/3311927.3323150
   Lovato SB, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00008
   Mack N, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P482, DOI 10.1145/3311927.3325336
   Manz PH, 2010, EARLY CHILD RES Q, V25, P409, DOI 10.1016/j.ecresq.2010.03.002
   Martin N. A., 2011, EXPRESSIVE ONE WORD
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Melson GF, 2009, J APPL DEV PSYCHOL, V30, P92, DOI 10.1016/j.appdev.2008.10.011
   Michaelis JE, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P301, DOI 10.1145/3025453.302549
   Mol SE, 2008, EARLY EDUC DEV, V19, P7, DOI 10.1080/10409280701838603
   Movellan J. R., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P307
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Nass C. I., 1997, Human values and the design of computer technology, P137
   Negi S. J, 2009, J NELTA, V14, P101, DOI [10.3126/nelta.v14i1.3096, DOI 10.3126/NELTA.V14I1.3096]
   O'Neal A. L., 2019, THESIS
   PAIVIO A, 1991, CAN J PSYCHOL, V45, P255, DOI 10.1037/h0084295
   Papadopoulos I, 2020, COMPUT EDUC, V155, DOI 10.1016/j.compedu.2020.103924
   Pauchet A, 2017, LECT NOTES ARTIF INT, V10498, P343, DOI 10.1007/978-3-319-67401-8_44
   Raphael T. E., 2006, QUESTION ANSWER RELA
   RAPHAEL TE, 1986, READ TEACH, V39, P516
   Rooy SCV, 2009, WORLD ENGLISH, V28, P15, DOI 10.1111/j.1467-971X.2008.01567.x
   Roth P, 2002, J EDUC RES, V95, P259, DOI 10.1080/00220670209596600
   Sabharwal N., 2020, COGNITIVE VIRTUAL AS, DOI [10.1007/978-1-4842-5741-8, DOI 10.1007/978-1-4842-5741-8]
   Sciuto A, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P857, DOI 10.1145/3196709.3196772
   Shamekhi A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173965
   Shanahan T, 2010, EDUC RESEARCHER, V39, P279, DOI 10.3102/0013189X10369172
   Smutny P, 2020, COMPUT EDUC, V151, DOI 10.1016/j.compedu.2020.103862
   Spolaor N, 2017, COMPUT EDUC, V112, P97, DOI 10.1016/j.compedu.2017.05.001
   Takacs ZK, 2018, J EXP CHILD PSYCHOL, V174, P1, DOI 10.1016/j.jecp.2018.04.013
   Tan HD, 2018, IEEE ROMAN, P129, DOI 10.1109/ROMAN.2018.8525584
   Tewari A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1807, DOI 10.1145/2556288.2557205
   VAQUERO C, 2006, 4 JORNADAS TECNOLOGI, P321
   VUKELICH C, 1976, LANG ARTS, V53, P889
   Westerveld MF, 2017, LANG SPEECH HEAR SER, V48, P260, DOI 10.1044/2017_LSHSS-17-0003
   Whorrall J, 2016, EARLY CHILD EDUC J, V44, P335, DOI 10.1007/s10643-015-0719-0
   Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496
   Xu Y, 2020, PROCEEDINGS OF IDC 2020, P216, DOI 10.1145/3392063.3394417
   Xu Y, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3383000
   Xu Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376416
   Xu Y, 2020, PROCEEDINGS OF IDC 2020, P361, DOI 10.1145/3392063.3394418
   Pham XL, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON EDUCATION AND E-LEARNING (ICEEL 2018), P16, DOI 10.1145/3291078.3291115
   Yen Kate, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274461
   Zevenbergen AA, 2003, CEN IM E R, P177
   Zhou MX, 2019, ACM T INTERACT INTEL, V9, DOI 10.1145/3232077
   Zhou N, 2017, ETR&D-EDUC TECH RES, V65, P1523, DOI 10.1007/s11423-017-9533-2
NR 108
TC 12
Z9 12
U1 6
U2 68
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0360-1315
EI 1873-782X
J9 COMPUT EDUC
JI Comput. Educ.
PD FEB
PY 2021
VL 161
AR 104059
DI 10.1016/j.compedu.2020.104059
PG 17
WC Computer Science, Interdisciplinary Applications; Education &
   Educational Research
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Education & Educational Research
GA PH9VI
UT WOS:000600750200006
OA Green Published
DA 2022-08-02
ER

PT C
AU Duan, W
   Yamashita, N
   Hwang, SY
   Fussell, S
AF Duan, Wen
   Yamashita, Naomi
   Hwang, Sun Young
   Fussell, Susan
GP ACM
TI "Let Me Ask Them to Clarify If You Don't Want To"-A Clarification Agent
   for Nonnative Speakers
SO CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS
   IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 21-26, 2018
CL Montreal, CANADA
SP Assoc Comp Machinery, ACM SIGCHI
DE Multilingual collaboration; conversational agents; computer-mediated
   communication
AB When non-native English speakers (NNS) encounter messages they do not understand, they are often reluctant to ask native speakers (NS) for clarification. In this paper, we explored whether a conversation agent that asks clarification questions would increase NNS' willingness to ask questions. We compared two agents: one that asked for clarification about specific message elements and one that asked general clarification questions. NNS and NS rated how disruptive the agent was, the quality of the conversation, and whether they would feel embarrassed to ask their own questions. NNS found both types of agent less disruptive than NS did, but both found the specific agent more disruptive than the generic agent. NS rated the conversations higher in quality than NNS, but there was no effect of agent condition. We discuss potential of using conversational agents to boost NNS's confidence in conversation.
C1 [Duan, Wen; Hwang, Sun Young; Fussell, Susan] Cornell Univ, Dept Commun, Ithaca, NY 14853 USA.
   [Yamashita, Naomi] NTT Commun Sci Labs, 2-4 Hikaridai, Seika, Kyoto, Japan.
RP Duan, W (corresponding author), Cornell Univ, Dept Commun, Ithaca, NY 14853 USA.
EM wd238@cornell.edu; naomiy@acm.org; sh2284@cornell.edu;
   sfussell@cornell.edu
FU NSF [1421929]
FX This work was funded in part by NSF grant #1421929. We thank the NTT
   development team for their technical support.
CR Clark H.H, 1996, USING LANGUAGE
   Gao G, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3463, DOI 10.1145/2702123.2702498
   He Helen Ai, 2017, Proceedings of the ACM on Human-Computer Interaction, V1, DOI 10.1145/3134686
   Li H. Z., 2005, J INTERCULTURAL COMM, V34, P233
   Rieser Verena, 2005, ASS COMPUTATIONAL LI, P239
   Yamashita N., 2013, P CSCW 2013, P923
NR 6
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5621-3
PY 2018
AR LBW524
DI 10.1145/3170427.3188600
PG 6
WC Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR8DX
UT WOS:000671090001139
DA 2022-08-02
ER

PT C
AU Mitchell, EG
   Maimone, R
   Mamykina, L
AF Mitchell, Elliot G.
   Maimone, Rosa
   Mamykina, Lena
GP Assoc Comp Machinery
TI Characterizing Human vs. Automated Coaching: Preliminary Results
SO CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS
   IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT ACM CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 25-30, 2020
CL Honolulu, HI
SP ACM SIGCHI, Assoc Comp Machinery
DE Conversational agents; health coaching; wizard-of-oz
AB Some have argued that human skills and abilities are essential to effective health coaching and cannot be replicated by conversational agents. We sought to understand the differences in interaction patterns between two group of participants. In one group, participants messaged with a wizard-of-oz (woz) conversational health coach. In the other group, participants messaged with an actual health coach who was given the same script as the agent, but encouraged to deviate from the script when necessary. We found that conversational patterns differed between the groups, with longer conversations in the human coach group. However, participants were not more likely to respond to messages from the human coach than the woz agent, and were more likely to proactively message the woz agent than the human coach. We discuss implications for the design of conversational health coaches.
C1 [Mitchell, Elliot G.; Mamykina, Lena] Columbia Univ, New York, NY 10032 USA.
   [Maimone, Rosa] Fdn Bruno Kessler, Trento, Italy.
RP Mitchell, EG (corresponding author), Columbia Univ, New York, NY 10032 USA.
EM egm2143@cumc.columbia.edu; rmaimone@fbk.eu; om2196@cumc.columbia.edu
CR [Anonymous], ART INT ROADM
   Bickmore TW, 2010, J HEALTH COMMUN, V15, P197, DOI 10.1080/10810730.2010.499991
   Bray GA, 2009, LANCET, V374, P1677, DOI 10.1016/S0140-6736(09)61457-4
   Clark L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300705
   Cole-Lewis HJ, 2016, INT J MED INFORM, V85, P96, DOI 10.1016/j.ijmedinf.2015.08.003
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Gao JF, 2018, ACM/SIGIR PROCEEDINGS 2018, P1371, DOI 10.1145/3209978.3210183
   Grudin J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300439
   Gutnick Damara, 2014, BRIEF ACTION PLANNIN
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Olsen JM, 2014, NURS FORUM, V49, P18, DOI 10.1111/nuf.12042
   Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553
   Rishe N, 2013, ACM TMIS, V4, P1, DOI [10.1145/2544103, DOI 10.1145/2544103]
   Rutjes H, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300900
   Schulman D., 2011, 2011 AAAI SPRING S S
   Serban Iulian Vlad, 2015, SURVEY AVAILABLE COR, DOI [10.5087/dad, DOI 10.5087/DAD]
NR 17
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6819-3
PY 2020
AR LBW160
DI 10.1145/3334480.3383081
PG 8
WC Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ9OG
UT WOS:000626317803110
DA 2022-08-02
ER

PT J
AU Rawassizadeh, R
   Sen, T
   Kim, SJ
   Meurisch, C
   Keshavarz, H
   Muhlhauser, M
   Pazzani, M
AF Rawassizadeh, Reza
   Sen, Taylan
   Kim, Sunny Jung
   Meurisch, Christian
   Keshavarz, Hamidreza
   Muehlhaeuser, Max
   Pazzani, Michael
TI Manifestation of virtual assistants and robots into daily life: vision
   and challenges
SO CCF TRANSACTIONS ON PERVASIVE COMPUTING AND INTERACTION
LA English
DT Review
DE Robot; Virtual assistant; Conversational agents; Ubiquitous computing
AB Similar to how the smartphone and Internet have significantly changed our daily lives, artificial intelligence (AI) applications have started to profoundly affect our everyday lives as well. Two major products of this relatively recent trend are virtual assistants and home robots. They have similar functional characteristics: both interact with users through conversational agents and attempt to imitate human behavior. Home robots host a virtual assistant and have mechanical capabilities as well. There are many discussions about risks, challenges and the future vision associated with the proliferation of AI at the industrial level. These discussions, however, have not yet widely extended to the user level within the context of daily lives. In this article, we provide a review to discuss the benefits, risks, challenges, open questions and the future vision of using virtual assistants and social robots in daily lives.
C1 [Rawassizadeh, Reza] Boston Univ, Dept Comp Sci, Metropolitan Coll, Boston, MA 02118 USA.
   [Sen, Taylan] Univ Rochester, Dept Comp Sci, New York, NY USA.
   [Kim, Sunny Jung] Virginia Commonwealth Univ, Sch Med, Dept Hlth Behav & Policy, Massey Canc Ctr, Richmond, VA USA.
   [Meurisch, Christian; Muehlhaeuser, Max] Tech Univ Darmstadt, Telecooperat Grp, Dept Comp Sci, Darmstadt, Germany.
   [Keshavarz, Hamidreza] Tarbiat Modares Univ, Fac Elect & Comp Engn, Tehran, Iran.
   [Pazzani, Michael] Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA.
RP Rawassizadeh, R (corresponding author), Boston Univ, Dept Comp Sci, Metropolitan Coll, Boston, MA 02118 USA.
EM rezar@bu.edu
RI Kim, Sunny Jung/AAP-2658-2020
OI Kim, Sunny Jung/0000-0002-6405-162X; Rawassizadeh,
   Reza/0000-0002-2607-1777; Pazzani, Michael/0000-0002-4240-7349
CR Alom, 2018, HIST BEGAN ALEXNET C
   [Anonymous], 2018, ARXIV180807042
   Bacon D., 2016, P NIPS WORKSH PRIV M
   Borenstein J, 2018, IEEE ROBOT AUTOM MAG, V25, P46, DOI 10.1109/MRA.2017.2778743
   Cerrudo C., 2017, HACKING ROBOTS SKYNE
   Chen Edward. T., 2017, INTERNET THINGS MODE, P167
   Cohen P., 2016, P 2016 CHI C HUM FAC, V07-12, P1032
   Deng L, 2013, INT CONF ACOUST SPEE, P8604, DOI 10.1109/ICASSP.2013.6639345
   Druga S, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P595, DOI 10.1145/3078072.3084330
   Druga S, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P231, DOI 10.1145/3202185.3202741
   Fang H., 2017, ALEXA PRIZE P
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Guha R, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P275, DOI 10.1145/2684822.2685309
   Gusev M, 2017, 2017 40TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P387, DOI 10.23919/MIPRO.2017.7973454
   HOFSTADTER D, 1980, GODEL ESCHER BACH ET
   Javaheri A., 2019, ARXIV PREPRINT ARXIV
   Jennings NR, 2014, COMMUN ACM, V57, P80, DOI 10.1145/2629559
   Kline R., 2018, SCIENCE, V361, P657
   Klopfenstein LC, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P555, DOI 10.1145/3064663.3064672
   Laput G, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3986, DOI 10.1145/3025453.3025773
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leite I, 2013, INT J SOC ROBOT, V5, P291, DOI 10.1007/s12369-013-0178-y
   Lovato Silvia, 2015, P 14 INT C INT DES C, P335, DOI [10.1145/2771839.2771910, DOI 10.1145/2771839.2771910]
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Maalej W, 2016, IEEE SOFTWARE, V33, P48, DOI 10.1109/MS.2015.153
   MacDorman KF, 2016, COGNITION, V146, P190, DOI 10.1016/j.cognition.2015.09.019
   Milhorat P, 2019, LECT NOTES ELECTR EN, V510, P119, DOI 10.1007/978-3-319-92108-2_14
   Moore RJ, 2018, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-3-319-95579-7_1
   Rawassizadeh R, 2020, IEEE T KNOWL DATA EN, V32, P2185, DOI 10.1109/TKDE.2019.2914653
   Rawassizadeh R, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030448
   Rawassizadeh R, 2018, IEEE PERVAS COMPUT, V17, P64, DOI 10.1109/MPRV.2018.011591063
   Rawassizadeh R, 2016, IEEE T KNOWL DATA EN, V28, P3098, DOI 10.1109/TKDE.2016.2592527
   Rawassizadeh R, 2015, COMMUN ACM, V58, P45, DOI 10.1145/2629633
   Russell S., 2009, ARTIFICIAL INTELLIGE
   Sharit J, 2014, J USABILITY STUD, V9, P173
   Sioni SR, 2017, COMPUT HUM BEHAV, V71, P11, DOI 10.1016/j.chb.2017.01.044
   Su Grace, 2018, AI Matters, V3, P35, DOI 10.1145/3175502.3175511
   Tegmark M., 2017, LIFE 3 0 BEING HUMAN, DOI 10.1080/24701475.2019.1565556
   Turing A.M., 1950, MIND, V59, P433, DOI [10.1093/mind/LIX.236.433, DOI 10.1093/MIND/LIX.236.433]
   Verto Analytics, 2017, RIS MACH AI DRIV PER
   Walsh T, 2018, INT J AUTOM COMPUT, V15, P637, DOI 10.1007/s11633-018-1127-x
   Waytz A, 2010, PERSPECT PSYCHOL SCI, V5, P219, DOI 10.1177/1745691610369336
   Westlund JMK, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P207, DOI 10.1145/3202185.3202732
   Wiener N., 1948, CYBERNETICS CONTROL
   Wu YH, 2016, J APPL GERONTOL, V35, P3, DOI 10.1177/0733464813515092
NR 46
TC 7
Z9 7
U1 8
U2 11
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 2524-521X
EI 2524-5228
J9 CCF T PERVAS COMPUT
JI CCF Trans. Pervas. Comput. Interact.
PD NOV
PY 2019
VL 1
IS 3
SI SI
BP 163
EP 174
DI 10.1007/s42486-019-00014-1
PG 12
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA WL6XR
UT WOS:000710546600001
DA 2022-08-02
ER

PT C
AU Kucherenko, T
   Jonell, P
   Yoon, Y
   Wolfert, P
   Henter, GE
AF Kucherenko, Taras
   Jonell, Patrik
   Yoon, Youngwoo
   Wolfert, Pieter
   Henter, Gustav Eje
GP ASSOC COMP MACHINERY
TI A Large, Crowdsourced Evaluation of Gesture Generation Systems on Common
   Data: The GENEA Challenge 2020
SO IUI '21 - 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES
LA English
DT Proceedings Paper
CT 26th International Conference on Intelligent User Interfaces (IUI)
CY APR 13-17, 2021
CL ELECTR NETWORK
SP Texas A & M Univ, Google, Microsoft, MDPI, Multimodal Technologies & Interact, AAAS, Sci Robot
DE gesture generation; conversational agents; evaluation paradigms
ID SPEECH; ANIMATION
AB Co-speech gestures, gestures that accompany speech, play an important role in human communication. Automatic co-speech gesture generation is thus a key enabling technology for embodied conversational agents (ECAs), since humans expect ECAs to be capable of multi-modal communication. Research into gesture generation is rapidly gravitating towards data-driven methods. Unfortunately, individual research efforts in the field are difficult to compare: there are no established benchmarks, and each study tends to use its own dataset, motion visualisation, and evaluation methodology. To address this situation, we launched the GENEA Challenge, a gesture-generation challenge wherein participating teams built automatic gesture-generation systems on a common dataset, and the resulting systems were evaluated in parallel in a large, crowdsourced user study using the same motion-rendering pipeline. Since differences in evaluation outcomes between systems now are solely attributable to differences between the motion-generation methods, this enables benchmarking recent approaches against one another in order to get a better impression of the state of the art in the field. This paper reports on the purpose, design, results, and implications of our challenge.
C1 [Kucherenko, Taras] KTH Royal Inst Technol, Div Robot Percept & Learning, Stockholm, Sweden.
   [Jonell, Patrik; Henter, Gustav Eje] KTH Royal Inst Technol, Div Speech Mus & Hearing, Stockholm, Sweden.
   [Yoon, Youngwoo] ETRI, Daejeon, South Korea.
   [Yoon, Youngwoo] Korea Adv Inst Sci & Technol, Daejeon, South Korea.
   [Wolfert, Pieter] Univ Ghent, Imec, IDLab, Ghent, Belgium.
RP Kucherenko, T (corresponding author), KTH Royal Inst Technol, Div Robot Percept & Learning, Stockholm, Sweden.
EM tarask@kth.se; pjjonell@kth.se; youngwoo@etri.re.kr;
   pieter.wolfert@ugent.be; ghe@kth.se
OI Kucherenko, Taras/0000-0001-9838-8848
FU Swedish Foundation for Strategic Research [RIT15-0107]; IITP - Korean
   government (MSIT) [2017-0-00162]; Flemish Research Foundation
   [1S95020N]; Wallenberg AI, Autonomous Systems and Software Program
   (WASP) - Knut and Alice Wallenberg Foundation
FX This research was partially supported by Swedish Foundation for
   Strategic Research contract no. RIT15-0107 (EACare), by IITP grant no.
   2017-0-00162 (Development of Human-care Robot Technology for Aging
   Society) funded by the Korean government (MSIT), the Flemish Research
   Foundation grant no. 1S95020N, and by the Wallenberg AI, Autonomous
   Systems and Software Program (WASP) funded by the Knut and Alice
   Wallenberg Foundation.
CR Alexanderson S, 2020, COMPUT GRAPH FORUM, V39, P487, DOI 10.1111/cgf.13946
   Alexanderson Simon, 2020, P GENEA WORKSH, DOI [10.5281/zenodo.4088600, DOI 10.5281/ZENODO.4088600]
   Bergmann K, 2010, LECT NOTES ARTIF INT, V6356, P104, DOI 10.1007/978-3-642-15892-6_11
   Bergmann K, 2009, LECT NOTES ARTIF INT, V5773, P76
   BLACK AW, 2005, P INT 2005, P77
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacl_a_00051]
   BOYNTON RM, 1989, P SOC PHOTO-OPT INS, V1077, P322
   Cassell J, 2001, COMP GRAPH, P477
   Charfuelan M, 2013, INTERSPEECH, P1563
   Chiu CC, 2015, LECT NOTES ARTIF INT, V9238, P152, DOI 10.1007/978-3-319-21996-7_17
   Ferstl Y, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P93, DOI 10.1145/3267851.3267898
   Ginosar S, 2019, PROC CVPR IEEE, P3492, DOI 10.1109/CVPR.2019.00361
   Govender A., 2019, P INTERSPEECH, P1551
   Grassia, 1998, J GRAPHICS TOOLS, V3, P29, DOI [DOI 10.1080/10867651.1998.10487493, 10.1080/10867651.1998.10487493]
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3483
   Hahn Gerald J., 1991, STAT INTERVALS GUIDE, V92
   Holler J, 2018, PSYCHON B REV, V25, P1900, DOI 10.3758/s13423-017-1363-z
   HOLM S, 1979, SCAND J STAT, V6, P65
   International Telecommunication Union Radiocommunication Sector, 2015, RECOMMENDATION ITU R
   International Telecommunication Union Telecommunication Standardisation Sector, 1996, METH SUBJ DET TRANSM
   Ishi CT, 2018, IEEE ROBOT AUTOM LET, V3, P3757, DOI 10.1109/LRA.2018.2856281
   Ishii R, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P87, DOI 10.1145/3267851.3267866
   Jonell P, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423911
   Jonell P, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423860
   Jonell Patrik, ARXIV210111898
   King S, 2014, LOQUENS, V1, DOI 10.3989/loquens.2014.006
   Korzun Vladislav, 2020, P GENEA WORKSH, DOI 10.5281/zenodo.4088609
   Kucherenko Taras, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P242, DOI 10.1145/3382507.3418815
   Kucherenko T, 2021, INT J HUM-COMPUT INT, V37, P1300, DOI 10.1080/10447318.2021.1883883
   Kucherenko T, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P97, DOI 10.1145/3308532.3329472
   Kucherenko T, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P520, DOI 10.1145/3242969.3264970
   Kucherenko Taras, 2020, GENEA CHALLENGE 2020, DOI [10.5281/zenodo.4094697, DOI 10.5281/ZENODO.4094697]
   Le Quoc Anh, 2012, EVALUATING EXPRESSIV
   Levine S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778861
   Lu JinHong, 2020, P GENEA WORKSH, DOI [10.5281/zenodo.4088376Proc.GENEA, DOI 10.5281/ZENODO.4088376PROC.GENEA]
   McNeill D., 1992, HAND MIND WHAT GESTU
   Mittag G., 2020, P INTERSPEECH, P1748
   Moller S, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1325
   MORASSO P, 1981, EXP BRAIN RES, V42, P223
   Nikulin Mikhail S., 2001, ENCY MATH
   NTIRE Challenge organisers,, 2020, NTIRE 2020 PERC EXTR
   Pang Kunkun, 2020, P GENEA WORKSH, DOI [10.5281/zenodo.4090879, DOI 10.5281/ZENODO.4090879]
   Pennington J., 2014, P 2014 C EMPIRICAL M, P1532
   Ribeiro MS, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1586
   Sadoughi N, 2019, SPEECH COMMUN, V110, P90, DOI 10.1016/j.specom.2019.04.005
   Salem M., 2011, 2011 RO-MAN: The 20th IEEE International Symposium on Robot and Human Interactive Communication, P247, DOI 10.1109/ROMAN.2011.6005285
   Salem M, 2013, INT J SOC ROBOT, V5, P313, DOI 10.1007/s12369-013-0196-9
   Salem M, 2012, INT J SOC ROBOT, V4, P201, DOI 10.1007/s12369-011-0124-9
   Salvi G, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/191940
   Saratxaga I, 2016, SPEECH COMMUN, V81, P30, DOI 10.1016/j.specom.2016.04.001
   SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047
   Szekely E, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3335
   Thangthai Ausdang, 2020, P GENEA WORKSH, DOI [10.5281/zenodo.4088629, DOI 10.5281/ZENODO.4088629]
   Toderici George, 2020, CLIC WORKSH CHALL LE
   UNO Y, 1989, BIOL CYBERN, V61, P89
   Wagner P, 2014, SPEECH COMMUN, V57, P209, DOI 10.1016/j.specom.2013.09.008
   Wester M, 2016, INTERSPEECH, P1637, DOI 10.21437/Interspeech.2016-1331
   Wolfert P., 2019, ICDL EPIROB 2019 WOR, P4
   Wolfert Pieter, ARXIV210103769
   Yoon Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417838
   Yoon Y, 2019, IEEE INT CONF ROBOT, P4303, DOI 10.1109/ICRA.2019.8793720
   Yoshimura T, 2016, INTERSPEECH, P342, DOI 10.21437/Interspeech.2016-847
NR 62
TC 8
Z9 8
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8017-1
PY 2021
BP 11
EP 21
DI 10.1145/3397481.3450692
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS6FR
UT WOS:000747690200006
OA Green Published, Bronze, Green Submitted
DA 2022-08-02
ER

PT C
AU Huber, B
   McDuff, D
   Brockett, C
   Galley, M
   Dolan, B
AF Huber, Bernd
   McDuff, Daniel
   Brockett, Chris
   Galley, Michel
   Dolan, Bill
GP ACM
TI Emotional Dialogue Generation using Image-Grounded Language Models
SO PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING
   SYSTEMS (CHI 2018)
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 21-26, 2018
CL Montreal, CANADA
SP Assoc Comp Machinery, ACM SIGCHI
DE Dialogue; conversation; emotion; computer vision; conversational agents
AB Computer-based conversational agents are becoming ubiquitous. However, for these systems to be engaging and valuable to the user, they must be able to express emotion, in addition to providing informative responses. Humans rely on much more than language during conversations; visual information is key to providing context. We present the first example of an image-grounded conversational agent using visual sentiment, facial expression and scene features. We show that key qualities of the generated dialogue can be manipulated by the features used for training the agent. We evaluate our model on a large and very challenging real-world dataset of conversations from social media (Twitter). The image-grounding leads to significantly more informative, emotional and specific responses, and the exact qualities can be tuned depending on the image features used. Furthermore, our model improves the objective quality of dialogue responses when evaluated on standard natural language metrics.
C1 [Huber, Bernd] Harvard Univ, Cambridge, MA 02138 USA.
   [Huber, Bernd; McDuff, Daniel; Brockett, Chris; Galley, Michel; Dolan, Bill] Microsoft Res, Redmond, WA 98052 USA.
RP Huber, B (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.; Huber, B (corresponding author), Microsoft Res, Redmond, WA 98052 USA.
EM bhb@seas.harvard.edu; damcduff@microsoft.com;
   chris.brockett@microsoft.com; mgalley@microsoft.com;
   billdol@microsoft.com
CR AndrewShin Y.U., 2016, P BRIT MACHINE VISIO
   Antoine Jean-Yves, 2014, EACL 2014
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Baltrusaitis T., 2016, PROC WACV, P1, DOI DOI 10.1109/WACV.2016.7477553
   Bennett FM, 1954, PUBLIC OPIN QUART, V18, P303
   Bickmore T., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P396
   Bickmore T. W., 2005, ACM Transactions on Computer-Human Interaction, V12, P293, DOI 10.1145/1067860.1067867
   Bickmore TW, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5239
   Cassell J, 2000, EMBODIED CONVERSATIONAL AGENTS, P29
   Cranshaw J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2382, DOI 10.1145/3025453.3025780
   Cui L, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P97, DOI 10.18653/v1/P17-4017
   Das A, 2017, IEEE I CONF COMP VIS, P2970, DOI 10.1109/ICCV.2017.321
   Das Abhishek, 2017, VISUAL DIALOG
   DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061
   Ekman P, 2002, FACIAL ACTION CODING
   Galley M, 2015, ARXIV150606863
   Ghosh S., 2017, ARXIV170406851
   Graham Y., 2015, P 2015 C N AM CHAPTE, P1183
   Gratch J, 2007, LECT NOTES ARTIF INT, V4722, P125
   Gwet K.L., 2014, HDB INTERRATER RELIA, V4th ed
   Hornbaek K, 2006, INT J HUM-COMPUT ST, V64, P79, DOI 10.1016/j.ijhcs.2005.06.002
   Jou B, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P159, DOI 10.1145/2733373.2806246
   Kassam K. S., 2010, ASSESSMENT EMOTIONAL
   Krippendorff K., 2011, COMPUTING KRIPPENDOR
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li J., 2016, P 2016 C N AM CHAPT, P110, DOI DOI 10.18653/V1/N16-1014
   Liu C., 2016, EMNLP, P2122, DOI DOI 10.18653/V1/D16-1230
   Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288
   Mathews A, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3574
   Matsuyama Y., 2016, P 17 ANN M SPEC INT, P224
   Mikolov T, 2013, EFFICIENT ESTIMATION, P1
   Morris MR, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5506, DOI 10.1145/2858036.2858116
   Morris MR, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1739
   Mostafazadeh N., 2017, ARXIV170108251
   Mostafazadeh N, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1802
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pennington J., 2014, P 2014 C EMPIRICAL M, P1532
   Przybocki M, 2008, METRICSMATR08 WORKSH
   Riggio R.E., 1992, APPL NONVERBAL BEHAV, P3
   Ritter A., 2011, P C EMP METH NAT LAN, P583
   Serban IV, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3776
   Shang LF, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1577
   Shechtman N., 2003, P SIGCHI C HUM FACT, P281, DOI [DOI 10.1145/642611.642661, 10.1145/642611.642661]
   Sordoni A., 2015, P 2015 C N AM CHAPT, P196, DOI DOI 10.3115/V1/N15-1020
   Sutskever I., 2014, ADV NEURAL INFORM PR, P3104
   Vinyals O, 2015, COMPUTER SCI
   Walker MA, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P271
   Weitz S., 2014, MEET XIAOICE CORTANA
   Wen T., 2016, PROC 2016 C EMPIRICA, P2153
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   You QZ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1445, DOI 10.1145/2964284.2971475
   Zhou B, 2014, ADV NEURAL INFORM PR, P487, DOI DOI 10.1162/153244303322533223
NR 52
TC 16
Z9 16
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-5620-6
PY 2018
DI 10.1145/3173574.3173851
PG 12
WC Computer Science, Cybernetics; Computer Science, Information Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BO2ZO
UT WOS:000509673103039
DA 2022-08-02
ER

PT C
AU Ahmad, R
   Siemon, D
   Robra-Bissantz, S
AF Ahmad, Rangina
   Siemon, Dominik
   Robra-Bissantz, Susanne
GP Assoc Informat Syst
TI ExtraBot vs IntroBot: The Influence of Linguistic Cues on Communication
   Satisfaction
SO AMCIS 2020 PROCEEDINGS
LA English
DT Proceedings Paper
CT Conference of the Association-for-Information-Systems (AMCIS)
CY AUG 10-14, 2020
CL ELECTR NETWORK
SP Assoc Informat Syst
DE Conversational Agents; Personality; Language; Chatbots; Big Five
ID COMPUTER PERSONALITIES; LANGUAGE
AB Conversational agents (CA) have emerged as a new type of dialogue systems, able to simulate human conversation. However, research suggests that current CAs fail to provide convincing interactions due to a lack of satisficing communication with users. To address this problem, we propose the idea of a personality adaptive CA that could enhance communication satisfaction during a user's interaction experience. As personality differences manifest themselves in language cues, we investigate in an experiment, whether linguistic styles have an influence regarding a user's communication satisfaction, when interacting with a CA. The results show that users perceive greater satisfaction when communicating with an extraverted CA (ExtraBot) than with an introverted CA (IntroBot). The outcomes of our study highlight that different linguistic styles can influence the course of the conversation and determine whether the user is satisfied with the communication and sees any value in the interaction with the CA.
C1 [Ahmad, Rangina; Siemon, Dominik; Robra-Bissantz, Susanne] TU Braunschweig, Braunschweig, Germany.
RP Ahmad, R (corresponding author), TU Braunschweig, Braunschweig, Germany.
EM rangina.ahmad@tu-bs.de; d.siemon@tu-bs.de; s.robra-bissantz@tu-bs.de
CR Abu Shawar BA and Atwell ES, 2007, J LANG TECHNOL COMPU, V22, P29
   ALLPORT GW, 1961, PATTERNS GROWTH PERS
   Back MD, 2009, J PERS SOC PSYCHOL, V97, P533, DOI 10.1037/a0016229
   Beukeboom CJ, 2013, J LANG SOC PSYCHOL, V32, P191, DOI 10.1177/0261927X12460844
   Botsociety, 2020, DES PREV PROT YOUR N
   Boyd RL, 2017, CURR OPIN BEHAV SCI, V18, P63, DOI 10.1016/j.cobeha.2017.07.017
   Charness G, 2012, J ECON BEHAV ORGAN, V81, P1, DOI 10.1016/j.jebo.2011.08.009
   Costa Jr PT, 2008, SAGE HDB PERSONALITY, P179, DOI [10.4135/9781849200479.n9, DOI 10.4135/9781849200479.N9]
   Dennis A.R., 2001, COMMUN ASSOC INF SYS, V7, DOI [10.17705/1CAIS.00705, DOI 10.17705/1CAIS.00705]
   Diederich S., 2019, ICIS 2019 P
   Downs JS, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2399
   Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009
   FURNHAM A, 1990, CURR PSYCHOL RES REV, V9, P46, DOI 10.1007/BF02686767
   Gill Alastair J, 2002, P ANN M COGN SCI SOC, V24
   Gnewuch U., 2017, DESIGNING COOPERATIV
   Golbeck J., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P149, DOI 10.1109/PASSAT/SocialCom.2011.33
   GRONROOS C, 1982, EUR J MARKETING, V16, P30, DOI 10.1108/eum0000000004859
   Grudin J., 2019, P 2019 CHI C HUM FAC, P1
   Guzman A.L., 2018, HUMAN MACHINE COMMUN, P1
   Hecht ML., 1978, HUM COMMUN RES, V4, P253, DOI DOI 10.1111/J.1468-2958.1978.TB00614.X
   IBM Watson PI, 2020, IBM WATS PERS INS
   Kim H., 2019, 2019 CHI C HUM FACT, P1
   Knijnenburg BP, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2963106
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lee SY, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8070794
   Mairesse F, 2007, J ARTIF INTELL RES, V30, P457, DOI 10.1613/jair.2349
   Mallios S., 2016, 2016 JUL PRESENTED 2, P1, DOI [10.1109/IISA.2016.7785371, DOI 10.1109/IISA.2016.7785371]
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   McTear M.F., 2016, CONVERSATIONAL INTER, V6
   Moon Y, 1996, COMMUN RES, V23, P651, DOI 10.1177/009365096023006002
   Mustelier-Puig LC, 2018, COGENT BUS MANAG, V5, P1, DOI 10.1080/23311975.2018.1470890
   NASS C, 1995, INT J HUM-COMPUT ST, V43, P223, DOI 10.1006/ijhc.1995.1042
   Pennebaker J. W., 2011, SECRET LIFE PRONOUNS
   Pennebaker JW, 1999, J PERS SOC PSYCHOL, V77, P1296, DOI 10.1037/0022-3514.77.6.1296
   Pilato G., 2010, SEMANTIC COMPUTING, P357
   Robert L. P., 2020, ARXIV PREPRINT ARXIV
   Robert L. P., 2018, PROC 24 AMERICAS C I, P16
   Robra-Bissantz S., 2018, SERVICE BUSINESS DEV, V1, P261
   Scherer KR, 1979, PERSONALITY MARKERS
   Schuetzler R., 2014, ICIS 2014 P
   Smestad TL, 2019, LECT NOTES COMPUT SC, V11551, P170, DOI 10.1007/978-3-030-17705-8_15
   SNYDER M, 1983, J PERS, V51, P497, DOI 10.1111/j.1467-6494.1983.tb00342.x
   Stieglitz S., 2018, ICIS
   Strohmann T., 2019, P WORKSH DES US ASS
   Turing AM., 1950, J MIND ASS, V59, P433, DOI [10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   Yarkoni T, 2010, J RES PERS, V44, P363, DOI 10.1016/j.jrp.2010.04.001
   Ye HF, 2017, 2017 IEEE CONFERENCE ON ELECTRICAL INSULATION AND DIELECTRIC PHENOMENON (CEIDP), P552, DOI 10.1109/CEIDP.2017.8257550
   You S, 2018, J ASSOC INF SYST, V19, P377, DOI 10.17705/1jais.00496
NR 48
TC 0
Z9 0
U1 0
U2 2
PU ASSOC INFORMATION SYSTEMS
PI ATLANTA
PA P.O. BOX 2712, ATLANTA, GA 30301-2712 USA
BN 978-1-7336325-4-6
PY 2020
PG 10
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP6LR
UT WOS:000559924501082
DA 2022-08-02
ER

PT C
AU Rossini, N
AF Rossini, Nicla
BE Esposito, A
   Esposito, AM
   Martone, R
   Muller, VC
   Scarpetta, G
TI Patterns of Synchronization of Non-verbal Cues and Speech in ECAs:
   Towards a More "Natural" Conversational Agent
SO TOWARD AUTONOMOUS, ADAPTIVE, AND CONTEXT-AWARE MULTIMODAL INTERFACES:
   THEORETICAL AND PRACTICAL ISSUES
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 3rd EUCOGII-COST 2102 International Training School
CY MAR 15-19, 2010
CL Caserta, ITALY
SP European Cooperat Sci & Technol, EUCogII 2nd European Network Adv Artificial, 2nd Univ Naples, Int Inst Adv Sci Studies ER Caianiello, Soc Italiana Reti Neuroniche, Regione Campania, Provincia Salerno
DE Embodied Conversational Agents; Prosody; Non-verbal Communication;
   Expressions; Gesture-Speech Synchronization
ID GESTURE
AB This paper presents an analysis of the verbal and non-verbal cues of Conversational Agents, with a special focus on REA and GRETA, in order to allow further research aimed at correcting some traits of their performance still considered unnatural by their final users. Despite the striking performance of new generation ECA, some important features make these conversational agents unreliable to the users, who usually prefer interacting with a classical computer for information retrieval. The users' preference can be due to several factors, such as the quality of speech synthesis, or the inevitable unnaturalness of the graphics animating the avatar. Apart from the unavoidable traits that can render ECAs unnatural to the ultimate users, instances of poor synchronization between verbal and non-verbal behaviour may contribute to unfavourable results. An instance of synchronization patterns between non-verbal cues and speech is here analysed and re-applied to the basic architecture of an ECA in order to improve the ECA's verbal and non-verbal synchronization. A proposal for future inquiry aimed at creating alternative model for the ultimate Mp4 output is also proposed, for further development in this field.
C1 Univ Piemonte Orientale, Dipartimento Studi Umanistici, LiCoTT Palazzo Tartara, I-13100 Vercelli, Italy.
RP Rossini, N (corresponding author), Univ Piemonte Orientale, Dipartimento Studi Umanistici, LiCoTT Palazzo Tartara, Via G Ferraris 109, I-13100 Vercelli, Italy.
EM rossini@lett.unipmn.it
CR CASSELL J, 2005, 2 ISGS C INT BOD EC
   CASSELL J, 2001, WORKSH REPR ANN EV N
   CASSELL J, 2002, P IMAGINA 2002 MONT
   Cassell J., 1999, P SIGCHI C HUM FACT, P520, DOI DOI 10.1145/302979.303150
   Eibl-Eibesfeldt I., 1972, NONVERBAL COMMUNICAT
   GIBBON D, 2009, P GESPIN 20 IN PRESS
   Hartmann B, 2006, LECT NOTES ARTIF INT, V3881, P188
   KITA S, NONLINGUIST IN PRESS
   Mancini M, 2007, IEEE T AUDIO SPEECH, V15, P1833, DOI 10.1109/TASL.2007.899256
   McNeill D., 1992, HAND MIND WHAT GESTU
   Niewiadomski R, 2008, LECT NOTES COMPUT SC, V5208, P37
   Poggi I, 1998, SPEECH COMMUN, V26, P5, DOI 10.1016/S0167-6393(98)00047-8
   Rossini N, 2003, LECT NOTES ARTIF INT, V2915, P124
   ROSSINI N., 2004, THESIS U PAVIA
   ROSSINI N., 2009, GESTO GESTUALITA TRA
   ROSSINI N, 2004, INTERCULTURAL COMMUN, V13, P144
   THIES A, 2003, THESIS U BIELEFELD
NR 17
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 978-3-642-18183-2
J9 LECT NOTES COMPUT SC
PY 2011
VL 6456
BP 96
EP 103
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BUX99
UT WOS:000290654500009
DA 2022-08-02
ER

PT C
AU Wambsganss, T
   Winkler, R
   Sollner, M
   Leimeister, JM
AF Wambsganss, Thiemo
   Winkler, Rainer
   Soellner, Matthias
   Leimeister, Jan Marco
GP Assoc Comp Machinery
TI A Conversational Agent to Improve Response Quality in Course Evaluations
SO CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS
   IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT ACM CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 25-30, 2020
CL Honolulu, HI
SP ACM SIGCHI, Assoc Comp Machinery
DE Conversational Agents; Online Course Evaluations; Field Experiment
ID LANGUAGE
AB Recent advances in Natural Language Processing (NLP) bear the opportunity to design new forms of human-computer interaction with conversational interfaces. We hypothesize that these interfaces can interactively engage students to increase response quality of course evaluations in education compared to the common standard of web surveys. Past research indicates that web surveys come with disadvantages, such as poor response quality caused by inattention, survey fatigue or satisficing behavior. To test if conversational interfaces have a positive impact on the level of enjoyment and the response quality, we design an NLP-based conversational agent and deploy it in a field experiment with 127 students in our lecture and compare it with a web survey as a baseline. Our findings indicate that using conversational agents for evaluations are resulting in higher levels of response quality and level of enjoyment, and are therefore, a promising approach to increase the effectiveness of surveys in general.
C1 [Wambsganss, Thiemo; Winkler, Rainer; Soellner, Matthias; Leimeister, Jan Marco] Univ St Gallen, St Gallen, Switzerland.
   [Soellner, Matthias; Leimeister, Jan Marco] Univ Kassel, Kassel, Germany.
RP Wambsganss, T (corresponding author), Univ St Gallen, St Gallen, Switzerland.
EM thiemo.wambsganss@unisg.ch; rainer.winkler@unisg.ch;
   soellner@uni-kassel.de; janmarco.leimeister@unisg.ch
CR [Anonymous], TECHNICAL REPORT
   Bird Steven, 2009, NATURAL LANGUAGE PRO, V43, DOI [10.1097/00004770-200204000-00018, DOI 10.1097/00004770-200204000-00018]
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Erikson M, 2016, REFLECT PRACT, V17, P663, DOI 10.1080/14623943.2016.1206877
   Fink Julia, 2012, Social Robotics. 4th International Conference (ICSR 2012). Proceedings, P199, DOI 10.1007/978-3-642-34103-8_20
   Flesch R, 1943, TEACHERS COLL CONTRI, V897
   Gnewuch Ulrich, 2018, 26 EUR C INF SYST EC
   Heerwegh D, 2008, PUBLIC OPIN QUART, V72, P836, DOI 10.1093/poq/nfn045
   Hobert Sebastian, 2019, SAY HELLO YOUR NEW A
   Joshi A, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P36
   Kerly A, 2007, KNOWL-BASED SYST, V20, P177, DOI 10.1016/j.knosys.2006.11.014
   Khawaja MA, 2010, IUI 2010, P333
   Kim S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300316
   Kowatsch T, 2017, EMB AG BEH CHANG PEA, P1
   Krassmann A. L., 2018, CREAT ED, V9, P1726, DOI DOI 10.4236/CE.2018.911126
   Laumer Sven, 2019, 27 EUR C INF SYST EC
   Moon Y, 2000, J CONSUM RES, V26, P323, DOI 10.1086/209566
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72
   Rubin VL, 2010, LIBR HI TECH, V28, P496, DOI 10.1108/07378831011096196
   Schuetzler Ryan M., 2014, 35 INT C INF SYST BU
   Shawar B.A., 2005, INT J CORPUS LINGUIS, V10, P489
   Song D, 2017, C HUM SYST INTERACT, P78, DOI 10.1109/HSI.2017.8005002
   Steyn C, 2019, ASSESS EVAL HIGH EDU, V44, P11, DOI 10.1080/02602938.2018.1466266
   Tucker B, 2008, HIGH EDUC RES DEV, V27, P281, DOI 10.1080/07294360802259067
   Tung FW, 2006, INTERACT LEARN ENVIR, V14, P251, DOI 10.1080/10494820600924750
   Walther JB, 2007, COMPUT HUM BEHAV, V23, P2538, DOI 10.1016/j.chb.2006.05.002
   Wambsganss T, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P1184
   Wambsganss Thiemo, 2020, 15 INT C WIRTSCH POT
   Winkler R., 2018, AC MAN M ANN CHIC AO
   Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496
NR 31
TC 0
Z9 0
U1 2
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6819-3
PY 2020
AR LBW349
DI 10.1145/3334480.3382805
PG 9
WC Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ9OG
UT WOS:000626317801072
OA Green Accepted, Green Published
DA 2022-08-02
ER

PT C
AU Bapat, R
   Kucherbaev, P
   Bozzon, A
AF Bapat, Rucha
   Kucherbaev, Pavel
   Bozzon, Alessandro
BE Mikkonen, T
   Klamma, R
   Hernandez, J
TI Effective Crowdsourced Generation of Training Data for Chatbots Natural
   Language Understanding
SO WEB ENGINEERING, ICWE 2018
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 18th International Conference on Web Engineering (ICWE)
CY JUN 05-08, 2018
CL Caceres, SPAIN
SP Int Soc Web Engn e V, Soc Ingn Software & Tecnologias Desarrollo Software, GNOSS, Univ Extremadura, Software Engn Grp, Diputac Caceres, Univ Extremadura
DE Conversational agents; Natural Language Understanding; Crowdsourcing
AB Chatbots are text-based conversational agents. Natural Language Understanding (NLU) models are used to extract meaning and intention from user messages sent to chatbots. The user experience of chatbots largely depends on the performance of the NLU model, which itself largely depends on the initial dataset the model is trained with. The training data should cover the diversity of real user requests the chatbot will receive. Obtaining such data is a challenging task even for big corporations. We introduce a generic approach to generate training data with the help of crowd workers, we discuss the approach workflow and the design of crowdsourcing tasks assuring high quality. We evaluate the approach by running an experiment collecting data for 9 different intents. We use the collected training data to train a natural language understanding model. We analyse the performance of the model under different training set sizes for each intent. We provide recommendations on selecting an optimal confidence threshold for predicting intents, based on the cost model of incorrect and unknown predictions.
C1 [Bapat, Rucha; Kucherbaev, Pavel; Bozzon, Alessandro] Delft Univ Technol, Van Mourik Broekmanweg 6, NL-2628 CD Delft, Netherlands.
RP Kucherbaev, P (corresponding author), Delft Univ Technol, Van Mourik Broekmanweg 6, NL-2628 CD Delft, Netherlands.
EM pavel@kucherbaev.com
OI Bozzon, Alessandro/0000-0002-3300-2913
FU Amsterdam Institute for Advanced Metropolitan Solutions; AMS Social Bot
   grant; SURF Cooperative [e-infra170237]; Dutch national e-infrastructure
FX This research has been supported in part by the Amsterdam Institute for
   Advanced Metropolitan Solutions with the AMS Social Bot grant, and by
   the Dutch national e-infrastructure with the support of SURF Cooperative
   (grant e-infra170237)
CR Agichtein, 2016, 4 AAAI C HUM COMP CR
   [Anonymous], 2010, P 23ND ANN ACM S USE, DOI [DOI 10.1145/1866029.1866078, 10.1145/1866029.1866078]
   [Anonymous], 2015, BUSINESS INSIDER
   Bigham J, 2015, P AAAI C HUM COMP CR
   Bigham J.P, 2016, P AAAI C HUM COMP CR
   Bigham J.P, 2017, COLLECTIVE INGELLIGE
   Bozzon Alessandro, 2013, Web Engineering. 13th International Conference, ICWE 2013. Proceedings: LNCS 7977, P514, DOI 10.1007/978-3-642-39200-9_48
   Bozzon A, 2014, LECT NOTES COMPUT SC, V8541, P218, DOI 10.1007/978-3-319-08245-5_13
   Callison-Burch C., 2009, P 2009 C EMP METH NA, V1, P286, DOI DOI 10.3115/1699510.1699548
   Cranshaw J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2382, DOI 10.1145/3025453.3025780
   Dias J., 2013, 1 AAAI C HUM COMP CR, P30
   Huang T.H.K., 2016, P 2016 CHI C EXT ABS, DOI [10.1145/2851581.2892502, DOI 10.1145/2851581.2892502]
   JIANG Y, 2017, UNDERSTANDING TASK D
   Lane I., 2010, P NAACL HLT 2010 WOR, P184
   Lasecki W., 2013, P HUM COMP WORKSH SC
   Lasecki W. S., 2015, P 12 WEB ALL C, P4
   Lasecki W.S., 2013, P 26 ANN ACM S US IN, P151
   McKeown, 2010, P NAACL HLT 2010 WOR, P13
   McTear M., 2016, CONVERSATIONAL INTER, DOI [10.1007/978-3-319-32967-3, DOI 10.1007/978-3-319-32967-3]
   Negri M, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2659
   Negri Matteo, 2011, P C EMP METH NAT LAN, P670
   ROTHWELL S, 2015, INTERSPEECH 2015, P2789
   Snow R, 2008, P 2008 C 383 EMP MET, P254, DOI DOI 10.3115/1613715.1613751
   Tagliasacchi M., 2012, P 1 INT WORKSH CROWD, P42
   Tur G, 2010, Proceedings 2010 IEEE Spoken Language Technology Workshop (SLT 2010), P19, DOI 10.1109/SLT.2010.5700816
   von Ahn L, 2004, P SIGCHI C HUM FACT, DOI DOI 10.1145/985692.985733
   Vtyurina A., 2017, P CHI C HUM FACT COM, P2187, DOI 10.1145/ 3027063
   Wang WY, 2012, IEEE W SP LANG TECH, P73, DOI 10.1109/SLT.2012.6424200
NR 28
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-319-91662-0; 978-3-319-91661-3
J9 LECT NOTES COMPUT SC
PY 2018
VL 10845
BP 114
EP 128
DI 10.1007/978-3-319-91662-0_8
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Software Engineering; Computer Science,
   Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS5EX
UT WOS:000728577100008
OA Green Submitted
DA 2022-08-02
ER

PT C
AU Shuster, K
   Ju, D
   Roller, S
   Dinan, E
   Boureau, YL
   Weston, J
AF Shuster, Kurt
   Ju, Da
   Roller, Stephen
   Dinan, Emily
   Boureau, Y-Lan
   Weston, Jason
GP Assoc Computat Linguist
TI The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded
   Conversational Agents
SO 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
   (ACL 2020)
LA English
DT Proceedings Paper
CT 58th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 05-10, 2020
CL ELECTR NETWORK
SP Assoc Computat Linguist
AB We introduce dodecaDialogue: a set of 12 tasks that measures if a conversational agent can communicate engagingly with personality and empathy, ask questions, answer questions by utilizing knowledge resources, discuss topics and situations, and perceive and converse about images. By multi-tasking on such a broad large-scale set of data, we hope to both move towards and measure progress in producing a single unified agent that can perceive, reason and converse with humans in an open-domain setting. We show that such multi-tasking improves over a BERT pretrained baseline, largely due to multi-tasking with very large dialogue datasets in a similar domain, and that the multi-tasking in general provides gains to both text and image-based tasks using several metrics in both the finetune and task transfer settings. We obtain state-of-the-art results on many of the tasks, providing a strong baseline for this challenge.
C1 [Shuster, Kurt; Ju, Da; Roller, Stephen; Dinan, Emily; Boureau, Y-Lan; Weston, Jason] Facebook AI Res, Menlo Pk, CA 08837 USA.
RP Shuster, K (corresponding author), Facebook AI Res, Menlo Pk, CA 08837 USA.
EM kshuster@fb.com; daju@fb.com; roller@fb.com; edinan@fb.com; ylan@fb.com;
   jase@fb.com
CR [Anonymous], 2015, PROC C N AM CHAPTER, DOI 10.3115/v1/ n15-1092
   [Anonymous], 2018, ARXIV180608730
   Bakhtin Anton, 2019, arXiv preprint arXiv:1906.03351
   Bordes, 2018, ARXIV180901984
   Choi E., 2018, P 2018 C EMP METH NA, P2174, DOI 10.18653/v1/D18-1241
   Danescu-Niculescu-Mizil C., 2011, P 2 WORKSH COGN MOD
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   Delangue, 2019, ARXIV190108149
   Devlin J., 2018, ARXIV
   Dinan E, 2020, SPRING SER CHALLENGE, P187, DOI 10.1007/978-3-030-29135-8_7
   Dinan Emily, 2019, P INT C LEARN REPR
   Fan A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3558
   Gopalakrishnan K., 2019, INTERSPEECH, P1891, DOI 10.21437/Interspeech.2019-3079
   He Tianxing, 2019, ARXIV191007117
   Holtzman Ari, 2019, ARXIV190409751
   Humeau, 2019, ARXIV190501969
   Joulin A., 2017, P 15 C EUR CHAPT ASS, P427, DOI DOI 10.18653/V1/E17-2068
   Keskar N. S., 2019, CTRL CONDITIONAL TRA
   Lewis M., 2019, ARXIV191013461
   Li L. Harold, 2019, ARXIV190803557
   Li Margaret, 2019, P NEURIPS WORKSH CON
   Li Y, 2017, P 8 INT JOINT C NAT, P986
   Lowe R, 2015, P 16 ANN M SPEC INT, P285, DOI DOI 10.18653/V1/W15-4640
   Lu J., 2019, ARXIV190802265
   Luan Yi, 2016, ARXIV160309457
   Mahajan D, 2018, LECT NOTES COMPUT SC, V11206, P185, DOI 10.1007/978-3-030-01216-8_12
   Moghe N., 2018, P 2018 C EMP METH NA, P2322
   Moon Seungwhan, 2019, P 2019 C EMP METH NA, P145
   Mostafazadeh N., 2017, ARXIV170108251
   Paulus R., 2018, P INT C LEARN REPR
   Qin LH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5427
   Raffel C., 2019, ARXIV191010683
   Rajpurkar P., 2016, P 2016 C EMP METH NA, P2383, DOI DOI 10.18653/V1/D16-1264
   Rashkin H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5370
   See A, 2019, P 2019 C N AM CHAPT, V1, P1702, DOI DOI 10.18653/V1/N19-1170.HTTPS://WWW.ACLWEB.0RG/ANTH0L0GY/N19-1170
   Shuster Kurt, 2018, ARXIV181100945
   Sordoni A., 2015, P 2015 C N AM CHAPT, P196, DOI DOI 10.3115/V1/N15-1020
   Sutskever I., 2018, IMPROVING LANGUAGE U
   Talmor A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4911
   Tan H., 2019, P 2019 C EMP METH NA, DOI DOI 10.18653/V1/D19-1514
   Urbanek J., 2019, P 2019 C EMP METH NA, P673
   Vaswani A., 2017, P 2017 ADV NEURAL IN, P5998
   Weston J., 2017, ARXIV170506476
   Wolf T, 2019, HUGGINGFACES TRANSFO HUGGINGFACES TRANSFO
   Wu J., 2019, OPENAI BLOG TECH REP, V1, P1
   Xie S, 2017, COMPUTER VISION PATT
   Yang YF, 2018, REPRESENTATION LEARNING FOR NLP, P164
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
NR 48
TC 5
Z9 5
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-952148-25-5
PY 2020
BP 2453
EP 2470
PG 18
WC Computer Science, Artificial Intelligence; Linguistics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Linguistics
GA BP9YK
UT WOS:000570978202066
DA 2022-08-02
ER

PT C
AU Restrepo, EGY
   Baldassarre, M
   Boticario, JG
AF Gutierrez y Restrepo, Emmanuelle
   Baldassarre, Martin
   Boticario, Jesus G.
BE Chova, LG
   Martinez, AL
   Torres, IC
TI ACCESSIBILITY, BIASES AND ETHICS IN CHATBOTS AND INTELLIGENT AGENTS FOR
   EDUCATION
SO EDULEARN19: 11TH INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING
   TECHNOLOGIES
SE EDULEARN Proceedings
LA English
DT Proceedings Paper
CT 11th International Conference on Education and New Learning Technologies
   (EDULEARN)
CY JUL 01-03, 2019
CL Palma, SPAIN
DE Conversational agents; Chatbot; accessibility; biases; ethics; empathy;
   artificial intelligence
AB The use of chatbots is increasingly common in universities around the world to support both educational and administrative tasks. There is also a growing awareness of the importance of inclusive education and, as a consequence, the need to comply with accessibility requirements regarding web contents and web interface (WCAG). These requirements are also supported by specific laws in most countries. But such awareness does not yet reach the interfaces of conversational agents or chatbots that are being developed.
   Within the framework of the European project ACACIA, co-funded by the Erasmus+ program of the European Union, Artemisa, a chatbot has been created dedicated to fight against sexual harassment and search for volunteers to promote the acceptance of diversity and tolerance, has been created using a platform that facilitates the generation and management of this type of artificial intelligences.
   But to what extent Artemisa is an accessible chatbot or not? Is it ethically acceptable to make use of a tool that is intended to support inclusiveness but presents accessibility barriers to some users? What is the current state in terms of accessibility compliance of chatbots that work on social networks?
   This article seeks to answer this and other questions related to accessibility in Chatbots, conversational agents and virtual assistant's. Based on the answer to these questions it follows that there is a need for training in interculturalism and web accessibility to combat the biases that present such entities, which are endowed with artificial intelligence and, unfortunately, in some cases causing serious damage to some people.
C1 [Gutierrez y Restrepo, Emmanuelle; Boticario, Jesus G.] UNED, Comp Sci Sch, Artificial Intelligence Dept, aDeNu Res Grp, Madrid, Spain.
   [Gutierrez y Restrepo, Emmanuelle; Baldassarre, Martin] Fdn Sidar Acceso Univ, Barcelona, Spain.
RP Restrepo, EGY (corresponding author), UNED, Comp Sci Sch, Artificial Intelligence Dept, aDeNu Res Grp, Madrid, Spain.; Restrepo, EGY (corresponding author), Fdn Sidar Acceso Univ, Barcelona, Spain.
RI Gutiérrez y Restrepo, Emmanuelle/I-2651-2015
OI Gutiérrez y Restrepo, Emmanuelle/0000-0001-9140-9319
FU European Commission; ERASMUS+: Higher Education -International Capacity
   Building - ACACIA -Project [561754-EPP-1-2015-1-CO-EPKA2-CBHE-JP]
FX The authors acknowledge the European Commission for its support and
   partial funding and the partners of the research project from ERASMUS+:
   Higher Education -International Capacity Building - ACACIA -Project
   reference number - 561754-EPP-1-2015-1-CO-EPKA2-CBHE-JP,
   (http://acacia.digital).
CR Andrade A. Molina, 2018, GUIAS TOLERANCIA ACE
   [Anonymous], 2019, ETHYKA ETICA INTELIG
   [Anonymous], 2016, 561754EPP120151COEPK
   [Anonymous], 2018, WEB CONTENT ACCESSIB
   Bollweg L., 2018, EDMEDIA INNOV LEARN, V2018, P1455
   Boshoff A., 2018, ACCESSIBILITY CHATBO
   Boudreau D., 2017, TOUT MONDE UX
   Calado C., 2017, WE NEED TALK ACCESSI
   Cardona J. A. Ayala, 2018, GUIAS TOLERANCIA ACE
   Colloquis, 2001, CHATB SMART C VIRT A
   du Boulay B, 2016, IEEE INTELL SYST, V31, P76, DOI 10.1109/MIS.2016.93
   Echenique E. Gallardo, 2018, GUIAS TOLERANCIA ACE
   European Commission, REQ TRUSTW AI FUTURI
   Fundacion Sidar, 1997, SIDAR ACC AD RED PRI
   Garay I. M. Torres, 2018, GUIAS TOLERANCIA ACE
   Garner Robby, CHATBOT ALBERT ONE R
   Guajardo A., 2018, GUIAS TOLERANCIA ACE
   Gutierrez E., 2018, ARTEMISA
   Gutierrez E., 2018, GUIAS TOLERANCIA ACE
   Heidari A., 2019, P 2019 ACM SIGMOD C
   Heller B., 2007, EDMEDIA, V2007, P945
   Heller Bob Mike, 2005, EDMEDIA INNOVATE LEA, P3913
   Holmes W., 2018, 19 INT C ART INT ED
   IBM, 2018, AI FAIRN 360
   Liu Yuxi, 2017, ACCOUNTABILITY AI CA
   Microsoft, 2018, DES CONTR CONV FLOW
   Molano G., 2018, GUIAS TOLERANCIA ACE
   Mullen R., 2018, ACCESSIBLE CHATBOTS
   Mullen R., ACCESSIBLE CHATBOTS
   Neyra L., 2018, GUIAS TOLERANCIA ACE
   Novoa G. Alfonso, 2018, GUIAS TOLERANCIA ACE
   Rekatsinas T, 2017, PROC VLDB ENDOW, V10, P1190
   Restrepo E. Gutierrez, 2017, 23 ICE IEEE INT TECH
   Selbst AD, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P59, DOI 10.1145/3287560.3287598
   Torres C, 2019, ADV INTELL SYST, V794, P623, DOI 10.1007/978-3-319-94947-5_63
   W3C-WAI, 2019, W3C WEBSITE
   Wallace Richard, CHATBOT ALICE ALICE
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
   Worswick S, MITSUKU
   Zhou L., 2018, DESIGN IMPLEMENTATIO
NR 40
TC 0
Z9 0
U1 2
U2 6
PU IATED-INT ASSOC TECHNOLOGY EDUCATION & DEVELOPMENT
PI VALENICA
PA LAURI VOLPI 6, VALENICA, BURJASSOT 46100, SPAIN
SN 2340-1117
BN 978-84-09-12031-4
J9 EDULEARN PROC
PY 2019
BP 8824
EP 8833
PG 10
WC Education & Educational Research
WE Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Education & Educational Research
GA BP4NG
UT WOS:000553304903063
DA 2022-08-02
ER

PT C
AU Huff, EW
   Stigall, B
   Brinkley, J
   Pak, R
   Caine, K
AF Huff, Earl W., Jr.
   Stigall, Brodrick
   Brinkley, Julian
   Pak, Richard
   Caine, Kelly
GP Assoc Comp Machinery
TI Can Computer-Generated Speech Have an Age?
SO CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS
   IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT ACM CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 25-30, 2020
CL Honolulu, HI
SP ACM SIGCHI, Assoc Comp Machinery
DE computer-generated speech; voice user interfaces; conversational agents
AB The present study examines whether computer-generated speech is perceived to have an age, and if so, whether we can manipulate the perceived age of the voice. We conducted an experimental study with 51 participants where each computer-generated voice had different age-related characteristics such as the speed rate of the voice and frequency of the pitch. Participants listened to vehicle reviews presented by computer-generated voices with age-related characteristics we manipulated and then evaluated the age of the voice. Results show that we can change the perceived age of a computer-generated voice by manipulating the age-related characteristics of the voice. This work contributes to communities of HCI researchers interested in voice user interfaces (VUIs), conversational agents, and age stereotypes.
C1 [Huff, Earl W., Jr.; Stigall, Brodrick; Brinkley, Julian; Pak, Richard; Caine, Kelly] Clemson Univ, Clemson, SC 29630 USA.
RP Huff, EW (corresponding author), Clemson Univ, Clemson, SC 29630 USA.
EM earlh@clemson.edu.edu; bstigal@clemson.edu; jbrinkl@clemson.edu;
   richpak@clemson.edu; caine@clemson.edu
CR [Anonymous], 2017, CAR BRAND STER INF W
   [Anonymous], 2016, MILLENNIAL CAR BUYER
   ENDRES W, 1971, J ACOUST SOC AM, V49, P1842, DOI 10.1121/1.1912589
   Huff Earl W.  Jr., 2019, Learning and Collaboration Technologies. Ubiquitous and Virtual Environments for Learning and Collaboration. 6th International Conference, LCT 2019 Held as Part of the 21st HCI International Conference, HCII 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11591), P80, DOI 10.1007/978-3-030-21817-1_7
   Morishima Y, 2002, UNPUB
   Nass C, 1997, J APPL SOC PSYCHOL, V27, P864, DOI 10.1111/j.1559-1816.1997.tb00275.x
   Nass Clifford, 2000, P SIGCHI C HUM FACT, DOI [10.1145/332040.332452, DOI 10.1145/332040.332452]
   Nass Clifford, 2005, WIRED SPEECH VOICE A
   Neto AT, 2008, SIGDOC'08: PROCEEDINGS OF THE 26TH ACM INTERNATIONAL CONFERENCE ON DESIGN OF COMMUNICATION, P277
   Oviatt Sharon, 2002, MULTIMODAL INTERFACE, P286
   Parker Joe, 2018, BUCKING BUICK STEREO
   Pearl C., 2016, DESIGNING VOICE USER
   Peer E, 2014, BEHAV RES METHODS, V46, P1023, DOI 10.3758/s13428-013-0434-y
   PTACEK PH, 1966, J SPEECH HEAR RES, V9, P273, DOI 10.1044/jshr.0902.273
   Reubold U, 2010, SPEECH COMMUN, V52, P638, DOI 10.1016/j.specom.2010.02.012
   Stathopoulos ET, 2011, J SPEECH LANG HEAR R, V54, P1011, DOI 10.1044/1092-4388(2010/10-0036)
   Tatarevic Bozi, 2016, SALESPEOPLE STEREOTY
   Waller SS, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01814
   Winkler R, 2007, INTERSPEECH 2007: 8TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION, VOLS 1-4, P2097
   Yang Stephanie, 2017, 15 CARS COMMON STERE
NR 20
TC 0
Z9 0
U1 0
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6819-3
PY 2020
AR LBW275
DI 10.1145/3334480.3383082
PG 7
WC Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ9OG
UT WOS:000626317803111
DA 2022-08-02
ER

PT J
AU Roda, C
   Angehrn, A
   Nabeth, T
   Razmerita, L
AF Roda, C
   Angehrn, A
   Nabeth, T
   Razmerita, L
TI Using conversational agents to support the adoption of knowledge sharing
   practices
SO INTERACTING WITH COMPUTERS
LA English
DT Article
DE software agents; knowledge sharing; virtual communities; knowledge
   management; change management; user modelling
AB In this paper, we present an agent-based system designed to support the adoption of knowledge sharing practices within communities. The system is based on a conceptual framework that, by modelling the adoption of knowledge management practices as a change process, identifies the pedagogical strategies best suited to support users through the various stages of the adoption process. Learning knowledge management practices is seen as a continuous process, taking place at individual and social level that includes the acquisition of information, as well as the contextual use of the information acquired. The resulting community-based system provides each member of the community with an artificial personal change-management agent capable of guiding users in the acquisition and adoption of new knowledge sharing practices by activating personalised and contextualised intervention. (C) 2002 Elsevier Science B.V. All rights reserved.
C1 INSEAD, Ctr Adv Learning Technol, F-77300 Fontainebleau, France.
RP Nabeth, T (corresponding author), INSEAD, Ctr Adv Learning Technol, Bd Constance, F-77300 Fontainebleau, France.
EM claudia.roda@insead.edu; angehrn@insead.edu; thierry.nabeth@insead.edu;
   liana.razmerita@insead.edu
RI Nabeth, Thierry/B-1700-2008; Razmerita, Liana/AAG-6570-2021
OI Razmerita, Liana/0000-0003-3246-8364
CR ALAVI M, 1999, P 32 HAW INT C SYST, V15, P275
   ANGEHRN A, 2001, P E2001 EBUS EWORK V
   ANGEHRN A, 1999, P ECIS COP
   ANGEHRN AA, 1997, EUROPEAN MANAGEMENT, V15, P275, DOI DOI 10.1016/S0263-2373(97)00007-8
   BEER N, 2000, HARVARD BUSINESS MAY
   BOY GA, 1997, SOFTWARE AGENTS COOP
   Bruner J. S., 1996, THEORY INSTRUCTION
   BRUSH B, 2001, MSRTR200187 MICR RES
   BRUSILOVSKY P, 1998, 4 INT C INT TUT SYST
   CAPUANO N, 2000, P INT WORKSH AD INT
   CAROTENUTO L, 1999, P CHANG PLAC WORKSH
   CHEIKES BA, 1995, P CIKM 95 WORKSH INT
   Chen W., 1999, P AIED 99 WORKSH ONT
   COHEN M, 2001, J STRATEGIC CHANGE, V10, P139
   COHEN PR, 1990, SYS DEV FDN, P221
   CONTE R, 2001, JASSS-J ARTIF SOC S, V4, P1
   Conte R., 1995, COGNITIVE SOCIAL ACT
   Davenport Thomas, 1998, WORKING KNOWLEDGE OR
   DAVIS JR, 1995, P COMP SUPP COLL LEA
   Deroian F, 2002, RES POLICY, V31, P835, DOI 10.1016/S0048-7333(01)00147-0
   DESANCTIS G, 2001, BUILDING GLOBAL LEAR
   DIVITNI M, 1993, P 1993 C ORG COMP SY, P178
   Dore L., 2001, WINNING KNOWLEDGE SU
   Dyer JH, 2000, STRATEGIC MANAGE J, V21, P345, DOI 10.1002/(SICI)1097-0266(200003)21:3<345::AID-SMJ96>3.0.CO;2-N
   FENSEL D, 2001, IEEE INTELLIGENT MAR
   GLANCE N, 2001, P GROUP 2001 BOULD C
   GONGLA P, 2001, IBM SYST J, V40, P4
   Grant RM, 1996, ORGAN SCI, V7, P375, DOI 10.1287/orsc.7.4.375
   Huberman B. A., 1996, BEEHIVE SYSTEM COOPE
   JAFARI A, 2001, P INT C INT AG LAS V
   Janssen MA, 2001, J ECON PSYCHOL, V22, P745, DOI 10.1016/S0167-4870(01)00063-0
   Jennings N., 1992, P 10 EUR C ART INT V, P224
   KAMIYA K, 1996, P 6 WWW C PAR FRANC
   KARAGIANNIDIS C, 2001, ED SOC TECHNOLOGY J, V4
   KOULOPOULOS TM, 1997, CORPORATE INSTINCT B
   Lave J., 1991, SITUATED LEARNING CO
   Leonard-Barton D., 1995, WELLSPRINGS KNOWLEDG
   Lesser E., 2001, IBM SYST J, V40, P4
   Lester J. C., 1997, P ACM SIGCHI C HUM F, P359, DOI DOI 10.1145/258549.258797
   LINTON F, 2000, ED TECHNOLOGY SOC, V3, P62
   Malhotra Y., 2000, EXECUTIVES J, V16, P5, DOI DOI 10.1080/07438613.2000.10744620
   MALTZ D, 1995, P CHI 95
   MAMDANI EH, 1999, NEW GENERATION COMPU, V17
   Manzoni J.-F., 1997, Journal of Management Information Systems, V14, P109
   NEAR J, 1993, MANAGING CHANGE CASE, P241
   Nonaka I., 1995, KNOWLEDGE CREATING C
   OGATA H, 1999, P ED MEDIA 99 AACE P, P119
   OREILLY CA, 1997, USING CUTLURE STRATE
   PAIVA A, 1996, P UM 96 WORKSH STAND
   PLOTKIN H, 1994, DARWING MACHINES NAT
   POLLACK ME, 1990, SYS DEV FDN, P77
   Rich E., 1979, COGNITIVE SCI, V3, P329, DOI [10.1207/s15516709cog0304_3, DOI 10.1207/S15516709COG0304_3]
   Rich E., 1989, USER MODELS DIALOG S, P35
   Roda C, 2001, P 7 INT NETT C FRIB, P931
   RODA C, 1994, THESIS U LONDON LOND
   Rogers C., 1969, FREEDOM LEARN
   Rogers E., 1995, DIFFUSION INNOVATION
   ROSCHEISEN M, 1995, D LIB J          AUG
   ROSCHEISEN M, 1995, P 3 INT WORLD WID WE
   Shute V. J., 1994, HDB RES ED COMMUNICA
   STUART A, 1996, CIO MAGAZINE    0601
   SUMNER T, 1999, P KAW 99 12 WORKSH K
   Teece DJ, 1997, STRATEGIC MANAGE J, V18, P509, DOI 10.1002/(SICI)1097-0266(199708)18:7<509::AID-SMJ882>3.0.CO;2-Z
   Vandenbosch B., 1996, Journal of Management Information Systems, V13, P65
   VANDURA A, 1971, SOCIAL LEARNING THEO
   WANT J, 1995, MANAGING RADICAL CHA
   Wenger E., 1990, SITUATED LEARNING LE
   Wenger E.C., 1998, COMMUNITIES PRACTICE
NR 68
TC 48
Z9 49
U1 0
U2 7
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 0953-5438
EI 1873-7951
J9 INTERACT COMPUT
JI Interact. Comput.
PD JAN
PY 2003
VL 15
IS 1
BP 57
EP 89
AR PII S0953-5438(02)00029-2
DI 10.1016/S0953-5438(02)00029-2
PG 33
WC Computer Science, Cybernetics; Ergonomics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 637CD
UT WOS:000180493300004
DA 2022-08-02
ER

PT S
AU Cowell, AJ
   Stanney, KM
AF Cowell, AJ
   Stanney, KM
BE Rist, T
   Aylett, R
   Ballin, D
   Rickel, J
TI Embodiment and interaction guidelines for designing credible,
   trustworthy embodied conversational agents
SO INTELLIGENT VIRTUAL AGENTS
SE LECTURE NOTES IN ARTIFICIAL INTELLIGENCE
LA English
DT Article; Proceedings Paper
CT 4th International Workshop on Intelligent Virtual Agents
CY SEP 15-17, 2003
CL KLOSTER IRSEE, GERMANY
SP EU 5th Framework VICTEC Project, SIGMEDIA, DFKI, BTexact Technologies, Univ Augsburg, Dept Multimedia Concepts & Applicat
ID SEX-ROLE STEREOTYPES; PERFORMANCE-APPRAISAL; BEHAVIOR; SELF;
   ATTRACTIVENESS; MODEL
AB This paper discusses our recent studies on Embodied Conversational Agent (ECA) design strategies to encourage credible and trustworthy dialogue. We approach the problem from two specific directions: the embodiment that the character 'wears' during its interchange with the user, and the method of interaction used by the ECA to engage the user. Our results indicate that while users generally prefer to interact with a youthful character matching their ethnicity, no significant preferences were indicated for character gender. For interaction, our results indicated that a character that portrayed trusting nonverbal behaviors was rated as being significantly more credible than a character portraying no nonverbal behavior, or one that portrayed non-trusting behaviors. Other interesting results from this work are also discussed.
C1 Pacific NW Natl Lab, Richland, WA 99352 USA.
   Univ Cent Florida, Dept Ind Engn & Management Syst, Orlando, FL 32816 USA.
RP Cowell, AJ (corresponding author), Pacific NW Natl Lab, Richland, WA 99352 USA.
CR ADDINGTON DW, 1963, THESIS U IOWA
   AMBADY N, 1993, J PERS SOC PSYCHOL, V64, P431, DOI 10.1037/0022-3514.64.3.431
   ARGYLE A, 1969, SOCIAL INTERACTI
   ARGYLE M, 1968, HUM RELAT, V21, P3, DOI 10.1177/001872676802100101
   BENFORD RD, 1998, SOC ISSUES
   BUGENTAL DB, 1986, PERS SOC PSYCHOL B, V12, P7, DOI 10.1177/0146167286121001
   CAPPELLA JN, 1985, HDB INTERPERSONAL CO, P393
   CARDNER RC, 1995, CANADIAN J BEHAV SCI, V27
   CAUTHEN NR, 1971, J APPL PSYCHOL, V68, P609
   Clayman SE, 2001, LANG SOC, V30, P403, DOI 10.1017/S0047404501003037
   CLEVELAND JN, 1981, PERS PSYCHOL, V34, P19, DOI 10.1111/j.1744-6570.1981.tb02173.x
   COSTRICH N, 1975, J EXP SOC PSYCHOL, V11, P520, DOI 10.1016/0022-1031(75)90003-7
   DEAUX K, 1974, J PERS SOC PSYCHOL, V29, P80, DOI 10.1037/h0035733
   DELENER N, 1990, J ADVERTISING RES, V30, P45
   DEMEUSE KP, 1987, J OCCUP PSYCHOL, V60, P207
   DEUTSCH CJ, 1976, J COUNS PSYCHOL, V23, P373, DOI 10.1037/0022-0167.23.4.373
   Ekman, 1971, SEMIOTICA, V3, P37, DOI [DOI 10.1515/SEMI.1971.3.1.37, 10.1515/semi.1971.3.1.37]
   EKMAN P, 1967, S C377 THEOR LING MO
   Ekman P., 1973, DARWIN FACIAL EXPRES
   Fairbanks G, 1939, SPEECH MONOGR, V6, P87, DOI 10.1080/03637753909374863
   FAIRCHILD HH, 1981, HISPANIC J BEHAVIORA, V3, P191
   FELDMANS.S, 1974, J PERS SOC PSYCHOL, V30, P846, DOI 10.1037/h0037604
   FISH S, 1993, REVERSE RACISM HOW P
   FISKE ST, 1990, ADV EXP SOC PSYCHOL, V23, P1, DOI 10.1016/S0065-2601(08)60317-2
   Frois-Wittmann J, 1930, J EXP PSYCHOL, V13, P113, DOI 10.1037/h0070158
   GERBNER G, 1986, 14 U PENNS ANN SCH C
   GROSS BR, 1977, REVERSE DISCRIMINATI
   HEILMAN ME, 1979, J APPL PSYCHOL, V64, P915
   Henley Nancy M, 1977, POWER DOMINANCE NONV, P151
   HOROWITZ D, 1999, HATING WHITEY OTHER
   HOSMAN LA, 1989, HUM COMMUN RES, V15, P383, DOI 10.1111/j.1468-2958.1989.tb00190.x
   Jackson L., 1995, STEREOTYPES EMOTIONS
   JANIK SW, 1978, PERCEPT MOTOR SKILL, V26, P34
   JAROFF L, 1994, TIME, P74
   JOHNSON AG, 1995, BLACKWELL DICT SOC
   KENDON A, 1968, SOME FUNCTIONS GAZE, V26, P1
   KLEINKE CL, 1980, J NONVERBAL BEHAV, V5, P3, DOI 10.1007/BF00987050
   Knapp M.L., 1978, NONVERBAL COMMUNICAT, V2nd ed.
   LEATHERS DG, 1997, SUCCESSFUL NONVERBAL
   Lynch FR, 1989, INVISIBLE VICTIMS WH
   MACK D, 1979, PSYCHOL REC, V29, P43, DOI 10.1007/BF03394587
   MARIN G, 1984, INT J INTERCULT REL, V8, P17, DOI 10.1016/0147-1767(84)90005-1
   Massaro DW, 2000, EMBODIED CONVERSATIONAL AGENTS, P287
   MEHRABIAN A, 1967, J COMMUN, V16, P324
   Mehrabian A, 1981, SILENT MESSAGES, V2nd ed.
   MONTENEGRO M, 1971, CHICANOS MEXICAN AM
   Nass C, 1997, J APPL SOC PSYCHOL, V27, P864, DOI 10.1111/j.1559-1816.1997.tb00275.x
   PETERSEN B, 1971, PSYCHOLOGY, V8, P22
   ROBINSON J, 1982, J PERS SOC PSYCHOL, V43, P236, DOI 10.1037/0022-3514.43.2.236
   Rodman R., 1999, COMPUTER SPEECH TECH
   ROMER N, 1980, SEX ROLES, V6, P246
   ROSEN B, 1976, J APPL PSYCHOL, V61, P428, DOI 10.1037/0021-9010.61.4.428
   ROSENKRANTZ P, 1968, J CONSULT CLIN PSYCH, V32, P287, DOI 10.1037/h0025909
   SCHERER KR, 1982, METHODS RES VOCAL CO
   SCHWAB DP, 1978, J APPL PSYCHOL, V63, P573, DOI 10.1037/0021-9010.63.5.573
   SMITH ER, 1992, PSYCHOL REV, V99, P3, DOI 10.1037/0033-295X.99.1.3
   Taylor CR, 1997, J ADVERTISING, V26, P47, DOI 10.1080/00913367.1997.10673522
   Webbink P., 1986, POWER EYES
   YIP A, 1997, ASIAN WEEK
   ZUCKERMAN M, 1990, J NONVERBAL BEHAV, V14, P97, DOI 10.1007/BF01670437
   1984, NEWSWEEK
NR 62
TC 18
Z9 18
U1 0
U2 8
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-20003-7
J9 LECT NOTES ARTIF INT
PY 2003
VL 2792
BP 301
EP 309
PG 9
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BX96B
UT WOS:000187008600050
DA 2022-08-02
ER

PT J
AU Liu, QT
   Huang, JX
   Wu, LJ
   Zhu, K
   Ba, S
AF Liu, Qingtang
   Huang, Jingxiu
   Wu, Linjing
   Zhu, Ke
   Ba, Shen
TI CBET: design and evaluation of a domain-specific chatbot for mobile
   learning
SO UNIVERSAL ACCESS IN THE INFORMATION SOCIETY
LA English
DT Article; Proceedings Paper
CT 7th International Conference on Software Development and Technologies
   for Enhancing Accessibility and Fiighting Info-Exclusion (DSAI)
CY 2016
CL Univ Tras os Montes Alto Douro, Vila Real, PORTUGAL
HO Univ Tras os Montes Alto Douro
DE Chatbots; Conversational agents; Mobile learning; Evaluation of
   educative chatbots; Usability evaluation
ID CONVERSATIONAL AGENT INTERVENTIONS; ACADEMICALLY PRODUCTIVE TALK;
   EMPIRICAL-EVALUATION; PERCEIVED USABILITY; NATURAL-LANGUAGE; SYSTEM;
   TRENDS; SATISFACTION
AB The popularity of mobile devices and conversational agents in recent years has seen wide use of chatbots in different educational scenarios. In relation to the advances in mobile devices and conversational agents, there are few research works concerning the design and evaluation of domain-specific chatbots to fulfill the demand of mobile learning. To address this issue, we propose an agent-based conceptual architecture to develop a domain-specific chatbot for mobile learning. We extend the open-domain DeepQA agent to make it sensitive to restricted domain questions by building a domain-specific gate, and employ WeChat as user interface. To evaluate our chatbot, subjective and objective criteria are employed to assess its effectiveness. Additionally, its usability evaluation proceeds with system usability scale questionnaire and net promoter score simultaneously. In total, 18 domain experts participated in the evaluation of effectiveness, and 52 participants were involved in the evaluation of usability. Based on the evaluation results, we conclude that our chatbot can serve as an effective information retrieval tool in a specific domain. The perceived usability of our chatbot tends to be moderate and marginal and has positively affected the promotion of our chatbot for mobile learning. This paper contributes to the educative application of chatbots in specific subject fields.
C1 [Liu, Qingtang; Huang, Jingxiu; Wu, Linjing; Ba, Shen] Cent China Normal Univ, Wuhan, Hubei, Peoples R China.
   [Zhu, Ke] Henan Normal Univ, Xinxiang, Henan, Peoples R China.
RP Huang, JX (corresponding author), Cent China Normal Univ, Wuhan, Hubei, Peoples R China.
EM jimsow@163.com
FU National Natural Science Foundation of China [61272205]; Technology
   Innovation Special Projects of Hubei Province [2017ACA105]; Nanyang
   Technological University
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 61272205 and the Technology Innovation Special
   Projects of Hubei Province under Grant No. 2017ACA105. We would like to
   express our sincere and heartfelt thanks to Prof. Wenli Chen from the
   Nanyang Technological University and to the editors and reviewers of
   this paper.
CR Adams Becker S., 2017, HORIZON REPORT 2017
   Apdplat, 2018, DEEP QA
   Ardito C., 2006, Universal Access in the Information Society, V4, P270, DOI 10.1007/s10209-005-0008-6
   Ayedoun E., 2016, J INF SYST ED, V15, P5, DOI [10.12937/ejsise.15.15, DOI 10.12937/EJSISE.15.15]
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Ben Abacha Asma, 2011, J Biomed Semantics, V2 Suppl 5, pS4, DOI 10.1186/2041-1480-2-S5-S4
   Benotti L., 2014, P 2014 C INN TECHN C, P63, DOI [10.1145/2591708.2591728, DOI 10.1145/2591708.2591728]
   Bringula RP, 2011, EDUC TECHNOL SOC, V14, P253
   Chakrabarti C, 2015, EXPERT SYST APPL, V42, P6878, DOI 10.1016/j.eswa.2015.04.067
   Coniam D, 2014, TEXT TALK, V34, P545, DOI 10.1515/text-2014-0018
   Crutzen R, 2011, J ADOLESCENT HEALTH, V48, P514, DOI 10.1016/j.jadohealth.2010.09.002
   Del Gaudio R, 2014, NAT LANG ENG, V20, P327, DOI 10.1017/S1351324912000381
   Desir C, 2013, PATTERN RECOGN, V46, P3490, DOI 10.1016/j.patcog.2013.05.022
   Dyke G, 2013, IEEE T LEARN TECHNOL, V6, P240, DOI 10.1109/TLT.2013.25
   Fadhil A., 2017, ADJ PUBL 25 C US MOD, P408, DOI [10.1145/3099023.3099112, DOI 10.1145/3099023.3099112]
   Ferrucci D, 2010, AI MAG, V31, P59, DOI 10.1609/aimag.v31i3.2303
   Flavian C, 2006, INFORM MANAGE-AMSTER, V43, P1, DOI 10.1016/j.im.2005.01.002
   GOH O, 2007, WORLD ACAD SCI ENG T, V3, P195
   Gould DJ, 2008, ANAT SCI EDUC, V1, P175, DOI 10.1002/ase.36
   Graesser AC, 2014, CURR DIR PSYCHOL SCI, V23, P374, DOI 10.1177/0963721414540680
   Griol D, 2016, COGN COMPUT, V8, P336, DOI 10.1007/s12559-015-9352-x
   Griol D, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/55791
   Harrati N, 2016, COMPUT HUM BEHAV, V61, P463, DOI 10.1016/j.chb.2016.03.051
   Hung JL, 2012, J COMPUT HIGH EDUC, V24, P1, DOI 10.1007/s12528-011-9044-9
   Hwang GJ, 2011, BRIT J EDUC TECHNOL, V42, pE65, DOI 10.1111/j.1467-8535.2011.01183.x
   Jia JY, 2009, KNOWL-BASED SYST, V22, P249, DOI 10.1016/j.knosys.2008.09.001
   Jin Y., 2013, P 2013 C EMP METH NA, P780
   Kerly A, 2008, APPLICATIONS AND INNOVATIONS IN INTELLIGENT SYSTEMS XV, P89, DOI 10.1007/978-1-84800-086-5_7
   Kerly A, 2007, KNOWL-BASED SYST, V20, P177, DOI 10.1016/j.knosys.2006.11.014
   Kumar R, 2011, IEEE T LEARN TECHNOL, V4, P21, DOI 10.1109/TLT.2010.41
   Liu C., 2016, ABS160308023 CORR
   Liu QT, 2011, KNOWL-BASED SYST, V24, P1254, DOI 10.1016/j.knosys.2011.06.001
   Lowe R, 2015, P 16 ANN M SPEC INT, P285, DOI DOI 10.18653/V1/W15-4640
   Michalco J, 2015, INT J HUM-COMPUT INT, V31, P603, DOI 10.1080/10447318.2015.1065696
   Moreno R, 2007, EDUC PSYCHOL REV, V19, P309, DOI 10.1007/s10648-007-9047-2
   Murdock JW, 2012, IBM J RES DEV, V56, DOI 10.1147/JRD.2012.2187249
   Na-Young Kim，, 2017, Studies in English Education, V22, P81, DOI 10.22275/SEE.22.3.04
   Orfanou K, 2015, INT REV RES OPEN DIS, V16, P227
   P Juszczak, 2006, THESIS
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Perez-Marin D, 2013, INT J INF COMMUN TEC, V9, P94, DOI 10.4018/ijicte.2013100107
   Preece A, 2017, IEEE T HUM-MACH SYST, V47, P1017, DOI 10.1109/THMS.2017.2700625
   Punuru J, 2012, J INTELL INF SYST, V38, P191, DOI 10.1007/s10844-011-0149-4
   Radziwill Nicole M., 2017, ABS170404579 CORR
   Reiplinger M., 2012, P ACL 2012 SPEC WORK, P55
   Revythi A., ABS170406127 CORR
   Sauro J, 2016, QUANTIFYING THE USER EXPERIENCE: PRACTICAL STATISTICS FOR USER RESEARCH, 2ND EDITION, P1
   Shawar B. A., 2007, P WORKSH BRIDG GAP A, P89, DOI [10.3115/1556328.1556341, DOI 10.3115/1556328.1556341]
   Shen MX, 2012, J INTELL INF SYST, V39, P749, DOI 10.1007/s10844-012-0210-y
   So S, 2016, INTERNET HIGH EDUC, V31, P32, DOI 10.1016/j.iheduc.2016.06.001
   Song D, 2017, C HUM SYST INTERACT, P78, DOI 10.1109/HSI.2017.8005002
   Su CH, 2015, J COMPUT ASSIST LEAR, V31, P268, DOI 10.1111/jcal.12088
   Sun Z, 2017, J COMPUT ASSIST LEAR, V33, P575, DOI 10.1111/jcal.12201
   Tegos S, 2016, LECT NOTES COMPUT SC, V9684, P260, DOI 10.1007/978-3-319-39583-8_27
   Tegos S, 2016, INT J COMP-SUPP COLL, V11, P417, DOI 10.1007/s11412-016-9246-2
   Tegos S, 2015, COMPUT EDUC, V87, P309, DOI 10.1016/j.compedu.2015.07.014
   Venkatesh A., 2018, ABS180103625 CORR
   Wu J, 2017, EURASIA J MATH SCI T, V13, P5847, DOI 10.12973/eurasia.2017.01034a
   Wu LJ, 2015, BRIT J EDUC TECHNOL, V46, P1118, DOI 10.1111/bjet.12298
   Wu WH, 2012, COMPUT EDUC, V59, P817, DOI 10.1016/j.compedu.2012.03.016
   Wu Y, 2018, NEUROCOMPUTING, V316, P251, DOI 10.1016/j.neucom.2018.07.073
   Xu JH, 2015, J ACAD LIBR, V41, P21, DOI 10.1016/j.acalib.2014.10.012
   Yasunami S, 2014, J INFORM SYSTEMS ED, V13, P1, DOI DOI 10.12937/EJSISE.13.1
   Yousafzai A, 2016, INT J INFORM MANAGE, V36, P784, DOI 10.1016/j.ijinfomgt.2016.05.010
   Yu Z, 2016, CHIN CONT DECIS CONF, P1025, DOI 10.1109/CCDC.2016.7531134
   Zhang C., 2008, J COMPUT INF SYST, V4, P1169
NR 66
TC 6
Z9 6
U1 6
U2 59
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1615-5289
EI 1615-5297
J9 UNIVERSAL ACCESS INF
JI Univers. Access Inf. Soc.
PD AUG
PY 2020
VL 19
IS 3
SI SI
BP 655
EP 673
DI 10.1007/s10209-019-00666-x
PG 19
WC Computer Science, Cybernetics; Ergonomics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA MO4SA
UT WOS:000551516700013
DA 2022-08-02
ER

PT C
AU Luerssen, M
   Lewis, T
   Powers, D
AF Luerssen, Martin
   Lewis, Trent
   Powers, David
BE Li, JY
TI Head X: Customizable Audiovisual Synthesis for a Multi-purpose Virtual
   Head
SO AI 2010: ADVANCES IN ARTIFICIAL INTELLIGENCE
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 23rd Australasian Joint Conference on Artificial Intelligence
CY DEC 07-10, 2010
CL Univ S Australia, Adelaide, AUSTRALIA
SP Univ S Australia
HO Univ S Australia
DE Embodied conversational agents; audiovisual speech synthesis; software
   library
ID AGENTS
AB The development of embodied conversational agents (ECAs) involves a wide range of cutting-edge technologies extending from multimodal perception to reasoning to synthesis. While each is important to a successful outcome, it is the synthesis that has the most immediate impact on the observer. The specific appearance and voice of an embodied conversational agent (ECA) can be decisive factors in meeting its social objectives. In light of this, we have developed an extensively customizable system for synthesizing a virtual talking 3D head. Rather than requiring explicit integration into a codebase, our software runs as a service that can be controlled by any external client, which substantially simplifies its deployment into new applications. We have explored the benefits of this approach across several internal research projects and student exercises as part of a university topic on ECAs.
C1 [Luerssen, Martin; Lewis, Trent; Powers, David] Flinders Univ S Australia, Artificial Intelligence Lab, Adelaide, SA 5001, Australia.
RP Luerssen, M (corresponding author), Flinders Univ S Australia, Artificial Intelligence Lab, Adelaide, SA 5001, Australia.
EM martin.luerssen@flinders.edu.au; trent.lewis@flinders.edu.au;
   david.powers@flinders.edu.au
RI Lewis, Trent/AAI-4260-2020; Powers, David MW/A-7698-2011
OI Powers, David MW/0000-0001-5998-2262
CR [Anonymous], FACEGEN SDK 3 6
   [Anonymous], MICR SPEECH API 5 3
   Bickmore T, 2005, TEXT SPEECH LANG TEC, V30, P23
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Cassell J, 2001, AI MAG, V22, P67
   Gulz A, 2006, INT J HUM-COMPUT ST, V64, P322, DOI 10.1016/j.ijhcs.2005.08.006
   Kopp S., 2004, Gesture-Based Communication in Human-Computer Interaction. 5th International Gesture Workshop, GW 2003. Selected Revised Papers (Lecture Notes in Comput. Sci. Vol.2915), P436
   Massaro D. W, 2004, HDB MULTISENSORY PRO, P153
   Milne M., 2010, 2010 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2010.5596584
   Moreno R, 2006, CONTEMP EDUC PSYCHOL, V31, P186, DOI 10.1016/j.cedpsych.2005.05.002
   Oh I, 2007, LECT NOTES COMPUT SC, V4561, P443, DOI 10.1007/978-3-540-73321-8_51
   Poggi I, 2005, TEXT SPEECH LANG TEC, V27, P3, DOI 10.1007/1-4020-3051-7_1
   Powers David M.W., 2010, P 2010 WORKSH COMP D, P7
   Schroder M., 2003, International Journal of Speech Technology, V6, P365, DOI 10.1023/A:1025708916924
   Wang A, 2007, SANDBOX SYMPOSIUM 2007: ACM SIGGRAPH VIDEO GAME SYMPOSIUM, PROCEEDINGS, P21
NR 15
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-17431-5
J9 LECT NOTES ARTIF INT
PY 2010
VL 6464
BP 486
EP 495
PG 10
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BSZ19
UT WOS:000286149100049
DA 2022-08-02
ER

PT C
AU Krenn, B
   Endrass, B
   Kistler, F
   Andre, E
AF Krenn, Brigitte
   Endrass, Birgit
   Kistler, Felix
   Andre, Elisabeth
BE Kurosu, M
TI Effects of Language Variety on Personality Perception in Embodied
   Conversational Agents
SO HUMAN-COMPUTER INTERACTION: ADVANCED INTERACTION MODALITIES AND
   TECHNIQUES, PT II
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 16th International Conference on Human-Computer Interaction (HCI)
CY JUN 22-27, 2014
CL Heraklion, GREECE
DE virtual agents; personality; extroversion-introversion; language variety
   and non-verbal behaviour
AB In this paper, we investigate the effects of language variety in combination with bodily behaviour on the perceived personality of a virtual agent. In particular, we explore changes on the extroversion-introversion dimension of personality. An online perception study was conducted featuring a virtual character with different levels of expressive body behaviour and different synthetic voices representing German and Austrian language varieties. Clear evidence was found that synthesized language variety, and gestural expressivity influence the human perception of an agent's extroversion. Whereby Viennese and Austrian standard language are perceived as more extrovert than it is the case for the German standard.
C1 [Krenn, Brigitte] Austrian Res Inst Artificial Intelligence, Freyung 6-6, A-1010 Vienna, Austria.
   [Endrass, Birgit; Kistler, Felix; Andre, Elisabeth] Univ Augsburg, D-86159 Augsburg, Germany.
RP Krenn, B (corresponding author), Austrian Res Inst Artificial Intelligence, Freyung 6-6, A-1010 Vienna, Austria.
EM brigitte.krenn@ofai.at; endrass@hcm-lab.de; kistler@hcm-lab.de;
   andre@hcm-lab.de
RI Lugrin, Birgit/AAE-9421-2021; Andre, Elisabeth/AAW-4960-2021
OI Lugrin, Birgit/0000-0002-2362-0080; 
CR Brebner J, 1985, PERSONALITY THEORY M, P27
   CAMPBELL A, 1978, BRIT J SOC CLIN PSYC, V17, P31, DOI 10.1111/j.2044-8260.1978.tb00893.x
   Clark R, 2007, P INTERSPEECH, P101
   Damian Ionut, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P15, DOI 10.1007/978-3-642-25090-3_2
   Gartig A.-K., 2010, ARBEITSPAPIERE MAT D, V40
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1
   Knapp Mark L., 2009, NONVERBAL COMMUNICAT, V7th
   Krenn Brigitte, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P377, DOI 10.1007/978-3-642-33197-8_39
   Lippa R, 1998, J RES PERS, V32, P80, DOI 10.1006/jrpe.1997.2189
   Neff Michael, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P398, DOI 10.1007/978-3-642-23974-8_43
   Neff M, 2010, LECT NOTES ARTIF INT, V6356, P222, DOI 10.1007/978-3-642-15892-6_24
   Neubarth F, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1877
   Pucher M, 2010, P 7 INT C LANG RES E, P105
   Pucher M, 2010, SPEECH COMMUN, V52, P164, DOI 10.1016/j.specom.2009.09.004
   Satow L, 2012, BIG 5 PERS NLICHKEIT
NR 15
TC 2
Z9 2
U1 2
U2 5
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-319-07230-2; 978-3-319-07229-6
J9 LECT NOTES COMPUT SC
PY 2014
VL 8511
BP 429
EP 439
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BB3FE
UT WOS:000342751800041
OA Green Submitted, Bronze
DA 2022-08-02
ER

PT C
AU Hu, JX
   Huang, Y
   Hu, XZ
   Xu, YQ
AF Hu, Jiaxiong
   Huang, Yun
   Hu, Xiaozhu
   Xu, Yingqing
GP ACM
TI Enhancing the Perceived Emotional Intelligence of Conversational Agents
   through Acoustic Cues
SO EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN
   COMPUTING SYSTEMS (CHI'21)
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems
CY MAY 08-13, 2021
CL ELECTR NETWORK
SP ACM SIGCHI, Assoc Comp Machinery, Bloomberg, Facebook, Google, Kyocera, Microsoft, Monash Univ, Verizon Media
DE conversational agent; voice assistant; emotion; chatbot; emotional
   intelligence
ID PRAISE
AB The perceived emotional intelligence of a conversational agent (CA) can significantly impact people's interaction with the CA. Prior research applies text-based sentiment analysis and emotional response generation to improve CAs' emotional intelligence. However, acoustic features in speech containing rich contexts are under-exploited. In this work, we designed and implemented an emotionally aware CA, called HUE (Heard yoUr Emotion) that stylized responses with emotion regulation strategies and empathetic interjections. We conducted a user study with 75 participants to evaluate their perceived emotional intelligence (PEI) of HUE by having them observe conversations between people and HUE in different emotional scenarios. Our results show that participants' PEI was significantly higher with the acoustic features than without.
C1 [Hu, Jiaxiong; Hu, Xiaozhu; Xu, Yingqing] Tsinghua Univ, Acad Arts & Design, Beijing, Peoples R China.
   [Hu, Jiaxiong; Xu, Yingqing] Tsinghua Univ, Future Lab, Beijing, Peoples R China.
   [Huang, Yun] Univ Illinois, Urbana, IL USA.
RP Hu, JX (corresponding author), Tsinghua Univ, Acad Arts & Design, Beijing, Peoples R China.; Hu, JX (corresponding author), Tsinghua Univ, Future Lab, Beijing, Peoples R China.
EM hujx19@mails.tsinghua.edu.cn; yunhuang@illinois.edu;
   huxz19@mails.tsinghua.edu.cn; yqxu@mail.tsinghua.edu.cn
OI Huang, Yun/0000-0003-0399-8032
FU National Key Research and Development Plan [2019YFF0302902]; Tsinghua
   University-Alibaba Joint Research Laboratory for Natural Interaction
   Experience [20182911173]
FX This work was supported by the National Key Research and Development
   Plan under Grant No.2019YFF0302902 and Tsinghua University-Alibaba Joint
   Research Laboratory for Natural Interaction Experience under Grant
   No.20182911173. Assistance provided by Yi Feng, Jincheng Liu, Yuekang
   Teng, Kexin Quan, Yiting Cheng, Jiahong Sun was greatly appreciated.
CR Albanie S, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P292, DOI 10.1145/3240508.3240578
   Bickmore TW, 2010, IEEE T AFFECT COMPUT, V1, P60, DOI 10.1109/T-AFFC.2010.4
   Chaves Ana Paula, 2019, CORR
   Chen DY, 2017, ANN WORK NETW, P19
   Chen Huimin, 2016, P 2016 C EMP METH NA
   Cohn M, 2019, 20TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2019), P293
   CRASKE MG, 1989, BEHAV RES THER, V27, P663, DOI 10.1016/0005-7967(89)90150-2
   Dohsaka Kohji, 2009, P SIGDIAL C 10 ANN M, P217
   Drescher M, 1997, LANGUAGE OF EMOTIONS, P233
   Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785
   Fredrickson BL, 2013, ADV EXP SOC PSYCHOL, V47, P1, DOI 10.1016/B978-0-12-407236-7.00001-2
   Hasler BS, 2014, CYBERPSYCH BEH SOC N, V17, P766, DOI 10.1089/cyber.2014.0213
   Haymaker CL, 2017, JOVE-J VIS EXP, DOI 10.3791/56255
   Hu TR, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173989
   Huang J, 2015, LECT NOTES COMPUT SC, V9085, P133, DOI 10.1007/978-3-319-19156-0_14
   Ivanovic Mirjana, 2014, INT C WEB INT
   Johnstone T, 1999, P 14 INT C PHON SCI, P2029
   Kanske P, 2011, CEREB CORTEX, V21, P1379, DOI 10.1093/cercor/bhq216
   Kim SH, 2019, STEM CELLS INT, V2019, DOI 10.1155/2019/2130973
   Lee YC, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376175
   Liao QV, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173577
   Ma XJ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1222, DOI 10.1145/3308558.3313400
   Mayer J.D., 1997, EMOTIONAL DEV EMOTIO, DOI DOI 10.1177/1066480710387486
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Moridis CN, 2012, IEEE T AFFECT COMPUT, V3, P260, DOI 10.1109/T-AFFC.2012.6
   Mumm J, 2011, COMPUT HUM BEHAV, V27, P1643, DOI 10.1016/j.chb.2011.02.002
   Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950
   Nezlek JB, 2008, EMOTION, V8, P145, DOI 10.1037/1528-3542.8.1.145
   Niculescu A, 2013, INT J SOC ROBOT, V5, P171, DOI 10.1007/s12369-012-0171-x
   Ochsner KN, 2008, CURR DIR PSYCHOL SCI, V17, P153, DOI 10.1111/j.1467-8721.2008.00566.x
   Ochsner KN, 2005, TRENDS COGN SCI, V9, P242, DOI 10.1016/j.tics.2005.03.010
   Qian Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1679, DOI 10.18653/v1/P17-1154
   Salovey P., 1990, IMAG COGN PERS, V9, P185, DOI [DOI 10.2190/DUGG-P24E-52WK-6CDG, 10.2190/DUGG-P24E-52WK-6CDG]
   Shum HY, 2018, FRONT INFORM TECH EL, V19, P10, DOI 10.1631/FITEE.1700826
   Song ZQ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3685
   Toxtli C, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173632
   Tzeng JY, 2012, COMPUT HUM BEHAV, V28, P2420, DOI 10.1016/j.chb.2012.07.013
   Weisz JD, 2019, PROCEEDINGS OF IUI 2019, P448, DOI 10.1145/3301275.3302290
   WIERZBICKA A, 1992, J PRAGMATICS, V18, P159, DOI 10.1016/0378-2166(92)90050-L
   Wierzbicka A., 1999, EMOTIONS LANGUAGES C, DOI [DOI 10.1017/CBO9780511521256, 10.1017/CBO9780511521256]
   WILLIAMS CE, 1972, J ACOUST SOC AM, V52, P1238, DOI 10.1121/1.1913238
   Willroth EC, 2020, J PERS, V88, P174, DOI 10.1111/jopy.12475
   Xiao ZA, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3381804
   Yang X, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300772
   Zhou H, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P730
   Zhou SP, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P579
NR 46
TC 1
Z9 1
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8095-9
PY 2021
DI 10.1145/3411763.3451660
PG 7
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7DM
UT WOS:000759178501142
DA 2022-08-02
ER

PT C
AU Olafsson, S
   O'Leary, T
   Bickmore, T
AF Olafsson, Stefan
   O'Leary, Teresa
   Bickmore, Timothy
GP ACM
TI Coerced Change-talk with Conversational Agents Promotes Confidence in
   Behavior Change
SO PROCEEDINGS OF THE 13TH EAI INTERNATIONAL CONFERENCE ON PERVASIVE
   COMPUTING TECHNOLOGIES FOR HEALTHCARE (PERVASIVEHEALTH 2019)
SE International Conference on Pervasive Computing Technologies for
   Healthcare
LA English
DT Proceedings Paper
CT 13th EAI International Conference on Pervasive Computing Technologies
   for Healthcare (PervasiveHealth)
CY MAY 20-23, 2019
CL Trento, ITALY
SP EAI
DE Virtual agents; Motivational interviewing; Attitude; Behavior change;
   Change-talk; Health; Forced compliance
ID DECISIONAL BALANCE; SELF-EFFICACY; FRUIT; CONSUMPTION; ADOLESCENTS
AB Motivational interviewing is a counseling technique that works, in part, by helping people talk about changing their behavior. We describe two conversational agent-based interventions to increase motivation and confidence to promote physical activity and fruit and vegetable consumption that incorporate principles from motivational interviewing. We also explore the efficacy of constraining input, so users are only allowed to express change talk in their conversation with the agent. In a within-subjects experiment we demonstrate that both interventions are effective at increasing motivation, confidence, and self-efficacy for behavior change during a single counseling session. We also demonstrate that coercing user change talk leads to significantly greater increases in confidence compared to equivalent counseling agents that allow users to express statements about not changing their behavior.
C1 [Olafsson, Stefan; O'Leary, Teresa; Bickmore, Timothy] Northeastern Univ, Boston, MA 02115 USA.
RP Olafsson, S (corresponding author), Northeastern Univ, Boston, MA 02115 USA.
EM stefanolafs@ccs.neu.edu; oleary.t@husky.neu.edu; bickmore@ccs.neu.edu
CR [Anonymous], 1998, ANN BEHAV MED
   Baranowski T, 2010, INT J BEHAV NUTR PHY, V7, DOI 10.1186/1479-5868-7-25
   Berry T, 2005, J ADOLESCENT HEALTH, V37, P452, DOI 10.1016/j.jadohealth.2004.09.019
   Bickmore TW, 2018, J MED INTERNET RES, V20, DOI 10.2196/11510
   Blackwell D. L., STATE VARIATION M 20, P1
   Cassell J, 2001, COMP GRAPH, P477
   Cassell J., 2000, EMBODIED CONVERSATIO
   Charmaz K., 2014, BROKERAGE CLOSURE, V2nd
   da Silva JGG, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.7737
   Di Noia J, 2006, AM J HEALTH PROMOT, V20, P342, DOI 10.4278/0890-1171-20.5.342
   FESTINGER L, 1959, J ABNORM SOC PSYCH, V58, P203, DOI 10.1037/h0041593
   Festinger L., 1957, THEORY COGNITIVE DIS, V2
   Hawkins RP, 2008, HEALTH EDUC RES, V23, P454, DOI 10.1093/her/cyn004
   Henry H, 2006, J AM DIET ASSOC, V106, P841, DOI 10.1016/j.jada.2006.03.012
   Kroll T, 2007, INT J BEHAV NUTR PHY, V4, DOI 10.1186/1479-5868-4-34
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Ma J, 2002, AM J HEALTH PROMOT, V16, P157, DOI 10.4278/0890-1171-16.3.157
   Martins RK, 2009, CLIN PSYCHOL REV, V29, P283, DOI 10.1016/j.cpr.2009.02.001
   McCambridge J, 2004, ADDICTION, V99, P39, DOI 10.1111/j.1360-0443.2004.00564.x
   Miller WR, 2009, AM PSYCHOL, V64, P527, DOI 10.1037/a0016830
   Miller WR, 2003, J CONSULT CLIN PSYCH, V71, P754, DOI 10.1037/0022-006X.71.4.754
   Noar SM, 2007, PSYCHOL BULL, V133, P673, DOI 10.1037/0033-2909.133.4.673
   Oliver I, 2012, IEEE IC COMP COM NET
   Prochaska J. O., AM J HEAL PROMOT, V12, P38
   Rishe N, 2013, ACM TMIS, V4, P1, DOI [10.1145/2544103, DOI 10.1145/2544103]
   Rubak S, 2005, BRIT J GEN PRACT, V55, P305
   Schurr D, 2011, AMST BEITR ALTER GER, V68, P1
   U. S. D. of H. and H. Services, 2017, DIET GUID AM 2015 20
   Walters ST, 2014, J SUBST ABUSE TREAT, V46, P60, DOI 10.1016/j.jsat.2013.07.003
   Webb TL, 2010, J MED INTERNET RES, V12, DOI 10.2196/jmir.1376
   Wilbourne P, 2018, INT CONF PER COMP, P389, DOI 10.1145/3240925.3240932
NR 31
TC 12
Z9 12
U1 1
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
SN 2153-1633
BN 978-1-4503-6126-2
J9 INT CONF PER COMP
PY 2019
BP 31
EP 40
DI 10.1145/3329189.3329202
PG 10
WC Computer Science, Interdisciplinary Applications; Medical Informatics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Medical Informatics
GA BN4LG
UT WOS:000482176100004
DA 2022-08-02
ER

PT C
AU Quanjer, AJ
   Jylha, A
   van Leeuwen, JP
AF Quanjer, Arnold Jan
   Jylha, Antti
   van Leeuwen, Jos P.
BE Griffiths, P
   Kabir, MN
TI Using Lo-Fi Prototyping to Envision Conversational Agents in Public
   Settings
SO PROCEEDINGS OF THE EUROPEAN CONFERENCE ON THE IMPACT OF ARTIFICIAL
   INTELLIGENCE AND ROBOTICS (ECIAIR 2019)
LA English
DT Proceedings Paper
CT European Conference on the Impact of Artificial Intelligence and
   Robotics (ECIAIR)
CY OCT 31-NOV 01, 2019
CL EM Normandie Business Sch, Oxford, ENGLAND
HO EM Normandie Business Sch
DE Smart city; artificial intelligence; conversational agent; speech
   interface
AB Speech interactions are often associated with virtual assistants and smart home devices, designed primarily for private contexts. A less developed domain is speech interfaces in public contexts. In a smart city development project, we explored the potential of distributed conversational speech interfaces in lampposts. Deploying a research- through-design method, we created a lo-fi prototype of the speech interface that test subjects could interact with during experiments in a lab setting. Our first exploratory prototype consisted of a loudspeaker that acted as the interface and preconceived dialogues designed to investigate the boundaries of desirable and acceptable experiences regarding issues such as privacy. Experiencing the interaction with this rudimentary prototype helped people envision potential use cases and reflect on privacy issues: the dialogues revealed subjective limits of what kind of (personal) information people were willing to share with the lamppost. They also elicited thoughts on possible consequences in the social context of citizens.
C1 [Quanjer, Arnold Jan; Jylha, Antti; van Leeuwen, Jos P.] The Hague Univ Appl Sci, The Hague, Netherlands.
RP Quanjer, AJ (corresponding author), The Hague Univ Appl Sci, The Hague, Netherlands.
EM a.j.r.quanjer@hhs.nl; a.t.jylha@hhs.nl; j.p.vleeuwen@hhs.nl
RI van Leeuwen, Jos/C-8727-2017
OI van Leeuwen, Jos/0000-0002-7182-2170
CR Bohn J, 2005, AMBIENT INTELLIGENCE, P5, DOI 10.1007/3-540-27139-2_2
   Clark L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300705
   Clark Leigh, 2018, ARXIV181006828
   Cowan B.R., 2017, P 19 INT C HUM COMP
   DAHLBACK N, 1993, KNOWL-BASED SYST, V6, P258, DOI 10.1016/0950-7051(93)90017-N
   Godin D., 2014, P DRS 2014 DES BIG D, P1
   Koelle M, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3170620
   Liao Y., 2019, INT C INF CONT SOC W
   Moore RJ, 2018, HUM-COMPUT INT-SPRIN, P181, DOI 10.1007/978-3-319-95579-7_9
   Moore Roger K, 2017, DIALOGUES SOCIAL ROB, P281, DOI DOI 10.1007/978-981-10-2585-3_22
   Moorthy A. E., 2014, INT C HUM INT MAN IN
   Oulasvirta A., 2006, ISCA DEGA TUT RES WO
   Porcheron M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174214
   Rico Julie., 2010, INT C MULT INT WORKS
   van Leeuwen J.P., 2018, KUNSTMATIGE INTELLIG
NR 15
TC 0
Z9 0
U1 1
U2 2
PU ACAD  CONFERENCES LTD
PI NR READING
PA CURTIS FARM, KIDMORE END, NR READING, RG4 9AY, ENGLAND
BN 978-1-912764-44-0
PY 2019
BP 469
EP 473
DI 10.34190/ECIAIR.19.064
PG 5
WC Computer Science, Artificial Intelligence; Robotics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Robotics
GA BP1JZ
UT WOS:000539633500053
DA 2022-08-02
ER

PT J
AU Perez-Marin, D
   Pascual-Nieto, I
AF Perez-Marin, Diana
   Pascual-Nieto, Ismael
TI An exploratory study on how children interact with pedagogic
   conversational agents
SO BEHAVIOUR & INFORMATION TECHNOLOGY
LA English
DT Article
DE pedagogic conversational agent; natural language interaction;
   E-learning; B-learning
AB A pedagogic conversational agent (PCA) can be defined as a computer system that interacts with the student in natural language assuming the role of the instructor, a student or a companion. It can have a personality and can generate different sentences according to the agent or the student mood. Empathy with the students' feelings seems to increase their motivation to study. However, the influence of the agent personality and role as well as the students' opinion is still unclear. Therefore, in this article, it is explored with the help of a field experiment, for the first time, how these factors can affect the interaction of children with PCAs, and their opinions according to an anonymous and voluntary opinion questionnaire and some personal interviews.
C1 [Perez-Marin, Diana; Pascual-Nieto, Ismael] Univ Rey Juan Carlos, Fac Comp Sci, Dept Comp Languages & Syst 1, Madrid, Spain.
RP Perez-Marin, D (corresponding author), Univ Rey Juan Carlos, Fac Comp Sci, Dept Comp Languages & Syst 1, Madrid, Spain.
EM diana.perez@urjc.es
RI Pérez-Marín, Diana/L-4100-2014; Pérez-Marín, Diana/ABF-6641-2021
OI Pérez-Marín, Diana/0000-0003-3390-0251; Pérez-Marín,
   Diana/0000-0003-3390-0251
CR Arroyo I., 2011, 2011 11th IEEE International Conference on Advanced Learning Technologies (ICALT 2011), P506, DOI 10.1109/ICALT.2011.157
   Callejas Z, 2011, CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND EFFECTIVE PRACTICES, P203, DOI 10.4018/978-1-60960-617-6.ch009
   Chase CC, 2009, J SCI EDUC TECHNOL, V18, P334, DOI 10.1007/s10956-009-9180-4
   De Angeli A, 2008, INTERACT COMPUT, V20, P302, DOI 10.1016/j.intcom.2008.02.004
   Fisher R., 2005, TEACHING CHILDREN LE
   Girard S, 2010, LECT NOTES COMPUT SC, V6094, P307
   Graesser Arthur C, 2008, Journal of Interactive Learning Research, V19, P293
   Graham C., 2006, Beltwide Cotton Conferences
   Gulz A, 2011, CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND EFFECTIVE PRACTICES, P128, DOI 10.4018/978-1-60960-617-6.ch006
   Johnson WL, 2000, INT J ARTIFICIAL INT, V11, P47
   Lane C., 2010, AD PERS E B LEARN US, P7
   Lester J. C., 1997, P SIGCHI C HUM FACT
   Manen M.V, 1991, TACT TEACHING MEANIN
   Pascual-Nieto Ismael, 2009, Advanced Learning, P1
   Perez-Marin D., 2007, BLENDED LEARNING, P186
   Porayska-Pomsta K, 2012, PERS UBIQUIT COMPUT, V16, P117, DOI 10.1007/s00779-011-0384-2
   Rickel J, 1999, FRONT ARTIF INTEL AP, V50, P578
   Ryokai K, 2003, J COMPUT ASSIST LEAR, V19, P195, DOI 10.1046/j.0266-4909.2003.00020.x
   Sabot Z., 2005, UNITAR E J, V1, P52
   Veletsianos G, 2012, COMPUT HUM BEHAV, V28, P275, DOI 10.1016/j.chb.2011.09.010
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   [No title captured]
   [No title captured]
   [No title captured]
NR 24
TC 11
Z9 11
U1 1
U2 10
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0144-929X
EI 1362-3001
J9 BEHAV INFORM TECHNOL
JI Behav. Inf. Technol.
PD SEP 1
PY 2013
VL 32
IS 9
BP 955
EP 964
DI 10.1080/0144929X.2012.687774
PG 10
WC Computer Science, Cybernetics; Ergonomics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 218UQ
UT WOS:000324458400008
DA 2022-08-02
ER

PT C
AU Stone, M
   Oh, I
AF Stone, Matthew
   Oh, Insuk
BE Wachsmuth, I
   Knoblich, G
TI Modeling facial expression of uncertainty in conversational animation
SO MODELLING COMMUNICATION WITH ROBOTS AND VIRTUAL HUMANS
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 2nd ZiF-Research-Group International Workshop on Embodied Communication
   in Humans and Machines
CY APR 05-08, 2006
CL Bielefeld, GERMANY
SP ZiF Res Grp
DE embodied conversational agents; facial displays; face-to-face;
   conversation; uncertainty
ID CONFUSION; PROSODY
AB Building animated conversational agents requires developing a fine-grained analysis of the motions and meanings available to interlocutors in face-to-face conversation and implementing strategies for using these motions and meanings to communicate effectively. In this paper, we sketch our efforts to characterize people's facial displays of uncertainty in face-to-face conversation. We analyze empirical data from human-human conversation and extend our platform for conversational animation, including RUTH (the Rutgers University Talking Head), to simulate what we find. This methodology leads to a range of new insights into the structure, timing, expressive content and communicative function of facial actions.
C1 [Stone, Matthew; Oh, Insuk] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.
RP Stone, M (corresponding author), Rutgers State Univ, Dept Comp Sci, 110 Frelinghuysen Rd, Piscataway, NJ 08854 USA.
EM matthew.stone@rutgers.edu
CR Bavelas JB, 2000, J LANG SOC PSYCHOL, V19, P163, DOI 10.1177/0261927X00019002001
   BLACK A, 1997, HCRCTR83 HUM COMM RE
   Brashers DE, 2001, J COMMUN, V51, P477, DOI 10.1111/j.1460-2466.2001.tb02892.x
   BRENNAN SE, 1995, J MEM LANG, V34, P383, DOI 10.1006/jmla.1995.1017
   BULL P, 1985, J NONVERBAL BEHAV, V9, P169, DOI 10.1007/BF01000738
   Cassell J, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P106
   CASSELL J, 1999, PRAGMATICS COGNITION, V6
   Clark HH, 2004, J MEM LANG, V50, P62, DOI 10.1016/j.jml.2003.08.004
   Cohen M. M., 1993, Models and Techniques in Computer Animation, P139
   Cohn JF, 2005, NEW HDB METHODS NONV, P9
   Darwin C, 1904, EXPRESS EMOT MAN, DOI 10.1037/10001-000
   DeCarlo D, 2004, COMPUT ANIMAT VIRT W, V15, P27, DOI [10.1002/cav.5, 10.1002/cav.3]
   DEVALT D, 2006, BRANDIAL, P64
   Ekman P., 2002, HUMAN FACE
   Ekman P., 1969, SEMIOTICA, V1, P49, DOI DOI 10.1515/SEMI.1969.1.1.49
   Ellsworth PC, 2003, EMOTION, V3, P81, DOI 10.1037/1528-3542.3.1.81
   ENGLE RA, 2000, THESIS STANFORD U
   FORBESRILEY K, 2007, RECENT TRENDS DISCOU
   FRANK M, 2006, NEW HDB METHODS NONV
   Givens D.B., 2001, NONVERBAL DICT GESTU
   Hirschberg, 1992, P INT C SPOK LANG PR, P867
   KING SA, 2001, THESIS OHIO STATE U
   Krahmer E, 2005, LANG SPEECH, V48, P29, DOI 10.1177/00238309050480010201
   KRAHMER E, 2002, S SPEECH PROS
   LISCOMBE J, 2005, P INTERSPEECH
   LOFQVIST A, 1990, NATO ADV SCI I D-BEH, V55, P289
   McNeill D., 1992, HAND MIND WHAT GESTU
   NAKANO YI, 2004, LNCS LNAI, V2922, P553
   OH I, 2006, THESIS RUTGERS U
   OH I, 2007, ICA INT COMMUNICATIO
   Paek T, 2000, P 16 C UNC ART INT S, P455
   Ploog D., 1979, HUMAN ETHOLOGY CLAIM, P169, DOI DOI 10.1007/978-1-4020-2783-33
   Rozin P, 2003, EMOTION, V3, P68, DOI 10.1037/1528-3542.3.1.68
   SMITH VL, 1993, J MEM LANG, V32, P25, DOI 10.1006/jmla.1993.1002
   STONE M, 2007, LNCS, V4561, P443
   Swerts M, 2005, J MEM LANG, V53, P81, DOI 10.1016/j.jml.2005.02.003
   Vilhjalmsson H. H., 1998, Proceedings of the Second International Conference on Autonomous Agents, P269, DOI 10.1145/280765.280843
NR 37
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-540-79036-5
J9 LECT NOTES ARTIF INT
PY 2008
VL 4930
BP 57
EP 76
PG 20
WC Computer Science, Artificial Intelligence; Robotics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Robotics
GA BHP49
UT WOS:000255181500004
DA 2022-08-02
ER

PT C
AU Zamora, J
AF Zamora, Jennifer
GP ACM
TI Are We Having Fun Yet? Designing for Fun in Artificial Intelligence That
   Is Multicultural and Multiplatform
SO PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT
   INTERACTION (HAI'19)
LA English
DT Proceedings Paper
CT 7th International Conference on Human-Agent Interaction (HAI)
CY OCT 06-10, 2019
CL Kyoto Sangyo Univ, Musubiwaza Kan, Kyoto, JAPAN
HO Kyoto Sangyo Univ, Musubiwaza Kan
DE HCI; Artificial Intelligence; Conversational Agents; US; India
AB Personality of Artificial Intelligence (A.I) is a vast and complex domain. Traits like trustworthiness and humanness have long been evaluated, but less so for traits like fun. In this study we evaluate fun in four conversational agents with a mix of menial tasks, games, and free play in the US and India on voice and text-based platforms. Our research explores user sentiment of fun in an A.I. personality, implications of fun personality on voice-based and text-based agents, and the perception of a fun A.I. personality in two culturally distinct markets. We used a mixed method approach to evaluate these objectives with 44 participants. Our results end with design principles for creating fun in artificial intelligence: 1) balance fun through conversational humor and goal-oriented actions, 2) create fun experiences through playful interactions, 3) convey fun through platform specific expressions like tone of voice or visual gestures and emojis, and 4) be inclusively fun by being culturally relevant so your conversational agent translates across borders.
C1 [Zamora, Jennifer] Google Inc, Mountain View, CA 94043 USA.
RP Zamora, J (corresponding author), Google Inc, Mountain View, CA 94043 USA.
EM zamora@google.com
CR Apple Developers, 2019, THEM IOS HUM INT GUI
   Benedek Joey, 2002, MEASURING DESIRABILI
   Braslavski P, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P225, DOI 10.1145/3176349.3176879
   Daniel F, 2018, 2018 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON SOFTWARE ENGINEERING FOR COGNITIVE SERVICES (SE4COG), P31, DOI 10.1145/3195555.3195563
   Dybala Pawel, 2012, P 21 ACM INT C INF K, P2587, DOI [10.1145/2396761.2398698, DOI 10.1145/2396761.2398698]
   Fullerton Tracy, 2014, GAME DESIGN WORKSHOP
   Google Developers, 2019, LEARN CONV CONV DES
   Kumar Ritesh, 2010, P 3 INT C INT COLL, DOI [10.1145/1841853.1841880, DOI 10.1145/1841853.1841880]
   Lee KM, 2006, J COMMUN, V56, P754, DOI 10.1111/j.1460-2466.2006.00318.x
   Li JY, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P275, DOI 10.1145/3025171.3025206
   Ross Steven, 2004, P INT US INT IUI 04, DOI [10.1145/964442.964536, DOI 10.1145/964442.964536]
   Schell J., 2015, ART GAME DESIGN BOOK, V2nd ed.
   van Mulken S., 1999, Human-Computer Interaction: Ergonomics and User Interfaces. Proceedings of HCI International '99 (8th International Conference on Human-Computer Interaction), P152
   Weisz JD, 2019, PROCEEDINGS OF IUI 2019, P448, DOI 10.1145/3301275.3302290
NR 14
TC 0
Z9 0
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6922-0
PY 2019
BP 208
EP 210
DI 10.1145/3349537.3352767
PG 3
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BS4HG
UT WOS:000719339300031
DA 2022-08-02
ER

PT J
AU Geoghegan, L
   Scarborough, A
   Wormald, JCR
   Harrison, CJ
   Collins, D
   Gardiner, M
   Bruce, J
   Rodrigues, JN
AF Geoghegan, L.
   Scarborough, A.
   Wormald, J. C. R.
   Harrison, C. J.
   Collins, D.
   Gardiner, M.
   Bruce, J.
   Rodrigues, J. N.
TI Automated conversational agents for post-intervention follow-up: a
   systematic review
SO BJS OPEN
LA English
DT Review
AB Background: Advances in natural language processing and other machine learning techniques have led to the development of automated agents (chatbots) that mimic human conversation. These systems have mainly been used in commercial settings, and within medicine, for symptom checking and psychotherapy. The aim of this systematic review was to determine the acceptability and implementation success of chatbots in the follow-up of patients who have undergone a physical healthcare intervention.
   Methods: A systematic review of MEDLINE, MEDLINE In-process, EMBASE, PsychINFO, CINAHL, CENTRAL and the grey literature using a PRISMA-compliant methodology up to September 2020 was conducted. Abstract screening and data extraction were performed in duplicate. Risk of bias and quality assessments were performed for each study.
   Results: The search identified 904 studies of which 10 met full inclusion criteria: three randomised control trials, one non-randomised clinical trial and six cohort studies. Chatbots were used for monitoring after the management of cancer, hypertension and asthma, orthopaedic intervention, ureteroscopy and intervention for varicose veins. All chatbots were deployed on mobile devices. A number of metrics were identified and ranged from a 31 per cent chatbot engagement rate to a 97 per cent response rate for system-generated questions. No study examined patient safety.
   Conclusion: A range of chatbot builds and uses was identified. Further investigation of acceptability, efficacy and mechanistic evaluation in outpatient care pathways may lend support to implementation in routine clinical care.
C1 [Geoghegan, L.] Imperial Coll London, Vasc Surg Sect, Dept Surg & Canc, London, England.
   [Scarborough, A.] Kings Coll Hosp London, Dept Cardiothorac Surg, London, England.
   [Wormald, J. C. R.; Harrison, C. J.] Univ Oxford, Nuffield Dept Orthopaed Rheumatol & Musculoskele, Oxford, England.
   [Collins, D.] Chelsea & Westminster Hosp, Dept Plast Reconstruct & Burns Surg, London, England.
   [Gardiner, M.] Frimley Pk Hosp, Dept Plast & Reconstruct Surg, Guildford, Surrey, England.
   [Bruce, J.; Rodrigues, J. N.] Univ Warwick, Warwick Med Sch, Warwick Clin Trials Unit, Coventry, W Midlands, England.
   [Rodrigues, J. N.] Stoke Mandeville Hosp, Dept Plast & Reconstruct Surg, Aylesbury, Bucks, England.
RP Geoghegan, L (corresponding author), Imperial Coll London, Acad Sect Vasc Surg, Vasc Surg Sect, Dept Surg & Canc, Exhibition Rd, London SW7 2AZ, England.
EM luke.geoghegan13@imperial.ac.uk
RI ; Bruce, Julie/G-7588-2014
OI Collins, Declan/0000-0003-3191-3606; Rodrigues,
   Jeremy/0000-0002-9347-5026; Wormald, Justin/0000-0001-6197-4093; Bruce,
   Julie/0000-0002-8462-7999
FU National Institute for Health Research Capability Funding via University
   Hospitals Coventry and Warwickshire; National Institute for Health
   Research (NIHR) Doctoral Research Fellowship [NIHR300684]; NIHR
   Postdoctoral Fellowship [PDF-201710-075]
FX No specific funding was received for the conduct of this review. J.B. is
   supported by National Institute for Health Research Capability Funding
   via University Hospitals Coventry and Warwickshire. C.J.H. is funded by
   a National Institute for Health Research (NIHR) Doctoral Research
   Fellowship (NIHR300684). J.N.R. is funded by an NIHR Postdoctoral
   Fellowship (PDF-201710-075). The views expressed are those of the
   authors and not necessarily those of the NHS, the NIHR or the Department
   of Health and Social Care.
CR Adamopoulou E., 2020, ARTIF INTELL APPL IN
   Anthony CA, 2020, J MED INTERNET RES, V22, DOI 10.2196/17750
   ASIT oral presentations, 2020, BRIT J SURG, V107, P5
   ASIT poster presentations, 2020, BRIT J SURG, V107, P25
   Bian YY, 2020, J MED INTERNET RES, V22, DOI 10.2196/16896
   Bibault JE, 2019, J MED INTERNET RES, V21, DOI 10.2196/15787
   Black C, 2020, J VAS INTERV RADIOL, V31, pS36
   Booth A, 2012, SYST REV-LONDON, V1, DOI 10.1186/2046-4053-1-2
   Chaix B, 2019, JMIR CANCER, V5, DOI 10.2196/12856
   Dekkers OM, 2012, ANN INTERN MED, V156, P37, DOI 10.7326/0003-4819-156-1-201201030-00006
   Giorgino T, 2005, INT J MED INFORM, V74, P159, DOI 10.1016/j.ijmedinf.2004.04.026
   Goldenthal Steven B, 2019, Mhealth, V5, P8, DOI 10.21037/mhealth.2019.03.01
   Greer S, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/15018
   Healy P, 2019, BMJ QUAL SAF, V28, P24, DOI 10.1136/bmjqs-2018-008171
   Arraras JI, 2010, EUR J CANCER, V46, P2726, DOI 10.1016/j.ejca.2010.06.118
   Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072
   Lexico, CHATB
   Moher D, 2009, PLOS MED, V6, DOI 10.1371/journal.pmed.1000097
   National Institutes of Health, QUALITY ASSESSMENT T
   Ofcom, AD MED US ATT REP 20
   Parkes RJ, 2019, BMJ OPEN QUAL, V8, DOI 10.1136/bmjoq-2018-000502
   Piau A, 2019, INT J MED INFORM, V128, P18, DOI 10.1016/j.ijmedinf.2019.05.013
   Rhee H, 2014, PATIENT PREFER ADHER, V8, P63, DOI 10.2147/PPA.S53504
   Scarborough A, 2020, J HAND SURG-EUR VOL, V45, P1005, DOI 10.1177/1753193420934679
   Sterne JAC, 2019, BMJ-BRIT MED J, V366, DOI 10.1136/bmj.l4898
   Sterne JAC, 2016, BMJ-BRIT MED J, V355, DOI 10.1136/bmj.i4919
   Stover AM, 2021, QUAL LIFE RES, V30, P3015, DOI 10.1007/s11136-020-02564-9
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168
NR 28
TC 1
Z9 1
U1 4
U2 4
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 2474-9842
J9 BJS OPEN
JI BJS Open
PD JUL
PY 2021
VL 5
IS 4
AR zrab070
DI 10.1093/bjsopen/zrab070
EA JUL 2021
PG 8
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA YY1KQ
UT WOS:000754552400018
PM 34323916
OA Green Published, gold
DA 2022-08-02
ER

PT C
AU Rastogi, A
   Zang, XX
   Sunkara, S
   Gupta, R
   Khaitan, P
AF Rastogi, Abhinav
   Zang, Xiaoxue
   Sunkara, Srinivas
   Gupta, Raghav
   Khaitan, Pranav
GP Assoc Advancement Artificial Intelligence
TI Towards Scalable Multi-Domain Conversational Agents: The Schema-Guided
   Dialogue Dataset
SO THIRTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THE
   THIRTY-SECOND INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE
   CONFERENCE AND THE TENTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN
   ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
LA English
DT Proceedings Paper
CT 34th AAAI Conference on Artificial Intelligence / 32nd Innovative
   Applications of Artificial Intelligence Conference / 10th AAAI Symposium
   on Educational Advances in Artificial Intelligence
CY FEB 07-12, 2020
CL New York, NY
SP Assoc Advancement Artificial Intelligence
AB Virtual assistants such as Google Assistant, Alexa and Siri provide a conversational interface to a large number of services and APIs spanning multiple domains. Such systems need to support an ever-increasing number of services with possibly overlapping functionality. Furthermore, some of these services have little to no training data available. Existing public datasets for task-oriented dialogue do not sufficiently capture these challenges since they cover few domains and assume a single static ontology per domain. In this work, we introduce the the Schema-Guided Dialogue (SGD) dataset, containing over 16k multi-domain conversations spanning 16 domains. Our dataset exceeds the existing task-oriented dialogue corpora in scale, while also highlighting the challenges associated with building large-scale virtual assistants. It provides a challenging testbed for a number of tasks including language understanding, slot filling, dialogue state tracking and response generation. Along the same lines, we present a schema-guided paradigm for task-oriented dialogue, in which predictions are made over a dynamic set of intents and slots, provided as input, using their natural language descriptions. This allows a single dialogue system to easily support a large number of services and facilitates simple integration of new services without requiring additional training data. Building upon the proposed paradigm, we release a model for dialogue state tracking capable of zero-shot generalization to new APIs, while remaining competitive in the regular setting.
C1 [Rastogi, Abhinav; Zang, Xiaoxue; Sunkara, Srinivas; Gupta, Raghav; Khaitan, Pranav] Google Res, Mountain View, CA 94043 USA.
RP Rastogi, A (corresponding author), Google Res, Mountain View, CA 94043 USA.
EM abhirast@google.com; xiaoxuez@google.com; srinivasksun@google.com;
   raghavgupta@google.com; pranavkhaitan@google.com
CR Bapna A., 2017, ARXIV170702363
   Budzianowski P., 2018, P EMNLP 2018, P5016, DOI 10.18653/v1/d18-1547
   Chao G.-L., 2019, P INTERSPEECH 2019, P1468
   Devlin J., 2018, ARXIV
   El Asri L, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017)
   Eric M., 2019, ARXIV190701669
   Goel Rahul, 2019, INTERSPEECH
   Hemphill C.T., 1990, SPEECH NAT LANG P WO
   Henderson M., 2014, P SIGDIAL 2014, P292
   Henderson M, 2014, IEEE W SP LANG TECH, P324, DOI 10.1109/SLT.2014.7078595
   Henderson Matthew, 2014, P 15 ANN M SPECIAL I, P263
   Hendrycks Dan, 2017, ARXIV160608415
   KELLEY JF, 1984, ACM T OFF INF SYST, V2, P26, DOI 10.1145/357417.357420
   KIM YB, 2018, LONG PAPERS, P2214
   KIM ZM, 2017, DIALOGUES SOCIAL ROB, P434
   MRKSIC N, 2017, LONG PAPERS, P1777, DOI DOI 10.18653/V1/P17-1163
   Peters M. E., 2018, IMPROVING LANGUAGE U, P2227
   Rastogi A, 2018, 19TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2018), P376
   Rastogi A, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P561, DOI 10.1109/ASRU.2017.8268986
   Ren L., 2018, P 2018 C EMP METH NA, P2780
   Shah DJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5484
   Shah Pararth, 2018, ARXIV180104871
   Wen TH, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P438
   WILLIAMS J, 2013, PROCEEDINGS OF THE S, P407, DOI DOI 10.1016/B978-0-12-397888-2.00014-6
   Wu CS, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P808
   Xia C, 2018, ARXIV PREPRINT ARXIV
   Yang Z., 2017, ARXIV170306345
   ZHONG V, 2018, LONG PAPERS, P1458
   Zhu S, 2018, 19TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2018), P391
NR 29
TC 23
Z9 24
U1 0
U2 1
PU ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE
PI PALO ALTO
PA 2275 E BAYSHORE RD, STE 160, PALO ALTO, CA 94303 USA
SN 2159-5399
EI 2374-3468
BN 978-1-57735-835-0
J9 AAAI CONF ARTIF INTE
PY 2020
VL 34
BP 8689
EP 8696
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Education, Scientific Disciplines
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Education & Educational Research
GA BR7JR
UT WOS:000668126801018
DA 2022-08-02
ER

PT C
AU Procter, M
   Heller, R
   Lin, FH
AF Procter, Michael
   Heller, Robert
   Lin, Fuhua
BE Nkambou, R
   Azevedo, R
   Vassileva, J
TI Classifying Interaction Behaviors of Students and Conversational Agents
   Through Dialog Analysis
SO INTELLIGENT TUTORING SYSTEMS, ITS 2018
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 14th International Conference on Intelligent Tutoring Systems (ITS)
CY JUN 11-15, 2018
CL Montreal, CANADA
SP Inst Intelligent Systems, Natl Sci Fdn, Springer, Tourisme Montreal
AB E-learning systems based on a conversational agent (CA) provide the basis of an intuitive and engaging interface for the student. The goal of this paper is to propose a method for detecting conversational interaction behaviors of learners and CAs, using an agent-based framework, for the purpose of improving the communication between students and CA-based intelligent tutoring systems. Our framework models both the student and the CA and uses agents to represent data sources for each. We show how the framework uses the detection of conversational behaviors to initiate interventions to improve student conversational engagement. The results of initial user testing are reported.
C1 [Procter, Michael; Lin, Fuhua] Athabasca Univ, Sch Comp & Informat Syst, Athabasca, AB, Canada.
   [Heller, Robert] Athabasca Univ, Fac Humanities & Social Sci, Athabasca, AB, Canada.
RP Lin, FH (corresponding author), Athabasca Univ, Sch Comp & Informat Syst, Athabasca, AB, Canada.
EM mprocter@athabascau.ca; bobh@athabascau.ca; oscarl@athabascau.ca
CR Asteriadis S, 2009, LECT NOTES COMPUT SC, V5610, P22, DOI 10.1007/978-3-642-02574-7_3
   Heller R, 2009, International Journal of Web-Based Learning and Teaching Technologies, V4, P54, DOI 10.4018/jwltt.2009010104
   Kerly A, 2009, APPLICATIONS AND INNOVATIONS IN INTELLIGENT SYSTEMS XVI, P169
   Nakano YI, 2010, IUI 2010, P139
   Paquette L, 2014, LECT NOTES COMPUT SC, V8474, P1, DOI 10.1007/978-3-319-07221-0_1
   Procter M, 2016, LECT NOTES ARTIF INT, V9673, P270, DOI 10.1007/978-3-319-34111-8_33
   Szafir Daniel, 2012, P SIGCHI C HUM FACT, P11, DOI 10.1145/2207676.2207679
   Turney P., 2011, P C EMP METH NAT LAN, P680
   Wen M., 2014, 8 INT AAAI C WEBL SO
   Xu Q., 2013, SIGCHI C HUM FACT CO, P2233
NR 10
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-319-91464-0; 978-3-319-91463-3
J9 LECT NOTES COMPUT SC
PY 2018
VL 10858
BP 373
EP 379
DI 10.1007/978-3-319-91464-0_42
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BL3GC
UT WOS:000449671300042
DA 2022-08-02
ER

EF