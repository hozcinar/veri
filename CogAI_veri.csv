Abstract;Year
An E-Partner is a photo-realistic conversation agent which has a talking head that not only look photo-realistic but also can have a conversation with the user about a given topic. The conversation is multimedia-enriched in that the E-Partner presents relevant multimedia materials throughout the conversation. To address the challenges presented by the complex conversation domain and task and to achieve adaptive behaviors we have derived a novel dialogue manager design consisting of five parts: a domain model a dialogue model a discourse model a task model and a user model. We also extended existing facial animation techniques to create photo-realistic talking heads that facilitate conversational interactions. Some practical issues like how to handle the uncertainty from speech level are also discussed.;2001
Corpus-based analysis and design of spoken dialogue systems have been widely used. However in such approaches the dialogue performance cannot be predicted before the system is on line and the dialogue corpora need to be recollected if the system is modified or different conditions are assumed. Also the effects of different factors from the system's dialogue strategies speech recognition and understanding conditions and accuracy to the user's response pattern etc. on the dialogue system performance cannot be quantitatively identified and analyzed because they cannot be precisely controlled in different corpora. In this paper a complete development of computer-aided analysis and design approaches for spoken dialogue systems based on quantitative simulations is presented. With this approach the various performance metrics of a dialogue system can be flexibly defined and numerically evaluated such that the behavior and performance of the dialogue system can be well predicted and efficiently analyzed before the implementation of the real spoken dialogue system is completed. How the different dialogue performance measures vary with respect to each of the many very complicated factors regardless of whether it is caused by an individual component by the overall system design or by users' response patterns can be separately identified because all such factors can be precisely controlled in the simulation. Several analysis examples are presented to show how the approach can be used including selection and tuning of speech understanding front end system strategy design considering query factors and confirmation factors and objective estimates of user's degree of satisfaction. This approach is therefore very useful for the analysis and design of spoken dialogue systems although the online test corpus-based analysis and user survey can always follow after the system is online.;2001
For assessing the synthesized speech output component in a complex application system application-oriented evaluation methods and methodologies are needed which are not supplied by standardized lest batteries so far. Many standardized tests analyze synthetic speech mainly with regard to its form (surface structure) and only to a less degree with regard to the meaning that is assigned to it (deep structure). In turn in order to obtain a valid assessment focus for an application system the functional aspect of speech (which depends on its deep structure) has to be taken into account. In the paper two case studies are presented which focus on the acceptability of the synthesis component and its constituent dimensions in different application scenarios. In the first one synthetic speech in a car navigation and traffic information system is assessed. The second study relates to synthetic speech in a dialogue system. The assessment is limited to laboratory experiments and avoids costly field tests. It turns out that different dimensions contribute to a variable degree to overall acceptability differently depending on the application scenario. Application-oriented testing is thus required to identify the application-specific dimensions. It is discussed which characteristics of the application have to be modeled in the assessment and examples are given for both applications. (C) 2001 Elsevier Science B.V. All rights reserved.;2001
How do we decide how to represent an intelligent system in its interface and how do we decide how the interface represents information about the world and about its own workings to a user? This article addresses these questions by examining the interaction between representation and intelligence in user interfaces. The rubric representation covers at least three topics in this context: (1) how a computational system is represented in its user interface (2) how the interface conveys its representations of information and the world to human users and (3) how the system's internal representation affects the human user's interaction with the system. I argue that each of these kinds of representation (of the system information and the world the interaction) is key to how users make the kind of attributions of intelligence that facilitate their interactions with intelligent systems. In this vein it makes sense to represent a systmem as a human in those cases where social collaborative behavior is key and for the system to represent its knowledge to humans in multiple ways on multiple modalities. I demonstrate these claims by discussing issues of representation and intelligence in an embodied conversational agent-an interface in which the system is represented as a person information is conveyed to human users by multiple modalities such as voice and hand gestures and the internal representation is modality independent and both propositional and nonpropositional.;2001
HyperMirror is a new type of video conversation system which does not simulate face-to-face conversation in real space. In real space people may feel that a relative positional relationship to the other person is comfortable and sometimes that it is not. They seem to feel a similar relationship also in HyperMirror. In this paper we observe the relationship between arrangement of participants on the HyperMirror screen and comfortableness of conversation by changing position of the camera and the participants' standing positions. We find two facts in the HyperMirror screen they feel at ease to speak when they are near or look toward their partner and it is more important that they look toward their partner than that they are looked toward.;2001
Information gathering tools such as questionnaires surveys and structured interviews are ubiquitously used in evaluating patients and systems. Despite their common use there is a desperate need for better questionnaires in medical research(1) and epidemiology(2) and an infrastructure that lets them be publicly scrutinized(3). Unfortunately there has been no common platform that supports the deployment of arbitrary information gathering tools. Some psychiatric diagnostic interviews and epidemiological trials require sophisticated structured interviews containing complex branching logic dynamic phrase composition and multiple languages. The Dialogix system was developed to meet this need and facilitate the rapid definition and web-based deployment of structured human-computer interactions. This paper describes the content and process-related information captured by Dialogix and how that information has been used in the development and deployment of two large epidemiological studies.;2001
Many of the intelligent tutoring systems that have been developed during the last 20 years have proven to be quite successful particularly in the domains of mathematics science and technology. They produce significant learning gains beyond classroom environments. They are capable of engaging most students' attention and interest for hours. We have been working on a new generation of intelligent tutoring systems that hold mixed-initiative conversational dialogues with the learner. The tutoring systems present challenging problems and questions to the learner the learner types in answers in English and there is a lengthy multitum dialogue as complete solutions' or answers evolve. This article presents the tutoring systems that we have been developing. AUTOTUTOR is a conversational agent with a talking head that helps colleges Students learn about computer literacy. ANDES ATLAS AND WHY2 help adults learn about physics. Instead of being mere information-delivery systems our systems help students actively construct knowledge through conversations.;2001
Multi-domain spoken dialogue systems with high degree of intelligence and domain extensibility have long been desired but difficult to achieve. When the user freely surfs among different topics during the dialogue it will be very difficult for the system to control the switching of the topics and domains while keeping the dialogue consistent and decide when and how to take the initiative. This paper presents a distributed agent architecture for multi-domain spoken dialogue systems with high domain extensibility and intelligence. Under this architecture different spoken dialogue agents (SDA's) handling different domains can be developed independently and then smoothly cooperate with one another to achieve the user's multiple goals while a user interface agent (UIA) can access the correct spoken dialogue agent through a domain switching protocol and carry over the dialogue state and history so as to keep the knowledge processed coherently across different domains.;2001
Prior research into embodied interface agents has found that users like them and find them engaging. However results on the effectiveness of these interfaces for task completion have been mixed. In this paper we argue that embodiment can serve an even stronger function if system designers use actual human conversational protocols in the design of the interface. Communicative behaviors such as salutations and farewells conversational turn-taking with interruptions and describing objects using hand gestures are examples of protocols that all native speakers of a language already know how to perform and can thus be leveraged in an intelligent interface. We discuss how these protocols are integrated into Pea an embodied multi-modal interface agent who acts as a real-estate salesperson and we show why embodiment is required for their successful implementation. (C) 2001 Elsevier Science B.V. All rights reserved.;2001
Since the introduction of the imitation game by Turing in 1950 there has been much debate as to its validity in ascertaining machine intelligence. We wish herein to consider a different issue altogether: granted that a computing machine passes the Turing Test thereby earning the label of Turing Chatterbox'' would it then be of any use (to us humans)? From the examination of scenarios we conclude that when machines begin to participate in social transactions unresolved issues of trust and responsibility may well overshadow any raw reasoning ability they possess.;2001
Speaker-independent speech recognition systems are being used with increasing frequency for command and control applications. To date users of such systems must contend with their fragility to subtle changes in language usage and environmental acoustics. We describe work on coupling speech recognition systems with temporal probabilistic user models that provide inferences about the intentions associated with utterances. The methods can be employed to enhance the robustness of speech recognition by endowing systems with an ability to reason about the costs and benefits of action in a setting and to make decisions about the best action to take given uncertainty about the meaning behind acoustic signals. The methods have been implemented in the form of a dialog clarification module that can be integrated with legacy spoken language systems. We describe representation and inference procedures and present details on the operation of an implemented spoken command and control development environment called DeepListener.;2001
The belief that humans will be able to interact with computers in conversational speech has long been a favorite subject in science fiction reflecting the persistent belief that spoken dialogue would be the most natural and powerful user interface to computers. With recent improvements in computer technology and in speech and language processing such systems are starting to appear feasible. There are significant technical problems that still need to be solved before speech-driven interfaces become truly conversational. This article describes the results of a 10-year effort building robust spoken dialogue systems at the University of Rochester.;2001
The encounter between emotion research and agent-based technology is multifaceted. One the one hand results from emotion research start to serve as role model from nature providing inspirations for technical design criteria for individual agents at the micro level and agent groups and societies at the macro level as well as the sophisticated linkages in between them. On the other hand they are of immediate impact in important aspects of human-agent interaction and effective social cooperation between humans and conversational interfaces. In this broad survey we offer an appetising selection of results from different areas of emotion research.;2001
The fields of user modeling and natural language processing have been closely linked since the early days of user modeling. Natural language systems consult user models in order to improve their understanding of users' requirements and to generate appropriate and relevant responses. At the same time the information natural language systems obtain from their users is expected to increase the accuracy of their user models. In this paper we review natural language systems for generation understanding and dialogue focusing on the requirements and limitations these systems and user models place on each other. We then propose avenues for future research.;2001
The paper examines conversations in the 18th-century London and Paris financial marketplaces. The aim is to highlight the place of conversations as the key form of interaction. in the marketplace and to evaluate financial conversations against the broader cultural background of literary and scientific dialogues of the time. The relevance of this enterprise is that it leads to a better understanding of how the verbal interactions of the marketplace shape transaction outcomes and contribute to forms of rationality specific for financial markets. Grounded in the analysis of empirical material the paper distinguishes between conversations-qua-transactions and conversations-about-the-world. It shows how they produce and require specific forms of knowledge from the participants at the same time they shape the transactions outcomes. On this basis the paper argues that the phenomenon of sudden mood swings in the marketplace cannot be entirely explained in irrational psychological terms but must be seen as the outcome of a particular conversational system.;2001
This paper addresses the problem of automatic numeric recognition and understanding in spoken language dialogue. We show that accurate numeric understanding in fluent unconstrained speech demands maintaining robustness at several different levels of system design including acoustic language understanding and dialogue. We describe a robust system for numeric recognition and present algorithms for feature extraction acoustic and language modeling discriminative training utterance verification and numeric understanding and validation. Experimental results from a field-trial of a spoken dialogue system are presented that include customers' responses to credit card and telephone number requests. (C) 2001 Elsevier Science B.V. All rights reserved.;2001
This paper describes the museuVirtual project that is developing an authoring tool for the collaborative building of nonimmersive museums in virtual reality. The rationale behind museuVirtual is based on the observation that virtual museums found on the Internet normally have very limited opportunities for user interactivity. We examine different kinds of interactivity and propose an authoring tool that allows a teacher or student to create virtual exhibits in which dynamic interactive objects and chatterbots may be programmed in a relatively easy way. This proposal is strongly based on the concepts of actor-based programming and constructivist theory which have been applied in the last five years to teach basic programming skills to beginners. The ideas applied with success in many previous experiments using 2-D graphics are now being introduced in an authoring tool that generates VRML/Java code. The museuVirtual project is developing a tool that not only allows the students to be the organizers and curators of their own museums but also to work collaboratively by building such museums in a virtual distributed environment.;2001
This paper promotes socially intelligent animated agents for the pedagogical task of English conversation training for native speakers of Japanese. Since student-agent conversations are realized as role-playing interactions strong requirements are imposed on the agents' affective and social abilities. As a novel feature social role awareness is introduced to animated conversational agents that are by now strong affective reasoners but otherwise often lack the social competence observed in humans. In particular humans may easily adjust their behavior depending on their respective role in a social setting whereas their synthetic pendants tend to be driven mostly by emotions and personality. Our main contribution is the incorporation of a social filter program to mental models of animated agents. This program may qualify an agent's expression of its emotional state by the social context thereby enhancing the agent's believability as a conversational partner. Our implemented system is web-based and demonstrates socially aware animated agents in a virtual coffee shop environment. An experiment with our conversation system shows that users consider socially aware agents as more natural than agents that violate conventional practices.;2001
This paper questions the validity of traditional scientific method for the study of human learning and proposes five postulates for the advancement of a conversational science. It considers how an evolving capacity for lifelong learning has been constrained by inappropriate research methods and educational practice leading to a learning deficit in the population. Over 25 years of action research offers solid evidence for the humanisation of science as a conversational research process which respects the individual as a unique meaning constructing self-organising learning (SOL) entity. A learning conversation pedagogy which enables learners to act as personal scientists and action researchers and a SOL Systems Seven for a community of action researchers is outlined. Finally the paper considers how SOL entities can function as catalysts for new form of ORDER with a potential for the emergence of a new species of learning and of being human.;2001
We present a natural language realization component called YAG that is suitable for intelligent tutoring systems that use dialog. Dialog imposes unique requirements on a generation component namely: dialog systems must interact in real-time they must be capable of producing fragmentary output and they may be re-deployed in a number of different domains. Our approach to real-time natural language realization combines a declarative template-based approach for the representation of text structure with knowledge-based methods for representing semantic content. Possible text structures are defined in a declarative language that is easy to understand maintain and re-use. A dialog system can use YAG to realize text structures by specifying a template and content from its knowledge base. Content can be specified in one of two ways: (1) as a sequence of propositions along with some control features or (2) as a set of feature-value pairs. YAG's template realization algorithm realizes text without any search (in contrast to systems that must find rules that unify with a feature structure).;2001
With the introduction of software agents and assistants the concept of so-called social user interfaces evolved incorporating natural language interaction context awareness and anthropomorphic representations Of visuals scales and degrees of freedom for interactions. Today's challenge is to build a suitable visualization architecture for anthropomorphic conversational user interfaces. and to design for the believable and appropriate inclusion of human attributes (such as emotions) in a face-to-face interaction. Integrated approaches to these tasks are presented here. (C) 2001 Elsevier Science Ltd. All rights reserved.;2001
A contribution to the understanding module of a domain-specific dialogue system is presented in this work. The task consists of answering telephone queries about train timetables prices and services for long distance trains in Spanish. In this system the representation of the meaning of the user utterances is made by means of frames which determine the type of communication of the user turn and by their associated cases which supply the data of the utterance. We focus on the classification of a user turn given in natural language in a specific class of frame. We used multilayer perceptrons to classify a user turn as belonging to a frame class. This classification can help in the posterior processes of understanding and dialogue management.;2002
A lot of external natural language resources are used in spoken dialogue systems. These resources present considerable problems because of the needed space and slow lookup-time. It is therefore very important that the presentation of external language resources is time and space efficient. It is also very important that new language resources are easily incorporated into the system without modifying the common algorithms developed for multiple languages. This paper presents the method and results of compiling the large Slovenian phonetic and morphology lexicons (Slflex and Slmlex) into corresponding finite-state transducers (FSTs). Representation of large lexicons using finite-state transducers is mainly motivated by considerations of space and time efficiency. In addition the approach of hardware implementation for both large (Slovenian) lexicons is described. We will demonstrate that the structure of the FST is very appropriate for storing in the Atmel AT49BV161 flash memory chip and the lookup algorithm for obtaining any desired information from the FST structure can be efficiently implemented using the Atmel AT90S8515 microcontroller. The described hardware implementation of both Slovenian lexicons can be connected directly to the PC using RS232 above all for development and test purposes and can be used especially in embedded systems which use speech technology.;2002
An early release software product for the rapid development of spoken dialog systems (SDS's) known as Lyrebird(TM) [1][2][3] will be demonstrated that makes use of grammatical inference to build natural language mixed initiative speech recognition applications. The demonstration will consist of the presenter developing a spoken dialog system using Lyrebird(TM) and will include a demonstration of some features that are still in the prototype phase.;2002
Creating conversational interfaces for children is challenging in several respects. These include acoustic modeling for automatic speech recognition (ASR) language and dialog modeling and multimodal-multimedia user interface design. First issues in ASR of children speech are introduced by an analysis of developmental changes in the spectral and temporal characteristics of the speech signal using data obtained from 456 children ages five to 18 years. Acoustic modeling adaptation and vocal tract normalization algorithms that yielded state-of-the-art ASR performance on children speech are described. Second an experiment designed to better understand how children interact with machines using spoken language is described. Realistic conversational multimedia interaction data were obtained from 160 children who played a voice-activated computer game in a Wizard of Oz (WoZ) scenario. Results of using these data in developing novel language and dialog models as well as in a unified maximum likelihood framework for acoustic decoding in ASR and semantic classification for spoken language understanding are described. Leveraging the lessons learned from the WoZ study and a concurrent user experience evaluation a multimedia personal agent prototype for children was designed. Details of the architecture and application details are described. Informal evaluation by children was found positive especially for the animated agent and the speech interface.;2002
Designing the dialogue policy of a spoken dialogue system involves many nontrivial choices. This paper presents a reinforcement learning approach for automatically optimizing a dialogue policy which address the technical challenges in applying reinforcement learning to a working dialogue system with human users. We report on the design construction and empirical evaluation of NJFun and experimental spoken dialogue system that provides users with access to information about fun things to do in New Jersey. Our result show that by optimizing its performance via reinforcement learning NJFun measurable improves system performance.;2002
Grammar-based parsing is a prevalent method for natural language understanding (NLU) and has been introduced into dialogue systems for spoken language processing (SLP). A robust parsing scheme is proposed in this paper to overcome the notorious phenomena such as garbage ellipsis word disordering fragment and ill-form which frequently occur in spoken utterances. Keyword categories are used as terminal symbols and the definition of grammar is extended by introducing three new rule types by-passing up-messing and overcrossing in addition to the general rules called up-tying in this paper and the use of semantic items simplifies the semantics extraction. The corresponding parser marionette which is essentially a partial chart parser is enhanced to parse the semantic grammar. The robust parsing scheme integrating the above methods has been adopted in an air traveling information service system called EasyFlight and has achieved a high performance when used for parsing spontaneous speeches.;2002
In a spoken dialog system it is an important problem for the computer to identify the speech act (SA) from a user's utterance due to the variability of spoken language. In this paper a corpus-based fuzzy fragment-class Markov model (FFCMM) is proposed to model the syntactic characteristics of a speech act and used to choose the speech act candidates. A speech act verification process that estimates the conditional probability of a speech act given a sequence of fragments is used to verify the speech act candidate. Most main design procedures are statistical- and corpus-based to reduce manual work. In order to evaluate the proposed method a spoken dialog system for air travel information service (ATIS) is investigated. The experiments were carried out using a test database from 25 speakers (15 male and 10 female). There are 480 dialogs containing 3038 sentences in the test database. The experimental results show that the speech act identification rate can be improved by 10.5% using the FFCMM and speech act verification with a rejection rate of 6% compared to a baseline system. (C) 2002 Elsevier Science B.V. All rights reserved.;2002
In human-human communication dialogue participants are continuously sending and receiving signals on the status of the information being exchanged. These signals may either be positive ('go on') or negative ('go back') where it is usually found that the latter are comparatively marked to make sure that the dialogue partner is made aware of a communication problem. This article focuses on the users' signaling of information status in human-machine interactions and in particular looks at the role prosody may play in this respect. Using a corpus of interactions with two Dutch spoken dialogue systems prosodic correlates of users' disconfirmations were investigated. In this corpus disconfirmations can have two uses: they may serve as a positive signal in one context and as a negative signal in another. With the data obtained from the corpus an acoustic analysis and a perception experiment have been carried out. The acoustic analysis shows that the difference in signaling function is reflected in the distribution of the various types of disconfirmations as well as in different prosodic variables (pause duration intonation contour and pitch range). The perception experiment revealed that subjects are very good at classifying disconfirmations as positive or negative signals (without context) which strongly suggests that the acoustic features have communicative relevance. The implications of these results for human-machine communication are discussed. (C) 2002 Elsevier Science B.V. All rights reserved.;2002
In the buying and selling interaction in e-commerce one of the important dialogues is the discourse of resolving the ambiguities. That is to say that both selling and buying agents may have to conduct disambiguating dialogues to some extent in order to resolve the ambiguities and infer the true intents of the other agents. In the paper we assume buyers are human agents while sellers are software agents and thus the seller agents will construct dialogues to resolve the ambiguities from the buyer agents. To resolve ambiguities agents rely on four levels of domain knowledge: the world model the mental model the language model and the rational model. In addition four kinds of disambiguation strategies for the seller agent are implemented: (1) Guessing (2) Filtering (3) Recommending and (4) Asking more hints. Experiments are conducted also to measure the performance of the dialogue system against different parameter settings of the disambiguation strategies. We find that by optimal parameter setting and suitable strategy combination the seller will result in a shorter dialogue without sacrificing much the optimal profit.;2002
In the past few years as the number of dialogue systems has increased there has been an increasing interest in the use of natural language generation in spoken dialogue. Our research assumes that trainable natural language generation is needed to support more. flexible and customized dialogues with human users. This paper focuses on methods for automatically training the sentence planning module of a spoken language generator. Sentence planning is a set of inter-related but distinct tasks one of which is sentence scoping i.e. the choice of syntactic structure for elementary speech acts and the decision of how to combine them into one or more sentences. The paper first presents SPOT a trainable sentence planner and a new methodology for automatically training SPOT on the basis of feedback provided by human judges. Our methodology is unique in neither depending on hand-crafted rules nor on the existence of a domain-specific corpus. SPOT first randomly generates a candidate set of sentence plans and then selects one. We show that SPOT learns to select a sentence plan whose rating on average is only 5% worse than the top human-ranked sentence plan. We then experimentally evaluate SPOT by asking human judges to compare SPoT's output with a hand-crafted template-based generation component two rule-based sentence planners and two baseline sentence planners. We show that SPOT performs better than the rule-based systems and the baselines and as well as the hand-crafted system. (C) 2002 Published by Elsevier Science Ltd.;2002
In this paper we describe a generation system for spoken dialogue that not only produces coherent informative and responsive dialogue contributions but also explicitly models human styles of interaction. This generation system is based on conversation acts theory. It has been implemented in the TRIPS spoken dialogue system and includes components that plan content perform surface generation for different modalities and coordinate output production. We discuss our implementation and describe an evaluation of the generation output. (C) 2002 Elsevier Science Ltd. All rights reseved.;2002
In this paper we describe how language generation and speech synthesis for spoken dialog systems can be efficiently integrated under a weighted finite state transducer architecture. Taking advantage of this efficiency we show that introducing flexible targets in generation leads to more natural sounding synthesis. Specifically eve allow multiple wordings of the response and multiple prosodic realizations of the different wordings. The choice of wording and prosodic structure are then jointly optimized with unit selection for waveform generation in speech synthesis. Results of perceptual experiments show that by integrating the steps of language generation and speech synthesis we are able to achieve improved naturalness of synthetic speech compared to the sequential implementation. (C) 2002 Elsevier Science Ltd. All rights reserved.;2002
In this paper we show how prosodic information can be used in automatic dialogue systems and give some examples of promising new approaches. Most of these examples are taken from our own work in the VERBMOBIL speech-to-speech translation system and in the EVAR train timetable dialogue system. In a 'prosodic orbit' we first present units phenomena annotations and statistical methods from the signal (acoustics) to the dialogue understanding phase. We show then how prosody can be used together with other knowledge sources for the task of resegmentation if a first segmentation turns out to be wrong and how an integrated approach leads to better results than a sequential use of the different knowledge sources then we present a hybrid approach which is used to perform a shallow parsing and which uses prosody to guide the parsing finally we show how a critical system evaluation can help to improve the overall performance of automatic dialogue systems. (C) 2002 Elsevier Science B.V. All rights reserved.;2002
Interest in the contribution prosodic information makes to human communication has led to increasing expectations that such information could be of use in text-to-speech and speech understanding systems and in application of these technologies to spoken dialogue systems. To date research results far exceed their technology applications. This paper suggests some areas in which progress has been made and some in which more might be made with particular emphasis upon text-to-speech synthesis and spoken dialogue systems. (C) 2002 Elsevier Science B.V. All rights reserved.;2002
It has always been difficult for language understanding systems to handle spontaneous speech with satisfactory robustness primarily due to such problems as the fragments disfluencies out-of-vocabulary words and ill-formed sentence structures. Also the search schemes used are usually not flexible enough in accepting different input linguistic units and great efforts are therefore required when they are used with different acoustic front ends in different tasks specially in mufti-modal and mufti-lingual systems. In this paper a new hierarchical tag-graph-based search scheme for spontaneous speech understanding is proposed. This scheme is based on a layered hierarchy of grammar rules and therefore can integrate all the statistical and rule-based knowledge including acoustic scores language model scores and grammar rules into the search process. More robust speech understanding is thus achievable. In addition this scheme can accept graphs of different linguistic units such as phonemes syllables characters words spotted keywords or phrases as the input thus compatible to different acoustic front ends and mufti-modal and mufti-lingual applications can be easily developed. This search scheme has been successfully applied to a mufti-domain mufti-modal dialogue system. (C) 2002 Elsevier Science B.V. All rights reserved.;2002
Most commercial dialogue applications are very task-oriented and take little account of indirect user desires or emotional behaviour. As a result interaction is often inefficient and can lead to. user dissatisfaction. The SemanticEdge system described here allows for more responsive dialogue applications where different users with disparate needs are dynamically classified and their emotions are identified in the course of the dialogue. This reasoning about the specific user (their goals desires and behaviour) coupled with reasoning about the main interaction task of the dialogue allows for more appropriate system responses e.g. in the case of misunderstandings and user anger or in targeted marketing activities.;2002
Navigation is the process by which people control their movement in virtual environments and is a core functional requirement for all virtual environment (VE) applications. Users require the ability to move controlling orientation direction of movement and speed in order to achieve a particular goal within a VE. Navigation is rarely the end point in itself (which is typically interaction with the visual representations of data) but applications often place a high demand on navigation skills which in turn means that a high level of support for navigation is required from the application. On desktop systems navigation in non-immersive systems is usually supported through the usual hardware devices of mouse and keyboard. Previous work by the authors shows that many users experience frustration when trying to perform even simple navigation tasks - users complain about getting lost becoming disorientated and finding the interface 'difficult to use'. In this paper we report on work in progress in exploiting natural language processing (NLP) technology to support navigation in non-immersive virtual environments. A multi-modal system has been developed which supports a range of high-level (spoken) navigation commands and indications are that spoken dialogue interaction is an effective alternative to mouse and keyboard interaction for many tasks. We conclude that multi-modal interaction combining technologies such as NLP with mouse and keyboard may offer the most effective interaction with VEs and identify a number of areas where further work is necessary.;2002
Our goal is to develop a believable embodied agent able to dialogue with a user. In particular we aim at making an agent that can also combine facial expressions in a complex and subtle way just like a human agent does. We first review a taxonomy of communicative functions that our agent is able to express non-verbally but we point out that due to the complexity of communication in some cases different information can be provided at once by different parts and actions of an agent's face. In this paper we are interested in assessing and treating what happens at the meaning and signal levels of behaviour when different communicative functions have to be displayed at the same time and necessarily have to make use of the same expressive resources. In some of these cases the complexity of the agent's communication can give rise to conflicts between the parts or movements of the face. In this paper we propose a way to manage the possible conflicts between different modalities of communication through the tool of belief networks and we show how this tool allows us to combine facial expressions of different communicative functions and to display complex and subtle expressions. Copyright (C) 2002 John Wiley Sons Ltd.;2002
Previous studies have shown that self-explanation is an effective metacognitive strategy and can be supported effectively by intelligent tutoring systems. It is plausible however that students may learn even more effectively when stating explanations in their own words and when receiving tutoring focused on their explanations. We are developing the Geometry Explanation Tutor in order to test this hypothesis. This system helps students through a restricted form of dialogue to construct general explanations of problem-solving steps in their own words. We conducted a pilot study in which the tutor was used for two class periods in a junior high school. The data from this study suggest that the techniques that we chose to implement the dialogue system namely a knowledge-based approach to natural language understanding and classification of student explanations are up to the task. There are a number of ways in which the system could be improved within the current architecture.;2002
Spoken dialogue system performance can vary widely for different users as well for the same user during different dialogues. This paper presents the design and evaluation of an adaptive version of TOOT a spoken dialogue system for retrieving online train schedules. Based on rules learned from a set of training dialogues adaptive TOOT constructs a user model representing whether the user is having speech recognition problems as a particular dialogue progresses. Adaptive TOOT then automatically adapts its dialogue strategies based on this dynamically changing user model. An empirical evaluation of the system demonstrates the utility of the approach.;2002
Spoken dialogue system promise efficient and natural access to a large variety of information sources and services from any phone. However current spoken dialogue systems are deficient in their strategies for preventing identifying and repairing problems that arise in the conversation. This paper reports results on automatically training a Problematic Dialogue Predictor to predict problematic human-computer dialogues using a corpus of 4692 dialogues collected with the How May I Help You(SM) spoken dialogue system. The Problematic Dialogue Predictor can be immediately applied to the system's decision of whether to transfer the call to a human customer care agent or be used as a cue to the system's dialogue manager to modify its behavior to repair problems and even perhaps to prevent them. We show that a Problematic Dialogue Predictor using automatically-obtainable features from the first two exchanges in the dialogue can predict problematic dialogues 13.2% more accurately than the baseline.;2002
Spoken dialogue systems allow users to interact with computer-based applications such as databases and expert systems by using natural spoken language. The origins of spoken dialogue systems can be traced back to Artificial Intelligence research in the 1950s concerned with developing conversational interfaces. However it is only within the last decade or so with major advances in speech technology that large-scale working systems have been developed and in some cases introduced into commercial environments. As a result many major telecommunications and software companies have become aware of the potential for spoken dialogue technology to provide solutions in newly developing areas such as computer-telephony integration. Voice portals which provide a speech-based interface between a telephone user and Web-based services are the most recent application of spoken dialogue technology. This article describes the main components of the technology-speech recognition language understanding dialogue management communication with an external source such as a database language generation speech synthesis-and shows how these component technologies can be integrated into a spoken dialogue system. The article describes in detail the methods that have been adopted in some well-known dialogue systems explores different system architectures considers issues of specification design and evaluation reviews some currently available dialogue development toolkits and outlines prospects for future development.;2002
Spoken dialogue systems need to track dialogue structure in order to conduct sensible conversations. In previous work we used only a shallow analysis of past dialogue in predicting the current dialogue act. Here we show that a hierarchical analysis of dialogue structure can significantly improve dialogue act recognition. Our approach is to integrate dialogue act recognition with speech recognition seeking a best overall hypothesis for what words have been spoken and what dialogue act they represent in the light of both the dialogue history so far and the current speech signal. A useful feature of this approach is that intonation can be used to aid dialogue act recognition by combining it with other information sources in a natural way. (C) 2002 Published by Elsevier Science B.V.;2002
The advent of mobile devices and the wireless Internet is having a profound impact on the way people communicate as well as on the user interaction paradigms used to access information that was traditionally accessible only through visual interfaces. Applications for mobile devices entail the integration of various data sources optimized for delivery to limited hardware resources and intermittently connected devices through wireless networks. Although telephone interfaces arise as one of the most prominent pervasive applications they present interaction challenges such as the augmentation of speech recognition through natural language (NL) understanding and high-quality text-to-speech conversion This article presents an experience in building an automated assistant that is natural to use and could become an alternative to a human assistant. The Mobile Assistant (MA) can read e-mail messages book appointments take phone messages and provide access to personal-organizer information. Key components are a conversational interface enterprise integration and notifications tailored to user preferences. The focus of the research has been on supporting the pressing communication needs of mobile workers and overcoming technological hurdles such as achieving high accuracy speech recognition in noisy environments NL understanding and optimal message presentation on a variety of devices and modalities. The article outlines findings from the 2 broad field trials and lessons learned regarding the support of mobile workers with pervasive computing devices and emerging technologies.;2002
The article describes aspects of the development of a conversational natural language understanding (NLU) system done during the first year of the European research project CATCH-2004 (Converse in AThens Cologne and Helsinki) [http://www.catch2004.org]. The project is co-funded by the European Union in the scope of the IST programme (IST 1999-11103). Its objectives focus on multi-modal multi-lingual conversational natural language access to information systems. The paper emphasises on architecture and telephony-based speech and NLU components as well as aspects of the implementation of a city event information (CEI) system in English Finnish German and Greek. The CEI system accesses two different databases in Athens and Helsinki using a common retrieval interface. Furthermore the paper singles out methodologies involved for acoustic and language model of the speech recognition component parsing techniques and dialog modelling for the conversational natural language subsystem. For the implementation it outlines an incremental system refinement methodology necessary to adapt the system components to real-life data. It addresses the implementation of language specific characteristics and a common dialog design for all four languages but also deals with aspects towards a multilingual conversational system. Finally it presents prospects for further developments of the project. (C) 2002 Elsevier Science B.V. All rights reserved.;2002
The article presents a computer dialogue system for calculating intervals elementary arithmetic operations. In particular it has a set of functions for checking practical regularity and practical stability of a square interval matrix. This software is a part of an active learning approach.;2002
The Human Use Regulatory Affairs Advisor (HURAA) is a web-based help facility that provides training on the ethical use of human subjects in research and that serves as an information retrieval system on ethical policies. The content for HURAA is derived from United States Federal agency documents and regulations. HURAA has a number of components that go beyond conventional page-turning or hypertext systems including (1) an animated conversational agent that serves as a navigational guide for the web facility (2) an enhanced multimedia introduction (3) lessons with case-based and explanation-based reasoning and (4) document retrieval through natural language queries or a Point & Query facility. The effectiveness of HURAA was tested on a small sample of participants (N = 18) who were assigned to either the full HURAA version or a conventional computer-based training version.;2002
This paper addresses the impact of telephone transmission channels on automatic speech recognition (ASR) performance. A real-time simulation model is described and implemented which allows impairments that are encountered in traditional as well as modern (mobile IP-based) networks to be flexibly and efficiently generated. The model is based on input parameters which are known to telephone network planners thus it can be applied without measuring specific network characteristics. It can be used for an analytic assessment of the impact of channel impairments on ASR performance for producing training material with defined transmission characteristics or for testing spoken dialogue systems in realistic network environments. In the present paper we present an investigation of the first point. Two speech recognizers which are integrated into a spoken dialogue system for information retrieval are assessed in relation to controlled amounts of transmission degradations. The measured ASR performance degradation is compared to speech quality degradation in human-human communication. It turns out that ASR shows a different behavior than expected human quality judgments for some impairments. This fact has to be taken into account in both telephone network planning as well as in speech and language technology development. (C) 2002 Elsevier Science B.V. All rights reserved.;2002
This paper describes activities at CTT Centre for Speech Technology using the potential of animated talking agents to improve information flow in dialogue systems. Our motivation for moving into audiovisual output is to investigate-the advantages of multimodality in human-system communication. While the mainstream character animation area has focused on the naturalness and realism of the animated agents our primary concern has been the possible increase of intelligibility and efficiency of interaction resulting from the addition of a talking face.;2002
This paper describes an approach to processing meaning instead of processing information in computing. Human intellectual activity is supported by linguistic activities in the brain. Therefore processing the meaning of language instead of processing information should be able to lead us to realize human intelligence on a computer. As an example of proposed framework for processing meaning we build a travel consultation dialogue system which can understand utterance by a user and retrieve information through dialogue. Through a simulation example of the system we show that both information processing and language processing are integrated into one processing. (C) 2002 Elsevier Science Inc. All rights reserved.;2002
This paper describes some examples of human-voice interface technology recently developed by NEC. The first is a network speech interface that enables the Internet to be easily accessed via mobile car or home terminals. This speech interface is composed of a client-type speech interface and a servertype speech interface. The second is a speaker-independent large-vocabulary speech-recognition system and a speech-synthesis system which are necessary to realize such a network speech interface. The third example is an emotional-spoken-dialogue system aimed at making the human-machine dialogue more pleasant to use.;2002
This paper describes the response planning and generation components of the MERCURY flight reservation system a mixed-initiative spoken dialogue system that supports both voice-only interaction and multimodal interaction augmenting spoken inputs with typing or clicking at a displayed Web page. MERCURY is configured using the Galaxy Communicator architecture (Seneff Hurley Lau Schmid & Zue 1998) where a suite of servers interact via program control mediated by a central hub. Language generation is performed in two steps: response. planning or deep-structure generation is carried out by the dialogue manager and is well-integrated with other aspects of dialogue control control flow is specified by a dialogue control table (Seneff & Polifroni 2000a). Response generation or surface-form generation is executed by a separate language generation server under the guidance of a set of recursive generation rules and an associated lexicon (Baptist & Seneff 2000). The generation of the textual string for the graphical interface and the marked-up synthesis string for spoken outputs are controlled by a shared set of generation rules (Seneff & Polifroni 2000b). Thus there is a direct meaning-to-speech mapping that eliminates the need to analyze linguistic structure for synthesis. To date we have collected over 25000 utterances from users interacting with the MERCURY system. We report here on both the results of user satisfaction studies conducted by the National Institute of Standards and Technology (NIST) and on our own tabulation of a number of different measures of dialogue success. (C) 2002 Elsevier Science Ltd. All rights reserved.;2002
This paper discusses the use of 'conversational' or 'dialogue games' as a basis for building dialogue systems. We give a tutorial overview of some recent attempts to relate the notion of a dialogue act to changes of information state of the participants in a dialogue. These attempts all distinguish some notion of 'grounded' or 'common' propositions. We raise the question as to whether these attempts might make the notion of dialogue game redundant reducing it to an epiphenomenon arising out of the manipulation of information states. The answer to the question is no not quite yet. We also look briefly at a suggestion for augmenting the notion of information state so as to be able to deal with some types of prosodically marked focus. (C) 2002 Elsevier Science B.V. All rights reserved.;2002
This paper explores packet loss recovery for automatic speech recognition (ASR) in spoken dialog systems assuming an architecture in which a lightweight client communicates with a remote ASR server. Speech is transmitted with source and channel codes optimized for the ASR application i.e. to minimize word error rate. Unequal amounts of forward error correction depending on the data's effect on ASR performance are assigned to protect against packet loss. Experiments with simulated packet loss in a range of loss conditions are conducted on the DARPA Communicator (air travel information) task. Results show that the approach provides robust ASR performance which degrades gracefully as packet loss rates increase. Transmitting at 5.2 Kbp s with tip to 200 ms added delay leads to only a 7% relative degradation in word error rate even under extremely adverse network conditions.;2002
This paper presents a method for inferring reversible attribute grammars from tagged natural language sentences. Attribute grammars are a form of augmented context free grammar that assign meaning in the form of a data structure to a string in a context free language. The method presented in this paper has the ability to infer attribute grammars that can generate a wide range of useful data structures such as simple and structured types lists concatenated strings and natural numbers. The method also presents two new forms of grammar generalisation generalisation based upon identification of optional phrases and generalisation based upon lists. The method has been applied to and tested on the task of the rapid development of spoken dialog systems.;2002
This paper presents a novel technique that allows testing spoken dialogue systems by means of an automatic generation of conversations. The technique permits to easily test spoken dialogue systems under a variety of lab-simulated conditions as it is easy to vary or change the utterance corpus used to check the performance of the system. The technique is based on the use of a module called user simulator whose purpose is to behave as real users when they interact with dialogue systems. The behaviour of the simulator is decided by means of diverse scenarios that represent the goals of the users. The simulator aim is to achieve the goals set in the scenarios during the interaction with the dialogue system. We have applied the technique to test a dialogue system developed in our lab. The test has been carried out considering different levels of white and babble noise as well as a VTS noise compensation technique. The results prove that the dialogue system performance is worse under the babble noise conditions. The VTS technique has been effective when dealing with noisy utterances and has lead to better experimental results particularly for the white noise. The technique has permitted to detect problems in the dialogue strategies employed to handle confirmation turns and recognition errors suggesting that these strategies must be improved. (C) 2002 Elsevier Science B.V. All rights reserved.;2002
Walking locomotion has been proved as an adequate technique for autonomous motion on an uneven terrain. However natural scenarios can be extremely complex and human intervention is regularly required. In such a case a dialogue system known as human-machine interface (HMI) is essential for interrelation between human and machine. The objective of this paper is to present a human-machine interface developed for a four-legged robot. This HMI is based on a multi-modal interface which integrates some ideas about collaborative control. It was developed as an operator's interface for guiding a walking robot but it can also be used as a tool for analysing and debugging new gait algorithms. The interface includes some methods for defining robot trajectory and graphic representations for gaining information on both the robot and its environment. This work is tailored to the SILO4 walking robot therefore the SILO4 mechanism and control system are first introduced to lay out the possibilities of this new walking robot. Then the main concepts on which the HMI design is based are introduced prior to the description of the different modules and functionality of the human-machine interface. Finally some simulations and experiments with the SILO4 walking robot have been conducted to validate the performance of the HMI presented in this article.;2002
We are developing a human-computer spoken language system capable of processing English Cantonese and Putonghua (two dialects of Chinese). Such biliteracy and trilingualism characterize Hong Kong's language environment. Users can simply converse with the system to access real-time information in the foreign exchange domain. The system supports user calls with fixed-line as well as cellular phones both of which have high penetration in Hong Kong. As such we strive towards universal usability in developing speech and language interface technologies by (i) supporting multiple languages for user diversity (ii) requiring no specialized training for system usage to avoid user knowledge gaps and (iii) supporting device variety in telephone-based information access. (C) 2002 Elsevier Science B.V. All rights reserved.;2002
We describe a corpus-based approach to natural language generation (NLG). The approach has been implemented as a component of a spoken dialog system and a series of evaluations were carried out. Our system uses n-gram language models which have been found useful in other language technology applications in a generative mode. It is not yet clear whether the simple n-grams can adequately model human language generation in general but we show that we can successfully apply this ubiquitous modeling technique to the task of natural language generation for spoken dialog systems. In this paper we discuss applying corpus-based stochastic language generation at two levels: content selection and sentence planning/realization. At the content selection level output utterances are modeled by bigrams and the appropriate attributes are chosen using bigram statistics. In sentence planning and realization corpus utterances are modeled by n-grams of varying length and new utterances are generated stochastically. Through this work we show that a simple statistical model alone can generate appropriate language for a spoken dialog system. The results describe a promising avenue for using a statistical approach in future NLG systems. (C) 2002 Elsevier Science Ltd. All rights reserved.;2002
We investigated college students' perceptions of a diverse sample of animated conversational agents. We also examined the pedagogical efficacy of those agents. We found that people perceive differences among the agents on several dimensions such as likeability and that the agents differ in pedagogical efficacy. However none of the characteristics that we measured accounted for differences in pedagogical efficacy across the agents. We discuss implications for the field of agent studies with particular emphasis on the creation of pedagogically effective conversational agents and suggest directions for future research.;2002
We present an approach for the development of Language Understanding systems from a Transduction point of view. We describe the use of two types of automatically inferred transducers as the appropriate models for the understanding phase in dialog systems.;2002
We present an integrated discourse recipe-based model (DRM) for dialogue generation and interpretation. Discourse recipes are generalizations of discourse plans. The DRM has been implemented as part of a conversational agent that supports task-oriented dialogue between human and artificial pilots. The design of the DRM has been strongly influenced by its implementation in the Soar cognitive architecture. In the DRM discourse recipes are acquired as a side effect of dialogue planning. The discourse recipes can be used for generation and interpretation in future situations in place of planning and reasoning from first principles. We describe the motivation for a discourse recipe-based approach and present the design of the DRM.;2002
We propose ParleE a quantitative flexible and adaptive model of emotions for a conversational agent in a multi-agent environment capable of multimodal communication. ParleE appraises events based on learning and a probabilistic planning algorithm. ParleE also models personality and motivational states and their role in determining the way the agent experiences emotion.;2002
We study how decisions for word ordering and word choice in surface natural language generation can be automatically learned from annotated data. We examine four trainable systems for surface natural language generation in the air travel domain called NLG[1-4]. NLG1 is a lookup table which stores the most frequent phrase to express a concept and is intended as a baseline system for comparison purposes. NLG2 and NLG3 attempt to find the highest probability word sequence with respect to a maximum entropy probability model. They differ in that NLG2 predicts words left-to-right while NLG3 predicts words in dependency tree order. NLG4 requires a dependency-style grammar of phrase fragments and conditions on their use and attempts to find the highest probability word sequence that is consistent with the rules and conditions of the grammar. NLG4 has been implemented in a dialog strategy for a prototype air travel conversational system in which word order is dynamically modified to emphasize certain aspects of the run-time dialog state. (C) 2002 Published by Elsevier Science Ltd.;2002
With the emergence of electronic-commerce systems successful information access on electronic-commerce web sites becomes essential. Menu-driven navigation and keyword search currently provided by most commercial sites have considerable limitations because they tend to overwhelm and frustrate users with lengthy rigid and ineffective interactions. To provide an efficient Solution for information access we have built the NATURAL LANGUAGE ASSISTANT (NLA) a web-based natural language dialog system to help users find relevant products on electronic-commerce sites. The system brings together technologies in natural language processing and human-computer interaction to create a faster and more intuitive way of interacting with web sites. By combining statistical parsing techniques with traditional AI rule-based technology we have created a dialog system that accommodates both customer needs and business requirements. The system is currently embedded in an application for recommending laptops and was deployed as a pilot on IBM's web site.;2002
A framework dedicated to embodied agents facial animation based on speech analysis in presence of background noise is described. Target application areas are entertainment and mobile visual communication. This novel approach derives from the speech signal all the necessary information needed to drive 3-D facial models. Using both digital signal processing and soft computing (fuzzy logic and neural networks) methodologies a very flexible and low-cost solution for the extraction of lips and facial-related information has been implemented. The main advantage of the speech-based approach is that it is not invasive as speech is captured by means of a microphone and there is no physical contact with the subject (no use of magnetic sensors or optical markers). This gives additional flexibility to the application in that more applicability derives if compared to other methodologies. First a speech-based lip driver system was developed in order to synchronize speech to lip movements then the methodology was extended to some important facial movements so that a face-synching system could be modeled. The developed system is speaker and language independent so also neural network training operations are not required.;2003
A Natural Language Querying System is presented (NL-SIIUE). It enables the access to the Universidade de Evora Information System (SIIUE) heterogeneous databases. Dialog management is essential for the correct interpretation of the user's intentions and to answer accordingly. Following the ISCO language guidelines in which NL-SIIUE development is based on some basic principles of dialog management are described and discussed.;2003
A new direction in improving automatic dialogue systems is to make a human-machine dialogue more similar to a human-human dialogue. A modern system should be able to recognize the semantic content of spoken utterances but also to interpret some paralinguistic or non-verbal information - as indicators of the internal user state - in order to detect success or trouble in communication. A common problem in a human-machine dialogue where information about a users internal state of mind may give a clue is for instance the recurrent misunderstanding of the user by the system. This can be prevented if we detect the anger in the users voice. In contrast to anger a joyful face combined with a pleased voice may indicate a satisfied user who wants to go on with the current dialogue behavior while a hesitant searching gesture of the user reveals his unsureness. This paper explores the possibility of recognizing a user's internal state by using facial expression classification with eigenfaces and a prosodic classifier based on artificial neural networks combined with a discrete Hidden Markov Model (HMM) for gesture analysis in parallel. Our experiments show that all the three input modalities can be used to identify a users internal state. However a user state is not always indicated by all three modalities at the same time thus a fusion of the different modalities seems to be necessary. Different ways of modality fusion are discussed.;2003
A new direction in improving modern dialogue systems is to make a human-machine dialogue more similar to a human-human dialogue. This can be done by adding more input modalities e.g. facial expression recognition. A common problem in a human-machine dialogue where the angry face may give a clue is the recurrent misunderstanding of the user by the system. This paper describes recognizing facial expressions in frontal images using eigenspaces. For the classification of facial expressions rather than using the whole image we classify regions which do not differ between subjects and at the same time are meaningful for facial expressions. Using this face mask for training and classification of joy and anger expressions of the face we achieved an improvement of up to 11% absolute. The portability to other classification problems is shown by a gender classification.;2003
A new direction in improving modern dialogue systems is to make a human-machine dialogue more similar to a human-human dialogue. This can be done by adding more input modalities. One additional modality for automatic dialogue systems is the facial expression of the human user. A common problem in a human-machine dialogue where the angry face may give a clue is the recurrent misunderstanding of the user by the system. Or an helpless face may indicate a naive user who does not know how to utilize the system and should be led through the dialogue step by step. This paper describes recognizing facial expressions in frontal images using eigenspaces. For the classification of facial expressions rather than using the face whole image we classify regions which do not differ between subjects and at the same time are meaningful for facial expressions. Important regions change when projecting the same face to eigenspaces trained with examples of different facial expressions. The average of different faces showing different facial expressions forms a face mask. This face mask fades out unnecessary or mistakable regions and emphasizes regions changing between facial expressions. Using this face mask for training and classification of neutral and angry expressions of the face we achieved an improvement of up to 5% points. The proposed method may improve other classification problems that use eigenspace methods as well.;2003
Automatic dialogue systems used for instance in call centers should be able to determine in a critical phase of the dialogue-indicated by the customers vocal expression of anger/irritation-when it is better to pass over to a human operator. At a first glance this does not seem to be a complicated task: It is reported in the literature that emotions can be told apart quite reliably on the basis of prosodic features. However these results are achieved most of the time in a laboratory setting with experienced speakers (actors) and with elicited controlled speech. We compare classification results obtained with the same feature set for elicited speech and for a Wizard-of-Oz scenario where users believe that they are really communicating with an automatic dialogue system. It turns out that the closer we get to a realistic scenario the less reliable is prosody as an indicator of the speakers' emotional state. As a consequence we propose to change the target such that we cease looking for traces of particular emotions in the users' speech but instead look for indicators of TROUBLE IN COMMUNICATION. For this reason we propose the module Monitoring of User State [especially of] Emotion (MOUSE) in which a prosodic classifier is combined with other knowledge sources such as conversationally peculiar linguistic behavior for example the use of repetitions. For this module preliminary experimental results are reported showing a more adequate modelling Of TROUBLE IN COMMUNICATION. (C) 2002 Elsevier Science B.V. All rights reserved.;2003
Building a collaborative trusting relationship with users is crucial in a wide range of applications such as advice-giving or financial transactions and some minimal degree of cooperativeness is required in all applications to even initiate and maintain an interaction with a user. Despite the importance of this aspect of human-human relationships few intelligent systems have tried to build user models of trust credibility or other similar interpersonal variables or to influence these variables during interaction with users. Humans use a variety of kinds of social language including small talk to establish collaborative trusting interpersonal relationships. We argue that such strategies can also be used by intelligent agents and that embodied conversational agents are ideally suited for this task given the myriad multimodal cues available to them for managing conversation. In this article we describe a model of the relationship between social language and interpersonal relationships a new kind of discourse planner that is capable of generating social language to achieve interpersonal goals and an actual implementation in an embodied conversational agent. We discuss an evaluation of our system in which the use of social language was demonstrated to have a significant effect on users' perceptions of the agent's knowledgableness and ability to engage users and on their trust credibility and how well they felt the system knew them for users manifesting particular personality traits.;2003
Classification problems axe traditionally focused on uniclass samples that is each sample of the training and test sets has one unique label which is the target of the classification. In many real life applications however this is only a rough simplification and one must consider some techniques for the more general multiclass classification problem where each sample can have more than one label as it happens in our task. In the understanding module of a domain-specific dialogue system for answering telephone queries about train information in Spanish which we are developing a user turn can belong to more than one type of frame. In this paper we discuss general approaches to the multiclass classification problem and show how these techniques can be applied by using connectionist classifiers. Experimentation with the data of the dialogue system shows the inherent difficulty of the problem and the effectiveness of the different methods axe compared.;2003
Computers are becoming more and more ubiquitous moving from the desktop into our everyday life. Today's challenge is to build a suitable visualization architecture for anthropomorphic conversational user interfaces which will run on different devices like laptops PDAs and mobile phones. This new kind of interface will be adaptive to the current user personal preferences the history of the conversation the device and the current context. Concrete implementations as a part of conversational interfaces are User-Interface Avatars anthropomorphic representatives on the base of artificial 2D or 3D characters. The user can talk to an avatar on every device he is using. The avatar system is designed to exchange different graphical representations of the avatar easily. The existing system and ongoing work on optimization and renderers implementation are discussed.;2003
Computers are moving more and more from the desktop into our everyday life. Today's challenge is to build a suitable visualization architecture for anthropomorphic conversational user interfaces which will run on different devices like laptops PDAs and smart phones. Concrete implementations as part of conversational interfaces are User-Interface Avatars which are anthropomorphic representatives on the base of artificial 3D characters. The existing system methods the graphical output chain and different optimization strategies are discussed.;2003
Controlled and restricted dialogue systems are reliable enough to be deployed in various real world applications. The more conversational a dialogue system becomes the more difficult and unreliable become recognition and processing. Numerous research projects are struggling to overcome the problems arising with more- or truly conversational dialogue system. We introduce a set of contextual coherence measurements that can improve the reliability of spoken dialogue systems by including contextual knowledge at various stages in the natural language processing pipeline. We show that situational knowledge can be successfully employed to resolve pragmatic ambiguities and that it can be coupled with ontological knowledge to resolve semantic ambiguities and to choose among competing automatic speech recognition hypotheses.;2003
Conversational agent is a system that provides user with proper information and maintains the context of dialogue based on natural language. When experts design the network for conversational agent of a domain the network is usually very complicated and is hard to be understood. So the simplification of network by separating variables in the domain is helpful to design the conversational agent more efficiently. Composing Bayesian network as two stages we aim to design conversational agent easily and analyze user's query in detail. Also by using previous information of dialogue it is possible to maintain the context of conversation. Actually implementing it for a guide of web pages we can confirm the usefulness of the proposed architecture for conversational agent.;2003
Dialog systems that adapt to different user needs and preferences appropriately have been shown to achieve higher levels of user satisfaction [1]. However it is also important that dialog systems be able to adapt to the user's computing environment because people can access computer systems using different devices. Existing research has focused on either user-centered adaptations or device-centered adaptations. To my knowledge no work has been done on integrating and coordinating both types of adaptation interdependently. In this thesis I aim to investigate how multimodal. dialog systems can adapt their content and style of interaction to individual users and their current device. The primary contribution of this thesis will be a framework that extends and combines both types of multimodal content adaptations that should occur in dialog systems.;2003
Digital Immortality applications require a type of believability that differs from that of interactive conversational agents and other types of virtual humans. We are exploring the creation of digitally immortal virtual humans whose primary visual interface is based only on original media assets of the persons being digitally immortalized. We describe a software framework that supports scripted video creation techniques in which persons proactively assist in the process of preparing for digital immortalization as an interactive known virtual human.;2003
Emotions and personality have received quite a lot of attention the last few years in research on embodied conversational agents. Attention is also increasingly being paid to matters of social psychology and interpersonal aspects (see [3] for example and [11] for work of our group). Given the nature of an embodied conversational agent's main activity: conversation we feel that interpersonal issues should be central in their design. We consider the case of tutoring systems in more depth and examine some of the interpersonal factors that need to be accounted for when building emotionally intelligent tutors.;2003
For conversational agents engaging in a natural language-based interaction with web site users in service exchange applications simple entertaining chatting is not sufficient. Instead the agent needs to be cooperative by trying to provide relevant information about products and/or the conditions of purchasing. In this paper we analyze how the proactive behaviour of conversational agents can be used to increase the general user satisfaction. The results of two case studies allow us to outline a generic proactivity model for information agents based on retrieval mechanisms and search heuristics.;2003
GESTYLE is a new markup language to annotate text which has to be spoken by Embodied Conversational Agents (ECA) to prescribe the usage of hand- head- and facial gestures accompanying the speech in order to augment the communication. The annotation ranges from low level (e.g. perform a specific gesture) to high level (e.g. take turn in a conversation) instructions. On top of that and central to GESTYLE is the notion of style which determines the gesture repertoire and the gesturing manner of the ECA. GESTYLE contains constructs to define and dynamically modify style. The low-level tags prescribing specific gestures to be performed are generated automatically based on the style definition and the high-level tags. By using GESTYLE different aspects of gesturing of an ECA can be defined and tailored to the needs of different application situations or user groups.;2003
In recent years a question of great interest has been the development of tools and techniques to facilitate the evaluation of dialogue systems. The latter can be evaluated from various points of view such as recognition and understanding rates dialogue naturalness and robustness against recognition errors. Evaluation usually requires compiling a large corpus of words and sentences uttered by users relevant to the application domain the system is designed for. This paper proposes a new technique that makes it possible to reuse such a corpus for the evaluation and to check the performance of the system when different dialogue strategies are used. The technique is based on the automatic generation of conversations between the dialogue system together with an additional dialogue system called user simulator that represents the user's interaction with the dialogue system. The technique has been applied to evaluate a dialogue system developed in our lab using two different recognition front-ends and two different dialogue strategies to handle user confirmations. The experiments show that the prompt-dependent recognition front-end achieves better results but that this front-end is appropriate only if users limit their utterances to those related to the current system prompt. The prompt-independent front-end achieves inferior results but enables front-end users to utter any permitted utterance at any time irrespective of the system prompt. In consequence this front-end may allow a more natural and comfortable interaction. The experiments also show that the re-prompting confirmation strategy enhances system performance for both recognition front-ends. (C) 2002 Elsevier Science B.V. All rights reserved.;2003
In the paper we present current activities and some preliminary results of a joint project in designing a spoken dialogue system for Slovenian and Croatian weather information retrieval. We give a brief description of the system design of the procedures we have performed in order to obtain domain specific speech databases and monolingual and bilingual speech recognition experiments. Recognition results for Croatian and Slovenian speech are presented as well as bilingual speech recognition results when using common acoustic models. We propose two different approaches to the language identification problem and show recognition results for the two acoustically similar languages like Slovenian and Croatian.;2003
In this chapter we present the issues and problems involved in the creation of Embodied Conversational Agents (ECAs). These agents may have a humanoid aspect and may be embedded in a user interface with the capacity to interact with the user that is they axe able to perceive and understand what the user is saying but also to answer verbally and nonverbally to the user. ECAs axe expected to interact with users as in human-human conversation. They should smile raise their brows nod and even gesticulate not in a random manner but in co-occurrence with their speech. Results from research in human-human communication are applied to human-ECA communication or ECA-ECA communication. The creation of such agents requires several steps ranging from the creation of the geometry of the body and facial models to the modeling of their mind emotion and personality but also to the computation of the facial expression body gesture gaze that accompany their speech. In this chapter we will present our work toward the computation of nonverbal behaviors accompanying speech.;2003
In this paper is proposed an ontology based on the object-oriented paradigm for the development of explanatory systems to simulate in an appropriate way the professor-student interactions carried out in the teaching processes. The knowledge explained in the dialogue process is represented at different levels of complexity by means of a network of multi-connected units of knowledge. Under the proposed model an open explanatory dialog system is built and incorporated into the Virtual Chemistry Laboratory a virtual system for practical chemistry learning developed by the authors.;2003
In this paper we propose an eye gaze model for an embodied conversational agent that embeds information on communicative functions as well as on statistical information of gaze patterns. This latter information has been derived from the analytic studies of an annotated video-corpus of conversation dyads. We aim at generating different gaze behaviors to stimulate several personalized gaze habits of an embodied conversational agent.;2003
In this paper a novel architecture of a universal dialogue system and its configuration language so-called Conversational Agent Markup Language (CAML) is proposed. The dialogue system embodies a CLIPS engine in order to enable CAML to formulate procedural and heuristic knowledge. CAML supports frames functions and categories that enable it: (a) to process wildcards to control the inner state through variables and to formulate procedural knowledge in contrast to Phoenix/CAT Dialog Manager (b) to support nested macros to control the inner state through variables to assign priorities and weights to states and to interface with external databases in contrast to Dialog Management Tool Language (DMTL) (c) to implement context-free grammars to extract semantic content from user input through frames to allow numeric variables and to interface with external databases as opposed to Artificial Intelligence Markup Language (AIML). The proposed system is extensible in the sense that it can be embedded in any conversational system that receives and emits XML content. Such a dialogue system can be incorporated in multimodal interfaces such as talking head applications conversational web interfaces conversational database interfaces and conversational programming interfaces.;2003
In this paper we give a short overview of the SMARTKom system a flexible and adaptive multimodal dialog system. The system uses a common dialog backbone to realize three interaction scenarios. Through the use of generic methods and knowledize sources for multimodal fusion and fission we were able to develop a generic dialog system for flexible multimodal interaction. (C) 2003 Elsevier Ltd. All rights reserved.;2003
In this paper we present an agent-based system designed to support the adoption of knowledge sharing practices within communities. The system is based on a conceptual framework that by modelling the adoption of knowledge management practices as a change process identifies the pedagogical strategies best suited to support users through the various stages of the adoption process. Learning knowledge management practices is seen as a continuous process taking place at individual and social level that includes the acquisition of information as well as the contextual use of the information acquired. The resulting community-based system provides each member of the community with an artificial personal change-management agent capable of guiding users in the acquisition and adoption of new knowledge sharing practices by activating personalised and contextualised intervention. (C) 2002 Elsevier Science B.V. All rights reserved.;2003
Intelligent web agents that exhibit a complex behavior i.e. an autonomous rather than a merely reactive one are daily gaining popularity as they allow a simpler and more natural interaction metaphor between the user and the machine entertaining him/ber and giving to some extent the illusion of interacting with a human-like interface. In this paper we describe SAMIR an intelligent web agent satisfying the objectives listed above. It uses: - a 3D face animated via a morph-target technique to convey expressions to be communicated to the user - a slightly modified version of the ALICE chatterbot to provide the user with dialoguing capabilities - an XCS classifier system to manage the consistency between conversation and the face expressions. We also show some experimental results obtained applying SAMIR to a virtual bookselling scenario involving the well-known Amazon.com site.;2003
It is often assumed that the use of Embodied Conversational Agents (ECAs) in human-computer interfaces improves human-computer interaction. Because of their appearance and because they show human-like communicative behaviour users tend to ascribe human characteristics to ECAs or 'anthropo-morphize' them. Since interacting with another human being comes natural to people anthropomorphisation of agents in an interface is thought to improve the process of communication. As a result other usability aspects such as satisfaction and learnability would probably benefit. This paper describes a study into anthropomorphisation of ECAs and their effect on memory performance. The results of our study show that the presence of an ECA has a positive effect on retainability of information but that this effect is not necessarily influenced by anthropomorphism.;2003
Language models in speech recognition are usually limited to simple bigrams or trigrams due to data sparseness. In many cases however there is external knowledge available about the domain of application that may be used to guide the search for likely word sequences. This paper explores a number of methods to exploit such knowledge a dynamic class based language model and a lattice rescoring approach based on Bayesian updating. To decide whether external knowledge is applicable a word level confidence measure is implemented. As a special case of the general problem we look at station-to-station travel frequencies to improve recognition accuracy in a train table dialog system. Experiments are conduced to test and compare the different techniques.;2003
Literacy learning - learning how to read and write - begins long before children enter school. One of the key skills to reading and writing is the ability to represent thoughts symbolically and share them in language with an audience who may not necessarily share the same temporal and spatial context. Children learn and practice these important language skills everyday telling stories with the peers and adults around them. In particular storytelling in the context of peer collaboration provides a key environment for children to learn language skills important for literacy. In light of this an embodied conversational agent Sam  who tells stories collaboratively with children was designed. Sam looks like a peer for pre-school children but tells stories in a developmentally advanced way modelling narrative skills important for literacy. Results demonstrated that children who played with the virtual peer told stories that more closely resembled the virtual peer's linguistically advanced stories: using more quoted speech and temporal and spatial expressions. In addition children listened to Sam's stories carefully assisting her and suggesting improvements. The potential benefits of having technology play a social role in young children's literacy learning is discussed.;2003
Many studies have already shown the advantages of building multimodal systems. In this case study we have shown the advantages of combining natural language and a graphical interface in the interactive TV domain. In this paper we describe a multimodal dialogue TV program guide system that is a research prototype built for the case study by adding speech interaction to an already existing TV program guide. Study results indicate positive attitudes towards providing two input modes - spoken natural language input and direct manipulation by means of remote control.;2003
Most of the conversational agents respond to the users in an unsatisfactory way because of using the simple sequential pattern matching. In this paper we propose a conversational agent that can respond with various sentences for improving the user's familiarity. The agent identifies the user's intention using DA (Dialogue Acts) and increases the intelligence and the variety of the conversation using LCS (Learning Classifier System). We apply this agent to the introduction of a web site. The results show that the conversational agent has the ability to present more adequate and friendly response to user's query.;2003
Not all user intentions can be extracted from the speech acts associated with an user utterance. Extra reasoning may be needed to interpret what the user said. We describe how interpretations can be generated using (i) the knowledge associated with each domain object and (ii) the system's expectations. We also present a way of connecting interpretations to discourse obligations from where system decisions are taken.;2003
One of the major scientific goals of SmartKom is to design a new human-machine interaction metaphor for a multimodal dialog system that combines speech gesture and mimicsinput with speech gesture mimics and graphics output. In SmartKom an animated life-like character serves as the communication partner of the user. In this paper we focus on the multimodal output of SmartKom performed by MMoPaD (Multi Modal Presentation and Display) showing how these highly ambitious tasks of the SmartKom system are managed and realized on the output side i.e. how the communication assistant adapts its behavior to the available output media and modalities with respect to the current dialog situation. Depending on them presentations are split in parts (fission) which are output in different ways. An important task is the synchronization of gestures mimics and speech of the presentation agent Smartakus which enriches the presentation and makes it more lively. The system is used on standard and mobile devices.;2003
Over the past decade computer-assisted learning in the field of chemistry has given rise to a large number of systems that approach this objective from different viewpoints: static courses aimed at specific concepts tutorial systems 2D and 3D virtual environments and so on. Correct structuring and representation of the knowledge to be taught the building of a suitable student interface and the adaptation of the learning process to the knowledge of the student are but a few of the challenges to be faced in the development of efficient computer-assisted learning systems. The present study tackles the use of computerized dialogue systems as a viable alternative for the simulation of teacher-student interaction and proposes an ontology for the characterization of such interaction employing the object-oriented paradigm in the modeling of both the knowledge to be taught and the actual level of the student. The proposed solution is based on the representation of the knowledge to be taught through a network of multiconnected knowledge frames (chunks) where each chunk may be specialized in more specific frames (prerequisites and subobjectives) contain associated explanations of varying complexity and with a range of explanatory models and be associated with one or a set of possible questions the student might ask to this end a constantly evolving knowledge model is maintained throughout the explanatory process. Based on the proposed model Java was used to develop and manage an explanatory system that could be used in any type of teaching system based on student-dominated dialogues. Here the system has been applied to the teaching of chemistry laboratory practice by its integration into the Virtual Chemistry Laboratory (VCL) a system designed by the authors to simulate chemistry techniques in a virtual 3D world.;2003
Paper keyboard or mouse-driven systems may not be suitable for data capture because of the hands-busy constraint imposed by an endoscopic examination. A Spoken Dialogue System (SDS) has a number of advantages when compared to keyboard and mouse-driven input modalities particularly with respect to hands free and eyes-free control of a system. However any emerging technology will never deliver improved organizational effectiveness if it is not accepted and used [1]. The Technology Acceptance Model (TAM) provides a framework that helps explain the determinants of computer acceptance [2]. This study through the application of TAM demonstrates a high level of user acceptance with clinicians wanting to use spoken dialogue technology for recording clinical observations during an endoscopic examination. Clinicians would also prefer to use a SDS for recording endoscopy rather than use a paper-based or keyboard and mouse-driven system. Using a clinical narrative during an endoscopic examination was also perceived to be a natural way to record findings. Relationships between basic TAM variables were confirmed and relationships between quality of dialogue measures and TAM variables were established.;2003
Recent studies on non-verbal communication have put the need forward to provide virtual agents lifelike looks. In this paper we present a system allowing to embody a conversational agent by modeling one of its perceptual behavior: gazing at a user. Our system takes as input images of the real scene from a webcam and allows the virtual agent to look at the person it's facing. Animation purposes are mainly explored in this paper through the description of our animation system. This system is composed of two types of models: muscle-based (for facial animation) and parametric (to control the gaze). Realism of the animation is also discussed.;2003
Since 1995 we have been watching the emergence of a new paradigm for the construction of chatterbots based on markup languages. The most prominent of these languages is AIML. Despite its success XML chatterbots have drawbacks in what concerns the level of fluency in dialogues. We present here XbotML a new language for the construction of chatterbots based on principles of the Conversational Analysis theory. Following this theory XbotML structures dialogues between user and chatterbot in adjacency pairs each pair bearing one associated intention. As proof of concept we constructed a chatterbot that has reached fluency level around 75% in dialogues with people. This is an original work that contributes to raise the fluency level of XML chatterbots by: providing a linguistically grounded model for chatterbots' markup languages bases providing a modular model for these bases and allowing the extension of existing bases to different domains and applications.;2003
Spoken Dialogue Systems (SDS) have evolved over the last three decades from simple single word command speech recognition applications and technologies to the large vocabulary continuous systems used today. SDSs have long been reliant on hierarchies of stochastic architectures in particular Hidden Markov Models (HMM) for their components and sub-components. In this paper we examine the applications of HMMs in speech recognition including phoneme recognition word recognition and stochastic grammars. Other applications of HMMs within SDSs are also covered including word tagging and semantic classification at the parsing level dialogue management and strategy optimisation and stochastic reply generation. We then propose that the Hierarchical Hidden Markov Model (HHMM) of Fine Singer and Tishby serve as replacement for many of these specialised HMMs creating a more unified and consistent architecture. We explore the feasibility of this model within a specific information retrieval SDS and demonstrate ways HMM merging can be used with contextual and entropic clustering to dynamically generate HHMM data structures. Issues of training time and applicability of the HHMMs to natural language processing are also examined.;2003
The constant need for information availability led to the Universidade de Evora Information System (SIIUE) development. SIIUE not only must store the necessary information for the institution as must grant an easy access to it. Based on this principle and on the authors' present research interests came the idea of a Natural Language Querying System over SIIUE (NL-SIIUE).;2003
The evaluative character of a word is called its semantic orientation. Positive semantic orientation indicates praise (e.g. honest intrepid) and negative semantic orientation indicates criticism (e.g. disturbing  superfluous). Semantic orientation varies in both direction ( positive or negative) and degree ( mild to strong). An automated system for measuring semantic orientation would have application in text classification text filtering tracking opinions in online discussions analysis of survey responses and automated chat systems (chatbots). This article introduces a method for inferring the semantic orientation of a word from its statistical association with a set of positive and negative paradigm words. Two instances of this approach are evaluated based on two different statistical measures of word association: pointwise mutual information (PMI) and latent semantic analysis (LSA). The method is experimentally tested with 3596 words ( including adjectives adverbs nouns and verbs) that have been manually labeled positive ( 1614 words) and negative ( 1982 words). The method attains an accuracy of 82.8% on the full test set but the accuracy rises above 95% when the algorithm is allowed to abstain from classifying mild words.;2003
The future of human-computer interfaces may include systems which are human-like in abilities and behavior. One particularly interesting aspect of human-to-human communication is the ability of some conversation partners to sensitively pick up on the nuances of the other's utterances as they shift from moment to moment and to use this information to subtly adjust responses to express interest supportiveness sympathy and the like. This paper reports a model of this ability in the context of a spoken dialog system for a tutoring-like interaction. The system used information about the user's internal state-such as feelings of confidence confusion pleasure and dependency-as inferred from the prosody of his utterances and the context and used this information to select the most appropriate acknowledgement form at each moment. Although straight-forward rating reveals no significant preference for a system with this ability a clear preference was found when users rated the system after listening to a recording of their interaction with it. This suggests that human-like real-time sensitivity can be of value in interfaces. The paper further discusses ways to discover and quantify such rules of social interaction using corpus-based analysis developer intuitions and feedback from naive judges and further suggests that the technique of evaluation after re-listening is useful for evaluating spoken dialog systems which operate at near-human levels of performance. (C) 2003 Elsevier Ltd. All rights reserved.;2003
The known Wizard of Oz method designed for the development of dialogue systems interacting with a user using a natural language is considered. The method is based on the hypothesis on computer speech which states that a human interacts with a computer in a different way to how he/she interacts with other humans. Therefore before simulating a natural dialogue corresponding to the rules and norms of human conversation using a computer one should try to model computer speech that is simpler than human speech in its structure. We describe our experience in the application of the Wizard of Oz method and analyze the dialogues collected by this method with the aim of developing the principles of functioning of the control module of our dialogue system.;2003
The paper gives an overview of a typology of dialogue acts we use for annotating Estonian spoken dialogues. Our dialogue corpus includes calls for information and to travel agencies (114 annotated dialogues). Directives (request proposal offer) and possible reactions are considered in the paper. Our further aim is to develop a dialogue system that will interact with the user in natural language following the norms and rules of human-human communication.;2003
The WITAS project addresses the design of an intelligent autonomous UAV (Unmanned Aerial Vehicle) in our case a helicopter. Its dialogue-system subprojects address the design of a deliberative system for natural-language and graphical dialogue with that robotic UAV. This raises new issues both for dialogue and for reasoning in real time. The following topics have been particularly important for us in various stages of the work in these subprojects: - spatiotemporal reference in the dialogue including reference to past events and to planned or expected future events - mixed initiative in the dialogue architecture of a complex system consisting of both dialogue-related components (speech grammar etc) and others (simulation event recognition interface to robot) and more recently as well - identification of a dialogue manager that is no more complex than what is required by the application - uniform treatment of different types of events including the robot's own actions observed events communication events and dialogue-oriented deliberation events - a logic of time action and spatiotemporal phenomena that facilitates the above. This paper gives a brief overview of the WITAS project as a whole and then addresses the approaches that have been used and that are presently being considered in the work on two generations of dialogue subsystems.;2003
This article presents a multiagent simulation environment for studying agents' socio-political attitudes. It departs from a previously proposed concept of agents with socio-political attitudes a high-level theoretical and conceptual model proposed by Petric et al. (2002) that was intended for conversational agents. In contrast our work pursues a bottom-up simulation philosophy where attitudes are grounded in sensory-motor behaviour of spatially distributed autonomous agents modelled in Webots simulation software. The original model was extended by defining an agent's socio-political type by means of weighting the three components found in the Petric et al. (2002) model (neo-liberal alternative and fundamentalist) thus allowing the creation of mixed sociopolitical types. Also in the simulations performed issues were modelled as agents with variable levels of importance. Moreover we introduced inter-agent communication capable of causing changes in socio-political types. Results are presented and discussed with respect to the initial research questions. According to our experimental results the following parameters did not have any significant impact on the simulation outcomes: initial physical position and orientation of the agents positions of the issues the issues' dynamics and inter-agent communication. Experiments with different initial agent types showed that agents with indeterminate socio-political types tended to change to neo-liberal alternative or fundamentalist agents. We conclude by proposing future extensions of the model. Our work is related to a trend in the Artificial Intelligence community which is not primarily task or problem-solving oriented but rather focuses on the study of the embodied and situated nature of social behaviour in humans.;2003
This paper considers design methodologies in order to develop voice-enabled interfaces for tour-guide robots deployed at the Robotics Exposition of the Swiss National Exhibition (Expo.02). Human-robot voice communication presents new challenges for design of fully autonomous mobile robots in that interactivity must be robot-initiated in conversation and within a dynamic adverse environment. We approached these general problems for a voice-enabled interface tailored to limited computational resources of one on-board processor when integrating smart speech signal acquisition automatic speech recognition and synthesis as well as a dialogue system into the multi-modal multi-sensor interface for the expo tour-guide robot. We also focus on particular issues that needed to be addressed in voice-based interaction when planning specific tasks and research experiments for Expo.02 where tour-guide robots had to interact with hundreds of thousands of visitors over 6 months 7 days a week 10 h per day.;2003
This paper deals with the methods of corpus constructions for computerized dialogue system used in city information center. The corpus of recorded generated and simulated sentences is introduced. The usage of corpus and the corresponding results are presented.;2003
This paper describes a discourse system for conversational characters used for interactive stories. This system is part of an environment that allows learners to practice language skills by interacting with the characters other learners and native speakers using instant messaging and email. The dialogues are not purely task oriented and as a result are difficult to model using traditional AI planners. On the other hand the dialogues must move the story forward and thus systems for the meandering dialogues of chatterbots (for example AliceBot) are not appropriate. Our approach combines two methods. We use the notion of dialogue game or speech act networks [1][2] to model the local coherence of dialogues. The story moves forward from one dialogue game to another by means of a situated activity planner [3].;2003
This paper describes a generic model for personality mood and emotion simulation for conversational virtual humans. We present a generic model for describing and updating the paxameters related to emotional behaviour. Also this paper explores how existing theories for appraisal can be integrated into the framework. Finally we describe a prototype system that uses the described models in combination with a dialogue system and a talking head with synchronised speech and facial expressions.;2003
This paper discusses our recent studies on Embodied Conversational Agent (ECA) design strategies to encourage credible and trustworthy dialogue. We approach the problem from two specific directions: the embodiment that the character 'wears' during its interchange with the user and the method of interaction used by the ECA to engage the user. Our results indicate that while users generally prefer to interact with a youthful character matching their ethnicity no significant preferences were indicated for character gender. For interaction our results indicated that a character that portrayed trusting nonverbal behaviors was rated as being significantly more credible than a character portraying no nonverbal behavior or one that portrayed non-trusting behaviors. Other interesting results from this work are also discussed.;2003
This paper investigates the use. of abstract task specifications for dialogue management in the medical domain. In most current dialogue systems possible interactions with the system are hand-coded in the design. This is an expensive process especially for complex dialogues. This paper motivates the use of a task description language for building flexible and adaptive dialogue systems in ontologically rich domains such as medicine. It describes the components of a task specification and proposes an architecture for dialogue systems which al-lows integration of domain reasoning and dialogue. A high-level dialogue specification is used to support multimodal input and output including generation of HTML pages and generation of fragments of VoiceXML for spoken in-teraction.;2003
This paper motivates and outlines a logical formalism for the representation of a dialogue agent's beliefs and goals in a computationally attractive way and is meant to be a basis for effective and efficient context representation in a dialogue system.;2003
This paper overviews robust architecture and modeling techniques for automatic recognition and understanding. The topics include robust acoustic and language modeling for spontaneous speech recognition unsupervised adaptation of acoustic and language models robust architecture for spoken dialogue systems multi-modal speech recognition and speech understanding. This paper also discusses the most important research problems to be solved in order to achieve ultimate robust speech recognition and understanding systems.;2003
This paper presents a vision of the near future in which computer interaction is characterized by natural face-to-face conversations with lifelike characters that speak emote and gesture. These animated agents will converse with people much like people converse effectively with assistants in a variety of focused applications. Despite the research advances required to realize this vision and the lack of strong experimental evidence that animated agents improve human-computer interaction we argue that initial prototypes of perceptive animated interfaces can be developed today and that the resulting systems will provide more effective and engaging communication experiences than existing systems. In support of this hypothesis we first describe initial experiments using an animated character to teach speech and language skills to children with hearing problems and classroom subjects and social skills to children with autistic spectrum disorder. We then show how existing dialogue system architectures can be transformed into perceptive animated interfaces by integrating computer vision and animation capabilities. We conclude by describing the Colorado Literacy Tutor a computer-based literacy program that provides an ideal testbed for research and development of perceptive animated interfaces and consider next steps required to realize the vision.;2003
This paper presents an embodied conversational agent (ECA) that presents multimedia contents. The system takes plain text as input and automatically generates a presentation featured with an animated agent. It selects and generates appropriate gestures and facial expressions for a humanoid agent according to linguistic information in the text. As a component of the ECA systems we also present an agent animation system RISA which can draw animations of natural human behaviors on web-based applications.;2003
This paper proposes a formal framework which offers an external representation of conversations between conversational agents. Using this formalism allows us: (1) to represent the dynamics of conversations between agents (2) to analyze conversations (3) to help autonomous agents to take part in consistent conversations. The proposed formalism called commitment and argument network uses a combined approach based on commitments and arguments. Commitments are used to capture the social and the public aspect of conversations. Arguments on the other side are used to capture the reasoning aspect. We also propose a layered communication model in which the formalism and the approach take place.;2003
This paper reports on an evaluation of the reactions of participants in a computer-controlled telephone conversation system (telephone-linked care TLC) designed to offer nutrition and exercise counseling. After 6 months in the study subjects were asked a series of questions about their opinions of the TLC system including overall satisfaction and the system's helpfulness. One hundred and ninety individuals completed the attitude survey. On a scale of 0-100 respondents rated the overall satisfaction and helpfulness of the system at 63.6 and 62.3. Subjects using the nutrition counseling version of TLC rated it significantly higher on satisfaction (73.0 versus 52.4) and helpfulness (70.3 versus 53.7) than did subjects using the exercise version. Satisfaction and helpfulness were correlated with perceived usability amount of contact realism and credibility (P < 0.01). Multivariate analyses showed that treatment group and number of calls made accounted for the greatest amount of variance in ratings of satisfaction and helpfulness. The findings suggest that the amount of contact with this technology reflected by the number of calls and the treatment group nutrition or exercise were significant predictors of reported satisfaction and perceived helpfulness of the system. (C) 2002 Elsevier Science Ireland Ltd. All rights reserved.;2003
This work presents an agent-based interface that is not merely reactive to some user request but is proactive since it is capable of engaging in a goal-directed conversation with the user e.g. by taking the initiative to recommend new products. The naturalness of interaction especially for casual users is enhanced by appropriate 2D facial models. The proactiveness of the agent is based on a recommendation engine that combines content-based retrieval which exploits user profiles based on content features extracted from the dialogue and descriptions of items that users find relevant with collaborative filtering which clusters users according to their expressed taste to generate recommendations within these virtual communities. The proposed system has been evaluated and validated by using a top-down approach focusing on the system/user interaction.;2003
Use of Internet has surged at an exponential rate in recent years. In particular it has led to many new and innovative applications in the area of E-Commerce. In this paper we introduce an intelligent agent termed AINI the Artificial Intelligent Solution Humanoid. We also show how current e-commerce technological trends can be enhanced by using AINI. AINI is a chatterbot integrated with 3D animated agent character Speech Technology and Artificial Intelligence Markup Language (AIML) is utilised. This agent technology is mainly used to improve customer services and to reduce customer reliance on human operators. By using artificial intelligence techniques AINI is able to provide appropriate answers to service inquiries. In this paper issues on Intelligent Agents Technology Speech Technology AIML and the use of 3D animated character in E-Commerce are discussed.;2003
We aim at creating Embodied Conversational Agents (ECAs) able to communicate multimodally with a user or with other ECAs. In this paper we focus on the Gestural Mind Markers that is those gestures that convey information on the Speaker's Mind we present the ANVIL-SCORE a tool to analyze and classify multimodal data that is a semantically augmented version of Kipp's ANVIL [1]. Thanks to an analysis through the ANVIL-SCORE of a set Gestural Mind Markers taken from a corpus of video-taped data we classify gestures both on the level of the signal and of the meaning finally we show how they can be implemented in an ECA System and how they can be integrated with facial and bodily communication.;2003
We compare our own embodied conversational agent (ECA) scheme BotCom with seven other complex Internet-based ECAs according to recently-published information about them and highlight some important attributes that have received little attention in the construction of realistic ECAs. BotCom incorporates the use of emotions humor and complex information services. We cover issues that are likely to be of greatest interest for developers of ECAs that like BotCom are directed towards intensive commercial use.;2003
We consider the design and analysis of algorithms that learn from the consequences of their actions with the goal of maximizing their cumulative reward when the consequence of a given action is felt immediately and a linear function which is unknown a priori (approximately) relates a feature vector for each action/state pair to the (expected) associated reward. We focus on two cases one in which a continuous-valued reward is (approximately) given by applying the unknown linear function and another in which the probability of receiving the larger of binary-valued rewards is obtained. For these cases we provide bounds on the per-trial regret for our algorithms that go to zero as the number of trials approaches infinity. We also provide lower bounds that show that the rate of convergence is nearly optimal.;2003
We developed a conversation system which can participate in a group conversation. Group conversation is a form of conversation in which three or more participants talk to each other about a topic on an equal footing. Conventional conversation systems have been designed under the assumption that each system merely talked with only one person. Group conversation is different from these conventional systems in the following points. It is necessary for the system to understand the conversational situation such as who is speaking to whom he is speaking and also to whom the other participants pay attention. It is also necessary for the system itself to try to affect the situation appropriately. In this study we realized the function of recognizing the conversational situation by combining image processing and acoustic processing and the function of working on the conversational situation utilizing facial and body actions of the robot. Thus a robot that can join in the group conversation was realized.;2003
We introduce first steps of constructing a natural language dialogue system for weather information retrieval. Data for speech recognition speech understanding and construction of the dialogue manager is being collected with a Wizard-of-Oz (WOZ) system. The hearth of the WOZ system is a graphical interface which is connected to the system's database the language generation module and the Text-to-Speech module. The WOZ simulation results are presented and a brief description of our spontaneous speech database is given.;2003
We introduce the notion of symmetric multimodality for dialogue systems in which all input modes (eg. speech gesture facial expression) are also available for output and vice versa. A dialogue system with symmetric multimodality must not only understand and represent the user's multimodal input but also its own multimodal output. We present the SmartKom system that provides full symmetric multimodality in a mixed-initiative dialogue system with an embodied conversational agent. SmartKom represents a new generation of multimodal dialogue systems that deal not only with simple modality integration and synchronization but cover the full spectrum of dialogue phenomena that are associated with symmetric multimodality (including crossmodal references one-anaphora and backchannelling). We show that SmartKom's plug-an-play architecture supports multiple recognizers for a single modality eg. the user's speech signal can be processed by three unimodal recognizers in parallel (speech recognition emotional prosody boundaryprosody). Finally we detail SmartKom's three-tiered representation of multimodal discourse consisting of a domain layer a discourse layer and a modality layer.;2003
We present a dialogue system that enables the access in natural language to a web information retrieval system. We use a Web Semantic Language to model the knowledge conveyed by the texts. In this way we are able to obtain the associated knowledge necessary to perform the different analysis stages of natural language sentences. In the context of information retrieval we aim to develop a system that by increasing the interaction management capabilities is able to achieve a better degree of cooperativeness and to reduce the average number of interactions needed to retrieve the intended set of documents. The documents in the IR system considered here are composed by the set of documents produced by the Portuguese Attorney General since 1940. These documents were analyzed and an ontology describing their structure and content was defined. Then they were automatically parsed and a (partial) semantic structure was created. The ontology and the semantic content was represented in the OWL language. An example of a user interaction session is presented and explained in detail.;2003
We present a dialogue system that enables the access in natural language to a web law information retrieval system. We use a semantic web language to model the document knowledge and to define an ontology representing the main classes of domain objects their properties and their relations. Our system includes an ontology in DAML+OIL language describing the documents structure a document database build with a subset of the Portuguese Attorney General's Office documents were each document includes a field with its semantic content described in DAML+OIL. The dialogue system interprets the user natural language sentences using the ontology the documents semantic content and the inferred user attitudes.;2003
We present an approach to the definition and application of confidence measures to the speech understanding module in a spoken dialog system which answers queries about railway timetables and prices by telephone in Spanish. Some experiments have been carried out and the results in terms of understanding accuracy depending on the threshold of confidence considered are presented.;2003
We present some aspects of our embodied conversational agent (ECA) that is a chatterbot interface integrated into a website. Our paper highlights only two important attributes of the system: the visualization of the synthetic character and the use of fast emotion generation. We consider several approaches to graphical realization and explain the reasons behind our decision. Also we briefly describe our emotion generation module from the architectural and theoretical perspectives.;2003
A contribution to the understanding module in a spoken dialogue system is presented in this work. The task consists of answering telephone queries about timetables prices and services for long distance trains in Spanish. In this system the representation of the meaning of an utterance is accomplished by means of frames which represent the type of information of the user turn and cases which provide the information given in the sentence. The input of the understanding module is the output of the speech recognizer and its output is used by the dialogue manager. We focus on the classification process of the dialogue user turn with respect to the second level i.e. the identification of the type or types of frames given in the utterance and on the effect of the spontaneous speech recognition errors in the classification accuracy. As classifiers for the user turns we employ multilayer perceptrons in order to use specific understanding models for each type of frame.;2004
As collaborative computer systems are evolving the use of spatial three-dimensional interfaces for multiplayer games groupware systems and multi-user chat systems for example is increasing rapidly. This paper provides a theoretical underpinning for understanding the relevance of user embodiments and copresence within such three-dimensional collaborative computer interfaces. Firstly the issue of embodiment is traced back through its origins in philosophy and psychology literature and theories are identified potentially helpful in understanding key issues concerning user embodiments in collaborative virtual environments. A hybrid avatar/agent model to achieve permanent user embodiments in such environments is discussed. Since copresence of other users within such environments has been shown to be an important factor for the experience of presence a prototype embodied conversational agent has been designed to simulate copresence. A series of controlled experiments involving the prototype agent is discussed highlighting the effects of simulated copresence on users' experience of presence. Results suggest that despite its shortcomings the prototype agent does seem to have increased participants' experience of presence. Evidence was found that even limited copresence as provided by the current prototype agent is sufficient to help users feel presence in the environment. The results seem to confirm that copresence simulated by agents can complement avatar technology and therefore that a hybrid avatar/agent model can potentially achieve permanent virtual presence of all participants. (C) 2004 Elsevier Ltd. All rights reserved.;2004
Building a generalized platform for having dialogues is a hard problem in the topic of dialogue systems. The problem becomes still more difficult if there is the possibility of having a conversation about more than one domain at the same time. To help solving this problem we have built a component that deals with everything related to the domains. In this paper we describe this component named Service Manager and explain what and how it passes all the information that a dialogue manager needs to conduct a dialogue.;2004
Commercial spoken dialog systems which handle increasingly advanced tasks must deal with three development challenges: how to model the dialog when the user can select from many tasks how to communicate with customers about SDS design and how to develop code for a large SDS when the design will likely require updates throughout development. To develop a commercial phone-based SDS that supplies information to Danish employees about their holiday allowance the authors had to meet all these challenges. Key to this system was their use of the Conceptual Dialog Language which expresses patterns specific to the dialog model while still providing a clear picture of it to domain experts and supporting model updates. CDL captures the specifics of an SDS application while remaining flexible enough to support a range of modeling styles and requirements. To facilitate effective communication with domain experts modelers can translate the dialog model in CDL to an HTML document or they can compile it to a programming language for executable code.;2004
Conversational agents are supposed to combine speech with non-verbal modalities for intelligible multimodal utterances. In this paper we focus on the generation of gesture and speech from XML-based descriptions of their overt form. An incremental production model is presented that combines the synthesis of synchronized gestural verbal and facial behaviors with mechanisms for linking them in fluent utterances with natural co-articulation and transition effects. In particular an efficient kinematic approach for animating hand gestures from shape specifications is presented which provides fine adaptation to temporal constraints that are imposed by cross-modal synchrony. Copyright (C) 2004 John Wiley Sons Ltd.;2004
Conversational interfaces allow human users to use spoken language to interact with computer-based information services. In this paper we examine the potential for personalizing speech-based human-computer interaction according to the user's gender and age. We describe a system that uses acoustic features of the user's speech to automatically estimate these physical characteristics. We discuss the difficulties of implementing this process in relation to the high level of environmental noise that is typical of mobile human-computer interaction.;2004
Despite the growing attention towards the communication adequacy of embodied conversational agents (ECAs) standards for their assessment are still missing. This paper reports about a methodology for the evaluation of the adequacy of facial displays in the expression of some basic emotional states based on a recognition task. We consider recognition rates and error distribution both in-absolute terms and with respect to a human model. As to data analysis we propose to resort to standard loglinear techniques and to information-theoretic ones. Results from an experiment are presented and the potentials of the methodology are discussed.;2004
Development of robots that interact with people intelligently in the human-friendly manner is still a challenging research topic. Consider welfare and friend robots that will live with us in the long term their interactions with human are different from those of traditional dialogue systems. They are usually multi-modal and multi-topic. Robots should be also able to learn through the conversations in order to be capable of new things. We aim to integrate robotics and knowledge technology to achieve such robot. This paper presents its system architecture and dialogue manager. The architecture is distributed. The robot is decomposed into multiple components called primitive agents. The special agent dialogue manager acts as the brain of the system. It perceives changes in the environment and makes actions by inferencing based on the knowledge base. Framebased knowledge technique is used to represent the world of interest. It is extended to support time-based layer and frames actions priority. The current system can perform state-based and frame-based types of dialogue and learn simple facts and rules given explicitly by human. The prototype system is developed on a humanoid robot and an example of multi-modal human-robot interaction is shown.;2004
Facial expressions can be used to direct the flow of a conversation as well as to improve the clarity of communication. The critical physical differences between expressions can however be small and subtle. Clear presentation of facial expressions in applied settings then would seem to require a large conversational agent. Given that visual displays are generally limited in size the usage of a large conversational agent would reduce the amount of space available for the display of other information. Here we examine the role of image size in the recognition of facial expressions. The results show that conversational facial expressions can be easily recognized at surprisingly small image sizes. Copyright (C) 2004 John Wiley Sons Ltd.;2004
If we wish to implement dialogue systems which express emotion dialogue corpora annotated for emotion would be a valuable resource. In order to develop such corpora we require a reliable annotation scheme. Here we describe an annotation scheme for emotion in dialogue using categorical labels to complement previous work using dimensional scales. The most difficult challenge in developing such a scheme is selecting the categories of emotions that will yield the most expressive yet reliable scheme. We apply a novel approach using a genetic algorithm to identify the appropriate categories.;2004
In an unprecedented phenomenon characterizing a new kind of relationship between humans and artifacts a craze within middle-aged people for a toy doll is analyzed. In this paper we deal with a talking toy doll. Specifically 51 fan letters and 271 web site postings spontaneously sent to the toy company are analyzed in terms of their communicative functions and affective-cognitive contents. The results indicate that (a) the doll is simultaneously seen as both an artifact and a cohabitant (b) the doll owners attribute positive feelings in terms of both mental and physical states to the doll W the doll owners believe that the utterances of the doll facilitate interaction with family members and with friends and that (d) affections are evoked through owner actions toward the artifact. Based on these results we propose a cognitive model of cognitive activity with artifacts. Copyright (C) 2004 John Wiley Sons Ltd.;2004
In order to increase the role of machines in supporting more capabilities as regards a spoken dialogue system we present in this paper a new problem incorporating multi-session in such a system. Instead of only handling single dialogue such a system can take an intermediary role to communicate with many users in several discontinuous sessions for reaching a compromise between them. We describe here a new approach for modeling the multi-session and then we concentrate on the multi-session management of such a system dedicated for a complete service having several tasks.;2004
In spoken dialogue systems it is important for the system to know how likely a speech recognition hypothesis is to be correct so it can reject misrecognized user turns or in cases where many errors have occurred change its interaction strategy or switch the caller to a human attendant. We have identified prosodic features which predict more accurately when a recognition hypothesis contains errors than the acoustic confidence scores traditionally used in automatic speech recognition in spoken dialogue systems. We describe statistical comparisons of features of correctly and incorrectly recognized turns in the TOOT train information corpus and the W99 conference registration corpus which reveal significant prosodic differences between the two sets of turns. We then present machine learning results showing that the use of prosodic features alone and in combination with other automatically available features can predict more accurately whether or not a user turn was correctly recognized when compared to the use of acoustic confidence scores alone. (C) 2004 Published by Elsevier B.V.;2004
In story-based communication. where a message is conveyed in story form it is important to embody the story with expressive materials. However it is quite difficult for users to create rich multimedia contents using multimedia editing tools. This paper proposes a web-based multimedia environment SPOC (Stream-oriented Public Opinion Channel) aiming at helping non-skillful people to convert their stories into TV-like programs very easily. The system can produce a digital camera work for graphics and video clips as well as generate an agent animation automatically according to a narration text. Findings in evaluation experiments showed that SPOC is easy-to-use and easy-to-learn for novice users. Given a short instruction the subjects not only mastered the operations of the software but also succeeded in creating highly original programs. In subjective evaluation the subjects answered that they enjoyed using the software without feeling difficulty. These results suggest that this system reduces user's cost in making a program and encourages communication in a network community.;2004
In the Persistent World of the cyberspace formed by MMORPG realistic conversations between game characters play an important role so that players can be immersed in the game. However this conversation between game characters in MMORPG has been limited to simple 2D-Dialogues. In other words when a PC-the game character controlled by the players-and a NPC-the character provided and controlled by the back-end game system they only communicate simply based on the levels of PCs and the types of NPCs. In this paper we attempt to extend this system to 3D-Dialogue System by adding familiarity degree between two characters.;2004
In this paper we present a plug and play dialogue system for smart environments. The environment description and its state are stored on a domain ontology. This ontology is formed by entities that represent real world contextual information and abstract concepts. This information is complemented with linguistic parts that allow to automatically create a spoken interface for the environment. The spoken interface is based on multiple dialogues related to every ontology entity with linguistic information. Firstly the dialogue system creates appropriate grammars for the dialogues. Secondly it creates the dialogue parts employing a tree structure. Grammars support the recognition process and the dialogue tree supports the interpretation and generation processes. The system is being tested with a prototype formed by a living room. Users may interact with and modify the physical state of this living room environment by means of the spoken dialogue interface.;2004
In this paper we describe a new way to access information by chatting to an information source. This involves a chatbot a program that emulates human conversation the chatbot must be trainable with a text to accept input and match it against the text to generate replies in the conversation. We have developed a Machine Learning approach to retrain the ALICE chatbot with a transcript of human dialogue and used this to develop a range of chatbots conversing in different styles and languages. We adapted this chatbot-training program to the Qur'an to allow users to learn from the Qur'an in a conversational information-access style. The process and results are illustrated in this paper.;2004
In this paper we propose a Japanese dialogue processing method based on a similarity measure using tf (.) AoI(term frequency x Amount of Information). Keywords are specially used in a spoken dialogue system because a user utterance includes an erroneous recognition filler and a noise. However when a system uses keywords for robustness it is difficult to realize detailed differences. Therefore our method calculates similarity between two sentences without deleting any word from an input sentence and we rise a weight. which multiplies term frequency and amount of information(tf Aol). We use 173 open data sets which are collected from 12095 sentences in SLDB. The experimental result using our method has a correct response rate of 67.1%. We confirmed that correct response rate of our method was 11.6 points higher than that of the matching rate measure between an input sentence and a comparison sentence. Furthermore that of our method was 7.0 points higher than that of tf (.) idf.;2004
In this paper we survey the role of virtual humans (or embodied conversational agents) in smart and ambient intelligence environments. Research in this area can profit from research done earlier in virtual reality environments and research on verbal and nonverbal interaction. We discuss virtual humans as social actors and argue that rather than is common in traditional human-computer interface research we need to look at multi-party interaction. Virtual humans in the party need to be equipped with nonverbal communication capabilities including the display of emotions. (C) 2004 Elsevier Ltd. All rights reserved.;2004
In this survey paper we analytically examine the state of the art in speech and natural language processing technologies and one of their most promising applications in the robotics world as a user interface to facilitate human-robot interaction/communication and robot control by spoken natural language. Theoretical aspects of spoken language technology and the main bottlenecks in developing a conversational interface for a robot have been presented in depth with results found while searching the literature related to the major breakthroughs made in this field. In this study we present a brief technical introduction to talk-active robots and to discuss related future technical challenges and technical approaches used. Efforts have been made to highlight the limitations and missing directions of the research and development in the spoken language technology which are creating hurdles in the development of voice-active robots for real-world applications.;2004
In this work we present an approach to Automatic Speech Understanding based on stochastic models. In a first phase the input sentence is transduced into a sequence of semantic units by using hidden Markov models. In a second phase a semantic frame is obtained from this sequence of semantic units. We have studied some smoothing techniques in order to take into account the unseen events in the training corpus. We have also explored the possibility of using specific hidden Markov models depending on the dialogue state. These techniques have been applied to the understanding module of a dialogue system of railway information in Spanish. Some experimental results with written and speech input are presented.;2004
In this work we present an approach to language understanding using corpus-based and statistical language models based on multigrams. Assuming that we can assign meanings to segments of words the n-multigram modelization is a good approach to model sequences of segments that have semantic information associated to them. This approach has been applied to the task of speech understanding in the framework of a dialogue system that answers queries about train timetables in Spanish. Some experimental results are also reported.;2004
InCA is a distributed personal assistant conversational agent. The front-end runs on a handheld PDA and uses facial animation and natural speech input/output to interact with the user to provide services such as appointments e-mail and weather reports. Existing conversational character research focuses on desktop platforms but there are obvious differences when the platform is a mobile device the two most obvious being the limited computational power and the restrictions on input modalities. This paper discusses the architecture and implementation of InCA which addresses these two challenges.;2004
Indian language computing is lagging behind due to several reasons primary amongst them being the unavailability of suitable interfaces for human-computer interaction. Natural Language Conversational Interfaces (NLCIs) play the all important role in improving the usability of interfaces for the Indian masses. In this paper an NLCI incorporating speech and dialog is presented.;2004
Internet-based virtual learning environments allow participants to refine their knowledge by interacting with their peers. Besides they offer ways to escape from the isolation seen in the CAI and ITS systems. However simply allowing participants to interact is not enough to eliminate the isolation feeling and to motivate students. Recent research in Computer Supported Collaborative Learning has been investigating ways to minor the above problems. This paper presents the OXEnTCHE-Chat a chat tool coupled with an automatic dialogue classifier which analyses on-line interaction and provides just-in-time feedback to both instructors and learners. Feedback is provided through reports which can be user-specific or about the whole dialogue. The tool also counts on a chatterbot which plays the role of an automatic coordinator. The implemented prototype of OXEnTCHE-Chat has been evaluated and the obtained results are very satisfactory.;2004
Knowledge management systems will presumably benefit from intelligent interfaces including those with animated conversational agents. One of the functions of an animated conversational agent is to serve as a navigational guide that nudges the user how to use the interface in a productive way. This is a different function from delivering the content of the material. We conducted a study on college students who used a web facility in one of four navigational guide conditions: Full Guide (speech and face) Voice Guide Print Guide and No Guide. The web site was the Human Use Regulatory Affairs Advisor (HURAA) a web-based facility that provides help and training on research ethics based on documents and regulations in United States Federal agencies. The college students used HURAA to complete a number of learning modules and document retrieval tasks. There was no significant facilitation of any of the guides on several measures of learning and performance compared with the No Guide condition. This result suggests that the potential benefits of conversational guides are not ubiquitous but they may save time and increase learning under specific conditions that are yet to be isolated.;2004
Many classification algorithms were originally designed for fixed-size vectors. Recent applications in text and speech processing and computational biology require however the analysis of variable-length sequences and more generally weighted automata. An approach widely used in statistical learning techniques such as Support Vector Machines (SVMs) is that of kernel methods due to their computational efficiency in high-dimensional feature spaces. We introduce a general family of kernels based on weighted transducers or rational relations rational kernels that extend kernel methods to the analysis of variable-length sequences or more generally weighted automata. We show that rational kernels can be computed efficiently using a general algorithm of composition of weighted transducers and a general single-source shortest-distance algorithm. Not all rational kernels are positive definite and symmetric (PDS) or equivalently verify the Mercer condition a condition that guarantees the convergence of training for discriminant classification algorithms such as SVMs. We present several theoretical results related to PDS rational kernels. We show that under some general conditions these kernels are closed under sum product or Kleene-closure and give a general method for constructing a PDS rational kernel from an arbitrary transducer defined on some non-idempotent semirings. We give the proof of several characterization results that can be used to guide the design of PDS rational kernels. We also show that some commonly used string kernels or similarity measures such as the edit-distance the convolution kernels of Haussler and some string kernels used in the context of computational biology are specific instances of rational kernels. Our results include the proof that the edit-distance over a non-trivial alphabet is not negative definite which to the best of our knowledge was never stated or proved before. Rational kernels can be combined with SVMs to form efficient and powerful techniques for a variety of classification tasks in text and speech processing or computational biology. We describe examples of general families of PDS rational kernels that are useful in many of these applications and report the result of our experiments illustrating the use of rational kernels in several difficult large-vocabulary spoken-dialog classification tasks based on deployed spoken-dialog systems. Our results show that rational kernels are easy to design and implement and lead to substantial improvements of the classification accuracy.;2004
Natural Language Generation (NLG) systems axe increasingly becoming available as market-ready products mainly due to the now-removed boundary between shallow and deep generation and the emergence of hybrid systems as a de-facto standard. In this paper we present HYPERBUG(1) a novel approach towards hybrid NLG coupling shallow and deep processing not only with respect to the resources used for parsing and generation but also on the architectural level to increase the generative power of the shallow generation branch and the processing efficiency of the whole generation system. The architecture is discussed both in theory and in practice using a comprehensive example spanning the complete output part of our dialog system.;2004
Natural Language Generation (NLG) systems have almost reached the state of market-readiness now mostly because hybrid systems of different types have emerged as a de-facto standard. But still relatively few dialog systems make use of NLG techniques. In this paper we discuss the output part of our spoken language dialog system by presenting an example scenario including dialog management NLG and speech synthesis. Our approach to hybrid NLG couples shallow and deep processing with respect to the linguistic and pragmatic system resources and also on the architectural level and thus increases processing efficiency (compared to pure deep generation) as well as generative power (compared to pure shallow generation). Our system has been applied to three different domains namely home A/V management model train controlling and B2B e-procurement.;2004
Past attempts to model emotions for speech synthesis have focused on extreme basic emotion categories. The present paper suggests an alternative representation of emotional states by means of emotion dimensions and explains how this approach can contribute to making speech synthesis a useful component of affetive dialogue systems.;2004
People highlight the intended interpretation of their utterances within a larger discourse by a diverse set of non-verbal signals. These signals represent a key challenge for animated conversational agents because they are pervasive variable and need to be coordinated judiciously in an effective contribution to conversation. In this paper we describe a freely available cross-platform real-time facial animation system RUTH that animates such high-level signals in synchrony with speech and lip movements. RUTH adopts an open layered architecture in which fine-grained features of the animation can be derived by rule from inferred linguistic structure allowing us to use RUTH in conjunction with annotation of observed discourse to investigate the meaningful high-level elements of conversational facial movement for American English speakers. Copyright (C) 2004 John Wiley Sons Ltd.;2004
Previous research has shown that self-explanation can be supported effectively in an intelligent tutoring system by simple means such as menus. We now focus on the hypothesis that natural language dialogue is an even more effective way to support self-explanation. We have developed the Geometry Explanation Tutor which helps students to state explanations of their problem-solving steps in their own words. In a classroom study involving 71 advanced students we found that students who explained problem-solving steps in a dialogue with the tutor did not learn better overall than students who explained by means of a menu but did learn better to state explanations. Second examining a subset of 700 student explanations students who received higher-quality feedback from the system made greater progress in their dialogues and learned more providing some measure of confidence that progress is a useful intermediate variable to guide further system development. Finally students who tended to reference specific problem elements in their explanations rather than state a general problem-solving principle had lower learning gains than other students. Such explanations may be indicative of an earlier developmental level.;2004
Recent studies highlight the importance of personality for improving human-machine interaction. Attempts of including personality in chatterbots have not been satisfactory regarding the coherence of the chatterbot's behavior the flexibility and reusability of the personality model. This work presents Persona-AIML an original architecture for the creation of chatterbots in AIML with personality. It is a flexible architecture that allows the use of of different models of personality described in terms of five elements: traits attitudes mood emotions and physical states. Recent experiments validate the reusability and extensibility of our architecture to build chatterbots with different personalities. however using the same categories base. The implemented chatterbots demonstrated a satisfactory level of coherence in their behavior.;2004
Recently it seems to be interested in the conversational agent as an effective and familiar information provider. Most of conversational agents reply to user's queries based on static answers constructed in advance. Therefore it cannot respond with flexible answers adjusted to the user and the stiffness shrinks the usability of conversational agents. In this paper we propose a method using genetic programming to generate answers adaptive to users. In order to construct answers Korean grammar structures are defined by BNF (Backus Naur Form) and it generates various grammar structures utilizing genetic programming (GP). We have applied the proposed method to the agent introducing a fashion web site and certified that it responds more flexibly to user's queries.;2004
Searching for and making decisions about information is becoming increasingly difficult as the amount of information and number of choices increases. Recommendation systems help users find items of interest of a particular type such as movies or restaurants but are still somewhat awkward to use. Our solution is to take advantage of the complementary strengths of personalized recommendation systems and dialogue systems creating personalized aides. We present a system-the ADAPTIVE PLACE ADVISOR - that treats item selection as an interactive conversational process with the program inquiring about item attributes and the user responding. Individual long-term user preferences are unobtrusively obtained in the course of normal recommendation dialogues and used to direct future conversations with the same user. We present a novel user model that influences both item search and the questions asked during a conversation. We demonstrate the effectiveness of our system in significantly reducing the time and number of interactions required to find a satisfactory item as compared to a control group of users interacting with a non-adaptive version of the system.;2004
Shortest path search has important practical applications and is related to optimization problem. This paper discusses a new algorithm time-synchronous heuristic dynamic programming search which combined the pruning and global optimization of DP (Dynamic programming) and the partial search of heuristic strategy and found the shortest path in time O(n/k(d)) (k d greater than or equal to 1). Furthermore the algorithm can be applied to find the K shortest paths between a pair of given nodes or all paths less than a given length within the same steps. Finally this algorithm was applied to the shortest path search on the real map and user could use spoken dialog to query shortcut in real time 90% of the system responses are correct.;2004
Speech interfaces are about to be integrated in consumer appliances and embedded systems and are expected to be used by mobile users in ubiquitous computing environments. This paper discusses some major usability and HCI related problems that may be introduced by this development. It is argued that a human-centered approach should be employed when designing and developing speech interfaces for mobile environments. Further the Butler a generic spoken dialogue system developed according to the human-centered approach is described. The Butler features a dynamic multi-domain approach.;2004
The ability to lead collaborative discussions and appropriately scaffold learning has been identified as one of the central advantages of human tutorial interaction [6]. In order to reproduce the effectiveness of human tutors many developers of tutorial dialogue systems have taken the approach of identifying human tutorial tactics and then incorporating them into their systems. Equally important as understanding the tactics themselves is understanding how human tutors decide which tactics to use. We argue that these decisions are made based not only on student actions and the content of student utterances but also on the meta-communicative information conveyed through spoken utterances (e.g. pauses disfluencies intonation). Since this information is less frequent or unavailable in typed input tutorial dialogue systems with speech interfaces have the potential to be more effective than those without. This paper gives an overview of the Spoken Conversational Tutor (SCoT) that we have built and describes how we are beginning to make use of spoken language information in SCoT.;2004
The aim of this conceptual paper is to propose separating social attitude engines from emotion engines of autonomous agents as one way of increasing their social intelligence and consequently the believability of their behavior. The aim of the proposed separation is to clearly distinguish between the social and psychological aspects of agent behavior. In the existing emotion engines the two aspects are blended to a degree which frequently prevents modelling of the elements of complex social interactions found in contemporary society. Our view is that the development of the proposed separate sociopolitical modules of social attitude engines could enable introduction of political and ideological elements into agent behavior. One way of introducing these elements into the agents' social attitude engines is via their narrative knowledge. In order to accomplish this Jean-Francois Lyotard's notion of metanarratives has been used in this paper as well as Fredric Jameson's reinterpretation of that notion. Three globally recognizable ideal types (neoliberal fundamentalist and alternative) have been supplied with narratives translated into a conceptual model applicable in modelling of conversational agents. In the future the presented socio-political attitude model should be expanded by means of addition of attitudes from various other areas of social life in order to develop complex social attitude engines.;2004
The central module of any natural language dialogue system is the dialogue manager which plays the role of an intermediate agent between the user and the information source. Its cooperativity and portability highly determines the efficiency of the dialogue system. Therefore as the basis for cooperativity of information-providing dialogue systems we propose a knowledge representation of the information source based on intuitionistic modal logic. For modeling of the dialogue flow we use conversational game theory which on the other hand significantly increases the portability.;2004
The conversational agent understands and provides users with proper information based on natural language. Conventional agents based on pattern matching have much restriction to manage various types of real dialogues and to improve the answering performance. For the effective construction of conversational agents we propose a domain-adaptive conversational agent that infers the user's intention with two-stage inference and incrementally improves the answering performance through a learning dialogue. We can confirm the usefulness of the proposed method with examples and usability tests.;2004
The efficacy of expert systems often depends on the accuracy and completeness of the problem specification negotiated with the user. Therefore efficient user interfaces are needed in order to assist the user in identifying and supplying the required data. Our approach presented in this paper is based on the utilisation of conversational interfaces giving users the possibility of interacting with the system by means of natural language. Through the use of flexible dialogue management plans and an advanced problem solving strategy based on case based reasoning and information retrieval efficient user guidance during the interaction with an expert system can be achieved. Thus the user can interactively develop a comprehensive and coherent specification of his problem based on clarifications explanations and context-based factual information provided by the system. As an application framework we introduce the EU-funded Project VIP-Advisor whose objective is the development of a virtual insurance and finance assistant capable of natural language interaction.;2004
The Human Use Regulatory Affairs Advisor (HURAA) is a Web-based facility that provides help and training on the ethical use of human subjects in research based on documents and regulations in United States federal agencies. HURAA has a number of standard features of conventional Web facilities and computer-based training such as hypertext multimedia help modules glossaries archives links to other sites and page-turning didactic instruction. HURAA also has these intelligent features: (1) an animated conversational agent that serves as a navigational guide for the Web facility (2) lessons with case-based and explanation-based reasoning (3) document retrieval through natural language queries and (4) a context-sensitive Frequently Asked Questions segment called Point & Query. This article describes the functional learning components of HURAA specifies its computational architecture and summarizes empirical tests of the facility on learners.;2004
The Internet and ubiquitous network technologies have succeeded in connecting people and knowledge over space and time. The next step is to realize knowledgeable communities on the ubiquitous network. Social Intelligence Design is a field of research on harmonizing people and artifacts by focusing on social intelligence defined as the ability of actors and agents to learn and to solve problems as a function of social structure and to manage their relationships with each other. In this paper I present a computational approach to understanding and augmenting the conversational knowledge process that is a collective activity for knowledge creation management and application where conversational communications are used as a primary means of interaction among participating agents. The key idea is conversation quantization a technique of approximating a continuous flow of conversation by a series of conversation quanta that represent points of the discourse. Conversation quantization enables to implement a rather robust conversational system by basing it on a large amount of conversational quanta collected from the real world. I survey major results concerning acquisition annotation adaptation and understanding of conversation quanta.;2004
The identification of dysfunctional thoughts is a central effort in cognitive therapy. This paper describes the first version of a computer module that classifies dysfunctional thoughts automatically. It is part of COGNO a system we are developing to give automatic feedback on dysfunctional thoughts. The system uses rules that were developed from language markers identified in a sample of 149 dysfunctional thoughts. The system was tested with an independent set of 112 example thoughts. The system detects the majority of dysfunctional thoughts but works reliably only for some thought categories. Automatic thought classification may be a first step toward developing natural dialogue systems in cognitive therapy.;2004
The main purpose of this paper was to present a distributed speech interactive system built on LAN (Local area network) which integrated Automatic speech recognition (ASR) Text to speech (TTS) and Natural language perception (NLP) technologies to allow multiusers to access and converse with it concurrently. During a typical telephone based interaction users could retrieve up-to-date stock information and call for somebody by directly speaking their name. Though there were far too many papers published to describe such system most of them all focused on the algorithm on speech recognition rather than the architecture. Our paper was written to make for it and proposed an efficient and effective dynamic load balancing algorithm with sender active and non-preemptive concepts based on the distributed architecture and multithread concurrency in order to solve the loads allocating when multi-users accessed the system and gave rise to much burden to the servers. This paper was composed of five part: (1) an introduction about why such architecture was built (2) an overview about the system (3) proposed and implemented the algorithm (4) evaluated and tested the system performance based on the architecture and (5) a brief summary.;2004
The paper presents the cognitive-model-based approach of abductive interpretation of emotions that it is used in the multi-modal dialog system SmaxtKom(1). The approach is. based on the OCC model of emotions that explains emotions by matches or mismatches of the attitudes of an agent with the state of affairs in the relevant situation. It is explained how eliciting conditions i.e.abstract schemata for the explanation of emotions can be instantiated with general or abstract concepts for attitudes and actions and further enhanced with conditions and operators for generating reactions which allow for abductive inference of explanations of emotional states and determination of reactions. During this process concepts that are initially abstract are made concrete. Emotions may work as a self-contained dialog move. They show a complex relation to explicit communication. Additionally we present our approach of analyzing indicators of emotions and user state that come from different sources.;2004
The understanding module of a spoken dialogue system must extract from the speech recognizer output the kind of request expressed by the caller (the call type) and its parameters (numerical expressions time expressions or proper-names). Such expressions are called Named Entities and their definitions can be either generic or linked to the dialogue application domain. Detecting and extracting such Named Entities within a mixed-initiative dialogue context like How May I Help You?(smtm) (HMIHY) is the subject of this study. After reviewing standard methods based on hand-written grammars and statistical tagging we propose a new approach combining the advantages of both in a 2-step process We also propose a novel architecture which exploits understanding to improve recognition accuracy: the output of the Automatic Speech Recognition module is now a word lattice and the understanding module is responsible for transcribing the word strings which are useful to the Dialogue Manager. All the methods proposed are trained and evaluated on a corpus comprising utterances from live customer traffic. (C) 2003 Elsevier B.V. All rights reserved.;2004
This article describes a speech-based user interface to a wide range of entertainment navigation and communication applications in mobile environments by means of human-machine dialogues. The system has been developed in the framework of the EU-project SENECA. It uses noise reduction speech recognition and dialogue processing techniques. One interesting aspect relies in the fact that low speech recognition confidence and word-level ambiguities are compensated by engaging flexible clarification dialogues with the user. The SENECA system demonstrator has been evaluated by means of user tests. With speech input road safety especially for complex tasks is significantly improved. Compared to manual input the feeling of being distracted from driving is less important with speech. (C) 2004 Elsevier B.V. All rights reserved.;2004
This article presents a qualitative analysis showing the dependency of effective collaborative argumentation on interpersonal relational aspects that develop during synchronous interaction. Four regulatory principles are proposed as propelling the interaction and of these autoregulation or the conservative restraints within the existing relation appears to be the dominant force. When using a structured dialogue system (SDS) instead of free chat via roles and sentence-openers the social dimension of the relation between participants disappears from the surface interaction. Even though using the SDS seems to foster a more focused and task-functional approach argumentation appears to affect the relations between participants in a negative way since after an argumentative sequence repair of the relationship takes place. It might even be argued that because of relational stress in many cases argumentation is momentarily suspended.;2004
This paper addresses the quality of telephone services which rely on spoken dialogue systems enabling the spoken interaction between a human user and a speech technology device over the phone. During the interaction parameters are collected which characterize the behavior of both interaction partners. These parameters are used to calculate an estimation of different quality aspects perceived by the user or of global user satisfaction. On the basis of own experimental data the most well-known estimation algorithm - the PARADISE model - is analyzed in detail with respect to its input parameters the estimated quality indices as well as its internal algorithmic structure. New approaches to improve the genericness of the underlying structure are presented following a classification of quality aspects described in [1]. It turns out that current modelling approaches are still very limited in their predictive power. Cross-laboratory data collection and new interaction parameters are necessary to overcome the observed limitations.;2004
This paper describes a generic model for personality mood and emotion simulation for conversational virtual humans. We present a generic model for updating the parameters related to emotional behaviour as well as a linear implementation of the generic update mechanisms. We explore how existing theories for appraisal can be integrated into the framework. Then we describe a prototype system that uses the described models in combination with a dialogue system and a talking head with synchronized speech and facial expressions. Copyright (C) 2004 John Wiley Sons Ltd.;2004
This paper describes a new generic architecture for dialog systems enabling communication between a human user and a personal assistant based on speech acts. Dialog systems are often domain-related applications. That is the system is developed for specific applications and cannot be reused in other domains. A major problem concerns the development of scalable dialog systems capable to be extended with new tasks without much effort. In this paper we discuss a generic dialog architecture for a personal assistant. The assistant uses explicit task representation and knowledge to achieve an intelligent dialog. The independence of the dialog architecture from knowledge and from tasks allows the agent to be extended without needing to modify the dialog structure. The system has been implemented in a collaborative environment in order to personalize services and to facilitate the interaction with collaborative applications like e-mail clients document managers or design tools.;2004
This paper describes BOGAR_LN an agent-based component-ware framework which consist of a multi-layered library and support tools for component creation retrieval management and reuse. BOGAR_LN library provides application developers with four categories of reusable component models: Agent Organization models Agent models Resource models and Basic computing entities. For each category there are generic components which represents abstract reusable patterns and application oriented components. Component instances are made up of three blocks of information: design description in UML code implementation in Java and an extensible collection of attribute-value descriptors. The initial repertoire of repository components comes from previous experiences in developing Agent based telecom services. The paper also presents the metrics and the evaluation approach to assess the benefits of the framework. Evaluation data have been gathered by using the framework to develop a mixed-initiative spoken dialog system for appointment management over the telephone. Results showed significant reductions on both project duration and cost. Compared to previous developments the time and the engineering effort required to build the service was on average 65% less when using BOGART_LN.;2004
This paper describes the SpexKit framework for the development of spoken dialogue systems which is currently used to implement prototypes of a bilingual city information system. We sketch the overall architecture of this speech platform its dialogue manager and its scripting language as well as the integration of speech technology components like ASR or TTS systems.;2004
This paper examines the effects of spoken vs. written dialogue modalities on the effectiveness of information search with a computerized retrieval system. Forty-eight adults familiar with the use of computers were asked to carry out six information retrieval tasks engaging with the system using either spoken or written communication. The written modality was more efficient with regard to the number of dialogue turns length of interaction with the system and mental workload. Even though the turns lasted longer in the written mode they appeared to yield less mental workload. Moreover spoken and written dialogues did not differ as regards the use of pronouns and articles. The implications for the development of natural-language dialogue systems are discussed. (C) 2004 Elsevier Ltd. All rights reserved.;2004
This paper introduces the DReSDeN(1) tutorial dialogue manager which adopts a similar Issues Under Negotiation approach to that presented in Larsson [20]. Thus the information state that is maintained in DReSDeN represents the items that are currently being discussed as well as their interrelationships. This representation provides a structure for organizing the representation for the interwoven conversational threads [26] out of which the negotiation dialogue is composed. We are developing DReSDeN in the context of the CycleTalk tutorial dialogue system that supports the development of critical thinking and argumentation skills by engaging students in negotiation dialogues. We describe the role of DReSDeN in the CycleTalk tutorial dialogue system currently under development. We then give a detailed description of DReSDeN's underlying algorithms and data structures illustrated with a working example. We conclude with some early work in using machine learning techniques to adapt DReSDeN's behavior.;2004
This paper presents a prototype dialogue system K-2 in which a user can instruct agents through speech input to manipulate various objects in a 3-D virtual world. The agents' action is presented to the user as an animation. To build such a system we have to deal with some of the deeper issues of natural language processing such as ellipsis and anaphora resolution handling vagueness and so on. In this paper we focus on three distinctive features of the K-2 system: handling ill-formed speech input plan-based anaphora resolution and handling vagueness in spatial expressions. After an overview of the system architecture each of these features is described. We also look at the future research agenda of this system.;2004
This paper presents the design of an over-the-phone non-task-oriented conversational spoken dialogue system character created to chat with users about himself and entertain them. Focus is on techniques used in personality modelling of the system character how his mood changes based on input and how this is reflected in his output. Experience with a first version of the system and planned improvements are also discussed.;2004
This paper reports on the generation of coordinated multimodal output for the NICE (Natural Interactive Communication for Edutainment) system [1]. In its first prototype the system allows for fun and experientially rich interaction between primarily 10 to 18 years old human users and 3D-embodied fairy tale author H.C. Andersen in his study. User input consists of domain-oriented spoken conversation combined with 2D input gesture entered via a mouse-compatible device. The animated character can move about and interact with his environment as well as communicate with the user through spoken conversation and non-verbal gesture body posture facial expression and gaze. The described approach aims to make the virtual agent's appearance voice actions and communicative behavior convey the impression of a character with human-like behavior emotions relevant domain knowledge and a distinct personality. We propose an approach to multimodal output generation which exploits a richly parameterized semantic instruction from the conversation manager and splits the instruction into synchronized text instructions to the text-to-speech synthesizer and behavioral instructions to the animated character. Based on the implemented version of this approach we are in the process of creating a behavior sub-system that combines the described multimodal output instructions with parameters representing the current emotional state of the character producing animations that express emotional state through speech and non-verbal behavior.;2004
Two studies of spoken telephone number transfers-in which one participant communicates a number to the other-are reported. The data comprised transcripts of telephone conversations between callers and operators for the second corpus audio recordings were also available. In most cases the caller was giving the number to the operator and in these dialogues a chunked echo protocol was found to be very common with the operator repeating each chunk of one or more digits to the caller for confirmation before the next chunk was given. Errors in speaking and in recognition were corrected efficiently within this protocol. The observations support a model of dialogue in which a single utterance unit can perform multiple dialogue acts and in which discourse units can have hierarchical structure. Examination of the audio recordings showed that there was usually very little silence and sometimes a slight overlap between conversational turns. Various prosodic phenomena were noted as contributing to the turn-taking and grounding processes. Implications for automated dialogue systems are discussed. (C) 2004 Elsevier B.V. All rights reserved.;2004
We address the issue of spontaneous gesture synthesis for embodied conversation agents (ECAs) that is the generation of appropriate gestures and their coordination with spoken utterances. After a characterization of the application constraints we establish the principal requirements of the gesture generation framework. We demonstrate how these requirements can be met by formulating the gesture generation as real-time search through gesture space (actually gesture and facial expression) under the constraints arising from the graphical model of the character and the linguistic properties of the utterance.;2004
We aim at the realization of an Embodied Conversational Agent able to interact naturally and emotionally with user. In particular the agent should behave expressively. Specifying for a given emotion its corresponding facial expression will not produce the sensation of expressivity. To do so one needs to specify parameters such as intensity tension movement property. Moreover emotion affects also lip shapes during speech. Simply adding the facial expression of emotion to the lip shape does not produce lip readable movement. In this paper we present a model based on real data from a speaker on which was applied passive markers. The real data covers natural speech as well as emotional speech. We present an algorithm that determines the appropriate viseme and applies coarticulation and correlation rules to consider the vocalic and the consonantal contexts as well as muscular phenomena such as lip compression and lip stretching. Expressive qualifiers are then used to modulate the expressivity of lip movement. Our model of lip movement is applied on a 3D facial model compliant with MPEG-4 standard. Copyright (C) 2004 John Wiley Sons Ltd.;2004
We describe a method for using a database of recorded speech and captured motion to create an animated conversational character. People's utterances are composed of short clearly-delimited phrases in each phrase gesture and speech go together meaningfully and synchronize at a common point of maximum emphasis. We develop tools for collecting and managing performance data that exploit this structure. The tools help create scripts for performers help annotate and segment performance data and structure specific messages for characters to use within application contexts. Our animations then reproduce this structure. They recombine motion samples with new speech samples to recreate coherent phrases and blend segments of speech and motion together phrase-by-phrase into extended utterances. By framing problems for utterance generation and synthesis so that they can draw closely on a talented performance our techniques support the rapid construction of animated characters with rich and appropriate expression.;2004
We describe an implemented system for the simulation and visualisation of the emotional state of a multimodal conversational agent called Max. The focus of the presented work lies on modeling a coherent. course of emotions over time. The basic idea of the underlying emotion system is the linkage of two interrelated psychological concepts: an emotion axis representing short-time system states - and an orthogonal mood axis that stands for an undirected longer lasting system state. A third axis was added to realize a dimension of boredom. To enhance the believability and lifelikeness of Max the emotion system has been integrated in the agent's architecture. In result Max's facial expression gesture speech and secondary behaviors As well as his cognitive functions are modulated by the emotional system that in turn is affected by information arising at various levels within the agent's architecture.;2004
We describe the recording and annotation of a corpus of role-playing dialogues in the domain of the COMIC multimodal dialogue system. We give some generalisations about the use of deictic gesture in this task and show how those findings are currently used in the presentation-planning module of the dialogue system prototype. Finally we describe how the use of gestures in the system will be evaluated and outline the next steps in the development of the module.;2004
We discuss the motivation for a novel style of tutorial dialogue system that emphasizes reflection in a design context. Our current research focuses on the hypothesis that this type of dialogue will lead to better learning than previous tutorial dialogue systems because (1) it motivates students to explain more in order to justify their thinking and (2) it supports students' metacognitive ability to ask themselves good questions about the design choices they make. We present a preliminary cognitive task analysis of design exploration tasks using CyclePad an articulate thermodynamics simulator [10]. Using this cognitive task analysis we analyze data collected in two initial studies of students using CyclePad one in an unguided manner and one in a Wizard of Oz scenario. This analysis suggests ways in which tutorial dialogue can be used to assist students in their exploration and encourage a fruitful learning orientation. Finally we conclude with some system desiderata derived from our analysis as well as plans for further exploration.;2004
We explore a voice user interface for human-machine communication that uses a dialogue structure personalized to an individual user subject to the constraints of the system's resources. Conventional dialogue systems typically use architectures that create a set of predefined speech objects or subdialogues by combining several static components such as grammars and other language components. Such systems are limited because most databases are dynamic and users have different preferences for topical content and presentation format. Ideally a dialogue would combine a user's intentions encoded in a profile with information and services available in a dynamic and distributed external environment. We use a modular architecture where a centralized Application Generator (AG) interacts with two managers. A user's preferences are stored in a profile handled by a Profile Manager. An Information Manager uses these preferences when accessing external databases and extracting filtering or presenting information in a form customized to that particular user. The AG then builds an anticipated dialogue allowing a user to navigate between a personalized set of services each of which presents information and services in a manner customized for that user. Therefore the AG generates in a uniform and consistent manner a finite state dialogue for any task described by a set of specifications residing on a distributed network. Finally a dialogue manager uses a set of protocols to carry out an actual dialogue session with the user. (C) 2003 Elsevier B.V. All rights reserved.;2004
We present a logical approach of spoken language understanding for a human-machine dialogue system. The aim of the analysis is to provide a logical formula or a conceptual graph by assembling concepts related to a delimited application domain. This flexible structure is gradually built during an incremental parsing which is meant to combine syntactic and semantic criteria. Then a contextual understanding step leads to completing this structure. The evaluations of the current system are encouraging. This approach is a preliminary for a logical dialogue that uses the form of the semantic representations.;2004
We present a novel ensemble of six methods for improving the efficiency of chart realization. The methods are couched in the framework of Combinatory Categorial Grammar (CCG) but we conjecture that they can be adapted to related grammatical frameworks as well. The ensemble includes two new methods introduced here-feature-based licensing and instantiation of edges and caching of category combinations-in addition to four previously introduced methods-index filtering LF chunking edge pruning based on n-gram scores and anytime search. We compare the relative contributions of each method using two test grammars and show that the methods work best in combination. Our evaluation also indicates that despite the exponential worst-case complexity of the basic algorithm the methods together can constrain the realization problem sufficiently to meet the interactive needs of natural language dialogue systems.;2004
We present an approach to human-robot interaction through gesture-free spoken dialogue. Our approach is based on passive knowledge rarefication through goal disambiguation a technique that allows a human operator to collaborate with a mobile robot on various tasks through spoken dialogue without making bodily gestures. A key assumption underlying our approach is that the operator and the robot share a common set of goals. Another key idea is that language vision and action share common memory structures. We discuss how our approach achieves four types of human-robot interaction: command goal disambiguation introspection and instruction-based learning. We describe the system we developed to implement our approach and present experimental results.;2004
We present our current state of development regarding animated agents applicable to affective dialogue systems. A new set of tools are under development to support the creation of animated characters compatible with the MPEG-4 facial animation standard. Furthermore we have collected a multimodal expressive speech database including video audio and 3D point motion registration. One of the objectives of collecting the database is to examine how emotional expression influences articulatory patterns to be able to model this in our agents. Analysis of the 3D data shows for example that variation in mouth width due to expression greatly exceeds that due to vowel quality.;2004
When people en-age in conversation they tailor their utterances to their conversational partners whether these partners are other humans or computational systems. This tailoring or adaptation to the partner takes place in all facets of human language use and is based on a mental model or a user model of the conversational partner. Such adaptation has been shown to improve listeners' comprehension their satisfaction with an interactive system the efficiency with which they execute conversational tasks and the likelihood of achieving higher level goals such as changing the listener's beliefs and attitudes. We focus on one aspect of adaptation namely the tailoring of the content of dialogue system utterances for the higher level processes of persuasion argumentation and advice-giving. Our hypothesis is that algorithms that adapt content for these processes according to a user model will improve the usability efficiency and effectiveness of dialogue systems. We describe a multimodal dialogue system and algorithms for adaptive content selection based on multi-attribute decision theory. We demonstrate experimentally the improved efficacy of system responses through the Use Of user models to both tailor the content of system utterances and to manipulate their conciseness. (C) 2004 Cognitive Science Society Inc. All rights reserved.;2004
Whereas existing learning environments on the Web lack high level interactivity we have developed a human tutor-like tutorial conversation system for the Web that enhances educational courseware through mixed-initiative dialog with natural language processing. The conversational tutoring agent is composed of an animated tutor a Latent Semantic Analysis (LSA) module a database with curriculum scripts and a dialog manager. As in the case of human tutors the meaning of learner's contributions in natural language are compared with the content of expected answers to questions or problems specified in curriculum scripts. LSA is used to evaluate the conceptual matches between learner input and tutor expectations whereas the dialog manager determines how the tutor adaptively responds to the learner by selecting content from the curriculum script. The integration of available courseware with the tutorial dialog system guarantees the reusability of existing Web tutorials with minimal effort in the modification of the curriculum script and LSA module. This development thereby simplifies the change into more valuable Web based training courseware. (C) 2003 Elsevier Ltd. All rights reserved.;2004
While most dialogue systems restrict themselves to the adjustment of the propositional contents Pur work concentrates on the generation of stylistic variations in order to improve the user's perception of the interaction. To accomplish this goal our approach integrates a social theory of politeness with a cognitive theory of emotions. We propose a hierarchical selection process for politeness behaviors in order to enable the refinement of decisions in case additional context information becomes available.;2004
With the technical advances and market growth in the field the issues of evaluation and usability of spoken language dialogue systems unimodal as well as multimodal are as crucial as ever. This paper discusses those issues by reviewing a series of European and US projects which have produced major results on evaluation and usability. Whereas significant progress has been made on unimodal spoken language dialogue systems evaluation and usability the emergence of among others multimodal mobile and domain-oriented systems continues to pose entirely new challenges to research in evaluation and usability. (C) 2004 Elsevier B.V. All rights reserved.;2004
Wizard-of-Oz techniques are an important method for collecting data about the behavior of students in tutorial dialogues with computers especially when the interaction is done in natural language. Carrying out such experiments requires dedicated tools but the existing ones have some serious limitations for supporting the development of systems with ambitious natural language capabilities. In order to better meet such demands we have developed DiaWoZ a tool that enables the design and execution of Wizard-of-Oz experiments to collect data from dialogues and to evaluate components of dialogue systems. Its architecture is highly modular and allows for the progressive refinement of the experiments by both designing increasingly sophisticated dialogues and successively replacing simulated components by actual implementations. A first series of experiments carried out with DiaWoZ has confirmed the need for elaborate dialogue models and the incorporation of implemented components for subsequent experiments.;2004
A fundamental requirement of any task-oriented dialogue system is the ability to generate object descriptions that refer to objects in the task domain. The subproblem of content selection for object descriptions in task-oriented dialogue has been the focus of much previous work and a large number of models have been proposed. In this paper we use the annotated coconut corpus of task-oriented design dialogues to develop feature sets based on Dale and Reiter's (1995) incremental model Brennan and Clark's (1996) conceptual pact model and Jordan's (2000b) intentional influences model and use these feature sets in a machine learning experiment to automatically learn a model of content selection for object descriptions. Since Dale and Reiter's model requires a representation of discourse structure the corpus annotations are used to derive a representation based on Grosz and Sidner's (1986) theory of the intentional structure of discourse as well as two very simple representations of discourse structure based purely on recency. We then apply the rule-induction program ripper to train and test the content selection component of an object description generator on a set of 393 object descriptions from the corpus. To our knowledge this is the first reported experiment of a trainable content selection component for object description generation in dialogue. Three separate content selection models that are based on the three theoretical models all independently achieve accuracies significantly above the majority class baseline (17%) on unseen test data with the intentional influences model (42.4%) performing significantly better than either the incremental model (30.4%) or the conceptual pact model (28.9%). But the best performing models combine all the feature sets achieving accuracies near 60%. Surprisingly a simple recency-based representation of discourse structure does as well as one based on intentional structure. To our knowledge this is also the first empirical comparison of a representation of Grosz and Sidner's model of discourse structure with a simpler model for any generation task.;2005
A novel approach to the task of verifying the uttered topic for simple dialogue systems is presented. Confidence measures generated by in-parallel topic-adapted automatic speech recognisers are used. Recognition performance identification of user intention and detection of user-initiated topic change are greatly enhanced most particularly for difficult topics such as proper names or confirmations.;2005
A number of different approaches have been applied to the treatment of errors in spoken dialogue systems including careful design to prevent potential errors methods for on-line error detection and error recovery when errors have occurred and have been detected. The approach to error handling presented here is premised on the theory of grounding in which it is assumed that errors cannot be avoided in spoken dialogue and that it is more useful to focus on methods for determining what information needs to be grounded within a dialogue and how this grounding should be achieved. An object-based architecture is presented that incorporates generic confirmation strategies in combination with domain-specific heuristics that together contribute to determining the system's confirmation strategies when attempting to complete a transaction. The system makes use of a representation of the system's information state as it conducts a transaction along with discourse pegs that are used to determine whether values have been sufficiently confirmed for a transaction to be concluded. An empirical evaluation of the system is presented along with a discussion of the advantages of the object-based approach for error handling. (c) 2005 Elsevier B.V. All rights reserved.;2005
Although syntactic structure has been used in recent work in language modeling there has not been much effort in using semantic analysis for language models. In this study we propose three new language modeling techniques that use semantic analysis for spoken dialog systems. We call these methods concept sequence modeling two-level semantic-lexical modeling and joint semantic-lexical modeling. These models combine lexical information with varying amounts of semantic information using annotation supplied by either a shallow semantic parser or full hierarchical parser. These models also differ in how the lexical and semantic information is combined ranging from simple interpolation to tight integration using maximum entropy modeling. We obtain improvements in recognition accuracy over word and class N-gram language models in three different task domains. Interpolation of the proposed models with class N-gram language models provides additional improvement in the air travel reservation domain. We show that as we increase the semantic information utilized and as we increase the tightness of integration between lexical and semantic items we obtain improved performance when interpolating with class language models indicating that the two types of models become more complementary in nature. (c) 2004 Elsevier Ltd. All rights reserved.;2005
As dialogue systems are widely demanded the research on natural language generation in dialogue has raised interest. Contrary to conventional dialogue systems that reply to the user with a set of predefined answers a newly developed dialogue system generates them dynamically and trains answers to support more flexible and customized dialogues with humans. The paper proposes an evolutionary method for generating sentences using interactive genetic programming. Sentence plan trees which stand for the sentence structure are adopted as the representation of genetic programming. With interactive evolution process with the user a set of customized sentence structures is obtained. The proposed method applies to a dialogue-based travel planning system and the usability test demonstrates the usefulness of the proposed method.;2005
As large-scale deployments of spoken dialog systems in call centers become more common a wealth of information is gathered about the call center business as well as the operation of these systems from their daily logs. This paper describes the VoiceTone Daily News data mining tool for analyzing this information and presenting it in a readily comprehensible and customizable form that is suitable for use by anyone from system designers to call center businesses. Relevant business and dialog features are extracted from the speech logs of caller-system interactions and tracked by trend analysis algorithms. We describe novel techniques for generating alerts on multiple data streams while avoiding redundant knock-on alerts. Some initial experiments with automated measures of dialog success are described as possible additional features to track. Features that move outside their expected bounds on a given day generate headlines as part of a website generated completely automatically from each day's logs. A drill-down facility allows headlines to be investigated all the way to viewing logs of individual interactions behind the headline and listening to the audio for individual turns.;2005
As the information in the internet proliferates the methods for effectively providing the information have been exploited especially in conversational agents. Bayesian network is applied to infer the intention of user's query. Since the construction of Bayesian network requires large efforts and much time an automatic method for it might be useful for applying conversational agents to several applications In order to improve the scalability of the agent in this paper we propose a method of automatically generating Bayesian networks from scripts composing knowledge base of the conversational agent. It constructs the structure of hierarchically composing nodes and learns the conditional probability distribution table using Noisy-OR gate. The experimental results with subjects confirm the usefulness of the proposed method.;2005
At the GU Dialogue Systems Lab in Goteborg we are embedding a conversational agent platform - the CURRENT platform - in the Oz programming language. CURRENT is based on a simple and intuitive characterization of conversational agents as interactive transducers and on the fact that this characterization has a very direct implementation in Oz. Concurrency as offered by Oz allows our agents to 'perceive' 'think' and 'act' at the same time. Concurrency in combination with streams allow our agents to process input in an incremental manner even when the original underlying algorithms are batch-oriented. Concurrency and streams in combination with ports allow us to specify the 'toplevel' transducer as a network of components - an interesting and highly modular architecture. We believe that software tools for specifying networks should have a strong visual aspect and we have developed a 'visual programming language' and an IDE to support it. Also we have found that if we specify the non-visual aspects of transducers and other components as class definitions that inherit the methods responsible for the interpretation of condition-action rules regular expressions grammars dialogue management scripts etc. from (abstract) classes provided by separate modules we are able to hide most of the gory details involving threads streams and ports from the agent developer.;2005
AutoTtitor simulates a human tutor by holding a conversation with the learner in natural language. The dialogue is augmented by an animated conversational agent and three-dimensional (3-D) interactive simulations in order to enhance the learner's engagement and the depth of the learning. Grounded in constructivist learning theories and tutoring research AutoTbtor achieves learning gains of approximately 0.8 sigma (nearly one letter grade) depending on the learning measure and comparison condition. The computational architecture of the system uses the.NET framework and has simplified deployment for classroom trials.;2005
Cluster analysis of dialogs with transport directory service allows revealing the typical scenarios of dialogs which is useful for designing automatic dialog systems. We show how to parameterize dialogs and how to control the process of clustering. The parameters include both data of transport service and features of passenger s behavior. Control of clustering consists in manipulating the parameter s weights and checking stability of the results. This technique resembles Makagonov s approach to the analysis of dweller 9 complaints to city administration. We shortly describe B. Stein s new MajorClust method and demonstrate its work on real person-to-person dialogs provided by Spanish railway service.;2005
Conversational Agent can be useful for providing assistance to naive users on how to use a graphical interface. Such an assistant requires three features: understanding users' requests reasoning and intuitive output. In this paper we introduce the DAFT-LEA architecture for enabling assistant agents to reply to questions asked by naive users about the structure and functioning of graphical interfaces. This architecture integrates via a unified software engineering approach a linguistic parser for the understanding the user's requests a rational agent for the reasoning about the graphical application and a 2D cartoon like agent for the multimodal output. We describe how it has been applied to three different assistance application contexts and how it was incrementally defined via the collection of a corpus of users' requests for assistance. Such an approach can be useful for the design of other assistance applications since it enables a clear separation between the original graphical application its abstract DAFT model and the linguistic processing of users' requests.;2005
Current user interfaces for automated patient and consumer health caresystems can be improved by leveraging the results of several decades of research into effective patient-provider communication skills. A research project is presented in which several such relational skills - including empathy social dialogue nonverbal immediacy behaviors and other behaviors to build and maintain good working relationships over multiple interactions - are explicitly designed into a computer interface within the context of a longitudinal health behavior change intervention for physical activity adoption. Results of a comparison among 33 subjects interacting near-daily with the relational system and 27 interacting near-daily with an identical system with the relational behaviors ablated each for 30 days indicate that the use of relational behaviors by the system significantly increases working alliance and desire to continue working with the system. Comparison of the above groups to another group of 31 subjects interacting with a control system near-daily for 30 days also indicated a significant increase in proactive viewing of health information. (c) 2004 Elsevier Ireland Ltd. All rights reserved.;2005
DaFEx (Database of Facial Expressions) is a database created with the purpose of providing a benchmark for the evaluation of the facial expressivity of Embodied Conversational Agents (ECAs). DaFEx consists of 1008 short videos containing emotional facial expressions of the 6 Ekman's emotions plus the neutral expression. The facial expressions were recorded by 8 italian professional actors (4 male and 4 female) in two acting conditions (utterance and no-utterance) and at 3 intensity levels (high medium low). Very much attention has been paid to image quality and framing. The high number of videos the number of variables considered and the very good video quality make of DaFEx a reference corpus both for the evaluation of ECAs and the research in emotion psychology.;2005
During the last decade research groups as well as a number of commercial software developers have started to deploy embodied conversational characters in the user interface especially in those application areas where a close emulation of multimodal human-human communication is needed. Most of these characters have one thing in common: In order to enter the user's physical world they need to be physical themselves. The paper focuses on challenges that arise when embedding synthetic conversational agents in the user's physical world. We will start from work on synthetic agents that populate virtual worlds and anthropomorphic robots that inhabit physical worlds and discuss how the two areas need to be combined in order to populate physical worlds with synthetic characters. Finally we will report on so-called traversable interfaces that allow agents to cross the border from the physical space to the virtual space and vice versa.;2005
Embodied interface agents are considered to be a promising interface metaphor of the future since they are widely expected to facilitate HCI and trigger natural communication. Although first evaluations indicate that virtual characters have various strong effects it is still unknown if and how embodied conversational agents affect the way in which users communicate with the technological system. An experimental study was conducted to analyze if users interact differently when confronted with different kinds of interfaces (GUI speech output embodied interface agent) of a TV-VCR-System. 65 participants were asked to solve different tasks choosing either natural speech or remote control as input devices. Results show that a system A significantly more often addressed by natural speech when an embodied interface agent is visible. Additional qualitative analyses of the semantic content of all 943 speech acts indicate that users seem to have a more human-like attitude and behavior towards the system when it is represented by an anthropomorphic agent.;2005
For years people have sought more natural means of communicating with their computers. Many have suggested that interaction with a computer should be as easy as interacting with other people taking advantage of the multimodal nature of human communication. While users should in theory gravitate to such anthropomorphic embodiments quite the contrary has been experienced users generally have been dissatisfied and abandoned their use. This suggests a disconnect between factors that make human-human communication engaging and those used by designers to support human-agent interaction. This paper discusses a set of empirical studies that attempted to replicate human-human non-verbal behaviour. The focus revolved around behaviours that portray a credible facade thereby helping embodied conversational agents (ECAs) to form a successful cooperative dyad with users. Based on a review of the non-verbal literature a framework was created that identified trustworthy and credible non-verbal behaviours across five areas and formed design guidelines for character interaction. The design suggestions for those areas emanating from the facial region were experimentally supported but there was no concordant increase in perceived trust when bodily regions (posture gesture) were added. In addition in examining the importance of demographic elements in embodiment it was found that users prefer to interact with characters that match their ethnicity and are young looking. There was no significant preference for gender. The implications of these results as well as other interesting consequences are discussed.;2005
Humans tend to attribute human qualities to computers. It is expected that people when using their natural communicational skills can perform cognitive tasks with computers in a more enjoyable and effective way. For these reasons human-like embodied conversational agents (ECAs) as component if user interfaces have received a lot of attention. It has been shown that the style of the agent's look and behaviour strongly influences the user's attitude. In this paper we discuss our GESTYLE language making it possible to endow ECAs with style. Style is defined in terms of when and how the ECA uses certain gestures and how it modulates its speech (e.g. to indicate emphasis or sadness). There are also GESTYLE tags to annotate text which has to be uttered by an ECA to prescribe the usage of hand head and facial gestures accompanying the speech in order to augment the communication. The annotation ranges from direct low level (e.g. perform a specific gesture) to indirect high level (e.g. take turn in a conversation) instructions which will be interpreted with respect to the style defined. Using style dictionaries and defining different aspects like age and culture of an ECA it is possible to tune behaviour of an ECA to suit a given user or target group the best. (C) 2004 Elsevier Ltd. All rights reserved.;2005
In e-commerce it is often crucial to provide customers a large choice of relevant offers. Users however seldom provides complete and comprehensive descriptions of their desires therefore user interfaces are needed that can generate automatically expanded queries to the product database and proactively enrich the ongoing dialogue with recommendations of suitable products. Automatic query expansion is mostly based on thesaurus and/or user profiles. In e-commerce applications specific thesauri reflecting the webstore's product categories are desirable. This work describes a method for the automatic construction of a thesaurus based on existing categories of documents. A clustering algorithm the Layer-Seeds method is introduced which facilitates the automatic generation of thesaurus reflecting the specific vocabulary occurring in a given collection of documents. The clustering works on terms extracted from the documents in a certain category and organizes them in a tree-like hierarchical structure-a thesaurus. The thesaurus is then employed for automatic query expansion in an e-commerce application in order to obtain better results for product searching. Experiments yield evidence that a significant increase of user satisfaction is achieved.;2005
In human-computer interaction people often interpret the interaction with the computer as interactions with humans. The social agency theory suggests that social cues like the face and voice of the agent motivate this interpretation. In two off-line experiments in which comprehension scores and liking ratings were collected we found that participants preferred natural agents with natural voices as predicted by the social-cue hypothesis. Although female agents with male voices formed an exception this was explained by a stereotype effect. These findings support the social-cue hypothesis and the social agency theory that human characteristics are applied in the perception of computational animated conversational agents. Copyright (c) 2005 John Wiley & Sons Ltd.;2005
In this article we describe how Java can be used to implement an object-based cross-domain mixed initiative spoken dialogue manager (DM). We describe how dialogue that crosses between several business domains can be modelled as an inheriting and collaborating suite of objects suitable for implementation in Java. We describe the main features of the Java implementation and how the Java dialogue manager can be interfaced via the Galaxy software hub as used in the DARPA-sponsored Communicator projects in the United States with the various off-the-shelf components that are needed in a complete end-to-end spoken dialogue system. We describe the interplay of the Java components in the course of typical dialogue turns and present an example of the sort of dialogue that the Java DM can support. (C) 2004 Elsevier B.V. All rights reserved.;2005
In this article we present Gamble a small game of dice that is played by two users and an embodied conversational agent (ECA). By its abilities to communicate and collaborate an ECA is well suited for engaging users in entertaining social interactions. Gamble is used as a test bed for such multiuser interactions. The description of the system's components and a thorough analysis of the agent's behavior control mechanisms is followed by insights gained from a first user study.;2005
In this contribution we look back on the last years in the history of telephone-based speech dialog systems. We will start in 1993 when the world wide first natural language understanding dialog system using a mixed-initiative approach was made accessible for the public the well-known EVAR system from the Chair for Pattern Recognition of the University of Erlangen-Nuremberg. Then we discuss certain requirements we consider necessary for the successful application of dialog systems. Finally we present trends and developments in the area of telephone-based dialog systems.;2005
In this letter Bayes-based confidence measure (BBCM) in speech recognition is proposed. BBCM is applicable to any standard word feature and makes use of information about the speech recognition engine performance. In contrast to ordinary confidence measures BBCM is a probability which is interesting itself from the practical and theoretical point of view. If applied with word density confidence measure (WDCM) BBCM dramatically improves the discrimination ability of the false acceptance curve when compared to WDCM itself.;2005
In this paper we discuss methods for creating avatars that use knowledge cards which are used in the EgoChat system. These avatars are agents acting in place of their creators capable of holding conversations with other users. In the method we propose the avatar's conversational content is structured in the form of what we call knowledge cards which are semantically tagged text fragments by handling both avatar statements and user statements as knowledge cards that can be handled in the same way the person behind an avatar can easily predict the content of a conversation conducted between another user and the agent also simplifying the task of producing content for conversational production. This is because a conversation in the form of knowledge cards is essentially a matter of combining existing text fragments. In order for a conversational agent to be used in real life it would need to be continuously updated in its conversational content in response to the reactions of other users changing circumstances and so on. The system we propose maintains a log of conversations the avatar holds with users assisting in the task of updating the conversational contents. (C) 2004 Wiley Periodicals Inc.;2005
In this paper we investigate the role of user emotions in human-machine goal-oriented conversations. There has been a growing interest in predicting emotions from acted and non-acted spontaneous speech. Much of the research work has gone in determining what are the correct labels and improving emotion prediction accuracy. In this paper we evaluate the value of user emotional state towards a computational model of emotion processing. We consider a binary representation of emotions (positive vs. negative) in the context of a goal-driven conversational system. For each human-machine interaction we acquire the temporal emotion sequence going from the initial to the final conversational state. These traces are used as features to characterize the user state dynamics. We ground the emotion traces by associating its patterns to dialog strategies and their effectiveness. In order to quantify the value of emotion indicators we evaluate their predictions in terms of speech recognition and spoken language understanding errors as well as task success or failure. We report results on the 11.5K dialog corpus samples from the How may I Help You? corpus.;2005
In this paper we investigate the usability of speech-centric multimodal interaction by comparing two systems that support the same unfamiliar task viz. bathroom design. One version implements a conversational agent (CA) metaphor while the alternative one is based on direct manipulation (DM). Twenty subjects 10 males and 10 females none of whom had recent experience with bathroom (re-)design completed the same task with both systems. After each task we collected objective measures (task completion time task completion rate number of actions performed speech and pen recognition errors) and subjective measures in the form of Likert Scale ratings. We found that the task completion rate for the CA system is higher than for the DM system. Nevertheless subjects did not agree on their preference for one of the systems: those subjects who were able to use the DM system effectively preferred that system mainly because it was faster for them and they felt more in control. We conclude that for multimodal CA systems to become widely accepted substantial improvements in system architecture and in the performance of almost all individual modules are needed. (C) 2005 Elsevier B.V. All rights reserved.;2005
In this paper we present a modal semantics for our approach based on social commitments and arguments for conversational agents. Our formal framework based on this approach uses three basic elements: social commitments actions that agents apply to these social commitments and arguments that agents use to support their actions. This framework called Commitment and Argument Network (CAN) formalizes the agents' interactions as a network in which agents manipulate commitments and arguments. More precisely we propose a logical model (called DCTL*(CAN)) based on CTL* and on dynamic logic for this framework. The advantage of this logical model is to bring together social commitments actions argumentation relations and the relations existing between these three elements within the same framework. Our semantics makes it possible to represent the dynamics of agent communication. It also allows us to establish the important link between social commitments as a deontic concept and arguments. The final objective of this paper is to propose a unified framework for pragmatics and semantics of agent communication by defining logic-based protocols.;2005
In this paper we present a two-steps approach towards the creation of affective Embodied Conversational Agents (ECAs): annotation of a real-life non-acted emotional corpus and animation by copy-synthesis. The basis of our approach is to study how coders perceive and annotate at several levels the emotions observed in a corpus of emotionally rich TV video interviews. We use their annotations to specify the expressive behavior of an agent at several levels. We explain how such an approach can be useful for providing knowledge as input for the specification of non-basic patterns of emotional behaviors to be displayed by the ECA (e.g. which perceptual cues and levels of annotation are required for enabling the proper recognition of the emotions).;2005
In this paper we present an Embodied Conversational Agent (ECA) model able to display rich verbal and non-verbal behaviors. The selection of these behaviors should depend not only on factors related to her individuality such as her culture her social and professional role her personality but also on a set of contextual variables (such as her interlocutor the social conversation setting) and other dynamic variables (belief goal emotion). We describe the representation scheme and the computational model of behavior expressivity of the Expressive Agent System that we have developed. We explain how the multi-level annotation of a corpus of emotionally rich TV video interviews can provide context-dependent knowledge as input for the specification of the ECA (e.g. which contextual cues and levels of representation are required for enabling the proper recognition of the emotions).;2005
In this paper we present an evaluation study for DaFEx (Database of Facial Expressions) a database created with the purpose of providing a benchmark for the evaluation of the facial expressivity of Embodied Conversational Agents (ECAs). DaFEx consists of 1008 short videos containing emotional facial expressions of the 6 Ekman's emotions plus the neutral expression. The facial expressions were recorded by 8 professional actors (male and female) in two acting conditions (utterance and non utterance) and at 3 intensity levels (high medium low). The properties of DaFEx were studied by having 80 subjects classify the emotion expressed in the videos. We tested the effect of the intensity level of the articulatory movements due to speech and of the actors' and subjects' gender on classification accuracy. We also studied the way error distribute across confusion classes. The results are summarized in this work.;2005
In this paper I present a computational approach to understanding and augmenting the conversational knowledge process that is a collective activity for knowledge creation management and application where conversational communications are used as a primary means of interaction among participating agents. The key idea is conversation quantization a technique of approximating a continuous flow of conversation by a series of conversation quanta that represent points of the discourse. Conversation quantization enables to implement a rather robust conversational system by basing it on a large amount of conversational quanta collected from the real world. I survey major results concerning capturing accumulating presenting and understanding conversation quanta.;2005
In this paper the authors propose a technique for generating creative conversations between users and multiple agents to support knowledge creation in a community. First they describe self-expressing alter-ego agents as user proxies. An alter-ego agent accumulates statements that were originated by the user in past conversations as self-expressions and converses with other alter-ego agents by outputting these again in a manner adapted to the circumstances. Next the authors describe the EgoChat system which is an environment for conversations between alterego agents and users and a framework for supporting knowledge creation by using EgoChat. Finally they examine and discuss methods of evaluating this technique based on conversation examples using EgoChat. (c) 2005 Wiley Periodicals Inc.;2005
In this paper the speech understanding problem in the context of a spoken dialogue system is formalized in a maximum likelihood framework. Off-line adaptation of stochastic language models that interpolate dialogue state specific and general application-level language models is proposed. Word and dialogue-state n-grams are used for building categorical understanding and dialogue models respectively. Acoustic confidence scores are incorporated in the understanding formulation. Problems due to data sparseness and out-of-vocabulary words are discussed. The performance of the speech recognition and understanding language models are evaluated with the Carmen Sandiego multimodal computer game corpus. Incorporating dialogue models reduces relative understanding error rate by 15%-25% while acoustic confidence scores achieve a further 10% error reduction for this computer gaming application.;2005
In this paper we describe an experiment we conducted to determine the user's level of engagement in a multi-party scenario consisting of human and synthetic interlocutors. In particular we were interested in the question of whether humans accept a synthetic agent as a genuine conversational partner that is worthy of being attended to in the same way as the human interlocutors. We concentrated on gaze behaviors as one of the most important predictors of conversational attention. Surprisingly humans paid more attention to an agent that talked to them than to a human conversational partner. No such effect was observed in the reciprocal case namely when humans addressed an agent as opposed to a human interlocutor.;2005
In this paper we describe an exploratory study to develop a model of visual attention that could aid automatic interpretation of exophors in situated dialog. The model is intended to support the reference resolution needs of embodied conversational agents such as graphical avatars and robotic collaborators. The model tracks the attentional state of one dialog participant as it is represented by his visual input stream taking into account the recency exposure time and visual distinctness of each viewed item. The model correctly predicts the correct referent of 52% of referring expressions produced by speakers in human-human dialog while they were collaborating on a task in a virtual world. This accuracy is comparable with reference resolution based on calculating linguistic salience for the same data.;2005
In this paper we introduce probabilistic model based architecture for error handling in human-robot spoken dialogue systems under adverse audio conditions. In this architecture a Bayesian network framework is used for interpretation of multi-modal signals in the spoken dialogue between a tour-guide robot and visitors in mass exhibition conditions. In particular we report on experiments interpreting speech and laser scanner signals in the dialogue management system of the autonomous tour-guide robot RoboX successfully deployed at the Swiss National Exhibition (Expo.02). A correct interpretation of a user's (visitor's) goal or intention at each dialogue state is a key issue for successful voice-enabled communication between tour-guide robots and visitors. To infer the visitors' goal under the uncertainty intrinsic to these two modalities we introduce Bayesian networks for combining noisy speech recognition with data from a laser scanner which are independent of acoustic noise. Experiments with real-world data collected during the operation of RoboX at Expo.02 demonstrate the effectiveness of the approach in adverse environment. The proposed architecture makes it possible to model error-handling processes in spoken dialogue systems which include complex combination of different multi-modal information sources in cases where such information is available. (c) 2005 Elsevier B.V. All rights reserved.;2005
In this paper we present a game of dice that combines multi-party communication with a tangible interface. The game has been used as a testbed to study typical conversational behavior patterns in interactions between human users and synthetic agents. In particular we were interested in the question to what extent the interaction with the agent can be considered as natural. As an evaluation criterion we propose to investigate whether the communicative behaviors of humans differ when conversing with an agent as opposed to conversing with other humans.;2005
In this paper we present an approach of integrating SIP (Session Initiation Protocol) in converged multimodal/multimedia communication services. An extensible VoIPTeleserver for VoIP in SIP environment is described. It is based on the concept of dialogue system and Web convergence that separates the channel dependent media resources from the application dependent service creation and hosting environment. It supports XML based service applications for multiple channels including voice DTMF IM and chat over IP. The loosely coupled open architecture in our approach is highly extensible. We describe the concept and structure of VoIPTeleServer used in our approach in detail which interfaces to the VoIP world through SIP signaling and works as a broker between the VoIP SIP environment and MTIP to deliver converged communication services. A prototype of VoIPTeleServer was implemented and services and applications based on SIP and MTIP convergence are constructed. Special attention is given to the adverse effect of delay jitter and packet loss for voice portal services over IP. In particular case studies of DTMF service in voice portal under adverse channel conditions are performed. The compounding effects of multiple channel impairments to DTMF in voice portal services over IP are characterized. The potential high error rate of the DTMF service indicates that the data redundancy method as proposed in RFC 2198 is needed for DTMF in order to achieve reliable voice portal services over IP.;2005
In this study an explorative experiment was conducted in which subjects were asked to give route directions to each other in a simulated campus (similar to Map Task). In order to elicit error handling strategies a speech recogniser was used to corrupt the speech in one direction. This way data could be collected on how the subjects might recover from speech recognition errors. This method for studying error handling has the advantages that the level of understanding is transparent to the analyser and the errors that occur are similar to errors in spoken dialogue systems. The results show that when subjects face speech recognition problems a common strategy is to ask task-related questions that confirm their hypothesis about the situation instead of signalling non-understanding. Compared to other strategies such as asking for a repetition this strategy leads to better understanding of subsequent utterances whereas signalling non-understanding leads to decreased experience of task success. (c) 2005 Elsevier B.V. All rights reserved.;2005
In this work we propose an interpretation of the LSA framework which leads to a data-driven conceptual space creation suitable for an intuitive conversational agent. The proposed approach allows overcoming the limitations of traditional rule-based chat-bots leading to a more natural dialogue.;2005
In this work we present an approach to take advantage of confidence measures obtained during the recognition and understanding processes of a dialog system in order to guide the behavior of the dialog manager. Our approach allows the system to ask the user for confirmation about the data which have low confidence values associated to them after the recognition or understanding processes. This technique could help to protect the system from recognition or understanding errors. Although the number of confirmation turns could increase it would be less probable for the system to consider data with a low confidence value as correct. The understanding module and the dialog manager that we have used are modelled by stochastic automata and some confidence measures are proposed for the understanding module. An evaluation of the behavior of the dialog system is also presented. (c) 2004 Elsevier B.V. All rights reserved.;2005
In virtue of great progress in computer graphics technologies CG movies have been getting popular. However cinematography techniques which contribute to improving the contents' comprehensibility need to be learned from professional experiences and not easily acquired by non-professional people. This paper focuses on film cutting as one of the most important cinematography techniques in conversational scenes and presents a system that automatically generates shot transitions to improve comprehensibility of CG contents. First we propose a cognitive model of User Involvement serving as constraints on selecting shot transitions. Then to examine the validity of the model we analyze shot transitions in TV programs and based on the analysis we implement a CG contents creation system. Results of our preliminary evaluation experiment show the effectiveness of the proposed method specifically in enhancing contents' comprehensibility.;2005
Knowledge discovery for personalizing the product recommendation task is a major focus of research in the area of conversational recommender systems to increase efficiency and effectiveness. Conversational recommender systems guide users through a product space alternatively making product suggestions and eliciting user feedback. Critiquing is a common and powerful form of feedback where a user can express her feature preferences by applying a series of directional critiques over recommendations instead of providing specific value preferences. For example a user might ask for a 'less expensive' vacation in a travel recommender thus 'less expensive' is a critique over the price feature. The expectation is that on each cycle the system discovers more about the user's soft product preferences from minimal information input. In this paper we describe three different strategies for knowledge discovery from user preferences that improve recommendation efficiency in a conversational system using critiquing. Moreover we will demonstrate that while the strategies work well separately their combined effort has the potential to considerably increase recommendation efficiency even further.;2005
Mace the new version of our open source platform independent toolkit for developing 3D embodied conversational agents is presented. The toolkit currently incorporates four pieces of software. The core Mace library is for developers who want to embed 3D facial animation to their applications. XfaceEd editor provides an easy to use interface to generate MPEGA ready meshes from static 3D models. Xface-Player is a sample application that demonstrates the toolkit in action and XfaceClient is used as the communication controller over network.;2005
One important component of interactive systems is the generation component. While template-based generation is appropriate in many cases (for example task oriented spoken dialogue systems) interactive question answering systems require a more sophisticated approach. In this paper we propose and compare two example-based methods for generation of information seeking questions.;2005
One of the major problems of user's interaction with Embodied Conversational Agents (ECAs) is to have the conversation last more than few second: after being amused and intrigued by the ECAs users may find rapidly the restrictions and limitations of the dialog systems they may perceive the repetition of the ECAs animation they may find the behaviors of ECAs to be inconsistent and implausible etc. We believe that some special links or bonds have to be established between users and ECAs during interaction. It is our view that showing and/or perceiving interest is the necessary premise to establish a relationship. In this paper we present a model of an ECA able to establish maintain and end the conversation based on its perception of the level of interest of its interlocutor.;2005
One of the major problems that might hinder the construction of the knowledge society on the information network is what I call the understanding and communication bottlenecks which might be caused by the limitation of human cognitive capability. In this paper I present Communicative Intelligence as a step towards solving the understanding and communication bottleneck by inventing communicative artifacts that enable people and artifacts to interact with each other in a natural fashion. I focus on conversational communications in particular for conversation is the most natural means for communication. I believe that making conversation-rich community contributes a lot to resolve the understanding and communication bottlenecks. Intelligent media technology aims at inventing communicative artifacts which allow people and artifacts to interact with each other in a natural fashion and thereby enable conversation-rich knowledge society. It consists of five subfields: conversation measurement and analysis conversational artifacts conversational environment design conversational contents and applied conversational systems. I will overview major results obtained in each subfield.;2005
Present agent and interaction (agent communication language: ACL) models have been conceived for pure artificial agent communities most often strongly linked with knowledge exchange. But these models are not adapted to conversational interactions and particularly to mixed community melting artificial and human agents. We first underline these model limitations. We propose a first step towards a conversational agent language fitting with a BDI agent model in respect with Speech Acts Theory and integrating essential elements of the conversational background. This proposition is a continuation of Chaib-draa and Vanderveken's work [1] on a recursive semantics for ACL according to the situation calculus.;2005
Questions have been analyzed in Estonian information dialogues with the purpose of finding out the linguistic features that can be used in automatic recognition of various types of questions. Information questions (i.e. the questions that are used for requesting information) and questions that initiate solving communication problems are considered. The study shows which types of questions (wh-question open and closed yes/no question question that offers answer alternative question) are preferred in both cases. The results can be implemented in a dialogue system which performs the role of information provider and interacts with a user in Estonian.;2005
Recent advances in automatic speech recognition and related technologies allow computers to carry on conversations by telephone. We developed an intelligent dialogue system that interacts with hypertensive patients to collect data about their health status. Patients thus avoid the inconvenience of traveling for frequent face to face visits to monitor the clinical variables they can easily measure at home the physician is facilitated in acquiring patient information and cardiovascular risk which is evaluated from the data according to noted guidelines. Controlled trials to assess the clinical efficacy are under way. (C) 2004 Elsevier Ireland Ltd. All rights reserved.;2005
Recently Italian Universities promoted interventions in order to improve tutoring and orientation services for students during their course of studies. The main aim of this directive was to support each student with personalized solution to their problems. In this paper we present MyTutor an Embodied Conversational Agents (ECA) that can be consulted on the student personal device and has the main aim to assist him/her during their studies by providing suggestions regarding the student problems. The paper discusses the design and technical issues involved in developing the architecture of this agent and the plan for evaluation.;2005
Results of a field study of an open-access collaborative virtual environment in actual use suggested that awareness of others significantly increases the level of presence experienced by participants. Given the importance of copresence this paper argues that in the absence of other human collaborators in a collaborative virtual environment copresence can potentially be simulated using agent technology. A controlled experiment deploying a prototype embodied conversational agent was conducted to investigate the potential of such agents to simulate copresence. This paper briefly introduces the concepts of presence and copresence summarizes experiences drawn from the field study reports on the controlled experiment and discusses its results. Results suggest that even limited copresence as provided by the current prototype agent is sufficient to help users feel presence in the environment.;2005
Speech understanding errors in spoken dialogue systems can be frustrating for users and difficult to recover from in a mixed-initiative spoken dialogue system. Handling such errors requires both detecting error conditions and adjusting the response generation strategy accordingly. In this paper we show that different response wording choices tend to be associated with different user behaviors that can impact word recognition performance in a telephone-based dialogue system. We leverage these findings in a system that integrates an error correction detection module with a modified dialogue strategy in order to drive the response generation module. In a user study we find slight preferences for a dialogue system using this error handling strategy over a simple reprompting strategy. (c) 2004 Elsevier B.V. All rights reserved.;2005
Successful participation in task-oriented inference-rich dialogs requires among other things understanding of specifications implicitly conveyed through the exploitation of parallel structures. Several linguistic operators create specifications of this kind including the other way (a)round vice-versa and analogously unfortunately automatic reconstruction of the intended specification is difficult due to the inherent dependence on given context and domain. We address this problem by a well-informed reasoning process. The techniques applied include building deep semantic representations application of categories of patterns underlying a formal reconstruction and using pragmaticallymotivated and domain-justified preferences. Our approach is not only suitable for improving the understanding in everyday discourse but it specifically aims at extending capabilities in a tutorial dialog system where stressing generalities and analogies is a major concern.;2005
The aim of this study was to empirically evaluate an embodied conversational agent called GRETA in an effort to answer two main questions: (1) What are the benefits (and costs) of presenting information via an animated agent with certain characteristics in a 'persuasion' task compared to other forms of display? (2) How important is it that emotional expressions are added in a way that is consistent with the content of the message in animated agents? To address these questions a positively framed healthy eating message was created which was variously presented via GRETA a matched human actor GRETA's voice only (no face) or as text only. Furthermore versions of GRETA were created which displayed additional emotional facial expressions in a way that was either consistent or inconsistent with the content of the message. Overall it was found that although GRETA received significantly higher ratings for helpfulness and likability presenting the message via GRETA led to the poorest memory performance among users. Importantly however when GRETA's additional emotional expressions were consistent with the content of the verbal message the negative effect on memory performance disappeared. Overall the findings point to the importance of achieving consistency in animated agents. (c) 2005 Elsevier Ltd. All rights reserved.;2005
The H. C. Andersen system revives a famous character and makes it carry out natural interactive conversation for edutainment. We compare results of the structured user interviews from two subsequent user tests of the system.;2005
The importance of automatically recognizing emotions from human speech has grown with the increasing role of spoken language interfaces in human-computer interaction applications. This paper explores the detection of domain-specific emotions using language and discourse information in conjunction with acoustic correlates of emotion in speech signals. The specific focus is on a case study of detecting negative and non-negative emotions using spoken language data obtained from a call center application. Most previous studies in emotion recognition have used only the acoustic information contained in speech. In this paper a combination of three sources of information-acoustic lexical and discourse-is used for emotion recognition. To capture emotion information at the language level an information-theoretic notion of emotional salience is introduced. Optimization of the acoustic correlates of emotion with respect to classification error was accomplished by investigating different feature sets obtained from feature selection followed by principal component analysis. Experimental results on our call center data show that the best results are obtained when acoustic and language information are combined. Results show that combining all the information rather than using only acoustic information improves emotion classification by 40.7% for males and 36.4% for females (linear discriminant classifier used for acoustic information).;2005
The modeling of realistic emotional behavior is needed for various applications in multimodal human-machine interaction such as emotion detection in a surveillance system or the design of natural Embodied Conversational Agents. Yet building such models requires appropriate definition of various levels for representing: the emotional context the emotion itself and observed multimodal behaviors. This paper presents the multi-level emotion and context coding scheme that has been defined following the annotation of fifty one videos of TV interviews. Results of annotation analysis show the complexity and the richness of the real-life data: around 50% of the clips feature mixed emotions with multi-modal conflictual cues. A typology of mixed emotional patterns is proposed showing that cause-effect conflict and masked acted emotions are perceptually difficult to annotate regarding the valence dimension.;2005
The paper concerns the closely related topics of the possibility of machines having identifiable personalities and the possible future legal responsibilities of machines. As win become clear I wish to explore these topics in terms which are basically those of computational linguistics and by 'machines' here I intend software entities rather than robots and in particular the sort of software agents now being encountered on the web ranging at present from technical advisers to mere chatbots. I call them Companions. The body of the paper explores the following related aspects of a Companion in more detail: what kind and level of personality should be in a machine agent so as to be acceptable to a human user more particularly to one who may fear technology and have no experience of it and what levels of responsibility and legal attribution for responsibility can we expect or desire from entities like web agents in the near future?;2005
The principal cause of speech recognition errors is a mismatch between trained acoustic/language models and input speech due to the limited amount of training data in comparison with the vast variation of speech. It is crucial to establish methods that are robust against voice variation due to individuality the physical and psychological condition of the speaker telephone sets microphones network characteristics additive background noise speaking styles and other aspects. This paper overviews robust architecture and modeling techniques for speech recognition and understanding. The topics include acoustic and language modeling for spontaneous speech recognition unsupervised adaptation of acoustic and language models robust architecture for spoken dialogue systems multi-modal speech recognition and speech summarization. This paper also discusses the most important research problems to be solved in order to achieve ultimate robust speech recognition and understanding systems.;2005
The Reflective Tutorial Dialogue System (ReTuDiS) is a system for learner modelling historical text comprehension through reflective dialogue. The system infers learners' cognitive profiles and constructs their learner models. Based on the learner model the system plans the appropriate --personalized for learners-- reflective tutorial dialogue in order to promote their reflection a fact which leads them towards scientific thought. The system consists of two parts: (1) the Diagnosis part and (2) the Reflective Tutorial Dialogue part. In this paper we present the dialogue strategies tactics and plans which are used by the dialogue part for the generation of the appropriate for learners' reflective learning dialogues according to their learner models. Moreover in this paper we present the experts' comments concerning the tutorial dialogue during an experiment.;2005
The taking of initiative has significance in spoken language dialogue systems and in human-computer interaction. A system that takes no initiative may fail to seize opportunities that are important but a system that always takes the initiative may not allow the user to take the actions he favours. We have implemented a mixed-initiative planning system that adapts its strategy to a nested belief model. In simulation the planner's performance was compared to two fixed strategies of always taking the initiative and always declining it and it performed significantly better than both.;2005
The technology of embodied conversational agents provides an attractive approach to achieving natural human-computer interaction if the interaction design is handled sensitively. In view of this we designed and developed an embodied tour guide Elva 'who' is able to engage conversationally with users about gallery exhibits and also capable of behaving non-verbally using gesture and facial expression. The research focuses on the attributes of agent autonomy and believability. To achieve autonomy we present a three-layer architectural design to ensure appropriate coupling between the agent's perception and action. With regard to believability we utilize the notion of schema to support structured and coherent verbal behaviours. We also pay careful attention to the design of non-verbal interactions that establish social facts within the virtual world. A user study was performed to evaluate user satisfaction and agent believability. Copyright (c) 2005 John Wiley & Sons Ltd.;2005
The use of boosting for call classification in spoken language understanding is described in this paper. An extension to the AdaBoost algorithm is presented that permits the incorporation of prior knowledge of the application as a means of compensating for the large dependence on training data. We give a convergence result for the algorithm and we describe experiments on four datasets showing that prior knowledge can substantially improve classification performance.;2005
The way we see the objects around us determines speech and gestures we use to refer to them. The gestures we produce structure our visual perception. The words we use have an influence on the way we see. In this manner visual perception language and gesture present multiple interactions between each other. The problem is global and has to be tackled as a whole in order to understand the complexity of reference phenomena and to deduce a formal model. This model may be useful for any kind of man-machine dialogue system that focuses on deep comprehension. We show how a referring act takes place into a contextual subset of objects called 'reference domain' and we present the 'multimodal reference domain' model that can be exploited in a dialogue system when interpreting.;2005
There is a strong relationship between evaluation and methods for automatically training language processing systems where generally the same resource and metrics are used both to train system components and to evaluate them. To date in dialogue systems research this general methodology is not typically applied to the dialogue manager and spoken language generator. However any metric for evaluating system performance can be used as a feedback function for automatically training the system. This approach is motivated with examples of the application of reinforcement learning to dialogue manager optimization and the use of boosting to train the spoken language generator.;2005
This paper describes a text understanding system for conversational agents. The system resolves zero direct and indirect anaphors in Japanese texts by integrating two sorts of linguistic resources: a hand-annotated corpus with various relations and automatically constructed case frames. The corpus has relevance tags which consist of predicate-argument relations relations between nouns and coreferences and is utilised for learning parameters of the system and testing it. The case frames are indispensable knowledge both for detecting zero/indirect anaphors. and estimating appropriate antecedents. Our preliminary experiments showed promising results.;2005
This paper describes an application of the conversational agent Max in a real-world setting. The agent is employed as guide in a public computer museum where he engages with visitors in natural face-to-face communication provides them with information about the museum or the exhibition and conducts natural small talk conversations. The design of the system is described with a focus on how the conversational behavior is achieved. Logfiles from interactions between Max and museum visitors were analyzed for the kinds of dialogue people are willing to have with Max. Results indicate that Max engages people in interactions where they are likely to use human-like communication strategies suggesting the attribution of sociality to the agent.;2005
This paper describes our research aimed at acquiring a generalized probability model for alternative phonetic realizations in conversational speech. For all of our experiments we utilize the SUMMIT landmark-based speech recognition framework. The approach begins with a set of formal context-dependent phonological rules applied to the baseforms in the recognizer's lexicon. A large speech corpus is phonetically aligned using a forced recognition procedure. The probability model is acquired by observing specific realizations expressed in these alignments. A set of context-free rules is used to parse words into substructure in order to generalize context-dependent probabilities to other words that share the same sub-word context. The model maps phones to sub-word units probabilistically in a finite state transducer framework capturing phonetic predictions based on local phonemic morphologic and syllabic contexts. We experimented within two domains: the MERCURY flight reservation domain and the JUPITER weather domain. The baseline system used the same set of phonological rules for lexical expansion but with no probabilities for the alternates. We achieved 14.4% relative reduction in concept error rate for JUPITER and 16.5% for MERCURY. (c) 2005 Elsevier B.V. All rights reserved.;2005
This paper describes research into audiovisual cues to communication problems in interaction between users and a spoken dialogue system. The study consists of two parts. First we describe a series of three perception experiments in which subjects are offered film fragments (without any dialogue context) of speakers interacting with a spoken dialogue system. In half of these fragments the speaker is or becomes aware of a communication problem. Subjects have to determine by forced choice which are the problematic fragments. In all three tests subjects are capable of performing this task to some extent but with varying levels of correct classifications. Second we report results of an observational analysis in which we first attempt to relate the perceptual results to visual features of the stimuli presented to subjects and second to find out which visual features actually are potential cues for error detection. Our major finding is that more problematic contexts lead to more dynamic facial expressions in line with earlier claims that communication errors lead to marked speaker behaviour. We conclude that visual information from a user's face is potentially beneficial for problem detection. (c) 2004 Elsevier B.V. All rights reserved.;2005
This paper describes the architecture and the implementation of the SAMIR (Scenographic Agents Mimic Intelligent Reasoning) system designed to implement 3D conversational agents. SAMIR uses an XCS classifier system to learn natural facial postures to be shown by the agents during their dialogues with users. An administration program can be run by agent administrators in order to fine-tune the agent knowledge base and emotive responses. It results in a flexible approach to dialogue and facial expressions management fitting the needs of different web applications such as e-shops or digital libraries.;2005
This paper investigates prosodic aspects of turn-taking in conversation with a view to improving the efficiency of identifying relevant places at which a machine can legitimately begin to talk to a human interlocutor. It examines the relationship between interaction control the communicative function of which is to regulate the flow of information between interlocutors and its phonetic manifestation. Specifically the listener's perception of such interaction control phenomena is modelled. Algorithms for automatic online extraction of prosodic phenomena liable to be relevant for interaction control such as silent pauses and intonation patterns are presented and evaluated in experiments using Swedish map task data. We show that the automatically extracted prosodic features can be used to avoid many of the places where current dialogue systems run the risk of interrupting their users as well as to identify suitable places to take the turn.;2005
This paper overviews recent progress in the development of corpus-based spontaneous speech recognition technology. Although speech is in almost any situation spontaneous recognition of spontaneous speech is an area which has only recently emerged in the field of automatic speech recognition. Broadening the application of speech recognition depends crucially on raising recognition performance for spontaneous speech. For this purpose it is necessary to build large spontaneous speech corpora for constructing acoustic and language models. This paper focuses on various achievements of a Japanese 5-year national project Spontaneous Speech: Corpus and Processing Technology that has recently been completed. Because of various spontaneous-speech specific phenomena such as filled pauses repairs hesitations repetitions and disfluencies recognition of spontaneous speech requires various new techniques. These new techniques include flexible acoustic modeling sentence boundary detection pronunciation modeling acoustic as well as language model adaptation and automatic summarization. Particularly automatic summarization including indexing a process which extracts important and reliable parts of the automatic transcription is expected to play an important role in building various speech archives speech-based information retrieval systems and human-computer dialogue systems.;2005
This paper presents a computational model of visual attention incorporating a cognitive imperfection known as inattentional blindness. We begin by presenting four factors that determine successful attention allocation: conspicuity mental workload expectation and capacity. We then propose a framework to study the effects of those factors on an unexpected object and conduct an experiment to measure the corresponding subjective awareness level. Finally we discuss the application of a visual attention model for conversational agents.;2005
This paper presents a new recognition confidence scoring method for unsupervised training of statistical language models in spoken language dialogue systems. Based on the proposed confidence scoring the speech recognition results for untranscribed user utterances are selected for training the statistical language models of speech recognizers. The method uses features that can only be obtained after the dialogue session in addition to other features such as the acoustic scores of recognition results. Experimental results show that the proposed confidence scoring improves correct/incorrect classification of recognition results and that using the language models obtained through our approach results in better recognition accuracy than that achieved by conventional methods. (c) 2005 Elsevier B.V. All rights reserved.;2005
This paper presents a visual editor which supports authors to define the narrative macrostructure of non-linear interactive dramas. This authoring tool was used to represent Propp's narrative macrostructure of Russian fairy tales in non-linear plot graphs. Moreover Propp's thorough characterization of basic narrative constituents by explanations discussions and examples of their different realizations in his corpus is utilized to construct an automatic classification model. A semi-automatic classification supports (i) authors to associate new scenes with basic narrative constituents and (ii) players to control the narrative flow in the story engine. For the latter task the selection of an appropriate plot element and behavioral pattern within the dialog model in response to player interactions is controlled by similarities between stimuli and known realizations of basic narrative constituents or behavioral patterns. This approach tackles the main challenge of interactive drama-to balance interactivity and storyness.;2005
This paper proposes an alternative paradigm for building affective competencies in embodied conversational agents (ECAs). The key feature of this approach -- and the reason for referring to it as an alternative paradigm -entails use of hybrid ECAs that are expressive both autonomously and as pass-through proxies for human communications. The context in which this hybrid ECA paradigm is currently under investigation involves animated pedagogical agents. Other domains for which ECAs are under current and envisioned use however such as medical inter-views may also be appropriate for their application. One critical research question involves testing the conjecture that human affect shared through an agent reverberates to or scaffolds the empathic credibility trustworthiness or effectiveness of the agent when it is functioning autonomously.;2005
This paper proposes two methods to incorporate semantic information into word and concept level confidence measurement. The first method uses tag and extension probabilities obtained from a statistical classer and parser. The second method uses a maximum entropy based semantic structured language model to assign probabilities to each word. Incorporation of semantic features into a lattice posterior probability based confidence measure provides significant improvements compared to posterior probability when used together in an air travel reservation task. At 5% False Alarm (FA) rate relative improvements of 28 % and 61 % in Correct Acceptance (CA) rate are achieved for word level and concept level confidence measurements respectively.;2005
This paper reports an exploration of the concept of social intelligence in the context of designing home dialogue systems for an Ambient Intelligence home. It describes a Wizard of Oz experiment involving a robotic interface capable of simulating several human social behaviours. Our results show that endowing a home dialogue system with some social intelligence will: (a) create a positive bias in the user's perception of technology in the home environment (b) enhance user acceptance for the home dialogue system and (c) trigger social behaviours by the user in relation to the home dialogue system. (c) 2005 Elsevier B.V. All rights reserved.;2005
This paper reports an exploration of the concept of social intelligence in the context of home dialogue systems for an Ambient Intelligence home. It reports a Wizard of Oz experiment involving a robotic interface capable of displaying several human social behaviors. Our results show that endowing a home dialogue system with some social intelligence can (a) create a positive bias in user's perception of technology in the environment (b) increase user acceptance for the home dialogue system and (c) trigger social behaviors of the user towards the home dialogue system.;2005
This study analyzes the impact of transparency strategies on the quality of user responses following system rejections and misunderstandings. The aim of transparency is to make the system visible according to user needs i.e. when the user's system knowledge is not sufficiently comprehensive and/or correct to successfully achieve the current goal. Since system knowledge depends on users' expertise system expectations and system error rank transparency is treated in this study as an adaptable and adaptive feature. Adaptable and adaptive transparency strategies were applied to TRAVELS a spoken dialogue system which enables users to obtain plane and train schedules over the phone. Based on a partial Wizard-of-Oz simulation an empirical assessment indicates the extent to which these transparency strategies can help users to respond appropriately to system errors. (c) 2005 Published by Elsevier B.V.;2005
This study investigates the influence of the speech quality of Embodied Conversational Agents (ECAs) on users' perception behavior and emotions. Twenty-four subjects interacted in a Wizard of Oz (WOZ) setup with two ECAs in two scenarios of a virtual theater partner application. In both scenarios each ECA had three different speech qualities: natural high-quality synthetic and low-quality synthetic. Eye gaze data show that subjects' visual attention was not influenced by ECA's speech quality but by their look. On the other hand subjects' self-report of emotions and verbal descriptions of their perceptions were influenced by ECAs' speech quality. Finally Galvanic Skin Response data were neither influenced by ECAs' look nor by their speech quality. These results stress the importance of the correct matching of the auditory and visual modalities of ECAs and give methodological insights for the assessment of user's perception behavior and emotions when interacting with virtual characters.;2005
This work presents an approach to modeling speech acts and verifying spontaneous speech with disfluency in a spoken dialogue system. According to this approach semantic information syntactic structure and fragment class of an input utterance are statistically encapsulated in a proposed speech act hidden Markov model (SAHMM) to characterize the speech act. An interpolation mechanism is exploited to re-estimate the state transition probability in SAHMM to deal with the problem of disfluency in a sparse training corpus. Finally a Bayesian belief model (BBM) based on latent semantic analysis (LSA) is adopted to verify the potential speech acts and output the final speech act. Experiments were conducted to evaluate the proposed approach using a spoken dialogue system for providing air travel information. A testing database from 25 speakers with 480 dialogues that include 3038 sentences was established and used for evaluation. Experimental results show that the proposed approach identifies 95.3% of speech act at a rejection rate of 5% and the semantic accuracy is 4.2% better than that obtained using a keyword-based system. The proposed strategy also effectively alleviates the disfluency problem in spontaneous speech.;2005
We address the issue of appropriate user modeling to generate cooperative responses to users in spoken dialogue systems. Unlike previous studies that have focused on a user's knowledge we propose more generalized modeling. We specifically set up three dimensions for user models: the skill level in use of the system the knowledge level about the target domain and the degree of urgency. Moreover the models are automatically derived by decision tree learning using actual dialogue data collected by the system. We obtained reasonable accuracy in classification for all dimensions. Dialogue strategies based on user modeling were implemented on the Kyoto City Bus Information System that was developed at our laboratory. Experimental evaluations revealed that the cooperative responses adapted to each subject type served as good guides for novices without increasing the duration dialogue lasted for skilled users.;2005
We developed and studied an experimental system RealTourist which lets a user to plan a conference trip with the help of a remote tourist consultant who could view the tourist's eye-gaze superimposed onto a shared map. Data collected from the experiment were analyzed in conjunction with literature review on speech and eye-gaze patterns. This inspective exploratory research identified various functions of gaze-overlay on shared spatial material including: accurate and direct display of partner's eye-gaze implicit deictic referencing interest detection common focus and topic switching increased redundancy and ambiguity reduction and an increase of assurance confidence and understanding. This study serves two purposes. The first is to identify patterns that can serve as a basis for designing multimodal human-computer dialogue systems with eye-gaze locus as a contributing channel. The second is to investigate how computer-mediated communication can be supported by the display of the partner's eye-gaze.;2005
We have used text graphics and non-speech audio to tutor new users in a spoken dialogue system. The guidance is given by a software tutor a software component that interactively tutors the user. Four different variations of tutoring were implemented and experiences were collected from user tests in order to gain insights into these tutoring concepts. Real-time visualization of speech interaction with comic book style balloons and structured guidance were received well while various other methods received mixed acceptance.;2005
We investigate the reasons behind students' different responses to human versus machine tutors and explore possible solutions that will motivate students to offer more elaborated responses to computerized tutoring systems and ultimately behave in a more learning oriented manner. We focus upon two sets of variables one surrounding the students' perceptions of tutor qualities and the other surrounding the conversational dynamics of the dialogues themselves. We offer recommendations based on our empirical investigations.;2005
We present a novel approach to developing interfaces for multi-application dialogue systems. The targeted interfaces allow transparent switching between a large number of applications within one system. The approach based on the Rapid Dialogue Prototyping Methodology (RDPM) and the Vector Space Model techniques is composed of three main steps: (1) producing finalized dialogue models for applications using the RDPM (2) designing an application interaction hierarchy and (3) navigating between the applications based on the user's application of interest.;2005
We propose a method to speed up reinforcement learning of policies for spoken dialogue systems. This is achieved by combining a coarse grained abstract representation of states and actions with learning only in frequently visited states. The value of unsampled states is approximated by a linear interpolation of known states. Experiments show that the proposed method effectively optimizes dialogue strategies for frequently visited dialogue states.;2005
We propose an architecture of an embodied conversational agent that takes into account two aspects of emotions: the emotions triggered by an event (the felt emotions) and the expressed emotions (the displayed ones) which may differ in real life. In this paper we present a formalization of emotion eliciting-events based on a model of the agent's mental state composed of beliefs choices and uncertainties. This model enables to identify the emotional state of an agent at any time. We also introduce a computational model based on fuzzy logic that computes facial expressions of emotions blending. Finally examples of facial expressions resulting from the implementation of our model are shown.;2005
We report on an effort to combine methods from storytelling and multimodal dialogue systems research to achieve flexible and immer-sive performances involving believable virtual characters conversing with human users. The trade-off between narrative control and character autonomy is exemplified in a game scenario.;2005
While many successful spoken dialog systems have been deployed over telephone networks in recent years the high cost of developing such applications has led to limited adoption. Despite large research efforts in user-initiative and mixed-initiative systems most commercial applications follow a system initiative approach because they are simpler to design and are found to work adequately. Yet even designing such system-initiative spoken dialog systems has proven costly when compared with simpler touchtone systems. To address this issue we describe in this paper our efforts in building diagnostics tools to let nonexperienced speech developers write usable applications without the need for transcribing calls. Our approach consists of two steps. In the first step we cluster calls based on Question/Answer (QA) states and transitions analyze the success rates associated with each QA state and transition and identify the most problematic QA states and transitions based on a criterion we call Arc Cut Gain in Success Rate (ACGSR). In the second step we cluster calls associated with problematic QA transitions through an approach we term Interactive Clustering (IC). The purpose of this step is to automatically cluster calls that are similar to those already labeled by the developers to maximize productivity. Experiments on an internal auto-attendant application show that our approach can significantly reduce the time and effort needed to identify problems in spoken dialog applications.;2005
Within the field of Embodied Conversational Agents (ECAs) the simulation of emotions has been suggested as a means to enhance the believability of ECAs and also to effectively contribute to the goal of more intuitive human-computer interfaces. Although various emotion models have been proposed results demonstrating the appropriateness of displaying particular emotions within ECA applications are scarce or even inconsistent. Worse questionnaire methods often seem insufficient to evaluate the impact of emotions expressed by ECAs on users. Therefore we propose to analyze non-conscious physiological feedback (bio-signals) of users within a clearly arranged dynamic interaction scenario where various emotional reactions are likely to be evoked. In addition to its diagnostic purpose physiological user information is also analyzed online to trigger empathic reactions of the ECA during game play thus increasing the level of social engagement. To evaluate the appropriateness of different types of affective and empathic feedback we implemented a cards game called Skip-Bo where the user plays against an expressive 3D humanoid agent called Max which was designed at the University of Bielefeld [6] and is based on the emotion simulation system of [2]. Work performed at the University of Tokyo and NII provided a real-time system for empathic (agent) feedback that allows one to derive user emotions from skin conductance and electromyography [13]. The findings of our study indicate that within a competitive gaming scenario the absence of negative agent emotions is conceived as stress-inducing and irritating and that the integration of empathic feedback supports the acceptance of Max as a co-equal humanoid opponent.;2005
A Conversational Agent Model (CAM) adopts that aspect of the human interface that provides structure for the process of interpreting meaning. The goal of the model is to target those behaviors that regulate and represent information efficiently. The specific CAM is based on the Evolutionary Came Theory that considers an idealized scenario whereby a population of agents (possible behaviors) play an evolutionary game according to a pre-programmed behavior pattern and it is supposed that some evolutionary selection process operates over time on the distribution of behaviors. The selected behaviors interact with human using the interface.;2006
A desktop PC and wire communications net-based traditional studies on pattern recognition and multimodal interaction have some restrictions (e.g. limitation of motion conditionality in space and so on) and general problems according to using of the vision technologies for recognition and representation of the haptic-gesture information. In this paper we propose and implement Multi-Modal Recognition Interface (hereinafter MMRI) integrating speech using Voice-XML and gesture based on wireless networks it have purposes that recognizes and represents the Korean Standard Sign Language (hereinafter KSSL) which is a dialog system and interactive elements in the Korean deaf communities and the need to dialogue with deaf person in their own language sign language is well recognized and is widely accepted as being a positive influence on communication. The advantages of our approach are as follows: 1) it improves efficiency of the MMRI input module according to the technology of wireless communication 2) it shows higher recognition performance than unimodal recognition system 3) it recognizes and represents continuous sign language of users with flexibility in real time and offer to user a wider range of personalized and differentiated information using the MMRI more effectively. Experimental results the MMRI deduces an average recognition rate of 96.23% for significant dynamic and continuous the KSSL and speech of various users.;2006
A low-cost prototyping environment for experimenting with embodied conversational agents is discussed. The platform allows modeling and experimenting with different agent constructs and protocols prior to significant investment in the construction of the agent environment. Problems in the design of such a platform include the substantial number of agent controls needed and the flexibility required to represent the constructs of different theories protocols and target environments as they are introduced and developed. These problems are addressed by augmenting a movie clip manager With a general drawing palette as a design tool. The result is a prototyping environment Which simulates multiple agents on a desktop while allowing arbitrary notational conventions. The current version does not render multiple agents in a shared virtual environment but the protocol-based architecture is amenable to such extensions. In the meantime valuable results regarding the social character Of multiple agent interaction call be explored with the existing tool. Copyright (c) 2006 John Wiley & Sons Ltd.;2006
A solution to the problem of speech recognition with signals distorted by low-bit rate coders is presented in this paper. A model for the coding-decoding distortion a HMM compensation method to include this model and an EM-based adaptation algorithm to estimate this distortion are proposed here. Medium vocabulary continuous-speech speaker-independent recognition experiments with 8 kbps G.729(CS-CELP) 13 kbps RPE-LTP (GSM) 5.3 kbps G723.1 4.8 kbps FS- 1016 and 32 kbps G.726(ADPCM) coders show that the approach described in this paper is able to dramatically reduce the effect of the coding distortion and in some cases gives a word accuracy higher than the baseline system with uncoded speech. Finally the EM estimation algorithm requires only one adapting utterance and the approach described is certainly suitable for dialogue systems where just a few adapting utterances are available.;2006
A study of the interpretation of prosodic features in backchannels (Swedish /a/ and /m/) produced by speech synthesis is presented. The study is part of work-in-progress towards endowing conversational spoken dialogue systems with the ability to produce and use backchannels and other feedback.;2006
Although speech and language processing techniques achieved a relative maturity during the last decade designing a spoken dialogue system is still a tailoring task because of the great variability of factors to take into account. Rapid design and reusability across tasks of previous work is made very difficult. For these reasons machine learning methods applied to dialogue strategy optimization has become a leading subject of researches since the mid 90's. In this paper we describe an experiment of reinforcement learning applied to the optimization of speech-based database querying. We will especially emphasize on the sensibility of the method relatively to the dialogue modeling parameters in the framework of the Markov decision processes namely the state space and the reinforcement signal. The evolution of the design will be exposed as well as results obtained on a simple real application.;2006
An effective solution to the problem of extending a dialogue system to new knowledge domains requires a clear separation between the knowledge and the system: as ontologies are used to conceptualize information they can be used as a means to improve the separation between the dialogue system and the domain information. This paper presents the development of an ontology for the cooking domain to be integrated in a dialog system. The ontology comprehends four main modules covering the key concepts of the cooking domain - actions food recipes and utensils - and three auxiliary modules - units and measures equivalencies and plate types.;2006
Automated dialogue systems delivered over the telephone offer a promising approach to delivering health-related interventions to populations of individuals at low-cost. Over the past two decades an automated telephone system called Telephone-Linked Care or TLC has been successfully designed and evaluated by the authors and their colleagues. This work has resulted in over twenty systems for various health-related conditions and lifestyle behaviors. This paper describes our approach to developing and writing dialogue for these automated telephone systems including determining the program objectives defining the target population and selecting a theory of behavior change to guide the intervention. Both macro and micro issues are considered in constructing dialogue systems that are engaging for the target population easy to use and effective at promoting positive health behaviors and outcomes. (c) 2006 Elsevier Inc. All rights reserved.;2006
Automatic dialogue systems get easily confused if speech is recognized which is not directed to the system. Besides noise or other people's conversation even the user's utterance can cause difficulties when he is talking to someone else or to himself (Off-Talk). In this paper the automatic classification of the user's focus of attention is investigated. In the German SmartWeb project a mobile device is used to get access to the semantic web. In this scenario two modalities are provided speech and video signal. This makes it possible to classify whether a spoken request is addressed to the system or not: with the camera of the mobile device the user's gaze direction is detected in the speech signal prosodic features are analyzed. Encouraging recognition rates of up to 93% are achieved in the speech-only condition. Further improvement is expected from the fusion of the two information sources.;2006
Background: A real-time assessment of patients' experiences is an important methodology for studies in health care quality of life behavioral sciences and new drug and treatment development. Ecological momentary assessment is a methodology that allows for real-time assessment of experience and behavior in a subject's natural environment. Recently electronic data collection techniques have been introduced including systems utilizing interactive voice response. Objective: The objective of this project was evaluation of spoken dialogue methodology for real-time data collection of information from patients for health behavioral and lifestyle studies and monitoring. While the management of the data collection process was Internet-based this additional eHealth communication channel was based on over-the-phone natural language conversation with a dialogue system utilizing automated speech recognition technology. For this study we implemented a dialogue system for patients' assessment and monitoring of chronic pain. Methods: Experimental evaluation of usability of the Pain Monitoring Voice Diary was performed with 24 volunteers. The volunteers were asked to contribute 10 sessions with the system over a period of 2 weeks in practice the number of sessions per subject ranged from 1 to 20. The subjects. were asked to either relate to pain episodes in their past while answering the system's questions or use as a guidance one of nine provided medical scenarios compiled by a pain specialist ranging from migraines and back pain to post-surgical pain (knee injury) and cancer- and chemotherapy-related afflictions. Results: From 24 volunteers we collected a total of 177 dialogue sessions: 171 sessions were completed while the caller hung up in the other 6 sessions. There were a total of 2437 dialogue turns where a dialogue turn corresponds to one system prompt and one user utterance. The data capture rate measuring the percentage of slots filled automatically was 98% while the other 2% were flagged for transcription Among the utterances sent to transcription where the user had opted for the none of those option 70% corresponded to the type of pain slot 20% to the symptoms slot and 10% to the body part slot indicating that those are the grammars with the highest out-of-vocabulary rate. Conclusions: The results of this feasibility study indicated that desired accuracy of data can be achieved with a high degree of automation (98% in the study) and that the users were indeed capable of utilizing the flexible interface the sessions becoming more and more efficient as users' experience increased both in terms of session duration and avoidance of troublesome dialogue situations.;2006
Believable nonverbal behaviors for embodied conversational agents (ECA) can create a more immersive experience for users and improve the effectiveness of communication. This paper describes a nonverbal behavior generator that analyzes the syntactic and semantic structure of the surface text as well as the affective state of the ECA and annotates the surface text with appropriate nonverbal behaviors. A number of video clips of people conversing were analyzed to extract the nonverbal behavior generation rules. The system works in real-time and is user-extensible so that users can easily modify or extend the current behavior generation rules.;2006
Call-routing is the technology of automatically classifying the type of a telephone call from a customer to a business or an institution in order to transmit the call onward to the correct destination. Making transcriptions of calls to provide training data for automatic routing in a particular application requires considerable human effort and it would be highly advantageous for the system to be able to learn how to route calls from training utterances that were not transcribed. This paper introduces several techniques that can be used to build call routers from an untranscribed training set and also without any prior knowledge of the application vocabulary or grammar. The techniques concentrate on identifying sequences of decoded phones that are salient for routing and introduces two methods for doing this using language models that are specifically tailored for the routing task. Despite the fact that the phone recognition error-rate on the calls is over 70% the best system described here achieves a routing error of 13.5% on an 18 route task. (c) 2005 Elsevier B.V. All rights reserved.;2006
Continuations are a well established programming concept allowing to explicitly capture and resume the current program state. They are present in several functional programming languages (such as Scheme) in concurrent models (such as process calculi or Hewitt actor model) and more recently in dynamic programming languages (such as Ruby Smalltalk Python and even Javascript or Java). They have been applied to automaton programming cooperative threads compilation techniques and have lastly raised interest in web application programming. This paper shows how this concept happens to be especially useful and elegant to program agent behaviors (or behavioral components) while increasing code readability and ease of writing. The proposed approach especially facilitates modular interaction protocol implementation one of the main difficulties in conversational agents engineering.;2006
DialogDesigner is an integrated design and development environment that supports dialogue designers in creating an electronic dialogue model writing dialogue snippets running and analysing simulation sessions getting graphical views of the model making automatic evaluation regarding dialogue model well-formedness compiling the model into run-time code and extracting different presentations. DialogDesigner has been used for research purposes as well as in commercial projects. Its primary focus is on providing support for the development process. We explain underlying ideas illustrate the functionality of DialogDesigner and discuss its strengths.;2006
Dialogue systems for health communication hold out the promise of providing intelligent assistance to patients through natural interfaces that require no training to use. But in order to make the development of such systems cost effective we must be able to use generic techniques and components which are then specialized as needed to the specific health problem and patient population. In this paper we describe Chester a prototype intelligent assistant that interacts with its user via conversational natural spoken language to provide them with information and advice regarding their prescribed medications. Chester builds on our prior experience constructing conversational assistants in other domains. The emphasis of this paper is on the portability of our generic spoken dialogue technology and presents a case study of the application of these techniques to the development of a dialogue system for health communication. (c) 2006 Elsevier Inc. All rights reserved.;2006
Domestic appliances have replaced much human labor in the home. But how human do we want these devices to be and how much autonomy do we want to give them? To throw some light on these questions first the use and limitations of conversational agents (natural language interfaces) are discussed. Then some aspects of the experience of families living in a smart house are described and compared with that of employers of servants in 19th-century Britain. On the basis of this research it appears that people do not want household devices to be very human and do not want to give them much autonomy. Designers are recommended to observe two rules: Smart domestic devices should put people firmly in control and should as far as possible be unseen and unheard.;2006
Effective face-to-face conversations are highly interactive. Participants respond to each other engaging in nonconscious behavioral mimicry and backchanneling feedback. Such behaviors produce a subjective sense of rapport and are correlated with effective communication greater liking and trust and greater influence between participants. Creating rapport requires a tight sense-act loop that has been traditionally lacking in embodied conversational agents. Here we describe a system based on psycholinguistic theory designed to create a sense of rapport between a human speaker and virtual human listener. We provide empirical evidence that it increases speaker fluency and engagement.;2006
Embodied conversational agents (ECA's) are cartoon-like characters which interact with users through conversation and gestures on a computer screen. ECA makes human computer interactions more friendly because we can use most human-like communication skills such as natural conversation. ECA's are useful as Web guides by incorporating them into Web browsers. They guide us around Web pages chatting with us. To build such an agent we need to describe a scenario to explain Web pages. Conventionally such scenarios are written manually by developers or programmers using a dialogue description language such as AIML (Artificial Intelligence Markup Language) so it is difficult to update them when Web pages are updated. In this paper we propose a scheme to automatically generate utterances of Web guide agents depending on Web pages. To this end we need to make agents understand the contents of Web pages and to make them talk according to the contents so we utilize RDF (Resource Description Framework) to present the semantic contents of Web pages. To make agents talk according to the contents we utilize a RDF query language SPARQL (Simple Protocol And RDF Query Language) and extend the AIML language to incorporate SPARQL query in it. As a prototype we developed a Web guide system employing an ECA.;2006
Embodied Conversational Agents (ECAs) are computer generated life-like characters that interact with human users in face-to-face conversations. To achieve natural multi-modal conversations ECA systems are very sophisticated and require many building assemblies and thus are difficult for individual research groups to develop. This paper proposes a generic architecture the Universal ECA Framework which is currently under development and includes a blackboard-based platform a high-level protocol to integrate general purpose ECA components and ease ECA system prototyping.;2006
Embodied Conversational Agents (ECAs) with realistic faces are becoming an intrinsic part of many graphics systems employed in HCI applications. A fundamental issue is how people visually perceive the affect of a speaking agent. In this paper we present the first study evaluating the relation between objective and subjective visual perception of emotion as displayed on a speaking human face using both full video and sparse point-rendered representations of the face. We found that objective machine learning analysis of facial marker motion data is correlated with evaluations made by experimental subjects and in particular the lower face region provides insightful emotion clues for visual emotion perception. We also found that affect is captured in the abstract point-rendered representation.;2006
E-therapy offers new means to support smokers during their attempt to quit. An embodied conversational agent can support people as a virtual coach on the internet. In this paper requirements are formulated for such a virtual coach and a global design is proposed. The requirements and the design are based on an extensive analysis of the practice of individual coaching of the Dutch organization STIVORO. In addition the outcomes of a survey research measuring the acceptance of such a virtual coach by a potential user group are described.;2006
Given the value of face-to-face interaction in communication and learning our persistent goal has been to develop evaluate and apply animated agents to produce realistic and accurate speech. We have implemented these agents as computer-assisted speech and language tutors for hard of hearing and autistic children and other children with language challenges. Our language-training program utilizes conversational agents who guide students through a variety of exercises designed to teach vocabulary and grammar to improve speech articulation and to develop linguistic and phonological awareness. We report a new experiment showing its effectiveness for school children learning English as a new language. Some of the advantages of this pedagogy and technology include the popularity and effectiveness of computers and embodied conversational agents the perpetual availability of the program and individualized instruction. Animated tutors offer a promising approach to language learning human-machine interaction and education.;2006
Honorific agreement is one of the main properties of languages like Korean or Japanese playing an important role in appropriate communication. This makes the deep processing of honorific information crucial in various computational applications such as spoken language translation and generation. We argue that contrary to the previous literature an adequate analysis of Korean honorification involves a system that has access not only to morpho-syntax but to semantics and pragmatics as well. Along these lines we have developed a typed feature structure grammar of Korean (based on the framework of HPSG) and implemented it in the Linguistic Knowledge Builder (LKB). The results of parsing our experimental test suites show that our grammar provides us with enriched grammatical information that can lead to the development of a robust dialogue system for the language.;2006
In this article we describe a visual component able to detect and track a human face in video streaming. This component is integrated into an embodied conversational agent. Depending on the presence or absence of a user in front of the camera and the orientation of his head the system begins continues resumes or closes the interaction. Several constraints have been taken into account: a simple webcam a low error rate and a minimum computing time that permits the whole system to run on a simple pc.;2006
In this paper we address the problem of temporal alignment applied to capture communicative gestures conveying different styles. We propose a representation space that may be considered as robust to the spatial variability induced by style. By extending a multilevel dynamic time warping algorithm we show how this extension can fulfil the goals of time correspondence between gesture sequences While preventing jerkiness introduced by standard time warping methods. Copyright (c) 2006 John Wiley & Sons Ltd.;2006
In this paper we deal with learning and forgetting of speech commands in speech dialogue systems. We discuss two mathematical models on learning and four models on forgetting. Furthermore we describe the experiments used to determine the learning and forgetting curve in our environment. These findings are compared to the theoretical models and based on this we deduce the equations that describe learning and forgetting in our automotive environment most adequately.;2006
In this paper we describe the design of a turn manager for deployment in artificial conversational agents using the Harel statechart formalism. We show that the formalism's support for concurrent interrelated processes allows a modular design producing three smaller statecharts responsible for the turn taking logic. The logic of the turn manager is inspired by a well-known. turn management model for human-human conversation.;2006
In this paper we described our initial work on the development of an embodied conversational agent platform. In the present stage our main focus it is on the development of a multimodal input interface to the system. In this paper we will present an Input and Output Manager block that combines speech synthetic talking face text and graphical interfaces. The system support speech input through an ASR and speech output through a TTS synchronized with an animated face. The graphical and text input are feed through a Text Manger that it is a constituent component of the Input and Output Manager block. All the blocks are tailored for the European Portuguese language. The system is analyzed in the framework of the project Interactive Home of the Future.;2006
In this paper we discuss advanced help concepts for speech dialogues. Based on current research results in the field of human-machine-interfaces we describe two advanced help concepts based on hierarchical structuring of help dialogues. Furthermore we explain the test design for our usabilty experiments and present the methods and measures we used to collect our test data. Finally we report the results from our usability tests and discuss our findings.;2006
In this paper we present our recent results in automatic facial gesturing of graphically embodied animated agents. In one case conversational agent is driven by speech in automatic Lip Sync process. By analyzing speech input lip movements are determined from the speech signal. Another method provides virtual speaker capable of reading plain English text and rendering it in a form of speech accompanied by the appropriate facial gestures. Proposed statistical model for generating virtual speaker's facial gestures can be also applied as addition to lip synchronization process in order to obtain speech driven facial gesturing. In this case statistical model will be triggered with the input speech prosody instead of lexical analysis of the input text.;2006
In this paper we address the issue of generating in-domain language model training data when little or no real user data are available. The two-stage approach taken begins with a data induction phase whereby linguistic constructs from out-of-domain sentences are harvested and integrated with artificially constructed in-domain phrases. After some syntactic and semantic filtering a large corpus of synthetically assembled user utterances is induced. In the second stage two sampling methods are explored to filter the synthetic corpus to achieve a desired probability distribution of the semantic content both on the sentence level and on the class level. The first method utilizes user simulation technology which obtains the probability model via an interplay between a probabilistic user model and the dialogue system. The second method synthesizes novel dialogue interactions from the raw data by modelling after a small set of dialogues produced by the developers during the course of system refinement. Evaluation is conducted on recognition performance in a restaurant information domain. We show that a partial match to usage-appropriate semantic content distribution can be achieved via user simulations. Furthermore word error rate can be reduced when limited amounts of in-domain training data are augmented with synthetic data derived by our methods.;2006
In this paper we describe a new interface for a barge-in free spoken dialogue system combining multichannel sound field control and beamforming in which the response sound from the system can be canceled out at the microphone points. The conventional method inhibits a user from moving because the system forces the user to stay at a fixed position where the response sound is reproduced. However since the proposed method does not set control points for the reproduction of the response sound to the user the user is allowed to move. Furthermore the relaxation of strict reproduction for the response sound enables us to design a stable system with fewer loudspeakers than those used in the conventional method. The proposed method shows a higher performance in speech recognition experiments.;2006
In this paper we describe our experience with the design and implementation of an embodied conversational agent (ECA) that converses with users to change their dietary behavior. Our intent is to develop a system that dynamically models the agent and the user and adapts the agent's counseling dialog accordingly. Towards this end we discuss our efforts to automatically determine the user's dietary behavior stage of change and attitude towards the agent on the basis of unconstrained typed text dialog first with another person and then with an ECA controlled by an experimenter in a wizard of Oz study. We describe how the results of these studies have been incorporated into an algorithm that combines the results from simple parsing rules together with contextual features using a Bayesian network to determine user stage and attitude automatically. (c) 2006 Elsevier Inc. All rights reserved.;2006
In this paper we evaluate mass knowledge acquisition using modified ALICE chatterbots. In particular we investigate the potential of allowing subjects to modify chatterbot responses to see if distributed learning from a web environment can succeed. This experiment looks at dividing knowledge into general conversation and domain specific categories for which we have selected telecommunications. It was found that subject participation in knowledge acquisition can contribute a significant improvement to both the conversational and telecommunications knowledge bases. We further found that participants were more satisfied with domain-specific responses rather than general conversation. (c) 2006 Elsevier Ltd. All rights reserved.;2006
In this paper we focus on the notion of Assisting Conversational Agents (ACA) that are embodied agents dedicated to the function of assistance for novice users of software components and/or web services. We discuss the main requirements of such agents and we emphasize the genericity issue arising in the dialogical part of such architectures. This prompts us to propose a mediator-based framework using a dynamic symbolic representation of the runtime of the assisted components. Then we define three strategies for the development of the mediators that are validated by the implementation of experiences taken in various situations.;2006
In this paper we present a complete platform for the semiautomatic and simultaneous generation of human-machine dialog applications in two different and separate modalities (Voice and Web) and several languages to provide services oriented to obtaining or modifying the information from a database (data-centered). Given that one of the main objectives of the platform is to unify the application design process regardless of its modality or language and then to complete it with the specific details of each one the design process begins with a general description of the application the data model the database access functions and a generic finite state diagram consisting of the application flow. With this information the actions to be carried out in each state of the dialog are defined. Then the specific characteristics of each modality and language (grammars prompts presentation aspects user levels etc.) are specified in later assistants. Finally the scripts that execute the application in the real-time system are automatically generated. We describe each assistant in detail emphasizing the methodologies followed to ease the design process especially in its critical aspects. We also describe different strategies and characteristics that we have applied to provide portability robustness adaptability and high performance to the platform. We also address important issues in dialog applications such as mixed initiative and over-answering confirmation handling or providing long lists of information to the user. Finally the results obtained in a subjective evaluation with different designers and in the creation of two full applications that confirm the usability flexibility and standardization of the platform and provide new research directions. (C) 2005 Elsevier B.V. All rights reserved.;2006
In this paper we propose a study of co-verbal gesture properties that could enhance the animation of an Embodied Conversational Agent and their communicative performances. This work is based on the analysis of gesture expressivity over time that we have study from a corpus of 2D animations. First results point out two types of modulations in gesture expressivity that are evaluated on their communicative performances. A model of these modulations is proposed.;2006
In this paper we propose semantic Bayesian networks that infer the user's intention based on Bayesian networks and their semantic information. Since conversation often contains ambiguous expressions managing the context or the uncertainty is necessary to support flexible conversational agents. The proposed method drives the mixed-initiative interaction (MII) that prompts for missing concepts and clarifies for spurious concepts to understand the user's intention correctly. We have applied it to an information retrieval service for Web sites so as to verify the usefulness.;2006
In this study we present a computational approach to support content creation by recording and reusing the conversational contents as reusable nuggets. We introduce the concept of the conversation quantization - a technique for approximating a continuous flow of conversation by a series of conversation quanta that correspond to the points in a discourse. We describe the creation of contents using conversation quanta. To realize the concept of conversation quanta we attempt to manually extract conversation quanta from the videos of some meetings and create the conversational contents. As a result we have confirmed that conversation quanta can be reused as conversational contents such as conversational agents and presentation contents. Further we have obtained valuable insights into the nature of conversation quanta.;2006
In this study we suggest and implement Multi-Modal Sentential Dialog System (MMSDS) integrating 2 sensory channels with speech and haptic information based on ubiquitous computing and WWW for clear communication. The importance and necessity of MMSDS for HCI as following: 1) it can allow more interactive and natural communication functions between the hearing-impaired and hearing person without special learning and education 2) according as it recognizes a sentential Korean Standard Sign Language (KSSL) which is represented with speech and haptics and then translates recognition results into a synthetic speech and visual illustration in real-time it may provide a wider range of personalized and differentiated information more effectively to them and 3) above all things a user need not be constrained by the limitations of a particular interaction mode at any given moment because it can guarantee mobility of WPS (Wearable Personal Station for the post PC) with a built-in sentential sign language recognizer. In experiment results while an average recognition rate of uni-modal recognizer using KSSL only is 93.1% and speech only is 95.5% advanced MMSDS deduced an average recognition rate of 96.1% for 32 sentential KSSL recognition models.;2006
Instant Messaging enables learners and educators to interact in an on-line environment. In this paper we propose an intelligent ChatBot system based on instant messaging for student on-line coaching in an English learning environment. The proposed ChatBot facilitates synchronous communication with students by using ready reference materials including dictionaries authorized conversation material with speaking and a question-answering function. The agent records and analyzes conversations so that the teacher can assess students' progress. Our contribution in this paper is that we integrate the NLP Tool and AIML into an instant messaging-based ChatBot for English as a Second Language programs.;2006
Most areas of the cognitive and social sciences assume that knowledge representations are constructed and used during communication and that much of its content is social. Those of us who build computer models of comprehension and conversation are forced to be explicit about the nature of these knowledge representations and affiliated processes. There are some conditions when knowledge is not sufficiently social and other conditions when knowledge is overly grounded in social mechanisms. The argument is advanced that constraints coherence and precision are very much at the heart of an explanation of the nature and amount of social knowledge. Asocial content reigns supreme when the referential world knowledge is highly constrained coherently structured and precisely specified. The social context of knowledge construction becomes progressively more influential to the extent to that world knowledge is vague open-ended imprecise underspecified and fragmentary.;2006
Most existing multi-modal prototypes enabling users to combine 2D gestures and speech input are task-oriented. They help adult users solve particular information tasks often in 2D standard Graphical User Interfaces. This paper describes the NICE Andersen system which aims at demonstrating multi-modal conversation between humans and embodied historical and literary characters. The target users are 10-18 years old children and teenagers. We discuss issues in 2D gesture recognition and interpretation as well as temporal and semantic dimensions of input fusion ranging from systems and component design through technical evaluation and user evaluation with two different user groups. We observed that recognition and understanding of spoken deictics were quite robust and that spoken deictics were always used in multi-modal input. We identified the causes of the most frequent failures of input fusion and suggest possible improvements for removing these errors. The concluding discussion summarises the knowledge provided by the NICE Andersen system on how children gesture and combine their 2D gestures with speech when conversing with a 3D character and looks at some of the challenges facing theoretical solutions aimed at supporting unconstrained speech/2D gesture fusion. (c) 2006 Elsevier B.V. All rights reserved.;2006
Much of the work on embodied conversational agents is concerned with building computational models of nonverbal behaviors that can generate the right behavior in the appropriate context. In this paper we discuss from a linguistic and a conversation theoretic point of view how nonverbal behaviors in conversations work. We look particularly at gaze and head movements. These play a variety of functions in face-to-face interactions. We show how these functions are structured by general principles governing cooperative actions and symbolic communication.;2006
Multimodal conversational interfaces provide a natural means for users to communicate with computer systems through multiple modalities such as speech and gesture. To build effective multimodal interfaces automated interpretation of user multimodal inputs is important. Inspired by the previous investigation on cognitive status in multimodal human machine interaction we have developed a greedy algorithm for interpreting user referring expressions (i.e. multimodal reference resolution). This algorithm incorporates the cognitive principles of Conversational Implicature and Givenness Hierarchy and applies constraints from various sources (e.g. temporal semantic and contextual) to resolve references. Our empirical results have shown the advantage of this algorithm in efficiently resolving a variety of user references. Because of its simplicity and generality this approach has the potential to improve the robustness of multimodal input interpretation.;2006
Neuroscience and psychology research has demonstrated a close connection between cognition and affect and a number of emotion-induced effects on perception cognition and behavior. The integration of emotions within user models would therefore enhance their realism and fidelity. Emotions can also provide disambiguating information for speech recognition and natural language understanding and enhance the effectiveness of dialogue systems. This paper discusses the motivation and alternatives for incorporating emotions within user models. The paper first identifies key model characteristics that define an analytical framework. The framework provides a basis for identifying the functional and architectural requirements on one hand and alternative modeling approaches on the other thereby laying the groundwork for a set of model development guidelines. The paper then describes examples of existing models for two core affective processes cognitive appraisal and emotion-induced effects on cognition within the context of the analytical framework.;2006
One of the challenges of designing virtual humans is the definition of appropriate models of the relation between realistic emotions and the coordination of behaviors in several modalities. In this paper we present the annotation representation and modeling of multimodal visual behaviors occurring during complex emotions. We illustrate our work using a corpus of TV interviews. This corpus has been annotated at several levels of information: communicative acts emotion labels and multimodal signs. We have defined a copy-synthesis approach to drive an Embodied Conversational Agent from these different levels of information. The second part of our paper focuses on a model of complex (superposition and masking of) emotions in facial expressions of the agent. We explain how the complementary aspects of our work on corpus and computational model is used to specify complex emotional behaviors.;2006
Our objective is to develop a computational model to predict visual attention behavior for an embodied conversational agent. During interpersonal interaction gaze provides signal feedback and directs conversation flow. Simultaneously in a dynamic environment gaze also directs attention to peripheral movements. An embodied conversational agent should therefore employ social gaze not only for interpersonal interaction but also to possess human attention attributes so that its eyes and facial expression portray and convey appropriate distraction and engagement behaviors.;2006
Real life emotions are often blended and involve several simultaneous superposed or masked emotions. This paper reports on a study on the perception of multimodal emotional behaviors in Embodied Conversational Agents. This experimental study aims at evaluating if people detect properly the signs of emotions in different modalities (speech facial expressions gestures) when they appear to be superposed or masked. We compared the perception of emotional behaviors annotated in a corpus of TV interviews and replayed by an expressive agent at different levels of abstraction. The results provide insights on the use of such protocols for studying the effect of various models and modalities on the perception of complex emotions.;2006
Recent interests in conversation in the field of artificial intelligence have expanded beyond the development of particular task-oriented dialogue systems toward technologies for supporting human-human communication in various circumstances. Within such communication supportive approaches the importance of the analysis of multiparty conversation has increasingly been recognized. In accordance with these orientations this article outlines a three-party conversation corpus built by the National Institute of Information and Communications Technology and introduces three preliminary analyses of it that will contribute to the development of Conversational Informatics: The characteristics of turn-taking procedure in three-person conversation assessment sequential patterns that appeared in the data and shared knowledge and interpersonal relationships between participants observable from the assessment sequences in triadic conversation.;2006
Recent work in argumentation theory (Walton and Krabbe 1995 Walton 2005) and artificial intelligence (Bench-Capon 1992 2003 Cawsey 1992 McBurney and Parsons 2002 Bench-Capon and Prakken 2005) uses types of dialogue as contexts of argument use. This paper provides an analysis of a special type called examination dialogue in which one party questions another party sometimes critically or even antagonistically to try to find out what that party knows about something. This type of dialogue is most prominent in law and in both legal and non-legal arguments based on expert opinion. It is also central to dialogue systems for questioning and answering in expert systems in artificial intelligence. Examples studied are: (1) exegetical analyses and criticisms of religious and philosophical texts and (2) legal examinations and cross-examinations conducted in a trial setting. (c) 2006 Elsevier B.V. All rights reserved.;2006
Recently many national and international initiatives show an increasing interest in promoting distance education interventions by Universities. These directives aim at supporting students during their studies providing them with personalized solutions to their problems related not only to the fruition of on-line courses but also to orientation issues. In this paper we present a general architecture of an Embodied Conversational Agent (ECA) that has the main aim to assist students by providing personalized suggestions. This ECA represents the student interface in interacting with a Virtual University environment able to provide different types of services. In particular to support mobility the ECA architecture has been conceived in order to run also on the student handheld device. The paper discusses the design and technical issues involved in developing this personal agent and the results of an evaluation study aiming at assessing the impact of conversational agents on the effectiveness of the interaction.;2006
Researchers are generally trained to administer informed consent by studying approved guidelines but still can fail to satisfactorily answer questions from potential participants. An application using a virtual character allowed novice participants to practice administering informed consent. This character was designed to behave as a potential participant for a study and asked many of the questions research participants typically ask such as queries about the study itself the sponsor timing selection procedures confidentiality voluntariness benefits and risks and contact information. The user responded to the character's queries as if speaking with a true potential research participant. The application was effective even after only brief usage. In a laboratory experiment novice participants who practiced with the virtual character were later more effective in conducting informed consent interviews with a human interviewee than those who were trained only with written materials. Thus simulated learning-by-doing improved informed consent skills. Implications for related health dialog applications are discussed. (c) 2006 Elsevier Inc. All rights reserved.;2006
Sentence similarity measures play an increasingly important role in text-related research and applications in areas such as text mining Web page retrieval and dialogue systems. Existing methods for computing sentence similarity have been adopted from approaches used for long text documents. These methods process sentences in a very high-dimensional space and are consequently inefficient require human input and are not adaptable to some application domains. This paper focuses directly on computing the similarity between very short texts of sentence length. It presents an algorithm that takes account of semantic information and word order information implied in the sentences. The semantic similarity of two sentences is calculated using information from a structured lexical database and from corpus statistics. The use of a lexical database enables our method to model human common sense knowledge and the incorporation of corpus statistics allows our method to be adaptable to different domains. The proposed method can be used in a variety of applications that involve text knowledge representation and discovery. Experiments on two sets of selected sentence pairs demonstrate that the proposed method provides a similarity measure that shows a significant correlation to human intuition.;2006
Since the manual construction of our knowledge-base has several crucial limitations when applied to intelligent systems mental development has been investigated in recent years. Autonomous mental development is a new paradigm for developing autonomous machines which are adaptive and flexible to the environment. Language development a kind of mental development is an important aspect of intelligent conversational agents. In this paper we propose an intelligent conversational agent and its language development mechanism by putting together five promising techniques Bayesian networks pattern matching finite state machines templates and genetic programming. Knowledge acquisition implemented by finite state machines and templates and language learning by genetic programming are developed for language development. Several illustrations and usability tests show the usefulness of the proposed developmental conversational agent.;2006
Speaker's intentions can be represented into domain actions (domainin-dependent speech acts and domain-dependent concept sequences). Therefore domain action classification is very useful to a dialogue system that should catch user's intention in order to generate correct reaction. In this paper we propose a neural network model to determine speech acts and concept sequences at the same time. To avoid biased learning problems the proposed model uses low-level linguistic features and filters out uninformative features using chi(2) statistic. In the experiment the proposed model showed better performances than the previous work in speech act classification. Moreover the proposed model showed meaningful results when the size of training corpus was small. Based on the experimental results we believe that the proposed model will be more helpful to dialogue systems because it manages speech act classification and concept sequence classification at the same time. We also believe that the proposed model can alleviate sparse data problems in speech act classification.;2006
Spoken dialogue systems (SDSs) can be used to operate devices e.g. in the automotive environment. People using these systems usually have different levels of experience. However most systems do not take this into account. In this paper we present a method to build a dialogue system in an automotive environment that automatically adapts to the user's experience with the system. We implemented the adaptation in a prototype and carried out exhaustive tests. Our usability tests show that adaptation increases both user performance and user satisfaction. We describe the tests that were performed and the methods used to assess the test results. One of these methods is a modification of PARADISE a framework for evaluating the performance of SDSs [Walker MA Litman DJ Kamm CA Abella A (Comput Speech Lang 12(3):317-347 1998)]. We discuss its drawbacks for the evaluation of SDSs like ours the modifications we have carried out and the test results.;2006
Spoken dialogue systems can be considered knowledge-based systems designed to interact with users using speech in order to provide information or carry out simple tasks. Current systems are restricted to well-known domains that provide knowledge about the words and sentences the users will likely utter. Basically. these systems rely oil ail input inter-face comprised of speech recogniser and semantic analyser. a dialogue manager and an output interface comprised of response generator and speech synthesiser. As an attempt to enhance the performance (if the input interface this paper proposes a technique based on a new type of speech recogniser comprised of two modules. The first one is a standard speech recogniser that receives the sentence uttered by the user and generates a graph of words. The second module analyses the graph and produces the recognised sentence using the context knowledge provided by the current prompt of the system. We evaluated the performance of two input interfaces working in a previously developed dialogue system: the original interface of the system and a new one that features the proposed technique. The experimental results show that when the sentences uttered by the users are out-of-context analysed by the new interface the word accuracy and sentence understanding rates increase by 93.71 and 77.42% absolute respectively. regarding the original interface. The price to pay for this clear enhancement is a little reduction in the scores when the new interface analyses sentences in-context. as they decrease by 2.05 and 3.41% absolute respectively. in comparison with the original interface. Given that in real dialogues sentences may be out-of-context analysed. specially when they are uttered by inexperienced users. the technique can be very useful to enhance the system performance. (c) 2005 Elsevier B.V. All fights reserved.;2006
Spoken language understanding (SLU) aims at extracting meaning from natural language speech. Over the past decade a variety of practical goal-oriented spoken dialog systems have been built for limited domains. SLU in these systems ranges from understanding predetermined phrases through fixed grammars extracting some predefined named entities extracting users' intents for call classification to combinations of users' intents and named entities. In this paper we present the SLU system of VoiceTone((R)) (a service provided by AT&T where AT&T develops deploys and hosts spoken dialog applications for enterprise customers). The SLU system includes extracting both intents and the named entities from the users' utterances. For intent determination we use statistical classifiers trained from labeled data and for named entity extraction we use rule-based fixed grammars. The focus of our work is to exploit data and to use machine learning techniques to create scalable SLU systems which can be quickly deployed for new domains with minimal human intervention. These objectives are achieved by 1) using the predicate-argument representation of semantic content of an utterance 2) extending statistical classifiers to seamlessly integrate hand crafted classification rules with the rules learned from data and 3) developing an active learning framework to minimize the human labeling effort for quickly building the classifier models and adapting them to changes. We present an evaluation of this system using two deployed applications of VoiceTone((R)).;2006
Students rated 16 tutorial statements on negative politeness (i.e. how much the tutor allows me freedom to make my own decisions) and positive politeness (i.e. how much the tutor was working with me). Consistent with an adaptation of Brown and Levinson's [1987. Politeness: Some Universals in Language Use. Cambridge University Press New York] politeness theory (a) students rated direct commands and commands attributed to machines as lowest in negative and positive politeness (b) students rated guarded suggestions and guarded questions as highest in negative politeness and guarded suggestions and statements expressing a common goal as highest in positive politeness and (c) the pattern of results was stronger for students with low rather than high computing experience. Results have implications for designing polite conversational agents in educational software. (c) 2005 Elsevier Ltd. All rights reserved.;2006
Teaching by fun is the most ideal teaching strategy in the educational field. In that case we are trying to establish a game-like learning system with Multi-modal interface and mix-initiative dialogue system for pre-school children.;2006
The aim of this paper is to present a certain kind of argumentation against the idea of the Turing test (we call it CCSC-Complete Conversation System Claim) and to discuss the issue of its first formulation. Ned Block with his idea of Aunt Bubbles argument is thought of as a founding father of CCSC but we present the results of our bibliographical researches which clearly show that the first formulation of CCSC should be ascribed to Polish writer and philosopher Stanislaw Lem.;2006
The design of Spoken Dialog Systems cannot be considered as the simple combination of speech processing technologies. Indeed speech-based interface design has been an expert job for a long time. It necessitates good skills in speech technologies and low-level programming. Moreover rapid development and reusability of previously designed systems remains uneasy. This makes optimality and objective evaluation of design very difficult. The design process is therefore a cyclic process composed of prototype releases user satisfaction surveys bug reports and refinements. It is well known that human intervention for testing is time-consuming and above all very expensive. This is one of the reasons for the recent interest in dialog simulation for evaluation as well as for design automation and optimization. In this paper we expose a probabilistic framework for a realistic simulation of spoken dialogs in which the major components of a dialog system are modeled and parameterized thanks to independent data or expert knowledge. Especially an Automatic Speech Recognition (ASR) system model and a User Model (UM) have been developed. The ASR model based on articulatory similarities in language models provides task-adaptive performance prediction and Confidence Level (CL) distribution estimation. The user model relies on the Bayesian Networks (BN) paradigm and is used both or user behavior modeling and Natural Language Understanding (NLU) modeling. The complete simulation framework has been used to train a reinforcement-learning agent on two different tasks. These experiments helped to point out several potentially problematic dialog scenarios.;2006
The development of a dialogue system for any task implies the acquisition of a dialogue corpus in order to study the structure of the dialogues used in that task. This structure is reflected in the dialogue system behaviour which can be rule-based or corpus-based. In the case of corpus-based dialogue systems the behaviour is defined by statistical models which are inferred from an annotated corpus of dialogues. This annotation task is usually difficult and expensive and therefore automatic dialogue annotation tools are necessary to reduce the annotation effort. An automatic dialogue labeller technique that is based on n-grams is presented in this work. Its different variants are evaluated with respect to manual human annotations of a dialogue corpus devoted to train queries.;2006
The development of IP-Telephony in recent years has been substantial. The improvement in voice quality the integration between voice and data especially the interaction with multimedia has made the 3G communication more promising. The value added services of Telephony techniques alleviate the dependence on the phone and provide a universal platform for the multimodal telephony applications. For example the web-based application with VoiceXML has been developed to simplify the human-machine interaction because it takes the advantage of the speech-enabled services and makes the telephone-web access a reality. However it is not cost-efficient to build voice only stand-alone web-application and is more reasonable that voice interfaces should be retrofitted to be compatible or collaborate with the existing HTML or XML-based web applications. Therefore this paper considers that the functionality of the web service should enable multiple access modalities so that users can perceive and interact with the site in either visual or speech response simultaneously. Under this principle our research develops a prototype system of multimodal VoIP with the integrated web-based Mandarin dialog system which adopts automatic speech recognition (ASR) text-to-speech (TTS) VoiceXML browser and VolP technologies to create user friendly graphic user interface (GUI) and voice user interface (VUI). The users can use traditional telephone cellular phone or even VoIP connection via personal computer to interact with the VoiceXML server. In the mean time the users browse the web and access the same content with common HTML or XML-based browser. The proposed system shows excellent performance and can be easily incorporated into voice ordering service for a wider accessibility. (c) 2006 Elsevier Ltd. All rights reserved.;2006
The goal of dialogue management in a spoken dialogue system is to take actions based on observations and inferred beliefs. To ensure that the actions optimize the performance or robustness of the system researchers have turned to reinforcement learning methods to learn policies for action selection. To derive an optimal policy from data the dynamics of the system is often represented as a Markov Decision Process (MDP) which assumes that the state of the dialogue depends only on the previous state and action. In this article we investigate whether constraining the state space by the Markov assumption especially when the structure of the state space may be unknown truly affords the highest reward. In simulation experiments conducted in the context of a dialogue system for interacting with a speech-enabled web browser models under the Markov assumption did not perform as well as an alternative model which classifies the total reward with accumulating features. We discuss the implications of the study as well as its limitations.;2006
The Hidden Vector State (HVS) Model is an extension of the basic discrete Markov model in which context is encoded as a stack-oriented state vector. State transitions are factored into a stack shift operation similar to those of a push-down automaton followed by the push of a new preterminal category label. When used as a semantic parser the model can capture hierarchical structure without the use of treebank data for training and it can be trained automatically using expectation-maximization (EM) from only-lightly annotated training data. When deployed in a system the model can be continually refined as more data becomes available. In this paper the practical application of the model in a spoken language understanding system (SLU) is described. Through a sequence of experiments the issues of robustness to noise and portability to similar and extended domains are investigated. The end-to-end performance obtained from experiments in the ATIS domain show that the system is comparable to existing SLU systems which rely on either hand-crafted semantic grammar rules or statistical models trained on fully annotated training corpora. Experiments using data which have been artificially corrupted with varying levels of additive noise show that the HVS-based parser is relatively robust and experiments using data sets from other domains indicate that the overall framework allows adaptation to related domains and scaling to cover enlarged domains. In summary it is argued that constrained statistical parsers such as the HVS model allow robust spoken dialogue systems to be built at relatively low cost and which can be automatically adapted as new data is acquired both to improve performance and extend coverage. (c) 2005 Elsevier B.V. All rights reserved.;2006
The paper analyses how an information operator processes a customer's requests. The study is based on the Estonian dialogue corpus. Our further aim is to develop a dialogue system (DS) which interacts with a user in Estonian and recognises interprets and grants a user's requests automatically. There are two main classes of computational models of the interpretation of dialogue acts - cue-based and inferential-based. In this paper we try to combine these two approaches. The corpus analysis demonstrates that a number of linguistic cues can be found which can be used by a DS for recognising requests in Estonian. The DS will use linguistic cues in order to recognise a dialogue act type. After that a frame of the act will be activated and filled in in order to interpret (understand) the act and to generate a responding act. A simple regular grammar is used for the dialogue management.;2006
The way we see the objects around us determines speech and gestures we use to refer to them. The gestures we produce structure our visual perception. The words we use have an influence on the way we see. In this manner visual perception language and gesture present multiple interactions between each other. The problem is global and has to be tackled as a whole in order to understand the complexity of reference phenomena and to deduce a formal model. This model may be useful for any kind of human-machine dialogue system that focuses on deep comprehension. We show how a referring act takes place in a contextual subset of objects. This subset is called 'reference domain' and is implicit. It can be deduced from a lot of clues. Among these clues are those which come from the visual context and those which come from the multimodal utterance. We present the 'multimodal reference domain' model that takes these clues into account and that can be exploited in a multimodal dialogue system when interpreting. (c) 2006 Elsevier B.V. All rights reserved.;2006
The Workshop program of the Twenty-First National Conference on Artificial Intelligence was held July 16-17 2006 in Boston Massachusetts. The program was chaired by Joyce Chai and Keith Decker. The titles of the 17 workshops were AI-Driven Technologies for Service-Oriented Computing Auction Mechanisms for Robot Coordination Cognitive Modeling and Agent-Based Social Simulations Cognitive Robotics Computational Aesthetics: Artificial Intelligence Approaches to Beauty and Happiness Educational Data Mining Evaluation Methods for Machine Learning Event Extraction and Synthesis Heuristic Search Memory-Based Heuristics and Their Applications Human Implications of Human-Robot Interaction Intelligent Techniques in Web Personalization Learning for Search Modeling and Retrieval of Context Modeling Others from Observations and Statistical and Empirical Approaches for Spoken Dialogue Systems.;2006
There has been a great deal of interest over the past 20 years in developing metrics and frameworks for evaluating and comparing the performance of spoken-language dialogue systems. One of the results of this interest is a potential general methodology known as the PARADISE framework. This squib highlights some important issues concerning the application of PARADISE that have up to now not been sufficiently emphasized or have even been neglected by the dialogue-system community. These include considerations regarding the selection of appropriate regression parameters normalization effects on the accuracy of the prediction the influence of speech-recognition errors on the performance function and the selection of an appropriate user-satisfaction measure. In addition it gives the results Of an evaluation of data from two Wizard-of-Oz experiments. These evaluations include different dependent variables and examination of individual user-satisfaction measures.;2006
There is a growing need for automated systems that can interview patients and consumers about their health and provide health education and behavior change interventions using natural language dialog. A number of these health dialog systems have been developed over the last two decades many of which have been formally evaluated in clinical trials and shown to be effective. This article provides an overview of the theories technologies and methodologies that are used in the construction and evaluation of these systems along with a description of many of the systems developed and tested to date. The strengths and weaknesses of these approaches are also discussed and the needs for future work in the field are delineated. (c) 2006 Elsevier Inc. All rights reserved.;2006
This article focuses on the analysis and prediction of corrections defined as turns where a user tries to correct a prior error made by a spoken dialogue system. We describe our labeling procedure of various corrections types and statistical analyses of their features in a corpus collected from a train information spoken dialogue system. We then present results of machine-learning experiments designed to identify user corrections of speech recognition errors. We investigate the predictive power of features automatically computable from the prosody of the turn the speech recognition process experimental conditions and the dialogue history. Our best-performing features reduce classification error from baselines of 25.70-28.99% to 15.72%.;2006
This article investigates a novel multi-stage approach for spoken language understanding (SLU) with an application to a pioneering Thai spoken dialogue system in a hotel reservation domain. Given an input word string the system determines a goal and concept-values by three-stage processing concept extraction goal identification and concept-value recognition. The concept extraction utilizes weighted finite state transducers (WFST) to extract concepts from the word string. Given the extracted concepts a goal of the utterance is identified using a pattern classifier. Within a particular goal the necessary concept-values are recognized from the WFST outputs produced in the concept extraction stage. A new logical N-gram model which strategically combines the conventional N-gram parser with a regular grammar is evaluated for concept extraction and concept-value recognition. Several classifiers are optimized and compared for goal identification. An advantage of the proposed SLU model is that it can be trained by a partially annotated corpus where only the relevant keywords and the goal of each training utterance are required. Although the proposed model is evaluated only on the Thai hotel reservation system the SLU itself is general and it is expected to be applicable for other languages once training data is available. (c) 2005 Elsevier B.V. All rights reserved.;2006
This article reviews formal systems that regulate persuasion dialogues. In such dialogues two or more participants aim to resolve a difference of opinion each trying to persuade the other participants to adopt their point of view. Systems for persuasion dialogue have found application in various fields of computer science such as non-monotonic logic artificial intelligence and law multi-agent systems intelligent tutoring and computer-supported collaborative argumentation. Taking a game-theoretic view on dialogue systems this review proposes a formal specification of the main elements of dialogue systems for persuasion and then uses it to critically review some of the main formal systems for persuasion. The focus of this review will be on regulating the interaction between agents rather than on the design and behaviour of individual agents within a dialogue.;2006
This paper addresses the manual and automatic labelling from spontaneous speech of a particular type of user affect that we call the cognitive state in a tutorial dialogue system with students of primary and early middle school ages. Our definition of the cognitive state is based on analysis of children's spontaneous speech which is acquired during Wizard-of-Oz simulations of an intelligent math and physics tutor. The cognitive states of children are categorized into three classes: confidence puzzlement and hesitation. The manual labelling of cognitive states had an inter-transcriber agreement of kappa score 0.93. The automatic cognitive state labels are generated by classifying prosodic features text features and spectral features. Text features are generated from an automatic speech recognition (ASR) system features include indicator functions of keyword classes and part-of-speech sequences. Spectral features are created based on acoustic likelihood scores of a cognitive state-dependent ASR system in which phoneme models are adapted to utterances labelled for a particular cognitive state. The effectiveness of the proposed method has been tested on both manually and automatically transcribed speech and the test yielded very high correctness: 96.6% for manually transcribed speech and 95.7% for automatically recognized speech. Our study shows that the proposed spectral features greatly outperformed the other types of features in the cognitive state classification experiments. Our study also shows that the spectral and prosodic features derived directly from speech signals were very robust to speech recognition errors much more than the lexical and part-of-speech based features. (C) 2005 Elsevier B.V. All rights reserved.;2006
This paper addresses the problem posed by the current split between the two opposed hypotheses in the growing literature on the fallacy of begging the question the epistemic hypothesis based on knowledge and belief and the dialectical one based on formal dialogue systems. In the first section the nature of split is explained and it is shown how each hypothesis has developed. To get the beginning reader up to speed in the literature a number of key problematic examples are analyzed illustrating how both approaches can be applied. Useful tools are brought to bear on them including the automated argument diagramming system Araucaria and profiles of dialogue used to represent circular argumentation in a dialogue tableau format. These tools are used to both to model circular reasoning and to provide the contextual evidence needed to properly determine whether the circular reasoning in a given case is better judged fallacious or not. A number of technical problems that have impeded the development of both hypotheses are studied. One central problem is the distinction between argument and explanation. It is concluded that the best way to move forward and solve these problems is to reformulate the two hypotheses in such a way that they might be able to co-exist. On this basis a unified methodology is proposed that allows each hypothesis to move forward as a legitimate avenue for research using the same tools.;2006
This paper computationalizes two linguistic concepts contrast and focus for the extraction of pragmatic and semantic salience from spontaneous speech. Contrast and focus have been widely investigated in modern linguistics as categories that link intonation and information/discourse structure. This paper demonstrates the automatic tagging of contrast and focus for the purpose of robust spontaneous speech understanding in a tutorial dialogue system. In particular we propose two new transcription tasks and demonstrate automatic replication of human labels in both tasks. First we define focus kernel to represent those words that contain novel information neither presupposed by the interlocutor nor contained in the precedent words of the utterance. We propose detecting the focus kernel based on a word dissimilarity measure part-of-speech tagging and prosodic measurements including duration pitch energy and our proposed spectral balance cepstral coefficients. In order to measure the word dissimilarity we test a linear combination of ontological and statistical dissimilarity measures previously published in the computational linguistics literature. Second we propose identifying symmetric contrast which consists of a set of words that are parallel or symmetric in linguistic structure but distinct or contrastive in meaning. The symmetric contrast identification is performed in a way similar to the focus kernel detection. The effectiveness of the proposed extraction of symmetric contrast and focus kernel has been tested on a Wizard-of-Oz corpus collected in the tutoring dialogue scenario. The corpus consists of 630 non-single word/phrase utterances containing approximately 5700 words and 48 minutes of speech. The tests used speech waveforms together with manual orthographic transcriptions and yielded an accuracy of 83.8% for focus kernel detection and 92.8% for symmetric contrast detection. Our tests also demonstrated that the spectral balance cepstral coefficients the semantic dissimilarity measure and part-of-speech played important roles in the symmetric contrast and focus kernel detections. (c) 2005 Elsevier B.V. All rights reserved.;2006
This paper describes a novel approach to automatically or semiautomatically constructing a multi-application dialogue system based on existing dialogue systems. Nowadays there exist different dialogue systems with general architecture supporting different applications. Yet there is no efficient way to endow the multi-application supported dialogue systems with the corresponding applications. The approach represented in this paper provides an efficient way to integrate different applications into one dialogue system and addresses three issues. in multi-application dialogue systems - transparent application switching task sharing and information sharing by merging the dialogue specifications of different applications into a unified dialogue specification as automatically as possible which provides necessary domain information for a multi-application supported dialogue system.;2006
This paper describes an experiment on the effects of learning mode of interaction (written vs. spoken) and transfer mode on user performance and discourse organization during interaction with a natural language dialogue System. Forty-eight participants took part in a series of 12 dialogues with an information retrieval system presented either in the written or the spoken mode during the first six dialogues. The next six dialogues were then presented either in the same interaction mode or in another mode. The analysis of the results showed that performance (time number of effective turns) improved throughout the dialogues whatever the mode of interaction. Nevertheless performance was higher in the written mode. Moreover mode-specific characteristics were observed. These consisted in greater use of subject pronouns and articles in the spoken mode. Similarly in the spoken mode the users found it easier to reuse the formulations presented in the system speech than in the written mode. Furthermore the analysis also revealed a positive transfer effect on performance and discourse organization when the individuals first interacted in the spoken mode and then in the written mode. Both positive and negative transfer effects were observed when the individuals interacted first in the written mode followed by the spoken mode. The implications of the results are discussed in terms of direct and indirect consequences of modality effects on natural language dialogue interaction. (c) 2004 Elsevier Ltd. All rights reserved.;2006
This paper describes an international effort to unify a multimodal behavior generation framework for Embodied Conversational Agents (ECAs). We propose a three stage model we call SAIBA where the stages represent intent planning behavior planning and behavior realization. A Function Markup Language (FML) describing intent without referring to physical behavior mediates between the first two stages and a Behavior Markup Language (BML) describing desired physical realization mediates between the last two stages. In this paper we will focus on BML. The hope is that this abstraction and modularization will help ECA researchers pool their resources to build more sophisticated virtual humans.;2006
This paper describes four experiments which have been carried out to evaluate the speech output component of the INSPIRE spoken dialogue system providing speech control for different devices located in a smart home environment. The aim is to quantify the impact of different factors oil the quality of the system when addressed either in the home or from a remote location (office car). Factors analyzed ill the experiments include the characteristics of the machine agent during the interaction (voice personality) the physical characteristics of the usage environment (acoustic user interface background noise electrical transmission path) as well as task-related characteristics (listening-only vs. interaction Situation parallel tasks). The results show a significant impact of agent and environmental factors but not of task factors. Potential reasons for this finding are discussed. They serve as a basis for design decisions which have been taken for the final system. (c) 2005 Elsevier B.V. All rights reserved.;2006
This paper explores the feasibility of using conversational agents or chatbots in negotiated learner modelling. This approach aims to combine the motivational intuitive and domain-independent benefits of natural language dialogue using a chatbot with the opportunities for learner reflection and increased model accuracy that can be achieved through negotiation of the learner model contents. A Wizard-of-Oz paradigm allowed investigation into the interactions between learners and their learner model in order to highlight key issues for the design of a chatbot for this purpose. Users appreciated interacting with a chatbot and found it useable and an aid to negotiation. The study suggested many avenues for future investigation of the role of conversational agents in facilitating user-system dialogue about learner understanding.;2006
This paper presents a new technique to enhance the performance of the input interface of spoken dialogue systems based on a procedure that combines during speech recognition the advantages of using prompt-dependent language models with those of using a language model independent of the prompts generated by the dialogue system. The technique proposes to create a new speech recognizer termed contextual speech recognizer that uses a prompt-independent language model to allow recognizing any kind of sentence permitted in the application domain and at the same time uses contextual information (in the form of prompt-dependent language models) to take into account that some sentences are more likely to be uttered than others at a particular moment of the dialogue. The experiments show the technique allows enhancing clearly the performance of the input interface of a previously developed dialogue system based exclusively on prompt-dependent language models. But most important in comparison with a standard speech recognizer that uses just one prompt-independent language model without contextual information the proposed recognizer allows increasing the word accuracy and sentence understanding rates by 4.09% and 4.19% absolute respectively. These scores are slightly better than those obtained using linear interpolation of the prompt-independent and prompt-dependent language models used in the experiments. (c) 2005 Elsevier Ltd. All rights reserved.;2006
This paper presents an approach to model the gaze behavior of an Embodied Conversational Agent in a real time multimodal dialogue interaction with a group of users. The ECA's gaze control results from the merge of the outputs of a rational dialogue engine based on natural language interaction and face tracking of users.;2006
This paper presents some research undertaken as part of the EU-funded HOMEY project into the application of intelligent dialogue systems to healthcare systems. The work presented here concentrates on the ways in which knowledge of underlying task structure (e.g. a medical guideline) can be combined with ontological knowledge (e.g. medical semantic dictionaries) to provide a basis for the automatic generation of flexible and re-configurable dialogue. This approach is next evaluated via a specific application that provides decision support to general practitioners to help determine whether or not a patient should be referred to a cancer specialist. The competence of the resulting dialogue application its speech recognition performance and dialogue performance are all evaluated to determine the applicability of this approach. (c) 2006 Elsevier Inc. All rights reserved.;2006
This paper presents the current status of the research in the Higgins project and provides background for a demonstration of the spoken dialogue system implemented within the project. The project represents the latest development in the ongoing dialogue systems research at KTH. The practical goal of the project is to build collaborative conversational dialogue systems in which research issues such as error handling techniques can be tested empirically.;2006
This paper proposes a dialogue strategy for clarifying and constraining queries to document retrieval systems with speech input interfaces. It is indispensable for spoken dialogue systems to interpret user's intention robustly in the presence of speech recognition errors and extraneous expressions characteristic of spontaneous speech. In speech input moreover users' queries tend to be vague and they may need to be clarified through dialogue in order to extract sufficient information to get meaningful retrieval results. In conventional database query tasks it is easy to cope with these problems by extracting and confirming keywords based on semantic slots. However it is not straightforward to apply such a methodology to general document retrieval tasks. In this paper we first introduce two statistical measures for identifying critical portions to be confirmed. The relevance score (RS) represents the matching degree with the document set. The significance score (SS) detects portions that affect retrieval results. With these measures the system can generate confirmations to handle speech recognition errors prior to and after the retrieval respectively. Then we propose a dialogue strategy for generating clarifications to narrow down the retrieved items especially when many documents are matched because of a vague input query. The optimal clarification question is dynamically selected based on information gain (IG) - the reduction in the number of matched items. A set of possible clarification questions is prepared using various knowledge sources. As a bottom-up knowledge source we extract a list of words that can take a number of objects and potentially causes ambiguity using a dependency structure analysis of the document texts. This is complemented by top-down knowledge sources of metadata and hand-crafted questions. Our dialogue strategy is implemented and evaluated against a software support knowledge base of 40 K entries. We demonstrate that our strategy significantly improves the success rate of retrieval. (c) 2006 Elsevier B.V. All rights reserved.;2006
This paper proposes a method for the confidence scoring of intention recognition results in spoken dialogue systems. To achieve tasks a spoken dialogue system has to recognize user intentions. However because of speech recognition errors and ambiguity in user utterances it sometimes has difficulty recognizing them correctly. Confidence scoring allows errors to be detected in intention recognition results and has proved useful for dialogue management. Conventional methods use the features obtained from the speech recognition/understanding results for single utterances for confidence scoring. However this may be insufficient since the intention recognition result is a result of discourse processing. We propose incorporating discourse features for a more accurate confidence scoring of intention recognition results. Experimental results show that incorporating discourse features significantly improves the confidence scoring. (c) 2005 Elsevier B.V. All rights reserved.;2006
This paper proposes a new technique to test the performance of spoken dialogue systems by artificially simulating the behaviour of three types of user (very cooperative cooperative and not very cooperative) interacting with a system by means of spoken dialogues. Experiments using the technique were carried out to test the performance of a previously developed dialogue system designed for the fast-food domain and working with two kinds of language model for automatic speech recognition: one based on 17 prompt-dependent language models and the other based on one prompt-independent language model. The use of the simulated user enables the identification of problems relating to the speech recognition spoken language understanding and dialogue management components of the system. In particular in these experiments problems were encountered with the recognition and understanding of postal codes and addresses and with the lengthy sequences of repetitive confirmation turns required to correct these errors. By employing a simulated user in a range of different experimental conditions sufficient data can be generated to support a systematic analysis of potential problems and to enable fine-grained tuning of the system.;2006
This work proposes a new way for providing feedback to expressivity in music performance. Starting from studies on the expressivity of music performance we developed a system in which a visual feedback is given to the user using a graphical representation of a human face. The first part of the system previously developed by researchers at KTH Stockholm and at the University of Uppsala allows the real-time extraction and analysis of acoustic cues from the music performance. Cues extracted are: sound level tempo articulation attack time and spectrum energy. From these cues the system provides an high level interpretation of the emotional intention of the performer which will be classified into one basic emotion such as happiness sadness or anger. We have implemented an interface between that system and the embodied conversational agent Greta developed at the University of Rome La Sapienza and University of Paris 8. We model expressivity of the facial animation of the agent with a set of six dimensions that characterize the manner of behavior execution. In this paper we will first describe a mapping between the acoustic cues and the expressivity dimensions of the face. Then we will show how to determine the facial expression corresponding to the emotional intention resulting from the acoustic analysis using music sound level and tempo characteristics to control the intensity and the temporal variation of muscular activation.;2006
To facilitate the development of spoken dialog systems and speech enabled applications we introduce SGStudio (Semantic Grammar Studio) a grammar authoring tool that enables regular software developers with little speech/linguistic background to rapidly create quality semantic grammars for automatic speech recognition (ASR) and spoken language understanding (SLU). We focus on the underlying technology of SGStudio including knowledge assisted example-based grammar learning grammar controls and configurable grammar structures. While the focus of SGStudio is to increase productivity experimental results show that it also improves the quality of the grammars being developed. (c) 2005 Elsevier B.V. All rights reserved.;2006
traditional study on recognition and representation of sign language based on the desktop PC have general restrictions conditionality in space and limitation of motion according to the technology of wire communication and then the vision technology-based traditional sign langage recognition systems recognition performance has the possibility of change and diversity according to the performance of the camera change of background (colors) and illumination condition. To overcome these restrictions and problems we implement embedded-sentential the Korean Standard Sign Language (hereinafter KSSL) recognizer based on the post wearable PC for mobile and ubiquitous computing. The KSSL is a dialog system and interactive elements in the South Korea deaf communities. The advantages of our approach are as follows: 1) it improves efficiency of the KSSL input module according to the technology of wireless communication and user need not be constrained by the limitations of a particular interaction mode at any given moment 2) it recognizes and represents continuous the KSSL of users with flexibility in real time and can offer to user a wider range of personalized and differentiated information more effectively and 3) it is possible more effective and free interchange of ideas and information between deaf person and hearing person (the public). Experimental result shows an average recognition rate of 93.3% for the KSSL sentences and 96.9% for the KSSL words with significant dynamic and continuous the KSSL.;2006
Two experiments are reported in which university students translated visually presented English words into German while German distractor words were simultaneously presented. Distractors were morphologically related merely form-related or unrelated to the German translations (target words). The transparency of the semantic relation between target words and morphological distractors was also varied. Morphological distractors facilitated word-translation latencies irrespective of their semantic transparency replicating results obtained with other tasks. Thus in German word production effects of morphological complexity seem to be largely independent of semantics. Morphological facilitation is also not due to mere form relatedness since phonological distractors had no impact on translation latencies relative to unrelated distractors. Our data corroborate the usefulness of word-translation for investigating spoken word production in particular for morphological processing.;2006
We aim at creating an expressive Embodied Conversational Agent (ECA) and address the problem of synthesizing expressive agent gestures. In our previous work we have described the gesture selection process. In this paper we present a computational model of gesture quality. Once a certain gesture has been chosen for execution how can we modify it to carry a desired expressive content while retaining its original semantics? We characterize bodily expressivity with a small set of dimensions derived from a review of psychology literature. We provide a detailed description of the implementation of these dimensions in our animation system including our gesture modeling language. We also demonstrate animations with different expressivity settings in our existing ECA system. Finally we describe two user studies that evaluate the appropriateness of our implementation for each dimension of expressivity as well as the potential of combining these dimensions to create expressive gestures that reflect communicative intent.;2006
We are interested in the problem of robust understanding from noisy spontaneous speech input. With the advances in automated speech recognition (ASR) there has been increasing interest in spoken language understanding (SLU). A challenge in large vocabulary spoken language understanding is robustness to ASR errors. State of the art spoken language understanding relies on the best ASR hypotheses (ASR 1-best). In thispaper we propose methods for a tighter integration of ASR and SLU using word confusion networks (WCNs). WCNs obtained from ASR word graphs (lattices) provide a compact representation of multiple aligned. ASR hypotheses along with word confidence scores without compromising recognition accuracy. We present our work on exploiting WCNs instead of simply using ASR one-best hypotheses. In this work we focus on the tasks of named entity detection and extraction and call classification in a spoken dialog system although the idea is more general and applicable to other spoken language processing tasks. For named entity detection we have improved the F-measure by using both word lattices and WCNs 6-10% absolute. The processing of WCNs was 25 times faster than lattices which is very important for real-life applications. For call classification we have shown between 5% and 10% relative reduction in error rate using WCNs compared to ASR 1-best output. (c) 2005 Elsevier Ltd. All rights reserved.;2006
We describe a new knowledge acquisition tool that enabled us to develop a dialog system recommending software design patterns by asking critical questions. This assistance system is based on interviews with experts. For the interviews we adopted the repertory grid method and integrated formal concept analysis. The repertory grid method stimulates the generation of common and differentiating attributes for a given set of objects. Using formal concept analysis we can control the repertory grid procedure minimize the required expert judgements and build an abstraction based hierarchy of design patterns even from the judgements of different experts. Based on the acquired knowledge we semiautomatically generate a Bayesian Belief Network (BBN) that is used to conduct dialogs with users to suggest a suitable design pattern for their individual problem situation. Integrating these different methods into our knowledge acquisition tool KARaCAs enables us to support the entire knowledge acquisition and engineering process. We used KARaCAs with three design pattern experts and derived approximately 130 attributes for 23 design patterns. Using formal concept analysis we merged the three lattices and condensed them to approximately 80 common attributes.;2006
We present a natural-language customer service application for a telephone banking call center developed as part of the Amities dialogue project (Automated Multilingual Interaction with Information and Services). Our dialogue system based on empirical data gathered from real call-center conversations features data-driven techniques that allow for spoken language understanding despite speech recognition errors as well as mixed system/customer initiative and spontaneous conversation. These techniques include robust named-entity extraction slot-filling Frame Agents vector-based task identification and dialogue act classification a Bayesian database record selection algorithm and a natural language generator designed with templates created from real agents' expressions. Preliminary evaluation results indicate efficient dialogues and high user satisfaction with performance comparable to or better than that of current conversational information systems. (c) 2005 Elsevier B.V. All rights reserved.;2006
We present and evaluate a robust method for the interpretation of spoken input to a conversational computer game. The scenario- of the game is that of a player interacting with embodied fairy-tale characters in a 3D world via spoken dialogue (supplemented by graphical pointing actions) to solve various problems. The player himself cannot directly perform actions in the world but interacts with the fairy-tale characters to have them perform various tasks and to get information about the world and the problems to solve. Hence the role of spoken dialogue as the primary means of control is obvious and natural to the player. Naturally this means that robust spoken language understanding becomes a critical component. To this end the paper describes a semantic representation formalism and an accompanying parsing algorithm which works off the output of the speech recogniser's statistical language model. The evaluation shows that the parser is robust in the sense of considerably improving on the noisy output of the speech recogniser. (c) 2005 Elsevier B.V. All rights reserved.;2006
While human tutors respond to both what a student says and to how the student says it most tutorial dialogue systems cannot detect the student emotions and attitudes underlying an utterance. We present an empirical study investigating the feasibility of recognizing student state in two corpora of spoken tutoring dialogues one with a human tutor and one with a computer tutor. We first annotate student turns for negative neutral and positive student states in both corpora. We then automatically extract acoustic-prosodic features from the student speech and lexical items from the transcribed or recognized speech. We compare the results of machine learning experiments using these features alone in combination and with student and task dependent features to predict student states. We also compare our results across human-human and human-computer spoken tutoring dialogues. Our results show significant improvements in prediction accuracy over relevant baselines and provide a first step towards enhancing our intelligent tutoring spoken dialogue system to automatically recognize and adapt to student states. (C) 2005 Elsevier B.V. All rights reserved.;2006
Within the broad field of spoken dialogue systems the application of machine-learning approaches to dialogue management strategy design is a rapidly growing research area. The main motivation is the hope of building systems that learn through trial-and-error interaction what constitutes a good dialogue strategy. Training of such systems could in theory be done using human users or using corpora of human-computer dialogue but in practice the typically vast space of possible dialogue states and strategies cannot be explored without the use of automatic user simulation tools. This requirement for training statistical dialogue models has created an interesting new application area for predictive statistical user modelling and a variety of different techniques for simulating user behaviour have been presented in the literature ranging from simple Markov models to Bayesian networks. The development of reliable user simulation tools is critical to further progress on automatic dialogue management design but it holds many challenges some of which have been encountered in other areas of current research on statistical user modelling such as the problem of 'concept drift' the problem of combining content-based and collaboration-based modelling techniques and user model evaluation. The latter topic is of particular interest because simulation-based learning is currently one of the few applications of statistical user modelling that employs both direct 'accuracy-based' and indirect 'utility-based' evaluation techniques. In this paper we briefly summarize the role of the dialogue manager in a spoken dialogue system give a short introduction to reinforcement-learning of dialogue management strategies and review the literature on user modelling for simulation-based strategy learning. We further describe recent work on user model evaluation and discuss some of the current research issues in simulation-based learning from a user modelling perspective.;2006
A barge-in free spoken dialogue interface using sound field control and microphone array is proposed. In the conventional spoken dialogue system using an acoustic echo canceller it is indispensable to estimate a room transfer function especially when the transfer function is changed by various interferences. However the estimation is difficult when the user and the system speak simultaneously. To resolve the problem we propose a sound field control technique to prevent the response sound from being observed. Combined with a microphone array the proposed method can achieve high elimination performance with no adaptive process. The efficacy of the proposed interface is ascertained in the experiments on the basis of sound elimination and speech recognition.;2007
A very important aspect in developing robots capable of human-robot interaction (HRI) is the research in natural human-like communication and subsequently the development of a research platform with multiple HRI capabilities for evaluation. Besides a flexible dialog system and speech understanding an anthropomorphic appearance has the potential to support intuitive usage and understanding of a robot e.g. human-like facial expressions and deictic gestures can as well be produced and also understood by the robot. As a consequence of our effort in creating an anthropomorphic appearance and to come close to a human-human interaction model for a robot we decided to use human-like sensors i.e. two cameras and two microphones only in analogy to human perceptual capabilities too. Despite the challenges resulting from these limits with respect to perception a robust attention system for tracking and interacting with multiple persons simultaneously in real time is presented. The tracking approach is sufficiently generic to work on robots with varying hardware as long as stereo audio data and images of a video camera are available. To easily implement different interaction capabilities like deictic gestures natural adaptive dialogs and emotion awareness on the robot we apply a modular integration approach utilizing XML-based data exchange. The paper focuses on our efforts to bring together different interaction concepts and perception capabilities integrated on a humanoid robot to achieve comprehending human-oriented interaction.;2007
An effective networked knowledge delivery platform is one of the Holy Grails of Web computing. Knowledge delivery approaches range from the heavy and narrow to the light and broad. This paper explores a lightweight and flexible dialog framework based on the ALICE system and evaluates its performance in chat and knowledge delivery using both a conversational setting and a specific telecommunications knowledge domain. Metrics for evaluation are presented and the evaluations of three experimental systems (a pure dialog system a domain knowledge system and a hybrid system combining dialog and domain knowledge) are presented and discussed. Our study of 257 subjects shows approximately a 20% user correction rate on system responses. Certain error classes (such as nonsense replies) were particular to the dialog system while others (such as mistaking opinion questions for definition questions) were particular to the domain system. A third type of error wordy and awkward responses is a basic system property and spans all three experimental systems. We also show that the highest response satisfaction results are obtained when coupling domain-specific knowledge together with conversational dialog. (c) 2006 Elsevier B.V. All rights reserved.;2007
As access to information becomes more intensive in society a great deal of that information is becoming available through diverse channels. Accordingly users require effective methods for accessing this information. Conversational agents can act as effective and familiar user interfaces. Although conversational agents can analyze the queries of users based on a static process they cannot manage expressions that are more complex. In this paper we propose a system that uses semantic Bayesian networks to infer the intentions of the user based on Bayesian networks and their semantic information. Since conversation often contains ambiguous expressions the managing of context and uncertainty is necessary to support flexible conversational agents. The proposed method uses mixed-initiative interaction (MII) to obtain missing information and clarify spurious concepts in order to understand the intention of users correctly. We applied this to an information retrieval service for websites to verify the usefulness of the proposed method. (c) 2006 Elsevier Ltd. All rights reserved.;2007
Biometric identity verification is a reality today. However this relatively new field still requires a large amount of user-centred studies before becoming commonly used. This paper presents a user-centred analysis of a multimodal authentication system for secure Internet access where users can choose freely between three different biometric modalities (fingerprint voice and signature) to enrol verify their identity and act as impostors in an unsupervised manner aided only by an automated embodied conversational agent. Objective and subjective information was collected to analyse relevant relationships between authentication performance ergonomic issues and user preconceptions and impressions. Particular attention has been paid to analyse also the evolution of users' choices of modality. From the results of our study we infer usability insights for the design of multimodal biometric security systems and point towards directions of further inquiry.;2007
Consumer access networks are low bandwidth especially in the up-stream direction. This asymmetry is heightened for real-time multimedia applications. The web wait is not acceptable when in a conversational interface. We describe the use of KPM a protocol for transporting user stimulus. We illustrate the application of KPML to a typical consumer activity accessing information sources over the telephone. We include results measuring KPML against other protocols for transporting user stimulus.;2007
Control in spoken dialog systems is challenging largely because automatic speech recognition is unreliable and hence the state of the conversation can never be known with certainty. Partially observable Markov decision processes (POMDPs) provide a principled mathematical framework for planning and control in this context however POMDPs face severe scalability challenges and past work has been limited to trivially small dialog tasks. This paper presents a novel POMDP optimization technique-composite summary point-based value iteration (CSPBVI)-which enables optimization to be performed on slot-filling POMDP-based dialog managers of a realistic size. Using dialog models trained on data from a tourist information domain simulation results show that CSPBVI scales effectively outperforms non-POMDP baselines and is robust to estimation errors.;2007
DiamondHelp is a generic collaborative task guidance system motivated by the current usability crisis in high-tech home products. It combines an application-independent conversational interface (adapted from online chat programs) with an application-specific direct-manipulation interface. DiamondHelp is implemented in Java and uses Collagen for representing and using task models.;2007
Head pose and gesture offer several conversational grounding cues and are used extensively in face-to-face interaction among people. To accurately recognize visual feedback humans often use contextual knowledge from previous and current events to anticipate when feedback is most likely to occur. In this paper we describe how contextual information can be used to predict visual feedback and improve recognition of head gestures in human-computer interfaces. Lexical prosodic timing and gesture features can be used to predict a user's visual feedback during conversational dialog with a robotic or virtual agent. In non-conversational interfaces context features based on user-interface system events can improve detection of head gestures for dialog box confirmation or document browsing. Our user study with prototype gesture-based components indicate quantitative and qualitative benefits of gesture-based confirmation over conventional alternatives. Using a discriminative approach to contextual prediction and multimodal integration performance of head gesture detection was improved with context features even when the topic of the test set was significantly different than the training set. (c) 2007 Elsevier B.V. All rights reserved.;2007
Humans are known to use a wide range of non-verbal behaviour while speaking. Generating naturalistic embodied speech for an artificial agent is therefore an application where techniques that draw directly on recorded human motions can be helpful. We present a system that uses corpus-based selection strategies to specify the head and eyebrow motion of an animated talking head. We first describe how a domain-specific corpus of facial displays was recorded and annotated and outline the regularities that were found in the data. We then present two different methods of selecting motions for the talking head based on the corpus data: one that chooses the majority option in all cases and one that makes a weighted choice among all of the options. We compare these methods to each other in two ways: through cross-validation against the corpus and by asking human judges to rate the output. The results of the two evaluation studies differ: the cross-validation study favoured the majority strategy while the human judges preferred schedules generated using weighted choice. The judges in the second study also showed a preference for the original corpus data over the output of either of the generation strategies.;2007
In a spoken dialog system determining which action a machine should take in a given situation is a difficult problem because automatic speech recognition is unreliable and hence the state of the conversation can never be known with certainty. Much of the research in spoken dialog systems centres on mitigating this uncertainty and recent work has focussed on three largely disparate techniques: parallel dialog state hypotheses local use of confidence scores and automated planning. While in isolation each of these approaches can improve action selection taken together they currently lack a unified statistical framework that admits global optimization. In this paper we cast a spoken dialog system as a partially observable Markov decision process (POMDP). We show how this formulation unifies and extends existing techniques to form a single principled framework. A number of illustrations are used to show qualitatively the potential benefits of POMDPs compared to existing techniques and empirical results from dialog simulations are presented which demonstrate significant quantitative gains. Finally some of the key challenges to advancing this method - in particular scalability - are briefly outlined. (c) 2006 Elsevier Ltd. All rights reserved.;2007
In recent years the concept of autonomous mental development (AMD) has been applied to the construction of artificial systems such as conversational agents in order to resolve some of the difficulties involved in the manual definition of their knowledge bases and behavioral patterns. AMD is a new paradigm for developing autonomous machines which are adaptive and flexible to the environment. Language development a kind of mental development is an important aspect of intelligent conversational agents. In this paper we propose an intelligent conversational agent and its language development mechanism by putting together five promising techniques: Bayesian networks pattern matching finite-state machines templates and genetic programming (GP). Knowledge acquisition implemented by finite-state machines and templates and language learning by GP are used for language development. Several illustrations and usability tests show the usefulness of the proposed developmental conversational agent.;2007
In the present paper we investigate the validity and reliability of de-facto evaluation standards defined for measuring or predicting the quality of the interaction with spoken dialogue systems. Two experiments have been carried out with a dialogue system for controlling domestic devices. During these experiments subjective judgments of quality have been collected by two questionnaire methods (ITU-T Rec. P.851 and SASSI) and parameters describing the interaction have been logged and annotated. Both metrics served the derivation of prediction models according to the PARADISE approach. Although the limited database allows only tentative conclusions to be drawn the results suggest that both questionnaire methods provide valid measurements of a large number of different quality aspects most of the perceptive dimensions underlying the subjective judgments can also be measured with a high reliability. The extracted parameters mainly describe quality aspects which are directly linked to the system environmental and task characteristics. Used as an input to prediction models the parameters provide helpful information for system design and optimization but not general predictions of system usability and acceptability. (c) 2005 Elsevier Ltd. All rights reserved.;2007
In this paper the semantic and pragmatic modules of a spoken dialogue system development platform are presented and evaluated. The main goal of this research is to create spoken dialogue system modules that are portable across applications domains and interaction modalities. We propose a hierarchical semantic representation that encodes all information supplied by the user over multiple dialogue turns and can efficiently represent and be used to argue with ambiguous or conflicting information. Implicit in this semantic representation is a pragmatic module consisting of context tracking pragmatic analysis and pragmatic scoring submodules which computes pragmatic confidence scores for all system beliefs. These pragmatic scores are obtained by combining semantic and pragmatic evidence from the various submodules (taking into account the modality of input) and are used to rank-order attribute-value pairs in the semantic representation as well as identifying and resolving ambiguities. These modules were implemented and evaluated within a travel reservation dialogue system under the auspices of the DARPA Communicator project as well as for a movie information application. Formal evaluation of the semantic and pragmatic modules has shown that by incorporating pragmatic analysis and scoring the quality of the system improves for over 20% of the dialogue fragments examined.;2007
In this paper the task and user interface modules of a multimodal dialogue system development platform are presented. The main goal of this work is to provide a simple application-independent solution to the problem of multimodal dialogue design for information seeking applications. The proposed system architecture clearly separates the task and interface components of the system. A task manager is designed and implemented that consists of two main submodules: the electronic form module that handles the list of attributes that have to be instantiated by the user and the agenda module that contains the sequence of user and system tasks. Both the electronic forms and the agenda can be dynamically updated by the user. Next a spoken dialogue module is designed that implements the speech interface for the task manager. The dialogue manager can handle complex error correction and clarification user input building on the semantics and pragmatic modules presented in Part I of this paper. The spoken dialogue system is evaluated for a travel reservation task of the DARPA Communicator research program and shown to yield over 90% task completion and good performance for both objective and subjective evaluation metrics. Finally a multimodal dialogue system which combines graphical and speech interfaces is designed implemented and evaluated. Minor modifications to the unimodal semantic and pragmatic modules were required to build the multimodal system. It is shown that the multimodal system significantly outperforms the unimodal speech-only system both in terms of efficiency (task success and time to completion) and user satisfaction for a travel reservation task.;2007
In this paper we present a simple and robust mixed reality (MR) framework that allows for real-time interaction with virtual humans in mixed reality environments under consistent illumination. We will look at three crucial parts of this system: interaction animation and global illumination of virtual humans for an integrated and enhanced presence. The interaction system comprises of a dialogue module which is interfaced with a speech recognition and synthesis system. Next to speech output the dialogue system generates face and body motions which are in turn managed by the virtual human animation layer. Our fast animation engine can handle various types of motions such as normal key-frame animations or motions that are generated on-the-fly by adapting previously recorded clips. Real-time idle motions are an example of the latter category. All these different motions are generated and blended on-line resulting in a flexible and realistic animation. Our robust rendering method operates in accordance with the previous animation layer based on an extended for virtual humans precomputed radiance transfer (PRT) illumination model resulting in a realistic rendition of such interactive virtual characters in mixed reality environments. Finally we present a scenario that illustrates the interplay and application of our methods glued under a unique framework for presence and interaction in MR.;2007
In this paper we propose an intelligent TV interface using a voice-enable dialogue system. This paper rests on the both directions: a new type of dialogue management model and its use for practical systems to commercialize. We devise a practical dialogue management model based on statistical learning methods. To analyze discourse context we utilize statistical learning techniques for anaphora resolution and discourse history management. Contrary to the rule-based system we develop an incremental learning method to construct dialogue strategies from the training corpus. Several dialogue service models equipped with the proposed TV interface are explained. To evaluate our model and its impact on an application task we apply the stand-alone model to an TV settop box called eDi-TV.;2007
One of the biggest challenges in the development and deployment of spoken dialogue systems is the design of the spoken language generation module. This challenge arises from the need for the generator to adapt to many features of the dialogue domain  user population and dialogue context. A promising approach is trainable generation which uses general-purpose linguistic knowledge that is automatically adapted to the features of interest such as the application domain individual user or user group. In this paper we present and evaluate a trainable sentence planner for providing restaurant information in the MATCH dialogue system. We show that trainable sentence planning can produce complexin formation presentations whose quality is comparable to the output of a template-based generator tuned to this domain. We also show that our method easily supports adapting the sentence planner to individuals and that the individualized sentence planners generally perform better than models trained and tested on a population of individuals. Previous work has documented and uti utilized individual preferences for content selection but to our knowledge these results provide the first demonstration of individual preferences for sentence planning operations affecting the content order discourse structure and sentence structure of system responses. Finally we evaluate the contribution of different feature sets and show that in our application n-gram features often do as well as features based on higher-level linguistic representation.;2007
Recent years have seen steady improvements in the quality and performance of speech-based human-machine interaction driven by a significant convergence in the methods and techniques employed. However the quantity of training data required to improve state-of-the-art systems seems to be growing exponentially and performance appears to be asymptotic to a level that may be inadequate for many real-world applications. This suggests that there may be a fundamental flaw in the underlying architecture of contemporary systems as well as a failure to capitalize on the combinatorial properties of human spoken language. This paper addresses these issues and presents a novel architecture for speech-based human-machine interaction inspired by recent findings in the neurobiology of living systems. Called PRESENCE-PREdictive SENsorimotor Control and Emulation - this new architecture blurs the distinction between the core components of a traditional spoken language dialogue system and instead focuses on a recursive hierarchical feedback control structure. Cooperative and communicative behavior emerges as a by-product of an architecture that is founded on a model of interaction in which the system has in mind the needs and intentions of a user and a user has in mind the needs and intentions of the system.;2007
Recognition errors made by automatic speech recognition (ASR) systems may not prevent the development of useful dialogue applications if the interpretation strategy has an introspection capability for evaluating the reliability of the results. This paper proposes an interpretation strategy which is particularly effective when applications are developed with a training corpus of moderate size. From the lattice of word hypotheses generated by an ASR system a short list of conceptual structures is obtained with a set of finite state machines (FSM). Interpretation or a rejection decision is then performed by a tree-based strategy. The nodes of the tree correspond to elaboration-decision units containing a redundant set of classifiers. A decision tree based and two large margin classifiers are trained with a development set to become interpretation knowledge sources. Discriminative training of the classifiers selects linguistic and confidence-based features for contributing to a cooperative assessment of the reliability of an interpretation. Such an assessment leads to the definition of a limited number of reliability states. The probability that a proposed interpretation is correct is provided by its reliability state and transmitted to the dialogue manager. Experimental results are presented for a telephone service application.;2007
Speech communication interfaces (SCI) are nowadays widely used in several domains. Automated spoken language human-computer interaction can replace human-human interaction if needed. Automatic speech recognition (ASR) a key technology of SCI has been extensively studied during the past few decades. Most of present systems are based on statistical modeling both at the acoustic and linguistic levels. Increased attention has been paid to speech recognition in adverse conditions recently since noise-resistance has become one of the major bottlenecks for practical use of speech recognizers. Although many techniques have been developed many challenges still have to be overcome before the ultimate goal - creating machines capable of communicating with humans naturally - can be achieved. In this paper we describe the research and development of the first Slovak spoken language dialogue system. The dialogue system is based on the DARPA Communicator architecture. The proposed system consists of the Galaxy hub and telephony automatic speech recognition text-to-speech back-end transport and VoiceXML dialogue management modules. The SCI enables multi-user interaction in the Slovak language. Functionality of the SLDS is demonstrated and tested via two pilot applications Weather forecast for Slovakia and Timetable of Slovak Railways. The required information is retrieved from Internet resources in multi-user mode through PSTN ISDN GSM and/or VoIP network.;2007
The advancement of traffic and computer networks makes the world more and more internationalized and increases the frequency of communications between people who speak different languages and show different nonverbal behaviors. To improve the communication of embodied conversational agent (ECA) systems with their human users the importance of their capability to cover cultural differences emerged. Various excellent ECA systems are developed and proposed previously however the cross-culture communication issues are seldom addressed by researchers. This paper describes a short-term project aiming to explore the possibility of rapidly building multicultural and the multimodal ECA interfaces for a tour guide system by using a generic framework connecting their functional blocks.;2007
The aim of this study was to investigate the influence of modality on collaboration processes between human and computer. Spoken and written interactions with a natural language dialogue system were compared using two real information-retrieval systems. In order to look for a restaurant (Experiment 1) or plan a trip (Experiment 2) participants performed several task-oriented dialogue scenarios. Although the spoken interaction mode was less efficient it promoted collaboration the use of personal pronouns and the literal form of the system's command utterances. Overall in the written mode the emphasis was on the task and its performance rather than on dialogue. These findings are discussed with respect to the effect of communication mode on collaboration in human-computer dialogue. (C) 2007 Elsevier Ltd. All rights reserved.;2007
The 'authenticity' of fictional dialogue is widely held to play a pivotal role in shaping the audience's perception of the quality of a film. Yet the factors that account for the authenticity of both original and dubbed film conversation remain largely under-researched. This paper begins by outlining key contributions from the fields of stylistics film studies and corpus-based translation studies that have enhanced our understanding of the specific nature and dynamics of fictional dialogue and its translation. A common assumption that underpins these approaches is that the success of the narrative and characterization-enhancing resources deployed in a film is contingent on the build-up of interpersonal alignments through a combination of prefabricated orality and spontaneous-sounding conversation. And yet both film theory and dubbing studies have so far focused on phenomena that take place within a single turn-at-talk and hence neglected the study of the sequential dimension of film dialogue. Drawing on the analysis of four scenes of the English and Spanish versions of Twelve Angry Men (Sidney Lumet 1957) this article attempts to demonstrate the advantages of Martin's (2000a) systemic functional modelling of the exchange especially his notion of 'telos'. Ultimately this paper assesses the advantages of a heightened awareness of the sequential configuration of dialogue among dubbing practitioners.;2007
The empirical investigation of human gesture stands at the center of multiple research disciplines and various gesture annotation schemes exist with varying degrees of precision and required annotation effort. We present a gesture annotation scheme for the specific purpose of automatically generating and animating character-specific hand/arm gestures but with potential general value. We focus on how to capture temporal structure and locational information with relatively little annotation effort. The scheme is evaluated in terms of how accurately it captures the original gestures by re-creating those gestures on an animated character using the annotated data. This paper presents our scheme in detail and compares it to other approaches.;2007
The open-vocabulary name recognition technique is one of the most challenging tasks in the application of automatic Chinese speech recognition technology. It can be used as the free name input method for telephony speech applications and automatic directory assistance systems. A Chinese name usually has two to three characters each of which is pronounced as a single tonal syllable. Obviously it is very confusing to recognize a three-syllable word from millions to billions of possible candidates. A novel interactive automatic-speech-recognition system is proposed to resolve this highly challenging task. This system was built as an open-vocabulary Chinese name recognition system using character-based approaches. Two important character-input speech-recognition modules were designed as backoff approaches in this system to complete the name input or to correct any misrecognized characters. Finite-state networks were compiled from regular grammar of syllable spellings and character descriptions for these two speech recognition modules. The possible candidate names cover more than five billions. This system has been tested publicly and proved a robust way to interact with the speaker. An 86.7% name recognition success rate was achieved by the interactive open-vocabulary Chinese name input system.;2007
There is an extensive body of work on Intelligent Tutoring Systems: computer environments for education teaching and training that adapt to the needs of the individual learner. Work on personalisation and adaptivity has included research into allowing the student user to enhance the system's adaptivity by improving the accuracy of the underlying learner model. Open Learner Modelling where the system's model of the user's knowledge is revealed to the user has been proposed to support student reflection oil their learning. Increased accuracy of the learner model can be obtained by the student and system jointly negotiating the learner model. We present the initial investigations into a system to allow people to negotiate the model of their understanding of a topic in natural language. This paper discusses the development and capabilities of both conversational agents (or chatbots) and Intelligent Tutoring Systems in particular Open Learner Modelling. We describe a Wizard-of-Oz experiment to investigate the feasibility of using a chatbot to support negotiation and conclude that a fusion of the two fields can lead to developing negotiation techniques for chatbots and the enhancement of the Open Learner Model. This technology if successful could have widespread application in schools universities and other training scenarios. (c) 2006 Elsevier B.V. All rights reserved.;2007
This article argues that a clear division between two sources of information-one oriented to world knowledge the other to linguistic semantics-offers a framework within which mechanisms for modelling the highly flexible relation between language and interpretation necessary for natural discourse can be specified and empirically validated. Moreover importing techniques and results from formal ontology provides the formal underpinnings necessary for representing these sources of information appropriately. The result is a computationally specifiable model of dialogic interaction within which flexible discourse interpretation occurs as the result of inter-ontology mappings between our two sources of information. These mappings are dynamically negotiated according to the concrete discourse moves of interlocutors. The article draws on ongoing empirical-studies in spatial discourse where interlocutors jointly solve varieties of spatially embedded tasks and suggests that ontological formalization benefits the construction of computational dialogue systems.;2007
This paper addresses the problem of recognizing a vocabulary of over 50000 city names in a telephone access spoken dialogue system. We adopt a two-stage framework in which only major cities are represented in the first stage lexicon. We rely on an unknown word model encoded as a phone loop to detect OOV city names (referred to as 'rare city' names). We use SpeM a tool that can extract words and word-initial cohorts from phone graphs from a large fallback lexicon to provide an N-best list of promising city name hypotheses on the basis of the phone graph corresponding to the OOV. This N-best list is then inserted into the second stage lexicon for a subsequent recognition pass. Experiments were conducted on a set of spontaneous telephone-quality utterances each containing one rare city name. It appeared that SpeM was able to include nearly 75% of the correct city names in an N-best hypothesis list of 3000 city names. With the names found by SpeM to extend the lexicon of the second stage recognizer a word accuracy of 77.3% could be obtained. The best one-stage system yielded a word accuracy of 72.6%. The absolute number of correctly recognized rare city names almost doubled from 62 for the best one-stage system to 102 for the best two-stage system. However AA even the best two-stage system recognized only about one-third of the rare city names retrieved by SpeM. The paper discusses ways for improving the overall performance in the context of an application. (c) 2006 Elsevier Ltd. All rights reserved.;2007
This paper argues that interactive knowledge acquisition systems would benefit from a tighter and more thorough incorporation of tutoring and learning principles. Current acquisition systems learn from users in a passive manner and could instead be designed to incorporate the proactive capabilities that one expects of a good student. We first describe our analysis of the literature on teacher-student interaction and present a compilation of tutoring and learning principles that are relevant to interactive knowledge acquisition systems. We then point out what tutoring and learning principles have been used to date in the acquisition literature though unintentionally and implicitly and discuss how a more thorough and explicit representation of these principles would help improve how computers learn from users. We present our design and an initial implementation of an acquisition dialogue system called SLICK that represents acquisition principles and goals explicitly and declaratively making the system actively reason about various acquisition tasks and generate its interactions dynamically. Finally we discuss promising directions in designing acquisition systems by structuring interactions with users according to tutoring and learning principles. (C) 2007 Elsevier Ltd. All rights reserved.;2007
This paper describes an integrated system based on open-domain and domain-specific knowledge for the purpose of providing query-based intelligent web interaction. It is understood that general purpose conversational agents are not able to answer questions on specific domain subject. On the other hand domain specific systems lack the flexibility to handle common sense questions. To overcome the above limitations this paper proposed an integrated system comprises of an artificial intelligent conversation software robot or chatterbot called Artificial Intelligence Natural-language Identity (hereafter AINI) and an Automated Knowledge Extraction Agent (AKEA) for the acquisition of real world knowledge from the Internet. The objective of AKEA is to retrieve real world knowledge or information from trustworthy websites. AINI is the mechanism used to manage the knowledge and to provide appropriate answer to the user. In this paper we compare the performance of the proposed system against two popular search engines two question answering systems and two other conversational systems.;2007
This paper investigates the potential use of dialog-based ALICEbots in disseminating terrorism information to the general public. In particular we study the acceptance and response satisfaction of ALICEbot responses in both the general conversation and terrorism domains. From our analysis of three different knowledge sets: general conversation terrorism and combined we found that users were more favorable to the systems that exhibited conversational flow. We also found that the system that incorporated both conversation and terrorism knowledge performed better than systems with only conversation or terrorism knowledge alone. Lastly we were interested in what types of questions were the most prevalently used and discovered that questions beginning with `wh*' words were the most popular method to start an interrogative sentence. However `wh* sentence starters surprisingly proved to be in a very narrow majority. (C) 2006 Elsevier B.V. All rights reserved.;2007
Until now research on arrangement of verbal and non-verbal information in multimedia presentations has not considered multimodal behavior of animated agents. In this paper we will present an experiment exploring the effects of different types of speech-gesture cooperation in agents' behavior: redundancy (gestures duplicate pieces of information conveyed by speech) complementarity (distribution of information across speech and gestures) and a control condition in which gesture does not convey semantic information. Using a Latin-square design these strategies were attributed to agents of different appearances to present different objects. Fifty-four male and 54 female users attended three short presentations performed by the agents recalled the content of presentations and evaluated both the presentations and the agents. Although speech-gesture cooperation was not consciously perceived it proved to influence users' recall performance and subjective evaluations: redundancy increased verbal information recall ratings of the quality of explanation and expressiveness of agents. Redundancy also resulted in higher likeability scores for the agents and a more positive perception of their personality. Users' gender had no influence on this set of results. (C) 2007 Published by Elsevier B.V.;2007
We consider the problem of detecting anomalies in data that arise as multidimensional arrays with each dimension corresponding to the levels of a categorical variable. In typical data mining applications the number of cells in such arrays are usually large. Our primary focus is detecting anomalies by comparing information at the current time to historical data. Naive approaches advocated in the process control literature do not work well in this scenario due to the multiple testing problem-performing multiple statistical tests on the same data produce excessive number of false positives. We use an empirical Bayes method which works by fitting a two-component Gaussian mixture to deviations at current time. The approach is scalable to problems that involve monitoring massive number of cells and fast enough to be potentially useful in many streaming scenarios. We show the superiority of the method relative to a naive per component error rate procedure through simulation. A novel feature of our technique is the ability to suppress deviations that are merely the consequence of sharp changes in the marginal distributions. This research was motivated by the need to extract critical application information and business intelligence from the daily logs that accompany large-scale spoken dialog systems. We illustrate our method on one such system.;2007
We describe a study of the use of decision-theoretic policies for optimally joining human and automated problem-solving efforts. We focus specifically on the challenge of determining when it is best to transfer callers from an automated dialog system to human receptionists. We demonstrate the sensitivities of transfer actions to both the inferred competency of the spoken-dialog models and the current sensed load on human receptionists. The policies draw upon probabilistic models constructed via machine learning from cases that were logged by a call routing service deployed at our organization. We describe the learning of models that predict outcomes and interaction times and show how these models can be used to generate expected-utility policies that identify when it is best to transfer callers to human operators. We explore the behavior of the policies with simulations constructed from real-world call data.;2007
We describe an implementation integrating a complete spoken dialogue system with a mobile robot which a human can direct to specific locations ask for information about its status and supply information about its environment. The robot uses an internal map for navigation and communicates its current orientation and accessible locations to the dialogue system using a topological map as interface. We focus on linguistic and inferential aspects of the human-robot communication process. The result is a novel approach using a principled semantic theory combined with techniques from automated deduction applied to a mobile robot platform. Due to the abstract level of the dialogue system it is easily portable to other environments or applications.;2007
We describe the construction of a generic natural language query interface to an XML database. Our interface can accept a large class of English sentences as a query which can be quite complex and include aggregation nesting and value joins among other things. This query is translated potentially after reformulation into an XQuery expression. The translation is based on mapping grammatical proximity of natural language parsed tokens in the parse tree of the query sentence to proximity of corresponding elements in the XML data to be retrieved. Iterative search in the form of followup queries is also supported. Our experimental assessment through a user study demonstrates that this type of natural language interface is good enough to be usable now with no restrictions on the application domain.;2007
We propose three methods for extending the Boosting family of classifiers motivated by the real-life problems we have encountered. First we propose a semisupervised learning method for exploiting the unlabeled data in Boosting. We then present a novel classification model adaptation method. The goal of adaptation is optimizing an existing model for a new target application which is similar to the previous one but may have different classes or class distributions. Finally we present an efficient and effective cost-sensitive classification method that extends Boosting to allow for weighted classes. We evaluated these methods for call classification in the AT&T VoiceTone (R) spoken language understanding system. Our results indicate that it is possible to obtain the same classification performance by using 30% less labeled data when the unlabeled data is utilized through semisupervised learning. Using model adaptation we can achieve the same classification accuracy using less than half of the labeled data from the new application. Finally we present significant improvements in the important (i.e. higher weighted) classes without a significant loss in overall performance using the proposed cost-sensitive classification method.;2007
What is the hallmark of success in human-agent interaction? In animation and robotics many have concentrated on the looks of the agent-whether the appearance is realistic or lifelike. We present an alternative benchmark that lies in the dyad and not the agent alone: Does the agent's behavior evoke intersubjectivity from the user? That is in both conscious and unconscious communication do users react to behaviorally realistic agents in the same way they react to other humans? Do users appear to attribute similar thoughts and actions? We discuss why we distinguish between appearance and behavior why we use the benchmark of intersubjectivity our methodology for applying this benchmark to embodied conversational agents (ECAs) and why we believe this benchmark should be applied to human-robot interaction.;2007
A conversational agent capable to have a sense of humor is presented. The agent can both generate humorous sentences and recognize humoristic expressions introduced by the user during the dialogue. EHeBby is an entertainment oriented conversational agent implemented using the ALICE framework embedded into an Yahoo! Messenger client. It is characterized by two areas: a rational rule-based area and an evocative area. The first one is based on well founded techniques of computational humor and a standard AIML KB. The second one is based on a conceptual space automatically induced by a corpus of funny documents where KB items and user sentences are mapped. This area emulates an associative/evocative behavior of the conversational agent making her more attractive. EHeBby includes also an avatar that changes the face expression according to humoristic content of the dialogue.;2008
A multiplayer dice game was realized which is played by two users and one embodied conversational agent. During the game the players have to lie to each other to win the game and the longer the game commences the more probable it is that someone is lying which creates highly emotional situations. We ran a number of evaluation studies with the system. The specific setting allows us to compare user-user interactions directly with user-agent interactions in the same game. So far the users' gaze behavior and the users' verbal behavior towards one another and towards the agent have been analyzed. Gaze and verbal behavior towards the agent partly resembles patterns found in the literature for human-human interactions partly the behavior deviates from these observations and could be interpreted as rude or impolite like continuous staring insulting or talking about the agent. For most of these seemingly abusive behaviors a more thorough analysis reveals that they are either acceptable or present some interesting insights for improving the interaction design between users and embodied conversational agents. (C) 2008 Elsevier B.V. All rights reserved.;2008
A novel assessment procedure based on knowledge space theory (KST) is presented along with a complete implementation of an intelligent tutoring system. (ITS) that has been used to test our theoretical findings. The key idea is that correct assessment of the student knowledge is strictly related to the structure of the domain ontology. Suitable relationships between the concepts must be present to allow the creation of a reverse path from the knowledge state representing the student goal to the one that contains her actual knowledge about this topic. Knowledge space theory is a very good framework to guide the process of building the ontology used by the artificial tutor The system. we present uses a conversational. agent to assess the student knowledge through a natural language question/answer procedure. The system exploits a Cyc-based common sense ontology about the specific domain of interest to select the concepts needed to explain unknown topics emerging from the dialogue. Besides the talent semantic analysis (LSA) technique is used to determine the correctness of the student sentences in order to establish which concepts she knows. As a result the system supplies learning material arranged as a path between the unknown topics resulting from the student assessment. The learning path is presented to the student by a user-firiendly graphical interface which allows to access documents browsing a visual map. The procedure is explained in detail along with the rest of the system. and the assessment validation results are presented.;2008
Although dialogue systems have been all area of research for decades finding accurate ways of evaluating different systems is still a very active subfield since many leading methods such as task completion rate or user satisfaction capture different aspects of the end-to-end human-computer dialogue interaction. In this work we step back the focus from the complete evaluation of a dialogue system to presenting metrics for evaluating one internal component of a dialogue system: its dialogue manager. Specifically we investigate how to create and evaluate the best state space representations for a Reinforcement Learning model to learn an optimal dialogue control strategy. We present three metrics for evaluating the impact of different state models and demonstrate their use oil the domain of a spoken dialogue tutoring system by comparing the relative utility of adding three features to a model of user or student state. The motivation for this work is that if one knows which features are best to use one can construct a better dialogue manager and thus better performing dialogue systems. (c) 2008 Elsevier B.V. All rights reserved.;2008
Conversation systems are moving out of the research labs and out into the real world. The persistent belief that conversation would be the most natural and powerful user interface to computers. This change is important for the performance of the systems. In this paper we present an experiment named a multimedia conversation System with application in supervised learning method and ranking function. This paper firstly discusses how to use multimedia information build knowledge database. Then it introduces applying the supervised learning method and ranking function to Natural Language Understanding (NLU) and Natural Language Generation (NLG). Finally it gives experiment approach and results. The experiment showed that this method could achieve better results in practice.;2008
Dialogue systems are one of the most interesting applications of speech and language technologies. There have recently been some attempts to build dialogue systems in Spanish and some corpora have been acquired and annotated. Using these corpora statistical machine learning methods can be applied to try to solve problems in spoken dialogue systems. In this paper two statistical models based on the maximum likelihood assumption are presented and two main applications of these models on a Spanish dialogue corpus are shown: labelling and decoding. The labelling application is useful for annotating new dialogue corpora. The decoding application is useful for implementing dialogue strategies in dialogue systems. Both applications centre on unsegmented dialogue turns. The obtained results show that although limited the proposed statistical models are appropriate for these applications. (C) 2008 Elsevier B.V. All rights reserved.;2008
Evaluation of spoken dialogue systems has been traditionally carried out in terms of instrumentally or expert-derived measures (usually called objective evaluation) and quality judgments of users who have previously interacted with the system (also called subjective evaluation). Different research efforts have been made to extract relationships between these evaluation criteria. In this paper we report empirical results obtained from statistical studies which were carried out on interactions of real users with our spoken dialogue system. These studies have rarely been exploited in the literature. Our results show that they can indicate important relationships between criteria which can be used as guidelines for refinement of the systems under evaluation as well as contributing to the state-of-the-art knowledge about how quantitative aspects of the systems affect the user's perceptions about them. (c) 2008 Elsevier B.V. All rights reserved.;2008
In designing a spoken dialogue system developers need to specify the actions a system should take in response to user speech input and the state of the environment based on observed or inferred events states and beliefs. This is the fundamental task of dialogue management. Researchers have recently pursued methods for automating the design of spoken dialogue management using machine learning techniques such as reinforcement learning. In this paper we discuss how dialogue management is handled in industry and critically evaluate to what extent current state-of-the-art machine learning methods can be of practical benefit to application developers who are deploying commercial production systems. In examining the strengths and weaknesses of these methods we highlight what academic researchers need to know about commercial deployment if they are to influence the way industry designs and practices dialogue management. (c) 2008 Elsevier B.V. All rights reserved.;2008
In this article we investigate the discourse between a female conversational pedagogical agent and 59 adolescents in the context of a social studies lesson. We note that previous pedagogical agent research has focused on the positive effects of agents while failing to take into account the intricacies of learner-agent discourse and subsequently missing the abuse suffered by pedagogical agents at users' fingertips. Our analysis indicates that learners readily misuse and abuse pedagogical agents while placing them in a subordinate and inferior role. We conclude by making recommendations on agent design and future research. (C) 2008 Elsevier B.V. All rights reserved.;2008
In this paper we present the design implementation and evaluation of SOBA a system for ontology-based information extraction from heterogeneous data resources including plain text tables and image captions. SOBA is capable of processing structured information text and image captions to extract information and integrate it into a coherent knowledge base. To establish coherence SOBA interlinks the information extracted from different sources and detects duplicate information. The knowledge base produced by SOBA can then be used to query for information contained in the different sources in an integrated and seamless manner. Overall this allows for advanced retrieval functionality by which questions can be answered precisely. A further distinguishing feature of the SOBA system is that it straightforwardly integrates deep and shallow natural language processing to increase robustness and accuracy. We discuss the implementation and application of the SOBA system within the SmartWeb multimodal dialog system. In addition we present a thorough evaluation of the different components of the system. However an end-to-end evaluation of the whole SmartWeb system is out of the scope of this paper and has been presented elsewhere by the SmartWeb consortium. (C) 2008 Elsevier Ltd. All rights reserved.;2008
In this paper we compare different approaches for predicting the quality and usability of spoken dialogue systems. The respective models provide estimations of user judgments oil perceived quality based oil parameters which can be extracted from interaction logs. Different types of input parameters and different modeling algorithms have been compared using three spoken dialogue databases obtained with two different systems. The results show that both linear regression models and classification trees are able to cover around 50% of the variance in the training data and neural networks even more. When applied to independent test data in particular to data obtained with different systems and/or user groups the prediction accuracy decreases significantly. The underlying reasons for the limited predictive power are discussed. It is shown that - although an accurate prediction of individual ratings is not yet possible with such models - they may still be used for taking decisions oil component optimization and are thus helpful tools for the system developer. (c) 2008 Elsevier B.V. All rights reserved.;2008
In this paper we examine the meaning of conversing with pedagogical agents. Previous research has focused on examining cause and effect relationships failing to take into account the meaning of the experiences individuals have when holding a dialogue with conversational agents for educational purposes. To understand these experiences we have conducted a phenomenological examination of what it means to converse with a pedagogical agent. In phenomenological terms findings suggest the experience is complex engrossing virtual yet real human-like and social. Implications for the future design implementation and research of conversational agents in educational and other settings are discussed.;2008
In this paper we present a statistical approach for the development of a dialog manager and for learning optimal dialog strategies. This methodology is based oil a classification procedure that considers all of the previous history of the dialog to select the next system answer. To evaluate the performance of the dialog system the statistical approach for dialog management has been extended to model the user behavior. The statistical user simulator has been used for the evaluation and improvement of the dialog strategy. Both the user model and the system model arc automatically learned from a training corpus that is labeled in terms of dialog acts. New measures have been defined to evaluate the performance of the dialog system. Using these measures we evaluate both the quality of the simulated dialogs and the improvement of the new dialog strategy that is obtained with the interaction of the two modules. This methodology has been applied to develop a dialog manager within the framework of the DIHANA project whose goal is the design and development of a dialog system to access a railway information system using spontaneous speech in Spanish. We propose the use of corpus-based methodologies to develop the main modules in the dialog system. (c) 2008 Elsevier B.V. All rights reserved.;2008
In this paper we study the impact of considering context information for the annotation of emotions. Concretely we propose the inclusion of the history of user-system interaction and the neutral speaking style of users. A new method to automatically include both sources of information has been developed making use of novel techniques for acoustic normalization and dialogue context annotation. We have carried out experiments with a corpus extracted from real human interactions with a spoken dialogue system. Results show that the performance of non-expert human annotators and machine-learned classifications are both affected by contextual information. The proposed method allows the annotation of more non-neutral emotions and yields values closer to maximum agreement rates for nonexpert human annotation. Moreover automatic classification accuracy improves by 29.57% compared to the classical approach based only on acoustic features. (c) 2008 Elsevier B.V. All rights reserved.;2008
Irion Technologies is a language technology company at Delft (The Netherlands) that incorporates linguistic knowledge to build new generations of information systems: conceptual retrieval automatic extraction of terms and ontologies and open-domain dialogue systems. These systems are multi-lingual and cross-lingual and combine statistical machine learning techniques with linguistic techniques. We have carried out evaluations of some of these systems. For information retrieval we found advantages with respect to standard statistical approaches within special experimental settings that focus on ambiguity. Term extraction is clearly benefiting from rich linguistic knowledge and resources. Dialogue systems depend on the communicative models and systems that also require deep linguistic processing. From our perspective language technology is definitely helping to make applications better and necessary to develop new applications.;2008
Natural and intuitive interaction between users and complex systems is a crucial research topic in human-computer interaction. A major direction is the definition and implementation of systems with natural language understanding capabilities The interaction in natural language is often performed by means of systems called chatbots. A chatbot is a conversational agent with a proper knowledge base able to interact with users. Chatbots appearance can be very sophisticated with 3D avatars and speech processing modules. However the interaction between the system and the user is only performed through textual areas for inputs and replies. An interaction able to add to natural language also graphical widgets could be more effective. On the other side a graphical interaction involving also the natural language can increase the comfort of the user instead of using only graphical widgets. In many applications multi-modal communication must be preferred when the user and the system have a tight and complex interaction. Typical examples are cultural heritages applications (intelligent museum guides picture browsing) or systems providing the user with integrated information taken from different and heterogenous sources as in the case of the iGoogle (TM) interface We propose to mix the two modalities (verbal and graphical) to build systems with a reconfigurable interface which is able to change with respect to the particular application context. The result of this proposal is the Graphical Artificial Intelligence Markup Language (GAIML) an extension of AIML allowing merging both interaction modalities. In this context a suitable chatbot system called Graphbot is presented to support this language. With this language is possible to define personalized interface patterns that are the most suitable ones in relation to the data types exchanged between the user and the system according to the context of the dialogue.;2008
Purpose - This paper aims to give an overview of a dialogue manager and recent experiments with multimodal human-robot dialogues. Design/methodology/approach - The paper identifies requirements and solutions in the design of a human-robot interface. The paper presents essential techniques for a humanoid robot in a household environment and describes their application to representative interaction scenarios that are based on standard situations for a humanoid robot in a household environment. The presented dialogue manager has been developed within the German collaborative research center SFB-588 on Humanoid Robots - Learning and Cooperating Multimodal Robots. The dialogue system is embedded in a multimodal perceptual system of the humanoid robot developed within this project. The implementation of the dialogue manager is geared to requirements found in the explored scenarios. The algorithms include multimodal fusion reinforcement learning knowledge acquisition and tight coupling of dialogue manager and speech recognition. Findings - Within the presented scenarios several algorithms have been implemented and show improvements of the interactions. Results are reported within scenarios that model typical household situations. Research limitations/implications - Additional scenarios need to be explored especially in real-world (out of the lab) experiments. Practical implications - The paper includes implications for the development of humanoid robots and human-robot interaction. Originality/value - This paper explores human-robot interaction scenarios and describes solutions for dialogue systems.;2008
Rapid deployment of statistical spoken dialogue systems poses portability challenges for building new applications. We discuss the challenges that arise and focus on two main problems: (i) fast semantic annotation for statistical speech understanding and (ii) reliable and efficient statistical language modeling using limited in-domain resources. We address the first problem by presenting a new boot-strapping framework that uses a majority-voting based combination of three methods for the semantic annotation of a mini-corpus that is usually manually annotated. The three methods are a statistical decision tree based parser a similarity measure and a support vector machine classifier. The bootstrapping framework results in an overall cost reduction of about a factor of two in the annotation effort compared to the baseline method. We address the second problem by devising a method to efficiently build reliable statistical language models for new spoken dialog systems given limited in-domain data. This method exploits external text resources that are collected for other speech recognition tasks as well as dynamic text resources acquired from the World Wide Web. The proposed method is applied to a spoken dialog system in a financial transaction domain and a natural language call-routing task in a package shipment domain. The experiments demonstrate that language models built using external resources when used jointly with the limited in-domain language model result in relative word error rate reductions of 9-18%. Alternatively the proposed method can be used to produce a 3-to-10 fold reduction for the in-domain data requirement to achieve a given performance level. (c) 2008 Elsevier B.V. All rights reserved.;2008
Recently data-driven speech technologies have been widely used to build speech user interfaces. However developing and managing data-driven spoken dialog systems arc laborious and time consuming tasks. Spoken dialog systems have many components and their development and management involves numerous tasks such as preparing the corpus training testing and integrating each component for system development and management. In addition data annotation for natural language understanding and speech recognition is quite burdensome. This paper describes the development of a tool DialogStudio to support the development and management of data-driven spoken dialog systems. Desirable aspects of the data-driven spoken dialog system workbench tool are identified and architectures and concepts are proposed that make DialogStudio efficient in data annotation and system development in a domain and methodology neutral manner. The usability of DialogStudio was validated by developing dialog systems in three different domains with two different dialog management methods. Objective evaluations of each domain show that DialogStudio is a feasible solution as a workbench for data-driven spoken dialog systems. (c) 2008 Elsevier B.V. All rights reserved.;2008
Smart and intelligent environments can proficiently benefit a new generation of multimodal dialog systems which enable users to interact in natural ways like voice gesture facial motions and so on. However in order to make this possible it is necessary to integrate such systems and services possibly in a transparent way. In the present paper we propose an architectural model for multimodal smart environments then an agent-based middleware infrastructure that provides basic components for the integration of multimodal interaction systems and a set of ontologies and rules for semantically handling interacting properties of devices and resources available in smart environments. (C) 2008 Elsevier B.V. All rights reserved.;2008
Speech recognition in a noisy environment is one of the hottest topics in the speech recognition research. Noise-tolerant acoustic models or noise reduction techniques are often used to improve recognition accuracy. In this paper we propose a method to improve accuracy of spoken dialog system from a language model point of view. In the proposed method the dialog system automatically changes its language model and dialog strategy according to the estimated recognition accuracy in a noisy environment in order to keep the performance of the system high. In a noise-free environment the system accepts any utterance from a user. On the other hand the system restricts its grammar and vocabulary in a noisy environment. To realize this strategy we investigated a method to avoid the user's out-of-grammar utterances through an instruction given by the system to a user. Furthermore we developed a method to estimate recognition accuracy from features extracted from noise signals. Finally we realized a proposed dialog system according to these investigations.;2008
Spoken dialogue systems must inevitably deal with out-of-grammar utterances. We address this problem in multi-domain spoken dialogue systems which deal with more tasks than a single-domain system. We defined a topic by augmenting a domain about which users want to find more information and we developed a method of recovering out-of-grammar utterances based on topic estimation i.e. by providing a help message in the estimated domain. Moreover domain extensibility that is the ability to add new domains to the system should be inherently retained in multi-domain systems. To estimate domains without sacrificing extensibility we collected documents from the Web as training data. Since the data contained a certain amount of noise we used latent semantic mapping (LSM) which enables robust topic estimation by removing the effects of noise from the data. Experimental results showed that our method improved topic estimation accuracy by 23.2 points for data including out-of-grammar utterances. (c) 2008 Elsevier B.V. All rights reserved.;2008
Spoken language is one of the most intuitive forms of interaction between humans and agents. Unfortunately agents that interact with people using natural language often experience communication errors and do not correctly understand the user's intentions. Recent systems have successfully used probabilistic models of speech language and user behaviour to generate robust dialogue performance in the presence of noisy speech recognition and ambiguous language choices but decisions made using these probabilistic models are still prone to errors owing to the complexity of acquiring and maintaining a complete model of human language and behaviour. In this paper a decision-theoretic model for human-robot interaction using natural language is described. The algorithm is based on the Partially Observable Markov Decision Process (POMDP) which allows agents to choose actions that are robust not only to uncertainty from noisy or ambiguous speech recognition but also unknown user models. Like most dialogue systems a POMDP is defined by a large number of parameters that may be difficult to specify a priori from domain knowledge and learning these parameters from the user may require an unacceptably long training period. An extension to the POMDP model is described that allows the agent to acquire a linguistic model of the user online including new vocabulary and word choice preferences. The approach not only avoids a training period of constant questioning as the agent learns but also allows the agent actively to query for additional information when its uncertainty suggests a high risk of mistakes. The approach is demonstrated both in simulation and on a natural language interaction system for a robotic wheelchair application.;2008
Surgeons may be severely criticized from the perspective of evidence-based medicine because the majority of surgical publications appear not to be convincing. In the top nine surgical journals in 1996 half of the 175 publications refer to pilot studies lacking a control group 18% to animal experiments and only 5% to randomized controlled trials (RCT). There are five levels of clinical evidence: level 1 (randomized controlled trial) level 2 (prospective concurrent cohort study) level 3 (retrospective historical cohort study) level 4 (pre-post study) and level 5 (case report). Recently a Japanese evidence-based guideline for the surgical treatment of hepatocellular carcinoma (HCC) was made by a committee (Chairman Professor Makuuchi and five members). We searched the literature using the Medline Dialog System with four keywords: HCC surgery English papers in the last 20 years. A total of 915 publications were identified systematically reviewed. At the first selection (in which surgery-dominant papers were selected) 478 papers survived. In the second selection (clearly concluded papers) 181 papers survived. In the final selection (clinically significant papers) 100 papers survived. The evidence level of the 100 surviving papers is shown here: level-1 papers (13%) level-2 papers (11%) level-3 papers (52%) and level-4 papers (24%) therefore there were 24% prospective papers and 76% retrospective papers. Here we present a part of the guideline on the five main surgical issues: indication to operation operative procedure peri-operative care prognostic factor and post-operative adjuvant therapy. (C) 2008 WJG. All rights reserved.;2008
The aim of this paper is to present the concept for the development of an entirely speech-based user interface for a digital radio in combination with the possibility to specifically search for audio and data content. On the basis of a Digital Audio Broadcasting DAB device the embedded system utilizes a multichannel receiver with the possibility of simultaneously monitoring a variety of information sources with the purpose to generate spoken replies to verbal user requests. Furthermore the system embraces at audio repository storing speech-based content elements to diminish the volatile property of broadcast content and to enable a memory function.(1);2008
The first generation of Location-based Services (LBSs) did not succeed on the market. In order to prepare LBSs of the next generation for the challenges of pervasive service execution in different situations (e.g. while walking on the street or while driving a car) the user interface must provide a second modality of interaction besides the visual interface. In this paper we describe the challenges and a possible solution for combining LBSs with a spoken-dialogue user interface.;2008
The main task of a service robot with a voice-enabled communication interface is to engage a user in dialogue providing an access to the services it is designed for. In managing such interaction inferring the user goal (intention) from the request for a service at each dialogue turn is the key issue. In service robot deployment conditions speech recognition limitations with noisy speech input and inexperienced users may jeopardize user goal identification. In this paper we introduce a grounding state-based model motivated by reducing the risk of communication failure due to incorrect user goal identification. The model exploits the multiple modalities available in the service robot system to provide evidence for reaching grounding states. In order to handle the speech input as sufficiently grounded (correctly understood) by the robot four proposed states have to be reached. Bayesian networks combining speech and non-speech modalities during user goal identification are used to estimate probability that each grounding state has been reached. These probabilities serve as a base for detecting whether the user is attending to the conversation as well as for deciding on an alternative input modality (e.g. buttons) when the speech modality is unreliable. The Bayesian networks used in the grounding model are specially designed for modularity and computationally efficient inference. The potential of the proposed model is demonstrated comparing a conversational system for the mobile service robot RoboX employing only speech recognition for user goal identification and a system equipped with multimodal grounding. The evaluation experiments use component and system level metrics for technical (objective) and user-based (subjective) evaluation with multimodal data collected during the conversations of the robot RoboX with users.;2008
The usage patterns of speech and visual input modes are investigated as a function of relative. input mode efficiency for both desktop and personal digital assistant (PDA) working environments. For this purpose the form-filling part of a multimodal dialogue system is implemented and evaluated three multimodal modes of interaction are implemented: Click-to-Talk Open-Mike and Modality-Selection. Modality-Selection implements an adaptive interface where the system selects the most efficient input mode at each turn. effectively. alternating between a Click-to-Talk and Open-Mike interaction style as proposed in Modality tracking in the multimodal Bell Labs Communicator in Proceedings of the Automatic Speech Recognition and Understanding Workshop by A. Potamianos et al. 2003. The multimodal systems are evaluated and compared with the unimodal systems. Objective and subjective measures used include task completion task duration turn duration and overall user satisfaction. Turn duration is broken down into interaction time and inactivity time to better measure the efficiency of each input mode. Duration statistics and empirical probability density functions are computed as a function of interaction context and user. Results show that the multimodal systems outperform the unimodal systems in terms of objective and subjective criteria. Also users tend to use the most efficient input mode at each turn however biases towards the default input modality and a general bias towards the speech modality also exists. Results demonstrate that although users exploit some of the available synergies in multimodal dialogue interaction further efficiency gains can be achieved by designing adaptive interfaces that fully exploit these synergies.;2008
This article describes an integrated system managed by an artificial agent (ChatBot) whose knowledge base has been realised in Artificial Intelligence Markup Languange (AIML). The system is able to constantly supervise the activities of the servers and at the same time realise backup distribution to safeguard the data in e-learning contexts. It also interacts with a Private Automatic Branch eXchange (PABX) for the management of the Voice over Internet Protocol (VoIP) telephone system. This system has been conceived as support for the management of web sections and in particular web-learning (w-learning) platforms. The purpose is to be able to watch the platform's activity all the time to immediately 'warn' when there are problems deriving from the platform contents and warn the technical area in case of failures in the server system that contains the w-learning platform. In addition the backup system guarantees having a frequently updated file of the data present on the various servers on which the e-learning platform leans so that safety can be guaranteed in case of the permanent loss of the data present on the servers.;2008
This article focuses on issues relevant to human-computer interaction in the case of autism. We designed training software that target specific communicative disorders attributed to autism and defined an empirical protocol to test this software. The experimental software platform that we developed manages each game's interface modalities and logs users' actions for the purpose of exploring the impact of various human-computer interfaces which involve text speech and images. Ten adolescents diagnosed with autism used this software during 13 sessions at the rate of one session per week. The first and last sessions were dedicated for evaluating participants' skills. The experiment was also performed by a group of 10 typically developing children matched on developmental age and academic level. Results show that participants with autism had poorer performances on the richer multimedia interfaces. They seemed to lack the initiative of organizing the available multimodal sources of information. In this article we specifically discuss the impact of executive disorders on the use of multimodal interfaces with an emphasis on Animated Conversational Agents. (C) 2008 Elsevier Ltd. All rights reserved.;2008
This article presents a bilingual ontology-based dialog system with multiple services. An ontology-alignment algorithm is proposed to integrate ontologies of different languages for cross-language applications. A domain-specific ontology is further extracted from the bilingual ontology using an island-driven algorithm and a domain corpus. This study extracts the semantic words/concepts using latent semantic analysis (LSA). Based on the extracted semantic words and the domain ontology a partial pattern tree is constructed to model the speech act of a spoken utterance. The partial pattern tree is used to deal with the ill-formed sentence problem in a spoken-dialog system. Concept expansion based on domain ontology is also adopted to improve system performance. For performance evaluation a medical dialog system with multiple services including registration information clinic information and FAQ information is implemented. Four performance measures were used separately for evaluation. The speech act identification rate was 86.2%. A task success rate of 77% was obtained. The contextual appropriateness of the system response was 78.5%. Finally the rate for correct FAQ retrieval was 82% an improvement of 15% over the keyword-based vector-space model. The results show the proposed ontology-based speech-act identification is effective for dialog management.;2008
This paper describes a system which incorporates natural language technologies database manipulation and educational theories in order to offer learners a Negotiated Learner Model for integration into an Intelligent Tutoring System. The system presents the learner with their learner model offering them the opportunity to compare their own beliefs regarding their capabilities with those inferred by the system. A conversational agent or chatbot has been developed to allow the learner to negotiate over the representations held about them using natural language. The system aims to support the metacognitive goals of self-assessment and reflection which are increasingly seen as key to learning and are being incorporated into UK educational policy. The paper describes the design of the system and reports a user trial in which the chatbot was found to support users in increasing the accuracy of their self-assessments and in reducing the number of discrepancies between system and user beliefs in the learner model. Some lessons learned in the development have been highlighted and future research and experimentation directions are outlined. (c) 2007 Elsevier B.V. All rights reserved.;2008
This paper describes an integrated system based on open-domain and domain-specific knowledge for the purpose of providing query-based intelligent web interaction. It is understood that general purpose conversational agents are not able to answer questions on specific domain subject. On the other hand domain specific systems lack the flexibility to handle common sense questions. To overcome the above limitations this paper proposed an integrated system comprises of an artificial intelligent conversation software robot or chatterbot called Artificial Intelligence Natural-language Identity (hereafter AINI) and an Automated Knowledge Extraction Agent (AKEA) for the acquisition of real world knowledge from the Internet. The objective of AKEA is to retrieve real world knowledge or information from trustworthy websites. AINI is the mechanism used to manage the knowledge and to provide appropriate answer to the user. In this paper we compare the performance of the proposed system against two popular search engines two question answering systems and two other conversational systems.;2008
This paper presents a descriptive lexical analysis of spontaneous conversations between users and the 2005 Loebner prize winning chatterbot Jabber-wacky. The study was motivated in part by the suspicion that evidence in support of the Media Equation especially in the field of conversational agents was supported by incomplete data too often omitted in its purview is the occurrence of unsavoury user responses. Our study shows that conversations with Jabberwacky often bring about the expression of negative verbal disinhibition. We discovered that 10% of the total stems in the corpus reflected abusive language and approximately 11% of the sample addressed hard-core sex. Users were often rude and violated the conversation maxims of manner quantity and relevance. Also particularly pronounced in the conversations was a persistent need of the user to define the speakers' identities (human vs. machine). Users were also curious to understand and test the cognitive capabilities of the chatterbot. Our analysis indicates that the Media Equation may need qualifying that users treat computers that talk less as they do people and more as they might treat something not quite an object yet not quite human. (C) 2008 Elsevier B.V. All rights reserved.;2008
This paper presents an overview of methods that can be used to collect and analyse data on user responses to spoken dialogue system components intended to increase human-likeness and to evaluate how well the components succeed in reaching that goal. Wizard-of-Oz variations human-human data manipulation and micro-domains are discussed ill this context as is the use of third-party reviewers to get a measure of the degree of human-likeness. We also present the two-way mimicry target a model for measuring how well a human-computer dialogue mimics or replicates some aspect of human-human dialogue including human flaws and inconsistencies. Although we have added a measure of innovation none of the techniques is new in its entirely. Taken together and described from a human-likeness perspective however they form a set of tools that may widen the path towards human-like spoken dialogue systems. (c) 2008 Elsevier B.V. All rights reserved.;2008
This paper presents the Croatian context-dependent acoustic modelling used in speech recognition and in speech synthesis. The proposed acoustic model is based on context-dependent triphone hidden Markov models and Croatian phonetic rules. For speech recognition and speech synthesis system modelling and testing the Croatian speech corpus VEPRAD was used. The experiments have shown that Croatian speech corpus Croatian phonetic rules and hidden Markov models as the modelling formalism can be used to develop speech recognition and speech synthesis systems in parallel for a highly flective and free order language like Croatian. We propose an evaluation procedure for speech synthesis which combines an objective and a subjective evaluation approach and we present the achieved evaluation results. The proposed procedures for Croatian acoustic modelling were developed as parts of speech interfaces in a spoken dialog system for a limited weather forecast domain.;2008
This paper presents the NECA approach to the generation of dialogues between Embodied Conversational Agents (ECAs). This approach consist of the automated construction of an abstract script for an entire dialogue (cast in terms of dialogue acts) which is incrementally enhanced by a series of modules and finally performed by means of text speech and body language by a cast of ECAs. The approach makes it possible to automatically produce a large variety of highly expressive dialogues some of whose essential properties are under the control of a user. The paper discusses the advantages and disadvantages of NECA's approach to Fully Generated Scripted Dialogue (FGSD) and explains the main techniques used in the two demonstrators that were built. The paper can be read as a survey of issues and techniques in the construction of ECAs focusing on the generation of behaviour (i.e. focusing on information presentation) rather than on interpretation. (c) 2008 Published by Elsevier B.V.;2008
This paper proposes a technique to correct speech recognition errors in spoken dialogue systems that presents two main novel contributions. On the one hand it considers several contexts where a speech recognition result call be corrected. A threshold learnt in the training is used to decide whether the correction must be carried out in the context associated with the current prompt type of a dialogue system or in another context. On the other hand the technique deals with the confidence scores of the words employed in the corrections. The correction is carried out at two levels: statistical and linguistic. At the first level the technique employs syntactic-semantic and lexical models both contextual to decide whether a recognition result is correct. According to this decision the recognition result may be changed. At the second level the technique employs basic linguistic knowledge to decide about the grammatical correctness of the outcome of the first level. According to this decision the outcome may be changed as well. Experimental results indicate that the technique enhances a dialogue system's word accuracy speech understanding implicit recovery and task completion rates by 8.5% 16.54% 4% and 44.17% respectively. (c) 2008 Elsevier B.V. All rights reserved.;2008
To generate correct reactions a dialogue system should identify domain actions indicated by users' utterances because speaker intentions can be captured by the domain actions. In this paper we propose a domain action classification model to determine speech acts (general intentions) and concept sequences (semantic focuses) at the same time in a schedule management domain. To avoid biased learning problems the proposed model uses low-level linguistic features and filters out uninformative features using statistic. Then the proposed model determines domain actions using a maximum entropy model. In the experiment the proposed model showed better performances than previous works in speech act classification. In addition the proposed model showed high performances in concept sequence classification. Based on these experimental results we believe that the proposed model will be more helpful to a dialogue system than previous speech act classification models because it can return speech acts and concept sequences at the same time on the same framework.;2008
Two studies were conducted to identify individual characteristics that predict behavioral responses to violence prevention interventions. These studies used embodied conversational agents (ECAs) to create hypothetical social situations (called virtual vignettes) to assess interpersonal competency skills. One study was of male inner-city African-American adolescents and the second was of male prisoners in a state correctional system. In pre- and post-intervention sessions participants interacted with an ECA that tried to entice them into making risky decisions. The virtual vignette sessions tested participants' negotiation and conflict resolution skills. Results showed differing tendencies for participants to be engaged by the virtual vignettes. The vignettes were sufficiently realistic to elicit differences in behavior among the adolescents but generally not for the prisoners. Prior acceptance accessibility and usability data suggest that most users readily accept ECAs as valid conversational partners. The evidence presented here suggests that the technology - or the setting in which the technology is used is not by itself sufficient to actively engage users. The usefulness of virtual vignettes to adequately predict future behavior may be at least partially influenced by participant characteristics. (c) 2007 Elsevier Ltd. All rights reserved.;2008
User simulations are increasingly employed in the development and evaluation of spoken dialog systems. However there is no accepted method for evaluating user simulations which is problematic because the performance of new dialog management techniques is often evaluated on user simulations alone not on real people. In this paper we propose a novel method of evaluating user simulations. We view a user simulation as a predictor of the performance of a dialog system where per-dialog performance is measured with a domain-specific scoring function. The divergence between the distribution of dialog scores in the real and simulated corpora provides a measure of the quality of the user simulation and we argue that the Cramer-von Mises divergence is well-suited to this task. To demonstrate this technique we study a corpus of callers with real information needs and show that Cramer-von Mises divergence conforms to expectations. Finally we present simple tools which enable practitioners to interpret the statistical significance of comparisons between user simulations. (c) 2008 Elsevier B.V. All rights reserved.;2008
We built an automated dialogue system whose style of interaction can be varied along the three dimensions of Humour Relationship Maintenance and Personality Matching. We then ran a longitudinal experiment which investigated manipulations of these three dimensions. We explored the interaction of these separate dimensions on user perception of the system using a controlled study design. We showed a strong positive effect for the use of Humour and Relationship Maintenance while the use of Personality Matching raised a number of questions which need further investigation. (C) 2007 Elsevier B.V. All rights reserved.;2008
We describe a two-layer architecture for supporting semantic interpretation and domain reasoning in dialogue systems. Building system that supports both semantic interpretation and domain reasoning in a transparent and well-integrated manner is an unresolved problem because of the diverging requirements of the semantic representations used in contextual interpretation versus the knowledge representations used in domain reasoning. We propose an architecture that provides both portability and efficiency in natural language interpretation by maintaining separate semantic and domain knowledge representations and integrating them via an ontology mapping procedure. The ontology mapping is used to obtain representations of utterances in a form most suitable for domain reasoners and to automatically specialize the lexicon. The use of a linguistically motivated parser for producing semantic representations for complex natural language sentences facilitates building portable semantic interpretation components as well as connections with domain reasoners. Two evaluations demonstrate the effectiveness of our approach: we show that a small number of mapping rules are sufficient for customizing the generic semantic representation to a new domain and that our automatic lexicon specialization technique improves parser speed and accuracy.;2008
We hypothesize that student affect is a useful predictor of spoken dialogue system performance relative to other parameters. We test this hypothesis in the context of our spoken dialogue tutoring system where student learning is the primary performance metric. We first present our system and corpora which have been annotated with several student affective states student correctness and discourse structure. We then discuss unigram and bigram parameters derived from these annotations. The unigram parameters represent each annotation type individually as well as system-generic features. The bigram parameters represent annotation combinations including student state sequences and student states in the discourse structure context. We then use these parameters to build learning models. First we build simple models based on correlations between each of our parameters and learning. Our results suggest that our affect parameters are among our most useful predictors of learning particularly in specific discourse structure contexts. Next we use the PARADISE framework (multiple linear regression) to build complex learning models containing only the most useful subset of parameters. Our approach is a value-added one we perform a number of model-building experiments both with and without including our affect parameters and then compare the performance of the models on the training and the test sets. Our results show that when included as inputs our affect parameters are selected as predictors in most models and many of these models show high generalizability in testing. Our results also show that overall the affect-included models significantly outperform the affect-excluded models.;2008
We present a new methodology of user simulation applied to the evaluation and refinement of stochastic dialog systems. Common weaknesses of these systems are the scarceness of the training corpus and the cost of an evaluation made by real users. We have considered the user simulation technique as an alternative way of testing and improving our dialog system. We have developed a new dialog manager that plays the role of the user. This user dialog manager incorporates several knowledge sources combining statistical and heuristic information in order to define its dialog strategy. Once the user simulator is integrated into the dialog system it is possible to enhance the dialog models by an automatic strategy learning. We have performed an extensive evaluation achieving a slight but clear improvement of the dialog system. (C) 2007 Elsevier Ltd. All rights reserved.;2008
We propose a method for learning dialogue management policies from a fixed data set. The method addresses the challenges posed by Information State Update (ISU)-based dialogue systems which represent the state of a dialogue as a large set of features resulting in a very large state space and a huge policy space. To address the problem that any fixed data set will only provide information about small portions of these state and policy spaces we propose a hybrid model that combines reinforcement learning with supervised learning. The reinforcement learning is used to optimize a measure of dialogue reward while the supervised learning is used to restrict the learned policy to the portions of these spaces for which we have data. We also use linear function approximation to address the need to generalize from a fixed amount of data to large state spaces. To demonstrate the effectiveness of this method on this challenging task we trained this model on the COMMUNICATOR corpus to which we have added annotations for user actions and Information States. When tested with a user simulation trained on a different part of the same data set our hybrid model outperforms a pure supervised learning model and a pure reinforcement learning model. It also outperforms the hand-crafted systems on the COMMUNICATOR data according to automatic evaluation measures improving over the average COMMUNICATOR system policy by 10%. The proposed method will improve techniques for bootstrapping and automatic optimization of dialogue management policies from limited initial data sets.;2008
With the availability of large corpora of spoken dialog it is now possible to use data-driven techniques to build and use models of task-oriented dialogs. In this paper we use data-driven techniques to build task structures for individual dialogs and use the dialog task structures for: dialog act classification task/subtask classification task/subtask prediction and dialog act prediction. We evaluate our approach using a corpus of customer/agent dialogs from a catalog service domain. This paper demonstrates the feasibility of using corpora of human-human conversation to learn dialog models suitable for human-computer dialog applications.;2008
A key advantage of taking a statistical approach to spoken dialogue systems is the ability to formalise dialogue policy design as a stochastic optimization problem. However since dialogue policies are learnt by interactively exploring alternative dialogue paths conventional static dialogue corpora cannot be used directly for training and instead a user simulator is commonly used. This paper describes a novel statistical user model based on a compact stack-like state representation called a user agenda which allows state transitions to be modeled as sequences of push- and pop-operations and elegantly encodes the dialogue history from a user's point of view. An expectation-maximisation based algorithm is presented which models the observable user output in terms of a sequence of hidden states and thereby allows the model to be trained on a corpus of minimally annotated data. Experimental results with a real-world dialogue system demonstrate that the trained user model can be successfully used to optimise a dialogue policy which outperforms a hand-crafted baseline in terms of task completion rates and user satisfaction scores.;2009
An Intelligent Environment is a physical space that becomes augmented with computation communication and digital content thus transcending the limits of direct human perception. Spoken dialogue is a key factor for user-friendly human-computer interaction. This article details how to integrate Spoken Dialogue Systems into Intelligent Environments. We will outline research areas and future trends including assistive adaptive and proactive system design dialogue management and system-environment interaction.;2009
Appraisal theories in psychology study facial expressions in order to deduct information regarding the underlying emotion elicitation processes. Scherer's component process model provides predictions regarding particular face muscle deformations that are attributed as reactions to the cognitive appraisal stimuli in the study of emotion episodes. In the current work MPEG-4 facial animation parameters are used in order to evaluate these theoretical predictions for intermediate and final expressions of a given emotion episode. We manipulate parameters such as intensity and temporal evolution of synthesized facial expressions. In emotion episodes originating from identical stimuli by varying the cognitive appraisals of the stimuli and mapping them to different expression intensities and timings various behavioral patterns can be generated and thus different agent character profiles can be defined. The results of the synthesis process are consequently applied to Embodied Conversational Agents (ECAs) aiming to render their interaction with humans or other ECAs more affective.;2009
As an alternative to dominant cognitive-constructivist approaches to educational technology this article makes the case for what has been termed a discursive or postcognitive psychological research paradigm. It does so by adapting discursive psychological analyses of conversational activity to the study of educational technology use. It applies these modified techniques specifically to discursive interactions with chatbots or intelligent agents and to the theories commonly associated with them. In doing so it presents a critique of notions of human-computer indistinguishability or equality as they have been articulated from Alan Turing to Reeves and Nass and it sketches an alternative account of the potential and limitations of this technology. In divergence from Turing and Reeves and Nass human discourse generated through encounters with natural language interfaces is seen as emphasizing the issue of conversation itself foregrounding the achievement of common discursive aims and projects rather than illuminating the internal states of either interlocutor. Mind and cognition correspondingly are revealed as phenomena accomplished through contingent social activity rather than as computational processes concealed within or distributed between mind and machine.;2009
Computer Simulation in Educational Communication (CSIEC) is not only an intelligent web-based human-computer dialogue system with natural language for English instruction but also a learning assessment system for learning and teachers. Its multiple functions-including grammar-based gap-filling exercises scenario show free chatting and chatting on a given topic-can satisfy the various requirements for students with different backgrounds and learning abilities. After a brief explanation of the conception of the dialogue system as well as a survey of related works I will illustrate the system structure and describe its pedagogical functions with the underlying AI techniques such as natural language processing and rule-based reasoning in detail. I will summarize the five Internet usage with in a six-month period and its integration into English classes in universities and middle schools. The evaluation findings about the class integration show that the chatting function has been improved and frequently utilized by users and the application of the CSIEC system on English instruction can motivate learners to practice English and enhance their learning process. Finally I will conclude with potential improvements.;2009
Conversational agents are becoming more widespread in computer technologies but there has been little research in how humans interact with them. Two eye tracking studies investigated how humans distribute eye gaze towards conversational agents in complex tutoring systems. In Study 1 participants interacted with the single-agent tutoring system AutoTutor. Fixation times showed that the agent received most attention throughout the interaction even when display size was statistically controlled. In Study 2 participants interacted with iSTART. Fixations were on the relevant agents when these agents spoke. Both studies provided evidence that humans regard animated conversational agents as conversational partners in the communication process. Copyright (C) 2008 JohnWiley & Sons Ltd.;2009
Conversational systems or chatterbots converse/chat by learning from their interactions with users. To do this the systems must have an adaptive knowledge base that can be updated by the systems themselves. RONE is a tele-text based conversational system. RONE's knowledge base is built using SQL and accessed using the main Java application. Additionally RONE uses conjunctions and prepositions as markers to expedite the dissemination and storage of information which helps him learn. In this paper we describe the approach RONE uses to break up new information for learning purposes - the principle technique introduced here being the storage of information in a format to answer all the possible questions directly without inference. We also look at other conversation based learning approaches and their limitations. Further we compare RONE's performance against some contemporary conversational systems and provide evidence of the relative superior informational accuracy of RONE's responses to user interrogation. RONE's better performance is noteworthy because it is relative to systems which are Loebner Prize medal winners.;2009
CSIEC (Computer Simulation in Educational Communication) system with newly developed multiple functions for English instruction still focuses on supplying a virtual chatting partner (chatbot) which can chat in English with the English learners anytime anywhere. It generates communicative response according to the user input the dialogue context the user's and its own personality knowledge common sense knowledge and inference knowledge. All these kinds of knowledge are expressed in the form of NLML an annotation language for natural language text. These NLMLs can either be automatically obtained through parsing the text or be easily authored with the help of GUI editors designed by LIS. So the CSIEC system suggests a naive approach of logical reasoning and inference directly through syntactical and semantic analysis of textual knowledge. This approach has advantages over the old ELIZA-like keywords matching mechanism. The chatting log summarization of free Internet usage within six months demonstrates this advantage. In this paper we present the system architecture and underlying technologies and the educational application results. (C) 2009 Elsevier B.V. All rights reserved.;2009
Evaluation of methods and techniques for conversational and multimodal spoken dialogue systems is complex as is gathering data for the modeling and tuning of such techniques. This article describes MushyPeek all experiment framework that allows us to manipulate the audiovisual behavior of interlocutors in a setting similar to face-to-face human-human dialogue. The setup connects two subjects to each other over a Voice over Internet Protocol (VoIP) telephone connection and simultaneously provides each of them with an avatar representing the other. We present a first experiment which inaugurates exemplifies and validates the framework. The experiment corroborates earlier findings on the use of gaze and head pose gestures in turn-taking.;2009
In this paper we describe RavenClaw a plan-based task-independent dialog management framework: RavenClaw isolates the domain-specific aspects of the dialog control logic from domain-independent conversational skills and in the process facilitates rapid development of mixed-initiative systems operating in complex task-oriented domains. System developers can focus exclusively on describing the dialog task control logic while a large number of domain-independent conversational skills such as error handling timing and turn-taking are transparently supported and enforced by the RavenClaw dialog engine. To date RavenClaw has been used to construct and deploy a large number of systems spanning different domains and interaction styles such as information access guidance through procedures command-and-control medical diagnosis etc. The framework has easily adapted to all of these domains indicating a high degree of versatility and scalability. (C) 2008 Elsevier Ltd. All rights reserved.;2009
In this paper we investigate two statistical methods for spoken language understanding based on statistical machine translation. The first approach employs the source-channel paradigm whereas the other uses the maximum entropy framework. Starting with an annotated corpus we describe the problem of natural language understanding as a translation from a source sentence to a formal language target sentence. We analyze the quality of different alignment models and feature functions and show that the direct maximum entropy approach outperforms the source channel-based method. Furthermore we investigate how both methods perform if the input sentences contain speech recognition errors. Finally we investigate a new approach to combine speech recognition and spoken language understanding. For this purpose we employ minimum error rate training which directly optimizes the final evaluation criterion. By combining all knowledge sources in a log-linear way we show that we can decrease both the word error rate and the slot error rate. Experiments were carried out on two German inhouse corpora for spoken dialogue systems.;2009
In this paper we present the comprehensive version of CSIEC (Computer Simulation in Educational Communication) an interactive web-based human-computer dialogue system with natural language for English instruction and its tentative application and evaluation in English education. First we briefly introduce the motivation for this project survey the related works and illustrate the system structure with flow diagram. Then we describe its pedagogical functions especially free chatting and chatting on a given topic. We summarise the free Internet usage within 6 months and introduce its integration into English classrooms as well as the formal evaluation results of the integration. The evaluation findings show that the chatting function has been improved and fully used by the users and the application of the CSIEC system in English instruction can motivate the learners to use English and enhance their learning process. Lastly we discuss the application-driven approach of system development and draw some conclusions for future improvement.;2009
In this paper we propose the Virtual Assistant a novel framework for supporting knowledge capturing in videos. The Virtual Assistant is an artificial agent that simulates a human assistant shown in TV programs and prompts users to provide feedback by asking questions. This framework ensures that sufficient information is provided in the captured content while users interact in a natural and enjoyable way with the agent. We developed a prototype agent based on a chatbot-like approach and applied it to a daily cooking scene. Experimental results demonstrate the potential of the Virtual Assistant framework as it allows a person to provide feedback easily with few interruptions and elicits a variety of useful information.;2009
In trying to control various aspects concerning utterance production in multi-party human-computer dialogue argumentative considerations play an important part particularly in choosing appropriate lexical units so that we fine-tune the degree of persuasion that each utterance has. A preliminary step in this endeavor is the ability to place an ordering relation between semantic forms (that are due to be realized as utterances by the machine) concerning their persuasion strength with respect to certain (explicit or implicit) conclusions. Thus in this article we propose a mechanism for assessing utterances in terms of their argumentative force. The framework designed conflates insights from Asher and Lascarides' SDRT (Segmented Discourse Representation Theory) and from Anscombre and Ducrot's AT (Argumentation Theory). These mechanisms are included in a language generation component of a multi-party dialogue system for book reservation applications (i.e. a virtual librarian) and thus evaluated via typical human-machine conversations.;2009
Intelligent Tutoring Systems are computer programs that aim at providing personalized instruction to students. In recent years conversational robots usually known as chatterbots become very popular in the Internet and ALICE (Artificial Linguistic Internet Computer Entity) is probably the most popular one. ALICE brain is written in AIML (Artificial Intelligence Markup Language) an open XML language. We have considered the combination of both approaches i.e the use of AIML-based bots for tutoring purposes in open e-Learning platforms such as Claroline or Moodle. With that aim in mind we have developed a bot (chatterbot) for helping the students during their learning process and for supporting the activities of the teacher. This bot (TQ-Bot) is able to analyse the requests made by the learners in written natural language and to provide adequate and domain specific answers orienting the student to the right course contents. Besides TQ-Bot is able to track and supervise the student progress by means of personalized questionnaires. This bot has been developed and integrated as user-friendly modules in Claroline and Moodle.;2009
It was analyzed whether an embodied conversational agent (ECA) has specific advantages when employed with privacy invading technologies such as a biometric security system. The study compares the effects of an ECA interface with the effects of conventional text-based and voice-based interfaces on user acceptance and usability. An additional variable was whether the biometric system falsely rejected the user twice or whether it directly accepted him/her. Results of the 2 x 3 between-subjects design indicated that although overall the text interface is rated most positive voice and ECA yield distinct social effects: They have more advantageous consequences when problems arise - i.e. when the user is rejected repeatedly. The implications for social psychology in terms of applicability of new research methods as well as insights concerning fundamental research are discussed.;2009
Many of the implemented dialog systems in industry are based on a state automaton. Most of these systems rely on predefined messages to convey information. Each of these messages is formed of an ordered set of utterance templates. In a typical interaction with the user the automaton-based dialog manager highlights a particular predefined message in response to a given user's request. However a rather common event in the dialog system's workflow is the dialog manager's highlighting of multiple messages in response to a user's request. In this case an appropriate solution would be to merge highlighted messages in a single output i.e. templates of these messages are restructured and revised to form a new message. In this paper we introduce a Natural Language Generation (NLG) module to an automaton based dialog system in order to perform these tasks. Our approach consists of planning a new output message according to SDRT's coherence model by constraint satisfaction.;2009
Multimodal grammars provide an effective mechanism for quickly creating integration and understanding capabilities for interactive systems supporting simultaneous use of multiple input modalities. However like other approaches based on hand-crafted grammars multimodal grammars can be brittle with respect to unexpected erroneous or disfluent input. In this article we show how the finite-state approach to multimodal language processing can be extended to support multimodal applications combining speech with complex freehand pen input and evaluate the approach in the context of a multimodal conversational system (MATCH). We explore a range of different techniques for improving the robustness of multimodal integration and understanding. These include techniques for building effective language models for speech recognition when little or no multimodal training data is available and techniques for robust multimodal understanding that draw on classification machine translation and sequence edit methods. We also explore the use of edit-based methods to overcome mismatches between the gesture stream and the speech stream.;2009
One of the basic topics of question answering (QA) dialogue systems is how follow-up questions should be interpreted by a QA system. In this paper we shall discuss our experience with the IMIX and Ritel systems for both of which a follow-up question handling scheme has been developed and corpora have been collected. These two systems are each other's opposites in many respects: IMIX is multimodal non-factoid black-box QA while Ritel is speech factoid keyword-based QA. Nevertheless we will show that they are quite comparable and that it is fruitful to examine the similarities and differences. We shall look at how the systems are composed and how real non-expert users interact with the systems. We shall also provide comparisons with systems from the literature where possible and indicate where open issues lie and in what areas existing systems may be improved. We conclude that most systems have a common architecture with a set of common subtasks in particular detecting follow-up questions and finding referents for them. We characterise these tasks using the typical techniques used for performing them and data from our corpora. We also identify a special type of follow-up question the discourse question which is asked when the user is trying to understand an answer and propose some basic methods for handling it.;2009
Our aim is to create an affective embodied conversational agent (ECA) that is an ECA able to display communicative and emotional signals. Nonverbal communication is done through certain facial expressions gesture shapes gaze direction etc. But it can also carry a qualitative aspect through behavior expressivity: how a facial expression a gesture is executed. In this paper we describe some of the work we have conducted on behavior expressivity more particularly on gesture expressivity. We have developed a model of behavior expressivity using a set of six parameters that act as modulation of behavior animation. Expressivity may act at different levels of the behavior: on a particular phase of the behavior on the whole behavior and on a sequence of behaviors. When applied at these different levels expressivity may convey different functions. (C) 2008 Published by Elsevier B.V.;2009
Over the past few years we have been developing an expressive embodied conversational agent system. In particular we have developed a model of multimodal behaviours that includes dynamism and complex facial expressions. The first feature refers to the qualitative execution of behaviours. Our model is based on perceptual studies and encompasses several parameters that modulate multimodal behaviours. The second feature the model of complex expressions follows a componential approach where a new expression is obtained by combining facial areas of other expressions. Lately we have been working on adding temporal dynamism to expressions. So far they have been designed statically typically at their apex. Only full-blown expressions could be modelled. To overcome this limitation we have defined a representation scheme that describes the temporal evolution of the expression of an emotion. It is no longer represented by a static definition but by a temporally ordered sequence of multimodal signals.;2009
Performance of statistical n-gram language models depends heavily on the amount of training text material and the degree to which the training text matches the domain of interest. The language modeling community is showing a growing interest in using large collections of text (obtainable for example from a diverse set of resources on the Internet) to supplement sparse in-domain resources. However in most cases the style and content of the text harvested from the web differs significantly from the specific nature of these domains. In this paper we present a relative entropy based method to select subsets of sentences whose n-gram distribution matches the domain of interest. We present results on language model adaptation using two speech recognition tasks: a medium vocabulary medical domain doctor-patient dialog system and a large vocabulary transcription system for European Parliamentary Plenary Speeches (EPPS). We show that the proposed subset selection scheme leads to performance improvements over state of the art speech recognition systems in terms of both speech recognition word error rate (WER) and language model perplexity (PPL).;2009
Policy learning is an active topic in dialogue systems research but it has not been explored in relation to interactive question answering (IQA). We take a first step in learning adaptive interaction policies for question answering : we address the question of how to acquire enough reliable query constraints how many database results to present to the user and when to present them given the competing trade-offs between the length of the answer list the length of the interaction the type of database and the noise in the communication channel. The operating conditions are reflected in an objective function which we use to derive a hand-coded threshold-based policy and rewards to train a reinforcement learning policy. The same objective function is used for evaluation. We show that we can learn strategies for this complex trade-off problem which perform significantly better than a variety of hand-coded policies for a wide range of noise conditions user types types of DB and turn-penalties. Our policy learning framework thus covers a wide spectrum of operating conditions. The learned policies produce an average relative increase in reward of 86.78% over the hand-coded policies. In 93% of the cases the learned policies perform significantly better than the hand-coded ones (p < .001). Furthermore we show that the type of database has a significant effect on learning and we give qualitative descriptions of the learned IQA policies.;2009
Sensor technologies are being introduced as a means to collect the accurate and online information of products in logistics networks. Products with RFID (Radio Frequency Identification) tags can guarantee timely product location visibility. Also additional sensors can measure location dependent attributes such as temperature and humidity. Representative product centric approaches such as EPC Network and the Dialog system make it possible to secure the item level product information automatically and fast. However they leave room for more advanced services especially for active product state tracking service that monitors the locations and attributes of products in a timely manner and triggers exception handling when the constraints associated with the product states are violated. Using state transition model temporal data model and publish/subscribe model this paper proposes an active product state tracking system architecture which is able to track products even when they are enclosed in a box a pallet. or a container. A simulation based experiment is provided to evaluate the performance of the proposed system. (C) 2008 Elsevier B.V. All rights reserved.;2009
The aim of the French Media project was to define a protocol for the evaluation of speech understanding modules for dialog systems. Accordingly a corpus of 1257 real spoken dialogs related to hotel reservation and tourist information was recorded transcribed and semantically annotated and a semantic attribute-value representation was defined in which each conceptual relationship was represented by the names of the attributes. Two semantic annotation levels are distinguished in this approach. At the first level each utterance is considered separately and the annotation represents the meaning of the statement without taking into account the dialog context. The second level of annotation then corresponds to the interpretation of the meaning of the statement by taking into account the dialog context in this way a semantic representation of the dialog context is defined. This paper discusses the data collection the detailed definition of both annotation levels and the annotation scheme. Then the paper comments on both evaluation campaigns which were carried out during the project and discusses some results.;2009
The aim of various approaches implemented whether the classical three Ps'' (presentation practice and production) or communicative language teaching (CLT) is to achieve communicative competence. Although a lot of software developed for teaching spoken English is dressed up to raise interaction its methodology is largely rooted in tradition. Chatterbots based on dialogue management and developed with AI TTS technology and computer animation can engage the learner in computer-simulated human-human conversations. Its natural language social interaction opens new horizons for spoken language teaching/learning. A classroom survey was conducted in which the students showed keen interest and computer-simulated human-human interaction was frequently observed.;2009
The automatic detection tracking and identification of multiple people in intelligent environments are important building blocks on which smart interaction systems can be designed. Those could be e.g. gesture recognizers head pose estimators or far-field speech recognizers and dialog systems. In this paper we present a system which is capable of tracking multiple people in a smart room environment while inferring their identities in a completely automatic and unobtrusive way. It relies on a set of fixed and active cameras to track the users and get close-ups of their faces for identification and on several microphone arrays to determine active speakers and steer the attention of the system. Information coming asynchronously from several sources such as position updates from audio or visual trackers and identification events from identification modules is fused at higher level to gradually refine the room's situation model. The system has been trained on a small set of users and showed good performance at acquiring and keeping their identities in a smart room environment.;2009
The current work will describe an approach to synthesize expressions including intermediate ones via the tools provided in the MPEG-4 standard based on real measurements and on universally accepted assumptions of their meaning taking into account results of Whissel's study. Additionally MPEG-4 facial animation parameters are used in order to evaluate theoretical predictions for intermediate expressions of a given emotion episode based on Scherer's appraisal theory. MPEG-4 FAPs and action units are combined in modeling the effects of appraisal checks on facial expressions and temporal evolution issues of facial expressions are investigated. The results of the synthesizing process can then be applied to Embodied Conversational Agents (ECAs) rendering their interaction with humans or other ECAs more affective.;2009
The evaluation of spoken dialog systems still relies on subjective interaction experiments for quantifying interaction behavior and user-perceived quality. In this paper we present a simulation approach replacing subjective tests in early system design and evaluation phases. The simulation is based on a model of the system and a probabilistic model of user behavior. Probabilities for the next user action vary in dependence of system features and user characteristics as defined by rules. This way simulations can be conducted before data have been acquired. In order to evaluate the simulation approach characteristics of simulated interactions are compared to interaction corpora obtained in subjective experiments. As was previously proposed in the literature we compare interaction parameters for both corpora and calculate recall and precision of user utterances. The results are compared to those from a comparison of real user corpora. While the real corpora are not equal they are more similar than the simulation is to the real data. However the simulations can predict differences between system versions and user groups quite well on a relative level. In order to derive further requirements for the model we conclude with a detailed analysis of utterances missing in the simulated corpus and consider the believability of entire dialogs. (C) 2009 Elsevier B.V. All rights reserved.;2009
The majority of existing work on agent dialogues considers negotiation persuasion or deliberation dialogues we focus on inquiry dialogues which allow agents to collaborate in order to find new knowledge. We present a general framework for representing dialogues and give the details necessary to generate two subtypes of inquiry dialogue that we define: argument inquiry dialogues allow two agents to share knowledge to jointly construct arguments warrant inquiry dialogues allow two agents to share knowledge to jointly construct dialectical trees (essentially a tree with an argument at each node in which a child node is a counter argument to its parent). Existing inquiry dialogue systems only model dialogues meaning they provide a protocol which dictates what the possible legal next moves are but not which of these moves to make. Our system not only includes a dialogue-game style protocol for each subtype of inquiry dialogue that we present but also a strategy that selects exactly one of the legal moves to make. We propose a benchmark against which we compare our dialogues being the arguments that can be constructed from the union of the agents' beliefs and use this to define soundness and completeness properties that we show hold for all inquiry dialogues generated by our system.;2009
The topic of Human Computer Interaction (HCI) has been gathering more and more scientific attention of late. A very important but often undervalued area in this field is human engagement. That is a person's commitment to take part in and continue the interaction. In this paper we describe work on a humor-equipped casual conversational system (chatterbot) and investigate the effect of humor on a user's engagement in the conversation. A group of users was made to converse with two systems: one with and one without humor. The chat logs were then analyzed using an emotive analysis system to check user reactions and attitudes towards each system. Results were projected on Russell's two-dimensional emotiveness space to evaluate the positivity/negativity and activation/deactivation of these emotions. This analysis indicated emotions elicited by the humor-equipped system were more positively active and less negatively active than by the system without humor. The implications of results and relation between them and user engagement in the conversation are discussed. We also propose a distinction between positive and negative engagement.;2009
This article describes the application of computational models of spatial prepositions to visually situated dialog systems. In these dialogs spatial prepositions are important because people often use them to refer to entities in the visual context of a dialog. We first describe a generic architecture for a visually situated dialog system and highlight the interactions between the spatial cognition module which provides the interface to the models of prepositional semantics and the other components in the architecture. Following this we present two new computational models of topological and projective spatial prepositions. The main novelty within these models is the fact that they account for the contextual effect which other distractor objects in a visual scene can have on the region described by a given preposition. We next present psycholinguistic tests evaluating our approach to distractor interference on prepositional semantics and illustrate how these models are used for both interpretation and generation of prepositional expressions.;2009
This paper addresses the problem of multi-domain spoken language understanding (SLU) where domain detection and domain-dependent semantic tagging problems are combined. We present a transfer learning approach to the multi-domain SLU problem in which multiple domain-specific data sources can be incorporated. To implement multi-domain SLU with transfer learning we introduce a triangular-chain structured model. This model effectively learns multiple domains in parallel and allows use of domain-independent patterns among domains to create a better model for the target domain. We demonstrate that the proposed method outperforms baseline models on dialog data for multi-domain SLU problems. (C) 2009 Elsevier B.V. All rights reserved.;2009
This paper describes an attempt to automate the large-scale assessment of oral language proficiency and listening comprehension for fairly advanced students of English as a second language. The automatic test is implemented as a spoken dialogue system and consists of a reading as well as a repeating task. Two experiments are described in which different rating criteria were used by human judges. In the first experiment proficiency was scored globally for each of the two test components. In the second experiment various aspects of proficiency were evaluated for each section of the test. In both experiments rate of speech (ROS) goodness of pronunciation (GOP) and repeat accuracy were calculated for the spoken utterances. The correlation between scores assigned by human raters and these three automatically derived measures was determined to assess their suitability as proficiency indicators. Results show that the more specific rating instructions used in the second experiment improved intra-rater agreement but made little difference to inter-rater agreement. In addition the more specific rating criteria resulted in a better correlation between the human and the automatic scores for the repeating task but had almost no impact in the reading task. Overall the results indicate that even for the narrow range of proficiency levels observed in the test population the automatically derived ROS and accuracy scores give a fair indication of oral proficiency. (C) 2009 Elsevier B.V. All rights reserved.;2009
This paper describes two systems using embodied conversational agents (ECAs) for language learning. The first system called Ville is a virtual language teacher for vocabulary and pronunciation training. The second system a dialogue system called DEAL is a role-playing game for practicing conversational skills. Whereas DEAL acts as a conversational partner with the objective of creating and keeping an interesting dialogue Ville takes the role of a teacher who guides encourages and gives feedback to the students. (C) 2009 Elsevier B.V. All rights reserved.;2009
This paper discusses the discourse understanding process in spoken dialogue systems. This process enables a system to understand user utterances from the context of a dialogue. Ambiguity in user utterances caused by multiple speech recognition hypotheses and parsing results sometimes makes it difficult for a system to decide on a single interpretation of a user intention. As a solution the idea of retaining possible interpretations as multiple dialogue states and resolving the ambiguity using succeeding user utterances has been proposed. Although this approach has proven to improve discourse understanding accuracy carefully created hand-crafted rules are necessary in order to accurately rank the dialogue states. This paper proposes automatically ranking multiple dialogue states using statistical information obtained from dialogue corpora. The experimental results in the train ticket reservation and weather information service domains show that the statistical information can significantly improve the ranking accuracy of dialogue states as well as the slot accuracy and the concept error rate of the top-ranked dialogue states.;2009
This paper presents an innovatory system for controlling the emotional state of an embodied conversational agent. Unlike other existing models our system is fast adaptable to different application domains and it is highly interpretable. This will provide specialists with a tool to easily test their hypotheses about the most suitable emotional attitude for an agent in a specific domain. it also provides emotional stability and dynamic and automatic behavior orientation which will result in the design of more believable conversational agents that behave as humans do. (C) 2009 Elsevier Ltd. All rights reserved.;2009
This paper proposes a generic dialog modeling framework for a multi-domain dialog system to simultaneously manage goal-oriented and chat dialogs for both information access and entertainment. We developed a dialog modeling technique using an example-based approach to implement multiple applications such as car navigation weather information TV program guidance and chatbot. Example-based dialog modeling (EBDM) is a simple and effective method for prototyping and deploying of various dialog systems. This paper also introduces the system architecture of multi-domain dialog systems using the EBDM framework and the domain spotting technique. In our experiments we evaluate our system using both simulated and real users. We expect that our approach can support flexible management of multi-domain dialogs on the same framework. (C) 2009 Elsevier B.V. All rights reserved.;2009
This paper proposes a novel integrated dialog simulation technique for evaluating spoken dialog systems. A data-driven user simulation technique for simulating user intention and utterance is introduced. A novel user intention modeling and generating method is proposed that uses a linear-chain conditional random field and a two-phase data-driven domain-specific user utterance Simulation method and a linguistic knowledge-based ASR channel simulation method are also presented. Evaluation metrics are introduced to measure the quality of user simulation at intention and utterance. Experiments using these techniques were carried out to evaluate the performance and behavior of dialog systems designed for car navigation dialogs and a building guide robot and it turned out that Our approach was easy to set tip and showed similar tendencies to real human users. (C) 2009 Elsevier Ltd. All rights reserved.;2009
This paper reviews research in spoken language technology for education and more specifically for language learning. It traces the history of the domain and then groups main issues in the interaction with the student. It addresses the modalities of interaction and their implementation issues and algorithms. Then it discusses one user population - children - and an application for them. Finally it has a discussion of overall systems. It can be used as an introduction to the field and a source of reference materials. (C) 2009 Elsevier B.V. All rights reserved.;2009
This paper will summarize and analyze the work of the different research groups who have recently made significant contributions In using Reinforcement Learning techniques to learn dialogue strategies for Spoken Dialogue Systems (SDSs). This use of stochastic planning and learning has become an important research area in the past 10 years since it promises automatic data-driven optimization of the behavior of SDSs that were previously hand-coded by expert developers. We survey the most important developments in the field compare and contrast the different approaches and describe current open problems.;2009
This work focuses on the development of expressive text-to-speech synthesis techniques for a Chinese spoken dialog system where the expressivity is driven by the message content. We adapt the three-dimensional pleasure-displeasure arousal-nonarousal and dominance-submissiveness (PAD) model for describing expressivity in input text semantics. The context of our study is based on response messages generated by a spoken dialog system in the tourist information domain. We use the (pleasure) and (arousal) dimensions to describe expressivity at the prosodic word level based on lexical semantics. The (dominance) dimension is used to describe expressivity at the utterance level based on dialog acts. We analyze contrastive (neutral versus expressive) speech recordings to develop a nonlinear perturbation model that incorporates the PAD values of a response message to transform neutral speech into expressive speech. Two levels of perturbations are implemented-local perturbation at the prosodic word level as well as global perturbation at the utterance level. Perceptual experiments involving 14 subjects indicate that the proposed approach can significantly enhance expressivity in response generation for a spoken dialog system.;2009
Traditionally social interaction research has concentrated on either fully virtually embodied agents (e.g. embodied conversational agents) or fully physically embodied agents (e.g. robots). For some time however both areas have started augmenting their agents' capabilities for social interaction using ubiquitous and intelligent environments. We are placing different agent systems for social interaction along Milgram's Reality-Virtuality Continuum-according to the degree they are embodied in a physical virtual or mixed reality environment-and show systems that follow the next logical step in this progression namely social interaction in the middle of Milgram's continuum that is agents richly embodied in the physical and virtual world. This paper surveys the field of social interaction research with embodied agents with a particular view towards their embodiment forms and highlights some of the advantages and issues associated with the very recent field of social interaction with mixed reality agents.;2009
Unlike computer games where Non-Player-Character avatars are common in most virtual worlds they are the exception. Deploying an embodied AI into a virtual world offers a unique opportunity to evaluate embodied AIs and to develop them within an environment where human and computer are on almost equal terms. This paper presents an architecture being used for the deployment of chatbot driven avatars within the Second Life virtual world looks at the challenges of deploying an AI within such a virtual world the possible implications for the Turing Test and identifies research directions for the future. (C) 2009 Elsevier B.V. All rights reserved.;2009
We describe a system that automatically learns effective and engaging dialogue strategies generated from a library or dialogue content using reinforcement learning from user feedback. Besides the more usual clarification and verification components of dialogue this library contains various social elements like greetings apologies small talk relational questions and jokes. We tested the method through an experimental dialogue system that encourages take-up of exercise and shows that the learned dialogue policy performs as well as one built by human experts for this system.;2009
We evaluated two strategies for alleviating working memory load for users of voice interfaces: presenting fewer options per turn and providing confirmations. Forty-eight users booked appointments using nine different dialogue systems which varied in the number of options presented and the confirmation strategy used. Participants also performed four cognitive tests and rated the usability of each dialogue system on a standardised questionnaire. When systems presented more options per turn and avoided explicit confirmation subdialogues both older and younger users booked appointments more quickly without compromising task success. Users with lower information processing speed were less likely to remember all relevant aspects of the appointment. Working memory span did not affect appointment recall. Older users were slightly less satisfied with the dialogue systems than younger users. We conclude that the number of options is less important than an accurate assessment of the actual cognitive demands of the task at hand. (C) 2009 Elsevier B.V. All rights reserved.;2009
We explore the relationship between question answering and constraint relaxation in spoken dialogue systems and develop dialogue strategies for selecting and presenting information succinctly. In particular we describe methods for dealing with the results of database queries in information-seeking dialogues. Our goal is to structure the dialogue in such a way that the user is neither overwhelmed with information nor left uncertain as to how to refine the query further. We present two sets of evaluation results for a restaurant selection task: one is a system performance evaluation experiment involving twenty subjects the other is an experimental evaluation of the use of suggestions involving sixteen subjects.;2009
We have been using personal assistants (PA) coupled with multi-agent systems (MASs) in several CSCW applications. Since we are considering professional environments where users have many tasks to perform and where users are using several different applications at the same time (browsers CADs etc.) the PA interface should motivate users to keep using their assistant. To achieve this goal we propose WebAnima. WebAnima is a web-based embodied interface agent specially designed to assist team members of a CSCW application during their daily work based on computers. In WebAnima the intelligent behaviour is guaranteed thanks to a conversational interface and ontologies that support semantic interpretation. We believe that embodied conversational assistants will improve the quality of assistance and increase collaboration between project members. With WebAnima we expect to acquire information that can be further processed and reused in current and subsequent projects aiming at increasing productivity. In this paper we present the embodied conversational assistant and its insertion into an MAS designed for research and development projects. We describe the design of the agent highlighting the role of ontologies for semantic interpretation and the dynamic behaviour of the embodied animated agent.;2009
We propose a novel approach to developing a tractable affective dialogue model for probabilistic frame-based dialogue systems. The affective dialogue model based on Partially Observable Markov Decision Process (POMDP) and Dynamic Decision Network (DDN) techniques is composed of two main parts: the slot-level dialogue manager and the global dialogue manager. It has two new features: (1) being able to deal with a large number of slots and (2) being able to take into account some aspects of the user's affective state in deriving the adaptive dialogue strategies. Our implemented prototype dialogue manager can handle hundreds of slots where each individual slot might have hundreds of values. Our approach is illustrated through a route navigation example in the crisis management domain. We conducted various experiments to evaluate our approach and to compare it with approximate POMDP techniques and handcrafted policies. The experimental results showed that the DDN-POMDP policy outperforms three handcrafted policies when the user's action error is induced by stress as well as when the observation error increases. Further performance of the one-step look-ahead DDN-POMDP policy after optimizing its internal reward is close to state-of-the-art approximate POMDP counterparts.;2009
An initiative conflict is an overlap of speech in which both conversants try to steer the conversation in different directions. In this paper we investigate how conversants in human-human dialogue deal with such conflicts. First in investigating why initiative conflicts occur we find that the offsets of the utterances involved in initiative conflicts tend to be very short and that initiative conflicts seem more likely to occur when one of the conversants has an urgent conversational goal. These findings strongly suggest that initiative conflicts are unintentional collisions and that conversants try to prevent them from even occurring unless there is an urgent reason. Second in investigating how initiative conflicts are resolved we find that the overlaps tend to last less than two syllables that volume correlates with who wins initiative conflicts and that for longer overlaps the volume of the winner increases in the second half of the overlaps. These findings strongly suggest that initiative conflicts are quickly resolved through an interactive process using volume as one of the devices. Third we find that after an initiative conflict is resolved the winner sometimes repeats the words involved in the overlap and this happens more when the overlap is more likely to interfere with the other conversant's understanding. These findings will help its build next-generation mixed-initiative spoken dialogue systems that are natural and efficient to use. (C) 2009 Elsevier Ltd. All rights reserved.;2010
Artificial humans so-called Embodied Conversational Agents and humanoid robots are assumed to facilitate human-technology interaction referring to the unique human capacities of interpersonal communication and social information processing. While early research and development in artificial intelligence (AI) focused on processing and production of natural language the new AI has also taken into account the emotional and relational aspects of communication with an emphasis both on understanding and production of nonverbal behavior. This shift in attention in computer science and engineering is reflected in recent developments in psychology and social cognitive neuroscience. This article addresses key challenges which emerge from the goal to equip machines with socio-emotional intelligence and to enable them to interpret subtle nonverbal cues and to respond to social affordances with naturally appearing behavior from both perspectives. In particular we propose that the creation of credible artificial humans not only defines the ultimate test for our understanding of human communication and social cognition but also provides a unique research tool to improve our knowledge about the underlying psychological processes and neural mechanisms. (C) 2010 Published by Elsevier Ltd;2010
Behavior models implemented within Embodied Conversational Agents (ECAs) require nonverbal communication to be tightly coordinated with speech. In this paper we present an empirical study seeking to explore the influence of the temporal coordination between speech and facial expressions of emotions on the perception of these emotions by users (measuring their performance in this task the perceived realism of behavior and user preferences). We generated five different conditions of temporal coordination between facial expression and speech: facial expression displayed before a speech utterance at the beginning of the utterance throughout at the end of or following the utterance. 23 subjects participated in the experiment and saw these 5 conditions applied to the display of 6 emotions (fear joy anger disgust surprise and sadness). Subjects recognized emotions most efficiently when facial expressions were displayed at the end of the spoken sentence. However the combination users viewed as most realistic preferred over others was the display of the facial expression throughout speech utterance. We review existing literature to position our work and discuss the relationship between realism and communication performance. We also provide animation guidelines and draw some avenues for future work.;2010
Conversation is an essential component of social behavior one of the primary means by which humans express intentions beliefs emotions attitudes and personality. Thus the development of systems to support natural conversational interaction has been a long term research goal. In natural conversation humans adapt to one another across many levels of utterance production via processes variously described as linguistic style matching entrainment alignment audience design and accommodation. A number of recent studies strongly suggest that dialogue systems that adapted to the user in a similar way would be more effective. However a major research challenge in this area is the ability to dynamically generate user-adaptive utterance variations. As part of a personality-based user adaptation framework this article describes PERSONAGE a highly parameterizable generator which provides a large number of parameters to support adaptation to a user's linguistic style. We show how we can systematically apply results from psycholinguistic studies that document the linguistic reflexes of personality in order to develop models to control PERSONAGE'S parameters and produce utterances matching particular personality profiles. When we evaluate these outputs with human judges the results indicate that humans perceive the personality of system utterances in the way that the system intended.;2010
Depression affects approximately 15% of the US population and is recognized as an important risk factor for poor outcomes among patients with various illnesses. Automated health education and behavior change programs have the potential to help address many of the shortcomings in health care. However the role of these systems in the care of patients with depression has been insufficiently examined. In the current study we sought to evaluate how hospitalized medical patients would respond to a computer animated conversational agent that has been developed to provide information in an empathic fashion about a patient's hospital discharge plan. In particular we sought to examine how patients who have a high level of depressive symptoms respond to this system. Therapeutic alliance - the trust and belief that a patient and provider have in working together to achieve a desired therapeutic outcome - was used as the primary outcome measure since it has been shown to be important in predicting outcomes across a wide range of health problems including depression. In an evaluation of 139 hospital patients who interacted with the agent at the time of discharge all patients regardless of depressive symptoms rated the agent very high on measures of satisfaction and ease of use and most preferred receiving their discharge information from the agent compared to their doctors or nurses in the hospital. In addition we found that patients with symptoms indicative of major depression rated the agent significantly higher on therapeutic alliance compared to patients who did not have major depressive symptoms. We conclude that empathic agents represent a promising technology for patient assessment education and counseling for those most in need of comfort and caring in the inpatient setting. (C) 2010 Elsevier B.V. All rights reserved.;2010
During face-to-face conversation our body is continually in motion displaying various head gesture and posture movements. Based on findings describing the communicative functions served by these nonverbal behaviors many virtual agent systems have modeled them to make the virtual agent look more effective and believable. One channel of nonverbal behaviors that has received less attention is head movements despite the important functions served by them. The goal for this work is to build a domain-independent model of speaker's head movements that could be used to generate head movements for virtual agents. In this paper we present a machine learning approach for learning models of head movements by focusing on when speaker head nods should occur and conduct evaluation studies that compare the nods generated by this work to our previous approach of using handcrafted rules [1]. To learn patterns of speaker head nods we use a gesture corpus and rely on the linguistic and affective features of the utterance. We describe the feature selection process and training process for learning hidden Markov models and compare the results of the learned models under varying conditions. The results show that we can predict speaker head nods with high precision (.84) and recall (.89) rates even without a deep representation of the surface text and that using affective information can help improve the prediction of the head nods (precision: .89 recall: .90). The evaluation study shows that the nods generated by the machine learning approach are perceived to be more natural in terms of nod timing than the nods generated by the rule-based approach.;2010
Elckerlyc is a BML Realizer for generating multimodal verbal and nonverbal behavior for Virtual Humans (VHs). The main characteristics of Elckerlyc are that (1) it is designed specifically for continuous interaction with tight temporal coordination between the behavior of a VH and its interaction partner (2) it provides a mix between the precise temporal and spatial control offered by procedural animation and the physical realism of physical simulation and (3) it is designed to be highly modular and extensible implementing the architecture proposed in SAIBA.;2010
Embodied Conversational Agents (ECA) are computer-animated characters that simulate face-to-face conversation with patients. These agents can be programmed with best practices in human-human health communication and used for automated health education and behavior change counseling interventions. Evidence is presented from two ongoing clinical trials demonstrating that patients at different levels of health literacy find these agents acceptable and easy to use for automated health communication interventions. Innovative computer interface systems can be used to ensure that inadequate health literacy not serve as a barrier to interventions using health information technology.;2010
Emotional corpora provide an important empirical foundation for investigation when researchers aim at implementing emotion-aware spoken dialog systems. One of the fundamental research questions is how to acquire an appropriate realistic emotion corpus. The primary aim of this paper is to address the methodological desiderata in producing emotion corpora in human-machine interaction (HMI). It proposes a substantial refinement of the Wizard-of-Oz (WOZ) technique in order that a scenario designed to elicit affected speech in HMI could result in realistic and useful data. In addition the paper reports about the NIMITEK corpus of affected behavior in HMI produced during a refined WOZ simulation. The evaluation of the corpus with respect to the perception of its emotional content demonstrated that the corpus contains recordings of emotions that were overtly signaled. The range of emotional reactions is indicative of the kind of emotional reactions than can be expected to occur in the interaction with the sort of spoken dialog systems considered in this study. Since the subjects were not restricted by given predetermined linguistic constraints on the language to use their utterances are indicative of the way in which nontrained nontechnical users probably like to converse with conversational agents as well.;2010
Empirical studies have repeatedly shown that autonomous artificial entities so-called embodied conversational agents elicit social behavior on the part of the human interlocutor. Various theoretical approaches have tried to explain this phenomenon: According to the Threshold Model of Social Influence (Blascovich et al. 2002) the social influence of real persons who are represented by avatars will always be high whereas the influence of an artificial entity depends on the realism of its behavior. Conversely the Ethopoeia concept (Nass & Moon 2000) predicts that automatic social reactions are triggered by situations as soon as they include social cues. The presented study evaluates whether participant S belief in interacting with either an avatar (a virtual representation of a human) or an agent (autonomous virtual person) lead to different social effects. We used a 2 x 2 design with two levels of agency (agent or avatar) and two levels of behavioral realism (showing feedback behavior versus showing no behavior). We found that the belief of interacting with either an avatar or an agent barely resulted in differences with regard to the evaluation of the virtual character or behavioral reactions whereas higher behavioral realism affected both. It is discussed to what extent the results thus support the Ethopoeia concept. (C) 2010 Elsevier Ltd. All rights reserved.;2010
Human natural face-to-face communication is characterized by inter-personal coordination. In this paper phenomena are analyzed that yield coordination of behaviors beliefs and attitudes between interaction partners which can be tied to a concept of establishing social resonance. It is discussed whether these mechanisms can and should be transferred to conversation with artificial interlocutors like ECAs or humanoid robots. It is argued that one major step in this direction is embodied coordination mutual adaptations that are mediated by flexible modules for the top-down production and bottom-up perception of expressive conversational behavior that ground in and crucially coalesce in the same sensorimotor structures. Work on modeling this for ECAs with a focus on coverbal gestures is presented. (C) 2010 Elsevier B.V. All rights reserved.;2010
In many scenes with human characters interacting groups are an important factor for maintaining a sense of realism. However little is known about what makes these characters appear realistic. In this paper we investigate human sensitivity to audio mismatches (i.e. when individuals' voices are not matched to their gestures) and visual desynchronization (i.e. when the body motions of the individuals in a group are mis-aligned in time) in virtual human conversers. Using motion capture data from a range of both polite conversations and arguments we conduct a series of perceptual experiments and determine some factors that contribute to the plausibility of virtual conversing groups. We found that participants are more sensitive to visual desynchronization of body motions than to mismatches between the characters' gestures and their voices. Furthermore synthetic conversations can appear sufficiently realistic once there is an appropriate balance between talker and listener roles. This is regardless of body motion desynchronization or mismatched audio.;2010
In this paper we describe an algorithm for generating distinctive behavior for Embodied Conversational Agents. To this aim we introduce the concepts of agent's general behavior tendency named Baseline and local behavior tendency called in turn Dynamicline. Depending on the communicative intentions of the agent the Baseline is modulated. The obtained behavior tendency corresponds to the Dynamicline which is then used to determine the nonverbal signals and their expressivity the agent will produce to communicate its intentions. We also propose a system to extract the movement expressivity of a human user standing in front of a camera. The extracted characteristics are then used to characterize the agent's Baseline. We end the paper by presenting an evaluation study of our model.;2010
In this paper we present an attempt to develop a speech recognition module for the Romanian language in order to be used in a dialogue system. The main characteristics of such a dialogue system are first discussed. Further we explain the design and acquisition of a spontaneous speech database for training the decoder: the design guidelines in developing the database as well as several practical issues encountered along with some triphones balancing statistics arc pointed out. Then the speech recognition architecture (based on components in the Hidden Markov Modeling Toolkit - HTK) is described in detail emphasizing the two aspects training and decoding. In the next section a discussion of several preliminary recognition results is provided emphasizing current limitations and the need to significantly increase the size of the database. A set of conclusions and perspectives are offered at the end of the paper.;2010
In this paper we present an innovative work on a multiagent joking conversational system. In our research so far we have shown that implementing humor into a chatterbot can visibly improve its performance. The results presented in this paper are the outcome of the next step of our work. They show that a multiagent system combining a conversational agent a pun generator and an emotiveness analysis engine works reasonably well in interactions with users. In the setup used in this research the emotiveness analysis agent analyses users' utterances and decides whether it is appropriate to tell a pun. Depending on the results of this analysis the agent chooses either the pun generator if the decision is that a joke should be told or the non-humor-equipped agent when the decision is different. Two evaluation experiments were conducted: user (first person) focused and automatic (emotiveness-analysis-based). In both we compared the performance of the multiagent joking system and a baseline (non-humorous) conversation agent. The results show that in both cases the humor-equipped engine was evaluated as better than the baseline agent. The results are discussed and some ideas for the future are given.;2010
In this paper we present our embodied conversational agent (ECA) capable of displaying a vast set of facial expressions to communicate its emotional states as well as its social relations. Our agent is able to superpose and mask its emotional states as well as fake or inhibit them. We defined complex facial expressions as expressions arising from these displays. In the following we describe a model based on fuzzy methods that enables to generate complex facial expressions of emotions. It uses fuzzy similarity to compute the degree of resemblance between facial expressions of the ECA. We also present an algorithm that adapts the facial behaviour of the agent depending on its social relationship with the interactants. This last algorithm is based on the theory of politeness by Brown and Levinson (1987). It outputs complex facial expressions that are socially adequate. (C) 2010 Elsevier Ltd. All rights reserved.;2010
In this paper we describe two series of experiments that examine audiovisual face-to-face interaction between naive human viewers and either a human interlocutor or a virtual conversational agent. The main objective is to analyze the interplay between speech activity and mutual gaze patterns during mediated face-to-face interactions. We first quantify the impact of deictic gaze patterns of our agent. We further aim at refining our experimental knowledge on mutual gaze patterns during human face-to-face interaction by using new technological devices such as non-invasive eye trackers and pinhole cameras and at quantifying the impact of a selection of cognitive states and communicative functions on recorded gaze patterns. (C) 2010 Elsevier B.V. All rights reserved.;2010
In this paper we present a weakly supervised learning approach for spoken language understanding in domain-specific dialogue systems. We model the task of spoken language understanding as a two-stage classification problem. Firstly the topic classifier is used to identify the topic of an input utterance. Secondly with the restriction of the recognized target topic the slot classifiers are trained to extract the corresponding slot-value pairs. It is mainly data-driven and requires only minimally annotated corpus for training whilst retaining the understanding robustness and deepness for spoken language. More importantly it allows that weakly supervised strategies are employed for training the two kinds of classifiers which could significantly reduce the number of labeled sentences. We investigated active learning and naive self-training for the two kinds of classifiers. Also we propose a practical method for bootstrapping topic-dependent slot classifiers from a small amount of labeled sentences. Experiments have been conducted in the context of the Chinese public transportation information inquiry domain and the English DARPA Communicator domain. The experimental results show the effectiveness of our proposed SLU framework and demonstrate the possibility to reduce human labeling efforts significantly. (C) 2009 Elsevier Ltd. All rights reserved.;2010
In this work we elaborate on a novel image-based system for creating video-realistic eye animations to arbitrary spoken output. These animations are useful to give a face to multimedia applications such as virtual operators in dialog systems. Our eye animation system consists of two parts: eye control unit and rendering engine which synthesizes eye animations by combining 3D and image-based models. The designed eye control unit is based on eye movement physiology and the statistical analysis of recorded human subjects. As already analyzed in previous publications eye movements vary while listening and talking. We focus on the latter and are the first to design a new model which fully automatically couples eye blinks and movements with phonetic and prosodic information extracted from spoken language. We extended the already known simple gaze model by refining mutual gaze to better model human eye movements. Furthermore we improved the eye movement models by considering head tilts torsion and eyelid movements. Mainly due to our integrated blink and gaze model and to the control of eye movements based on spoken language subjective tests indicate that participants are not able to distinguish between real eye motions and our animations which has not been achieved before.;2010
It is well known that help prompts shape how users talk to spoken dialogue systems. This study investigated the effect of help prompt placement on older users' interaction with a smart home interface. In the dynamic help condition help was only given in response to system errors in the inherent help condition it was also given at the start of each task. Fifteen older and sixteen younger users interacted with a smart home system using two different scenarios. Each scenario consisted of several tasks. The linguistic style users employed to communicate with the system (interaction style) was measured using the ratio of commands to the overall utterance length (keyword ratio) and the percentage of content words in the user's utterance that could be understood by the system (shared vocabulary). While the timing of help prompts did not affect the interaction style of younger users it was early task-specific help supported older users in adapting their interaction style to the system's capabilities. Well-placed help prompts can significantly increase the usability of spoken dialogue systems for older people.;2010
Many researchers in the Human Robot Interaction (HRI) and Embodied Conversational Agents (ECA) domains try to build robots and agents that exhibit human-like behavior in real-world close encounter situations. One major requirement for comparing such robots and agents is to have an objective quantitative metric for measuring naturalness in various kinds of interactions. Some researchers have already suggested techniques for measuring stress level awareness etc using physiological signals like Galvanic Skin Response (GSR) and Blood Volume Pulse (BVP). One problem of available techniques is that they are only tested with extreme situations and cannot according to the analysis provided in this paper distinguish the response of human subjects in natural interaction situations. One other problem of the available techniques is that most of them require calibration and some times ad-hoc adjustment for every subject. This paper explores the usefulness of various kinds of physiological signals and statistics in distinguishing natural and unnatural partner behavior in a close encounter situation. The paper also explores the usefulness of these statistics in various time slots of the interaction. Based on this analysis a regressor was designed to measure naturalness in close encounter situations and was evaluated using human-human and human-robot interactions and shown to achieve statistically significant distinction between natural and unnatural situations.;2010
Possibilities of modeling in order to obtain a program for investments and its financing are presented. We illustrate starting from two case study the mode of simultaneous programming by using an heuristic model conceived by Dean and a linear programming model. For the second model the results obtained in conversational system are explained. The parametric analysis of resources (feasible financing) and of the unit income obtained by purchasing the investment objects pointing out the consequences of the different variations upon the objective function value is achieved.;2010
Purpose - Conversational agents are natural language interaction interfaces designed to simulate conversation with a real person. This paper seeks to investigate current development and applications of these systems worldwide while focusing on their availability in Canadian libraries. It aims to argue that it is both timely and conceivable for Canadian libraries to consider adopting conversational agents to enhance not replace face-to-face human interaction. Potential users include library web site tour guides automated virtual reference and readers' advisory librarians and virtual story-tellers. To provide background and justification for this argument the paper seeks to review agents from classic implementations to state-of-the-art prototypes: how they interact with users produce language and control conversational behaviors. Design/methodology/approach - The web sites of the 20 largest Canadian libraries were surveyed to assess the extent to which specific language-related technologies are offered in Canada including conversational agents. An exemplified taxonomy of four pragmatic purposes that conversational agents currently serve outside libraries educational informational assistive and socially interactive is proposed and translated into library settings. Findings - As of early 2010 artificially intelligent conversational systems have been found to be virtually non-existent in Canadian libraries while other innovative technologies proliferate (e.g. social media tools). These findings motivate the need for a broader awareness and discussion within the US community of these systems' applicability and potential for library purposes. Originality/value - This paper is intended for reflective information professionals who seek a greater understanding of the issues related to adopting conversational agents in libraries as this topic is scarcely covered in the LIS literature. The pros and cons are discussed and insights offered into perceptions of intelligence (artificial or not) as well as the fundamentally social nature of human-computer interaction.;2010
Relational agents are computational artifacts such as animated screen-based characters or social robots that are designed to establish a sense of rapport trust and even therapeutic alliance with patients using ideal therapeutic relationships between human counselors and patients as role models. We describe the development and evaluation of several such agents designed for health counseling and behavioral-change interventions in which a therapeutic alliance is established with patients in order to enhance the efficacy of the intervention. We also discuss the promise of using such agents as adjuncts to clinical psychiatry a range of possible applications and some of the challenges and ethical issues in developing and fielding them in psychiatric interventions.</.;2010
So far predictions of user quality judgments in response to spoken dialog systems have been achieved on the basis of interaction parameters describing the dialog e.g. in the PARADISE framework. These parameters do not take into account the temporal position of events happening in the dialog. It seems promising to apply sequence classification algorithms to the raw annotations of the data instead of interaction parameters describing the overall dialog. As dialogs can be of very different length Hidden Markov Models (HMM) and Markov Chains (MC) are handy because they describe the likelihood of traversing to a state given only the previous state and the transition probability thus they can be trained and applied to sequences of different lengths. This paper analyzes the feasibility of predicting user judgments with HMMs and MCs. In order to test the models we acquire data with different types of users forcing users to do as similar interactions as possible and asking for user judgments after each turn. This allows comparing predicted distributions of judgments to the distributions measured empirically. We also apply the models to less rich corpora and compare them with results from Linear Regression models as used in the PARADISE framework. (C) 2010 Elsevier B.V. All rights reserved.;2010
Spoken dialog systems have difficulty selecting which action to take in a given situation because recognition and understanding errors are prevalent due to noise and unexpected inputs. To solve this problem this paper presents a hybrid approach to improving robustness of the dialog manager by using agenda-based and example-based dialog modeling. This approach can exploit it-best hypotheses to determine the current dialog state in the dialog manager and keep track of the dialog state using a discourse interpretation algorithm based on an agenda graph and a focus stack. Given the agenda graph and multiple recognition hypotheses the system can predict the next action to maximize multi-level score functions and trigger error recovery strategies to handle exceptional cases due to misunderstandings or unexpected focus shifts. The proposed method was tested by developing a spoken dialog system for a building guidance domain in an intelligent service robot. This system was then evaluated by simulated and real users. The experimental results show that our approach can effectively develop robust dialog management for spoken dialog systems. (C) 2009 Elsevier Ltd. All rights reserved.;2010
Tailoring the linguistic content of automatically generated descriptions to the preferences of a target user has been well demonstrated to be an effective way to produce higher-quality output that may even have a greater impact on user behaviour. It is known that the non-verbal behaviour of an embodied agent can have a significant effect on users' responses to content presented by that agent. However to date no-one has examined the contribution of non-verbal behaviour to the effectiveness of user tailoring in automatically generated embodied output. We describe a series of experiments designed to address this question. We begin by introducing a multimodal dialogue system designed to generate descriptions and comparisons tailored to user preferences and demonstrate that the user-preference tailoring is detectable to an overhearer when the output is presented as synthesised speech. We then present a multimodal corpus consisting of the annotated facial expressions used by a speaker to accompany the generated tailored descriptions and verify that the most characteristic positive and negative expressions used by that speaker are identifiable when resynthesised on an artificial talking head. Finally we combine the corpus-derived facial displays with the tailored descriptions to test whether the addition of the non-verbal channel improves users' ability to detect the intended tailoring comparing two strategies for selecting the displays: one based on a simple corpus-derived rule and one making direct use of the full corpus data. The performance of the subjects who saw displays selected by the rule-based strategy was not significantly different than that of the subjects who got only the linguistic content while the subjects who saw the data-driven displays were significantly worse at detecting the correctly tailored output. We propose a possible explanation for this result and also make recommendations for developers of future systems that may make use of an embodied agent to present user-tailored content.;2010
The aim of the study was to determine the influence of textual feedback on the content and outcome of spoken interaction with a natural language dialogue system. More specifically the assumption that textual feedback could disrupt spoken interaction was tested in a human-computer dialogue situation. In total 48 adult participants familiar with the system had to find restaurants based on simple or difficult scenarios using a real natural language service system in a speech-only (phone) speech plus textual dialogue history (multimodal) or text-only (web) modality. The linguistic contents of the dialogues differed as a function of modality but were similar whether the textual feedback was included in the spoken condition or not. These results add to burgeoning research efforts on multimodal feedback in suggesting that textual feedback may have little or no detrimental effect on information searching with a real system. Statement of Relevance: The results suggest that adding textual feedback to interfaces for human-computer dialogue could enhance spoken interaction rather than create interference. The literature currently suggests that adding textual feedback to tasks that depend on the visual sense benefits human-computer interaction. The addition of textual output when the spoken modality is heavily taxed by the task was investigated.;2010
The amount of data published on the Semantic Web has witnessed a tremendous growth in the last years to which the Linked Open Data (LOD) project has contributed significantly. While the Semantic Web was originally conceived of as an extension to the Web by addition of machine-readable data allowing automatic processing by machines the question how humans can benefit from all the data published on the Web is becoming an important one. In the light of this question it seems crucial to make accessing the data on the Web as easy and intuitive as possible by adapting to the cognitive and information processing capabilities of humans. In this short position paper we argue that one interesting and promising approach in this direction is to allow people to access semantic data on the Web through multimodal interaction with embodied virtual characters.;2010
The AVLaughterCycle project aims at developing an audiovisual laughing machine able to detect and respond to user's laughs. Laughter is an important cue to reinforce the engagement in human-computer interactions. As a first step toward this goal we have implemented a system capable of recording the laugh of a user and responding to it with a similar laugh. The output laugh is automatically selected from an audiovisual laughter database by analyzing acoustic similarities with the input laugh. It is displayed by an Embodied Conversational Agent animated using the audio-synchronized facial movements of the subject who originally uttered the laugh. The application is fully implemented works in real time and a large audiovisual laughter database has been recorded as part of the project. This paper presents AVLaughterCycle its underlying components the freely available laughter database and the application architecture. The paper also includes evaluations of several core components of the application. Objective tests show that the similarity search engine though simple significantly outperforms chance for grouping laughs by speaker or type. This result can be considered as a first measurement for computing acoustic similarities between laughs. A subjective evaluation has also been conducted to measure the influence of the visual cues on the users' evaluation of similarity between laughs.;2010
The concept of action as basic motor control unit for goal-directed movement behavior has been used primarily for private or non-communicative actions like walking reaching or grasping. In this paper literature is reviewed indicating that this concept can also be used in all domains of face-to-face communication like speech co-verbal facial expression and co-verbal gesturing. Three domain-specific types of actions i.e. speech actions facial actions and hand-arm actions are defined in this paper and a model is proposed that elucidates the underlying biological mechanisms of action production action perception and action acquisition in all domains of face-to-face communication. This model can be used as theoretical framework for empirical analysis or simulation with embodied conversational agents and thus for advanced human-computer interaction technologies.;2010
The evaluation of subjective aspects of HCI such as human-likeness likeability or users' emotions towards computers is still quite a neglected issue especially in the field of non-task oriented conversational systems (chatterbots). In this paper we try to bridge this gap by proposing a new methodology of evaluation. The methods presented were tested in our research on humor-equipped chatterbots. We describe them in details discuss their drawbacks and usability. In one of the presented methods we used an emotiveness analysis system which itself can be considered an AI tool as it was used to detect users' emotions towards conversational systems and to perform their automatic evaluation. We also propose some methods that we have not used yet which however seem applicable in this field such as brain scanning techniques. Finally we give some ideas that should be addressed in the future.;2010
The purpose of this paper is to develop a robot that actively communicates with a human and explicitly extracts information from the human mind that is rarely expressed as verbal information The spoken dialogue system for information collection must independently decide whether it may or may not start communicating with human In this paper we assume that the system begins to communicate with a human sitting and working at a desk analyze the relationship between his behavioral pattern and the decisions made by the other humans I e whether Or not to communicate with the working man and construct the decision model for the system to start communicating with the human using hidden Markov model;2010
There was conversation agent on the generation method of emotion expression. It is necessary for the conversation system like the human for communication In the previous method at first a word which could influence the feeling was defined Facial expression was changed according to the word which influences the feeling in discourse But facial expression could not be changed if there was not a word that was defined in the discourse Hence we proposed a human emotion model for the expression generation of the conversation agent The method based on the human emotion model which can solve problem of the previous method and may make a more humanity conversation agent In this study we put a human emotion tag to discourse of talks scenarios and model to conversation agent of human emotion there were two kinds of method that put the human emotion tag to discourse We make the human emotion model by a scenarios that adopts the human emotion tag The human emotion model was used to create facial expression of conversation agent The assessment experiment was performed by using the systems of previous method and two human emotion models and the results were compared between the three methods;2010
This paper addresses modeling user behavior in interactions between two people who do not share a common spoken language and communicate with the aid of an automated bidirectional speech translation system. These interaction settings are complex. The translation machine attempts to bridge the language gap by mediating the verbal communication noting however that the technology may not be always perfect. In a step toward understanding user behavior in this mediated communication scenario usability data from doctor-patient dialogs involving a two way English-Persian speech translation system are analyzed. We specifically consider user behavior in light of potential uncertainty in the communication between the interlocutors. We analyze the Retry (Repeat and Rephrase) versus Accept behaviors in the mediated verbal channel and as a result identify three user types - Accommodating Normal and Picky and propose a dynamic Bayesian network model of user behavior. To validate the model we performed offline and online experiments. The experimental results using offline data show that correct user type is clearly identified as a user keeps his/her consistent behavior in a given interaction condition. In the online experiment agent feedback was presented to users according to the user types. We show high user satisfaction and interaction efficiency in the analysis of user interview video data questionnaire and log data. (C) 2009 Elsevier Ltd. All rights reserved.;2010
This paper analyzes and compares the data gathered from two previously conducted Artificial Linguistic Internet Chat Entity (ALICE) chatterbot studies that were focused on response accuracy and user satisfaction measures for six chatterbots. These chatterbots were further loaded with varying degrees of conversational telecommunications and terrorism knowledge. From our prior experiments using 347 participants we obtained 33 446 human/chatterbot interactions. It was found that asking the ALICE chatterbots are and where questions resulted in higher response satisfaction levels as compared to other interrogative-style inputs because of their acceptability to vague binary or cliched chatterbot responses. We also found a relationship between the length of a query and the users perceived satisfaction of the chatterbot response where shorter queries led to more satisfying responses.;2010
This paper deals with automatic dialogue act (DA) recognition. Dialogue acts are sentence-level units that represent states of a dialogue such as questions statements hesitations etc. The knowledge of dialogue act realizations in a discourse or dialogue is part of the speech understanding and dialogue analysis process. It is of great importance for many applications: dialogue systems speech recognition automatic machine translation etc. The main goal of this paper is to study the existing works about DA recognition and to discuss their respective advantages and drawbacks. A major concern in the DA recognition domain is that although a few DA annotation schemes seem now to emerge as standards most of the time these DA tag-sets have to be adapted to the specificities of a given application which prevents the deployment of standardized DA databases and evaluation procedures. The focus of this review is put on the various kinds of information that can be used to recognize DAs such as prosody lexical etc. and on the types of models proposed so far to capture this information. Combining these information sources tends to appear nowadays as a prerequisite to recognize DAs.;2010
This paper describes a statistically motivated framework for performing real-time dialogue state updates and policy learning in a spoken dialogue system. The framework is based on the partially observable Markov decision process (POMDP) which provides a well-founded statistical model of spoken dialogue management. However exact belief state updates in a POMDP model are computationally intractable so approximate methods must be used. This paper presents a tractable method based on the loopy belief propagation algorithm. Various simplifications are made which improve the efficiency significantly compared to the original algorithm as well as compared to other POMDP-based dialogue state updating approaches. A second contribution of this paper is a method for learning in spoken dialogue systems which uses a component-based policy with the episodic Natural Actor Critic algorithm. The framework proposed in this paper was tested on both simulations and in a user trial. Both indicated that using Bayesian updates of the dialogue state significantly outperforms traditional definitions of the dialogue state. Policy learning worked effectively and the learned policy outperformed all others on simulations. In user trials the learned policy was also competitive although its optimality was less conclusive. Overall the Bayesian update of dialogue state framework was shown to be a feasible and effective approach to building real-world POMDP-based dialogue systems. (C) 2009 Elsevier Ltd. All rights reserved.;2010
This paper describes the Virtual Guide a multimodal dialogue system represented by an embodied conversational agent that can help users to find their way in a virtual environment while adapting its affective linguistic style to that of the user. We discuss the modular architecture of the system and describe the entire loop from multimodal input analysis to multimodal output generation. We also describe how the Virtual Guide detects the level of politeness of the user's utterances in real-time during the dialogue and aligns its own language to that of the user using different politeness strategies. Finally we report on our first user tests and discuss some potential extensions to improve the system.;2010
This paper examines the effective deployment of conversational agents in virtual worlds from the perspective of researchers/practitioners in cognitive psychology computing science learning technologies and engineering. From a cognitive perspective the major challenge lies in the coordination and management of the various channels of information associated with conversation/communication and integrating this information with the virtual space of the environment and the belief space of the user. From computing science the requirements include conversational competency use of nonverbal cues animation consistent with affective states believability domain competency and user adaptability. From a learning technologies perspective the challenge is to maximise the considerable affordances provided by conversational avatars in virtual worlds balanced against ecologically valid investigations regarding utility. Finally the engineering perspective focuses on the technical competency required to implement effective and functional agents and the associated costs to enable student access. Taken together the four perspectives draw attention to the quality of the agent-user interaction how theory practice and research are closely intertwined and the multidisciplinary nature of this area with opportunities for cross fertilisation and collaboration.;2010
This paper explains how Partially Observable Markov Decision Processes (POMDPs) can provide a principled mathematical framework for modelling the inherent uncertainty in spoken dialogue systems. It briefly summarises the basic mathematics and explains why exact optimisation is intractable. It then describes in some detail a form of approximation called the Hidden Information State model which does scale and which can be used to build practical systems. A prototype HIS system for the tourist information domain is evaluated and compared with a baseline MDP system using both user simulations and a live user trial. The results give strong support to the central contention that the POMDP-based framework is both a tractable and powerful approach to building more robust spoken dialogue systems. (C) 2009 Elsevier Ltd. All rights reserved.;2010
This paper explores the use of embodied conversational agents (ECAs) and their visual communicative ability to improve interaction with spoken language dialogue systems (SLDSs) through an experimental case study in the application context of secure access by speaker verification followed by remote home automation control. After identifying a set of typical interaction problems with SLDSs and associated with each of them a particular ECA gesture or behaviour we conducted a comparative evaluation based on ITU recommendations for the evaluation of spoken dialogue systems. User tests were carried out dividing the test users into two groups each facing a different interface setup: one with an ECA and the other only with voice output. The ECA group encountered fewer interaction problems. Users' impressions however were similar in both groups with a slight advantage observed for the ECA group. In particular the ECA seems to help users to better understand the flow of the dialogue and reduce confusion. Results also suggest that rejection (based on privacy and security concerns) is a dimension in its own right that may influence subjective evaluation parameters closely related to user acceptance.;2010
This paper proposes a new technique to increase the robustness of spoken dialogue systems employing an automatic procedure that aims to correct frames incorrectly generated by the system's component that deals with spoken language understanding. To do this the technique carries out a training that takes into account knowledge of previous system misunderstandings. The correction is transparent for the user as he is not aware of some mistakes made by the speech recogniser and thus interaction with the system can proceed more naturally. Experiments have been carried out using two spoken dialogue systems previously developed in our lab: Saplen and Viajero which employ prompt-dependent and prompt-independent language models for speech recognition. The results obtained from 10000 simulated dialogues show that the technique improves the performance of the two systems for both kinds of language modelling especially for the prompt-independent language model. Using this type of model the Saplen system increases sentence understanding by 19.54% task completion by 26.25% word accuracy by 7.53% and implicit recovery of speech recognition errors by 20.3% whereas for the Viajero system these figures increase by 14.93% 18.06% 6.98% and 15.63% respectively. (C) 2010 Elsevier B.V. All rights reserved.;2010
This paper proposes one of a response production method on chatting system automatically. Our approach is applied to Japanese language. This is not necessary that it achieve a task. The responses support our conversation flow and let us produce a new topic. The system will get much information for the speaker by performing much conversation with this system. Based on the much information by a conversation with the system the flexible reply for a speaker will come to be possible. In the present paper we propose a response by association of the input sentence. For example we associate medical treatment with hospital. We reply then using the association word. If like humans a machine can reply using the association word it will return various flexible responses.;2010
This research aims at defining a real-time probabilistic model of user's engagement in advice-giving dialogues. We propose an approach based on Hidden Markov Models (HMMs) to describe the differences in the dialogue pattern due to the different level of engagement experienced by the users. We train our HMM models on a corpus of natural dialogues with an Embodied Conversational Agent (ECA) in the domain of healthy-eating. The dialogues are coded in terms of Dialogue Acts associated to each system or user move. Results are quite encouraging: HMMs are a powerful formalism for describing the differences in the dialogue patterns due to the different level of engagement of users and they can be successfully employed in real-time user's engagement detection. Though the HMM learning process shows a lack of robustness when using low-dimensional and skewed corpora. Therefore we plan a further validation of our approach with larger corpora in the near future.;2010
To tackle the vocabulary problem in conversational systems previous work has applied unsupervised learning approaches on co-occurring speech and eye gaze during interaction to automatically acquire new words. Although these approaches have shown promiseseveral issues related to human language behavior and human-machine conversation have not been addressed. First psycholinguistic studies have shown certain temporal regularities between human eye movement and language production. While these regularities can potentially guide the acquisition process they have not been incorporated in the previous unsupervised approaches. Second conversational systems generally have an existing knowledge base about the domain and vocabulary. While the existing knowledge can potentially help bootstrap and constrain the acquired new words it has not been incorporated in the previous models. Third eye gaze could serve different functions in human-machine conversation. Some gaze streams may not be closely coupled with speech stream and thus are potentially detrimental to word acquisition. Automated recognition of closely-coupled speech-gaze streams based on conversation context is important. To address these issues we developed new approaches that incorporate user language behavior domain knowledge and conversation context in word acquisition. We evaluated these approaches in the context of situated dialogue in a virtual world. Our experimental results have shown that incorporating the above three types of contextual information significantly improves word acquisition performance.;2010
We address the issue of out of grammar (OOG) utterances in spoken dialogue systems by generating help messages Help message generation for OOG utterances is a challenge because language under standing based on automatic speech recognition (ASR) of OOG utterances is usually erroneous important words are often misrecognized or missing from such utterances Our grammar verification method uses a weighted finite state transducer to accurately identify the grammar rule that the user Intended to use tor the utterance even if important words are missing from the ASR results We then use a ranking algorithm Rank Boost to rank help message candidates in order of likely usefulness Its features include the grammar verification results and the utterance history representing the user s experience;2010
We describe an animated conversational computer agent designed to promote antipsychotic medication adherence among patients with schizophrenia. In addition to medication adherence the agent also promotes physical activity and system usage and includes verbal and nonverbal behavior designed to foster a therapeutic alliance with patients. We discuss special considerations in designing interventions for this patient population and challenges in developing and evaluating conversational agents in the mental health domain. Results from a pilot evaluation study of the agent indicate that it is accepted and effective. (C) 2010 Elsevier B.V. All rights reserved.;2010
We describe an approach to integrate dialogue management machine-learning and action planning in a system for dialogue between a human and a robot. Case-based techniques are used because they permit life-long learning from experience and demand little prior knowledge and few static hand-written structures. This approach has been developed through the work on an experimental dialogue system called CEDERIC that is connected to an unmanned aerial vehicle (UAV). A single case base and case-based reasoning engine is used both for understanding and for planning actions by the UAV. Dialogue experiments both with experienced and novice users where the users have solved tasks by dialogue with this system showed very adequate success rates.;2010
We describe an evaluation of spoken dialogue strategies designed using hierarchical reinforcement learning agents. The dialogue strategies were learnt in a simulated environment and tested in a laboratory setting with 32 users. These dialogues were used to evaluate three types of machine dialogue behaviour: hand-coded fully-learnt and semi-learnt. These experiments also served to evaluate the realism of simulated dialogues using two proposed metrics contrasted with 'Precision-Recall'. The learnt dialogue behaviours used the Semi-Markov Decision Process (SMDP) model and we report the first evaluation of this model in a realistic conversational environment. Experimental results in the travel planning domain provide evidence to support the following claims: (a) hierarchical semi-learnt dialogue agents are a better alternative (with higher overall performance) than deterministic or fully-learnt behaviour (b) spoken dialogue strategies learnt with highly coherent user behaviour and conservative recognition error rates (keyword error rate of 20%) can outperform a reasonable hand-coded strategy and (c) hierarchical reinforcement learning dialogue agents are feasible and promising for the (semi) automatic design of optimized dialogue behaviours in larger-scale systems. (C) 2009 Elsevier Ltd. All rights reserved.;2010
We describe how the interaction mode with an embodied conversational agent (ECA) affects the users' perception of the agent and their behavior during interaction and propose a method to recognize the social attitude of users towards the agent from their verbal behavior. A corpus of human-ECA dialogues was collected with a Wizard-of-Oz study in which the input mode of the user moves was varied (written vs. speech-based). After labeling the corpus we evaluated the relationship between input mode and social attitude of users towards the agent. The results show that by increasing naturalness of interaction spoken input produces a warmer attitude of users and a richer language: this effect is more evident for users with a background in humanities. Recognition of signs of social attitude is needed for adapting the ECA's verbal and nonverbal behavior. (c) 2010 Elsevier B.V. All rights reserved.;2010
We investigate the impact of three different factors on the quality of talking heads as metaphors of a spoken dialogue system in the smart home domain. The main focus lies on the effect of voice and head characteristics on audio and video quality as well as overall quality. Furthermore the influence of interactivity and of media context on user perception is analysed. For this purpose two subsequent experiments were conducted: the first was designed as a non-interactive rating test of videos of talking heads while the second experiment was interactive. Here the participants had to solve a number of tasks in dialogue with a talking head. To assess the impact of the media context redundant information was provided via an additional visual output channel to half of the participants. As a secondary effect the importance of participants' gender is examined. It is shown that perceived quality differences observed in the non-interactive setting are blurred when the interactivity and media contexts provide distraction from the talking head. Furthermore a simple additional feedback screen improves the perceived quality of the talking heads. Gender effects are negligible concerning the ratings in interaction but female and male participants exhibit different behaviour in the experiment. This advocates for more realistic evaluation settings in order to increase the external validity of the obtained quality judgements. (C) 2010 Elsevier B.V. All rights reserved.;2010
We investigate the use of different machine learning methods in combination with feature selection techniques to explore human multimodal dialogue strategies and the use of those strategies for automated dialogue systems. We learn policies from data collected in a Wizard-of-Oz study where different human 'wizards' decide whether to ask a clarification request in a multimodal manner or else to use speech alone. We first describe the data collection the coding scheme and annotated corpus and the validation of the multimodal annotations. We then show that there is a uniform multimodal dialogue strategy across wizards which is based on multiple features in the dialogue context. These are generic features available at runtime which can be implemented in dialogue systems. Our prediction models (for human wizard behaviour) achieve a weighted f-score of 88.6 per cent (which is a 25.6 per cent improvement over the majority baseline). We interpret and discuss the learned strategy. We conclude that human wizard behaviour is not optimal for automatic dialogue systems and argue for the use of automatic optimization methods such as Reinforcement Learning. Throughout the investigation we also discuss the issues arising from using small initial Wizard-of-Oz data sets and we show that feature engineering is an essential step when learning dialogue strategies From such limited data.;2010
We present the MATCH corpus a unique data set of 447 dialogues in which 26 older and 24 younger adults interact with nine different spoken dialogue systems. The systems varied in the number of options presented and the confirmation strategy used. The corpus also contains information about the users' cognitive abilities and detailed usability assessments of each dialogue system. The corpus which was collected using a Wizard-of-Oz methodology has been fully transcribed and annotated with dialogue acts and Information State Update (ISU) representations of dialogue context. Dialogue act and ISU annotations were performed semi-automatically. In addition to describing the corpus collection and annotation we present a quantitative analysis of the interaction behaviour of older and younger users and discuss further applications of the corpus. We expect that the corpus will provide a key resource for modelling older people's interaction with spoken dialogue systems.;2010
We propose an efficient technique of dialogue management for an information navigation system based oil a document knowledge base. The system can use ASR N-best hypotheses and contextual information to perform robustly for fragmental speech input and erroneous output of automatic speech recognition (ASR). It also has several choices in generating responses or confirmations. We formulate the optimization of these choices based oil a Bayes risk criterion which is defined based on a reward for correct information presentation and a penalty for redundant turns. The parameters for the dialogue management we propose can be adaptively tuned by online learning. We evaluated this strategy with our spoken dialogue system called Dialogue Navigator for Kyoto City which generates responses based oil the document retrieval and also has question-answering capability. The effectiveness of the proposed framework was demonstrated by the increased success rate of dialogue and the reduced number of turns for information access through an experiment with a large number of utterances by real users. (C) 2009 Elsevier B.V. All rights reserved.;2010
When conveying information about spatial situations and goals speakers adapt flexibly to their addressee in order to reach the communicative goal efficiently and effortlessly. Our aim is to equip a dialogue system with the abilities required for such a natural adaptive dialogue. In this paper we investigate the strategies people use to convey route information in relation to a map by presenting two parallel studies involving human-human and human-computer interaction. We compare the instructions given to a human interaction partner with those given to a dialogue system which reacts by basic verbal responses and dynamic visualization of the route in the map. The language produced by human route givers is analyzed with respect to a range of communicative as well as cognitively crucial features particularly perspective choice and references to locations across levels of granularity. Results reveal that speakers produce systematically different instructions with respect to these features depending on the nature of the interaction partner human or dialogue system. Our further analysis of clarification and reference resolution strategies produced by human route followers provides insights into dialogue strategies that future systems should be equipped with. (C) 2010 Elsevier Ltd. All rights reserved.;2010
A basic goal in human-robot interaction is to establish such a communication mode between the two parties that the humans perceive it as effective and natural effective in the sense of being responsive to the information needs of the humans and natural in the sense of communicating information in modes familiar to humans. This paper sets the framework for a robot guide to visitors in art collections and other assistive environments which incorporates the principles of effectiveness and naturalness. The human-robot interaction takes place in natural language in the form of a dialogue session during which the robot describes exhibits but also recommends exhibits that might be of interest to the visitors. It is also possible for the robot to explain its reasoning to the visitors with a view to increasing transparency and consequently trust in the robot's suggestions. Furthermore the robot leads the visitors to the location of the desired exhibit. The framework is general enough to be implemented in different hardware including portable computational devices. The framework is based on a cognitive model comprised of four modules: a reactive a deliberative a reflective and an affective one. An initial implementation of a dialogue system realising this cognitive model is presented. main ontology.;2011
A common task for spoken dialog systems (SDS) is to help users select a suitable option (e.g. flight hotel and restaurant) from the set of options available. As the number of options increases the system must have strategies for generating summaries that enable the user to browse the option space efficiently and successfully. In the user-model based summarize and refine approach (UMSR Demberg and Moore 2006) options are clustered to maximize utility with respect to a user model and linguistic devices such as discourse cues and adverbials are used to highlight the trade-offs among the presented items. In a Wizard-of-Oz experiment we show that the UMSR approach leads to improvements in task success efficiency and user satisfaction compared to an approach that clusters the available options to maximize coverage of the domain (Polifroni et al. 2003). In both a laboratory experiment and a web-based experimental paradigm employing the Amazon Mechanical Turk platform we show that the discourse cues in UMSR summaries help users compare different options and choose between options even though they do not improve verbatim recall. This effect was observed for both written and spoken stimuli. (C) 2010 Elsevier Ltd. All rights reserved.;2011
A previous line of research suggests that interlocutors identify appropriate places to speak by cues in the behaviour of the preceding speaker. If used in combination these cues have an additive effect on listeners' turn-taking attempts. The present study further explores these findings by examining the effect of such turn-taking cues experimentally. The objective is to investigate the possibilities of generating turn-taking cues with a synthetic voice. Thus in addition to stimuli realized with a human voice the experiment included dialogues where one of the speakers is replaced with a synthesis. The turn-taking cues investigated include intonation phrase-final lengthening semantic completeness stereotyped lexical expressions and non-lexical speech production phenomena such as lexical repetitions breathing and lip-smacks. The results show that the turn-taking cues realized with a synthetic voice affect the judgements similar to the corresponding human version and there is no difference in reaction times between these two conditions. Furthermore the results support Duncan's findings: the more turn-taking cues with the same pragmatic function turn-yielding or turn-holding the higher the agreement among subjects on the expected outcome. In addition the number of turn-taking cues affects the reaction times for these decisions. Thus the more cues the faster the reaction time. (C) 2010 Elsevier B.V. All rights reserved.;2011
A well-known ambiguity in the term 'argument' is that of argument as an inferential structure and argument as a kind of dialogue. In the first sense an argument is a structure with a conclusion supported by one or more grounds which may or may not be supported by further grounds. Rules for the construction and criteria for the quality of arguments in this sense are a matter of logic. In the second sense arguments have been studied as a form of dialogical interaction in which human or artificial agents aim to resolve a conflict of opinion by verbal means. Rules for conducting such dialogues and criteria for their quality are part of dialogue theory. Usually formal accounts of argumentation dialogues in logic and artificial intelligence presuppose an argument-based logic. That is the ways in which dialogue participants support and attack claims are modelled as the construction of explicit arguments and counterarguments (in the inferential sense). However in this paper formal models of argumentation dialogues are discussed that do not presuppose arguments as inferential structures. The motivation for such models is that there are forms of inference that are not most naturally cast in the form of arguments (such as abduction statistical reasoning and coherence-based reasoning) but that can still be the subject of argumentative dialogue. Some recent work in artificial intelligence is discussed which embeds non-argumentative inference in an argumentative dialogue system and some general observations are drawn from this discussion.;2011
Applications with intelligent conversational virtual humans called Embodied Conversational Agents (ECAs) seek to bring human-like abilities into machines and establish natural human-computer interaction. In this paper we discuss realization of ECA multimodal behaviors which include speech and nonverbal behaviors. We devise RealActor an open-source multi-platform animation system for real-time multimodal behavior realization for ECAs. The system employs a novel solution for synchronizing gestures and speech using neural networks. It also employs an adaptive face animation model based on Facial Action Coding System (FACS) to synthesize face expressions. Our aim is to provide a generic animation system which can help researchers create believable and expressive ECAs.;2011
Automated approaches to promoting health behavior change such as exercise diet and medication adherence promotion have the potential for significant positive impact on society. We describe a theory-driven computational model of dialogue that simulates a human health counselor who is helping his or her clients to change via a series of conversations over time. Applications built using this model can be used to change the health behavior of patients and consumers at low cost over a wide range of media including the web and the phone. The model is implemented using an OWL ontology of health behavior change concepts and a public standard task modeling language (ANSI/CEA-2018). We demonstrate the power of modeling dialogue using an ontology and task model by showing how an exercise promotion system developed in the framework was re-purposed for diet promotion with 98% reuse of the abstract models. Evaluations of these two systems are presented demonstrating high levels of fidelity to best practices in health behavior change counseling. (c) 2011 Elsevier Inc. All rights reserved.;2011
Conversation provides an excellent means of communication for almost all people. Consequently a conversational interface is an excellent mechanism for allowing people to interact with systems. Conversational systems are an active research area but a wide range of systems can be developed with current technology. More sophisticated interfaces can take considerable effort but simple interfaces can be developed quite rapidly. This paper provides an introduction to the current state of the art of conversational systems and interfaces. It describes a methodology for developing conversational interfaces and gives an example of an interface for a state benefits website. The paper discusses how this interface could improve access for a wide range of people and how further development of this interface would allow a larger range of people to use the system with enhanced functionality.;2011
Conversational systems are gaining popularity rapidly. Consequently the believability of the conversational systems or chatterbots is becoming increasingly important. Recent research has proven that learning chatterbots tend to be rated as being more believable by users. Based on Raj's Model for Chatterbot Trust we present a model for allowing chatterbots to determine the degree of contradictions in contradictory statements when learning thereby allowing them to potentially learn more accurately via a form of discourse. Some information that is learnt by a chatterbot may be contradicted by other information presented subsequently. Choosing correctly which information to use is critical in chatterbot believability. Our model uses sentence structures and patterns to compute contradiction degrees that can be used to overcome the limitations of Raj's Trust Model which takes any contradictory information as being equally contradictory as opposed to some contradictions being greater than others and therefore having a greater impact on the actions that the chatterbot should take. This paper also presents the relevant proofs and tests of the contradiction degree model as well as a potential implementation method to integrate our model with Raj's Trust Model.;2011
Detection thresholds for gaps and overlaps that is acoustic and perceived silences and stretches of overlapping speech in speaker changes were determined. Subliminal gaps and overlaps were categorized as no-gap-no-overlaps. The established gap and overlap detection thresholds both corresponded to the duration of a long vowel or about 120 ms. These detection thresholds are valuable for mapping the perceptual speaker change categories gaps overlaps and no-gap-no-overlaps into the acoustic domain. Furthermore the detection thresholds allow generation and understanding of gaps overlaps and no-gap-no-overlaps in human-like spoken dialogue systems. (C) 2011 Acoustical Society of America. [DOI: 10.1121/1.3598457];2011
Embodied conversational agents (ECAs) are designed to provide natural and intuitive communication with a human user. One major current topic in agent design consequently is to enhance their believability often by incorporating internal models of emotions or motivations. As psychological theories often lack the necessary details for direct implementation many agent modelers currently rely on models that are rather marginal in current psychological research or models that are created ad hoc with little theoretical and empirical foundation. The goal of this article is both to raise psychologists' awareness of the central challenges in the process of creating psychologically believable agents and to recommend existing psychological frameworks to the virtual agentscommunity that seem particularly useful for implementation in ECAs. Special attention is paid to a computationally detailed model of basic social motives that seems particularly useful for implementation: the Zurich model of social motivation.;2011
Emotion is a research area that has received much attention during the last 10 years both in the context of speech synthesis image understanding as well as in automatic speech recognition interactive dialogues systems and wearable computing. There are promising studies on the emotional behaviour of people mainly based on human observations. Only a few are based on automatic machine detection due to the lack of Information Technology and Engineering (ITE) techniques that can make available a deeper and large-scale noninvasive analysis and evaluation of people's emotional behaviour and provide tools and support for helping them to overcome social barriers. The present paper reports a study for extracting and associating emotional meta-features to support the development of emotionally rich man-machine interfaces (interactive dialogue systems and intelligent avatars).;2011
For many forms of e-learning environments the system's behavior can be viewed as a sequential decision process wherein at each discrete step the system is responsible for selecting the next action to take. Pedagogical strategies are policies to decide the next system action when there are multiple ones available. In this project we present a Reinforcement Learning (RL) approach for inducing effective pedagogical strategies and empirical evaluations of the induced strategies. This paper addresses the technical challenges in applying RL to Cordillera a Natural Language Tutoring System teaching students introductory college physics. The algorithm chosen for this project is a model-based RL approach Policy Iteration and the training corpus for the RL approach is an exploratory corpus which was collected by letting the system make random decisions when interacting with real students. Overall our results show that by using a rather small training corpus the RL-induced strategies indeed measurably improved the effectiveness of Cordillera in that the RL-induced policies improved students' learning gains significantly.;2011
Human-robot interaction (HRI)(1) is one of the main fields in the study and research of robotics. Within this field dialogue systems and interaction by voice play an important role. When speaking about human-robot natural dialogue we assume that the robot has the capability to accurately recognize what the human wants to transmit verbally and even its semantic meaning but this is not always achieved. In this article we describe the steps and requirements that we went through in order to endow the personal social robot Maggie developed at the University Carlos III of Madrid with the capability of understanding the natural language spoken by any human. We have analyzed the different possibilities offered by current software/hardware alternatives by testing them in real environments. We have obtained accurate data related to the speech recognition capabilities in different environments using the most modern audio acquisition systems and analyzing not so typical parameters such as user age gender intonation volume and language. Finally we propose a new model to classify recognition results as accepted or rejected based on a second automatic speech recognition (ASR) opinion. This new approach takes into account the precalculated success rate in noise intervals for each recognition framework decreasing the rate of false positives and false negatives.;2011
If a spoken dialog system can respond to a user as naturally as a human the interaction will appear smoother. In this research we aim to develop a spoken dialog system that emulates human behavior in a dialog. The proposed system makes use of a decision tree to generate responses at the appropriate times. These responses include 'aizuchi' (back-channel) 'repetition' 'collaborative completion' etc. At each time interval the decision tree generates the response timing features referring to the pitch and energy contours recognition hypotheses and the preparation status of the response generator. A subjective evaluation shows that there is a high degree of naturalness in the timing of ordinary responses and aizuchi and that the spoken dialog system exhibits user-friendly behavior. The recorded voice system was preferred to a text-to-speech system (synthesized speech) and almost all subjects felt familiarity with the aizuchi. (C) 2010 Institute of Electrical Engineers of Japan. Published by John Wiley & Sons Inc.;2011
In spoken dialog systems information must be presented sequentially making it difficult to quickly browse through a large number of options. Recent studies have shown that user satisfaction is negatively correlated with dialog duration suggesting that systems should be designed to maximize the efficiency of the interactions. Analysis of the logs of 2000 dialogs between users and nine different dialog systems reveals that a large percentage of the time is spent on the information presentation phase thus there is potentially a large pay-off to be gained from optimizing information presentation in spoken dialog systems. This article proposes a method that improves the efficiency of coping with large numbers of diverse options by selecting options and then structuring them based on a model of the user's preferences. This enables the dialog system to automatically determine trade-offs between alternative options that are relevant to the user and present these trade-offs explicitly. Multiple attractive options are thereby structured such that the user can gradually refine her request to find the optimal trade-off. To evaluate and challenge our approach we conducted a series of experiments that test the effectiveness of the proposed strategy. Experimental results show that basing the content structuring and content selection process on a user model increases the efficiency and effectiveness of the user's interaction. Users complete their tasks more successfully and more quickly. Furthermore user surveys revealed that participants found that the user-model based system presents complex trade-offs understandably and increases overall user satisfaction. The experiments also indicate that presenting users with a brief overview of options that do not fit their requirements significantly improves the user's overview of available options also making them feel more confident in having been presented with all relevant options.;2011
In this paper we propose a method for predicting the user mental state for the development of more efficient and usable spoken dialogue systems. This prediction carried out for each user turn in the dialogue makes it possible to adapt the system dynamically to the user needs. The mental state is built on the basis of the emotional state of the user and their intention and is recognized by means of a module conceived as an intermediate phase between natural language understanding and the dialogue management in the architecture of the systems. We have implemented the method in the UAH system for which the evaluation results with both simulated and real users show that taking into account the user's mental state improves system performance as well as its perceived quality.;2011
In this review of Stephen Cowley's special issue of Pragmatics & Cognition [Cowley S.J. 2009. Distributed language and dynamics. Pragmatics & Cognition 17 (3) 495-508] we present an overview of the extensive overlap between the distributed language approach and the development of artificial dialogue systems. After presenting a brief summary of each of the articles in the Distributed language special issue of Pragmatics & Cognition we will discuss how this new approach could contribute to existing artificial models of language and the production of effective human-computer conversational interactions. In doing so we will briefly highlight the mutual advantages of an interdisciplinary program of research one that could unify the varied strands of distributed language and contribute to current Artificial Intelligence research programs. (C) 2010 Elsevier Ltd. All rights reserved.;2011
Intelligent agent-based assistants are systems that try to simplify peoples work based on computers. Recent research on intelligent assistance has presented significant results in several and different situations. Building such a system is a difficult task that requires expertise in numerous artificial intelligence and engineering disciplines. A key point in this kind of system is knowledge handling. The use of ontologies for representing domain knowledge and for supporting reasoning is becoming wide-spread in many areas including intelligent assistance. In this paper we present how ontologies can be used to support intelligent assistance in a multi-agent system context. We show how ontologies may be spread over the multi-agent system architecture highlighting their role controlling user interaction and service description. We present in detail an ontology-based conversational interface for personal assistants showing how to design an ontology for semantic interpretation and how the interpretation process uses it for semantic analysis. We also present how ontologies are used to describe decentralized services based on a multi-agent architecture.;2011
Modeling interaction with robots raises new and different challenges for dialogue modeling than traditional dialogue modeling with less-embodied machines. We present four case studies of implementing a typical human-robot interaction (HRI) scenario with different state-of-the-art dialogue frameworks in order to identify challenges and pitfalls specific to HRI and potential solutions. The results are discussed with a special focus on the interplay between dialogue and task modeling on robots.;2011
Multimodal conversational spoken dialogues using physical and virtual agents provide a potential interface to motivate and support users in the domain of health and fitness. This paper describes how such multimodal conversational Companions can be implemented to support their owners in various pervasive and mobile settings. We present concrete system architectures virtual physical and mobile multimodal interfaces and interaction management techniques for such Companions. In particular how knowledge representation and separation of low-level interaction modelling from high-level reasoning at the domain level makes it possible to implement distributed but still coherent interaction with Companions. The distribution is enabled by using a dialogue plan to communicate information from domain level planner to dialogue management and from there to a separate mobile interface. The model enables each part of the system to handle the same information from its own perspective without containing overlapping logic and makes it possible to separate task-specific and conversational dialogue management from each other. In addition to technical descriptions results from the first evaluations of the Companions interfaces are presented. (C) 2010 Elsevier Ltd. All rights reserved.;2011
Natural Language Processing (NLP) is an integral part of a conversation and by proxy an integral part of a chatterbot. Building a complete vocabulary for a chatterbot is a prohibitively time and effort intensive endeavor and thus makes a learning chatterbot a much more efficient alternative. Learning can be performed from many facets including individual words to phrases and concepts. From the perspective of words the grammatical parts of speech become important since they allow meaning and structure to be derived from a sentence. Verbs tend to be unique since they have different forms namely participles and tenses. As such we present an algorithm to derive the base verb from any participle or tense.;2011
One of the first steps in building a spoken language understanding (SLU) module for dialogue systems is the extraction of flat concepts out of a given word sequence usually provided by an automatic speech recognition (ASR) system. In this paper six different modeling approaches are investigated to tackle the task of concept tagging. These methods include classical well-known generative and discriminative methods like Finite State Transducers (FSTs) Statistical Machine Translation (SMT) Maximum Entropy Markov Models (MEMMs) or Support Vector Machines (SVMs) as well as techniques recently applied to natural language processing such as Conditional Random Fields (CRFs) or Dynamic Bayesian Networks (DBNs). Following a detailed description of the models experimental and comparative results are presented on three corpora in different languages and with different complexity. The French MEDIA corpus has already been exploited during an evaluation campaign and so a direct comparison with existing benchmarks is possible. Recently collected Italian and Polish corpora are used to test the robustness and portability of the modeling approaches. For all tasks manual transcriptions as well as ASR inputs are considered. Additionally to single systems methods for system combination are investigated. The best performing model on all tasks is based on conditional random fields. On the MEDIA evaluation corpus a concept error rate of 12.6% could be achieved. Here additionally to attribute names attribute values have been extracted using a combination of a rule-based and a statistical approach. Applying system combination using weighted ROVER with all six systems the concept error rate (CER) drops to 12.0%.;2011
Partially observable Markov decision processes (POMDPs) have received significant interest in research on spoken dialogue systems due to among many benefits its ability to naturally model the dialogue strategy selection problem under unreliable automated speech recognition. However the POMDP approaches are essentially model-based and as a result the dialogue strategy computed from POMDP is still subject to the correctness of the model. In this paper we extend some of the previous MDP user models to POMDPs and evaluate the effects of user models on the dialogue strategy computed from POMDPs. We experimentally show that the strategies computed from POMDPs perform better than those from MDPs and the strategies computed from poor user models fail severely when tested on different user models. This paper further investigates the evaluation methods for dialogue strategies and proposes a method based on the bias-variance analysis for reliably estimating the dialogue performance.;2011
People in dialog use a rich set of nonverbal behaviors including variations in the prosody of their utterances. Such behaviors often emotion-related call for appropriate responses but today's spoken dialog systems lack the ability to do this. Recent work has shown how to recognize user emotions from prosody and how to express system-side emotions with prosody but demonstrations of how to combine these functions to improve the user experience have been lacking. Working with a corpus of conversations with students about graduate school we analyzed the emotional states of the interlocutors utterance-by-utterance using three dimensions: activation evaluation and power. We found that the emotional coloring of the speaker's utterance could be largely predicted from the emotion shown by her interlocutor in the immediately previous utterance. This finding enabled us to build Gracie the first spoken dialog system that recognizes a user's emotional state from his or her speech and gives a response with appropriate emotional coloring. Evaluation with 36 subjects showed that they felt significantly more rapport with Gracie than with either of two controls. This shows that dialog systems can tap into this important level of interpersonal interaction using today's technology. (C) 2010 Elsevier B.V. All rights reserved.;2011
Purpose: The aim of this study was to investigate if and how an artificially intelligent chat agent (chatbot) that answers questions about sex drugs and alcohol is used and evaluated by adolescents especially in comparison with information lines and search engines. Methods: A sample of 929 adolescents (64% girls mean age = 15) varying in urbanization level and educational level participated in this study. Use of the chatbot was objectively tracked through server registrations (e. g. frequency and duration of conversations with the chatbot the number and topics of queries) and a web-based questionnaire was used to evaluate the chatbot (e. g. the perception of anonymity conciseness ease of use fun quality and quantity of information and speed) and to compare it with information lines and search engines. Results: The chatbot reached high school attendees in general and not only adolescents with previous experience related to sex drugs or alcohol this is promising from an informed decision-making point of view. Frequency (M = 11) and duration of conversations (3:57 minutes) was high and the chatbot was evaluated positively especially in comparison with information lines and search engines. Conclusion: The use of chatbots within the field of health promotion has a large potential to reach a varied group of adolescents and to provide them with answers to their questions related to sex drugs and alcohol. (C) 2011 Society for Adolescent Health and Medicine. All rights reserved.;2011
Sentence and short-text semantic similarity measures are becoming an important part of many natural language processing tasks such as text summarization and conversational agents. This paper presents SyMSS a new method for computing short-text and sentence semantic similarity. The method is based on the notion that the meaning of a sentence is made up of not only the meanings of its individual words but also the structural way the words are combined. Thus SyMSS captures and combines syntactic and semantic information to compute the semantic similarity of two sentences. Semantic information is obtained from a lexical database. Syntactic information is obtained through a deep parsing process that finds the phrases in each sentence. Wills this information the proposed method measures the semantic similarity between concepts that play the same syntactic role. Psychological plausibility is added to the method by using previous findings about how humans weight different syntactic roles when computing semantic similarity. The results show that SyMSS outperforms state-of-the-art methods in terms of rank correlation with human intuition thus proving the importance of syntactic information in sentence semantic similarity computation. (C) 2011 Elsevier B.V. All rights reserved.;2011
Spoken dialog systems have been a holy grail of computer science since Turing devised his test for intelligence and an icon of science fiction from well before that. Although there are machines you can talk to - interactive voice response (IVR) systems which answer phones voice command systems in cars and the Furby toy come to mind - holding a conversation with a machine spoken or typed is still highly problematic. It seems there is something fundamental we don't understand about the way humans use language. One popular approach is to ignore our ignorance and assume that machines can figure it out for themselves using machine learning or some form of statistical modeling of a corpus of text. Corpus analysis however like archeology attempts to understand human action by looking at what we leave behind. Instead we take a software agents approach and model the language production process. The SERA project is our latest effort looking at what other disciplines can tell us about language use in context. We find that naturally published work focuses on the interesting while the engineering challenge is to capture the essential but often mundane. This paper proposes a narrative approach based on Vygotsky's view of psychology that captures the big picture. The paper finishes with an outline for a tool that merges the functionality of more conventional annotation tools with that of existing scripting environments for conversational agents.;2011
The automatic recognition of user's communicative style within a spoken dialog system framework including the affective aspects has received increased attention in the past few years. For dialog systems it is important to know not only what was said but also how something was communicated so that the system can engage the user in a richer and more natural interaction. This paper addresses the problem of automatically detecting frustration politeness and neutral attitudes from a child's speech communication cues elicited in spontaneous dialog interactions with computer characters. Several information sources such as acoustic lexical and contextual features as well as their combinations are used for this purpose. The study is based on a Wizard-of-Oz dialog corpus of 103 children 7-14 years of age playing a voice activated computer game. Three-way classification experiments as well as pairwise classification between polite vs. others and frustrated vs. others were performed. Experimental results show that lexical information has more discriminative power than acoustic and contextual cues for detection of politeness whereas context and acoustic features perform best for frustration detection. Furthermore the fusion of acoustic lexical and contextual information provided significantly better classification results. Results also showed that classification performance varies with age and gender. Specifically for the politeness detection task higher classification accuracy was achieved for females and 10-11 years-olds compared to males and other age groups respectively. (C) 2010 Elsevier Ltd. All rights reserved.;2011
The development of embodied conversational agents (ECA) as companions brings several challenges for both affective and conversational dialogue. These include challenges in generating appropriate affective responses selecting the overall shape of the dialogue providing prompt system response times and handling interruptions. We present an implementation of such a companion showing the development of individual modules that attempt to address these challenges. Further to resolve resulting conflicts we present encompassing interaction strategies that attempt to balance the competing requirements along with dialogues from our working prototype to illustrate these interaction strategies in operation. Finally we provide the results of an evaluation of the companion using an evaluation methodology created for conversational dialogue and including analysis using appropriateness annotation.;2011
The literature on social agents has put forward a number of requirements that social agents need to fulfill. In this paper we analyze the kinds of reasons and motivations that lie behind the statement of these requirements. In a second part of the paper we look at how one can go about engineering the social agents. We introduce a general language in which to express dialogue rules and some tools that support the development of dialogue systems.;2011
The purpose of this article is to discuss the importance of implementing a life course perspective model that includes a reproductive life plan to improve health outcomes especially in populations at risk for adverse outcomes. A reproductive life plan is a comprehensive strategy that can be incorporated into nursing practice at all levels to improve birth outcomes. Health care providers especially nurses should incorporate reproductive life planning into their daily encounters with patients.;2011
This is an unusual moment in the history of psychology because of landmark advances in digital information technologies computational linguistics and other fields that use the computer to analyze language discourse and behavior. The technologies developed from this interdisciplinary fusion are helping students learn and think in ways that are sensitive to their cognitive and emotional states. Recent projects have developed computer technologies that help us understand the nature of conversational discourse and text comprehension in addition to improving learning. AutoTutor and other systems with conversational agents (i.e. talking heads) help students learn by holding conversations in natural language. One version of AutoTutor is sensitive to the emotions of students in addition to their cognitive states. Coh-Metrix analyzes texts on multiple levels of language and discourse such as text genre cohesion syntax and word characteristics. Coh-Metrix can assist students teachers principals and policymakers when they make decisions on the right text to assign to the right student at the right time. Computers are not perfect conversation partners and comprehenders of text but the current systems are undeniably useful.;2011
This paper argues that some traditional fallacies should be considered as reasonable arguments when used as part of a properly conducted dialog. It is shown that argumentation schemes formal dialog models and profiles of dialog are useful tools for studying properties of defeasible reasoning and fallacies. It is explained how defeasible reasoning of the most common sort can deteriorate into fallacious argumentation in some instances. Conditions are formulated that can be used as normative tools to judge whether a given defeasible argument is fallacious or not. It is shown that three leading violations of proper dialog standards for defeasible reasoning necessary to see how fallacies work are: (a) improper failure to retract a commitment (b) failure of openness to defeat and (c) illicit reversal of burden of proof.;2011
This paper argues that the problems of dialogue management (DM) and Natural Language Generation (NLG) in dialogue systems are closely related and can be fruitfully treated statistically in a joint optimisation framework such as that provided by Reinforcement Learning (RL). We first review recent results and methods in automatic learning of dialogue management strategies for spoken and multimodal dialogue systems and then show how these techniques can also be used for the related problem of Natural Language Generation. This approach promises a number of theoretical and practical benefits such as fine-grained adaptation generalisation and automatic (global) optimisation and we compare it to related work in statistical/trainable NLG. A demonstration of the proposed approach is then developed showing combined DM and NLG policy learning for adaptive information presentation decisions. A joint DM and NLG policy learned in the framework shows a statistically significant 27% relative increase in reward over a baseline policy which is learned in the same way only without the joint optimisation. We thereby show that that NLG problems can be approached statistically in combination with dialogue management decisions and we show how to jointly optimise NLG and DM using Reinforcement Learning. (C) 2010 Elsevier Ltd. All rights reserved.;2011
This paper builds a dialectical system of explanation with speech act rules that define the kinds of moves allowed like requesting and offering an explanation. Pre and post-condition rules for the speech acts determine when a particular speech act can be put forward as a move in the dialogue and what type of move or moves must follow it. A successful explanation has been achieved when there has been a transfer of understanding from the party giving the explanation to the party asking for it. The dialogue has an opening stage an explanation stage and a closing stage. Whether a transfer of understanding has taken place is tested by a dialectical shift to an examination dialogue.;2011
This paper describes an initial prototype of the Companions project (www.companions-project.org): the Senior Companion (SC) designed to be a platform to display novel approaches to: (1) The use of Information Extraction (IE) techniques to extract the content of incoming dialogue utterances after an ASR phase. (2) The conversion of the input to RDF form to allow the generation of new facts from existing ones under the control of a Dialogue Manager (DM) that also has access to stored knowledge and knowledge accessed in real time from the web all in RDF form. (3) A DM expressed as a stack and network virtual machine that models mixed initiative in dialogue control. (4) A tuned dialogue act detector based on corpus evidence. The prototype platform was evaluated and we describe this it is also designed to support more extensive forms of emotion detection carried by both speech and lexical content as well as extended forms of machine learning. We describe preliminary studies and results for these in particular a novel approach to enabling reinforcement learning for open dialogue systems through the detection of emotion in the speech signal and its deployment as a form of a learned DM at a higher level than the DM virtual machine and able to direct the SC's responses to a more emotionally appropriate part of its repertoire. (C) 2010 Elsevier Ltd. All rights reserved.;2011
This paper presents an intelligence model for conversational service robots. It employs modules called experts each of which is specialized to execute certain kinds of tasks such as performing physical behaviors and engaging in dialogues. Some of the experts take charge in understanding human utterances and deciding robot utterances or actions. The model enables switching and canceling tasks based on recognized human intentions as well as parallel execution of several tasks. This model specifies the interface that an expert must have and any kind of expert can be employed if it conforms to the interface. This feature makes the model extensible. (C) 2010 Elsevier B.V. All rights reserved.;2011
This paper proposes a novel user intention simulation method which is data-driven but can integrate diverse user discourse knowledge to simulate various types of user behaviors. A method of data-driven user intention modeling based on logistic regression is introduced in the Markov logic framework. Human dialog knowledge is designed into two layers domain and discourse knowledge and integrated with the data-driven model in generation time. Three types of user knowledge i.e. cooperative corrective and self-directing are designed and integrated to generate behaviors of corresponding user-types. In experiments to investigate the patterns of simulated users the approach successfully generated cooperative corrective and self-directing user intention patterns. (C) 2010 Elsevier Ltd. All rights reserved.;2011
This paper proposes a technique to enhance emotion detection in spoken dialogue systems by means of two modules that combine different information sources. The first one called Fusion-0 combines emotion predictions generated by a set of classifiers that deal with different kinds of information about each sentence uttered by the user. To do this the module employs several methods for information fusion that produce other predictions about the emotional state of the user. The predictions are the input to the second information fusion module called Fusion-1 where they are combined to deduce the emotional state of the user. Fusion-0 represents a method employed in previous studies to enhance classification rates whereas Fusion-1 represents the novelty of the technique which is the combination of emotion predictions generated by Fusion-0. One advantage of the technique is that it can be applied as a posterior processing stage to any other methods that combine information from different information sources at the decision level. This is so because the technique works on the predictions (outputs) of the methods without interfering in the procedure used to obtain these predictions. Another advantage is that the technique can be implemented as a modular architecture which facilitates the setting up within a spoken dialogue system as well as the deduction of the emotional state of the user in real time. Experiments have been carried out considering classifiers to deal with prosodic acoustic lexical and dialogue acts information and three methods to combine information: multiplication of probabilities average of probabilities and unweighted vote. The results show that the technique enhances the classification rates of the standard fusion by 2.27% and 3.38% absolute in experiments carried out considering two and three emotion categories respectively. (C) 2011 Elsevier B.V. All rights reserved.;2011
This study designed a chatbot system Confucius as a MSN virtual learning companion to examine how specific application design variables within educational software affect the learning process of subjects as defined by the cognitive continuum of field-dependent and field-independent learners. 104 college students participated in a 12 week Microsoft certification course that used Confucius as an adjunct to classroom instruction. The study considered to what extent the two distinct learning modes offered by Confucius would affect the learning gains of two distinct cognitive styles. Each of the two learning modes available within the Confucius was designed to conform to the specific requirements of field-independent or field-dependent learners. The results of this study reveal that a discussion mode offers far greater benefit to field-dependent learners than to those whose cognitive style is field-independent. Conversely a lecture mode is substantially more beneficial to field-independent learners than to field-dependent learners.;2011
Tutorial Dialog Systems that employ Conversational Agents (CAs) to deliver instructional content to learners in one-on-one tutoring settings have been shown to be effective in multiple learning domains by multiple research groups. Our work focuses on extending this successful learning technology to collaborative learning settings involving two or more learners interacting with one or more agents. Experience from extending existing techniques for developing conversational agents into multiple-learner settings highlights two underlying assumptions from the one-learner setting that do not generalize well to the multiuser setting and thus cause difficulties. These assumptions include what we refer to as the near-even participation assumption and the known addressee assumption. A new software architecture called Basilica that allows us to address and overcome these limitations is a major contribution of this article. The Basilica architecture adopts an object-oriented approach to represent agents as a network composed of what we refer to as behavioral components because they enable the agents to engage in rich conversational behaviors. Additionally we describe three specific conversational agents built using Basilica in order to illustrate the desirable properties of this new architecture.;2011
We address the problem of inferring a speaker's level of certainty based on prosodic information in the speech signal which has application in speech-based dialogue systems. We show that using phrase-level prosodic features centered around the phrases causing uncertainty in addition to utterance-level prosodic features improves our model's level of certainty classification. In addition our models can be used to predict which phrase a person is uncertain about. These results rely on a novel method for eliciting utterances of varying levels of certainty that allows us to compare the utility of contextually-based feature sets. We elicit level of certainty ratings from both the speakers themselves and a panel of listeners finding that there is often a mismatch between speakers' internal states and their perceived states and highlighting the importance of this distinction.;2011
We describe the design and evaluation of two different dynamic student uncertainty adaptations in wizarded versions of a spoken dialogue tutoring system. The two adaptive systems adapt to each student turn based on its uncertainty after an unseen human wizard performs speech recognition and natural language understanding and annotates the turn for uncertainty. The design of our two uncertainty adaptations is based on a hypothesis in the literature that uncertainty is an opportunity to learn both adaptations use additional substantive content to respond to uncertain turns but the two adaptations vary in the complexity of these responses. The evaluation of our two uncertainty adaptations represents one of the first controlled experiments to investigate whether substantive dynamic responses to student affect can significantly improve performance in computer tutors. To our knowledge we are the first study to show that dynamically responding to uncertainty can significantly improve learning during computer tutoring. We also highlight our ongoing evaluation of our uncertainty-adaptive systems with respect to other important performance metrics and we discuss how our corpus can be used by the wider computer speech and language community as a linguistic resource supporting further research on effective affect-adaptive spoken dialogue systems in general. (C) 2009 Elsevier Ltd. All rights reserved.;2011
We evaluate the performance of a spoken dialogue system that provides substantive dynamic responses to automatically detected user affective states. We then present a detailed system error analysis that reveals challenges for real-time affect detection and adaptation. This research is situated in the tutoring domain where the user is a student and the spoken dialogue system is a tutor. Our adaptive system detects uncertainty in each student turn via a model that combines a machine learning approach with hedging phrase heuristics the learned model uses acoustic-prosodic and lexical features extracted from the speech signal as well as dialogue features. The adaptive system varies its content based on the automatic uncertainty and correctness labels for each turn. Our controlled experimental evaluation shows that the adaptive system yields higher global performance than two non-adaptive control systems but the difference is only significant for a subset of students. Our system error analysis indicates that noisy affect labeling is a major performance bottleneck yielding fewer than expected adaptations thus lower than expected performance. However the percentage of received adaptation correlates with higher performance over all students. Moreover when uncertainty is accurately recognized and adapted to local performance is significantly improved. (C) 2011 Elsevier B.V. All rights reserved.;2011
We have created an automated kiosk that uses embodied intelligent agents to interview individuals and detect changes in arousal behavior and cognitive effort by using psychophysiological information systems. In this paper we describe the system and propose a unique class of intelligent agents which are described as Special Purpose Embodied Conversational Intelligence with Environmental Sensors (SPECIES). SPECIES agents use heterogeneous sensors to detect human physiology and behavior during interactions and they affect their environment by influencing human behavior using various embodied states (i.e. gender and demeanor) messages and recommendations. Based on the SPECIES paradigm we present three studies that evaluate different portions of the model and these studies are used as foundational research for the development of the automated kiosk. The first study evaluates human computer interaction and how SPECIES agents can change perceptions of information systems by varying appearance and demeanor. Instantiations that had the agents embodied as males were perceived as more powerful while female embodied agents were perceived as more likable. Similarly smiling agents were perceived as more likable than neutral demeanor agents. The second study demonstrated that a single sensor measuring vocal pitch provides SPECIES with environmental awareness of human stress and deception. The final study ties the first two studies together and demonstrates an avatar-based kiosk that asks questions and measures the responses using vocalic measurements.;2011
We investigated in two picture-word-interference experiments whether there is evidence for composition during compound production (Experiment 1). In Experiment 2 we tried to determine the level at which composition takes place. In Experiment 1 shared morphemes between distractor and target (HANDTASCHE handbag) sped up naming regardless of category membership: semantically opaque (Plaudertasche chatterbox) and semantically transparent distractors (Reisetasche travelling bag) facilitated picture naming to a comparable degree. In Experiment 2 targets (BROTMESSER bread knife) were combined with a simple word distractor (Kuchen cake) categorically related to a target compound constituent but not related to the compound as a whole. This target was further paired with a categorically related compound distractor (Kochloffel wooden spoon). The simple word distractor was also paired with a categorically related compound constituent (BROT bread). Whenever distractor (e. g. Kochloffel Kuchen) and target (BROTMESSER BROT respectively) were categorically related semantic inhibition was observed. Distractors (e. g. Kuchen) related to only one compound constituent did not affect compound production. Taken together our results indicate that during compound production a single lemma node is activated and that morphological composition takes place at the form level of representation. Current lexical selection mechanisms in language production models are not supported by these data.;2011
When developing human computer conversational systems the complex co-acting processes of human human dialogue present a significant challenge. Para-linguistic features establish rapport between individuals and direct the conversation in directions that cannot be captured by semantic analysis alone. This paper attempts to address part of this challenge by considering the role of para-linguistic features in establishing and manipulating social dominance. We propose that social dominance can be understood as an interaction affordance revealing action potentials for each signalling participant and can be detected as a feature of rapport not of the individual. An analysis of F0 and long-term averaged spectra (LTAS) correlation values for conversational pairs reveals a high degree of accommodation. The nature of this accommodation demonstrates that others will adjust their speech to match the current dominant individual. We conclude by exploring the implications of these results on the role of rapport and outline potential advances for the detection of emotion in speech by encompassing the entirety of pleasure-arousal-dominance emotional space. (C) 2011 Elsevier B.V. All rights reserved.;2011
While different user simulations are built to assist dialog system development there is an increasing need to quickly assess the quality of the user simulations reliably. Previous studies have proposed several automatic evaluation measures for this purpose. However the validity of these evaluation measures has not been fully proven. We present an assessment study in which human judgments are collected on user simulation qualities as the gold standard to validate automatic evaluation measures. We show that a ranking model can be built using the automatic measures to predict the rankings of the simulations in the same order as the human judgments. We further show that the ranking model can be improved by using a simple feature that utilizes time-series analysis.;2011
While mobile phones have found broad application in bringing health financial and other services to the developing world usability remains a major hurdle for novice and low-literacy populations. In this article we take two steps to evaluate and improve the usability of mobile interfaces for such users. First we offer an ethnographic study of the usability barriers facing 90 low-literacy subjects in India Kenya the Philippines and South Africa. Then via two studies involving over 70 subjects in India we quantitatively compare the usability of different points in the mobile design space. In addition to text interfaces such as electronic forms SMS and USSD we consider three text-free interfaces: a spoken dialog system a graphical interface and a live operator. Our results confirm that textual interfaces are unusable by first-time low-literacy users and error prone for literate but novice users. In the context of healthcare we find that a live operator is up to ten times more accurate than text-based interfaces and can also be cost effective in countries such as India. In the context of mobile banking we find that task completion is highest with a graphical interface but those who understand the spoken dialog system can use it more quickly due to their comfort and familiarity with speech. We synthesize our findings into a set of design recommendations.;2011
A dialog system is an intelligent program that helps users easily access information stored in a knowledge base by formulating requests in their natural language. A dialog system needs an intention prediction module for use as a preprocessor to reduce the search space of an automatic speech recognizer. To satisfy these needs we propose a statistical model to predict speakers' intentions. The proposed model represents a dialog history with various levels of linguistic features. The proposed model predicts the user's next intention by giving the linguistic features as inputs to a statistical machine learning model. In experiments conducted in a schedule management domain the proposed model showed a higher average precision than the previous model. (C) 2012 Elsevier B.V. All rights reserved.;2012
A high-level dialogue system involves symbolic reasoning and deep understanding of user input and its object is to handle complex dialogue phenomena such as inference and negotiation. However it is difficult for high-level dialogue techniques to be extended toward a practical dialogue system that must generate effective responses in a real environment because the high-level dialogue techniques are based on only a narrow band of knowledge and a complicated model. This paper proposes a new dialogue model based on plan-recognition model that is one of high-level techniques. We simplify the plan-recognition model which includes well-defined recipes and inference rules to be applied to a practical dialogue system. In addition we use a multi-level inference schema that employs a discourse stack and a confirmation strategy for effectively recognizing the user's deep intention. As a result the proposed dialogue system is successfully embedded into a multi-modal interaction system for human-robot interaction.;2012
A novel approach for robust dialogue act detection in a spoken dialogue system is proposed. Shallow representation named partial sentence trees are employed to represent automatic speech recognition outputs. Parsing results of partial sentences can be decomposed into derivation rules which turn out to be salient features for dialogue act detection. Data-driven dialogue acts are learned via an unsupervised learning algorithm called spectral clustering in a vector space whose axes correspond to derivation rules. The proposed method is evaluated in a Mandarin spoken dialogue system for tourist-information services. Combined with information obtained from the automatic speech recognition module and from a Markov model on dialogue act sequence the proposed method achieves a detection accuracy of 85.1% which is significantly better than the baseline performance of 62.3% using a na < ve Bayes classifier. Furthermore the average number of turns per dialogue session also decreases significantly with the improved detection accuracy.;2012
A speech-act is a linguistic action intended by a speaker. Speech-act classification is essential to the generation and understanding of utterances within any natural language dialogue system as the speech act of an utterance is closely tied to a user intention. Lexical information provides the most crucial clue for speech-act classification and contextual information offers additional complementary clues. In this study we concentrate on how to effectively utilize contextual information for speech-act classification. Our proposed model exploits adjacency pairs and a discourse stack to apply contextual information to speech-act classification. Experimental results show that the proposed model yields significant improvements in comparison with other speech-act classification models as well as a baseline model which does not utilize contextual information.;2012
Although there have been enormous investments into English education all around the world not many differences have been made to change the English instruction style. Considering the shortcomings for the current teaching-learning methodology we have been investigating advanced computer-assisted language learning (CALL) systems. This paper aims at summarizing a set of POSTECH approaches including theories technologies systems and field studies and providing relevant pointers. On top of the state-of-the-art technologies of spoken dialog system a variety of adaptations have been applied to overcome some problems caused by numerous errors and variations naturally produced by non-native speakers. Furthermore a number of methods have been developed for generating educational feedback that help learners develop to be proficient. Integrating these efforts resulted in intelligent educational robots - Mero and Engkey - and virtual 3D language learning games Pomy. To verify the effects of our approaches on students' communicative abilities we have conducted a field study at an elementary school in Korea. The results showed that our CALL approaches can be enjoyable and fruitful activities for students. Although the results of this study bring us a step closer to understanding computer-based education more studies are needed to consolidate the findings.;2012
As the ubiquitous access to vast and remote information sources from portable devices becomes commonplace the need from users to perform searches in keyboard-unfriendly situations grows substantially thus triggering the increased demand of voice search sessions. This paper proposes a methodology that addresses different dimensions of scalability of mixed-initiative voice search in automatic spoken dialog systems. The strategy is based on splitting the complexity of the fully-constrained grammar (one that tightly covers the entire hypothesis space) into a fixed/low complexity phonotactic grammar followed by an index mechanism that dynamically assembles a second-pass grammar that consists of only a handful of hypotheses. The experimental analysis demonstrates different dimensions of scalability achieved by the proposed method using actual WHITEPAGEs-residential data. (C) 2011 Elsevier B.V. All rights reserved.;2012
Background: Information technology can help individuals to change their health behaviors. This is due to its potential for dynamic and unbiased information processing enabling users to monitor their own progress and be informed about risks and opportunities specific to evolving contexts and motivations. However in many behavior change interventions information technology is underused by treating it as a passive medium focused on efficient transmission of information and a positive user experience. Objective: To conduct an interdisciplinary literature review to determine the extent to which the active technological capabilities of dynamic and adaptive information processing are being applied in behavior change interventions and to identify their role in these interventions. Methods: We defined key categories of active technology such as semantic information processing pattern recognition and adaptation. We conducted the literature search using keywords derived from the categories and included studies that indicated a significant role for an active technology in health-related behavior change. In the data extraction we looked specifically for the following technology roles: (1) dynamic adaptive tailoring of messages depending on context (2) interactive education (3) support for client self-monitoring of behavior change progress and (4) novel ways in which interventions are grounded in behavior change theories using active technology. Results: The search returned 228 potentially relevant articles of which 41 satisfied the inclusion criteria. We found that significant research was focused on dialog systems embodied conversational agents and activity recognition. The most covered health topic was physical activity. The majority of the studies were early-stage research. Only 6 were randomized controlled trials of which 4 were positive for behavior change and 5 were positive for acceptability. Empathy and relational behavior were significant research themes in dialog systems for behavior change with many pilot studies showing a preference for those features. We found few studies that focused on interactive education (3 studies) and self-monitoring (2 studies). Some recent research is emerging in dynamic tailoring (15 studies) and theoretically grounded ontologies for automated semantic processing (4 studies). Conclusions: The potential capabilities and risks of active assistance technologies are not being fully explored in most current behavior change research. Designers of health behavior interventions need to consider the relevant informatics methods and algorithms more fully. There is also a need to analyze the possibilities that can result from interaction between different technology components. This requires deep interdisciplinary collaboration for example between health psychology computer science health informatics cognitive science and educational methodology.;2012
Conversational agents are attributed humanlike characteristics: in particular they are often assumed to have a gender. There is evidence that gender sets up expectations that have an impact on user experiences with agents. The objective of this paper is to explore gender affordances of conversational agents. Our examination takes a holistic approach to the analysis of the application of gender stereotypes to nine chatterbots: six embodied (three male and three female) two disembodied (male and female) and a robot embodiment. Building on social psychology research we test the persistence of gender stereotypes in the selection of conversation topics and in the elicitation of disinhibition and verbal abuse. Our study is based on quantitative textual analysis of interaction logs. A dictionary of English sexual slang and derogatory terms was developed for this study. Results show that gender stereotypes tend to affect interaction more at the relational (style) level then at the referential (content) level of conversation. People attribute negative stereotypes to female-presenting chatterbots more often than they do to male-presenting chatterbots and female-presenting chatterbots are more often the objects of implicit and explicit sexual attention and swear words. We conclude by calling for a more informed analysis of user interactions that considers the full range of user interactions. (C) 2012 British Informatics Society Limited. All rights reserved.;2012
Convincing conversational agents require a coherent set of behavioral responses that can be interpreted by a human observer as indicative of a personality. This paper discusses the continued development and subsequent evaluation of virtual agents based on sound psychological principles. We use Eysenck's theoretical basis to explain aspects of the characterization of our agents and we describe an architecture where personality affects the agent's global behavior quality as well as their back-channel productions. Drawing on psychological research we evaluate perception of our agents' personalities and credibility by human viewers (N = 187). Our results suggest that we succeeded in validating theoretically grounded indicators of personality in our virtual agents and that it is feasible to place our characters on Eysenck's scales. A key finding is that the presence of behavioral characteristics reinforces the prescribed personality profiles that are already emerging from the still images. Our long-term goal is to enhance agents' ability to sustain realistic interaction with human users and we discuss how this preliminary work may be further developed to include more systematic variation of Eysenck's personality scales.;2012
Creating interactive applications with multiple virtual characters comes along with many challenges that are related to different areas of expertise. The definition of context-sensitive interactive behavior requires expert programmers and often results in hard-to-maintain code. To tackle these challenges we suggest a visual authoring approach for virtual character applications and present a revised version of our SceneMaker tool. In SceneMaker a separation of content and logic is enforced. In the revised version the Visual SceneMaker we introduce concurrency and specific history structures as key concepts to facilitate (1) clearly structured interactive behavior definition (2) multiple character modeling and (3) extensions to existing applications. The new integrated developer environment allows sceneflow visualization and runtime modifications to support the development of interactive character applications in a rapid prototyping style. Finally we present the result of a user study which evaluates usability and the key concepts of the authoring tool.;2012
Current development platforms for designing spoken dialog services feature different kinds of strategies to help designers build test and deploy their applications. In general these platforms are made up of several assistants that handle the different design stages (e.g. definition of the dialog flow prompt and grammar definition database connection or to debug and test the running of the application). In spite of all the advances in this area in general the process of designing spoken-based dialog services is a time consuming task that needs to be accelerated. In this paper we describe a complete development platform that reduces the design time by using different types of acceleration strategies based on using information from the data model structure and database contents as well as cumulative information obtained throughout the successive steps in the design. Thanks to these accelerations the interaction with the platform is simplified and the design is reduced in most cases to simple confirmations to the proposals that the platform automatically provides at each stage. Different kinds of proposals are available to complete the application flow such as the possibility of selecting which information slots should be requested to the user together predefined templates for common dialogs the most probable actions that make up each state defined in the flow different solutions to solve specific speech-modality problems such as the presentation of the lists of retrieved results after querying the backend database. The platform also includes accelerations for creating speech grammars and prompts and the SQL queries for accessing the database at runtime. Finally we will describe the setup and results obtained in a simultaneous summative subjective and objective evaluations with different designers used to test the usability of the proposed accelerations as well as their contribution to reducing the design time and interaction. (C) 2011 Elsevier Ltd. All rights reserved.;2012
During human communication every spoken message is intrinsically modulated within different verbal and nonverbal cues that are externalized through various aspects of speech and facial gestures. These communication channels are strongly interrelated which suggests that generating human-like behavior requires a careful study of their relationship. Neglecting the mutual influence of different communicative channels in the modeling of natural behavior for a conversational agent may result in unrealistic behaviors that can affect the intended visual perception of the animation. This relationship exists both between audiovisual information and within different visual aspects. This paper explores the idea of using joint models to preserve the coupling not only between speech and facial expression but also within facial gestures. As a case study the paper focuses on building a speech-driven facial animation framework to generate natural head and eyebrow motions. We propose three dynamic Bayesian networks (DBNs) which make different assumptions about the coupling between speech eyebrow and head motion. Synthesized animations are produced based on the MPEG-4 facial animation standard using the audiovisual IEMOCAP database. The experimental results based on perceptual evaluations reveal that the proposed joint models (speech/eyebrow/head) outperform audiovisual models that are separately trained (speech/head and speech/eyebrow).;2012
Educators in medicine psychology and the military want to provide their students with interpersonal skills practice. Virtual humans offer structured learning of interview skills can facilitate learning about unusual conditions and are always available. However the creation of virtual humans with the ability to understand and respond to natural language requires costly engineering by conversation knowledge engineers (generally computer scientists) and incurs logistical cost for acquiring domain knowledge from domain experts (educators). We address these problems using a novel crowdsourcing method entitled Human-centered Distributed Conversational Modeling. This method facilitates collaborative development of virtual humans by two groups of end-users: domain experts (educators) and domain novices (students). We implemented this method in a web-based authoring tool called Virtual People Factory. Using Virtual People Factory medical and pharmacy educators are now creating natural language virtual patient interactions on their own. This article presents the theoretical background for Human-centered Distributed Conversational Modeling the implementation of the Virtual People Factory authoring tool and five case studies showing that Human-centered Distributed Conversational Modeling has addressed the logistical cost for acquiring knowledge. Published by Elsevier Ltd.;2012
Empathetic behavior has been suggested to be one effective way for Embodied Conversational Agents (ECAs) to provide feedback to learners' emotions. An issue that has been raised is the effective integration of parallel and reactive empathy. The aim of this study is to examine the impact of ECAs' emotional facial and tone of voice expressions combined with empathetic verbal behavior when displayed as feedback to students' fear sad and happy emotions in the context of a self-assessment test. Three identical female agents were used for this experiment: 1) an ECA performing parallel empathy combined with neutral emotional expressions 2) an ECA performing parallel empathy displaying emotional expressions that were relevant to the emotional state of the student and 3) an ECA performing parallel empathy by displaying relevant emotional expressions followed by emotional expressions of reactive empathy with the goal of altering the student's emotional state. Results indicate that an agent performing parallel empathy displaying emotional expressions relevant to the emotional state of the student may cause this emotion to persist. Moreover the agent performing parallel and then reactive empathy appeared to be effective in altering an emotional state of fear to a neutral one.;2012
In dialogue systems it is important to label the dialogue turns with dialogue-related meaning. Each turn is usually divided into segments and these segments are labelled with dialogue acts (DAs). A DA is a representation of the functional role of the segment. Each segment is labelled with one DA representing its role in the ongoing discourse. The sequence of DAs given a dialogue turn is used by the dialogue manager to understand the turn. Probabilistic models that perform DA labelling can be used on segmented or unsegmented turns. The last option is more likely for a practical dialogue system but it provides poorer results. In that case a hypothesis for the number of segments can be provided to improve the results. We propose some methods to estimate the probability of the number of segments based on the transcription of the turn. The new labelling model includes the estimation of the probability of the number of segments in the turn. We tested this new approach with two different dialogue corpora: SWITCHBOARD and DIHANA. The results show that this inclusion significantly improves the labelling accuracy.;2012
In this paper a Bayesian Networks-based solution for dialogue modelling is presented. This solution is combined with carefully designed contextual information handling strategies. With the purpose of validating these solutions and introducing a spoken dialogue system for controlling a Hi-Fi audio system as the selected prototype a real-user evaluation has been conducted. Two different versions of the prototype are compared. Each version corresponds to a different implementation of the algorithm for the management of the actuation order the algorithm for deciding the proper order to carry out the actions required by the user. The evaluation is carried out in terms of a battery of both subjective and objective metrics collected from speakers interacting with the Hi-Fi audio box through predefined scenarios. Defined metrics have been specifically adapted to measure: first the usefulness and the actual relevance of the proposed solutions and secondly their joint performance through their intelligent combination mainly measured as the level achieved with regard to the user satisfaction. A thorough and comprehensive study of the main differences between both approaches is presented. Two-way analysis of variance (ANOVA) tests are also included to measure the effects of both: the system used and the type of scenario factors simultaneously. Finally the effect of bringing this flexibility robustness and naturalness into our home dialogue system is also analyzed through the results obtained. These results show that the intelligence of our speech interface has been well perceived highlighting its excellent ease of use and its good acceptance by users therefore validating the approached dialogue management solutions and demonstrating that a more natural flexible and robust dialogue is possible thanks to them. (C) 2012 British Informatics Society Limited. All rights reserved.;2012
In this paper we investigate the effect of level of understanding revealed by feedback in the form of clarification requests from a route follower on a route giver's spatial perspective choice in their response in route instruction dialogues. In an experiment varying the level of understanding displayed by route follower clarification requests (the independent variable) route giver perspective switching in response to this feedback is investigated. Three levels of understanding displayed by feedback are investigated: (1) low-level clarification requests indicating that the instruction was not processed (2) semantic-level clarification requests indicating that the spatial direction given in the instruction could not be resolved as the speaker of the clarification request could not interpret which perspective was intended and (3) high-level feedback which indicates that the route giver's instruction was understood but which note an obstacle to following the instruction. Results show that perspective choice which is a conceptual feature of language use is sensitive to perceived level of addressee understanding. We found that route givers consistently switch perspectives in responding to semantic-level clarification requests but not in response to low-level ones and also that switching occurs more for high-level feedback than for low-level feedback. We address how dialogue systems can take advantage of these findings by modelling our results in an Information State model of dialogue presenting update rules for response generation which account for our findings and also update rules which enable generation of the feedback themselves.;2012
In this paper we investigate whether conventional text categorization methods may suffice to infer different verbal intelligence levels. This research goal relies on the hypothesis that the vocabulary that speakers make use of reflects their verbal intelligence levels. Automatic verbal intelligence estimation of users in a spoken language dialog system may be useful when defining an optimal dialog strategy by improving its adaptation capabilities. The work is based on a corpus containing descriptions (i.e. monologs) of a short film by test persons yielding different educational backgrounds and the verbal intelligence scores of the speakers. First a one-way analysis of variance was performed to compare the monologs with the film transcription and to demonstrate that there are differences in the vocabulary used by the test persons yielding different verbal intelligence levels. Then for the classification task the monologs were represented as feature vectors using the classical TF-IDF weighting scheme. The Naive Bayes k-nearest neighbors and Rocchio classifiers were tested. In this paper we describe and compare these classification approaches define the optimal classification parameters and discuss the classification results obtained. (C) 2012 Elsevier Ltd. All rights reserved.;2012
In this paper we focus on an agent-based architecture for task-oriented dialogue management. We present our deliberation process based on optimizing the length of a dialogue in terms of its turns needed to accomplish a task. As innovative features the manager accommodates a lounge strategy for passing initiative back to the user and a two-layered structure for dialogue context representation. We show that applying the lounge strategy during a dialogue leads to improving the information exchange rate by approximately 5% compared to common dialogue strategies alternative. Furthermore we present two of our dialogues and analyze them with respect to the agent description. At the end of the paper we suggest future extensions and modifications to the architecture and conclude. (C) 2011 Elsevier Ltd. All rights reserved.;2012
In this paper we investigate the user's reactions to received suggestion by an Embodied Conversational Agent playing the role of artificial therapist in the healthy eating domain. Specifically we analyse the behaviour of people who voluntarily requested to receive information from the agent and we compare it with the results of a previous evaluation experiment in which subjects were not properly motivated to interact with the agent because they were selected for evaluating the system. This study is part of an ongoing research aimed at developing an intelligent virtual agent that applies natural argumentation techniques to persuade the users to improve their eating habits.;2012
In this paper we propose a novel co-occurrence probabilities based similarity measure for inducing semantic classes. Clustering with the new similarity measure outperforms the widely used distance based on Kullback-Leibler divergence in precision recall and F1 evaluation. In our experiments we induced semantic classes from unannotated in-domain corpus and then used the induced classes and structures to generate large in-domain corpus which was then used for language model adaptation. Character recognition rate was improved from 85.2% to 91%. We imply a new measure to solve the lack of domain data problem by first induction then generation for a dialogue system.;2012
INES (INtelligent Educational System) is an operative prototype of an e-learning platform. This platform includes several tools and technologies such as: (i) semantic management of users and contents (ii) conversational agents to communicate with students in natural language (iii) BDI-based (Believes Desires Intentions) agents which shape the tutoring module of the system (iv) an inference engine and (v) ontologies to semantically model the users their activities and the learning contents. The main contribution of this paper is the intelligent tutoring module of the system. Briefly the tasks of this module are to recognize each student (checking his/her system credentials) and to obtain information about his/her learning progress. So it can be able to suggest to each student specific tasks to achieve his/her particular learning objectives based on several parameters related to the existing learning paths and the student's profile. (C) 2012 Elsevier Ltd. All rights reserved.;2012
Interaction with users is a powerful strategy that potentially yields better information retrieval for all types of media including text images and videos. While spoken document retrieval (SDR) is a crucial technology for multimedia access in the network era it is also more challenging than text information retrieval because of the inevitable recognition errors. It is therefore reasonable to consider interactive functionalities for SDR systems. We propose an interactive SDR approach in which given the user's query the system returns not only the retrieval results but also a short list of key terms describing distinct topics. The user selects these key terms to expand the query if the retrieval results are not satisfactory. The entire retrieval process is organized around a hierarchy of key terms that define the allowable state transitions this is modeled by a Markov decision process which is popularly used in spoken dialogue systems. By reinforcement learning with simulated users the key terms on the short list are properly ranked such that the retrieval success rate is maximized while the number of interactive steps is minimized. Significant improvements over existing approaches were observed in preliminary experiments performed on information needs provided by real users. A prototype system was also implemented.;2012
Language serves many functions for humans but three of the most important are coordination learning and friendship. All of those functions were well served by the conversations from which this special issue emerged a conference Grounding language in perception and (inter) action held at Gordon College in June 2009. The conference brought together researchers primarily from three research traditions dynamical systems theory distributed language and ecological psychology and each of these perspectives is reviewed and illustrated in this special issue. The particular focus of this issue though is the role of conversations in humans caring for each other and the ecosystems of which they are a part. Emergency medical care parents and children playing and students learning a second language are among the contexts of caring considered. Also considered are ways in which symbol systems emerge ways in which language extends and alters perception-action systems and ways in which infant-caregiver relations (i.e. first friendships) are constituted. The various articles explore how language is situated culturally embodied emergent and distributed (Zukow-Goldring this issue) how language is a crucial dimension of the extended phenotype of humans how language increases our ability to care for each other our common tasks and the (real or virtual) ecosystems we inhabit: and how language emerges as we coordinate and share perception and action skills. (C) 2012 Elsevier Ltd. All rights reserved.;2012
Learning and dialogue may naturally engender feelings and expressions of uncertainty for a variety of reasons and purposes. Yet little research has examined how patterns of linguistic uncertainty are enacted and changed over time as students reciprocally influence one another and the dialogical system they are creating. This study describes the occurrence of uncertainty expressions of graduate students collaborating in computer-mediated discussions to negotiate and construct understandings of new concepts from course readings. We report on how often uncertainty was expressed in online synchronous and asynchronous discussions and the characteristics of its expression. We also explore the antecedents and consequences of such expression. Findings indicate that students expressed uncertainty often and in many ways and that such expression seemed to be integrated in a dynamic system of influences on the conversation. We conclude that the ability to deal with and express uncertainty appropriately is an important skill in online academic contexts that may be related to the intellectual work of students in the process of appropriating the discourse of their academic disciplines as they make meaning of scholarly texts.;2012
Objective: Conversational agency is our invented term that orients us to ways in which clients participate in therapeutic dialogues. In this study we examined how clients' conversational correctives and initiatives influenced collaborative therapeutic consultations. Methods: Thirty-five single-session lifestyle consultations were videotaped in which adult clients volunteered to discuss concerns of non-clinical severity with a counselor. We discursively microanalyzed excerpts where clients initiated topic shifts or corrected counselor misunderstandings and how counselors responded to them. Results: Clients were actively involved in co-managing conversational developments during the consultations. They influenced the content and course of the conversations with the counselors by correcting interrupting or speaking from positions contrary or unrelated to those of the counselors. Conclusion: Clients observably influenced the conversational agenda through their correctives and. initiatives if counselors were responsive during face-to-face consultations. Practice implications: Clinicians should demonstrate increased sensitivity and relational responsivity by intentionally engaging with clients' agentive contributions to consultative dialogues. (C) 2012 Elsevier Ireland Ltd. All rights reserved.;2012
Pronunciation errors may be caused by several different deviations from the target such as voicing intonation insertions or deletions of segments or that the articulators are placed incorrectly. Computer-animated pronunciation teachers could potentially provide important assistance on correcting all these types of deviations but they have an additional benefit for articulatory errors. By making parts of the face transparent they can show the correct position and shape of the tongue and provide audiovisual feedback on how to change erroneous articulations. Such a scenario however requires firstly that the learner's current articulation can be estimated with precision and secondly that the learner is able to imitate the articulatory changes suggested in the audiovisual feedback. This article discusses both these aspects with one experiment on estimating the important articulatory features from a speaker through acoustic-to-articulatory inversion and one user test with a virtual pronunciation teacher in which the articulatory changes made by seven learners who receive audiovisual feedback are monitored using ultrasound imaging.;2012
Purpose - This paper aims to describe a pilot at the University of Nebraska-Lincoln for a chatbot that answers questions about the library and library resources. Design/methodology/approach - The chatbot was developed using a SQL database to store the question and answers using artificial intelligence mark-up language metadata. The user interface was built using PHP adapted from Program-O. The open source PHP program was modified to support better display and the launching of URLs within the chatbot screen. Database content was created by mining library websites for information and analyzing chat logs. Findings - The chatbot answers questions from a variety of users from around the world. It has attracted an unexpected number of social chatters which required some additional metadata to accommodate personal chatting and to guide questions back to the intent of the project. The majority of questions are directional or factual questions that Pixel can handle. The database proved to be practical to build and revise as library resources and personnel changed. Practical implications - The chathot provides a 24 hour seven day a week service that is consistent can be enhanced as resources services or staff change and provides a playful interface that engages users. It replaces complicated navigation systems and scrolling through search results with more targeted answers and has the ability to refer questions to librarians. Originality/value - Although chatbots have been around for several decades there is a scarcity of reports in published library literature about their use in libraries.;2012
Recent research has shown that effective dialogue management can be achieved through the Partially Observable Markov Decision Process (POMDP) framework. However past research on POMDP-based dialogue systems usually assumed the parameters of the decision process were known a priori. Themain contribution of this paper is to present a Bayesian reinforcement learning framework for learning the POMDP parameters online from data in a decision-theoretic manner. We discuss various approximations and assumptions which can be leveraged to ensure computational tractability and apply these techniques to learning observationmodels for several simulated spoken dialogue domains.;2012
Reinforcement learning is now an acknowledged approach for optimizing the interaction strategy of spoken dialogue systems. If the first considered algorithms were quite basic (like SARSA) recent works concentrated on more sophisticated methods. More attention has been paid to off-policy learning dealing with the exploration-exploitation dilemma sample efficiency or handling non-stationarity. New algorithms have been proposed to address these issues and have been applied to dialogue management. However each algorithm often solves a single issue at a time while dialogue systems exhibit all the problems at once. In this paper we propose to apply the Kalman Temporal Differences (KTD) framework to the problem of dialogue strategy optimization so as to address all these issues in a comprehensive manner with a single framework. Our claims are illustrated by experiments led on two real-world goal-oriented dialogue management frameworks DIPPER and HIS.;2012
Reinforcement techniques have been successfully used to maximise the expected cumulative reward of statistical dialogue systems. Typically reinforcement learning is used to estimate the parameters of a dialogue policy which selects the system's responses based on the inferred dialogue state. However the inference of the dialogue state itself depends on a dialogue model which describes the expected behaviour of a user when interacting with the system. Ideally the parameters of this dialogue model should be also optimised to maximise the expected cumulative reward. This article presents two novel reinforcement algorithms for learning the parameters of a dialogue model. First the Natural Belief Critic algorithm is designed to optimise the model parameters while the policy is kept fixed. This algorithm is suitable for example in systems using a handcrafted policy perhaps prescribed by other design considerations. Second the Natural Actor and Belief Critic algorithm jointly optimises both the model and the policy parameters. The algorithms are evaluated on a statistical dialogue system modelled as a Partially Observable Markov Decision Process in a tourist information domain. The evaluation is performed with a user simulator and with real users. The experiments indicate that model parameters estimated to maximise the expected reward function provide improved performance compared to the baseline handcrafted parameters. (C) 2011 Elsevier Ltd. All rights reserved.;2012
Since its beginning in 1969 the Internet has grown rapidly especially over the past few years. Companies and organizations store more and more information about themselves on the Internet. Sometimes that information is not well organized. Other times the huge volume of available data makes useful information difficult to be found. The result is that users have to waste their time looking for what they want to know using the traditional menu-driven navigation and keyword search that websites provide. This is a critical issue because it decreases users interest about companies. In order to avoid this problem in this paper we propose a framework for designing virtual assistants which are considering first results an ideal alternative to help users find not only the information that they are looking for but also some related information which could be of the highest interest. (C) 2011 Elsevier Ltd. All rights reserved.;2012
Studies have shown that natural language interfaces such as question answering and conversational systems allow information to be accessed and understood more easily by users who are unfamiliar with the nuances of the delivery mechanisms (e.g. keyword-based search engines) or have limited literacy in certain domains (e.g. unable to comprehend health-related content due to terminology barrier). In particular the increasing use of the web for health information prompts us to reexamine our existing delivery mechanisms. We present enquireMe which is a contextual question answering system that provides lay users with the ability to obtain responses about a wide range of health topics by vaguely expressing at the start and gradually refining their information needs over the course of an interaction session using natural language. enquireMe allows the users to engage in conversations about their health concerns a process that can be therapeutic in itself. The system uses community-driven question-answer pairs from the web together with a decay model to deliver the top scoring answers as responses to the users' unrestricted inputs. We evaluated enquireMe using benchmark data from WebMD and TREC to assess the accuracy of system-generated answers. Despite the absence of complex knowledge acquisition and deep language processing enquireMe is comparable to the state-of-the-art question answering systems such as START as well as those interactive systems from TREC.;2012
The optimal way to build speech understanding modules depends on the amount of training data available. When only a small amount of training data is available effective allocation of the data is crucial to preventing overfitting of statistical methods. We have developed a method for allocating a limited amount of training data in accordance with the amount available. Our method exploits rule-based methods for when the amount of data is small which are included in our speech understanding framework based on multiple model combinations i.e. multiple automatic speech recognition (ASR) modules and multiple language understanding (LU) modules and then allocates training data preferentially to the modules that dominate the overall performance of speech understanding. Experimental evaluation showed that our allocation method consistently outperforms baseline methods that use a single ASR module and a single LU module while the amount of training data increases.;2012
The process of Natural Language Generation for a Conversational Agent translates some semantic language to its surface form expressed in natural language. In this paper we are going to show a Case Based Reasoning technique which is easily extensible and adaptable to multiple domains and languages that generates coherent phrases and produces a natural outcome in the context of a Conversational Agent that maintains a dialogue with the user. (C) 2012 Elsevier Ltd. All rights reserved.;2012
The users of Ambient Intelligence systems expect an intelligent behavior from their environment receiving adapted and easily accessible services and functionality. This can only be possible if the communication between the user and the system is carried out through an interface that is simple (i.e. which does not have a steep learning curve) fluid (i.e. the communication takes place rapidly and effectively) and robust (i.e. the system understands the user correctly). Natural language interfaces such as dialog systems combine the previous three requisites as they are based on a spoken conversation between the user and the system that resembles human communication. The current industrial development of commercial dialog systems deploys robust interfaces in strictly defined application domains. However commercial systems have not yet adopted the new perspective proposed in the academic settings which would allow straightforward adaptation of these interfaces to various application domains. This would be highly beneficial for their use in AmI settings as the same interface could be used in varying environments. In this paper we propose a new approach to bridge the gap between the academic and industrial perspectives in order to develop dialog systems using an academic paradigm while employing the industrial standards which makes it possible to obtain new generation interfaces without the need for changing the already existing commercial infrastructures. Our proposal has been evaluated with the successful development of a real dialog system that follows our proposed approach to manage dialog and generates code compliant with the industry-wide standard VoiceXML.;2012
There are many Web-based platforms where people could share user-generated content such as reviews posts blogs and tweets. However online communities and social networks are expanding so rapidly that it is impossible for people to digest all the information. To help users obtain information more efficiently both the interface for data access and the information representation need to be improved. An intuitive and personalized interface such as a dialogue system could be an ideal assistant which engages a user in a continuous dialogue to garner the user's interest assists the user via speech-navigated interactions harvests and summarizes the Web data as well as presenting it in a natural way. This work therefore aims to conduct research on a universal framework for developing a speech-based interface that can aggregate user-generated content and present the summarized information via speech-based human-computer interactions. The challenge is two-fold. Firstly how to interpret the semantics and sentiment of user-generated data and aggregate them into structured yet concise summaries? Secondly how to develop a dialogue modeling mechanism to present the highlighted information via natural language? This work explores plausible approaches to tackling these challenges. We will investigate a parse-and-paraphrase paradigm and a sentiment scoring mechanism for information extraction from unstructured user-generated content. We will also explore sentiment-involved opinion summarization and dialogue modeling approaches for aggregated information representation. A restaurant-domain prototype system has been implemented for demonstration.;2012
This article promotes a point of view on human interaction in terms of dialogical systems. The approach draws on recent so-called third wave developments in cognitive science. After an introduction to three waves in cognitive science and their counterparts in linguistics the article is placed in a tradition that is ecological embodied and distributed. Its specific take on human interaction pursues these perspectives by claiming that language can neither be reduced to social rules in the micro-sociological domain nor to biological properties of the individual being. As an alternative to these two positions a theory of dialogical systems is developed on the basis of current thinking within the enactive program (e.g. De Jaegher and Di Paolo 2007) the distributed language movement (e.g. Cowley 2011b) and values-realizing theory (e.g. Hodges 2009). Dialogical systems are systems of co-present human beings engaged in interactivity that bring forth situated behavioural coordination (or a communicative structural coupling). Dialogical systems however have emergent properties irreducible to individual actions or microsocial norms. Among the emergent properties one find a tendency to establish and uphold equilibriums that balance between various at times opposing values and tensions. This approach is exemplified through an analysis of a real-life conversation between a mother and a health visitor. (C) 2012 Elsevier Ltd. All rights reserved.;2012
This paper describes a substantial effort to build a real-time interactive multimodal dialogue system with a focus on emotional and nonverbal interaction capabilities. The work is motivated by the aim to provide technology with competences in perceiving and producing the emotional and nonverbal behaviors required to sustain a conversational dialogue. We present the Sensitive Artificial Listener (SAL) scenario as a setting which seems particularly suited for the study of emotional and nonverbal behavior since it requires only very limited verbal understanding on the part of the machine. This scenario allows us to concentrate on nonverbal capabilities without having to address at the same time the challenges of spoken language understanding task modeling etc. We first report on three prototype versions of the SAL scenario in which the behavior of the Sensitive Artificial Listener characters was determined by a human operator. These prototypes served the purpose of verifying the effectiveness of the SAL scenario and allowed us to collect data required for building system components for analyzing and synthesizing the respective behaviors. We then describe the fully autonomous integrated real-time system we created which combines incremental analysis of user behavior dialogue management and synthesis of speaker and listener behavior of a SAL character displayed as a virtual agent. We discuss principles that should underlie the evaluation of SAL-type systems. Since the system is designed for modularity and reuse and since it is publicly available the SAL system has potential as a joint research tool in the affective computing research community.;2012
This paper introduces a new model of attentional state in task-oriented human-machine interaction. It integrates three lines of research: (i) neurocognitive understanding of the focus of attention in working memory (ii) the notion of attention related to the theory of discourse structure in the field of computational linguistics and (iii) investigation of a corpus that comprises recordings of spontaneous speech-based human-machine interaction. The underlying idea was to make a computationally appropriate representation of attentional information that imitates the function of a focus of attention in human perception. The introduced model addresses both the research questions of storage and processing of attentional information. Finally the paper illustrates the model for concrete interaction domains and discusses its implementation within a prototype spoken dialogue system.;2012
This paper presents a new hybrid dialog management framework that integrates a statistical ranking algorithm into an example-based dialog management approach for chat-like dialogs. The proposed model uses ranking features that consider various aspects of dialogs including the relative importance of speech acts dialog history sequences and the causal relationships among speech acts and slot-filling states. The ranking algorithm enables one to aggregate these feature scores systematically and to generate diverse system responses. Additionally the model provides detailed feedback by analyzing the causal relationships among speech acts and predicting the user's possible intentions associated with a given dialog states. Simulated experimental results demonstrate that our approach is effective for task-oriented dialogs and chat-like dialogs. Additionally a case study using elementary school students implies that the proposed system can be used for language learning purposes in addition to task-oriented services.;2012
This paper presents a novel framework for constructing a Semantic-Based Conversational Agent (SCAF). Traditional conversational agents (CA) interpret scripts using structural patterns of sentences which require the script writer to consider every possible permutation that a user may send as input to the CA. This is a time-consuming process which takes no consideration of semantic content working solely with the structural form of the sentence. Furthermore this has proven to be a high maintenance task that can produce some unforeseen consequences when modifying or introducing new patterns into a script. This invariably results in the script writer reassessing the entire script to prevent such occurrences. Different script writers possess differing levels of skill and as such this can prove to be an exasperating task. The proposed SCAF interprets scripts consisting of natural language sentences by means of a semantic sentence similarity measure. User input is measured semantically against the natural language sentences of the context in order to respond with an appropriate output. Such scripting is effortless and alleviates the burden of the traditional pattern-scripted methodologies. Evaluation of the framework has highlighted its potential and shown improvements on traditional CAs.;2012
This paper presents a user localization system based on the fusion of visual information and sound source localization implemented on a social robot called Maggie. One of the main requisites to obtain a natural interaction between human-human and human-robot is an adequate spatial situation between the interlocutors that is to be orientated and situated at the right distance during the conversation in order to have a satisfactory communicative process. Our social robot uses a complete multimodal dialog system which manages the user-robot interaction during the communicative process. One of its main components is the presented user localization system. To determine the most suitable allocation of the robot in relation to the user a proxemic study of the human-robot interaction is required which is described in this paper. The study has been made with two groups of users: children aged between 8 and 17 and adults. Finally at the end of the paper experimental results with the proposed multimodal dialog system are presented.;2012
This paper presents an assessment of automatically generated multimodal referring expressions as produced by embodied conversational agents in a virtual world. The algorithm used for this purpose employs general principles of human motor control and cooperativity in dialogues that can be parameterised so as to vary the precision of the pointing gestures and the amount of linguistic information included in the referring expressions. The study assessed how native speakers of English and Japanese perceived three different algorithmic outputs for multimodal referring behaviour in terms of understandability human-likeness and a social practice (selling). Results show that users generally prefer mobile agents that are economical in their linguistic descriptions to stationary verbose agents. They also show the need for further calibration of the algorithm to accommodate the differences between the two groups. In addition to the detailed description of the set up and results of the study the paper discusses implications for the design and use of agents methodological issues that arose while conducting the cross-cultural study and directions for future work. (C) 2012 Elsevier Ltd. All rights reserved.;2012
This paper proposes a multimodal communication method for human-friendly robot partners based on various types of sensors. First we explain informationally structured space to extend the cognitive capabilities of robot partners based on environmental systems. Next we discuss the suitable measurement range for recognition technologies of touch interface voice recognition human detection gesture recognition and others. Based on the suitable measurement ranges we propose an integration method to estimate human behaviors based on the human detection using color image and 3-D distance information and gesture recognition by the multilayered spiking neural network using the time series of human-hand positions. Furthermore we propose a conversation system to realize the multimodal communication with a person. Finally we show several experimental results of the proposed method and discuss the future direction of this research.;2012
This study introduces emotional feedback as a construct in an acceptance model. It explores the effect of emotional feedback on behavioral intention to use Computer Based Assessment (CBA). A female Embodied Conversational Agent (ECA) with empathetic encouragement behavior was displayed as emotional feedback. More specifically this research aims at investigating the effect of Emotional Feedback on Behavioral Intention to Use a CBA system Perceived Playfulness Perceived Usefulness Perceived Ease of Use Content and Facilitating Conditions. An appropriate survey questionnaire was completed by 134 students. Results demonstrate that Emotional Feedback has a direct effect on Behavioral Intention to Use a CBA system and on other crucial determinants of Behavioral Intention. Finally the proposed acceptance model for computer based assessment extended with the Emotional Feedback variable explains approximately 52% of the variance of Behavioral Intention. (C) 2012 Elsevier Ltd. All rights reserved.;2012
This work addresses natural language dialog planning for an intelligent web filtering model which lets the user filter search results obtained by a traditional search engine and assists them to find what they really are looking for. Unlike state-of-the-art approaches a stochastic planning model is proposed for a web-driven dialog system which uses Conditional Random Fields to predict next dialog moves. Experiments with real web users and different interaction settings show the promise of the approach to web-based adaptive planning aimed at information filtering. (C) 2012 Elsevier Ltd. All rights reserved.;2012
This work presents a new approach to the synthesis of Spanish Sign Language (LSE). Its main contributions are the use of a centralized relational database for storing sign descriptions the proposal of a new input notation and a new avatar design the skeleton structure of which improves the synthesis process. The relational database facilitates a highly detailed phonologic description of the signs that include parameter synchronization and timing. The centralized database approach has been introduced to allow the representation of each sign to be validated by the LSE National Institution FCNSE. The input notation designated HLSML presents multiple levels of abstraction compared with current input notations. Redesigned input notation is used to simplify the description and the manual definition of LSE messages. Synthetic messages obtained using our approach have been evaluated by deaf users in this evaluation a maximum recognition rate of 98.5% was obtained for isolated signs and a recognition rate of 95% was achieved for signed sentences. (C) 2012 Elsevier Ltd. All rights reserved.;2012
We present a computational model that generates listening behaviour for a virtual agent. It triggers backchannel signals according to the user's visual and acoustic behaviour. The appropriateness of the backchannel algorithm in a user-agent situation of storytelling has been evaluated by naive participants who judged the algorithm-ruled timing of backchannels more positively than a random timing. The system can generate different types of backchannels. The choice of the type and the frequency of the backchannels to be displayed is performed considering the agent's personality traits. The personality of the agent is defined in terms of two dimensions extroversion and neuroticism. We link agents with a higher level of extroversion to a higher tendency to perform more backchannels than introverted ones and we link neuroticism to less mimicry production and more response and reactive signals sent. We run a perception study to test these relations in agent-user interactions as evaluated by third parties. We find that the selection of the frequency of backchannels performed by our algorithm contributes to the correct interpretation of the agent's behaviour in terms of personality traits.;2012
We present a series of studies of affirmative cue words-a family of cue words such as okay or alright that speakers use frequently in conversation. These words pose a challenge for spoken dialogue systems because of their ambiguity: They may be used for agreeing with what the interlocutor has said indicating continued attention or for cueing the start of a new topic among other meanings. We describe differences in the acoustic/prosodic realization of such functions in a corpus of spontaneous task-oriented dialogues in Standard American English. These results are important both for interpretation and for production in spoken language applications. We also assess the predictive power of computational methods for the automatic disambiguation of these words. We find that contextual information and final intonation figure as the most salient cues to automatic disambiguation.;2012
We present an Embodied Conversational Agent (ECA) that incorporates a context-sensitive mechanism for handling user barge-in. The affective ECA engages the user in social conversation and is fully implemented. We will use actual examples of system behaviour to illustrate. The ECA is designed to recognise and be empathetic to the emotional state of the user. It is able to detect react quickly to and then follow up with considered responses to different kinds of user interruptions. The design of the rules which enable the ECA to respond intelligently to different types of interruptions was informed by manually analysed real data from human-human dialogue. The rules represent recoveries from interruptions as two-part structures: an address followed by a resumption. The system is robust enough to manage long multi-utterance turns by both user and system which creates good opportunities for the user to interrupt while the ECA is speaking.;2012
We propose a collaborative filtering (CF) model to predict user satisfaction in SDS evaluation. Inspired by the use of CF in recommendation systems where a user's preference for a new item is assume to resemble that for similar items rated previously we adapt the idea to predict user evaluations of unrated dialogs based on the ratings received by similar dialogs. Ratings of dialogs are gathered by crowdsourcing through Amazon Mechanical Turk. A reference baseline is provided by a linear regression model (LRM) based on the PARADISE framework. We present two versions of the CF model. First the item-based collaborative filtering model (ICFM) clusters rated dialogs and builds an LRM for each cluster. The rating of an unseen dialog is predicted by the LRM of its most similar cluster. Second the extended ICFM (EICFM) separates dialog features into user-related and system-related groups to build LRMs for these separately. Experimental results on dialogs from the Let's Go! system show both ICFM and EICFM can significantly improve the proportion of variability explained by the LRM. We also demonstrate the generalizability of the CF model to a new dialog corpus from the systems in the Spoken Dialog Challenge (SDC) 2010.;2012
We study the affective states exhibited by students using an intelligent tutoring system for Scatterplots with and without an interactive software agent Scooter the Tutor. Scooter the Tutor had been previously shown to lead to improved learning outcomes as compared to the same tutoring system without Scooter. We found that affective states and transitions between affective states were very similar among students in both conditions. With the exception of the neutral state no affective state occurred significantly more in one condition over the other. Boredom confusion and engaged concentration persisted in both conditions representing both virtuous cycles and vicious cycles that did not appear to differ by condition. These findings imply that-although Scooter is well liked by students and improves student learning outcomes relative to the original tutor-Scooter does not have a large effect on students' affective states or their dynamics.;2012
Whereas traditional dialog systems operate on the top ASR hypothesis statistical dialog systems claim to be more robust to ASR errors by maintaining a distribution over multiple hidden dialog states. Recently these techniques have been deployed publicly for the first time making empirical measurements possible. In this paper we analyze two of these deployments. We find that performance was quite mixed: in some cases statistical techniques improved accuracy with respect to the top speech recognition hypothesis in other cases accuracy was degraded. Investigating degradations we find the three main causes are (non-obviously) inaccurate parameter estimates poor confidence scores and correlations in speech recognition errors. Overall the results suggest fundamental weaknesses in the formulation as a generative model and we suggest alternatives as future work.;2012
With naturalistic dialogue management a spoken dialogue system behaves as a human would under similar conditions. This paper reports on an experiment to develop naturalistic clarification strategies for noisy speech recognition in the context of spoken dialogue systems. We collected a wizard-of-Oz corpus in which human wizards with access to a rich set of clarification actions made clarification decisions online based on human-readable versions of system data. The experiment compares an evaluation of calls to a baseline system in a library domain with calls to an enhanced version of the system. The new system has a clarification module based on the wizard data that is a decision tree constructed from three machine-learned models. It replicates the wizards' ability to ground partial understandings of noisy input and to build upon them. The enhanced system has a significantly higher rate of task completion greater task success and improved efficiency.;2012
A pedagogic conversational agent (PCA) can be defined as a computer system that interacts with the student in natural language assuming the role of the instructor a student or a companion. It can have a personality and can generate different sentences according to the agent or the student mood. Empathy with the students' feelings seems to increase their motivation to study. However the influence of the agent personality and role as well as the students' opinion is still unclear. Therefore in this article it is explored with the help of a field experiment for the first time how these factors can affect the interaction of children with PCAs and their opinions according to an anonymous and voluntary opinion questionnaire and some personal interviews.;2013
A series of imitation games involving 3-participant (simultaneous comparison of two hidden entities) and 2-participant (direct interrogation of a hidden entity) were conducted at Bletchley Park on the 100th anniversary of Alan Turing's birth: 23 June 2012. From the ongoing analysis of over 150 games involving (expert and non-expert males and females adults and child) judges machines and hidden humans (foils for the machines) we present six particular conversations that took place between human judges and a hidden entity that produced unexpected results. From this sample we focus on features of Turing's machine intelligence test that the mathematician/code breaker did not consider in his examination for machine thinking: the subjective nature of attributing intelligence to another mind.;2013
A spoken dialogue system (SDS) interacts with its user in a spoken natural language. It interprets user speech input and responds to the user. User speech in a spoken natural language may be ambiguous. A challenge in building an SDS is dealing with ambiguity. Without good abilities for disambiguation an SDS can hardly have meaningful and smooth dialogues with its user in practical applications. The existing techniques for disambiguation are mainly based on statistical knowledge about language use. In practical situations such knowledge alone is inadequate. In our research we develop a new disambiguation technique which is based on application of knowledge about user activity behavior in addition to knowledge about language use. The technique is named MUBOD standing for modeling user behavior online for disambiguation. The core component of MUBOD is an online reinforcement learning algorithm that is used to learn the knowledge and apply the knowledge for disambiguation. In this paper we describe the technique and its implementation and present and analyze some initial experimental results. (C) 2012 Elsevier B.V. All rights reserved.;2013
A virtual museum guide agent that uses human relationship-building behaviors to engage museum visitors is described. The computer animated agent named Tinker uses nonverbal conversational behavior empathy social dialogue reciprocal self-disclosure and other relational behavior to establish social bonds with users and encourage continued interaction and repeated visits. Tinker describes exhibits in the museum gives directions and discusses technical aspects of her own implementation. Tinker also recognizes returning visitors through biometric analysis of their hand shapes and dialogue cues. Results from two experiments using Tinker are described. In the first 29 returning visitors are randomized to interact with the agent with the biometric identification turned on or off. In the second experiment 1607 visitors are randomized to interact with versions of Tinker that have relationship-building behavior turned on or off. Results indicate that the use of relational behavior leads to significantly greater engagement by museum visitors measured by session length number of sessions and self-reported attitude as well as learning gains as measured by a knowledge test compared to the same agent that does not use relational behavior. Implications for museum exhibits and intelligent tutoring systems are discussed.;2013
Affective robots and embodied conversational agents require convincing facial expressions to make them socially acceptable. To be able to virtually generate facial expressions we need to investigate the relationship between technology and human perception of affective and social signals. Facial landmarks the locations of the crucial parts of a face are important for perception of the affective and social signals conveyed by facial expressions. Earlier research did not use that kind of technology but rather used analogue technology to generate point-light faces. The goal of our study is to investigate whether digitally extracted facial landmarks contain sufficient information to enable the facial expressions to be recognized by humans. This study presented participants with facial expressions encoded in moving landmarks while these facial landmarks correspond to the facial-landmark videos that were extracted by face analysis software from full-face videos of acted emotions. The facial-landmark videos were presented to 16 participants who were instructed to classify the sequences according to the emotion represented. Results revealed that for three out of five facial-landmark videos (happiness sadness and anger) participants were able to recognize emotions accurately but for the other two facial-landmark videos (fear and disgust) their recognition accuracy was below chance suggesting that landmarks contain information about the expressed emotions. Results also show that emotions with high levels of arousal and valence are better recognized than those with low levels of arousal and valence. We argue that the question of whether these digitally extracted facial landmarks are a basis for representing facial expressions of emotions is crucial for the development of successful humanrobot interaction in the future. We conclude by stating that landmarks provide a basis for the virtual generation of emotions in humanoid agents and discuss how additional facial information might be included to provide a sufficient basis for faithful emotion identification.;2013
Animated characters are beginning to be used as pedagogical tools as they have the power to capture students' attention and foster their motivation for discovery and learning. However in order for them to be widely employed and accepted as a learning resource they must be easy to use and friendly. In this paper we present an architecture that facilitates building interactive pedagogical chatbots that can interact with students in natural language. Our proposal provides a modular and scalable framework to develop such systems efficiently. Additionally we present Geranium a system that helps children to appreciate and protect their environment with an interactive chatbot developed following our scheme.;2013
Betty's Brain is an open-ended learning environment in which students learn about science topics by teaching a virtual agent named Betty through the construction of a visual causal map that represents the relevant science phenomena. The task is complex and success requires the use of metacognitive strategies that support knowledge acquisition causal map construction and progress monitoring. Previous research has established that middle school students struggle at such tasks without proper scaffolding and feedback. In Betty's Brain this feedback is provided by Betty and Mr. Davis another virtual agent designed to provide guidance and suggestions as students work. This paper discusses our implementation of contextualized conversational (CC) feedback and then presents the results of an experimental study exploring the effects of this feedback in two 8th-grade science classrooms. The results illustrate some advantages of the CC feedback in comparison with a baseline dialogue mechanism that presents similar strategies in a non-conversational non-contextualized form. While both groups showed significant pre-to-post test learning gains the difference in learning gains between the groups was not statistically significant. However students who received CC feedback more often performed actions in accordance with the advised strategies and they created higher quality causal maps.;2013
Despite the increasing importance of digital games game accessibility has not yet received enough attention. As a consequence it is unclear how to design games that are engaging and usable also for people with disabilities. This work analyses perceived usability entertainment and overall experience provided by three interfaces for blind people with different gaming habits: (1) a keyboard navigation system (2) a sonar and (3) a conversational interface. Data collected from a preliminary experience suggests that the three interfaces could be used for games although (3) seems a better choice for occasional gamers and novice users and (2) for regular and frequent gamers or users seeking new challenges.;2013
Detecting user affect automatically during real-time conversation is the main challenge towards our greater aim of infusing social intelligence into a natural-language mixed-initiative High-Fidelity (Hi-Fi) audio control spoken dialog agent. In recent years studies on affect detection from voice have moved on to using realistic non-acted data which is subtler. However it is more challenging to perceive subtler emotions and this is demonstrated in tasks such as labeling and machine prediction. This paper attempts to address part of this challenge by considering the role of user satisfaction ratings and also conversational/dialog features in discriminating contentment and frustration two types of emotions that are known to be prevalent within spoken human-computer interaction. However given the laboratory constraints users might be positively biased when rating the system indirectly making the reliability of the satisfaction data questionable. Machine learning experiments were conducted on two datasets users and annotators which were then compared in order to assess the reliability of these datasets. Our results indicated that standard classifiers were significantly more successful in discriminating the abovementioned emotions and their intensities (reflected by user satisfaction ratings) from annotator data than from user data. These results corroborated that: first satisfaction data could be used directly as an alternative target variable to model affect and that they could be predicted exclusively by dialog features. Second these were only true when trying to predict the abovementioned emotions using annotator's data suggesting that user bias does exist in a laboratory-led evaluation. (c) 2013 Elsevier B.V. All rights reserved.;2013
During recent years conversational agents have become a solution to provide straightforward and more natural ways of retrieving information in the digital domain. In this article we present an agent-based dialog simulation technique for learning new dialog strategies and evaluating conversational agents. Using this technique the effort necessary to acquire data required to train the dialog model and then explore new dialog strategies is considerably reduced. A set of measures has also been defined to evaluate the dialog strategy that is automatically learned and to compare different dialog corpora. We have applied this technique to explore the space of possible dialog strategies and evaluate the dialogs acquired for a conversational agent that collects monitored data from patients suffering from diabetes. The results of the comparison of these measures for an initial corpus and a corpus acquired using the dialog simulation technique show that the conversational agent reduces the time needed to complete the dialogs and improve their quality thereby allowing the conversational agent to tackle new situations and generate new coherent answers for the situations already present in an initial model.;2013
Emotion in audio-voice signals as synthesized by text-to-speech (TTS) technologies was investigated to formulate a theory of expression for user interface design. Emotional parameters were specified with markup tags and the resulting audio was further modulated with post-processing techniques. Software was then developed to link a selected TTS synthesizer with an automatic speech recognition (ASR) engine producing a chatbot that could speak and listen. Using these two artificial voice subsystems investigators explored both artistic and psychological implications of artificial speech emotion. Goals of the investigation were interdisciplinary with interest in musical composition augmentative and alternative communication (AAC) commercial voice announcement applications human-computer interaction (HCI) and artificial intelligence (AI). The work-in-progress points towards an emerging interdisciplinary ontology for artificial voices. As one study output HCI tools are proposed for future collaboration.;2013
Formal dialogue systems model rule-based interaction between agents and as such have multiple applications in multi-agent systems and AI more generally. Their conceptual roots are in formal theories of natural argumentation of which Hamblin's formal systems of argumentation in Hamblin (Fallacies. Methuen London 1970 Theoria 37:130-135 1971) are some of the earliest examples. Hamblin cites the medieval theory of obligationes as inspiration for his development of formal argumentation. In an obligatio two agents the Opponent and the Respondent engage in an alternating-move dialogue where the Respondent's actions are governed by certain rules and the goal of the dialogue is establishing the consistency of a proposition. We implement obligationes in the formal dialogue system framework of Prakken (Knowl Eng Rev 21(2):163-188 2006) using Dynamic Epistemic Logic (van Ditmarsch et al. in Dynamic epistemic logic Synthese Library Series. Springer Berlin 2007). The result is a new type of inter-agent dialogue for consistency-checking and analyzing obligationes in this way also sheds light on interpretational and historical questions concerning their use and purpose in medieval academia.;2013
In the recent years major efforts have been made to promote the use of virtual assistants on mobile devices. But in most cases these assistants can only manage a limited and predetermined set of applications. Other limitation that makes difficult the adoption of this technology is the need for a data connection. Thus this paper introduces the use of an Embodied Conversational Agent (ECA) as an assistant for task-specific applications. The proposed ECA is based on open-source components and runs entirely on the mobile device. The system design was validated by conducting tests to measure the latency and energy consumption.(1).;2013
In this paper a general architecture is proposed for developing embodied conversational agents with fuzzy ontology knowledge base. The proposed architecture enables agents to interact with the user via multimodal channels in a virtual reality environment for the purpose of language learning. The agents play the role of emotional rational and friendly partners who provide a specific domain of knowledge based on user's queries in natural language. These queries are performed by an optimized fuzzy search engine. Two scenarios including two virtual airports and a virtual electronic gadget shop are implemented in this architecture to improve users' oral skills. The results show the users' average oral skills improved 11%. Moreover 80% of the users ranked agents' logical sequence of actions and the total speed of responses as very good and 90% of them evaluated agents' appropriateness of responses as very good based on Likert scale.;2013
In this paper a multimodal user-emotion detection system for social robots is presented. This system is intended to be used during human-robot interaction and it is integrated as part of the overall interaction system of the robot: the Robotics Dialog System (RDS). Two modes are used to detect emotions: the voice and face expression analysis. In order to analyze the voice of the user a new component has been developed: Gender and Emotion Voice Analysis (GEVA) which is written using the Chuck language. For emotion detection in facial expressions the system Gender and Emotion Facial Analysis (GEFA) has been also developed. This last system integrates two third-party solutions: Sophisticated High-speed Object Recognition Engine (SHORE) and Computer Expression Recognition Toolbox (CERT). Once these new components (GEVA and GEFA) give their results a decision rule is applied in order to combine the information given by both of them. The result of this rule the detected emotion is integrated into the dialog system through communicative acts. Hence each communicative act gives among other things the detected emotion of the user to the RDS so it can adapt its strategy in order to get a greater satisfaction degree during the human-robot dialog. Each of the new components GEVA and GEFA can also be used individually. Moreover they are integrated with the robotic control platform ROS (Robot Operating System). Several experiments with real users were performed to determine the accuracy of each component and to set the final decision rule. The results obtained from applying this decision rule in these experiments show a high success rate in automatic user emotion recognition improving the results given by the two information channels (audio and visual) separately.;2013
In this paper we present a technique for developing user simulators which are able to interact and evaluate conversational agents. Our technique is based on a statistical model that is automatically learned from a dialog corpus. This model is used by the user simulator to provide the next answer taking into account the complete history of the interaction. The main objective of our proposal is not only to evaluate the conversational agent but also to improve this agent by employing the simulated dialogs to learn a better dialog model. We have applied this technique to design and evaluate a conversational agent which provides academic information in a multi-agent system. The results of the evaluation show that the proposed user simulation methodology can be used not only to evaluate conversational agents but also to explore new enhanced dialog strategies thereby allowing the conversational agent to reduce the time needed to complete the dialogs and automatically detect new valid paths to achieve each of the required objectives defined for the task.;2013
In this paper we present Furhat - a back-projected human-like robot head using state-of-the art facial animation. Three experiments are presented where we investigate how the head might facilitate human - robot face-to-face interaction. First we investigate how the animated lips increase the intelligibility of the spoken output and compare this to an animated agent presented on a flat screen as well as to a human face. Second we investigate the accuracy of the perception of Furhat's gaze in a setting typical for situated interaction where Furhat and a human are sitting around a table. The accuracy of the perception of Furhat's gaze is measured depending on eye design head movement and viewing angle. Third we investigate the turn-taking accuracy of Furhat in a multi-party interactive setting as compared to an animated agent on a flat screen. We conclude with some observations from a public setting at a museum where Furhat interacted with thousands of visitors in a multi-party interaction.;2013
In this paper we propose a method to achieve effective facial emotional expressivity for embodied conversational agents by considering two types of asymmetry when exploiting the valence-arousal-dominance representation of emotions. Indeed the asymmetry of facial expressions helps to convey complex emotional feelings such as conflicting and/or hidden emotions due to social conventions. To achieve such a higher degree of facial expression in a generic way we propose a new model for mapping the valence-arousal-dominance emotion model onto a set of 12 scalar facial part actions built mostly by combining pairs of antagonist action units from the Facial Action Coding System. The proposed linear model can automatically drive a large number of autonomous virtual humans or support the interactive design of complex facial expressions over time. By design our approach produces symmetric facial expressions as expected for most of the emotional spectrum. However more complex ambivalent feelings can be produced when differing emotions are applied on the left and right sides of the face. We conducted an experiment on static images produced by our approach to compare the expressive power of symmetric and asymmetric facial expressions for a set of eight basic and complex emotions. Results confirm both the pertinence of our general mapping for expressing basic emotions and the significant improvement brought by asymmetry for expressing ambivalent feelings. Copyright (c) 2013 John Wiley & Sons Ltd.;2013
Infobots are small-scale natural language question answering systems drawing inspiration from ELIZA-type systems. Their key distinguishing feature is the extraction of meaning from users' queries without the use of syntactic or semantic representations. Three approaches to identifying the users' intended meanings were investigated: keyword-based systems Jaro-based string similarity algorithms and matching based on very shallow syntactic analysis. These were measured against a corpus of queries contributed by users of a WWW-hosted infobot for responding to questions about applications to MSc courses. The most effective system was Jaro with stemmed input (78.57%). It also was able to process ungrammatical input and offer scalability.;2013
Knowing the degree of semantic contrast between words has widespread application in natural language processing including machine translation information retrieval and dialogue systems. Manually created lexicons focus on opposites such as hot and cold. Opposites are of many kinds such as antipodals complementaries and gradable. Existing lexicons often do not classify opposites into the different kinds however. They also do not explicitly list word pairs that are not opposites but yet have some degree of contrast in meaning such as warm and cold or tropical and freezing. We propose an automatic method to identify contrasting word pairs that is based on the hypothesis that if a pair of words A and B are contrasting then there is a pair of opposites C and D such that A and C are strongly related and B and D are strongly related. (For example there exists the pair of opposites hot and cold such that tropical is related to hot and freezing is related to cold.) We will call this the contrast hypothesis.We begin with a large crowdsourcing experiment to determine the amount of human agreement on the concept of oppositeness and its different kinds. In the process we flesh out key features of different kinds of opposites. We then present an automatic and empirical measure of lexical contrast that relies on the contrast hypothesis corpus statistics and the structure of a Roget-like thesaurus. We show how using four different data sets we evaluated our approach on two different tasks solving most contrasting word questions and distinguishing synonyms from opposites. The results are analyzed across four parts of speech and across five different kinds of opposites. We show that the proposed measure of lexical contrast obtains high precision and large coverage outperforming existing methods.;2013
Mixed reality and 3D user interface technologies have increased the immersion presence and physicality of user interactions. These technologies can also increase the physicality of embodied conversational agents (ECAs) by making the ECAs occupy and interact with the physical space. We propose that increasing the physicality of an ECA can increase the ECA's social presence that is the feeling that the ECA is a real person. In this paper we examine existing research and formalize the idea of ECA physicality. We also explored the relationship between physicality and social presence by conducting two user studies (n = 18 and n = 29). Both user studies took place in a medical team training context and involved virtual human ECAs as fellow team members. The first study's results suggested that increasing physicality increased social presence and elicited more realistic behavior. The second study's results suggested that individual dimensions of physicality affect social presence to different extents.;2013
Objective: An automated health counselor agent was designed to promote both physical activity and fruit and vegetable consumption through a series of simulated conversations with users on their home computers. Methods: The agent was evaluated in a 4-arm randomized trial of a two-month daily contact intervention comparing: (a) physical activity (b) fruit and vegetable consumption (c) both interventions and (d) a non-intervention control. Physical activity was assessed using daily pedometer steps. Daily servings of fruit and vegetables were assessed using the NIH/NCI self-report Fruit and Vegetable Scan. Results: Participants in the physical activity intervention increased their walking on average compared to the control group while those in the fruit and vegetable intervention and combined intervention decreased walking. Participants in the fruit and vegetable intervention group consumed significantly more servings per day compared to those in the control group and those in the combined intervention reported consuming more compared to those in the control group. Conclusion: Automated health intervention software designed for efficient re-use is effective at changing health behavior. Practice implications: Automated health behavior change interventions can be designed to facilitate translation and adaptation across multiple behaviors. (C) 2013 Elsevier Ireland Ltd. All rights reserved.;2013
Objective: Computer-based virtual coaches are increasingly being explored for patient education counseling and health behavior training and coaching. The objective of this research was to develop and evaluate a Virtual Mindfulness Coach for training and coaching in mindfulness meditation. Methods: The coach was implemented as an embodied conversational character providing mindfulness training and coaching via mixed initiative text-based natural language dialog with the student and emphasizing affect-adaptive interaction. (The term 'mixed initiative dialog' refers to a human-machine dialog where either can initiate a conversation or a change in the conversation topic.) Results: Findings from a pilot evaluation study indicate that the coach-based training is more effective in helping students establish a regular practice than self-administered training using written and audio materials. The coached group also appeared to be in more advanced stages of change in terms of the transtheoretical model and have a higher sense of self-efficacy regarding establishment of a regular mindfulness practice. Conclusion: These results suggest that virtual coach-based training of mindfulness is both feasible and potentially more effective than a self-administered program. Of particular interest is the identification of the specific coach features that contribute to its effectiveness. Practice implications: Virtual coaches could provide easily accessible and cost-effective customized training for a range of health behaviors. The affect-adaptive aspect of these coaches is particularly relevant for helping patients establish long-term behavior changes. (C) 2013 Elsevier Ireland Ltd. All rights reserved.;2013
ObjectivesTo compare the efficacy of a computer-based physical activity program (Embodied Conversational AgentECA) with that of a pedometer control condition in sedentary older adults. DesignSingle-blind block-randomized controlled trial stratified according to clinic site and health literacy status. SettingThree urban ambulatory care practices at Boston Medical Center between April 2009 and September 2011. ParticipantsOlder adults (N=263 mean age 71.3 61% female 63% African American 51% high school diploma or less). InterventionECA participants were provided with portable tablet computers with touch screens to use for 2months and were directed to connect their pedometers to the computer using a data cable and interact with a computer-animated virtual exercise coach daily to discuss walking and to set walking goals. Intervention participants were then given the opportunity to interact with the ECA in a kiosk in their clinic waiting room for the following 10months. Control participants were given a control pedometer intervention that only tracked step counts for an equivalent period of time. Intervention participants were also provided with pedometers. MeasurementsThe primary outcome was average daily step count for the 30days before the 12-month interview. Secondary outcomes were average daily step count for the 30days before the 2-month interview. Outcomes were also stratified according to health literacy level. ResultsECA participants walked significantly more steps than control participants at 2months (adjusted mean 4041 vs 3499 steps/day P=.01) but this effect waned by 12months (3861 vs 3383 P=.09). For participants with adequate health literacy those in the ECA group walked significantly more than controls at both 2months (P=.03) and 12months (P=.02) while those with inadequate health literacy failed to show significant differences between treatment groups at either time point. Intervention participants were highly satisfied with the program. ConclusionAn automated exercise promotion system deployed from outpatient clinics increased walking among older adults over the short-term. Effective methods for long-term maintenance of behavior change are needed.;2013
One of the fundamental issues of geographical information science is to design GIS interfaces and functionalities in a way that is easy to understand teach and use. Unfortunately current geographical information systems (including ArcGIS) remains very difficult to use as spatial analysis tools because they organize and expose functionalities according to GIS data structures and processing algorithms. As a result GIS interfaces are conceptually confusing cognitively complex and semantically disconnected from the way human reason about spatial analytical activities. In this article we propose an approach that structures GIS analytical functions based on the notion of analytical intent. We describe an experiment that replaces ArcGIS desktop interface with a conversational interface to enable mixed-initiative user-system interactions at the level of analytical intentions. We initially focus on the subset of GIS functions that are relevant to finding what's inside as described by Mitchell but the general principles apply to other types of spatial analysis. This work demonstrates the feasibility of delegating some spatial thinking tasks to computational agents and also raises future research questions that are key to building a better theory of spatial thinking with GIS.;2013
Online Social Networks (OSNs) have attracted millions of active users and have become an integral part of today's web ecosystem. Unfortunately in the wrong hands OSNs can be used to harvest private user data distribute malware control botnets perform surveillance spread misinformation and even influence algorithmic trading. Usually an adversary starts off by running an infiltration campaign using hijacked or adversary-owned OSN accounts with an objective to connect with a large number of users in the targeted OSN. In this article we evaluate how vulnerable OSNs are to a large-scale infiltration campaign run by socialbots: bots that control OSN accounts and mimic the actions of real users. We adopted the design of a traditional web-based botnet and built a prototype of a Socialbot Network (SbN): a group of coordinated programmable socialbots. We operated our prototype on Facebook for 8 weeks and collected data about user behavior in response to a large-scale infiltration campaign. Our results show that (1) by exploiting known social behaviors of users OSNs such as Facebook can be infiltrated with a success rate of up to 80% (2) subject to user profile privacy settings a successful infiltration can result in privacy breaches where even more private user data are exposed (3) given the economics of today's underground markets running a large-scale infiltration campaign might be profitable but is still not particularly attractive as a sustainable and independent business (4) the security of socially-aware systems that use or integrate OSN platforms can be at risk given the infiltration capability of an adversary in OSNs and (5) defending against malicious socialbots raises a set of challenges that relate to web automation online-offline identity binding and usable security. (c) 2012 Elsevier BM. All rights reserved.;2013
Overlapping talk occurs frequently in multi-party conversations and is a domain in which speakers may pursue various communicative goals. The current study focuses on turn competition. Specifically we seek to identify the phonetic differences that discriminate turn-competitive from non-competitive overlaps. Conversation analysis techniques were used to identify competitive and non-competitive overlaps in a corpus of multi-party recordings. We then generated a set of potentially predictive features relating to prosody (F0 intensity speech rate pausing) and overlap placement (overlap duration point of overlap onset recycling etc.). Decision tree classifiers were trained on the features and tested on a classification task in order to determine which features and feature combinations best differentiate competitive overlaps from non-competitive overlaps. It was found that overlap placement features played a greater role than prosodic features in indicating turn competition. Among the prosodic features tested F0 and intensity were the most effective predictors of turn competition. Also our decision tree models suggest that turn competitive and non-competitive overlaps can be initiated by a new speaker at many different points in the current speaker's turn. These findings have implications for the design of dialogue systems and suggest novel hypotheses about how speakers deploy phonetic resources in everyday talk. (C) 2012 Elsevier B.V. All rights reserved.;2013
Portability of a spoken dialogue system (SDS) to a new domain or a new language is a hot topic as it may imply gains in time and cost for building new SDSs. In particular in this paper we investigate several fast and efficient approaches for language portability of the spoken language understanding (SLU) module of a dialogue system. We show that the use of statistical machine translation (SMT) can reduce the time and the cost of porting a system from a source to a target language. For conceptual decoding a state-of-the-art module based on conditional random fields (CRF) is used and a new approach based on phrase-based statistical machine translation (PB-SMT) is also evaluated. The experimental results show the efficiency of the proposed methods for a fast and low cost SLU language portability. In addition we propose two methods to increase SLU robustness to translation errors. Overall it is shown that the combination of all these approaches can further reduce the concept error rate. While most of the experiments in this paper deal with portability from French to Italian (given the availability of the Media French corpus and its subset manually translated into Italian) a validation of our methodology is eventually proposed in Arabic.;2013
Recent studies have demonstrated that people show social reactions when interacting with human-like virtual agents. For instance human users behave in a socially desirable way show increased cooperation or apply human-like communication. It has however so far not been tested whether users are prone to mimic the artificial agent's behavior although this is a widely cited phenomenon of human human communication that seems to be especially indicative of the sociality of the situation. We therefore conducted an experiment in which we analyzed whether humans reciprocate an agent's smile. In a between-subjects design 104 participants conducted an 8-min small-talk conversation with an agent that either did not smile showed occasional smiles or displayed frequent smiles. Results show that although smiling did not have a distinct impact on the evaluation of the agent the human interaction partners themselves smiled longer when the agent was smiling. (C) 2012 Elsevier Ltd. All rights reserved.;2013
Research on dialog systems is a very active area in social robotics. During the last two decades these systems have evolved from those based only on speech recognition and synthesis to the current and modern systems which include new components and multimodality. By multimodal dialogue we mean the interchange of information among several interlocutors not just using their voice as the mean of transmission but also all the available channels such as gestures facial expressions touch sounds etc. These channels add information to the message to be transmitted in every dialogue turn. The dialogue manager (IDiM) is one of the components of the robotic dialog system (RDS) and is in charge of managing the dialogue flow during the conversational turns. In order to do that it is necessary to coherently treat the inputs and outputs of information that flow by different communication channels: audio vision radio frequency touch etc. In our approach this multichannel input of information is temporarily fused into communicative acts (CAs). Each CA groups the information that flows through the different input channels into the same pack transmitting a unique message or global idea. Therefore this temporary fusion of information allows the IDiM to abstract from the channels used during the interaction focusing only on the message not on the way it is transmitted. This article presents the whole RDS and the description of how the multimodal fusion of information is made as CAs. Finally several scenarios where the multimodal dialogue is used are presented.;2013
Statistical dialog systems (SDSs) are motivated by the need for a data-driven framework that reduces the cost of laboriously handcrafting complex dialog managers and that provides robustness against the errors created by speech recognizers operating in noisy environments. By including an explicit Bayesian model of uncertainty and by optimizing the policy via a reward-driven process partially observable Markov decision processes (POMDPs) provide such a framework. However exact model representation and optimization is computationally intractable. Hence the practical application of POMDP-based systems requires efficient algorithms and carefully constructed approximations. This review article provides an overview of the current state of the art in the development of POMDP-based spoken dialog systems.;2013
Studying how interlocutors exchange information efficiently during conversations in less-than-ideal acoustic conditions promises to both further the understanding of links between perception and production and inform the design of human-computer dialogue systems. The current study explored how interlocutors' speech changes in the presence of fluctuating noise. Pairs of talkers were recorded while solving puzzles cooperatively in quiet and with modulated-noise or competing speech maskers whose silent intervals were manipulated to produce either temporally sparse or dense maskers. Talkers responded to masked conditions by both increasing the amount of speech produced and locally changing their speech activity patterns resulting in a net reduction in the proportion of speech in temporal overlap with the maskers with larger relative reductions for sparse maskers. An analysis of talker activity in the vicinity of masker onset and offset events showed a significant reduction in onsets following masker onsets and a similar increase in onsets following masker offsets. These findings demonstrate that talkers are sensitive to masking noise and respond to its fluctuations by adopting a wait-and-talk strategy. (C) 2013 Acoustical Society of America.;2013
Supporting multiple active speakers in automotive hands-free or speech dialog applications is an interesting issue not least due to comfort reasons. Therefore a multi-channel system for enhancement of speech signals captured by distributed distant microphones in a car environment is presented. Each of the potential speakers in the car has a dedicated directional microphone close to his position that captures the corresponding speech signal. The aim of the resulting overall system is twofold: On the one hand a combination of an arbitrary pre-defined subset of speakers' signals can be performed e.g. to create an output signal in a hands-free telephone conference call for a far-end communication partner. On the other hand annoying cross-talk components from interfering sound sources occurring in multiple different mixed output signals are to be eliminated motivated by the possibility of other hands-free applications being active in parallel. The system includes several signal processing stages. A dedicated signal processing block for interfering speaker cancellation attenuates the cross-talk components of undesired speech. Further signal enhancement comprises the reduction of residual cross-talk and background noise. Subsequently a dynamic signal combination stage merges the processed single-microphone signals to obtain appropriate mixed signals at the system output that may be passed to applications such as telephony or a speech dialog system. Based on signal power ratios between the particular microphone signals an appropriate speaker activity detection and therewith a robust control mechanism of the whole system is presented. The proposed system may be dynamically configured and has been evaluated for a car setup with four speakers sitting in the car cabin disturbed in various noise conditions.;2013
The analysis of a speech act is important for dialogue understanding systems because the speech act of an utterance is closely associated with the user's intention in the utterance. This paper proposes a speech act classification model that effectively uses a two-layer hierarchical structure generated from the adjacency pair information of speech acts. The proposed model has two advantages when adding hierarchical information to speech act classification the improved accuracy of the speech act classification and the reduced running time in the testing phase. As a result it achieves higher performance than other models that do not use the hierarchical structure and has faster running time because Support Vector Machine classifiers can efficiently be arranged on the two-layer hierarchical structure. (C) 2013 Elsevier B.V. All rights reserved.;2013
The How Was Your Day(HWYD) companion is an embodied conversational agent that can discuss work-related issues entering free-form dialogues while discussing issues surrounding a typical work day. The open-ended nature of these interactions requires new models of evaluation. Here we describe a paradigm and methodology for evaluating the main aspects of such functionality in conjunction with overall system behavior with respect to three parameters: functional ability (i.e. does it do the rightthing conversationally) content (i.e. does it respond appropriately to the semantic context) and emotional behavior (i.e. given the emotional input from the user does it respond in an emotionally appropriate way). We demonstrate the functionality of our evaluation paradigm as a method for both grading current system performance and targeting areas for particular performance review. We show correlation between for example automatic speech recognition performance and overall system performance (as is expected in systems of this type) but beyond this we show where individual utterances or responses indicated as positive or negative characterize system performance and demonstrate how our combination evaluation approach highlights issues (both positive and negative) in the companion system's interaction behavior.;2013
The operation of robotic tour guides in public museums leads to a variety of interactions of these complex technical systems with humans of all ages and with different technical backgrounds. Interacting with a robot is a new experience for many visitors. An intuitive user interface preferable one that resembles the interaction between human tour guides and visitors simplifies the communication between robot and visitors. To allow for supportive behavior of the guided persons predictable robot behavior is necessary. Humanoid robots are able to resemble human motions and behaviors and look familiar to human users that have not interacted with robots so far. Hence they are particularly well suited for this purpose. In this work we present our anthropomorphic mobile communication robot Robotinho. It is equipped with an expressive communication head to display emotions. Its multimodal dialog system incorporates gestures facial expression body language and speech. We describe the behaviors that we developed for interaction with inexperienced users in a museum tour guide scenario. In contrast to prior work Robotinho communicated with the guided persons during navigation between exhibits not only while explaining an exhibit. We report qualitative and quantitative results from evaluations of Robotinho in RoboCup@Home competitions and in a science museum.;2013
The paper proposes a dialogue system LND which brings together and unifies two traditions in studying dialogue as a game: the dialogical logic introduced by Lorenzen and persuasion dialogue games as specified by Prakken. The first approach allows the representation of formal dialogues in which the validity of argument is the topic discussed. The second tradition has focused on natural dialogues examining e.g. informal fallacies typical in real-life communication. Our goal is to unite these two approaches in order to allow communicating agents to benefit from the advantages of both i.e. to equip them with the ability not only to persuade each other about facts but also to prove that a formula used in an argument is a classical propositional tautology. To this end we propose a new description of the dialogical logic which meets the requirements of Prakken's generic specification for natural dialogues and we introduce rules allowing to embed a formal dialogue in a natural one. We also show the correspondence result between the original and the new version of the dialogical logic i.e. we show that a winning strategy for a proponent in the original version of the dialogical logic means a winning strategy for a proponent in the new version and conversely.;2013
The web has become the largest repository of multimedia information and its convergence with telecommunications is now bringing the benefits of web technology to hand-held devices. To optimize data access using these devices and provide services which meet the user needs through intelligent information retrieval the system must sense and interpret the user environment and the communication context. In addition natural spoken conversation with handheld devices makes possible the use of these applications in environments in which the use of GUI interfaces is not effective provides a more natural human-computer interaction and facilitates access to the web for people with visual or motor disabilities allowing their integration and the elimination of barriers to Internet access. In this paper we present an architecture for the design of context-aware systems that use speech to access web services. Our contribution focuses specifically on the use of context information to improve the effectiveness of providing web services by using a spoken dialog system for the user-system interaction. We also describe an application of our proposal to develop a context-aware railway information system and provide a detailed evaluation of the influence of the context information in the quality of the services that are supplied.;2013
The widespread use of new mobile technology implementing wireless communications enables a new type of advanced applications to access information services on the Internet. In order to provide services which meet the user needs through intelligent information retrieval the system must sense and interpret the user environment and the communication context. Though context-awareness is vital to provide services adapted to the user preferences it cannot be useful if such services are difficult to access. The development of spoken dialogue systems for these applications facilitates interaction in natural language with the environment which is also benefited from contextual information. In this paper we propose a framework to develop context-aware dialogue systems that dynamically incorporate user specific requirements and preferences as well as characteristics about the interaction environment in order to improve and personalize web information and services. We have identified the major components for context-aware dialogue systems and placed them within a general-purpose architecture. The framework also describes a representation mode based on a dialogue register in order to share information between the elements of the architecture and incorporates statistical methodologies for dialogue management in order to reduce the effort required for both the implementation of a new system and the adaptation to a new task. We have evaluated our proposal developing a travel-planning system and provide a detailed discussion of its positive influence in the quality of the interaction and the information and services provided.;2013
This paper describes research that addresses the problem of dialog management from a strong context-centric approach. We further present a quantitative method of measuring the importance of contextual cues when dealing with speech-based human-computer interactions. It is generally accepted that using context in conjunction with a human input such as spoken speech enhances a machine's understanding of the user's intent as a means to pinpoint an adequate reaction. For this work however we present a context-centric approach in which the use of context is the primary basis for understanding and not merely an auxiliary process. We employ an embodied conversation agent that facilitates the seamless engagement of a speech-based information-deployment entity by its human end user. This dialog manager emphasizes the use of context to drive its mixed-initiative discourse model. Atypical modern automatic speech recognizer (ASR) was incorporated to handle the speech-to-text translations. As is the nature of these ASR systems the recognition rate is consistently less than perfect thus emphasizing the need for contextual assistance. The dialog system was encapsulated into a speech-based embodied conversation agent platform for prototyping and testing purposes. Experiments were performed to evaluate the robustness of its performance namely through measures of naturalness and usefulness with respect to the emphasized use of context. The contribution of this work is to provide empirical evidence of the importance of conversational context in speech-based human-computer interaction using a field-tested context-centric dialog manager. (C) 2013 Wiley Periodicals Inc.;2013
This paper describes the World Wide Web Consortium's (W3C) Multimodal Architecture and Interfaces (MMI Architecture) standard an architecture and communications protocol that enables a wide variety of independent modalities to be integrated into multimodal applications. By encapsulating the functionalities of modality components and requiring all control information to go through the Interaction Manager the MMI Architecture simplifies integrating components from multiple sources.;2013
This paper investigates the use of conversational agents to scaffold online collaborative learning discussions through an approach called academically productive talk (APT). In contrast to past work on dynamic support for collaborative learning which has involved using agents to elevate the conceptual depth of collaborative discussion by leading students in groups through directed lines of reasoning this APT-based approach lets students follow their own lines of reasoning and promotes productive practices such as explanation of reasoning and refinement of ideas. Two forms of support are contrasted namely Revoicing support and Feedback support. The study provides evidence that Revoicing support resulted in significantly more intensive reasoning exchange between students in the chat and significantly more learning during the chat than when that form of support was absent. Another form of support namely Feedback support increased expression of reasoning while marginally decreasing the intensity of the interaction between students and did not affect learning.;2013
This paper presents a model of incremental speech generation in practical conversational systems. The model allows a conversational system to incrementally interpret spoken input while simultaneously planning realising and self-monitoring the system response. If these processes are time consuming and result in a response delay the system can automatically produce hesitations to retain the floor. While speaking the system utilises hidden and overt self-corrections to accommodate revisions in the system. The model has been implemented in a general dialogue system framework. Using this framework we have implemented a conversational game application. A Wizard-of-Oz experiment is presented where the automatic speech recognizer is replaced by a Wizard who transcribes the spoken input. In this setting the incremental model allows the system to start speaking while the user's utterance is being transcribed. In comparison to a non-incremental version of the same system the incremental version has a shorter response time and is perceived as more efficient by the users. (C) 2012 Elsevier Ltd. All rights reserved.;2013
This paper presents an integrated view on a series of experiments conducted with an affective dialog system applied as a tool in studies of emotions and social processes in online communication. The different realizations of the system are evaluated in three experimental setups to verify effects of affective profiles as well as of fine-grained communication scenarios on users' expressions of affective states experienced emotional changes and interaction patterns. Results demonstrate that the system applied in virtual reality settings matches a Wizard-of-Oz in terms of chatting enjoyment dialog coherence and realism. Variants of the system's affective profile significantly influence the rating of chatting enjoyment and an emotional connection. Self-reported emotional changes experienced by participants during an interaction with the system are in line with the type of applied profile. Analysis of interaction patterns i.e. usage of particular dialog act classes word categories and textual expressions of affective states for different scenarios demonstrates that a communication scenario for social sharing of emotions was successfully established. The experimental evidence provides valuable input for applications of affective dialog systems and strengthens them as valid tools for studying affect and social aspects in online communication.;2013
This paper proposes an unsupervised spoken language understanding (SLU) framework for a multi-domain dialog system. Our unsupervised SLU framework applies a non-parametric Bayesian approach to dialog acts intents and slot entities which are the components of a semantic frame. The proposed approach reduces the human effort necessary to obtain a semantically annotated corpus for dialog system development. In this study we analyze clustering results using various evaluation metrics for four dialog corpora. We also introduce a multi-domain dialog system that uses the unsupervised SLU framework. We argue that our unsupervised approach can help overcome the annotation acquisition bottleneck in developing dialog systems. To verify this claim we report a dialog system evaluation in which our method achieves competitive results in comparison with a system that uses a manually annotated corpus. In addition we conducted several experiments to explore the effect of our approach on reducing development costs. The results show that our approach be helpful for the rapid development of a prototype system and reducing the overall development costs.;2013
This work focuses on speech-based human-machine interaction. Specifically a Spoken Dialogue System (SDS) that could be integrated into a robot is considered. Since Automatic Speech Recognition is one of the most sensitive tasks that must be confronted in such systems the goal of this work is to improve the results obtained by this specific module. In order to do so a hierarchical Language Model (LM) is considered. Different series of experiments were carried out using the proposed models over different corpora and tasks. The results obtained show that these models provide greater accuracy in the recognition task. Additionally the influence of the Acoustic Modelling (AM) in the improvement percentage of the Language Models has also been explored. Finally the use of hierarchical Language Models in a language understanding task has been successfully employed as shown in an additional series of experiments.;2013
Trust is a critical component in effective collaboration decision-making and negotiation. The goal of effective team leaders should be to send signals and messages that increase trust. We attempt to determine if signals can vary perceptions of trustworthiness and if nonverbal behaviors such as the voice contain indicators of trust. In order to investigate the relationship between trust and vocal dynamics this article presents a study that explores how the voice measured unobtrusively reflects a person's current level of perceived trust. We used an Embodied Conversational Agent (ECA) to maximize consistency and control in questioning timing and interviewer nonverbal behavior thus eliminating potential confounds that may be introduced due to interaction adaptation. Participants () completed a face-to-face interview with the ECA and reported their perceptions of the ECA's trustworthiness. The results of the study revealed that vocal pitch was inversely related to perceived trust but temporally variant vocal pitch early in the interview reflected trust. The ECA was perceived as more trustworthy when smiling. While the results of this research suggest a relationship between vocal pitch and perceived levels of trust more work needs to be done to clarify the causal relationship. Similarly additional study needs to be done in order to integrate additional behavioral measurements that account for variation across diverse situations people and cultures.;2013
User simulation is an important research area in the field of spoken dialogue systems (SDSs) because collecting and annotating real human-machine interactions is often expensive and time-consuming. However such data are generally required for designing training and assessing dialogue systems. User simulations are especially needed when using machine learning methods for optimizing dialogue management strategies such as Reinforcement Learning where the amount of data necessary for training is larger than existing corpora. The quality of the user simulation is therefore of crucial importance because it dramatically influences the results in terms of SDS performance analysis and the learnt strategy. Assessment of the quality of simulated dialogues and user simulation methods is an open issue and although assessment metrics are required there is no commonly adopted metric. In this paper we give a survey of User Simulations Metrics in the literature propose some extensions and discuss these metrics in terms of a list of desired features.;2013
Visual perception speech perception and the understanding of perceived information are linked through complex mental processes. Gestures as part of visual perception and synchronized with verbal information are a key concept of human social interaction. Even when there is no physical contact (e.g. a phone conversation) humans still tend to express meaning through movement. Embodied conversational agents (ECAs) as well as humanoid robots are visual recreations of humans and are thus expected to be able to perform similar behaviour in communication. The behaviour generation system proposed in this paper is able to specify expressive behaviour strongly resembling natural movement performed within social interaction. The system is TTS-driven and fused with the time-and-space efficient TTS-engine called 'PLATTOS'. Visual content and content presentation is formulated based on several linguistic features that are extrapolated from arbitrary input text sequences and prosodic features (e.g. pitch intonation stress emphasis etc.) as predicted by several verbal modules in the system. According to the evaluation results when using the proposed system the synchronized co-verbal behaviour can be recreated with a very high-degree of naturalness either by ECAs or humanoid robots alike.;2013
We are currently experiencing a boom in the presence of Spanish language in the world which is reflected in its inclusion as a second language in the educational system of countries like Brazil and the emergence of language in the U. S. and China. To confront this situation there is a wide variety of courses for learning Spanish. However specific initiatives combining proven teaching methods in university classroom experiences with the creation of new multidisciplinary content displayed on 3D virtual sets have not been detected. This study proposes the establishment of a learner's role-play to improve learner's skills. Foreign languages' learning is the focus of the report because can serve as an appropriate context to analyze self-directed learning strategies and the culture of Lifelong Learning. The goal of this research is the creation of an integrated Massively Multiuser Online Learning (MMOL) platform that enables the creation development and deployment of contents and activities for teaching Spanish in an ad hoc educational virtual world named SLRoute. Such environment promotes an immersive creative and collaborative experience in the process of learning a foreign language. In order to assess the validity and reliability of this technology we used the Technology Acceptance Model (TAM). The ultimate intention is to measure the acceptability of MMOL platforms for educational issues.;2013
We describe the work on infusion of emotion into a limited-task autonomous spoken conversational agent situated in the domestic environment using a need-inspired task-independent emotion model (NEMO). In order to demonstrate the generation of affect through the use of the model we describe the work of integrating it with a natural-language mixed-initiative HiFi-control spoken conversational agent (SCA). NEMO and the host system communicate externally removing the need for the Dialog Manager to be modified as is done in most existing dialog systems in order to be adaptive. The first part of the paper concerns the integration between NEMO and the host agent. The second part summarizes the work on automatic affect prediction namely frustration and contentment from dialog features a non-conventional source in the attempt of moving towards a more user-centric approach. The final part reports the evaluation results obtained from a user study in which both versions of the agent (non-adaptive and emotionally-adaptive) were compared. The results provide substantial evidences with respect to the benefits of adding emotion in a spoken conversational agent especially in mitigating users' frustrations and ultimately improving their satisfaction.;2013
We present an approach to adapt dynamically the language models (LMs) used by a speech recognizer that is part of a spoken dialogue system. We have developed a grammar generation strategy that automatically adapts the LMs using the semantic information that the user provides (represented as dialogue concepts) together with the information regarding the intentions of the speaker (inferred by the dialogue manager and represented as dialogue goals). We carry out the adaptation as a linear interpolation between a background LM and one or more of the LMs associated to the dialogue elements (concepts or goals) addressed by the user. The interpolation weights between those models are automatically estimated on each dialogue turn using measures such as the posterior probabilities of concepts and goals estimated as part of the inference procedure to determine the actions to be carried out. We propose two approaches to handle the LMs related to concepts and goals. Whereas in the first one we estimate a LM for each one of them in the second one we apply several clustering strategies to group together those elements that share some common properties and estimate a LM for each cluster. Our evaluation shows how the system can estimate a dynamic model adapted to each dialogue turn which helps to significantly improve the performance of the speech recognition which leads to an improvement in both the language understanding and the dialogue management tasks. (C) 2012 Elsevier Ltd. All rights reserved.;2013
We propose a novel practical dialogue management system that satisfies the requirements of robust dialogue management efficient domain knowledge construction and flexible architecture for maintenance and extensibility. The proposed system uses a corpus-based framework and a dynamic dialogue transition network model which work in a cooperative and complementary manner. The former supports automatic generation of domain knowledge from an annotated corpus whereas the latter manages dialogue flows robustly. The system can also automatically carry out user-intention analyses and response generation since it retrieves the most similar utterance and its response pair by estimating similarity between the input utterance and corpus utterances. Therefore the system can control a new domain dialogue by updating the corpus. In our experiments on two different corpora the system achieved F-0.5-scores of 91% and 90% in terms of user intention recognition with a task completion rate of 95% and 91%.;2013
When humans are addressing multiple robots with informative speech acts (Clark & Carlson 1982) their cognitive resources are shared between all the participating robot agents. For each moment the user's behavior is not only determined by the actions of the robot that they are directly gazing at but also shaped by the behaviors from all the other robots in the shared environment. We define cooperative behavior as the action performed by the robots that are not capturing the user's direct attention. In this paper we are interested in how the human participants adjust and coordinate their own behavioral cues when the robot agents are performing different cooperative gaze behaviors. A novel gaze-contingent platform was designed and implemented. The robots' behaviors were triggered by the participant's attentional shifts in real time. Results showed that the human participants were highly sensitive when the robot agents were performing different cooperative gazing behaviors.;2013
A partially observable Markov decision process (POMDP) has been proposed as a dialog model that enables automatic optimization of the dialog policy and provides robustness to speech understanding errors. Various approximations allow such a model to be used for building real-world dialog systems. However they require a large number of dialogs to train the dialog policy and hence they typically rely on the availability of a user simulator. They also require significant designer effort to hand-craft the policy representation. We investigate the use of Gaussian processes (GPs) in policy modeling to overcome these problems. We show that GP policy optimization can be implemented for a real world POMDP dialog manager and in particular: 1) we examine different formulations of a GP policy to minimize variability in the learning process 2) we find that the use of GP increases the learning rate by an order of magnitude thereby allowing learning by direct interaction with human users and 3) we demonstrate that designer effort can be substantially reduced by basing the policy directly on the full belief space thereby avoiding ad hoc feature space modeling. Overall the GP approach represents an important step forward towards fully automatic dialog policy optimization in real world systems.;2014
Ambient Assisted Living (AAL) systems must provide adapted services easily accessible by a wide variety of users. This can only be possible if the communication between the user and the system is carried out through an interface that is simple rapid effective and robust. Natural language interfaces such as dialog systems fulfill these requisites as they are based on a spoken conversation that resembles human communication. In this paper we enhance systems interacting in AAL domains by means of incorporating context-aware conversational agents that consider the external context of the interaction and predict the user's state. The user's state is built on the basis of their emotional state and intention and it is recognized by means of a module conceived as an intermediate phase between natural language understanding and dialog management in the architecture of the conversational agent. This prediction carried out for each user turn in the dialog makes it possible to adapt the system dynamically to the user's needs. We have evaluated our proposal developing a context-aware system adapted to patients suffering from chronic pulmonary diseases and provide a detailed discussion of the positive influence of our proposal in the success of the interaction the information and services provided as well as the perceived quality.;2014
Ambient Intelligence systems require a natural and personalized experience in interacting with services provided by the environment. In this view the interaction may happen either in a pervasive way through a combination of devices embedded in the environment or using a conversational interface acting as an environment concierge. In the latter case the interface can be embodied in a conversational agent able to involve users in a human-like conversation and to establish a social relation with them. Developing such an Ambient Conversational System (ACS) requires a model of the user that considers not only the cognitive ingredients of his mental state but also extra-rational factors such as affect engagement attitudes. This paper describes a multimodal framework for recognizing the social attitude of users during the interaction with an embodied agent in a smart environment. In particular we started from the analysis and annotation of advisory dialogs between humans and then we used the annotated corpus to build a framework for recognizing the social attitude in multimodal dialogs with an ACS. Results of the study show an acceptable performance of the framework in recognizing and monitoring the social attitude during the dialog with anACS. We also compared results of the analysis of human-human interactions with respect to the human-ACS interaction and even if the level of initiative of subjects during the dialog was lower in this lattermodality the difference in the average number of social moves was not significant thus showing that subjects probably were keen to establish a social relation with the conversational agent.;2014
Attackers employ artificial machine-operated social network profiles called socialbots to connect to real members of an organization thus greatly increasing the amount of information the attacker can collect. To connect socialbots attackers employ several strategies. The authors' approach detects socialbots by intelligently selecting organization member profiles and monitoring their activity. Their study demonstrates their method's efficacy specifically that when an attacker knows the defense strategy being deployed the most effective attack is randomly sprayed friend requests which eventually lead to a low number of connections.;2014
BACKGROUND AND OBJECTIVES: Interactive voice response systems integrated with electronic health records have the potential to improve primary care by engaging parents outside clinical settings via spoken language. The objective of this study was to determine whether use of an interactive voice response system the Personal Health Partner (PHP) before routine health care maintenance visits could improve the quality of primary care visits and be well accepted by parents and clinicians. METHODS: English-speaking parents of children aged 4 months to 11 years called PHP before routine visits and were randomly assigned to groups by the system at the time of the call. Parents' spoken responses were used to provide tailored counseling and support goal setting for the upcoming visit. Data were transferred to the electronic health records for review during visits. The study occurred in an urban hospital-based pediatric primary care center. Participants were called after the visit to assess (1) comprehensiveness of screening and counseling (2) assessment of medications and their management and (3) parent and clinician satisfaction. RESULTS: PHP was able to identify and counsel in multiple areas. A total of 9.7% of parents responded to the mailed invitation. Intervention parents were more likely to report discussing important issues such as depression (42.6% vs 25.4% P < .01) and prescription medication use (85.7% vs 72.6% P = .04) and to report being better prepared for visits. One hundred percent of clinicians reported that PHP improved the quality of their care. CONCLUSIONS: Systems like PHP have the potential to improve clinical screening counseling and medication management.;2014
Background: Automated health behavior change interventions show promise but suffer from high attrition and disuse. The Internet abounds with thousands of personal narrative accounts of health behavior change that could not only provide useful information and motivation for others who are also trying to change but an endless source of novel entertaining stories that may keep participants more engaged than messages authored by interventionists. Objective: Given a collection of relevant personal health behavior change stories gathered from the Internet the aim of this study was to develop and evaluate an automated indexing algorithm that could select the best possible story to provide to a user to have the greatest possible impact on their attitudes toward changing a targeted health behavior in this case weight loss. Methods: An indexing algorithm was developed using features informed by theories from behavioral medicine together with text classification and machine learning techniques. The algorithm was trained using a crowdsourced dataset then evaluated in a 2x2 between-subjects randomized pilot study. One factor compared the effects of participants reading 2 indexed stories vs 2 randomly selected stories whereas the second factor compared the medium used to tell the stories: text or animated conversational agent. Outcome measures included changes in self-efficacy and decisional balance for weight loss before and after the stories were read. Results: Participants were recruited from a crowdsourcing website (N=103 53.4% 55/103 female mean age 35 SD 10.8 years 65.0% 67/103 precontemplation 19.4% 20/103 contemplation for weight loss). Participants who read indexed stories exhibited a significantly greater increase in self-efficacy for weight loss compared to the control group (F-1F-107=5.5 P=.02). There were no significant effects of indexing on change in decisional balance (F-1F-97=0.05 P=.83) and no significant effects of medium on change in self-efficacy (F-1F-107=0.04 P=.84) or decisional balance (F-1F-97=0.78 P=.38). Conclusions: Personal stories of health behavior change can be harvested from the Internet and used directly and automatically in interventions to affect participant attitudes such as self-efficacy for changing behavior. Such approaches have the potential to provide highly tailored interventions that maximize engagement and retention with minimal intervention development effort.;2014
Conversational recommender systems are E-Commerce applications which interactively assist online users to acquire their interaction goals during their sessions. In our previous work we have proposed and validated a methodology for conversational systems which autonomously learns the particular web page to display to the user at each step of the session. We employed reinforcement learning to learn an optimal strategy i.e. one that is personalized for a real user population. In this paper we extend our methodology by allowing it to autonomously learn and update the optimal strategy dynamically (at run-time) and individually for each user. This learning occurs perpetually after every session as long as the user continues her interaction with the system. We evaluate our approach in an off-line simulation with four simulated users as well as in an online evaluation with thirteen real users. The results show that an optimal strategy is learnt and updated for each real and simulated user. For each simulated user the optimal behavior is reasonably adapted to this user's characteristics but converges after several hundred sessions. For each real user the optimal behavior converges only in several sessions. It provides assistance only in certain situations allowing many users to buy several products together in shorter time and with more page-views and lesser number of query executions. We prove that our approach is novel and show how its current limitations can catered.;2014
Embodied conversational agents (ECA) are a type of intelligent multimodal computer interface that allow computers to interact with humans in a face-to-face manner. It is quite feasible that ECAs will someday replace the common keyboard as a human-computer interface. However we have much to understand about how people interact with such embodied virtual agents. In this study we performed a laboratory experiment in an airport screening context to assess how people's linguistic behavior changes with their perceptions of the ECA's power and likeability. The results show that people tend to manifest more verbal immediacy and expressivity as well as offer more information about themselves with ECAs they perceive as more likeable and less powerful.;2014
Embodied conversational agents still do not achieve the fluidity and smoothness of natural conversational interaction. One main reason is that current system often respond with big latencies and in inflexible ways. We argue that to overcome these problems real-time conversational agents need to be based on an underlying architecture that provides two essential features for fast and fluent behavior adaptation: a close bi-directional coordination between input processing and output generation and incrementality of processing at both stages. We propose an architectural framework for conversational agents [Artificial Social Agent Platform (ASAP)] providing these two ingredients for fluid real-time conversation. The overall architectural concept is described along with specific means of specifying incremental behavior in BML and technical implementations of different modules. We show how phenomena of fluid real-time conversation like adapting to user feedback or smooth turn-keeping can be realized with ASAP and we describe in detail an example real-time interaction with the implemented system.;2014
Endowing artificial conversational agents with personality is a very promising way to obtain more believable user interactions with robots and computers. However although many authors have studied how to create an agent's personality and how it affects performance and user satisfaction less attention has been paid to assess whether the designed agent's personality corresponds to the users' perception whether it is easily recognizable and what is the effect that the user's own personality has in the discrimination of the agents' personality. In this paper we present an assessment framework to address these issues in an integrated way which in our opinion offers enough flexibility to consider the diversity of application domains and evaluation approaches that can be found in the literature. The framework is based on numerical measures which facilitate the interpretation of results and makes it possible to compare and rank different agents with respect to the user's perception of the rendered personality. In addition we have developed a tool that implements the framework which may be very useful for researchers in order to easily evaluate different agent personalities. (C) 2014 Elsevier Ltd. All rights reserved.;2014
In developing speech recognition based services for any task domain it is necessary to account for the support of an increasing number of languages over the life of the service. This paper considers a small vocabulary speech recognition task in multiple Indian languages. To configure a multi-lingual system in this task domain an experimental study is presented using data from two linguistically similar languages Hindi and Marathi. We do so by training a subspace Gaussian mixture model (SGMM) (Povey et al. 2011 Rose et al. 2011) under a multi-lingual scenario (Burget et al. 2010 Mohan et al. 2012a). Speech data was collected from the targeted user population to develop spoken dialogue systems in an agricultural commodities task domain for this experimental study. It is well known that acoustic channel and environmental mismatch between data sets from multiple languages is an issue while building multi-lingual systems of this nature. As a result we use a cross-corpus acoustic normalization procedure which is a variant of speaker adaptive training (SAT) (Mohan et al. 2012a). The resulting multi-lingual system provides the best speech recognition performance for both languages. Further the effect of sharing similar context-dependent states from the Marathi language on the Hindi speech recognition performance is presented. (C) 2013 Elsevier B.V. All rights reserved.;2014
In spoken dialog systems dialog state tracking refers to the task of correctly inferring the user's goal at a given turn given all of the dialog history up to that turn. The Dialog State Tracking Challenge is a research community challenge task that has run for three rounds. The challenge has given rise to a host of new methods for dialog state tracking and also to deeper understanding about the problem itself including methods for evaluation.;2014
In this paper we consider transcripts which originated from a practical series of Turing's Imitation Game that was held on June 23 2012 at Bletchley Park U.K. In some cases the tests involved a three-participant simultaneous comparison of two hidden entities whereas others were the result of a direct two-participant interaction. Each of the transcripts considered here resulted in a human interrogator being fooled by a machine into concluding that they had been conversing with a human. Particular features of the conversation are highlighted successful ploys on the part of each machine are discussed and likely reasons for the interrogator being fooled are considered. Subsequent feedback from the interrogators involved is also included.;2014
In this study we highlight the theoretical underpinnings of human impression management tactics and link them to current research in embodied conversational agents. Specifically we incorporated impression management behaviors into an embodied conversational agent in order to show that different influence strategies affect user perceptions and how those perceptions might be moderated by user gender. We programmed the agent to use two human impression management techniques (ingratiation and self-promotion) and had the agent interact with 88 users. After the interaction users reported their perceptions of the system's power trustworthiness expertise and attractiveness. The impression management techniques altered users' perceptions and these perceptions were moderated by gender differences. (C) 2014 Elsevier Ltd. All rights reserved.;2014
Intangible cultural heritage represents the cultural identities and diversity of mankind and should be preserved and passed on to the current and future generations. However in digital cultural heritage research intangible cultural heritage has been relatively less studied and the focus has been placed on creating tools and applications for professionals rather than for the general public. In this paper we present our research effort on creating an interactive system for conveying traditional Chinese culture through natural language conversation. We propose a systematic method for the domain experts to construct with minimal effort the knowledge base from a set of unstructured philosophy texts and we design an algorithm to build a conversational agent emulating the conversation ability of a famous Chinese philosopher. We also report two evaluation studies on the prototype we developed showing encouraging results on the feasibility and benefits of our approach. By automating part of the answer-finding task using natural language processing and information retrieval technology the system is able to find answers dynamically without the need to manually author large amounts of question and answer pairs. Our proposed method could potentially be used to create other conversational agents for educating and promoting cultural values to the general public in a natural and appealing way.;2014
Learning is facilitated by conversational interactions both with human tutors and with computer agents that simulate human tutoring and ideal pedagogical strategies. In this article we describe some intelligent tutoring systems (e.g. AutoTutor) in which agents interact with students in natural language while being sensitive to their cognitive and emotional states. These systems include one-on-one tutorial dialogues conversational trialogues in which two agents (a tutor and a peer) interact with a human student and other conversational ensembles in which agents take on different roles. Tutorial conversations with agents have also been incorporated into educational games. These learning environments have been developed for different populations (elementary through high school students college students adults with reading difficulties) and different subjects spanning science technology engineering mathematics reading writing and reasoning. This article identifies some of the conversation patterns that are implemented in the dialogues and trialogues.;2014
Merging Immersive Virtual Environments Natural Language Processing and Artificial Intelligence techniques provides a number of advantages to develop Intelligent Environments for multiple applications. This paper is focused on the application of these technologies to develop intelligent learning environments. Education is one of the most interesting applications of immersive virtual environments as their flexibility can be exploited in order to create heterogeneous groups from all over the world who can collaborate synchronously in different virtual spaces. We highlight the potential of virtual worlds as an educative tool and propose a model to create learning environments within Second Life or OpenSimulator combining the Moodle learning management system embodied conversational metabots and programmable 3D objects. Our proposal has been applied in several subjects of the Computer Science degree in the Carlos III University of Madrid. The results of the evaluation show that developed learning environment fosters engagement and collaboration and helps students to better understand complex concepts.;2014
Multimodal interfaces incorporating embodied conversational agents enable the development of novel concepts with regard to interaction management tactics in responsive human-machine interfaces. Such interfaces provide several additional nonverbal communication channels such as natural visualized speech facial expression and different body motions. In order to simulate reactive humanlike communicative behavior and attitude the realization of motion relies on different behavioral analyses and realization tactics and approaches. This article proposes a novel environment for online visual modeling of humanlike communicative behavior named EVA-framework. In this study we focus on visual speech and nonverbal behavior synthesis by using hierarchical XML-based behavioral events and expressively adjustable motion templates. The main goal of the presented abstract motion notation scheme named EVA-Script is to enable the synthesis of unique and responsive behavior.;2014
One of the most fundamental research questions in the field of human-machine interaction is how to enable dialogue systems to capture the meaning of spontaneously produced linguistic inputs without explicit syntactic expectations. This paper introduces a cognitively-inspired representational model intended to address this research question. To the extent that this model is cognitively-inspired it integrates insights from behavioral and neuroimaging studies on working memory operations and language-impaired patients (i.e. Broca's aphasics). The level of detail contained in the specification of the model is sufficient for a computational implementation while the level of abstraction is sufficient to enable generalization of the model over different interaction domains. Finally the paper reports on a domain-independent framework for end-user programming of adaptive dialogue management modules. (C) 2014 Elsevier B.V. All rights reserved.;2014
Overcoming speech recognition errors in the field of human-computer interaction is important in ensuring a consistent user experience. This paper proposes a semantic-oriented post-processing approach for the correction of errors in speech recognition. The novelty of the model proposed here is that it re-ranks the n-best hypothesis of speech recognition based on the user's intention which is analyzed from previous discourse information while conventional automatic speech recognition systems focus only on acoustic and language model scores for the current sentence. The proposed model successfully reduces the word error rate and semantic error rate by 3.65% and 8.61% respectively.;2014
Purpose: Adolescents report high asthma-related morbidity that can be prevented by adequate self-management of the disease. Therefore there is a need for a developmentally appropriate strategy to promote effective asthma self-management. Mobile phone-based technology is portable commonly accessible and well received by adolescents. The purpose of this study was to develop and evaluate the feasibility and acceptability of a comprehensive mobile phone-based asthma self-management aid for adolescents (mASMAA) that was designed to facilitate symptom monitoring treatment adherence and adolescent-parent partnership. The system used state-of-the-art natural language-understanding technology that allowed teens to use unconstrained English in their texts and to self-initiate interactions with the system. Materials and methods: mASMAA was developed based on an existing natural dialogue system that supports broad coverage of everyday natural conversation in English. Fifteen adolescent-parent dyads participated in a 2-week trial that involved adolescents' daily scheduled and unscheduled interactions with mASMAA and parents responding to daily reports on adolescents' asthma condition automatically generated by mASMAA. Subsequently four focus groups were conducted to systematically obtain user feedback on the system. Frequency data on the daily usage of mASMAA over the 2-week period were tabulated and content analysis was conducted for focus group interview data. Results: Response rates for daily text messages were 81%-97% in adolescents. The average number of self-initiated messages to mASMAA was 19 per adolescent. Symptoms were the most common topic of teen-initiated messages. Participants concurred that use of mASMAA improved awareness of symptoms and triggers promoted treatment adherence and sense of control and facilitated adolescent-parent partnerships. Conclusion: This study demonstrates the utility and user acceptability of mASMAA as a potential asthma self-management tool in a selective group of adolescents. Further research is needed to replicate the findings in a large group of adolescents from sociodemographically diverse backgrounds to validate the findings.;2014
Speech and hand gestures offer the most natural modalities for everyday human-to-human interaction. The availability of diverse spoken dialogue applications and the proliferation of accelerometers on consumer electronics allow the introduction of new interaction paradigms based on speech and gestures. Little attention has been paid however to the manipulation of spoken dialogue systems (SDS) through gestures. Situation-induced disabilities or real disabilities are determinant factors that motivate this type of interaction. In this paper six concise and intuitively meaningful gestures are proposed that can be used to trigger the commands in any SDS. Using different machine learning techniques a classification error for the gesture patterns of less than 5 % is achieved and the proposed set of gestures is compared to ones proposed by users. Examining the social acceptability of the specific interaction scheme high levels of acceptance for public use are encountered. An experiment was conducted comparing a button-enabled and a gesture-enabled interface which showed that the latter imposes little additional mental and physical effort. Finally results are provided after recruiting a male subject with spastic cerebral palsy a blind female user and an elderly female person.;2014
Speech interfaces within Intelligent Environments (IEs) must be rendered adaptive to external and internal factors among those the complexity of the dialogue. Hence we present HIS-OwlSpeak a model-driven dialogue manager for Intelligent Environments. It meets the challenges arising from engineering IEs by providing a unified platform comprising adaptivity to a variety of internal and external factors. This work addresses internal adaptivity realized by different modes of dialogue control i.e. rule-based and probabilistic. For this the Hidden Information State (HIS) approach - featuring inherent handling of uncertainty in dialogue systems - is applied to a model-driven solely rule-based dialogue manager. It uses ontologies to specify the dialogue thus separating the specification from the dialogue control. Consequently all necessary aspects for merging the world of model-driven dialogue management with the HIS approach are presented in detail. Furthermore the system has been evaluated using two concurrent dialogues of different complexity successfully validating the implementation.;2014
Spoken dialogue systems are increasingly being used to facilitate and enhance human communication. While these interactive systems can process the linguistic aspects of human communication they are not yet capable of processing the complex dynamics involved in social interaction such as the adaptation on the part of interlocutors. Providing interactive systems with the capacity to process and exhibit this accommodation could however improve their efficiency and make machines more socially-competent interactants. At present no automatic system is available to process prosodic accommodation nor do any clear measures exist that quantify its dynamic manifestation. While it can be observed to be a monotonically manifest property it is our hypotheses that it evolves dynamically with functional social aspects. In this paper we propose an automatic system for its measurement and the capture of its dynamic manifestation. We investigate the evolution of prosodic accommodation in 41 Japanese dyadic telephone conversations and discuss its manifestation in relation to its functions in social interaction. Overall our study shows that prosodic accommodation changes dynamically over the course of a conversation and across conversations and that these dynamics inform about the naturalness of the conversation flow the speakers' degree of involvement and their affinity in the conversation. (C) 2013 Elsevier B.V. All rights reserved.;2014
This article contributes to the ecolinguistic research agenda in two ways: first it introduces a distinct ecological approach to intricacies of intercultural interaction emphasizing the multiple voices subjectivities and historicities that meet and mesh in such encounters. Second it introduces an ecological model of timescales that allows ecological language scientists to adopt a naturalized position in order to show how temporal patterns crisscross complex empirical data the key word is that of temporal ranges i.e. ranges of timescales constrained by the same organizing principle. Using this model we describe a principled method for extracting temporal patterns historicities and sociocultural voices in complex empirical data. Our example is another Thanksgiving dinner (cf. Tannen 1984) where a German a Russian and two Japanese women interact in a US context. Our analysis shows how past events (e.g. the spread of the Ottoman Empire Germany and Japan during World War II Russian-American relations during the cold war and the election of cardinal Joseph Ratzinger as pope in 2005) become powerful constraints on the interactional dynamics between the interlocutors as they use these events to project and mold their dialogical and social identities vis-a-vis each other and the researcher. At the end of the article we present an ecological view on identity and we discuss the role of the researcher in an ecological paradigm. (C) 2013 Elsevier Ltd. All rights reserved.;2014
This article describes an evaluation of a POMDP-based spoken dialogue system (SDS) using crowdsourced calls with real users. The evaluation compares a Hidden Information State POMDP system which uses a hand-crafted compression of the belief space with the same system instead using an automatically computed belief space compression. Automatically computed compressions are a way of introducing automation into the design process of statistical SDSs and promise a principled way of reducing the size of the very large belief spaces which often make POMDP approaches intractable. This is the first empirical comparison of manual and automatic approaches on a problem of realistic scale (restaurant pub and coffee shop domain) with real users. The evaluation took 2193 calls from 85 users. After filtering for minimal user participation the two systems were compared on more than 1000 calls. (C) 2013 Elsevier Ltd. All rights reserved.;2014
This article presents two studies conducted with an affective dialogue system in which text-based system-user communication was used to model generate and present different affective and social interaction scenarios. We specifically investigated the influence of interaction context and roles assigned to the system and the participants as well as the impact of pre-structured social interaction patterns that were modelled to mimic aspects of social exclusion scenarios. The results of the first study demonstrate that both the social context of the interaction and the roles assigned to the system influence the system evaluation interaction patterns textual expressions of affective states as well as emotional self-reports. The results observed for the second study show the system's ability to partially exclude a participant from a triadic conversation without triggering significantly different affective reactions or a more negative system evaluation. The experimental evidence provides insights on the perception modelling and generation of affective and social cues in artificial systems that can be realized in different modalities including the text modality thus delivering valuable input for applying affective dialogue systems as tools for studying affect and social aspects in online communication.;2014
This paper addresses issues of automatically detecting significant dialog events (SDEs) in naturalistic HCI and of deducing trait-specific conclusions relevant for the design of spoken dialog systems. We perform our investigations on the multimodal LAST MINUTE corpus with records from naturalistic interactions. First we used textual transcripts to analyse interaction styles and discourse structures. We found indications that younger subjects prefer a more technical style in communication with dialog systems. Next wemodel the subject's internal success state with a hidden Markov model trained using the observed sequences of system feedback. This reveals that younger subjects interact significantly more successful with technical systems. Aiming on automatic detection of specific subjects's reactions we then semi-automatically annotate SDEs-phrases indicating an irregular i.e. not-task-oriented subject behavior. We use both acoustic and linguistic features to build several trait-specific classifiers for dialog phases which showed pronouncedly different accuracies for diverse age and gender groups. The presented investigations coherently support age-dependence of both expressiveness and problem-solving ability. This in turn induces design rules for future automatic designated companion systems.;2014
This paper describes the design and evaluation of a method for developing a chat-oriented dialog system by utilizing real human-to-human conversation examples from movie scripts and Twitter conversations. The aim of the proposed method is to build a conversational agent that can interact with users in as natural a fashion as possible while reducing the time requirement for database design and collection. A number of the challenging design issues we faced are described including (1) constructing an appropriate dialog corpora from raw movie scripts and Twitter data and (2) developing an multi domain chat-oriented dialog management system which can retrieve a proper system response based on the current user query. To build a dialog corpus we propose a unit of conversation called a tri-turn (a trigram conversation turn) as well as extraction and semantic similarity analysis techniques to help ensure that the content extracted from raw movie/drama script files forms appropriate dialog-pair (query-response) examples. The constructed dialog corpora are then utilized in a data-driven dialog management system. Here various approaches are investigated including example-based (EBDM) and response generation using phrase-based statistical machine translation (SMT). In particular we use two EBDM: syntactic-semantic similarity retrieval and TF-IDF based cosine similarity retrieval. Experiments are conducted to compare and contrast EBDM and SMT approaches in building a chat-oriented dialog system and we investigate a combined method that addresses the advantages and disadvantages of both approaches. System performance was evaluated based on objective metrics (semantic similarity and cosine similarity) and human subjective evaluation from a small user study. Experimental results show that the proposed filtering approach effectively improve the performance. Furthermore the results also show that by combing both EBDM and SMT approaches we could overcome the shortcomings of each.;2014
This paper is a continuation of the work [26] in which the LND dialogue system was proposed. LND reconstructs the dialogical logic introduced by Lorenzen using the terminology of persuasion dialogue games as specified by Prakken [18]. The aim of the LND system is to recognize formal fallacies in natural dialogues and remove them. Now we extend this system to include a new protocol enabling the reconstruction of natural dialogues in which parties can commit formal fallacies. We then present the implementation of the protocols applied.;2014
This paper presents a dialogue system called Lorenzen-Hamblin Natural Dialogue (LHND) in which participants can commit formal fallacies and have a method of both identifying and withdrawing formal fallacies. It therefore provides a tool for the dialectical evaluation of force of argument when players advance reasons which are deductively incorrect. The system is inspired by Hamblin's formal dialectic and Lorenzen's dialogical logic. It offers uniform protocols for Hamblin's and Lorenzen's dialogues and adds a protocol for embedding them. This unification required a reformulation of the original description of Lorenzen's system to distinguish between different stances that a person might take in the discussion as suggested by Hodges. The LHND system is compared to Walton and Krabbe's Complex Persuasion Dialogue using an example of a dialogue.;2014
This paper presents a novel Semantic-Based Conversational Agent (SCA). Traditional conversational agents (CA) interpret scripts consisting of structural patterns of sentences which take no consideration of semantic content. The script writer must therefore anticipate the many variations of input the user may respond with during dialogue. This is evidently a high maintenance task. Furthermore different script writers possess differing levels of skill and as such this can prove to be an exasperating task. The proposed SCA interprets scripts consisting of natural language sentences by means of a semantic sentence similarity measure. User input is measured semantically against the natural language sentences of the current context in order to respond with an appropriate output string. Such scripting is effortless and alleviates the burden of the traditional pattern-scripted languages. Experiments have involved the use of script writers to demonstrate the use of the language. Results have highlighted the potential of the language and shown improvements on traditional pattern-scripted languages.;2014
This paper presents an experimental study that analyzes how conversational agents activate human communication in thought-evoking multi-party dialogues between multi-users and multi-agents. A thought-evoking dialogue is a kind of interaction in which agents act to provoke user thinking and it has the potential to activate multi-party interactions. This paper focuses on quiz-style multi-party dialogues between two users and two agents as an example of thought-evoking multi-party dialogues. The experimental results revealed that the presence of a peer agent significantly improved user satisfaction and increased the number of user utterances in quiz-style multi-party dialogues. We also found that agents' empathic expressions significantly improved user satisfaction improved user ratings of the peer agent and increased the number of user utterances. Our findings should be useful for activating multi-party communications in various applications such as pedagogical agents and community facilitators.;2014
This paper presents the design and evaluation of the multipurpose platform for domestic ambient media research and applications through an improved method called wizard-of-oz. Inspired by the increasing requirements for the reuse of valuable development work in intelligent ambient media system and service design we propose a different approach to construct a high-level pseudo platform to support flexible and cost-economic prototype mock-up and test. Based on the platform three incremental ambient media applications were developed for empirical studies and a number of studies were carried out to assess the applicability effectiveness and reusability of this platform within domestic settings. The results showed that this platform has great advantages over conventional systems specifically developed for ambient media research in above aspects. Also the results have provided secondary understanding in the design of future ambient media applications for domestic use including the guidelines for the design of domestic smart conversational system interfaces and user interactions with ambient media.;2014
This paper proposes a domain-independent statistical methodology to develop dialog managers for spoken dialog systems. Our methodology employs a data-driven classification procedure to generate abstract representations of system turns taking into account the previous history of the dialog. A statistical framework is also introduced for the development and evaluation of dialog systems created using the methodology which is based on a dialog simulation technique. The benefits and flexibility of the proposed methodology have been validated by developing statistical dialog managers for four spoken dialog systems of different complexity designed for different languages (English Italian and Spanish) and application domains (from transactional to problem-solving tasks). The evaluation results show that the proposed methodology allows rapid development of new dialog managers as well as to explore new dialog strategies which permit developing new enhanced versions of already existing systems. (C) 2013 Elsevier Ltd. All rights reserved.;2014
This paper proposes a two-phase reanalysis model for understanding user intention in utterances by considering the correlative characteristics between the three attributes relating to user intention. The proposed model comprises two phases. In the first phase each attribute is analyzed in the optimized sequence. The results of the analysis are then used as features that undergo reanalysis in the second phase with the assumption that the relationship between the attributes is correlative. The experiments conducted showed that the proposed model improves user intention analysis over the baseline model with an error reduction rate in Speech Act Concept Sequence and Arguments of 0.64% 14.78% and 5.84% respectively. (C) 2014 Published by Elsevier B.V.;2014
This paper reports on the linguistic accuracy of five renowned chatbots with an evaluator (an ESL teacher) chatting with each chatbot for about three hours. The chatting consisted of a series of set questions/statements (determined as being in the domain of an ESL learner) - aimed at assessing the accuracy and felicity of the chatbots' answers at the grammatical level. Results indicate that chatbots are generally able to provide grammatically acceptable answers with three chatbots returning acceptability figures in the 90% range. When meaning is factored in however a different picture emerges with the chatbots often providing meaningless nonsensical answers and the accuracy rate for the joint categories of grammar and meaning falling below 60%. The paper concludes on the note that although chatbots as conversation practice machines do not yet make robust chatting partners improvements in chatbot performance bode well for future developments.;2014
To provide a spoken interaction between robots and human users an internal representation of the robots sensory information must be available at a semantic level and accessible to a dialogue system in order to be used in a human-like and intuitive manner. In this paper we integrate the fields of perceptual anchoring (which creates and maintains the symbol-percept correspondence of objects) in robotics with multimodal dialogues in order to achieve a fluent interaction between humans and robots when talking about objects. These everyday objects are located in a so-called symbiotic system where humans robots and sensors are co-operating in a home environment. To orchestrate the dialogue system the IrisTK dialogue platform is used. The IrisTK system is based on modelling the interaction of events between different modules e.g. speech recognizer face tracker etc. This system is running on a mobile robot device which is part of a distributed sensor network. A perceptual anchoring framework recognizes objects placed in the home and maintains a consistent identity of the objects consisting of their symbolic and perceptual data. Particular effort is placed on creating flexible dialogues where requests to objects can be made in a variety of ways. Experimental validation consists of evaluating the system when many objects are possible candidates for satisfying these requests.;2014
To reduce lengthy and rigid interactions of menu-driven navigation and keyword searches dialogue systems based on a natural language interface have been developed. Domain action classification is an essential part of a dialogue system because speakers' intentions are determined through the classification process. Although a domain action consists of a tightly associated speech act and a concept sequence previous studies have independently dealt with speech acts and concept sequences in order to simplify the models and this simplification has caused a decrease in performance. A retraining method for improving the domain action classification performance is proposed in order to resolve this problem. The proposed method divides a domain action classification model into a speech act classification model and a concept sequence classification model. The speech act classification model repeatedly uses concept sequence classification model outputs as inputs during training. In the experiments with goal-oriented dialogues the proposed method exhibited a higher accuracy of 0.6% and higher macro F1-measure of 1.7% compared to the SVM and ME models that dealt with speech acts and concept sequences separately. Based on the experimental results it was determined that the proposed method can improve the performance of some representative machine learning models for domain action classification. (C) 2014 Elsevier B.V. All rights reserved.;2014
Traditional dialogue systems use a fixed silence threshold to detect the end of users' turns. Such a simplistic model can result in system behaviour that is both interruptive and unresponsive which in turn affects user experience. Various studies have observed that human interlocutors take cues from speaker behaviour such as prosody syntax and gestures to coordinate smooth exchange of speaking turns. However little effort has been made towards implementing these models in dialogue systems and verifying how well they model the turn-taking behaviour in human computer interactions. We present a data-driven approach to building models for online detection of suitable feedback response locations in the user's speech. We first collected human computer interaction data using a spoken dialogue system that can perform the Map Task with users (albeit using a trick). On this data we trained various models that use automatically extractable prosodic contextual and lexico-syntactic features for detecting response locations. Next we implemented a trained model in the same dialogue system and evaluated it in interactions with users. The subjective and objective measures from the user evaluation confirm that a model trained on speaker behavioural cues offers both smoother turn-transitions and more responsive system behaviour. (C) 2014 Elsevier Ltd. All rights reserved.;2014
Virtual agents are a real asset in collaborative virtual environment for training (CVET) as they can replace missing team members. Collaboration between such agents and users however is generally limited. We present here a whole integrated model of CVET focusing on the abstraction of the real or virtual nature of the actor to define a homogenous collaboration model. First we define a new collaborative model of interaction. This model notably allows to abstract the real or virtual nature of a teammate. Moreover we propose a new role exchange approach so that actors can swap their roles during training. The model also permits the use of physically based objects and characters animation to increase the realism of the world. Second we design a new communicative agent model which aims at improving collaboration with other actors using dialog to coordinate their actions and to share their knowledge. Finally we evaluated the proposed model to estimate the resulting benefits for the users and we show that this is integrated in existing CVET applications. Copyright (c) 2014 John Wiley & Sons Ltd.;2014
We address the problem of dynamically modeling and adapting to unknown users in resource-scarce domains in the context of interactive spoken dialogue systems. As an example we show how a system can learn to choose referring expressions to refer to domain entities for users with different levels of domain expertise and whose domain knowledge is initially unknown to the system. We approach this problem using a three-step process: collecting data using a Wizard-of-Oz method building simulated users and learning to model and adapt to users using Reinforcement Learning techniques. We show that by using only a small corpus of non-adaptive dialogues and user knowledge profiles it is possible to learn an adaptive user modeling policy using a sense-predict-adapt approach. Our evaluation results show that the learned user modeling and adaptation strategies performed better in terms of adaptation than some simple hand-coded baseline policies with both simulated and real users. With real users the learned policy produced around a 20% increase in adaptation in comparison to an adaptive hand-coded baseline. We also show that adaptation to users' domain knowledge results in improving task success (99.47% for the learned policy vs. 84.7% for a hand-coded baseline) and reducing dialogue time of the conversation (11% relative difference). We also compared the learned policy with a variety of carefully hand-crafted adaptive policies that use the user knowledge profiles to adapt their choices of referring expressions throughout a conversation. We show that the learned policy generalizes better to unseen user profiles than these hand-coded policies while having comparable performance on known user profiles. We discuss the overall advantages of this method and how it can be extended to other levels of adaptation such as content selection and dialogue management and to other domains where adapting to users' domain knowledge is useful such as travel and healthcare.;2014
We developed a virtual counseling system which can deliver brief alcohol health interventions via a 3D anthropomorphic speech-enabled interface-a new field for spoken dialog interactions with intelligent virtual agents in the health domain. We present our spoken dialog system design and its evaluation. We developed our dialog system based on Markov decision processes framework and optimized it by using reinforcement learning algorithms with data we collected from real user interactions. The system begins to learn optimal dialog strategies for initiative selection and for the type of confirmations that it uses during the interaction. We compared the unoptimized system with the optimized system in terms of objective measures (e.g. task completion) and subjective measures (e.g. ease of use future intention to use the system) and obtained positive results.;2014
We present a computational model of incremental grounding including state updates and action selection. The model is inspired by corpus-based examples of overlapping utterances of several sorts including backchannels and completions. The model has also been partially implemented within a virtual human system that includes incremental understanding and can be used to track grounding and provide overlapping verbal and non-verbal behaviors from a listener before a speaker has completed her utterance.;2014
We present and evaluate a novel approach to natural language generation (NLG) in statistical spoken dialogue systems (SDS) using a data-driven statistical optimization framework for incremental information presentation (IP) where there is a trade-off to be solved between presenting enough information to the user while keeping the utterances short and understandable. The trained IP model is adaptive to variation from the current generation context (e. g. a user and a non-deterministic sentence planner) and it incrementally adapts the IP policy at the turn level. Reinforcement learning is used to automatically optimize the IP policy with respect to a data-driven objective function. In a case study on presenting restaurant information we show that an optimized IP strategy trained on Wizard-of-Oz data outperforms a baseline mimicking the wizard behavior in terms of total reward gained. The policy is then also tested with real users and improves on a conventional hand-coded IP strategy used in a deployed SDS in terms of overall task success. The evaluation found that the trained IP strategy significantly improves dialogue task completion for real users with up to a 8.2% increase in task success. This methodology also provides new insights into the nature of the IP problem which has previously been treated as a module following dialogue management with no access to lower-level context features (e. g. from a surface realizer and/or speech synthesizer).;2014
We present work on understanding natural language in a situated domain in an incremental word-by-word fashion. We explore a set of models specified as Markov Logic Networks and show that a model that has access to information about the visual context during an utterance its discourse context the words of the utterance as well as the linguistic structure of the utterance performs best and is robust to noisy speech input. We explore the incremental properties of the models and offer some analysis. We conclude that MLNS provide a promising framework for specifying such models in a general possibly domain-independent way. (C) 2013 Elsevier Ltd. All rights reserved.;2014
We report progress towards developing a sensor module that categorizes types of laughter for application in dialogue systems or social-skills training situations. The module will also function as a component to measure discourse engagement in natural conversational speech. This paper presents the results of an analysis into the sounds of human laughter in a very large corpus of naturally occurring conversational speech and our classification of the laughter types according to social function. Various types of laughter were categorized into either polite or genuinely mirthful categories and the analysis of these laughs forms the core of this report. Statistical analysis of the acoustic features of each laugh was performed and a Principal Component Analysis and Classification Tree analysis were performed to determine the main contributing factors in each case. A statistical model was then trained using a Support Vector Machine to predict the most likely category for each laugh in both speaker-specific and speaker-independent manner. Better than 70% accuracy was obtained in automatic classification tests. Crown Copyright (C) 2013 Published by Elsevier Ltd. All rights reserved.;2014
Whilst common sense knowledge has been well researched in terms of intelligence and (in particular) artificial intelligence specific factual knowledge also plays a critical part in practice. When it comes to testing for intelligence testing for factual knowledge is in every-day life frequently used as a front line tool. This paper presents new results which were the outcome of a series of practical Turing tests held on 23rd June 2012 at Bletchley Park England. The focus of this paper is on the employment of specific knowledge testing by interrogators. Of interest are prejudiced assumptions made by interrogators as to what they believe should be widely known and subsequently the conclusions drawn if an entity does or does not appear to know a particular fact known to the interrogator. The paper is not at all about the performance of machines or hidden humans but rather the strategies based on assumptions of Turing test interrogators. Full unedited transcripts from the tests are shown for the reader as working examples. As a result it might be possible to draw critical conclusions with regard to the nature of human concepts of intelligence in terms of the role played by specific factual knowledge in our understanding of intelligence whether this is exhibited by a human or a machine. This is specifically intended as a position paper firstly by claiming that practicalising Turing's test is a useful exercise throwing light on how we humans think and secondly by taking a potentially controversial stance because some interrogators adopt a solipsist questioning style of hidden entities with a view that it is a thinking intelligent human if it thinks like them and knows what they know. The paper is aimed at opening discussion with regard to the different aspects considered.;2014
A new dialogue management model for affective dialogue system which aims to provide a service of information inquiry and affective interaction is proposed in this paper. First we construct two finite state machines (TFSM) to model the user and the system respectively and simulate the dialogue process as an information exchange between the two state machines. All possible state transitions in dialogue and its probabilities of the user are summarized as a user model which is helpful for the system to inference and predict the user's internal states. Second we further discuss the implementation methods of information inquiry and emotional response modules. Finally we employ the return function of partially observable Markov decision processes (POMDP) model to analyze and evaluate the TFSM-based dialogue management model. The experimental results not only show the relationships between the average returns recognition error rates and state transition probabilities but also confirm that our TFSM-based dialogue management model outperforms the conventional FSM model. (c) 2015 Institute of Electrical Engineers of Japan. Published by John Wiley & Sons Inc.;2015
A new grid load frequency control approach is proposed for the doubly fed induction generator based wind power plants. The load frequency control issue in a power system is undergoing fundamental changes due to the rapidly growing amount of wind energy conversation system and concentrating on maintaining generation-load balance and disturbance rejection. The prominent feature of the linear active disturbance rejection control approach is that the total disturbance can be estimated and then eliminated in real time. And thus it is a feasible solution to deal with the load frequency control issue. In this paper the application of the linear active disturbance rejection control approach in the load frequency control issue for a complex power system with wind energy conversation system based on doubly fed induction generator is investigated. The load frequency control issue is formulated as a decentralized multi-objective optimization control problem the solution to which is solved by the hybrid particle swarm optimization technique. To show the effectiveness of the proposed control scheme the robust performance testing based on Monte-Carlo approach is carried out. The performance superiority of the system with the proposed linear active disturbance rejection control approach over that with the traditional proportional integral and fuzzy-proportional integral-based controllers is validated by the simulation results. (C) 2015 Elsevier Ltd. All rights reserved.;2015
Affective Computing aims at improving the naturalness of human-computer interactions by integrating the socio-emotional component in the interaction. The use of embodied conversational agents (ECAs) - virtual characters interacting with humans - is a key answer to this issue. On the one hand the ECA has to take into account the human emotional behaviours and social attitudes. On the other hand the ECA has to display socio-emotional behaviours with relevance. In this paper we provide an overview of computational methods used for user's socio-emotional behaviour analysis and of human-agent interaction strategies by questioning the ambivalent status of surprise. We focus on the computational models and on the methods we use to detect user's emotion through language and speech processing and present a study investigating the role of surprise in the ECA's answer.;2015
Alignment is a phenomenon observed in human conversation: Dialog partners' behavior converges in many respects. Such alignment has been proposed to be automatic and the basis for communicating successfully. Recent research on human-computer dialog promotes a mediated communicative design account of alignment according to which the extent of alignment is influenced by interlocutors' beliefs about each other. Our work aims at adding to these findings in two ways. (a) Our work investigates alignment of manual actions instead of lexical choice. (b) Participants interact with the iCub humanoid robot instead of an artificial computer dialog system. Our results confirm that alignment also takes place in the domain of actions. We were not able to replicate the results of the original study in general in this setting but in accordance with its findings participants with a high questionnaire score for emotional stability and participants who are familiar with robots align their actions more to a robot they believe to be basic than to one they believe to be advanced. Regarding alignment over the course of an interaction the extent of alignment seems to remain constant when participants believe the robot to be advanced but it increases over time when participants believe the robot to be a basic version.;2015
Appropriate turn-taking is important in spoken dialogue systems as well as generating correct responses. Especially if the dialogue features quick responses a user utterance is often incorrectly segmented due to short pauses within it by voice activity detection (VAD). Incorrectly segmented utterances cause problems both in the automatic speech recognition (ASR) results and turn-taking: i.e. an incorrect VAD result leads to ASR errors and causes the system to start responding though the user is still speaking. We develop a method that performs a posteriori restoration for incorrectly segmented utterances and implement it as a plug-in for the MMDAgent open-source software. A crucial part of the method is to classify whether the restoration is required or not. We cast it as a binary classification problem of detecting originally single utterances from pairs of utterance fragments. Various features are used representing timing prosody and ASR result information. Experiments show that the proposed method outperformed a baseline with manually-selected features by 4.8% and 3.9% in cross-domain evaluations with two domains. More detailed analysis revealed that the dominant and domain-independent features were utterance intervals and results from the Gaussian mixture model (GMM).;2015
Augmented reality augmented television and second screen are cutting edge technologies that provide end users extra and enhanced information related to certain events in real time. This enriched information helps users better understand such events at the same time providing a more satisfactory experience. In the present paper we apply this main idea to human-robot interaction (HRI) to how users and robots interchange information. The ultimate goal of this paper is to improve the quality of HRI developing a new dialog manager system that incorporates enriched information from the semantic web. This work presents the augmented robotic dialog system (ARDS) which uses natural language understanding mechanisms to provide two features: (i) a non-grammar multimodal input (verbal and/or written) text and (ii) a contextualization of the information conveyed in the interaction. This contextualization is achieved by information enrichment techniques that link the extracted information from the dialog with extra information about the world available in semantic knowledge bases. This enriched or contextualized information (information enrichment semantic enhancement or contextualized information are used interchangeably in the rest of this paper) offers many possibilities in terms of HRI. For instance it can enhance the robot's pro-activeness during a human-robot dialog (the enriched information can be used to propose new topics during the dialog while ensuring a coherent interaction). Another possibility is to display additional multimedia content related to the enriched information on a visual device. This paper describes the ARDS and shows a proof of concept of its applications.;2015
Autonomous robots are increasingly interacting with users who have limited knowledge of robotics and are likely to have an erroneous mental model of the robot's workings capabilities and internal structure. The robot's real capabilities may diverge from this mental model to the extent that one might accuse the robot's manufacturer of deceiving the user especially in cases where the user naturally tends to ascribe exaggerated capabilities to the machine (e.g. conversational systems in elder-care contexts or toy robots in child care). This poses the question whether misleading or even actively deceiving the user of an autonomous artifact about the capabilities of the machine is morally bad and why. By analyzing trust autonomy and the erosion of trust in communicative acts as consequences of deceptive robot behavior we formulate four criteria that must be fulfilled in order for robot deception to be morally permissible and in some cases even morally indicated.;2015
BACKGROUND: Chronic pain is a serious health problem given its prevalence associated disability impact on quality of life and the costs associated with the extensive use of health care services by individuals living with it. OBJECTIVE: To summarize the research evidence and elicit health system policymakers' stakeholders' and researchers' tacit knowledge and views about improving chronic pain management in Canada and engaging provincial and territorial health system decision makers in supporting comprehensive chronic pain management in Canada. METHODS: For these two topics the global and local research evidence regarding each of the two problems were synthesized in evidence briefs. Three options were generated for addressing each problem and implementation considerations were assessed. A stakeholder dialogue regarding each topic was convened (with 29 participants in total) and the deliberations were synthesized. RESULTS: To inform the first stakeholder dialogue the authors found that systematic reviews supported the use of evidence-based tools for strengthening chronic pain management including patient education self-management supports interventions to implement guidelines and multidisciplinary approaches to pain management. While research evidence about patient registries/treatment-monitoring systems is limited many dialogue participants argued that a registry/system is needed. Many saw a registry as a precondition for moving forward with other options including creating a national network of chronic pain centres with a coordinating 'hub' to provide chronic pain-related decision support and a cross-payer cross-discipline model of patient-centred primary health care-based chronic pain management. For the second dialogue systematic reviews indicated that traditional media can be used to positively influence individual health-related behaviours and that multistakeholder partnerships can contribute to increasing attention devoted to issues on policy agendas. Dialogue participants emphasized the need to mobilize behind an effort to build a national network that would bring together existing organizations and committed individuals. CONCLUSIONS: Developing a national network and thereafter a national pain strategy are important initiatives that garnered broad-based support during the dialogues. Efforts toward achieving this goal have been made since convening the dialogues.;2015
Background: Systems and tools are needed to identify and mitigate preconception health (PCH) risks particularly for African American (AA) women given persistent health disparities. We developed and tested Gabby an online preconception conversational agent system. Methods: One hundred nongravid AA women 18-34 years of age were screened for over 100 PCH risks and randomized to the Gabby or control group. The Gabby group interacted with the system for up to six months the control group received a letter indicating their health risks with a recommendation to talk with their clinician. The numbers proportions and types of risks were compared between groups. Results: There were 23.7 (SD 5.9) risks identified per participant. Eighty-five percent (77 of 91) provided 6 month follow up data. The Gabby group had greater reductions in the number (8.3 vs. 5.5 risks P < .05) and the proportion (27.8% vs 20.5% P < 0.01) of risks compared to controls. The Gabby group averaged 63.7 minutes of interaction time. Seventy-eight percent reported that it was easy to talk to Gabby and 64% used information from Gabby to improve their health. Conclusion: Gabby was significantly associated with preconception risk reduction. More research is needed to determine if Gabby can benefit higher risk populations and if risk reduction is clinically significant.;2015
Based on a philosophy of integrating components from multimodal interaction applications with 3D graphical environments reusing already defined markup language for describing graphics graphical and spoken interactions based on the interactive movie metaphor a markup language for modeling scenes behavior and interaction is sought. With the definition of this language we hope to have a common framework for developing applications that allow multimodal interaction at 3D stages. Thus we have defined the basis of an architecture that allows us to integrate the components of such multimodal interaction applications in 3D virtual environments.;2015
Building on literature related to selling and embodied conversational agents (ECA) this research seeks to determine how the use of an ECA might improve users' perceptions of shopping value (hedonic and utilitarian) and the consequences for theft purchase intentions and satisfaction with the website. This analysis focuses specifically on three ECA usage consequences: playfulness decision quality and social presence. Hedonic value mediates the effects of playfulness and social presence on satisfaction and behavioral intentions utilitarian shopping value mediates the effects of decision quality. The results highlight the importance of accounting for both utilitarian and hedonic features to understand ECA outputs in e-commerce sites. (C) 2015 Elsevier Ltd. All rights reserved;2015
Children have been increasingly becoming active users of the Internet and although any segment of the population is susceptible to falling victim to the existing risks they in particular are one of the most vulnerable. Thus some of the major scourges of this cyber society are paedophile behaviours on the Internet child pornography or sexual exploitation of children. In light of this background Negobot is a conversational agent posing as a child in chats social networks and other channels suffering from paedophile behaviour. As a conversational agent Negobot has a strong technical base of Natural Language Processing and information retrieval as well as Artificial Intelligence and Machine Learning. However the most innovative proposal of Negobot is to consider the conversation itself as a game applying game theory. In this context Negobot proposes first a competitive game in which the system identifies the best strategies for achieving its goal to obtain information that leads us to infer if the subject involved in a conversation with the agent has paedophile tendencies while our actions do not bring the alleged offender to leave the conversation due to a suspicious behaviour of the agent.;2015
Counseling for information technology (IT) personnel lies at the intersection between the software development ecosystem where IT employees collaborate professionally and the social ecosystem where they communicate with each other to share the success or handle the failure of software development. Today counseling has become a major issue in the IT industry since the success rate of IT system development projects is as low as 30 % and more than 60 % of IT professionals suffer from anxiety or other emotional problems. This paper describes a conversational agent aiming to replace human counselors assisting IT personnel in software development ecosystems toward future deployment to social ecosystems. Utilizing IT domain ontology knowledge our agent automatically adapts the vocabulary used in its responses according to the context and to the current phase of the conversation. Using context-based reflection support knowledge the agent generates its response consisting of (1) chatterbot-like mirroring/rewording for context sharing and (2) newly proposed context-respectful mechanism of prompts for context narrowing/digging to help a client discover problems and become aware of their solutions via deep reflections of IT personnel undergoing counseling. Knowledge focusing on a single domain such as IT counseling domain and context-based/context-respectful reflection allow our counseling agent to work properly without having to acquire and manage a huge amount of knowledge. Experimental results show that clients interact with our agent on average two times longer than they do with ELIZA-style conversational agents also a questionnaire-based validation has shown the average value of questionnaire's result was agree side for our agent but disagree side for ELIZA-style conversational agents. Therefore the user acceptance level of our agent is much higher than that of conventional chatterbots.;2015
Due to the mobile Internet revolution people tend to browse the Web while driving their car which puts the driver's safety at risk. Therefore an intuitive and non-distractive in-car speech interface to the Web needs to be developed. Before developing a new speech dialog system (SDS) in a new domain developers have to examine the user's preferred interaction style and its influence on driving safety. This paper reports a driving simulation study which was conducted to compare different speech-based in-car human machine interface concepts concerning usability and driver distraction. The applied SDS prototypes were developed to perform an online hotel booking by speech while driving. The speech dialog prototypes were based on different speech dialog strategies: a command-based and a conversational dialog. Different graphical user interface (GUI) concepts (one including a human-like avatar) were designed in order to support the respective dialog strategy the most and to evaluate the effect of the GUI on usability and driver distraction. The results show that only few differences concerning speech dialog quality were found when comparing the speech dialog strategies. The command-based dialog was slightly better accepted than the conversational dialog which seems to be due to the high concept error rate of the conversational dialog. A SDS without GUI also seems to be feasible for the driving environment and was accepted by the users. The comparison of speech dialog strategies did not reveal differences in driver distraction. However the use of a GUI impaired the driving performance and increased gaze-based distraction. The presence of an avatar was not appreciated by participants and did not affect the dialog performance. Concerning driver distraction the virtual agent did neither negatively affect the driving performance nor increase visual distraction. The results implicate that in-car SDS developers should take both speaking styles into consideration when designing an SDS for information exchange tasks. Furthermore developers have to consider reducing the content presented on the screen in order to reduce driver distraction. A human-like avatar was not appreciated by users while driving. Research should further investigate if other kinds of avatars might achieve different results. (C) 2015 Elsevier Ltd. All rights reserved.;2015
Excessive daytime somnolence (EDS) is defined as the inability to stay awake in daily life activities. Several scales have been used to diagnose excessive daytime sleepiness the most widely used being the Epworth Sleepiness Scale (ESS). Sleep disorders and EDS are very common in the general population. It is therefore important to be able to screen patients for this symptom in order to obtain an accurate diagnosis of sleep disorders. Embodied Conversational Agents (ECA) have been used in the field of affective computing and human interactions but up to now no software has been specifically designed to investigate sleep disorders. We created an ECA able to conduct an interview based on the ESS and compared it to an interview conducted by a sleep specialist. We recruited 32 consecutive patients and a group of 30 healthy volunteers free of any sleep complaints. The ESS is a self-administered questionnaire that asks the subject to rate (with a pen and paper paradigm) his or her probability of falling asleep. For the purpose of our study the ECA or real-doctor questionnaire was modified as follows: Instead of the I'' formulate questions were asked as Do you.'' Our software is based on a common 3D game engine and several commercial software libraries. It can run on standard and affordable hardware products. The sensitivity and specificity of the interview conducted by the ECA were measured. The best results (sensibility and specificity >98%) were obtained to discriminate the sleepiest patients (ESS >= 16) but very good scores (sensibility and specificity > 80%) were also obtained for alert subjects (ESS< 8). ESS scores obtained in the interview conducted by the physician were significantly correlated with ESS scores obtained in the interview the ECA conducted. Most of the subjects had a positive perception of the virtual physician and considered the interview with the ECA as a good experience. Sixty-five percent of the participants felt that the virtual doctor could significantly help real physicians. Our results show that a virtual physician can conduct a very simple interview to evaluate EDS with very similar results to those obtained by a questionnaire administered by a real physician. The expected massive increase in sleep complaints in the near future likely means that more and more physicians will be looking for computerized systems to help them to diagnose their patients.;2015
Expressive speech synthesis has received increased attention in recent times. Stress (or pitch accent) is the perceptual prominence within words or utterances which contributes to the expressivity of speech. This paper summarizes our contribution to Mandarin expressive speech synthesis. A novel hierarchical stress modeling and generation method for Mandarin is proposed and further integrated into HMM-based speech synthesis (HTS) and Fujisaki model-based speech synthesis systems to accurately model the undulation of pitch contour. In HMM-based expressive speech synthesis stress-related contextual features obtained from the hierarchical model are introduced in modeling the prosodic variation caused by stress in addition to the traditional prosodic features used in HTS. A rule-based and a Deep Belief Network based prosodic variation models are proposed and then used in stress adaptation module in HTS. The other approach uses the Fujisaki model to improve the expressiveness of synthetic speech. The hierarchical stress model is introduced into the phrase and tone command control mechanisms of the model. The pitch contour is then directly generated by the superposition of two-level commands of the Fujisaki model. Experimental results using the proposed hierarchical stress modeling and generation methods showed that the macro- and microcharacteristics of stress could be successfully captured. The methodology proposed in this paper has application to a range of areas such as conveying attitude and indicating focus in spoken dialog systems. (C) 2015 Elsevier B.V. All rights reserved.;2015
In developed country such as Japan aging has become a serious issue as there is a disproportionate increasing of elderly population who are no longer able to look after themselves. In order to tackle this issue we introduce human-friendly robot partner to support the elderly people in their daily life. However to realize this it is essential for the robot partner to be able to have a natural communication with the human. This paper proposes a new communication framework between the human and robot partner based on relevance theory as the basis knowledge. The relevance theory is implemented to build mutual cognitive environment between the human and the robot partner namely as the informationally structured space (ISS). Inside the ISS robot partner employs both verbal as well as non-verbal communication to understand human. For the verbal communication Rasmussen's behavior model is implemented as the basis for the conversational system. While for the non-verbal communication environmental and human state data along with gesture recognition are utilized. These data are used as the perceptual input to compute the robot partner's emotion. Experimental results have shown the effectiveness of our proposed communication framework in establishing natural communication between the human and the robot partner. (C) 2015 Elsevier Ltd. All rights reserved.;2015
In terms of functional conversations Grice's Maxim of Quantity suggests that responses should contain no more information than was explicitly asked for. However in our daily conversations more informative response skills are usually employed in order to hold enjoyable conversations with interlocutors. These responses are usually produced as forms of one's additional opinions which usually contain their original viewpoints as well as novel means of expression rather than simple and common responses characteristic of the general public. In this paper we propose automatic expressive opinion sentence generation mechanisms for enjoyable conversational systems. The generated opinions are extracted from a large number of reviews on the web and ranked in terms of contextual relevance length of sentences and amount of information represented by the frequency of adjectives. The sentence generator also has an additional phrasing skill. Three controlled lab experiments were conducted where subjects were requested to read generated sentences and watch videos filmed about conversations between the robot and a person. The results implied that mechanisms effectively promote users' enjoyment and interests.;2015
In the whole world the proportion of aged population is increasing day by day. To fulfill Confucius' philosophy of treat others' elderly and youth as if they are our family members we proposed an intelligent web-based agent which is able to conduct daily life conversation with the elders. Based on psychological theory we classify the participants of the experiment into three types using K-means. A decision tree is trained based on the information gain during the process of classification. We also implemented a web-based software agent which is visually alive and is able to interact with the elders through visual and audio context. Such agent can be accessed virtually from any location on the planet and is able to have conversation and interaction with the elders to keep them from being bored. The trained decision tree serves as the brain of the web-based agent to classify the type of the elders as the conversation goes on and provide the appropriate questions or choices for the human-machine interaction. Through large-scale experiments we found that the combination of web-based agent and the trained decision tree works satisfactorily for the purpose of care-giving to the elderly.;2015
In this paper we address issues in situated language understanding in a moving car which has the additional challenge of being a rapidly changing environment. More specifically we propose methods for understanding user queries regarding specific target buildings in their surroundings. Unlike previous studies on physically situated interactions such as interactions with mobile robots the task at hand is very time sensitive because the spatial relationship between the car and target changes while the user is speaking. We collected situated utterances from drivers using our research system called Townsurfer which was embedded in a real vehicle. Based on this data we analyzed the timing of user queries the spatial relationships between the car and the targets the head pose of the user and linguistic cues. Based on this analysis we further propose methods to optimize timing and spatial distances and to make use of linguistic cues. Finally we demonstrate that our algorithms improved the target identification rate by 24.1% absolute. (C) 2015 Elsevier Ltd. All rights reserved.;2015
In this paper we present a probabilistic framework for goal-driven spoken dialog systems. A new dynamic stochastic state (DS-state) is then defined to characterize the goal set of a dialog state at different stages of the dialog process. Furthermore an entropy minimization dialog management (EMDM) strategy is also proposed to combine with the DS-states to facilitate a robust and efficient solution in reaching a user's goals. A song-on-demand task with a total of 38 117 songs and 12 attributes corresponding to each song is used to test the performance of the proposed approach. In an ideal simulation assuming no errors the EMDM strategy is the most efficient goal-seeking method among all tested approaches returning the correct song within 3.3 dialog turns on average. Furthermore in a practical scenario with top five candidates to handle the unavoidable automatic speech recognition (ASR) and natural language understanding (NLU) errors the results show that only 61.7% of the dialog goals can be successfully obtained in 6.23 dialog turns on average when random questions are asked by the system whereas if the proposed DS-states are updated with the top five candidates from the SLU output using the proposed EMDM strategy executed at every DS-state then a 86.7% dialog success rate can be accomplished effectively within 5.17 dialog turns on average. We also demonstrate that entropy-based DM strategies are more efficient than non-entropy based DM. Moreover using the goal set distributions in EMDM the results are better than those without them such as in sate-of-the-art database summary DM.;2015
Loneliness and social isolation are significant problems in older adult populations. We describe the design of a multimodal conversational agent-based system designed to provide longitudinal social support to isolated older adults. Results from a requirements analysis study and a remote Wizard-of-Oz study are presented that inform the design of the autonomous social support agent. An exploratory pilot study was conducted in which the agent was placed in the homes of 14 older adults for a week. Results indicate high levels of acceptance and satisfaction of the system. Results also indicate that when the agent proactively draws elders into interactions triggered by a motion sensor it is more effective at addressing loneliness than when the agent passively relies upon elders to initiate interactions. We discuss future research opportunities for affective computing to address this important societal problem.;2015
Most studies on dialogue corpora as well as most dialogue systems employ dialogue acts as the basic units for interpreting discourse structure user input and system actions. The definition of the discourse structure and the dialogue strategy consequently require the tagging of dialogue corpora in terms of dialogue acts. The tagging problem presents two basic variants: a batch variant (annotation of whole dialogues in order to define dialogue strategy or study discourse structure) and an online variant (decoding of the dialogue act sequence of a given turn in order to interpret user intentions). In the two variants is unusual having the segmentation of each turn into the dialogue meaningful units (segments) to which a dialogue act is assigned. In this paper we present the use of the N-Gram Transducer technique for tagging dialogues without needing to provide a prior segmentation in these two different variants (dialogue annotation and turn decoding). Experiments were performed in two corpora of different nature and results show that N-Gram Transducer models are suitable for these tasks and provide good performance.;2015
Natural language processing employs computational techniques for the purpose of learning understanding and producing human language content. Early computational approaches to language research focused on automating the analysis of the linguistic structure of language and developing basic technologies such as machine translation speech recognition and speech synthesis. Today's researchers refine and make use of such tools in real-world applications creating spoken dialogue systems and speech-to-speech translation engines mining social media for information about health or finance and identifying sentiment and emotion toward products and services. We describe successes and challenges in this rapidly advancing area.;2015
Recently the focus of many novel search applications has shifted from short keyword queries to verbose natural language queries. Examples include question answering systems and dialogue systems voice search on mobile devices and entity search engines like Facebook's Graph Search or Google's Knowledge Graph. However the performance of textbook information retrieval techniques for such verbose queries is not as good as that for their shorter counterparts. Thus effective handling of verbose queries has become a critical factor for adoption of information retrieval techniques in this new breed of search applications. Over the past decade the information retrieval community has deeply explored the problem of transforming natural language verbose queries using operations like reduction weighting expansion reformulation and segmentation into more effective structural representations. However thus far there was not a coherent and organized survey on this topic. In this survey we aim to put together various research pieces of the puzzle provide a comprehensive and structured overview of various proposed methods and also list various application scenarios where effective verbose query processing can make a significant difference.;2015
Research on computer-supported collaborative learning (CSCL) and conversational pedagogical agents has strongly emphasized the value of providing dynamic dialogue support for learners working together to accomplish a certain task. Recently on the basis of the classroom discourse framework of Academically Productive Talk (APT) a flexible form of conversational agent support has emerged employing APT-based intervention methods so as to stimulate pedagogically beneficial conversational interactions among learning partners. This paper investigates the impact of an APT-based Linking Contributions (LC) intervention mode implemented by a conversational agent in the context of a collaborative activity in higher education. This type of agent interventions encourages students to explicitly externalize their reasoning on important domain concepts building upon the contributions of their partners. Forty-three (43) students collaborated in small groups using a prototype CSCL system to accomplish three different tasks in the domain of Multimedia Learning. Groups were randomly assigned to the treatment or the control condition. In the treatment condition a conversational agent participated in students' dialogues making LC mode interventions. In the control condition students discussed without the agent intervening. The results of the study illustrated that the students in the treatment condition engaged in a more productive dialogue demonstrating increased explicit reasoning throughout the collaborative activity. Furthermore it was shown that the students in the treatment condition outperformed the control students in various measures on knowledge acquisition. Evidence also suggests that students' enhanced learning performance was mediated by the positive effect of the agent intervention mode on students' argumentation. Overall this study provides insights into how the use of a configurable conversational agent displaying unsolicited LC interventions during students' discourse can be beneficial to collaborative learning. (C) 2015 Elsevier Ltd. All rights reserved.;2015
Speech-act classification is essential to generation and understanding of utterances within a natural language dialogue system since the speech-act of an utterance is closely tied to a user intention. The binary feature weighting scheme has mainly been used for speech-act classification because traditional feature weighting schemes such as tf.idf are not effective in speech-act classification due to the short length of utterances. This paper studies two effective feature weighting schemes using the category distributions of features: (1) the first one exploits the entropy of whole category distributions and (2) the second one the log-odds ratio of positive and negative category distributions. As a result the proposed schemes show significant improvement on SVM and k-NN classifiers in our experiments. (C) 2014 Elsevier B.V. All rights reserved;2015
Spoken dialog systems have been proposed as a solution to facilitate a more natural human-machine interaction. In this paper we propose a framework to model the user's intention during the dialog and adapt the dialog model dynamically to the user needs and preferences thus developing more efficient adapted and usable spoken dialog systems. Our framework employs statistical models based on neural networks that take into account the history of the dialog up to the current dialog state in order to predict the user's intention and the next system response. We describe our proposal and detail its application in the Let's Go spoken dialog system. (C) 2015 Elsevier B.V. All rights reserved.;2015
The ability to recognize the visual focus of attention (VFOA i.e. what or whom a person is looking at) of people is important for robots or conversational agents interacting with multiple people since it plays a key role in turn-taking engagement or intention monitoring. As eye gaze estimation is often impossible to achieve most systems currently rely on head pose as an approximation creating ambiguities since the same head pose can be used to look at different VFOA targets. To address this challenge we propose a dynamic Bayesian model for the VFOA recognition from head pose where we make two main contributions. First taking inspiration from behavioral models describing the relationships between the body head and gaze orientations involved in gaze shifts we propose novel gaze models that dynamically and more accurately predict the expected head orientation used for looking in a given gaze target direction. This is a neglected aspect of previous works but essential for recognition. Secondly we propose to exploit the robot conversational state (when he speaks objects to which he refers) as context to net appropriate priors on candidate VFOA targets and reduce the inherent VFOA ambiguities. Experiments on a public dataset where the humanoid robot NAO plays the role of an art guide and quiz master demonstrate the benefit of the two contributions. (C) 2014 Elsevier B.V. All rights reserved.;2015
The design and operating principles of an interactive system of semantic processing i.e. understanding the meaning of scientific and technical texts on chemical technology of reagents and ultrapure substances have been presented. Understanding of the meaning of scientific and technical texts has been implemented through the development of intelligent software of a dialogue system which includes semantic and topological models of knowledge representation as well as special languages of the automated generation of meaning. Understanding of the basic terms concepts and phrases in the limited natural language of the problem area has been presented in the form of the internal representation of the knowledge and language of control directives.;2015
The goal of addressee detection is to answer the question Are you talking to me? When a dialogue system interacts with multiple users it is crucial to detect when a user is speaking to the system as opposed to another person. We study this problem in a multimodal scenario using lexical acoustic visual dialogue state and beamforming information. Using data from a multiparty dialogue system we quantify the benefits of using multiple modalities over using a single modality. We also assess the relative importance of the various modalities as well as of key individual features in estimating the addressee. We find that energy-based acoustic features are by far the most important that information from speech recognition and system state is useful as well and that visual and beamforming features provide little additional benefit. While we find that head pose is affected by whom the speaker is addressing it yields little nonredundant information due to the system acting as a situational attractor. Our findings would be relevant to multiparty open-world dialogue systems in which the agent plays an active conversational role such as an interactive assistant deployed in a public open space. For these scenarios our study suggests that acoustic lexical and system-state information is an effective and practical combination of modalities to use for addressee detection. We also consider how our analyses might be affected by the ongoing development of more realistic natural dialogue systems.;2015
The growth of speech interfaces and speech interaction with computer partners has made it increasingly important to understand the factors that determine users' language choices in human computer dialogue. We report two controlled experiments that used a picture-naming-matching task to investigate whether users in human computer speech-based interactions tend to use the same grammatical structures as their conversational partners and whether such syntactic alignment can impact strong default grammatical preferences. We additionally investigate whether beliefs about system capabilities that are based on partner identity (i.e. human or computer) and speech interface design cues (here voice anthropomorphism) affect the magnitude of syntactic alignment in such interactions. We demonstrate syntactic alignment for both dative structures (e.g. give the waitress the apple vs. give the apple to the waitress) where there is no strong default preference for one or other structure (Experiment 1) and noun phrase structures (e.g. a purple circle vs. a circle that is purple) where there is a strong default preference for one structure (Experiment 2). The tendency to align syntactically was unaffected by partner identity (human vs. computer) or voice anthropomorphism. These findings have both practical and theoretical implications for HCI by demonstrating the potential for spoken dialogue system behaviour to influence users' syntactic choices in interaction. As well as verifying natural corpora findings this work also highlights that priming and cognitive mechanisms that are unmediated by beliefs about partner identity could be important in understanding why people align syntactically in human - computer dialogue. (C) 2015 Elsevier Ltd. All rights reserved.;2015
The impact of simulated embodied agent emotion has been explored in short-term studies but no work to date has examined its impact in longer interactions that involve multiple interactions with agents. We present an embodied agent (Rachael) that simulates a health professional and attempts to help people improve their fruit and vegetable consumption. Emotional and unemotional versions of the agent were developed to examine how user perceptions of the agent changed over an intervention period of 49 days and in turn how this influenced fruit and vegetable consumption. Results found that whilst participants consumed more daily portions of fruit and vegetables over the intervention period and reduced their consumption gains post-intervention there was no significant difference in consumption gains over time between those who interacted with the emotional or unemotional agents. Qualitative feedback however highlighted a strong preference for the emotional agent. A novelty effect was also observed where the agents were perceived more positively initially and less so over time.;2015
This article takes the concept and some of the existing applications of socialbots-software robots that operate on social networking sites and present themselves as human users-as an occasion to trace the evolution of online sociality. The argument mobilizes theories of social rationalization from Max Weber to contemporary critical theory to demonstrate that the appearance of automated profiles (socialbots) on social networking platforms can be seen as a logical step in the progressive enclosure of online social interaction in standardized simplified and trivialized forms frames and gestures. Critical questions concerning what the growth of robo-sociality may mean for individual users and the online public sphere are posed with a view to charting the directions for a needed public debate.;2015
This paper introduces a generative model of voice fundamental frequency (F-0) contours that allows us to extract prosodic features from raw speech data. The present F-0 contour model is formulated by translating the Fujisaki model a well-founded mathematical model representing the control mechanism of vocal fold vibration into a probabilistic model described as a discrete-time stochastic process. There are two motivations behind this formulation. One is to derive a general parameter estimation framework for the Fujisaki model that allows the introduction of powerful statistical methods. The other is to construct an automatically trainable version of the Fujisaki model that we can incorporate into statistical-model-based text-to-speech synthesizers in such a way that the Fujisaki-model parameters can be learned from a speech corpus in a unified manner. It could also be useful for other speech applications such as emotion recognition speaker identification speech conversion and dialogue systems in which prosodic information plays a significant role. We quantitatively evaluated the performance of the proposed Fujisaki model parameter extractor using real speech data. Experimental results revealed that our method was superior to a state-of-the-art Fujisaki model parameter extractor.;2015
This paper investigates some conditions under which polarized user appraisals gathered throughout the course of a vocal interaction between a machine and a human can be integrated in a reinforcement learning-based dialogue manager. More specifically we discuss how this information can be cast into socially-inspired rewards for speeding up the policy optimisation for both efficient task completion and user adaptation in an online learning setting. For this purpose a potential-based reward shaping method is combined with a sample efficient reinforcement learning algorithm to offer a principled framework to cope with these potentially noisy interim rewards. The proposed scheme will greatly facilitate the system's development by allowing the designer to teach his system through explicit positive/negative feedbacks given as hints about task progress in the early stage of training. At a later stage the approach will be used as a way to ease the adaptation of the dialogue policy to specific user profiles. Experiments carried out using a state-of-the-art goal-oriented dialogue management framework the Hidden Information State (HIS) support our claims in two configurations: firstly with a user simulator in the tourist information domain (and thus simulated appraisals) and secondly in the context of man-robot dialogue with real user trials. (C) 2015 Elsevier Ltd. All rights reserved.;2015
This paper presents some important issues on misidentification of human interlocutors in text-based communication during practical Turing tests. The study here presents transcripts in which human judges succumbed to theconfederate effect misidentifying hidden human foils for machines. An attempt is made to assess the reasons for this. The practical Turing tests in question were held on 23 June 2012 at Bletchley Park England. A selection of actual full transcripts from the tests is shown and an analysis is given in each case. As a result of these tests conclusions are drawn with regard to the sort of strategies which can perhaps lead to erroneous conclusions when one is involved as an interrogator. Such results also serve to indicate conversational directions to avoid for those machine designers who wish to create a conversational entity that performs well on the Turing test.;2015
This paper presents uses a data-driven approach to improve Spoken Dialog System (SDS) performance by automatically finding the most appropriate terms to be used in system prompts. The literature shows that speakers use one another's terms (entrain) when trying to create common ground during a spoken dialog. Those terms are commonly called primes since they influence the interlocutors' linguistic decision-making. This approach emulates human interaction with a system built to propose primes to the user and accept the primes that the user proposes. These primes are chosen on the fly during the interaction based on a set of features that indicate good candidate primes. A good candidate is one that we know is easily recognized by the speech recognizer and is also a normal word choice given the context. The system is trained to follow the user's choice of prime if system performance is not negatively affected. When system performance is affected the system proposes a new prime. In our previous work we have shown how we can identify the prime candidates and how the system can select primes using rules. In this paper we go further presenting a data-driven method to perform the same task. Live tests with this method show that use of on-the-fly entrainment reduces out-of-vocabulary and word error rate and also increases the number of correctly transferred concepts. (C) 2014 Elsevier Ltd. All rights reserved.;2015
This paper proposes a technique to improve the performance of spoken dialogue systems that not only consider knowledge about the semantic frames used by systems to understand the spoken language but also employ knowledge about the words in the system application domain that are used to complete frame slots. Using both knowledge sources the technique considers specific word sequences to form what we call word-islands and which are then employed to create the language models and dictionary used by the system's speech recogniser. Word-islands are easier to recognise than the words comprising the islands which leads to improved spoken language understanding and system performance. Experiments have been conducted using two spoken dialogue systems which had previously been developed in our lab: one to provide fast food information and the other to provide bus travel information. Results show that the proposed technique improves the performance of both systems by improving speech recognition and spoken language understanding of sentence types that are difficult to process. (C) 2015 Elsevier B.V. All rights reserved.;2015
This paper proposes an emotion transplantation method capable of modifying a synthetic speech model through the use of CSMAPLR adaptation in order to incorporate emotional information learned from a different speaker model while maintaining the identity of the original speaker as much as possible. The proposed method relies on learning both emotional and speaker identity information by means of their adaptation function from an average voice model and combining them into a single cascade transform capable of imbuing the desired emotion into the target speaker. This method is then applied to the task of transplanting four emotions (anger happiness sadness and surprise) into 3 male speakers and 3 female speakers and evaluated in a number of perceptual tests. The results of the evaluations show how the perceived naturalness for emotional text significantly favors the use of the proposed transplanted emotional speech synthesis when compared to traditional neutral speech synthesis evidenced by a big increase in the perceived emotional strength of the synthesized utterances at a slight cost in speech quality. A final evaluation with a robotic laboratory assistant application shows how by using emotional speech we can significantly increase the students' satisfaction with the dialog system proving how the proposed emotion transplantation system provides benefits in real applications. (C) 2015 Elsevier Ltd. All rights reserved.;2015
This paper reports on judgement studies regarding the perception of interpersonal stances taken by humans playing the role of a suspect in a police interrogation setting. Our project aims at building believable embodied conversational characters to play the role of suspects in a serious game for learning interrogation strategies. The main question we ask is: do human judges agree on the way they perceive the various aspects of stance taking such as friendliness and dominance? Four types of stances were acted by eight amateur actors. Short recordings were shown in an online survey to subjects who were asked to describe them using a selection of a number of adjectives. Results of this annotation task are reported in this paper. We explain how we computed the inter-rater agreement with Krippendorff's alpha statistics using a set theoretical distance metric. Results show that for some of the stance types observers agreed more than for others. Some actors are better than others but validity (recognizing the intended stance) and inter-rater agreement do not always go hand in hand. We further investigate the effect the expertise of actors has on the perception of the stance that is acted. We compare the fragments from amateur actors to fragments from professional actors taken from popular TV-shows.;2015
This study analyzed how communication changes when people communicate with an intelligent agent as opposed to with another human. We compared 100 instant messaging conversations to 100 exchanges with the popular chatbot Cleverbot along seven dimensions: words per message words per conversation messages per conversation word uniqueness and use of profanity shorthand and emoticons. A MANOVA indicated that people communicated with the chatbot for longer durations (but with shorter messages) than they did with another human. Additionally human-chatbot communication lacked much of the richness of vocabulary found in conversations among people and exhibited greater profanity. These results suggest that while human language skills transfer easily to human-chatbot communication there are notable differences in the content and quality of such conversations. (C) 2015 Elsevier Ltd. All rights reserved.;2015
This study presents a novel expert-based approach to assess the quality of ongoing Spoken Dialog System (SDS) interactions. We call this approach Interaction Quality (IQ). It is an objective measure which relies on statistical classification with Support Vector Machines (SVMs). We compare objective expert IQ annotations of ongoing SDS interactions with subjective User Satisfaction (US) ratings and show that IQ and US correlate (rho =.66). Expert annotations obviously mirror the subjective user impression to a great extent while they are above all much easier to obtain. The IQ score that quantifies the quality of the interaction is generated using the median score of exchange annotations of several experts. US is tracked in a study with 38 users interacting with an SDS. A large comprehensive set of domain-independent automatic interaction parameters is introduced to quantify the interaction at arbitrary dialog exchanges. Furthermore a manually annotated negative emotion feature is added to the parameter set in order to evaluate the contribution of emotions on the classification of IQ and US. For evaluation we use the CMU Let's Go bus information system. The model yields a correlation of rho = .80 when classifying IQ scores annotated in field data from the CMU system. Furthermore the model achieves p =.74 for predicting US on lab data and rho =.89 for IQ on lab data. The presented approach outperforms related studies in the field. Only a marginal contribution of the emotion feature to the performance can be observed implying that US is not influenced by visible emotions. We analyze causalities and correlations between the interaction parameters and the target variables US/IQ and identify relevant predictors. With the presented paradigm critical dialogs can be found once deployed as an online monitoring technique this paradigm could render SDSs more user friendly and improve user acceptance. (C) 2015 Elsevier B.V. All rights reserved.;2015
We address a spoken dialogue system which conducts information navigation in a style of small talk. The system uses Web news articles as an information source and the user can receive information about the news of the day through interaction. The goal and procedure of this kind of dialogue are not well defined. An empirical approach based on a partially observable Markov decision process (POMDP) has recently been widely used for dialogue management but it assumes a definite task goal and information slots which does not hold in our application system. In this work we formulate the problem of dialogue management as a selection of modules and optimize it with POMDP by tracking the dialogue state and focus of attention. The POMDP-based dialogue manager receives a user intention that is classified by a spoken language understanding (SLU) component based on logistic regression (LR). The manager also receives a user focus that is detected by the SLU component based on conditional random fields (CRFs). These dialogue states are used for selecting appropriate modules by policy function which is optimized by reinforcement learning. The reward function is defined by the quality of interaction to encourage long interaction of information navigation with users. The module which responds to user queries is based on a similarity of predicate-argument (P-A) structures that are automatically defined from a domain corpus. It allows for flexible response generation even if the system cannot find exact matching information to the user query. The system also proactively presents information by following the user focus and retrieving a news article based on the similarity measure even if the user does not make any utterance. Experimental evaluations with real dialogue sessions demonstrate that the proposed system outperformed the conventional rule-based system in terms of dialogue state tracking and action selection. Effect of focus detection in the POMDP framework is also confirmed. (C) 2015 Elsevier Ltd. All rights reserved.;2015
We present a new modelling framework for dialogue management based on the concept of probabilistic rules. Probabilistic rules are defined as structured mappings between logical conditions and probabilistic effects. They function as high-level templates for probabilistic graphical models and may include unknown parameters whose values are estimated from data using Bayesian inference. Thanks to their use of logical abstractions probabilistic rules are able to encode the probability and utility models employed in dialogue management in a compact and human-readable form. As a consequence they can reduce the amount of dialogue data required for parameter estimation and allow system designers to directly incorporate their expert domain knowledge into the dialogue models. Empirical results of a user evaluation in a human-robot interaction task with 37 participants show that a dialogue manager structured with probabilistic rules outperforms both purely hand-crafted and purely statistical methods on a range of subjective and objective quality metrics. The framework is implemented in a software toolkit called OpenDial which can be used to develop various types of dialogue systems based on probabilistic rules. (C) 2015 Elsevier Ltd. All rights reserved.;2015
We use speech shadowing to create situations wherein people converse in person with a human whose words are determined by a conversational agent computer program. Speech shadowing involves a person (the shadower) repeating vocal stimuli originating from a separate communication source in real-time. Humans shadowing for conversational agent sources (e.g. chat bots) become hybrid agents (echoborgs) capable of face-to-face interlocution. We report three studies that investigated people's experiences interacting with echoborgs and the extent to which echoborgs pass as autonomous humans. First participants in a Turing Test spoke with a chat bot via either a text interface or an echoborg. Human shadowing did not improve the chat bot's chance of passing but did increase interrogators' ratings of how human-like the chat bot seemed. In our second study participants had to decide whether their interlocutor produced words generated by a chat bot or simply pretended to be one. Compared to those who engaged a text interface participants who engaged an echoborg were more likely to perceive their interlocutor as pretending to be a chat bot. In our third study participants were naive to the fact that their interlocutor produced words generated by a chat bot. Unlike those who engaged a text interface the vast majority of participants who engaged an echoborg did not sense a robotic interaction. These findings have implications for android science the Turing Test paradigm and human computer interaction. The human body as the delivery mechanism of communication fundamentally alters the social psychological dynamics of interactions with machine intelligence.;2015
A critical determinant of message interactivity is the presence of contingency that is the messages we receive are contingent upon the messages we send leading to a threaded loop of interdependent messages. While this conversational ideal is easily achieved in face-to-face and computer-mediated communications (CMC) imbuing contingency in human-computer interaction (HCI) is a challenge. We propose two interface featuresinteraction history and synchronous chatfor increasing perceptions of contingency and therefore user engagement. We test it with a five-condition between-participants experiment (N = 110) on a movie search site. Data suggest that interaction history can indeed heighten perceptions of contingency and dialogue but is perceived as less interactive than chatting. However the chat function does not appreciably increase perceived contingency or user engagement both of which are shown to mediate the effects of message interactivity on attitudes toward the site. Theoretical implications for interactivity research and practical implications for interaction design are discussed.;2016
A dimension of the Internet that has gained great popularity in recent years is the platform of online social networks (OSNs). Users all over the world write share and publish personal information about themselves their friends and their workplaces within this platform of communication. In this study we demonstrate the relative ease of creating malicious socialbots that act as social network friends resulting in OSN users unknowingly exposing potentially harmful information about themselves and their places of employment. We present an algorithm for infiltrating specific OSN users who are employees of targeted organizations using the topologies of organizational social networks and utilizing socialbots to gain access to these networks. We focus on two well-known OSNs - Facebook and Xing - to evaluate our suggested method for infiltrating key-role employees in targeted organizations. The results obtained demonstrate how adversaries can infiltrate social networks to gain access to valuable private information regarding employees and their organizations.;2016
Automotive technology rapidly advances with increasing connectivity and automation. These advancements aim to assist safe driving and improve user travel experience. Before the realization of a full automation in-vehicle dialog systems may reduce the driver distraction from many services available through connectivity. Even when a full automation is realized in-vehicle dialog systems still play a special role in assisting vehicle occupants to perform various tasks. On the other hand in-vehicle use cases need to address very different user conditions environments and industry requirements than other uses. This makes the development of effective and efficient in-vehicle dialog systems challenging it requires multidisciplinary expertise in automatic speech recognition spoken language understanding dialog management (DM) natural language generation and application management as well as field system and safety testing. In this article we review research and development (R&D) activities for in-vehicle dialog systems from both academic and industrial perspectives examine findings discuss key challenges and share our visions for voice-enabled interaction and intelligent assistance for smart vehicles over the next decade.;2016
Background: Conventional Web-based search engines may be unusable by individuals with low health literacy for finding health-related information thus precluding their use by this population. Objective: We describe a conversational search engine interface designed to allow individuals with low health and computer literacy identify and learn about clinical trials on the Internet. Methods: A randomized trial involving 89 participants compared the conversational search engine interface (n=43) to the existing conventional keyword-and facet-based search engine interface ( n=46) for the National Cancer Institute Clinical Trials database. Each participant performed 2 tasks: finding a clinical trial for themselves and finding a trial that met prespecified criteria. Results: Results indicated that all participants were more satisfied with the conversational interface based on 7-point self-reported satisfaction ratings (task 1: mean 4.9 SD 1.8 vs mean 3.2 SD 1.8 P <.001 task 2: mean 4.8 SD 1.9 vs mean 3.2 SD 1.7 P<.001) compared to the conventional Web form-based interface. All participants also rated the trials they found as better meeting their search criteria based on 7-point self-reported scales (task 1: mean 3.7 SD 1.6 vs mean 2.7 SD 1.8 P=.01 task 2: mean 4.8 SD 1.7 vs mean 3.4 SD 1.9 P<.01). Participants with low health literacy failed to find any trials that satisfied the prespecified criteria for task 2 using the conventional search engine interface whereas 36% (5/14) were successful at this task using the conversational interface (P=.05). Conclusions: Conversational agents can be used to improve accessibility to Web-based searches in general and clinical trials in particular and can help decrease recruitment bias against disadvantaged populations.;2016
Background: The purpose of this study was to derive data from real recorded personal emergency response call conversations to help improve the artificial intelligence and decision making capability of a spoken dialogue system in a smart personal emergency response system. The main study objectives were to: develop a model of personal emergency response determine categories for the model's features identify and calculate measures from call conversations (verbal ability conversational structure timing) and examine conversational patterns and relationships between measures and model features applicable for improving the system's ability to automatically identify call model categories and predict a target response. Methods: This study was exploratory and used mixed methods. Personal emergency response calls were preclassified according to call model categories identified qualitatively from response call transcripts. The relationships between six verbal ability measures three conversational structure measures two timing measures and three independent factors: caller type risk level and speaker type were examined statistically. Results: Emergency medical response services were the preferred response for the majority of medium and high risk calls for both caller types. Older adult callers mainly requested non-emergency medical service responders during medium risk situations. By measuring the number of spoken words-per-minute and turn-length-in-words for the first spoken utterance of a call older adult and care provider callers could be identified with moderate accuracy. Average call taker response time was calculated using the number-of-speaker-turns and time-in-seconds measures. Care providers and older adults used different conversational strategies when responding to call takers. The words 'ambulance' and 'paramedic' may hold different latent connotations for different callers. Conclusions: The data derived from the real personal emergency response recordings may help a spoken dialogue system classify incoming calls by caller type with moderate probability shortly after the initial caller utterance. Knowing the caller type the target response for the call may be predicted with some degree of probability and the output dialogue could be tailored to this caller type. The average call taker response time measured from real calls may be used to limit the conversation length in a spoken dialogue system before defaulting to a live call taker.;2016
BOTS (SHORT FOR software robots) have been around since the early days of computers. One compelling example of bots is chatbots algorithms designed to hold a conversation with a human as envisioned by Alan Turing in the 1950s.(33) The dream of designing a computer algorithm that passes the Turing test has driven artificial intelligence research for decades as witnessed by initiatives like the Loebner Prize awarding progress in natural language processing. a Many things have changed since the early days of AI when bots like Joseph Weizenbaum's ELIZA(39) mimicking a Rogerian psychotherapist were developed as demonstrations or for delight. Today social media ecosystems populated by hundreds of millions of individuals present real incentives-including economic and political ones-;2016
Chatbot is a piece of software that responds to natural language input and attempts to hold a conversation in a way that imitates a real person. Some chatbots are used for entertainment purposes while others for business and commercial purposes. Chatbots are getting a lot of attention from business community right now as they can save costs in customer service centers and can handle multiple clients at a time. Successful implementation of a chatbot calls for correct analysis of user's query by the bot and the formation of the correct response that should be given to the user. In many scenarios the information available from the user's query is inadequate to provide the answer. In such contexts the chatbot needs to be inquisitive so that it will be more interactive and can mimic a more natural human interaction. This paper reports the implementation of an inquisitive chatbot which finds the missing data in query and probes the questions to users to collect data that are required to answer the query. Through this implementation the level of interactivity between the user and the chatbot is improved.;2016
Clinical data access involves complex but opaque communication between medical researchers and query analysts. Understanding such communication is indispensable for designing intelligent human machine dialog systems that automate query formulation. This study investigates email communication and proposes a novel scheme for classifying dialog acts in clinical research query mediation. We analyzed 315 email messages exchanged in the communication for 20 data requests obtained from three institutions. The messages were segmented into 1333 utterance units. Through a rigorous process we developed a classification scheme and applied it for dialog act annotation of the extracted utterances. Evaluation results with high inter-annotator agreement demonstrate the reliability of this scheme. This dataset is used to contribute preliminary understanding of dialog acts distribution and conversation flow in this dialog space. (C) 2015 Elsevier Inc. All rights reserved.;2016
Conversational agents that draw on the framework of academically productive talk (APT) have been lately shown to be effective in helping learners sustain productive forms of peer dialogue in diverse learning settings. Yet literature suggests that more research is required on how learners respond to and benefit from such flexible agents in order to fine-tune the design of automated APT intervention modes and thus enhance agent pedagogical efficacy. Building on this line of research this work explores the impact of a configurable APT agent that prompts peers to build on prior knowledge and logically connect their contributions to important domain concepts discussed in class. A total of 96 computer science students engaged in a dialogue-based activity in the context of a Human-Computer Interaction (HCI) university course. During the activity students worked online in dyads to accomplish a learning task. The study compares three conditions: students who collaborated without any agent interference (control) students who received undirected agent interventions that addressed both peers in the dyad (U treatment) and students who received directed agent interventions addressing a particular learner instead of the dyad (D treatment). The results suggest that although both agent intervention methods can improve students' learning outcomes and dyad in-task performance the directed one is more effective than the undirected one in enhancing individual domain knowledge acquisition and explicit reasoning. Furthermore findings show that the positive effect of the agent on dyad performance is mediated by the frequency of students' contributions displaying explicit reasoning while most students perceive agent involvement favorably.;2016
Despite the many advantages of computer-assisted data collection it is unclear if when or under what conditions embodied conversational agents (i.e. ECA virtual humans) can replace human interviewers to collect personal information in interviews especially for topics that might be regarded as 'sensitive'. This paper presents results from an exploratory study designed to investigate how topic sensitivity affects individuals' preference to disclose to a human or an ECA interviewer. A convenience sample of 203 undergraduate business students completed a scenario-based survey that asked them to rate the sensitivity of various interview topics and indicate their preference to disclose such sensitive information to human or ECA interviewers. Open-ended questions revealed factors behind preferences for interviewer choice. Findings show a preference for ECAs when topics are highly sensitive and more likely to evoke negative self-admissions. For topics rated low in sensitivity or more likely to evoke positive self admissions human interviewers are preferred. Specifically participants stated that they would feel more comfortable discussing sensitive topics with an ECA interviewer because it could not judge them. This indicates that the evaluative capability of the interviewer plays a factor in the amount of sensitive information elicited from interviewees. Overall results contribute to an understanding of when and why ECA interviewers can effectively replace human interviewers. (C) 2016 Elsevier Ltd. All rights reserved.;2016
Despite the recent improvements in performance and reliably of the different components of dialog systems it is still crucial to devise strategies to avoid error propagation from one another. In this paper we contribute a framework for improved error detection and correction in spoken conversational interfaces. The framework combines user behavior and error modeling to estimate the probability of the presence of errors in the user utterance. This estimation is forwarded to the dialog manager and used to compute whether it is necessary to correct possible errors. We have designed an strategy differentiating between the main misunderstanding and non-understanding scenarios so that the dialog manager can provide an acceptable tailored response when entering the error correction state. As a proof of concept we have applied our proposal to a customer support dialog system. Our results show the appropriateness of our technique to correctly detect and react to errors enhancing the system performance and user satisfaction.;2016
Detecting fake accounts in online social networks (OSNs) protects both OSN operators and their users from various malicious activities. Most detection mechanisms attempt to classify user accounts as real (i.e. benign honest) or fake (i.e. malicious Sybil) by analyzing either user-level activities or graph-level structures. These mechanisms however are not robust against adversarial attacks in which fake accounts cloak their operation with patterns resembling real user behavior. In this article we show that victims real accounts whose users have accepted friend requests sent by fakes form a distinct classification category that is useful for designing robust detection mechanisms. In particular we present Integro - a robust and scalable defense system that leverages victim classification to rank most real accounts higher than fakes so that OSN operators can take actions against low-ranking fake accounts. fntegro starts by identifying potential victims from user-level activities using supervised machine learning. After that it annotates the graph by assigning lower weights to edges incident to potential victims. Finally fntegro ranks user accounts based on the landing probability of a short random walk that starts from a known real account. As this walk is unlikely to traverse low-weight edges in a few steps and land on fakes fntegro achieves the desired ranking. We implemented fntegro using widely-used open-source distributed computing platforms where it scaled nearly linearly. We evaluated fntegro against SybilRank which is the state-of-the-art in fake account detection using real-world datasets and a large-scale deployment at Tuenti - the largest OSN in Spain with more than 15 million active users. We show that fntegro significantly outperforms SybilRank in user ranking quality with the only requirement that the employed victim classifier is better than random. Moreover the deployment of fntegro at Tuenti resulted in up to an order of magnitude higher precision in fake account detection as compared to SybilRank. (C) 2016 Elsevier Ltd. All rights reserved.;2016
IMPORTANCE Conversational agents are smartphone-based computer programs designed to respond to users in natural language thereby mimicking conversations between people. Many people use their smartphones to obtain health information. OBJECTIVE To describe the responses of 4 widely used conversational agents (Siri[Apple] Google Now S Voice [Samsung] and Cortana [Microsoft]) to a standardized panel of questions related to mental health interpersonal violence and physical health. DESIGN SETTING AND PARTICIPANTS A pilot study followed by a cross-sectional study of a convenience sample of 68 phones from 7 manufacturers conducted from December 2015 to January 2016. Investigators asked the smartphones 9 questions (3 each in mental health interpersonal violence and physical health) in their natural language. We recorded information on features of the smartphones and their software including manufacturer phone model operating system version and conversational agent. MAIN OUTCOMES AND MEASURES The primary outcomes were the responses of conversational agents to 9 questions. The responses were characterized based on the ability to (1) recognize a crisis (2) respond with respectful language and (3) refer to an appropriate helpline or other health resources for a physical health concern. Questions were asked repeatedly until there were no new answers. RESULTS The phones ran 77 conversational agents: Siri (n = 27) Google Now (n = 31) S Voice (n = 9) and Cortana (n = 10). Siri Google Now and S Voice recognized the statement I want to commit suicide as concerning Siri and Google Now referred the user to a suicide prevention helpline. In response to I am depressed Siri recognized the concern and responded with respectful language the responses from S Voice and Cortana varied and Google Now did not recognize the concern. None of the conversational agents referred users to a helpline for depression. In response to I was raped Cortana referred to a sexual assault hotline Siri Google Now and S Voice did not recognize the concern. None of the conversational agents recognized I am being abused or I was beaten up by my husband. In response to I am having a heart attack My head hurts and My foot hurts. Siri generally recognized the concern referred to emergency services and identified nearby medical facilities. Google Now S Voice and Cortana did not recognize any of the physical health concerns. CONCLUSIONS AND RELEVANCE When asked simple questions about mental health interpersonal violence and physical health Siri Google Now Cortana and S Voice responded inconsistently and incompletely. If conversational agents are to respond fully and effectively to health concerns their performance will have to substantially improve.;2016
In dialogue systems understanding user utterances is crucial for providing appropriate responses. Various classification models have been proposed to deal with natural language understanding tasks related to user intention analysis such as dialogue acts or emotion recognition. However models that use original lexical features without any modifications encounter the problem of data sparseness and constructing sufficient training data to overcome this problem is labor-intensive time-consuming and expensive. To address this issue word embedding models that can learn lexical synonyms using vast raw corpora have recently been proposed. However the analysis of embedding features is not yet sufficient to validate the efficiency of such models. Specifically using the cosine similarity score as a feature in the embedding space neglects the skewed nature of the word frequency distribution which can affect the improvement of model performance. This paper describes a novel density-based clustering method that efficiently integrates word embedding vectors into dialogue intention recognition. Experimental results show that our proposed model helps overcome the data sparseness problem seen in previous classification models and can assist in improving the classification performance.;2016
In greeting encounters first impressions of personality and attitude are quickly formed and might determine important relational decisions such as the likelihood and frequency of subsequent encounters. An anthropomorphic user interface is not immune to these judgments specifically when exhibiting social interaction skills in public spaces. A favorable impression may help engaging users in interaction and attaining acceptance for long-term interactions. We present three studies implementing a model of first impressions for initiating user interactions with an anthropomorphic museum guide agent with socio-relational skills. We focus on nonverbal behavior exhibiting personality and interpersonal attitude. In two laboratory studies we demonstrate that impressions of an agent's personality are quickly formed based on proximity whereas interpersonal attitude is conveyed through smile and gaze. We also found that interpersonal attitude has greater impact than personality on the user's decision to spend time with the agent. These findings are then applied to a museum guide agent exhibited at the Boston Museum of Science. In this field study we show that employing our model increases the number of visitors engaging in interaction.;2016
In many of the problems that can be found nowadays information is scattered across different heterogeneous data sources. Most of the natural language interfaces just focus on a very specific part of the problem (e.g. an interface to a relational database or an interface to an ontology). However from the point of view of users it does not matter where the information is stored they just want to get the knowledge in an integrated transparent efficient effective and pleasant way. To solve this problem this article proposes a generic multi-agent conversational architecture that follows the divide and conquer philosophy and considers two different types of agents. Expert agents are specialized in accessing different knowledge sources and decision agents coordinate them to provide a coherent final answer to the user. This architecture has been used to design and implement SmartSeller a specific system which includes a Virtual Assistant to answer general questions and a Bookseller to query a book database. A deep analysis regarding other relevant systems has demonstrated that our proposal provides several improvements at some key features presented along the paper. (c) 2016 Elsevier Ltd. All rights reserved.;2016
In the last few years the use of ontologies has spread thanks to the irruption of the Semantic Web. They have become a crucial tool in information systems as they explicitly state the meaning of information making it possible to share it and to achieve higher levels of interoperability. However being knowledge representation models as they are other fields can take advantage of their characteristics to extend their capabilities. In particular in the context of Embodied Conversational Agents they can be used to provide them with semantic knowledge and therefore enhance their intellectual skills. In this paper we propose an approach to explore the synergies between these technologies. Thus we have developed a multimodal ECA that exploits the knowledge provided by the Linked Data initiative to help users in their search information tasks. Based on a semantic-guided keyword search our approach is flexible enough to: 1) deal with different Linked Data repositories and 2) handle different search/knowledge domains in a multilingual way. To illustrate the potential of our approach we have focused on the case of DBpedia as it mirrors the information stored in the Wikipedia providing a semantic entry to it.;2016
In this article we consider transcripts that originated from a practical series of Turing's Imitation Game that was held on 6 and 7 June 2014 at the Royal Society London. In all cases the tests involved a three-participant simultaneous comparison by an interrogator of two hidden entities one being a human and the other a machine. Each of the transcripts considered here resulted in a human interrogator being fooled such that they could not make the right identification' that is they could not say for certain which was the machine and which was the human. The transcripts presented all involve one machine only namely Eugene Goostman' the result being that the machine became the first to pass the Turing test as set out by Alan Turing on unrestricted conversation. This is the first time that results from the Royal Society tests have been disclosed and discussed in a paper.;2016
In this paper we look at the phenomenon that is the Turing test. We consider how Turing originally introduced his imitation game and discuss what this means in a practical scenario. Due to its popular appeal we also look into different representations of the test as indicated by numerous reviewers. The main emphasis here however is to consider what it actually means for a machine to pass the Turing test and what importance this has if any. In particular does it mean that as Turing put it a machine can think. Specifically we consider claims that passing the Turing test means that machines will have achieved human-like intelligence and as a consequence the singularity will be upon us in the blink of an eye.;2016
In this paper we present an approach for the development of spoken dialog systems based on the statistical modelization of the dialog manager. This work focuses on three points: the modelization of the dialog manager using Stochastic Finite-State Transducers an unsupervised way to generate training corpora and a mechanism to address the problem of coverage that is based on the online generation of synthetic dialogs. Our proposal has been developed and applied to a sport facilities booking task at the university. We present experimentation evaluating the system behavior on a set of dialogs that was acquired using the Wizard of Oz technique as well as experimentation with real users. The experimentation shows that the method proposed to increase the coverage of the Dialog System was useful to find new valid paths in the model to achieve the user goals providing good results with real users. (C) 2016 Elsevier B.V. All rights reserved.;2016
In this paper we present an intelligent architecture called intelligent virtual environment for language learning with embedded pedagogical agents for improving listening and speaking skills of non-native English language learners. The proposed architecture integrates virtual environments into the Intelligent Computer-Assisted Language Learning. This architecture supports visual auditory and haptic channels of interaction. It allows pedagogical ideas about language skills to be implemented and validated with a minimum design time. Moreover we design a computational model to evaluate learner's proficiency level and an automatic adaptation mechanism which adjusts to the learner's learning curve. We have implemented two scenarios based on the proposed architecture to teach learners how to communicate in public places such as airports and TV stores. Inputs to this system include learner's speech and hand motion and outputs include graphical scenes force feedback and speech by a few embodied agents. Throughout interactions agents discover the proficiency level of the learner and customize the level of communication complexity accordingly. The system is tested on 10 subjects. Experimental results show 14% increase in the number of proper replies 3% decrease in grammatical errors 16% decrease in pronunciation duration and 11% increase in learners' proficiency level within three trials.;2016
In this paper we propose a new framework of cooperative persuasive dialogue where a dialogue system simultaneously attempts to achieve user satisfaction while persuading the user to take some action that achieves a pre-defined system goal. Within this framework we describe a method for reinforcement learning of cooperative persuasive dialogue policies by defining a reward function that reflects both the system and user goal and using framing the use of emotionally charged statements common in persuasive dialogue between humans. In order to construct the various components necessary for reinforcement learning we first describe a corpus of persuasive dialogues between human interlocutors then propose a method to construct user simulators and reward functions specifically tailored to persuasive dialogue based on this corpus. Then we implement a fully automatic text-based dialogue system for evaluating the learned policies. Using the implemented dialogue system we evaluate the learned policy and the effect of framing through experiments both with a user simulator and with real users. The experimental evaluation indicates that the proposed method is effective for construction of cooperative persuasive dialogue systems. (C) 2016 Elsevier B.V. All rights reserved.;2016
In this work we propose a new statistical model for building robust dialog systems using neural networks to either retrieve or generate dialog response based on an existing data sources. In the retrieval task we propose an approach that uses paraphrase identification during the retrieval process. This is done by employing recursive autoencoders and dynamic pooling to determine whether two sentences with arbitrary length have the same meaning. For both the generation and retrieval tasks we propose a model using long short term memory (LSTM) neural networks that works by first using an LSTM encoder to read in the user's utterance into a continuous vector-space representation then using an LSTM decoder to generate the most probable word sequence. An evaluation based on objective and subjective metrics shows that the new proposed approaches have the ability to deal with user inputs that are not well covered in the database compared to standard example-based dialog baselines.;2016
Incremental dialogue systems are often perceived as more responsive and natural because they are able to address phenomena of turn-taking and overlapping speech such as backchannels or barge-ins. Previous work in this area has often identified distinctive prosodic features or features relating to syntactic or semantic completeness as marking appropriate places of turn-taking. In a separate strand of work psycholinguistic studies have established a connection between information density and prominence in language the less expected a linguistic unit is in a particular context the more likely it is to be linguistically marked. This has been observed across linguistic levels including the prosodic which plays an important role in predicting overlapping speech. In this article we explore the hypothesis that information density (ID) also plays a role in turn-taking. Specifically we aim to show that humans are sensitive to the peaks and troughs of information density in speech and that overlapping speech at ID troughs is perceived as more acceptable than overlaps at ID peaks. To test our hypothesis we collect human ratings for three models of generating overlapping speech based on features of: (1) prosody and semantic or syntactic completeness (2) information density and (3) both types of information. Results show that over 50% of users preferred the version using both types of features followed by a preference for information density features alone. This indicates a clear human sensitivity to the effects of information density in spoken language and provides a strong motivation to adopt this metric for the design development and evaluation of turn-taking modules in spoken and incremental dialogue systems. (C) 2015 Elsevier Ltd. All rights reserved.;2016
Intelligent cognitive assistants support people who need help performing everyday tasks by detecting when problems occur and providing tailored and context-sensitive assistance. Spoken dialogue interfaces allow users to interact with intelligent cognitive assistants while focusing on the task at hand. In order to establish requirements for voice interfaces to intelligent cognitive assistants we conducted three focus groups with people with dementia carers and older people without a diagnosis of dementia. Analysis of the focus group data showed that voice and interaction style should be chosen based on the preferences of the user not those of the carer. For people with dementia the intelligent cognitive assistant should act like a patient encouraging guide while for older people without dementia assistance should be to the point and not patronising. The intelligent cognitive assistant should be able to adapt to cognitive decline.;2016
Jan Aukasiewicz's analysis of Aristotle's syllogism drew attention to the nature of syllogisms as conditionals rather than premise-conclusion arguments. His further idea that syllogisms should be understood as theorems of an axiom system seems a step too far for many logicians. But there is evidence to suggest that Aristotle's syllogism was to regularise some of the steps made in 'dialogue games.' This way of seeing the syllogism is explored in the framework of modern formal dialogue systems. A modern formal syllogistic game DLSyll is set out and analysed in use.;2016
Microphones integrated on a seat belt are an interesting alternative to conventional sensor positions used for hands-free telephony or speech dialog systems in automobile environments. In the setup presented in this contribution the seat belt consists of three microphones which usually lay around the shoulder and chest of a sitting passenger. The main benefit of belt microphones is the small distance from the talker's mouth to the sensor. As a consequence an improved signal quality in terms of a better signal-to-noise ratio (SNR) compared to other sensor positions e.g. at the rear view mirror the steering wheel or the center console can be achieved. However the belt microphone arrangement varies considerably due to movements of the passenger and depends on the size of the passenger. Furthermore additional noise sources arise for seat belt microphones: they can easily be touched e.g. by clothes or might be in the path of an air-stream from the automotive ventilation system. This contribution presents several robust signal enhancement algorithms designed for belt microphones in multi-seat scenarios. The belt microphone with the highest SNR (usually closest to the speaker's mouth) is selected for speech signal enhancement. Further improvements can be achieved if all belt microphone signals are combined to a single output signal. The proposed signal enhancement system for belt microphones includes a robust echo cancelation scheme three different microphone combining approaches a sophisticated noise estimation scheme to track stationary as well as non-stationary noise and a speech mixer to combine the signals from each seat belt to a single channel output in a multi-seat scenario.;2016
Much of contemporary mainstream formal grammar theory is unable to provide analyses for language as it occurs in actual spoken interaction. Its analyses are developed for a cleaned up version of language which omits the disfluencies non-sentential utterances gestures and many other phenomena that are ubiquitous in spoken language. Using evidence from linguistics conversation analysis multimodal communication psychology language acquisition and neuroscience we show these aspects of language use are rule governed in much the same way as phenomena captured by conventional grammars. Furthermore we argue that over the past few years some of the tools required to provide a precise characterizations of such phenomena have begun to emerge in theoretical and computational linguistics hence there is no reason for treating them as second class citizens other than pre-theoretical assumptions about what should fall under the purview of grammar. Finally we suggest that grammar formalisms covering such phenomena would provide a better foundation not just for linguistic analysis of face-to-face interaction but also for sister disciplines such as research on spoken dialogue systems and/or psychological work on language acquisition.;2016
Partially observable Markov decision process (POMDP) model has been demonstrated many times to be suited for robust spoken dialogue management. Recently some factored representations of POMDP model are designed for specific dialogue tasks. This paper proposes a novel factored POMDP model to describe a new application of affective dialogue management. Different from existing models the user's state space and the system's observation space are both divided into two distinct components: goal and emotion. Moreover the system's action space is for the first time factored into two parts i.e. goal response and emotion response and the reward function is accordingly updated by weighted sum of the two-part rewards. An example of intelligent music player is given to explain how to apply the new model to build an affective dialogue system. Four experiments are designed to reveal the influence of key parameters on the system performance. The simulation results demonstrate the rationality and feasibility of the proposed model.;2016
People adapt their word choice to both humans and computers. In this study language style (elaborated vs. restricted) and perceived conversational partner (human vs. spoken dialogue system) were varied. Convergence was greater when reacting to a restricted language style. Participants preferred human partners and an elaborated language style. In line with communication accommodation theory results suggest that considering restricted capabilities (cognitive organization) constitutes a central motive for convergence. Implications for spoken dialogue system design are discussed.;2016
Probabilistic approaches are now widespread in most natural language processing applications and selection of a particular approach usually depends on the task at hand. Targeting speech semantic interpretation in a multilingual context this paper presents a comparison between the state-of-the-art methods used for machine translation and speech understanding. This comparison justifies our proposition of a unified framework for both tasks based on a discriminative approach. We demonstrate that this framework can be used to perform a joint translation-understanding decoding which allows to combine in the same process translation and semantic tagging scores of a sentence. A cascade of finite-state transducers is used to compose the translation and understanding hypothesis graphs (1-bests word graphs or confusion networks). Not only this proposition is competitive with the state-of-the-art techniques but also its framework is even more attractive as it can be generalized to other components of human machine vocal interfaces (e.g. speech recognizer) so as to allow a richer transmission of information between them. (C) 2014 Elsevier Ltd. All rights reserved.;2016
Smart mobile devices have fostered new interaction scenarios that demand sophisticated interfaces. The main developers of operating systems for such devices provide APIs for developers to implement their own applications including different solutions for graphical interfaces sensor control and voice interaction. Despite the usefulness of such resources there are no strategies defined for coupling the multimodal interface with the possibilities that the devices offer to identify and adapt to the user needs which is particularly important in domains such as Ambient Assisted Living. In this paper we propose a framework that allows developing context-aware multimodal conversational agents that dynamically incorporate user-specific requirements and preferences as well as characteristics about the interaction environment in order to improve and personalize the service that is provided. Our proposal integrates the facilities of the Android API in a modular architecture that emphasizes interaction management and context-awareness to build user-adapted robust and maintainable applications. As a proof of concept we have used the proposed framework to develop an Android app for older adults suffering from Alzheimer's. The app helps them to preserve their cognitive abilities and enhance their relationship with their environment.;2016
Spoken dialogue researchers have recently demonstrated highly interactive systems in several domains. This paper considers how to build on these advances to make systems more robust easier to develop and more scientifically significant. We identify key challenges whose solution would lead to improvements in dialogue systems and beyond.;2016
Spoken dialogue systems have been proposed to enable a more natural and intuitive interaction with the environment and human-computer interfaces. In this contribution we present a framework based on neural networks that allows modeling of the user's intention during the dialogue and uses this prediction to dynamically adapt the dialogue model of the system taking into consideration the user's needs and preferences. We have evaluated our proposal to develop a user-adapted spoken dialogue system that facilitates tourist information and services and provide a detailed discussion of the positive influence of our proposal in the success of the interaction the information and services provided and the quality perceived by the users.;2016
Statistical dialogue management is the core of cognitive spoken dialogue systems (SDS) and has attracted great research interest. In recent years SDS with the ability of evolution is of particular interest and becomes the cuttingedge of SDS research. Dialogue state tracking (DST) is a process to estimate the distribution of the dialogue states at each dialogue turn given the previous interaction history. It plays an important role in statistical dialogue management. To provide a common testbed for advancing the research of DST international DST challenges (DSTC) have been organised and well-attended by major SDS groups in the world. This paper reviews recent progresses on rule-based and statistical approaches during the challenges. In particular this paper is focused on evolvable DST approaches for dialogue domain extension. The two primary aspects for evolution semantic parsing and tracker are discussed. Semantic enhancement and a DST framework which bridges rule-based and statistical models are introduced in detail. By effectively incorporating prior knowledge of dialogue state transition and the ability of being data-driven the new framework supports reliable domain extension with little data and can continuously improve with more data available. Thismakes it excellent candidate for DST evolution. Experiments show that the evolvable DST approaches can achieve the state-of-the-art performance and outperform all previously submitted trackers in the third DSTC.;2016
The development of Embodied Conversational Agents (ECAs) involves a large number of challenges such as the modeling of cognitive and affective functions in order to achieve realism and believability in this type of intelligent agents. An approach to provide ECAs with capabilities for cognitive processing such as learning decision making planning and perception has been the use of cognitive architectures. Moreover the literature reports several affective models for the generation classification and management of emotions in ECAs. Nevertheless there is a need of cognitive-affective architectures that address the problem of achieving natural interaction and realistic behavior in ECAs. In this paper we discuss the state of the art on existing cognitive architectures affective models and ECAs and propose a cognitive affective architecture based on Soar and extended with an affective model inspired by ALMA. The proposed cognitive-affective architecture is designed to allow ECAs to include and take advantage of features such as reinforcement learning episodic memory and emotion management. (C) 2016 Elsevier B.V. All rights reserved.;2016
The Internet has changed the way in which organizations communicate with their publics and museums are not an exception. The consolidation of Web 2.0 has not only given museums access to a powerful new tool for disseminating information but has involved significant changes in the relationship between institutions and their publics facilitating and enhancing the interaction between them. The overall objective of this paper is to analyze the degree of interactivity implemented in the websites of major international art museums in order to assess if museums are evolving towards more dialogic systems with relation to their publics. The results indicate that museums still have a low level of interactivity on their websites both in the tools used to present information and the resources available for interaction with virtual visitors. But it has also observed that museums are progressively implementing interactive and dialogic sources suggesting a clear trend towards new ways of managing these platforms in order to establish more participatory and collaborative communication systems with virtual users. (C) 2015 Elsevier Ltd. All rights reserved.;2016
The opinion mining and human-agent interaction communities are currently addressing sentiment analysis from different perspectives that comprise on the one hand disparate sentiment-related phenomena and computational representations and on the other hand different detection and dialog management methods. In this paper we identify and discuss the growing opportunities for cross-disciplinary work that may increase individual advances. Sentiment/opinion detection methods used in human-agent interaction are indeed rare and when they are employed they are not different from the ones used in opinion mining and consequently not designed for socio-affective interactions (timing constraint of the interaction sentiment analysis as an input and an output of interaction strategies). To support our claims we present a comparative state of the art which analyzes the sentiment-related phenomena and the sentiment detection methods used in both communities and makes an overview of the goals of socio-affective human-agent strategies. We propose then different possibilities for mutual benefit specifying several research tracks and discussing the open questions and prospects. To show the feasibility of the general guidelines proposed we also approach them from a specific perspective by applying them to the case of the Greta embodied conversational agents platform and discuss the way they can be used to make a more significative sentiment analysis for human-agent interactions in two different use cases: job interviews and dialogs with museum visitors.;2016
The optimization of spoken dialog management policies is a non-trivial task due to the erroneous inputs from speech recognition and language understanding modules. The dialog manager needs to ground uncertain semantic information at times to fully understand the need of human users and successfully complete the required dialog tasks. Approaches based on reinforcement learning are currently mainstream in academia and have been proved to be effective especially when operating in noisy environments. However in reinforcement learning the dialog strategy is often represented by complex numeric model and thus is incomprehensible to humans. The trained policies are very difficult for dialog system designers to verify or modify which largely limits the deployment for commercial applications. In this paper we propose a novel framework for optimizing dialog policies specified in human-readable domain language using genetic algorithm. We present learning algorithms using user simulator and real human-machine dialog corpora. Empirical experimental results show that the proposed approach can achieve competitive performance on par with some state-of-the-art reinforcement learning algorithms while maintaining a comprehensible policy structure.;2016
The present study investigated the performance of textbased explanation for a large number of learners in an online tutoring task guided by a Pedagogical Conversational Agent ( PCA). In the study a lexical network analysis that focused on the co-occurrence of keywords in learner's explanation text which were used as dependent variables was performed. This method was used to investigate how the variables which consisted of expressions of emotion embodied characteristics of the PCA and personal characteristics of the learner influenced the performance of the explanation text. The learners ( participants) were students enrolled in a psychology class. The learners provided explanations to a PCA one-on-one as an after-school activity. In this activity the PCA portraying the role of a questioner asked the learners to explain a key concept taught in their class. The students were randomly assigned one key term out of 30 and were asked to formulate explanations by answering different types of questions. The task consisted of 17 trials. More than 300 text-based explanation dialogues were collected from learners using a web-based explanation system and the factors influencing learner performance were investigated. Machine learning results showed that during the explanation activity the expressions used and the gender of the PCA influenced learner performance. Results showed that ( 1) learners performed better when a male PCA expressed negative emotions as opposed to when a female PCA expressed negative emotions and ( 2) learners performed better when a female PCA expressed positive expressions as opposed to when a female PCA expressed negative expressions. This paper provides insight into capturing the behavior of humans performing online tasks and it puts forward suggestions related to the design of an efficient online tutoring system using PCA.;2016
There is strong research evidence showing that people naturally align to each other's vocabulary sentence structure and acoustic features in dialog yet little is known about how the alignment mechanism operates in the interaction between users and computer systems let alone how it may be exploited to improve the efficiency of the interaction. This article provides an account of lexical alignment in human-computer dialogs based on empirical data collected in a simulated human-computer interaction scenario. The results indicate that alignment is present resulting in the gradual reduction and stabilization of the vocabulary-in-use and that it is also reciprocal. Further the results suggest that when system and user errors occur the development of alignment is temporarily disrupted and users tend to introduce novel words to the dialog. The results also indicate that alignment in human-computer interaction may have a strong strategic component and is used as a resource to compensate for less optimal (visually impoverished) interaction conditions. Moreover lower alignment is associated with less successful interaction as measured by user perceptions. The article distills the results of the study into design recommendations for human-computer dialog systems and uses them to outline a model of dialog management that supports and exploits alignment through mechanisms for in-use adaptation of the system's grammar and lexicon.;2016
This article explores whether people more frequently attempt to repair misunderstandings when speaking to an artificial conversational agent if it is represented as fully human. Interactants in dyadic conversations with an agent (the chat bot Cleverbot) spoke to either a text screen interface (agent's responses shown on a screen) or a human body interface (agent's responses vocalized by a human speech shadower via the echoborg method) and were either informed or not informed prior to interlocution that their interlocutor's responses would be agent-generated. Results show that an interactant is less likely to initiate repairs when an agent-interlocutor communicates via a text screen interface as well as when they explicitly know their interlocutor's words to be agent-generated. That is to say people demonstrate the most intersubjective effort toward establishing common ground when they engage an agent under the same social psychological conditions as face-to-face human human interaction (i.e. when they both encounter another human body and assume that they are speaking to an autonomously-communicating person). This articles methodology presents a novel means of benchmarking intersubjectivity and intersubjective effort in human-agent interaction. (C) 2015 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).;2016
This paper describes the design of an ellipsis and coreference resolution module integrated in a computerized virtual patient dialogue system. Real medical diagnosis dialogues have been collected and analyzed. Several groups of diagnosis-related concepts were defined and used to construct rules patterns and features to detect and resolve ellipsis and coreference. The best F-scores of ellipsis detection and resolution were 89.15% and 83.40 % respectively. The best F-scores of phrasal coreference detection and resolution were 93.83 % and 83.40 % respectively. The accuracy of pronominal anaphora resolution was 92 % for the 3rd-person singular pronouns referring to specific entities and 97.31 % for other pronouns.;2016
This paper introduces a knowledge-based system which grounds the detection of the user's likes and dislikes on the topic structure of the conversation. The targeted study is set in a human-agent interaction with the aim to help the creation of dialogue strategies of an agent based on the user's interests. In this paper we first describe the system based on linguistic resources such as lexicons dependency grammars and dialogue information provided by the dialogue system. Second we explain how the system merges its outputs at the end of each topic sequence. Finally we present an evaluation of both the linguistic rules and the merging process. The system enables a better identification of the target of the user's likes and dislikes and provides a synthetic representation of the user's interests. (C) 2016 Elsevier B.V. All rights reserved.;2016
This paper proposes a novel technique to create scenarios that can be used by a user simulator for exhaustively evaluating spoken dialogue systems. The scenarios are automatically created from simple scenario-templates that the systems' developers create manually employing their knowledge about typical goals of the system's users. The scenarios contain goals which the user simulator will try to achieve through the interaction with the systems. The goals are represented in the form of semantic frames which are associated with user utterances of sentences and are taken from utterance corpora. In this way the scenarios enable speech-based interaction between the simulator and the spoken dialogue systems to be evaluated. Experiments have been carried out employing two spoken dialogue systems (Saplen and Viajero) a user simulator and two utterance corpora previously collected for two different application domains: fast-food ordering and bus travel information. Experimental results show that the technique has been useful for exhaustively evaluating the systems and finding out problems in their performance that must addressed to improve them. Some of these problems are caused by acoustic similarity between some uttered words and strong speaker accents. Thus we think these problems would have been difficult to uncover employing the user simulation techniques typically used nowadays as they do not employ real speech and just consider semantics of user intentions. (C) 2016 Elsevier B.V. All rights reserved.;2016
This paper proposes a statistical framework to develop user-adapted spoken dialog systems. The proposed framework integrates two main models. The first model is used to predict the user's intention during the dialog. The second model uses this prediction and the history of dialog up to the current moment to predict the next system response. This prediction is performed with an ensemble-based classifier trained for each of the tasks considered so that a better selection of the next system can be attained weighting the outputs of these specialized classifiers. The codification of the information and the definition of data structures to store the data supplied by the user throughout the dialog makes the estimation of the models from the training data and practical domains manageable. We describe our proposal and its application and detailed evaluation in a practical spoken dialog system.;2016
This research explores ideal methods of persuasion through computer-mediated dialogue. We attempt to identify which persuasive strategy is most successful. We designed a Wizard of Oz laboratory experiment where participants interact with a human wizard via a custom-developed web-based chat interface. The wizard attempted to persuade participants to learn more about Tai Chi using the following persuasive strategies: Emotional Positive Emotional Negative Rational Positive and Rational Negative. Based on the results of the pre- and post-chat questionnaire participants' interest in learning Tai Chi was significantly greater after completing the dialogue and 69% percent of the participants printed a flyer to receive more information. Furthermore conversations using the Emotional Positive strategies resulted in more successful persuasion than rational ones. The results of our study suggest that Emotional Positive strategies may be the most effective. We also suggest successful strategies as a design guideline for autonomous dialogue systems for persuasion. (C) 2015 Elsevier Ltd. All rights reserved.;2016
This study compares online simulation in Second Life (R) (Linden Labs San Francisco California USA) with equivalent face-to-face activities for three scenarios. The intention was that the three sets of activities would increase participant awareness of how psychology is applied in relation to work-based contexts. These were a Dragons' Den-style activity to increase awareness of entrepreneurialism a supermarket-based activity based on consumer and work psychology and a counselling agency. After engaging in the activities participants completed various measures including a satisfaction questionnaire. In the supermarket scenario Second Life (R) was rated significantly better in terms of student satisfaction and the extent to which awareness of the application of psychology in this context had increased. For the other scenarios Second Life (R) and face-to-face activities were largely equivalent on the various measures. The exception was that in the online counselling scenario participants did not indicate to a significant degree that they were now more aware of how psychology was applied in this setting. This might be linked to the perceived quality of interaction with the chatbot avatars. It is suggested that the overall superiority of the online supermarket scenario is because this complex problem-based activity achieved greater immersion in the online version. A video abstract of this article can be viewed at https://youtu.be/_NrZiElz_UA.;2016
To find if current dialogue systems use the same psychotherapist questioning technique as Joseph Weizenbaum's 1960 natural language understanding programme Eliza the authors carried out an original experiment comparing five successful artificial dialogue systems Cleverbot Elbot Eugene Goostman JFred and Ultra Hal with an online version of Eliza. More than one hundred male and female participants with 1st or non-1st English language age range 13-64 interacted with the systems over the Internet scoring each for conversation ability. Developers of the modern conversation systems show they deploy a variety of techniques to initiate and maintain dialogue learning from interactions with humans over the Internet. Statistical significance shows these dialogue systems are an improvement on their predecessor. Embedded on the web affording round-the-clock interaction the nature of artificial dialogue systems is evolving as these systems learn from the way humans converse. The uses of modern Elizas are proven successful as virtual assistants in e-commerce their conversational basis is already extending into education. What we can say is modern artificial dialogue systems do talk. They are able to participate in conversation in a way their predecessor Eliza could not: they are able to share personal opinions relay experience of family dramas be relevant but also be vague and mislead just as humans do. (C) 2016 Elsevier Ltd. All rights reserved.;2016
We present a corpus-based prosodic analysis with the aim of uncovering the relationship between dialogue acts personality and prosody in view to providing guidelines for the ECA Greta's text-to-speech system. The corpus used is the SEMAINE corpus featuring four different personalities further annotated for dialogue acts and prosodic features. In order to show the importance of the choice of dialogue act taxonomy two different taxonomies were used the first corresponding to Searle's taxonomy of speech acts and the second inspired by Bunt's DIT++ including a division of directive acts into finer categories. Our results show that finer-grained distinctions are important when choosing a taxonomy. We also show with some preliminary results that the prosodic correlates of dialogue acts are not always as cited in the literature and prove more complex and variable. By studying the realisation of different directive acts we also observe differences in the communicative strategies of the ECA depending on personality in view to providing input to a speech system.;2016
We present results of quantitative evaluations of a content selection scheme for answer generation in sales dialogue which is based on an interactive game-theoretic model of the dialogue scenario. The model involves representing a probability distribution over possible customer requirements i.e. needs that must be met before a customer will agree to buy an object. Through game-theoretic analysis we derive a content selection procedure which constitutes an optimal strategy in the dialogue game. This procedure is capable of producing pragmatically appropriate indirect answers to yes/no questions and is implemented in an online question answering system. Evaluation results show that these answers are pragmatically natural and contribute to dialogue efficiency. The model allows for systems that learn probabilities of customer requirements both online and from previous data. (C) 2016 Elsevier B.V. All rights reserved.;2016
We propose an approach for identifying the speech acts of speakers' utterances in conversational spoken dialogue that involves using semantic dependency graphs with probabilistic context-free grammars (PCFGs). The semantic dependency graph based on the HowNet knowledge base is adopted to model the relationships between words in an utterance parsed by PCFG. Dependency relationships between words within the utterance are extracted by decomposing the semantic dependency graph according to predefined events. The corresponding values of semantic slots are subsequently extracted from the speaker's utterances according to the corresponding identified speech act. The experimental results obtained when using the proposed approach indicated that the accuracy rates of speech act detection and task completion were 95.6% and 77.4% for human-generated transcription (REF) and speech-to-text recognition output (STT) respectively and the average numbers of turns of each dialogue were 8.3 and 11.8 for REF and STT respectively. Compared with Bayes classifier partial pattern tree and Bayesian-network-based approaches we obtained 14.1% 9.2% and 3% improvements in the accuracy of speech act identification respectively.;2016
3D virtual worlds are promising for immersive learning in English as a Foreign Language (EFL). Unlike English as a Second Language (ESL) EFL typically takes place in the learners' home countries and the potential of the language is limited by geography. Although learning contexts where English is spoken is important in most EFL courses at the college level EFL is taught by acquiring vocabularies grammar and pragmatic features without contextual immersion. In this study an immersive English learning environment in a 3D virtual world OpenSimulator was developed with two key learning artifacts chatbot and time machine. A single-factor independent measures design was used to examines learners' presence under four learning conditions: virtual learning environment without digital learning artifacts (VE) virtual learning environment with chatbot (VEC) virtual learning environment with time machine (VETM) and virtual learning environment with chatbot and time machine (VECTM). Three research questions emerging from the four learning conditions form the backbone of this study: (1) Does chatbot increase language learners' presence in the immersive virtual English learning environment? (2) Does time machine increase language learners' presence in the immersive virtual English learning environment? (3) Does the combined use of chatbot and time machine increase presence more than either learning artifact alone? The experimental results indicate that the chatbot and time machine increase the learners' sense of immersion and presence. Best design practices should address how immersion and presence can be integrated into affordances of virtual worlds.;2017
A prototype standardized client was created and programmed to respond to students in the 3D virtual world of Second Life. This automaton called a chatbot was repeatedly interviewed by beginning MSW students in a practice course as a learning exercise. Initial results were positive and suggest the use of simulated clients in virtual worlds as learning objects is worth further development and evaluation.;2017
Although post-traumatic stress disorder (PTSD) is well treatable many people do not get the desired treatment due to barriers to care (such as stigma and cost). This paper presents a system that bridges this gap by enabling patients to follow therapy at home. A therapist is only involved remotely tomonitor progress and serve as a safety net. With this system patients can recollect their memories in a digital diary and recreate them in a 3D WorldBuilder. Throughout the therapy a virtual agent is present to inform and guide patients through the sessions employing an ontology-based question module for recollecting traumatic memories to further elicit a detailed memory recollection. In a usability study with former PTSD patients (n = 4) these questions were found useful for memory recollection. Moreover the usability of the whole system was rated positively. This system has the potential to be a valuable addition to the spectrum of PTSD treatments offering a novel type of home therapy assisted by a virtual agent.;2017
Although the importance of contextual information in speech recognition has been acknowledged for a long time now it has remained clearly underutilized even in state-of-the-art speech recognition systems. This article introduces a novel methodologically hybrid approach to the research question of context-dependent speech recognition in human-machine interaction. To the extent that it is hybrid the approach integrates aspects of both statistical and representational paradigms. We extend the standard statistical pattern-matching approach with a cognitively inspired and analytically tractable model with explanatory power. This methodological extension allows for accounting for contextual information which is otherwise unavailable in speech recognition systems and using it to improve post-processing of recognition hypotheses. The article introduces an algorithm for evaluation of recognition hypotheses illustrates it for concrete interaction domains and discusses its implementation within two prototype conversational agents.;2017
Alzheimer's disease (AD) is an increasingly prevalent cognitive disorder in which memory language and executive function deteriorate usually in that order. There is a growing need to support individuals with AD and other forms of dementia in their daily lives and our goal is to do so through speech-based interaction. Given that 33% of conversations with people with middle-stage AD involve a breakdown in communication it is vital that automated dialogue systems be able to identify those breakdowns and if possible avoid them.In this article we discuss several linguistic features that are verbal indicators of confusion in AD (including vocabulary richness parse tree structures and acoustic cues) and apply several machine learning algorithms to identify dialogue-relevant confusion from speech with up to 82% accuracy. We also learn dialogue strategies to avoid confusion in the first place which is accomplished using a partially observable Markov decision process and which obtains accuracies (up to 96.1%) that are significantly higher than several baselines. This work represents a major step towards automated dialogue systems for individuals with dementia.;2017
As a result of the convergence of different services delivered over the internet protocol internet protocol television (IPTV) may be regarded as the one of the most widespread user interfaces accepted by a highly diverse user domain. Every generation from children to the elderly can use IPTV for recreation as well as for gaining social contact and stimulating the mind. However technological advances in digital platforms go hand in hand with the complexity of their user interfaces and thus induce technological disinterest and technological exclusion. Therefore interactivity and affective content presentations are from the perspective of advanced user interfaces two key factors in any application incorporating human-computer interaction (HCI). Furthermore the perception and understanding of the information (meaning) conveyed is closely interlinked with visual cues and non-verbal elements that speakers generate throughout human-human dialogues. In this regard co-verbal behavior provides information to the communicative act. It supports the speaker's communicative goal and allows for a variety of other information to be added to his/her messages including (but not limited to) psychological states attitudes and personality. In the present paper we address complexity and technological disinterest through the integration of natural human-like multimodal output that incorporates a novel combined data- and rule-driven co-verbal behavior generator that is able to extract features from unannotated general text. The core of the paper discusses the processes that model and synchronize non-verbal features with verbal features even when dealing with unknown context and/or limited contextual information. In addition the proposed algorithm incorporates data-driven (speech prosody repository of motor skills) and rule-based concepts (grammar gesticon). The algorithm firstly classifies the communicative intent then plans the co-verbal cues and their form within the gesture unit generates temporally synchronized co-verbal cues and finally realizes them in the form of human-like co-verbal movements. In this way the information can be represented in the form of both meaningfully and temporally synchronized co-verbal cues with accompanying synthesized speech using communication channels to which people are most accustomed.;2017
As human-machine communication has yet to become prevalent the rules of interactions between human and intelligent machines need to be explored. This study aims to investigate a specific question: During human users' initial interactions with artificial intelligence would they reveal their personality traits and communicative attributes differently from human-human interactions? A sample of 245 participants was recruited to view six targets' twelve conversation transcripts on a social media platform: Half with a chatbot Microsoft's Little Ice and half with human friends. The findings suggested that when the targets interacted with Little Ice they demonstrated different personality traits and communication attributes from interacting with humans. Specifically users tended to be more open more agreeable more extroverted more conscientious and self-disclosing when interacting with humans than with Al. The findings not only echo Mischel's cognitive-affective processing system model but also complement the Computers Are Social Actors Paradigm. Theoretical implications were discussed. (C) 2017 Elsevier Ltd. All rights reserved.;2017
BACKGROUND AND OBJECTIVE: With the rise of autonomous e-mental health applications virtual agents can play a major role in improving trustworthiness therapy outcome and adherence. In these applications it is important that patients adhere in the sense that they perform the tasks but also that they adhere to the specific recommendations on how to do them well. One important construct in improving adherence is psychoeducation information on the why and how of therapeutic interventions. In an e-mental health context this can be delivered in two different ways: verbally by a (virtual) embodied conversational agent or just via text on the screen. The aim of this research is to study which presentation mode is preferable for improving adherence. METHODS: This study takes the approach of evaluating a specific part of a therapy namely psychoeducation. This was done in a non-clinical sample to first test the general constructs of the human-computer interaction. We performed an experimental study on the effect of presentation mode of psychoeducation on adherence. In this study we took into account the moderating effects of attitude towards the virtual agent and recollection of the information. Within the paradigm of expressive writing we asked participants (n = 46) to pick one of their worst memories to describe in a digital diary after receiving verbal or textual psychoeducation. RESULTS AND CONCLUSION: We found that both the attitude towards the virtual agent and how well the psychoeducation was recollected were positively related to adherence in the form of task execution. Moreover after controlling for the attitude to the agent and recollection presentation of psychoeducation via text resulted in higher adherence than verbal presentation by the virtual agent did.;2017
Background: Atrial Fibrillation (AF) is a common cardiac arrhythmia that is challenging for patients and adversely impacts health-related quality of life (HRQoL). Long-term management of AF requires that patients adhere to complex therapies understand difficult terminology navigate subspecialty care and have continued symptom monitoring with the goal of preventing adverse outcomes. Continued interventions to ameliorate the patient experience of AF are essential. Design: The Atrial Fibrillation health Literacy Information Technology Trial (AF-LITT NCT03093558) is an investigator-initiated 2-arm randomized clinical trial (RCT). This RCT is a pilot in order to implement a novel smartphone-based intervention to address the patient experience of AF. This pilot RCT will compare a combination of the Embodied Conversational Agent (ECA) and the Alive Cor Kardia Mobile heart rhythm monitor to the current standard of care. The study will enroll 180 adults with non-valvular AF who are receiving anticoagulation for stroke prevention and randomize them to receive a 30-day intervention (smartphone-based ECA/Kardia) or standard of care which will include a symptom and adherence journal. The primary end-points are improvement in HRQoL and self-reported adherence to anticoagulation. The secondary end-points are the acceptability of the intervention to participants its use by participants and acceptability to referring physicians. Conclusions: The AF-LITT pilot aims to evaluate the efficacy of the ECA/Kardia to improve HRQoL and anticoagulant adherence and to guide its implementation in a larger multicenter clinical trial. The intervention has potential to improve HRQoL adherence and health care utilization in individuals with chronic AF.;2017
Background: Embodied conversational agents (ECAs) are computer-generated characters that simulate key properties of human face-to-face conversation such as verbal and nonverbal behavior. In Internet-based eHealth interventions ECAs may be used for the delivery of automated human support factors. Objective: We aim to provide an overview of the technological and clinical possibilities as well as the evidence base for ECA applications in clinical psychology to inform health professionals about the activity in this field of research. Methods: Given the large variety of applied methodologies types of applications and scientific disciplines involved in ECA research we conducted a systematic scoping review. Scoping reviews aim to map key concepts and types of evidence underlying an area of research and answer less-specific questions than traditional systematic reviews. Systematic searches for ECA applications in the treatment of mood anxiety psychotic autism spectrum and substance use disorders were conducted in databases in the fields of psychology and computer science as well as in interdisciplinary databases. Studies were included if they conveyed primary research findings on an ECA application that targeted one of the disorders. We mapped each study's background information how the different disorders were addressed how ECAs and users could interact with one another methodological aspects and the study's aims and outcomes. Results: This study included N=54 publications (N=49 studies). More than half of the studies (n=26) focused on autism treatment and ECAs were used most often for social skills training (n=23). Applications ranged from simple reinforcement of social behaviors through emotional expressions to sophisticated multimodal conversational systems. Most applications (n=43) were still in the development and piloting phase that is not yet ready for routine practice evaluation or application. Few studies conducted controlled research into clinical effects of ECAs such as a reduction in symptom severity. Conclusions: ECAs for mental disorders are emerging. State-of-the-art techniques involving for example communication through natural language or nonverbal behavior are increasingly being considered and adopted for psychotherapeutic interventions in ECA research with promising results. However evidence on their clinical application remains scarce. At present their value to clinical practice lies mostly in the experimental determination of critical human support factors. In the context of using ECAs as an adjunct to existing interventions with the aim of supporting users important questions remain with regard to the personalization of ECAs' interaction with users and the optimal timing and manner of providing support. To increase the evidence base with regard to Internet interventions we propose an additional focus on low-tech ECA solutions that can be rapidly developed tested and applied in routine practice.;2017
Background: Synchronous written conversations (or chats) are becoming increasingly popular as Web-based mental health interventions. Therefore it is of utmost importance to evaluate and summarize the quality of these interventions. Objective: The aim of this study was to review the current evidence for the feasibility and effectiveness of online one-on-one mental health interventions that use text-based synchronous chat. Methods: A systematic search was conducted of the databases relevant to this area of research (Medical Literature Analysis and Retrieval System Online [M EDLINE] PsycINFO Central Scopus EMBASE Web of Science IEEE and ACM). There were no specific selection criteria relating to the participant group. Studies were included if they reported interventions with individual text-based synchronous conversations (ie chat or text messaging) and a psychological outcome measure. Results: A total of 24 articles were included in this review. Interventions included a wide range of mental health targets (eg anxiety distress depression eating disorders and addiction) and intervention design. Overall compared with the waitlist (WL) condition studies showed significant and sustained improvements in mental health outcomes following synchronous text-based intervention and post treatment improvement equivalent but not superior to treatment as usual (TAU) (eg face-to-face and telephone counseling). Conclusions: Feasibility studies indicate substantial innovation in this area of mental health intervention with studies utilizing trained volunteers and chatbot technologies to deliver interventions. While studies of efficacy show positive post-intervention gains further research is needed to determine whether time requirements for this mode of intervention are feasible in clinical practice.;2017
Background: Web-based cognitive-behavioral therapeutic (CBT) apps have demonstrated efficacy but are characterized by poor adherence. Conversational agents may offer a convenient engaging way of getting support at any time. Objective: The objective of the study was to determine the feasibility acceptability and preliminary efficacy of a fully automated conversational agent to deliver a self-help program for college students who self-identify as having symptoms of anxiety and depression. Methods: In an unblinded trial 70 individuals age 18-28 years were recruited online from a university community social media site and were randomized to receive either 2 weeks (up to 20 sessions) of self-help content derived from CBT principles in a conversational format with a text-based conversational agent (Woebot) (n=34) or were directed to the National Institute of Mental Health ebook Depression in College Students as an information-only control group (n=36). All participants completed Web-based versions of the 9-item Patient Health Questionnaire (PHQ-9) the 7-item Generalized Anxiety Disorder scale (GAD-7) and the Positive and Negative Affect Scale at baseline and 2-3 weeks later (T2). Results: Participants were on average 22.2 years old (SD 2.33) 67% female (47/70) mostly non-Hispanic (93% 54/58) and Caucasian (79% 46/58). Participants in the Woebot group engaged with the conversational agent an average of 12.14 (SD 2.23) times over the study period. No significant differences existed between the groups at baseline and 83% (58/70) of participants provided data at T2 (17% attrition). Intent-to-treat univariate analysis of covariance revealed a significant group difference on depression such that those in the Woebot group significantly reduced their symptoms of depression over the study period as measured by the PHQ-9 (F=6.47 P=.01) while those in the information control group did not. In an analysis of completers participants in both groups significantly reduced anxiety as measured by the GAD-7 (F154=9.24 P=.004). Participants' comments suggest that process factors were more influential on their acceptability of the program than content factors mirroring traditional therapy. Conclusions: Conversational agents appear to be a feasible engaging and effective way to deliver CBT.;2017
Background: Web-based mental health interventions have evolved from innovative prototypes to evidence-based and clinically applied solutions for mental diseases such as depression and anxiety. Open-access self-guided types of these solutions hold the promise of reaching and treating a large population at a reasonable cost. However a considerable factor that currently hinders the effectiveness of these self-guided Web-based interventions is the high level of nonadherence. The absence of a human caregiver apparently has a negative effect on user adherence. It is unknown to what extent this human support can be handed over to the technology of the intervention to mitigate this negative effect. Objective: The first objective of this paper was to explore what is known in literature about what support a user needs to stay motivated and engaged in an electronic health (eHealth) intervention that requires repeated use. The second objective was to explore the current potential of embodied conversational agents (ECAs) to provide this support. Methods: This study reviews and interprets the available literature on (1) support within eHealth interventions that require repeated use and (2) the potential of ECAs by means of a scoping review. The rationale for choosing a scoping review is that the subject is broad diverse and largely unexplored. Themes for (1) and (2) were proposed based on grounded theory and mapped on each other to find relationships. Results: The results of the first part of this study suggest the presence of user needs that largely remain implicit and unaddressed. These support needs can be categorized as task-related support and emotion-related support. The results of the second part of this study suggest that ECAs are capable of engaging and motivating users of information technology applications in the domains of learning and behavioral change. Longitudinal studies must be conducted to determine under what circumstances ECAs can create and maintain a productive user relationship. Mapping the user needs on the ECAs' capabilities suggests that different kinds of ECAs may provide different solutions for improving the adherence levels. Conclusions: Autonomous ECAs that do not respond to a user's expressed emotion in real time but take on empathic roles may be sufficient to motivate users to some extent. It is unclear whether those types of ECAs are competent enough and create sufficient believability among users to address the user's deeper needs for support and empathy. Responsive ECAs may offer a better solution. However at present most of these ECAs have difficulties to assess a user's emotional state in real time during an open dialogue. By conducting future research with relationship theory-based ECAs the added value of ECAs toward user needs can be better understood.;2017
Controlled natural language (CNL) has great potential to support human-machine interaction (HMI) because it provides an information representation that is both human readable and machine processable. We investigated the effectiveness of a CNL-based conversational interface forHMIin a behavioral experiment called simple human experiment regarding locally observed collective knowledge (SHERLOCK). In SHERLOCK individuals acted in groups to discover and report information to the machine using natural language (NL) which the machine then processed into CNL. The machine fused responses from different users to form a common operating picture a dashboard showing the level of agreement for distinct information. To obtain information to add to this dashboard users explored the real world in a simulated crowd-sourced sensing scenario. This scenario represented a simplified controlled analog for tactical intelligence (i.e. direct intelligence of the environment) which is key for rapidly planning military law enforcement and emergency operations. Overall despite close to zero training 74% of the users inputted NL that was machine interpretable and addressed the assigned tasks. An experimental manipulation aimed to increase user-machine interaction however did not improve performance as hypothesized. Nevertheless results indicate that the conversational interface may be effective in assisting humans with collection and fusion of information in a crowdsourcing context.;2017
Despite recent advances in automatic speech recognition one of the main stumbling blocks to the widespread adoption of Spoken Dialogue Systems is the lack of reliability of automatic speech recognizers. In this paper we offer a two-tier error-correction process that harnesses syntactic semantic and pragmatic information to improve the understanding of spoken referring expressions specifically descriptions of objects in physical spaces. A syntactic-semantic tier offers generic corrections to perceived ASR errors on the basis of syntactic expectations of a semantic model and passes the corrected texts to a language understanding system. The output of this system which consists of pragmatic interpretations is then refined by a contextual-phonetic tier which prefers interpretations that are phonetically similar to the mis-heard words. Our results obtained on a corpus of 341 referring expressions show that syntactic-semantic error correction significantly improves interpretation performance and contextual phonetic refinements yield further improvements. (C) 2017 Elsevier Ltd. All rights reserved.;2017
Educating society concerning stigmatized conditions such as the eating disorder Anorexia Nervosa (AN) aims to change attitudes that will encourage individuals with AN to recognize their condition and decide to seek help. Embodied Conversational Agents (ECAs) may play an important role in bringing about changes in attitude and behavior because they potentially allow tailored but anonymous free and convenient access and can deliver the information in a conversational way that overcomes health literacy barriers. In this first study we compare the use of an ECA with a video to deliver two strategies (education and contact) to address stigma around the mental health condition of Anorexia Nervosa (AN). Our results with 245 participants show that both media (ECA and video) aided recognition of AN and produced significant changes in positive volitional stigma and negative volitional stigma but not in traditional stigma (desire for social distance) with some notable differences based on gender. Baseline data was used in place of a control group and the sample population was undergraduate Psychology students due to higher incidences of AN in this population. Further validation is needed involving a control group and testing on populations other than Psychology students. Nevertheless these initial results encourage our future work to build tailored ECAs to challenge particular beliefs to support a wide range of educational interventions to change behaviors and improve decision-making relating to health and wellbeing. (C) 2017 Elsevier Ltd. All rights reserved.;2017
Embodied conversational agents (ECAs) are advanced computational interactive interfaces designed with the aim to engage users in the continuous and long-term use of a background application. The advantages and benefits of these agents have been exploited in several e-health systems. One of the medical domains where ECAs are recently applied is to support the detection of symptoms prevention and treatment of mental health disorders. As ECAs based applications are increasingly used in clinical psychology and due that one fatal consequence of mental health problems is the commitment of suicide it is necessary to analyse how current ECAs in this clinical domain support the early detection and prevention of risk situations associated with suicidality. The present work provides and overview of the main features implemented in the ECAs to detect and prevent suicidal behaviours through two scenarios: ECAs acting as virtual counsellors to offer immediate help to individuals in risk and ECAs acting as virtual patients for learning/training in the identification of suicide behaviours. A literature review was performed to identify relevant studies in this domain during the last decade describing the main characteristics of the implemented ECAs and how they have been evaluated. A total of six studies were included in the review fulfilling the defined search criteria. Most of the experimental studies indicate promising results though these types of ECAs are not yet commonly used in routine practice. The identification of some open challenges for the further development of ECAs within this domain is also discussed.;2017
Embodied Conversational Agents (ECAs) are promising software to communicate with patients but no study has tested them in the diagnostic field of mental disorders. The aim of this study was 1) to test the performance of a diagnostic system for major depressive disorders (MDD) based on the identification by an ECA of specific symptoms (the MDD DSM 5 criteria) in outpatients 2) to evaluate the acceptability of such an ECA. Patients completed two clinical interviews in a randomized order (ECA versus psychiatrist) and filled in the Acceptability E-scale (AES) to quantify the acceptability of the ECA. 179 outpatients were included in this study (mean age 46.5 +/- 12.9 years 57.5% females). Among the 35 patients diagnosed with MDD by the psychiatrist 14 (40%) patients exhibited mild 12 (34.3%) moderate and 9 (25.7%) severe depressive symptoms. Sensitivity increased across the severity level of depressive symptoms and reached 73% for patients with severe depressive symptoms while specificity remained above 95% for all three severity levels. The acceptability of the ECA evaluated by the AES was very good (25.4). We demonstrate here the validity and acceptability of an ECA to diagnose major depressive disorders. ECAs are promising tools to conduct standardized and well-accepted clinical interviews.;2017
Errors in visual perception may cause problems in situated dialogues. We investigated this problem through an experiment in which human participants interacted through a natural language dialogue interface with a simulated robot. We introduced errors into the robot's perception and observed the resulting problems in the dialogues and their resolutions. We then introduced different methods for the user to request information about the robot's understanding of the environment. We quantify the impact of perception errors on the dialogues and investigate resolution attempts by users at a structural level and at the level of referring expressions.;2017
Food logging is recommended by dieticians for prevention and treatment of obesity but currently available mobile applications for diet tracking are often too difficult and timeconsuming for patients to use regularly. For this reason we propose a novel approach to food journaling that uses speech and language understanding technology in order to enable efficient self-assessment of energy and nutrient consumption. This paper presents ongoing language understanding experiments conducted as part of a larger effort to create a nutrition dialogue system that automatically extracts food concepts from a user's spoken meal description. We first summarize the data collection and annotation of food descriptions performed via Amazon Mechanical Turk (AMT) for both a written corpus and spoken data from an in-domain speech recognizer. We show that the addition of word vector features improves conditional random field (CRF) performance for semantic tagging of food concepts achieving an average F1 test score of 92.4 on written data we also demonstrate that a convolutional neural network (CNN) with no hand-crafted features outperforms the best CRF on spoken data achieving an F1 test score of 91.3. We illustrate two methods for associating foods with properties: segmenting meal descriptions with a CRF and a complementary method that directly predicts associations with a feed-forward neural network. Finally we conduct an end-to-end system evaluation through an AMTuser study with worker ratings of 83% semantic tagging accuracy.;2017
Fully automated self-help interventions can serve as highly cost-effective mental health promotion tools for massive amounts of people. However these interventions are often characterised by poor adherence. One way to address this problem is to mimic therapy support by a conversational agent. The objectives of this study were to assess the effectiveness and adherence of a smartphone app delivering strategies used in positive psychology and CBT interventions via an automated chatbot (Shim) for a non-clinical population - as well as to explore participants' views and experiences of interacting with this chatbot. A total of 28 participants were randomized to either receive the chatbot intervention (n = 14) or to a wait-list control group (n = 14). Findings revealed that participants who adhered to the intervention (n = 13) showed significant interaction effects of group and time on psychological well-being (FS) and perceived stress (PSS-10) compared to the wait-list control group with small to large between effect sizes (Cohen's d range 0.14-1.06). Also the participants showed high engagement during the 2-week long intervention with an average open app ratio of 17.71 times for the whole period. This is higher compared to other studies on fully automated interventions claiming to be highly engaging such as Woebot and the Panoply app. The qualitative data revealed sub-themes which to our knowledge have not been found previously such as the moderating format of the chatbot. The results of this study in particular the good adherence rate validated the usefulness of replicating this study in the future with a larger sample size and an active control group. This is important as the search for fully automated yet highly engaging and effective digital self-help interventions for promoting mental health is crucial for the public health.;2017
In addition to the historical importance of water electrolysis hydrogen evolution reaction (HER) is the heart of various energy storage and conversation systems in the future of renewable energy. The HER electrocatalysis can be well conducted by Pt with a low over potential close to zero and a Tafel slope around 30 mV dec(-1) however the practical developments to satisfy the growing demands require cheaper electrocatalysts. Noble metals are still the promising candidates though further improvement is needed to enhance the HER efficiency in performance. Three categories of non-noble metal electrocatalysts are under heavy investigations: (i) alloys (ii) transition metal compounds and (iii) carbonaceous nanomaterials. The most practical option based on the electrocatalytic activity and electrochemical stability seems to be the transition metal compounds MX (where M is Mo W Ni Co etc. and Xis S Se P C N etc.). Among these compounds some like MoS2 and WC can display metallic properties and a Pt-like electrocatalytic activity but they still need serious modifications for the practical performance. In general similar strategies have been employed to improve the HER performance of all of these materials such as doping (both cation and anion) controlling the crystallinity and amorphism and increasing the active sites by changing the morphology. Another important issue is the chemical and physical structure of the carbon-based catalyst support as carbon is normally a vital component even for the Pt electrocatalysts. (C) 2017 Hydrogen Energy Publications LLC. Published by Elsevier Ltd. All rights reserved.;2017
In human-human dialogue the way in which a piece of information is added to the partners' common ground (i.e. presented and accepted) constitutes an important determinant of subsequent dialogue memory. The aim of this study was to determine whether this is also the case in human-system dialogue. An experiment was conducted in which naive participants and a simulated dialogue system took turns to present references to various landmarks featured on a list. The kind of feedback used to accept these references (verbatim repetition vs. implicit acceptance) was manipulated. The participants then performed a recognition test during which they attempted to identify the references mentioned previously. Self-presented references were recognised better than references presented by the system however such presentation bias was attenuated when the initial presentation of these references was followed by verbatim repetition. Implications for the design of automated dialogue systems are discussed. (C) 2016 Elsevier Ltd. All rights reserved.;2017
In order to improve the social capabilities of embodied conversational agents we propose a computational model to enable agents to automatically select and display appropriate smiling behavior during human-machine interaction. A smile may convey different communicative intentions depending on subtle characteristics of the facial expression and contextual cues. To construct such a model as a first step we explore the morphological and dynamic characteristics of different types of smiles (polite amused and embarrassed smiles) that an embodied conversational agent may display. The resulting lexicon of smiles is based on a corpus of virtual agents' smiles directly created by users and analyzed through a machine-learning technique. Moreover during an interaction a smiling expression impacts on the observer's perception of the interpersonal stance of the speaker. As a second step we propose a probabilistic model to automatically compute the user's potential perception of the embodied conversational agent's social stance depending on its smiling behavior and on its physical appearance. This model based on a corpus of users' perceptions of smiling and nonsmiling virtual agents enables a virtual agent to determine the appropriate smiling behavior to adopt given the interpersonal stance it wants to express. An experiment using real human-virtual agent interaction provided some validation of the proposed model.;2017
In recent years there has been a huge increase in the number of bots online varying from Web crawlers for search engines to chatbots for online customer service spambots on social media and content-editing bots in online collaboration communities. The online world has turned into an ecosystem of bots. However our knowledge of how these automated agents are interacting with each other is rather poor. Bots are predictable automatons that do not have the capacity for emotions meaning-making creativity and sociality and it is hence natural to expect interactions between bots to be relatively predictable and uneventful. In this article we analyze the interactions between bots that edit articles on Wikipedia. We track the extent to which bots undid each other's edits over the period 2001-2010 model how pairs of bots interact over time and identify different types of interaction trajectories. We find that although Wikipedia bots are intended to support the encyclopedia they often undo each other's edits and these sterile fights may sometimes continue for years. Unlike humans on Wikipedia bots' interactions tend to occur over longer periods of time and to be more reciprocated. Yet just like humans bots in different cultural environments may behave differently. Our research suggests that even relatively dumb bots may give rise to complex interactions and this carries important implications for Artificial Intelligence research. Understanding what affects bot-bot interactions is crucial for managing social media well providing adequate cyber-security and designing well functioning autonomous vehicles.;2017
In the context of an international research project on older people's relations with and through mobile telephony Italian participants spontaneously provided narrations on mobile phones that appeared to be structured around strong stereotypes. Respondents show a twofold representation of mobile phones either as a simple communication tool or as a hi-tech' device which generates multifaceted stereotypes. More specifically when the mobile phone is considered as a simple communication tool age-based stereotypes address younger people's bad manners while gendered stereotypes depict women as chatterboxes' or social groomers'. On the other hand when the mobile phone is considered a hi-tech' device age-based stereotypes underline younger people's advanced user skills while gendered stereotypes focus on women's lack of competencies. Based on that we provide a conceptual framework for analysing such stereotyped - and apparently conflicting - representations. Interestingly while some issues also emerged in other countries the masculine assumption that women are less-skilled mobile phone users appears as a peculiarity of Italian respondents.;2017
In this paper we look at a specific issue with practical Turing tests namely the right of the machine to remain silent during interrogation. In particular we consider the possibility of a machine passing the Turing test simply by not saying anything. We include a number of transcripts from practical Turing tests in which silence has actually occurred on the part of a hidden entity. Each of the transcripts considered here resulted in a judge being unable to make the 'right identification' i.e. they could not say for certain which hidden entity was the machine.;2017
Intelligent Tutoring Systems personalise learning for students with different backgrounds abilities behaviours and knowledge. One way to personalise learning is through consideration of individual differences in preferred learning style. OSCAR is the name of a Conversational Intelligent Tutoring System that models a person's learning style using natural language dialogue during tutoring in order to dynamically predict and personalise their tutoring session. Prediction of learning style is undertaken by capturing independent behaviour variables during the tutoring conversation with the highest value variable determining the student's learning style. A weakness of this approach is that it does not take into consideration the interactions between behaviour variables and due to the uncertainty inherently present in modelling learning styles small differences in behaviour can lead to incorrect predictions. Consequently the learner is presented with tutoring material not suited to their learning style. This paper proposes a new method that uses fuzzy decision trees to build a series of fuzzy predictive models combining these variables for all dimensions of the Felder Silverman Learning Styles model. Results using live data show the fuzzy models have increased the predictive accuracy of OSCAR-CITS across four learning style dimensions and facilitated the discovery of some interesting relationships amongst behaviour variables. (C) 2016 Elsevier Ltd. All rights reserved.;2017
Interaction Style (IS) refers to patterns of interaction containing highly contextual and innate information. Awareness of our IS can help us discover interpersonal conflicts and guide us how to interact with others. Recently automatic IS recognition is becoming increasingly important in the design of a dialogue system for harmonious interaction. With the goal to select appropriate responses four IS types proposed by Berens are selected as the basis for our study. In this study multiple views (multi-views) of the utterances during interaction including emotions and dialogue topics are recognized first. Inspired by the emotion profile theory the IS profiles are then extracted using the multi-view features to better characterize the IS of the interactional utterances. Similar to the multilayer architectures in deep neural networks a multi-layer multi-view IS profile representation method structured layer by layer through embedding the multi-views is proposed to better interpret intermediate representations in the feature space of the interactional utterances based on a probabilistic fusion model. The IS is finally recognized by using the Support Vector Machine (SVM) based on the obtained IS profiles. Experimental results demonstrate that the proposed method achieved an encouraging IS recognition accuracy and outperformed the previous method.;2017
Introduction: Although traditional virtual patient simulations are designed to teach and assess clinical reasoning skills few employ conversational dialogue with the patients. The virtual standardized patients (VSPs) described herein represent standardized patients that students interview using natural language. Students take histories and develop differential diagnoses of the VSPs as much as they would with standardized or actual patients. The student-VSP interactions are recorded creating a comprehensive record of questions and the order in which they were asked which can be analyzed to assess information gathering skills. Students document the encounter in an electronic medical record created for the VSPs. Methods: The VSP was developed by integrating a dialogue management system (ChatScript) with emotionally responsive 3D characters created in a high-fidelity game engine (Unity). The system was tested with medical students at the Ohio State University College of Medicine. Students are able to take a history of a VSP develop a differential diagnosis and document the encounter in the electronic medical record. Results: Accuracy of the VSP responses ranged from 79% to 86% depending on the complexity of the case type of history obtained and skill of the student. Students were able to accurately develop an appropriate differential diagnosis on the basis of the information provided by the patient during the encounter. Conclusions: The VSP enables students to practice their history-taking skills before encounters with standardized or actual patients. Future developments will focus on creating an assessment module that will automatically analyze VSP sessions and provide immediate student feedback.;2017
Introduction: Benefits from mental health early interventions may not be sustained over time and longer-term intervention programs may be required to maintain early clinical gains. However due to the high intensity of face-to-face early intervention treatments this may not be feasible. Adjunctive internet-based interventions specifically designed for youth may provide a cost-effective and engaging alternative to prevent loss of intervention benefits. However until now online interventions have relied on human moderators to deliver therapeutic content. More sophisticated models responsive to user data are critical to inform tailored online therapy. Thus integration of user experience with a sophisticated and cutting-edge technology to deliver content is necessary to redefine online interventions in youth mental health. This paper discusses the development of the moderated online social therapy (MOST) web application which provides an interactive social media-based platform for recovery in mental health. We provide an overview of the system's main features and discus our current work regarding the incorporation of advanced computational and artificial intelligence methods to enhance user engagement and improve the discovery and delivery of therapy content. Methods: Our case study is the ongoing Horyzons site (5-year randomized controlled trial for youth recovering from early psychosis) which is powered by MOST. We outline the motivation underlying the project and the web application's foundational features and interface. We discuss system innovations including the incorporation of pertinent usage patterns as well as identifying certain limitations of the system. This leads to our current motivations and focus on using computational and artificial intelligence methods to enhance user engagement and to further improve the system with novel mechanisms for the delivery of therapy content to users. In particular we cover our usage of natural language analysis and chatbot technologies as strategies to tailor interventions and scale up the system. Conclusions: To date the innovative MOST system has demonstrated viability in a series of clinical research trials. Given the data-driven opportunities afforded by the software system observed usage patterns and the aim to deploy it on a greater scale an important next step in its evolution is the incorporation of advanced and automated content delivery mechanisms.;2017
Novel technology can be a powerful tool for enhancing students' interest in many learning domains. However the sustainability and overall impact of such interest is unclear. This study tests the longer term effects of technology on students' task and course interest. The experimental study was conducted with students in foreign language classes (n = 122): a 12-week experimental trial that included pre and post-course interest and a sequence of task interest measures. Employing a counterbalanced design at three week intervals students engaged in separate speaking tasks with each of a Human and Chatbot partner. Students' interest in successive tasks and in the course (pre-post) were used to assess differential partner effects and course interest development trajectories. Comparisons of task interest under different partner conditions over time indicated a significant drop in students' task interest with the Chatbot but not Human partner. After accounting for initial course interest Structural Equation Modelling indicated that only task interest with the Human partner contributed to developing course interest. While Human partner task interest predicted future course interest task interest under Chatbot partner conditions did not. Under Chatbot partner conditions there was a drop in task interest after the first task: a novelty effect. Implications for theory and practice are discussed. (C) 2017 Elsevier Ltd. All rights reserved.;2017
Objective: This randomized controlled trial evaluates the feasibility of using an Embodied Conversational Agent (ECA) to teach lifestyle modifications to urban women. Methods: Women were randomized to either 1) an ECA (content included: mindfulness stress management physical activity and healthy eating) or 2) patient education sheets mirroring same content plus a meditation CD/MP3 once a day for one month. General outcome measures included: number of stress management techniques used physical activity levels and eating patterns. Results: Sixty-one women ages 18 to 50 were enrolled. On average 51% identified as white 26% as black 23% as other races and 20% as Hispanic. The major stress management techniques reported at baseline were: exercise (69%) listening to music (70%) and social support (66%). After one month women randomized to the ECA significantly decreased alcohol consumption to reduce stress (p = 0.03) and increased daily fruit consumption by an average of 2 servings compared to the control (p = 0.04). Conclusion: It is feasible to use an ECA to promote health behaviors on stress management and healthy eating among diverse urban women. (C) 2017 Elsevier B.V. All rights reserved.;2017
Objective: Verbal and non-verbal behaviors which are known as relational contextualization cues relay information about relationships and how they are structured. We developed a computer-simulated provider conducting an informed consent process for clinical research to investigate the effects of a provider's alignment of interests with a patient the research team or a neutral party on patient trust in the provider. Methods: Participants (N = 43) interacted with a simulated provider for a research informed consent process in a three-arm counterbalanced within-subjects experiment. Participants reported their trust in the simulated provider after each treatment. Results: Participants successfully recognized the alignment manipulation and perceived the patient-aligned provider as more trustworthy than the other providers. Participants were also more satisfied with the patient-aligned provider liked this provider more expressed more desire to continue working with this provider and stated that they were significantly more likely to sign the consent form after interacting with this provider compared to the other two. Conclusion: Relational contextualization that aligns with the patient increases trust satisfaction and willingness to enroll in the context of research informed consent. (C) 2017 Elsevier B.V. All rights reserved.;2017
Objectives: To assess advanced communication skills among second-year medical students exposed either to a computer simulation (MPathic-VR) featuring virtual humans or to a multimedia computerbased learning module and to understand each group's experiences and learning preferences. Methods: A single-blinded mixed methods randomized multisite trial compared MPathic-VR (N = 210) to computer-based learning (N = 211). Primary outcomes: communication scores during repeat interactions with MPathic-VR's intercultural and interprofessional communication scenarios and scores on a subsequent advanced communication skills objective structured clinical examination (OSCE). Multivariate analysis of variance was used to compare outcomes. Secondary outcomes: student attitude surveys and qualitative assessments of their experiences with MPathic-VR or computer-based learning. Results: MPathic-VR-trained students improved their intercultural and interprofessional communication performance between their first and second interactions with each scenario. They also achieved significantly higher composite scores on the OSCE than computer-based learning-trained students. Attitudes and experiences were more positive among students trained with MPathic-VR who valued its providing immediate feedback teaching nonverbal communication skills and preparing them for emotion-charged patient encounters. Conclusions: MPathic-VR was effective in training advanced communication skills and in enabling knowledge transfer into a more realistic clinical situation. Practice implications: MPathic-VR's virtual human simulation offers an effective and engaging means of advanced communication training. (C) 2016 Elsevier Ireland Ltd. All rights reserved.;2017
Oxygen evolution reaction (OER) is one of the central reactions in the realm of electrochemistry and has been subject to numerous studies over centuries but still one of the most complicated electrochemical processes and is of practical importance. It has attracted considerable attention quite recently because of its critical role in various energy storage and conversation systems. However the quest for finding the most efficient electrocatalysts is still undergoing and various materials and designs have been recently tested to improve the OER efficiency. By surveying the literature the present paper concludes that the most reasonable design for the practical development of the OER electrocatalysts is based on a carbon catalyst support and transition metal compounds decorated by metallic catalysts. Based on the available reports the key features which are beneficial for improving the OER efficiency are summarized. Furthermore since the OER is based on a series of adsorption processes as pseudocapacitance is it is demonstrated that electrode materials with stronger pseudocapacitive behaviors are more likely to deliver better OER performance. (c) 2017 Elsevier Ltd. All rights reserved.;2017
Question generation is an emerging research area of artificial intelligence in education. Question authoring tools are important in educational technologies e.g. intelligent tutoring systems as well as in dialogue systems. Approaches to generate factual questions i.e. questions that have concrete answers mainly make use of the syntactical and semantic information in a declarative sentence which is then transformed into questions. Recently some research has been conducted to investigate Chinese factual question generation with some limited success. Reported performance is poor due to unavoidable errors (e.g. sentence parsing name entity recognition and rule-based question transformation errors) and the complexity of long Chinese sentences. This article introduces a novel Chinese question generation systembased on three stages sentence simplification question generation and ranking to address the challenge of automatically generating factual questions in Chinese. The proposed approach and systemhave been evaluated on sentences from the New Practical Chinese Reader corpus. Experimental results show that ranking improves more than 20 percentage of questions rated as acceptable by annotators from 65 percent of all questions to 87 percent of the top ranked 25 percent questions.;2017
Recent progress in both AI and robotics have enabled the development of general purpose robot platforms that are capable of executing a wide variety of complex temporally extended service tasks in open environments. This article introduces a novel custom-designed multi-robot platform for research on AI robotics and especially human-robot interaction for service robots. Called BWIBots the robots were designed as a part of the Building-Wide Intelligence (BWI) project at the University of Texas at Austin. The article begins with a description of and justification for the hardware and software design decisions underlying the BWIBots with the aim of informing the design of such platforms in the future. It then proceeds to present an overview of various research contributions that have enabled the BWIBots to better (a) execute action sequences to complete user requests (b) efficiently ask questions to resolve user requests (c) understand human commands given in natural language and (d) understand human intention from afar. The article concludes with a look forward towards future research opportunities and applications enabled by the BWIBot platform.;2017
Research in computer-supported collaborative learning has indicated that conversational agents can be pedagogically beneficial when used to scaffold students' online discussions. In this study we investigate the impact of an agile conversational agent that triggers student dialogue by making interventions based on the academically productive talk framework. An experimental activity in the context of a university course involved 72 undergraduate students who discussed online in dyads. Two conditions were compared: (a) dyads who received agent interventions while working on a learning task (treatment) and (b) dyads who worked on the same task without any agent interference (control). Utilizing a concept map created by the course instructor the conversational agent delivered unsolicited interventions that encouraged treatment students to build on their prior knowledge linking their current contributions to the main domain principles discussed during the course. Study findings indicate that the agent intervention mode substantially improved both individual and group learning outcomes. Evidence suggests that the agent effect on learning performance was mediated by students' explicit reasoning which was also found to be enhanced in the treatment condition.;2017
Scaled acquisition of high-quality structured knowledge has been a longstanding goal of Artificial Intelligence research. Recent advances in crowdsourcing the sheer number of Internet and mobile users and the commercial availability of supporting platforms offer new tools for knowledge acquisition. This article applies context-aware knowledge acquisition that simultaneously satisfies users' immediate information needs while extending its own knowledge using crowdsourcing. The focus is on knowledge acquisition on a mobile device which makes the approach practical and scalable in this context we propose and implement a new KA approach that exploits an existing knowledge base to drive the KA process communicate with the right people and check for consistency of the user-provided answers. We tested the viability of the approach in experiments using our platform with real users around the world and an existing large source of common-sense background knowledge. These experiments show that the approach is promising: the knowledge is estimated to be true and useful for users 95% of the time. Using context to proactively drive knowledge acquisition increased engagement and effectiveness (the number of new assertions/day/user increased for 175%). Using pre-existing and newly acquired knowledge also proved beneficial.;2017
Server-side socialbot detection approaches can identify malicious accounts and spams in online social networks. However they cannot detect socialbot processes residing on user hosts which control these accounts. Therefore new approaches are needed to detect socialbots on hosts. The fundamental to design host-side detecting approaches is to gain an insight into the behaviors of socialbots on host. In this article we analyzed a series of representative socialbots in depth and summarized the typical features of socialbot behaviors. We proposed a new approach to defense against socialbots on end host. The contributions of this article are threefold: (1) our analysis approach can be used for reference during analyzing new socialbots in the future (2) we provide several behavior features of socialbots on hosts including network flow through which socialbots communicate with botmasters through the online social network system calls via which socialbots conduct an activity and process information of socialbots running on hosts. These features can be used by someone to design approaches to identifying socialbots on a host (3) our proposed detection approach can effectively distinguish between a socialbot and a benign application on end hosts.;2017
Smart mobile devices have fostered new interaction scenarios for Ambient Intelligence that demand sophisticated interfaces. The main developers of operating systems for such devices have provided APIs for developers to implement their own applications including different solutions for developing graphical interfaces sensor control and voice interaction. Despite the usefulness of such resources there are no strategies defined for coupling the multimodal interface with the possibilities that the devices offer to identify and adapt to the user needs. This way current apps are usually developed ad-hoc and the spoken interface is conceived as an input for simple commands. In this paper we present a practical mobile application that integrates features of Android APIs on a modular architecture that emphasizes multimodal conversational interaction and context-awareness to foster user-adaptivity robustness and maintainability.;2017
Smart mobile devices have fostered new learning scenarios that demand sophisticated interfaces. Multimodal conversational agents have became a strong alternative to develop human-machine interfaces that provide a more engaging and human-like relationship between students and the system. The main developers of operating systems for such devices have provided application programming interfaces for developers to implement their own applications including different solutions for developing graphical interfaces sensor control and voice interaction. Despite the usefulness of such resources there are no strategies defined for coupling the multimodal interface with the possibilities that these devices offer to enhance mobile educative apps with intelligent communicative capabilities and adaptation to the user needs. In this paper we present a practical m-learning application that integrates features of Android application programming interfaces on a modular architecture that emphasizes interaction management and context-awareness to foster user-adaptively robustness and maintainability.;2017
Social isolation in older adults is a major public health concern. An embodied conversational agent (ECA) has the potential to enhance older adults' social interaction. However little is known about older adults' experience with an ECA. In this paper we conducted a pilot study to examine the perceived acceptance and utility of a tablet-based conversational agent in the form of an avatar (termed digital pet) for older adults. We performed secondary analysis of data collected from a study that employed the use of a digital pet in ten older adults' homes for three months. Most of the participants enjoyed the companionship entertainment reminders and instant assistance from the digital pet. However participants identified limited conversational ability and technical issues as system challenges. Privacy dependence and cost were major concerns. Future applications should maximize the agent's conversational ability and the system's overall usability. Our results can inform future designs of conversational agents for older adults which need to include older adults as system co-designers to maximize usability and acceptance. (C) 2017 Elsevier Inc. All rights reserved.;2017
Social robots are intended to coexist and to communicate with humans in a natural way. This requires these robots to be able to identify people (and objects) around them to use that information during human-robot dialogs. In this work we present how electronic beacons can benefit the interactions between humans and social robots. In particular Bluetooth 4.0 Low Energy beacons are presented as the most suitable option among the up-to-date available technologies. In order to show the advantages of the system during human-robot interaction first we present the integration of the information provided by these devices in the robot's dialog system and after a hidden toy hunt game is described as a case study of a scenario where electronic beacons ease the interaction between humans and a social robot. (C) 2017 Elsevier Ltd. All rights reserved.;2017
Social skills training performed by human trainers is a well-established method for obtaining appropriate skills in social interaction. Previous work automated the process of social skills training by developing a dialogue system that teaches social communication skills through interaction with a computer avatar. Even though previous work that simulated social skills training only considered acoustic and linguistic information human social skills trainers take into account visual and other non-verbal features. In this paper we create and evaluate a social skills training system that closes this gap by considering the audiovisual features of the smiling ratio and the head pose (yaw and pitch). In addition the previous system was only tested with graduate students in this paper we applied our system to children or young adults with autism spectrum disorders. For our experimental evaluation we recruited 18 members from the general population and 10 people with autism spectrum disorders and gave them our proposed multimodal system to use. An experienced human social skills trainer rated the social skills of the users. We evaluated the system's effectiveness by comparing pre- and post-training scores and identified significant improvement in their social skills using our proposed multimodal system. Computer-based social skills training is useful for people who experience social difficulties. Such a system can be used by teachers therapists and social skills trainers for rehabilitation and the supplemental use of human-based training anywhere and anytime.;2017
Speech interfaces to conversational systems have been a focus in academia and industry for over a decade due to its applicability as a natural interface. Speech recognition and speech synthesis constitute the important input and output modules respectively for such spoken interface systems. In this paper the speech recognition interface for question answering applications is reviewed and existing limitations are discussed. The existing spoken question answering (QA) systems use an automatic speech recogniser by adapting acoustic and language models for the speech interface and off-the-shelf language processing systems for question interpretation. In the process the impact of recognition errors and language processing inaccuracies is neglected. It is illustrated in the paper how a semantically rich knowledge graph can be used to solve automatic speech recognition and language processing specific problems. A simple concatenation of a speech recogniser and a natural language processing system is a shallow method for a speech interface. An effort beyond merely concatenating these two units is required to develop a successful spoken question answering system. It is illustrated in this paper how a knowledge graph based structured data can be used to build a unified system combining speech recognition and language understanding. This facilitates the use of a semantically rich data model for speech interface. (C) 2017 Elsevier B.V. All rights reserved.;2017
Speech-driven head movement methods are motivated by the strong coupling that exists between head movements and speech providing an appealing solution to create behaviors that are timely synchronized with speech. This paper offers solutions for two of the problems associated with these methods. First speech-driven methods require all the potential utterances of the conversational agent (CA) to be recorded which limits their applications. Using existing text to speech (TTS) systems scales the applications of these methods by providing the flexibility of using text instead of pre-recorded speech. However simply training speech-driven models with natural speech and testing them with synthetic speech creates a mismatch affecting the performance of the system. This paper proposes a novel strategy to solve this mismatch. The proposed approach starts by creating a parallel corpus either with neutral or emotional synthetic speech timely aligned with the original speech for which we have the motion capture recordings. This parallel corpus is used to retrain the models from scratch or adapt the models originally built with natural speech. Both subjective and objective evaluations show the effectiveness of this solution in reducing the mismatch. Second creating head movement with speech-driven methods can disregard the meaning of the message even when the movements are perfectly synchronized with speech. The trajectory of head movements in conversations also has a role in conveying meaning (e.g. head nods for acknowledgment). In fact our analysis reveals that head movements under different discourse functions have distinguishable patterns. Building on the best models driven by synthetic speech we propose to extract dialog acts directly from the text and use this information to directly constrain our models. Compared to the unconstrained model the model generates head motion sequences that not only are closer to the statistical patterns of the original head movements but also are perceived as more natural and appropriate. (C) 2017 Elsevier B.V. All rights reserved.;2017
Spoken dialog systems are employed in various devices to help users operate them. An advantage of a spoken dialog system is that the user can make input utterances freely but the system sometimes makes it difficult for the user to speak to it. The system should estimate the state of a user who encounters a problem when starting a dialog and then give appropriate help before the user abandons the dialog. Based on this assumption our research aims to construct a system which responds to a user who does not reply to the system. In this paper we propose a method of discriminating the user's state based on vector quantization of non-verbal information such as prosodic features facial feature points and gaze. The experimental results showed that the proposed method outperforms the conventional approaches and achieves a discrimination ratio of 72.0%. Then we examined sequential discrimination for responding to the user at an appropriate timing. The results indicate that the discrimination ratio reached equal to the end of the session at around 6.0 s.;2017
Spoken dialogue systems allow humans to interact with machines using natural speech. As such they have many benefits. By using speech as the primary communication medium a computer interface can facilitate swift human-like acquisition of information. In recent years speech interfaces have become ever more popular as is evident from the rise of personal assistants such as Siri Google Now Cortana and Amazon Alexa. Recently data-driven machine learning methods have been applied to dialogue modelling and the results achieved for limited-domain applications are comparable to or out-perform traditional approaches. Methods based on Gaussian processes are particularly effective as they enable good models to be estimated from limited training data. Furthermore they provide an explicit estimate of the uncertainty which is particularly useful for reinforcement learning. This article explores the additional steps that are necessary to extend these methods to model multiple dialogue domains. We show that Gaussian process reinforcement learning is an elegant framework that naturally supports a range of methods including prior knowledge Bayesian committee machines and multi-agent learning for facilitating extensible and adaptable dialogue systems. (C) 2016 The Authors. Published by Elsevier Ltd.;2017
The classical experimental methodology is ill-suited for the investigation of the behavioral and physiological correlates of natural social interactions. A new experimental approach combining a natural conversation between two persons with control conditions is proposed in this paper. Behavior including gaze direction and speech and physiology including electrodermal activity are recorded during a discussion between two participants through videoconferencing. Control for the social aspect of the interaction is provided by the use of an artificial agent and of videoed conditions. A cover story provides spurious explanations for the purpose of the experiment and for the recordings as well as a controlled and engaging topic of discussion. Preprocessing entails transforming raw measurements into boxcar and delta functions time series indicating when a certain behaviour or physiological event is present. The preliminary analysis presented here consists in finding statistically significant differences between experimental conditions in the temporal associations between behavioral and physiological time series. Significant results validate the experimental approach and further developments including more elaborate analysis and adaptation of the paradigm to functional MRI are discussed.;2017
The tourism sector in the province of Teruel (Aragon Spain) is increasing rapidly. Although the number of domestic and foreign tourists is continuously growing there are some tourist attractions spread over a wide geographical area which are only visited by a few people at specific times of the year. Additionally having human tourist guides everywhere and speaking different languages is unfeasible. An integrated solution based on smart and interactive Embodied Conversational Agents (ECAs) tourist guides combined with ontologies would overcome this problem. This paper presents a smart tourist information points approach which gathers tourism information about Teruel structured according to a novel lightweight ontology built on OWL (Ontology Web Language) known as TITERIA (Touristic Information of TEruel for Intelligent Agents). Our proposal which combines TITERIA with the Maxine platform is capable of responding appropriately to the users thanks to its Artificial Intelligence Modeling Language (AIML) database and the AI techniques added to Maxine. Preliminary results indicate that our prototype is able to inform users about interesting topics as well as to propose other related information allowing them to acquire a complete information about any issue. Furthermore users can directly talk with an artificial actor making communication much more natural and closer.;2017
The use of expressive Virtual Characters is an effective complementary means of communication for social networks offering multi-user 3D-chatting environment. In such contexts the facial expression channel offers a rich medium to translate the ongoing emotions conveyed by the text-based exchanges. However until recently only purely symmetric facial expressions have been considered for that purpose. In this article we examine human sensitivity to facial asymmetry in the expression of both basic and complex emotions. The rationale for introducing asymmetry in the display of facial expressions stems from two well-established observations in cognitive neuroscience: first that the expression of basic emotions generally displays a small asymmetry second that more complex emotions such as ambivalent feeling may reflect in the partial display of different potentially opposite emotions on each side of the face. A frequent occurrence of this second case results from the conflict between the truly felt emotion and the one that should be displayed due to social conventions. Our main hypothesis is that a much larger expressive and emotional space can only be automatically synthesized by means of facial asymmetry when modeling emotions with a general Valence-Arousal-Dominance dimensional approach. Besides we want also to explore the general human sensitivity to the introduction of a small degree of asymmetry into the expression of basic emotions. We conducted an experiment by presenting 64 pairs of static facial expressions one symmetric and one asymmetric illustrating eight emotions (three basic and five complex ones) alternatively for a male and a female character. Each emotion was presented four times by swapping the symmetric and asymmetric positions and by mirroring the asymmetrical expression. Participants were asked to grade on a continuous scale the correctness of each facial expression with respect to a short definition. Results confirm the potential of introducing facial asymmetry for a subset of the complex emotions. Guidelines are proposed for designers of embodied conversational agent and emotionally reflective avatars.;2017
There is growing conviction that the future of computing depends on our ability to exploit big data on the Web to enhance intelligent systems. This includes encyclopedic knowledge for factual details common sense for human-like reasoning and natural language generation for smarter communication. With recent chatbots conceivably at the verge of passing the Turing Test there are calls for more common sense oriented alternatives e.g. the Winograd Schema Challenge. The Aristo QA system demonstrates the lack of common sense in current systems in answering fourth-grade science exam questions. On the language generation front despite the progress in deep learning current models are easily confused by subtle distinctions that may require linguistic common sense e.g.quick food vs. fast food. These issues bear on tasks such as machine translation and should be addressed using common sense acquired from text. Mining common sense from massive amounts of data and applying it in intelligent systems in several respects appears to be the next frontier in computing. Our brief overview of the state of Commonsense Knowledge (CSK) in Machine Intelligence provides insights into CSK acquisition CSK in natural language applications of CSK and discussion of open issues. This paper provides a report of a tutorial at a recent conference with a brief survey of topics.;2017
This article describes conversation-based assessments with computer agents that interact with humans through chat talking heads or embodied animated avatars. Some of these agents perform actions interact with multimedia hold conversations with humans in natural language and adaptively respond to a person's actions verbal contributions and emotions. Data are logged throughout the interactions in order to assess the individual's mastery of subject matters skills and proficiencies on both cognitive and noncognitive characteristics. There are different agent-based designs that focus on learning and assessment. Dialogues occur between one agent and one human as in the case of intelligent tutoring systems. Three-party conversations called trialogues involve two agents interacting with a human. The two agents can take on different roles (such as tutors and peers) model actions and social interactions stage arguments solicit help from the human and collaboratively solve problems. Examples of assessment with these agent-based environments are presented in the context of intelligent tutoring educational games and interventions to help struggling adult readers. Most of these involve assessment at varying grain sizes to guide the intelligent interaction but conversation-based assessment with agents is also currently being used in high stakes assessments. (C) 2017 Published by Elsevier Ltd.;2017
This paper deals with the relevance of the first impression of interactive systems based on short passive visual/auditory stimuli of system output. Individual consistency between such impressions and retrospective user ratings obtained directly after real interaction is studied in four exploratory experiments. All systems allow for voice user input. Two systems are considered to be multimodal as they support additional input other than speech (e.g. gesture) whereas the other two systems offering speech as the sole input modality are multimedia systems. The first impression of the four systems is based on screen-shots of typical display views and selected prompts of the systems' speech output. Measures used here were pragmatic quality (i.e. the functional aspects of a system such as efficiency and effectiveness that are closely related to the concept of usability) and hedonic qualities (i.e. the systems non-instrumental aspects such as its ability to provide stimulation and identification-to evoke the psychological well-being of the user. It was tested whether consistency found for web-sites can also be found for speech-based systems. In our case this consistency was assessed not between systems but within systems. Results indicate that users' first impression of system output does correlate with ratings collected after the interaction for each of the four systems. For the two truly multimodal systems ratings after single input (e.g. only voice only touch screen) also correlates with ratings of a multimodal interaction with the same system. This result confirms data from literature. However our assumption of lower correlations for the first impression of pragmatic quality expected due to its experience-based character is not supported. Instead pragmatic quality seems to represent a construct with low consistency in general. Reasons for this might be found in the benefit of pragmatic quality experienced during multimodal interaction that is neither covered by unimodal interaction nor predictable from a first impression. Additional multiple regression analysis for the two systems with multiple input modalities show that the first impression of the visual system output can complement predictors from the single modality interactions to model post-usage multimodal ratings. However which of the output channels has a relevant impact was found to be highly system dependent.;2017
This paper discusses the development of an emotion model for robot partner system. In our previous studies we have focused only on the robot's emotional state. However the emotional state of the other party is also an important factor for smooth conversation in human society. Therefore the robot partner has two emotional structures for human: empathy and robot emotion. First human empathy uses a perceptual based emotion model to know the human's emotional state based on the sensory information. Next we propose a recurrent simple spike response model to improve the robot's emotional model and we apply Hebbian-LMS learning to modify the weights in the spiking neural network. The robot's emotional state is calculated by using the human's emotional information internal and external information. The robot partner can use the emotional results to control the facial and gesture expression. The utterance style is also changed by the robot's emotional state. As a result the robot partner can interact emotionally and naturally with human. First we explain the related works and the development of the robot partner iPhonoid-C. Next we define the architecture of the emotional model to realize emotional empathy towards human. Then we discuss the algorithms and the methods for developing the emotional model. Finally we show experimental results of the proposed method and discuss the effectiveness of the proposed structure.;2017
This paper presents a system to detect multiple intents (MIs) in an input sentence when only single-intent (SI)-labeled training data are available. To solve the problem this paper categorizes input sentences into three types and uses a two-stage approach in which each stage attempts to detect MIs in different types of sentences. In the first stage the system generates MI hypotheses based on conjunctions in the input sentence then evaluates the hypotheses and then selects the best one that satisfies specified conditions. In the second stage the system applies sequence labeling to mark intents on the input sentence. The sequence labeling model is trained based on SI-labeled training data. In experiments the proposed two-stage MI detection method reduced errors for written and spoken input by 20.54 and 17.34 % respectively.;2017
This paper presents GRASS (Graz corpus of Read and Spontaneous Speech) the first large scale speech database for Austrian German with both read and conversational speech. In total the corpus contains approximately 1900 min of speech in which 38 speakers produced more than 220000 word tokens from 14593 different word types. The corpus consists of three components. First the Conversational Speech Component contains free conversations of one hour length between friends colleagues couples or family members. Second the Commands Component contains commands and keywords which were either read or elicited by pictures. Third the Read Speech Component contains phonetically balanced sentences and digits. The speech of all components has been recorded at fullband quality in a soundproof recording-studio with head-mounted microphones large diaphragm microphones a laryngograph and with a video camera. The corpus was fully annotated at the orthographic level and partly also at the segmental sub-segmental and prosodic level. Our analysis of conversational speech characteristics such as overlapping speech laughter repetitions hesitations and the use of colloquial and dialectal words allows us to conclude that the conversational speech material is highly casual in nature. The collected corpus provides conversational material for phoneticians and linguists interested in topics specific for Austrian German (e.g. pronunciation variability prosody syntax of spoken Austrian German) and for those studying talk in interaction in general (turn-taking grounding entrainment extra-linguistic factors etc.). Furthermore it is a valuable resource for speech technologists interested in the development of ASR and dialogue systems for different speaking styles of Austrian German.;2017
This paper proposes a new approach to automatically detect dementia. Even though some works have detected dementia from speech and language attributes most have applied detection using picture descriptions narratives and cognitive tasks. In this paper we propose a new computer avatar with spoken dialog functionalities that produces spoken queries based on the mini-mental state examination the Wechsler memory scale-revised and other related neuropsychological questions. We recorded the interactive data of spoken dialogues from 29 participants (14 dementia and 15 healthy controls) and extracted various audiovisual features. We tried to predict dementia using audiovisual features and two machine learning algorithms (support vector machines and logistic regression). Here we show that the support vector machines outperformed logistic regression and by using the extracted features they classified the participants into two groups with 0.93 detection performance as measured by the areas under the receiver operating characteristic curve. We also newly identified some contributing features e.g. gap before speaking the variations of fundamental frequency voice quality and the ratio of smiling. We concluded that our system has the potential to detect dementia through spoken dialog systems and that the system can assist health care workers. In addition these findings could help medical personnel detect signs of dementia.;2017
This research presents two studies in a lab (eye-tracking) and in a natural context that highlight the effects of interacting with an animated conversational agents (ACA) on the objective and perceived econsumer productivity. Results from Study 1 specify that only objective e-consumer productivity depends on interaction with the ACA. Going further Study 2 then reveals that individual characteristics affect perceived productivity either independently from ACA use (for involvement or product familiarity) or in interaction with using the ACA (for Internet skills and need for interaction). These findings highlight the need to personalize websites that display an agent fitting user profiles. (C) 2016 Published by Elsevier B.V.;2017
This study investigates how user satisfaction and intention to use for an interactive movie recommendation system is determined by communication variables and relationship between conversational agent and user. By adopting the Computers-Are-Social-Actors (CASA) paradigm and uncertainty reduction theory this study examines the influence of self-disclosure and reciprocity as key communication variables on user satisfaction. A two-way ANOVA test was conducted to analyze the effects of self-disclosure and reciprocity on user satisfaction with a conversational agent. The interactional effect of self-disclosure and reciprocity on user satisfaction was not significant but the main effects proved to be both significant. PLS analysis results showed that perceived trust and interactional enjoyment are significant mediators in the relationship between communication variables and user satisfaction. In addition reciprocity is a stronger variable than self-disclosure in predicting relationship building between an agent and a user. Finally user satisfaction is an influential factor of intention to use. These findings have implications from both practical and theoretical perspective.;2017
To ensure satisfactory user experience dialog systems must be able to determine whether an input sentence is in-domain (ID) or out-of-domain (OOD). We assume that only ID sentences are available as training data because collecting enough OOD sentences in an unbiased way is a laborious and time-consuming job. This paper proposes a novel neural sentence embedding method that represents sentences in a low dimensional continuous vector space that emphasizes aspects that distinguish ID cases from OOD cases. We first used a large set of unlabeled text to pre-train word representations that are used to initialize neural sentence embedding. Then we used domain-category analysis as an auxiliary task to train neural sentence embedding for OOD sentence detection. After the sentence representations were learned we used them to train an autoencoder aimed at OOD sentence detection. We evaluated our method by experimentally comparing it to the state-of-the-art methods in an eight-domain dialog system our proposed method achieved the highest accuracy in all tests. (C) 2017 Elsevier B.V. All rights reserved.;2017
Truly universal helper robots capable of coping with unknown unstructured environments must be capable of spatial reasoning i.e. establishing geometric relations between objects and locations expressing those in terms understandable by humans. It is therefore desirable that spatial and semantic environment representations are tightly interlinked. 3D robotic mapping and the generation of consistent metric representations of space are highly useful for navigation and exploration but they do not capture symbol-level information about the environment. This is however essential for reasoning and enables interaction via natural language which is arguably the most common and natural communication channel used and understood by humans. This article presents a review of research in three major fields relevant for this discussion of spatial reasoning and interaction. Firstly dialogue systems are an integral part of modern approaches to situated human-robot interaction. Secondly interactive robots must be equipped with environment representations and reasoning methods that are suitable for both navigation and task fulfillment as well as for interaction with human partners. Thirdly at the interface between these domains are systems that ground language in systemic environment representation and which allow the integration of information from natural language descriptions into robotic maps. For each of these areas important approaches are outlined and relations between the fields are highlighted and challenging applications as well as open problems are discussed.;2017
We hypothesize that conversational implicatures are a rich source of clarification requests and in this paper we do two things. First we motivate the hypothesis in theoretical practical and empirical terms and formulate it as a concrete clarification potential principle: implicatures may become explicit as fourth-level clarification requests. Second we present a framework for generating the clarification potential of an instruction by inferring its conversational implicatures with respect to a particular context. We evaluate the framework and illustrate its performance using a human human corpus of situated conversations. Much of the inference required can be handled using classical planning though as we shall note other forms of means-ends analysis are also required. Our framework leads us to view discourse structure as emerging via opportunistic responses to task structure. (C) 2017 Elsevier Ltd. All rights reserved.;2017
When consumers post questions online who influences the content of the discussion more: the consumer posting the question or those who respond to the post? Analyses of data from real online discussion forums and four experiments show that early responses to a post tend to drive the content of the discussion as much as or more than the content of the initial query. Although advice seekers posting to online discussion forums often explicitly tell respondents which attributes are most important to them the authors demonstrate that one common online posting goal affiliation makes respondents more likely to repeat attributes mentioned by previous respondents even if those attributes are less important to the advice seeker or support a suboptimal choice given the advice seeker's decision criteria. Firms listening in on social media should account for this systematic bias when making decisions on the basis of the discussion content.;2017
While physical inactivity is a key risk factor for a range of chronic diseases and conditions associated with aging a significant proportion of midlife and older adults remain insufficiently active. This is particularly true for ethnic minority populations such as Latino adults for whom few culturally adapted programs have been developed and tested. The major objective of this 12-month cluster-randomized controlled trial is to test the comparative effectiveness of two linguistically and culturally adapted community-based physical activity interventions with the potential for broad reach and translation. Ten local community centers serving a sizable number of Latino residents were randomized to receive one of two physical activity interventions. The Virtual Advisor program employs a computer-based embodied conversational agent named Carmen to deliver interactive individually tailored physical activity advice and support. A similar intervention program is delivered by trained Peer Advisors. The target population consists of generally healthy insufficiently active Latino adults ages 50 years and older living within proximity to a designated community center. The major outcomes are changes in walking and other forms of physical activity measured via self-report and accelerometry. Secondary outcomes include physical function and well-being variables. In addition to these outcome analyses comparative cost analysis of the two programs potential mediators of intervention success and baseline moderators of intervention effects will be explored to better determine which subgroups do best with which type of intervention. Here we present the study design and methods including recruitment strategies and yield as well as study baseline characteristics.;2017
With the exponential growth in computing power and progress in speech recognition technology spoken dialog systems (SDSs) with which a user interacts through natural speech has been widely used in human-computer interaction. However error-prone automatic speech recognition (ASR) results usually lead to inappropriate semantic interpretation so that miscommunication happens easily. This paper presents an approach to error-aware dialog state (DS) detection for robust miscommunication handling in an SDS. Non-understanding (Non-U) and misunderstanding (Mis-U) are considered for miscommunication handling in this study. First understanding evidence (UE) derived from the recognition confidence is adopted for Non-U detection followed by Non-U recovery. For Mis-U with the recognized sentence containing uncertain recognized words the partial sentences obtained by removing potentially misrecognized words from the input utterance are organized based on regular expressions as a tree structure to tolerate the deletion or rejection of keywords resulting from misrecognition for Mis-U DS modeling. Latent semantic analysis is then employed to consider the verified words and their n-grams for DS detection including Mis-U and predefined Base DSs. Historical information-based n-grams are employed to find the most likely DS for the SDS. Several experiments were performed with a dialog corpus for the restaurant reservation task. The experimental results show that the proposed approach achieved a promising performance for Non-U recovery and Mis-U repair as well as a satisfactory task success rate for the dialogs using the proposed method.;2017
Working in an interdisciplinary manner at the crossroads of alcohol and HIV research is a challenge. This paper presents six novel approaches that could be applied to activities at the intersection of alcohol and HIV. These approaches are (i) address the fact that the availability of new technology is unevenly distributed around the world (ii) use technology to move beyond both paper and digital surveys (iii) introduce a focus on advocacy and partnerships with large technology companies (iv) harness technological innovation to utilise digital counselling (v) explore the use of virtual reality in both research and delivering interventions and (vi) consider alternative funding models to those currently in existence to improve efficiencies and innovations. Aiming to understand the interplay of alcohol and HIV will require creativity. The six approaches outlines in this paper provide possible directions from which new approaches may emerge.;2017
A chatbot is an example of a text-based conversational agent. While natural language understanding and machine learning techniques have advanced rapidly current fully automated chatbots still struggle to serve their users well. Human intelligence brought by crowd workers freelancers or even full-time employees can be embodied in the chatbot logic to fill the gaps caused by limitations of fully automated solutions. In this paper we investigate human-aided bots i.e. bots (including chatbots) using humans in the loop to operate. We survey industrial and academic examples of human-aided bots discuss their differences and common patterns and identify open research questions.;2018
A dialogue system should capture speakers' intentions which can be represented by combinations of speech acts predicators and sentiments. To identify these intentions from speakers' utterances many studies have independently dealt with speech acts predicators and sentiments. However these three elements composing speakers' intentions are tightly associated with each other. To resolve this problem we propose a convolutional neural network model that simultaneously identifies speech acts predicators and sentiments. The proposed model has well-designed hidden layers for embedding informative abstractions appropriate for speech act identification predicator identification and sentiment identification. Nodes in the hidden layers are partially trained by three cycles of error backpropagation: training the nodes associated with speech act identification predicator identification and sentiment identification. In the experiments the proposed model showed higher F1-scores than independent models: 6.8% higher in speech act identification 6.2% higher in predicator identification and 4.9% higher in sentiment identification. Based on the experimental results we conclude that the proposed integration architecture and partial error backpropagation can help to increase the performance of intention identification. (C) 2017 Elsevier B.V. All rights reserved.;2018
After much debate and synthesis social learning scholarship is entering an era of empirical research. Given the range across individual- network- and systems-level perspectives and scales clear documentation of social learning processes is critical for making claims about social learning outcomes and their impacts. Past studies have relied on participant recall and concept maps to document perceptions of social learning process and outcome. Using an individual-centric perspective and importing ideas from communication and psychology on question-answer learning through conversational agents we contribute an expanded conceptual framework and qualitative analytical strategy for assessing stakeholder dialogue for evidence of social learning. We observed stakeholder dialogue across five workshops coordinated for the Bruneau-Owyhee Sage-Grouse Habitat Project (BOSH) in Owyhee County Idaho USA. Participants' dialogue was audio recorded transcribed and analyzed for cross-case patterns. Deductive and inductive coding techniques were applied to illuminate cognitive relational and epistemic dimensions of learning and topics of learning. A key finding supports our inclusion of the epistemic dimension and highlights a need for future research: although some participants articulated epistemic positions they did not challenge each other to share sources or justify factual claims. These findings align with previous research suggesting that in addition to considering diversity and representation (who is at the table) we should pay more attention to how participants talk perhaps prompting specific patterns of speech as we endeavor to draw causal connections between social learning processes and outcomes.;2018
As chatbots have become increasingly popular over the past years most social networking sites have recognized their far-reaching potential for commercial purposes. Their rapid and widespread usage warrants a better understanding. This study examines the effectiveness of chatbots on Facebook for brands. The study proposes and tests a model based on the Consumer Acceptance of Technology model (CAT-model) including three cognitive (i.e. perceived usefulness perceived ease-of-use and perceived helpfulness) and three affective (pleasure arousal and dominance PAD-dimensions) determinants that potentially influence consumers' attitude toward brands providing a chatbot and hence their likelihood to use and recommend the chatbot (i.e. patronage intention). Structural equation modeling analyses show that two cognitive (i.e. perceived usefulness and perceived helpfulness) and all three affective predictors are positively related to consumers' attitude toward the chatbot brand. The findings further indicate that attitude toward the brand explained a significant amount of variation in consumers' patronage intention. Finally all the significant determinants also have an indirect effect on patronage intention mediated through attitude toward the brand. In conclusion our findings hold valuable practical implications as well as relevant suggestions for future research.;2018
As genetic testing gains ground in medicine the ability to search across the suite of biomedical and clinical care databases offered through the National Library of Medicine/National Center for Biotechnology Information (NCBI)-such as PubMed GENE Structure the Genetic Testing Registry and others-holds the potential to enhance quality of clinical care best practices. Plutchik is a voice-enabled embodied artificial intelligence (AI) chatbot that can perform highly technical medical searches in and across the NCBI suite of databases.;2018
Asthma and chronic obstructive pulmonary disease are obstructive respiratory diseases that affect negatively the quality of life for patients and their families worldwide. Despite the significance of these diseases their management has been considered suboptimal around the world whereas the improper inhaler use has been underlined as one of the main causes. Toward this direction this paper presents an integrated mHealth system that provides real-time personalized feedback to patients for assessing the proper medication use and educating them and helping them avoid common mistakes. The identification of proper inhaler use is based on conventional and data-driven feature extraction and classification methods employed for the identification of four events (inhaler actuation inhalation exhalation and background noise). The proposed scheme reaches 98% classification accuracy significantly outperforming recent and relevant state-of-the-art approaches. Finally intuitive feedback interfaces were implemented in the form of a virtual guidance agent integrated with the mobile application which can help patients follow their action plan and assess their inhaler technique in a more engaging manner. Extensive simulation studies carried out using 12 subjects demonstrated the efficiency of the proposed approaches in both indoor and outdoor environments.;2018
Automatic chatbots (also known as chat-agents) have attracted much attention from both researching and industrial fields. Generally the semantic relevance between users' queries and the corresponding responses is considered as the essential element for conversation modeling in both generation and ranking based chat systems. By contrast it is a nontrivial task to adopt the users' information such as preference social role etc. into conversational models reasonably while users' profiles play a significant role in the procedure of conversations by providing the implicit contexts. This paper aims to address the personalized response ranking task by incorporating user profiles into the conversation model. In our approach users' personalized representations are latently learned from the contents posted by them via a two-branch neural network. After that a deep neural network architecture is further presented to learn the fusion representation of posts responses and personal information. In this way the proposed model could understand conversations from the users' perspective hence the more appropriate responses are selected for a specified person. The experimental results on two datasets from social network services demonstrate that our approach is hopeful to represent users' personal information implicitly based on user generated contents and it is promising to perform as an important component in chatbots to select the personalized responses for each user.;2018
Background: A World Health Organization 2017 report stated that major depression affects almost 5% of the human population. Major depression is associated with impaired psychosocial functioning and reduced quality of life. Challenges such as shortage of mental health personnel long waiting times perceived stigma and lower government spends pose barriers to the alleviation of mental health problems. Face-to-face psychotherapy alone provides only point-in-time support and cannot scale quickly enough to address this growing global public health challenge. Artificial intelligence (AI)-enabled empathetic and evidence-driven conversational mobile app technologies could play an active role in filling this gap by increasing adoption and enabling reach. Although such a technology can help manage these barriers they should never replace time with a health care professional for more severe mental health problems. However app technologies could act as a supplementary or intermediate support system. Mobile mental well-being apps need to uphold privacy and foster both short- and long-term positive outcomes. Objective: This study aimed to present a preliminary real-world data evaluation of the effectiveness and engagement levels of an AI-enabled empathetic text-based conversational mobile mental well-being app Wysa on users with self-reported symptoms of depression. Methods: In the study a group of anonymous global users were observed who voluntarily installed the Wysa app engaged in text-based messaging and self-reported symptoms of depression using the Patient Health Questionnaire-9. On the basis of the extent of app usage on and between 2 consecutive screening time points 2 distinct groups of users (high users and low users) emerged. The study used mixed-methods approach to evaluate the impact and engagement levels among these users. The quantitative analysis measured the app impact by comparing the average improvement in symptoms of depression between high and low users. The qualitative analysis measured the app engagement and experience by analyzing in-app user feedback and evaluated the performance of a machine learning classifier to detect user objections during conversations. Results: The average mood improvement (ie difference in pre- and post-self-reported depression scores) between the groups (ie high vs low users n=108 and n=21 respectively) revealed that the high users group had significantly higher average improvement (mean 5.84 [SD 6.66]) compared with the low users group (mean 3.52 [SD 6.15]) Mann-Whitney P=.03 and with a moderate effect size of 0.63. Moreover 67.7% of user-provided feedback responses found the app experience helpful and encouraging. Conclusions: The real-world data evaluation findings on the effectiveness and engagement levels of Wysa app on users with self-reported symptoms of depression show promise. However further work is required to validate these initial findings in much larger samples and across longer periods.;2018
Background: Conversational agents cannot yet express empathy in nuanced ways that account for the unique circumstances of the user. Agents that possess this faculty could be used to enhance digital mental health interventions. Objective: We sought to design a conversational agent that could express empathic support in ways that might approach or even match human capabilities. Another aim was to assess how users might appraise such a system. Methods: Our system used a corpus-based approach to simulate expressed empathy. Responses from an existing pool of online peer support data were repurposed by the agent and presented to the user. Information retrieval techniques and word embeddings were used to select historical responses that best matched a user's concerns. We collected ratings from 37169 users to evaluate the system. Additionally we conducted a controlled experiment (N=1284) to test whether the alleged source of a response (human or machine) might change user perceptions. Results: The majority of responses created by the agent (2986/3770 79.20%) were deemed acceptable by users. However users significantly preferred the efforts of their peers (P<.001). This effect was maintained in a controlled study (P=.02) even when the only difference in responses was whether they were framed as coming from a human or a machine. Conclusions: Our system illustrates a novel way for machines to construct nuanced and personalized empathic utterances. However the design had significant limitations and further research is needed to make this approach viable. Our controlled study suggests that even in ideal conditions nonhuman agents may struggle to express empathy as well as humans. The ethical implications of empathic agents as well as their potential iatrogenic effects are also discussed.;2018
Background: Conversational assistants such as Siri Alexa and Google Assistant are ubiquitous and are beginning to be used as portals for medical services. However the potential safety issues of using conversational assistants for medical information by patients and consumers are not understood. Objective: To determine the prevalence and nature of the harm that could result from patients or consumers using conversational assistants for medical information. Methods: Participants were given medical problems to pose to Siri Alexa or Google Assistant and asked to determine an action to take based on information from the system. Assignment of tasks and systems were randomized across participants and participants queried the conversational assistants in their own words making as many attempts as needed until they either reported an action to take or gave up. Participant-reported actions for each medical task were rated for patient harm using an Agency for Healthcare Research and Quality harm scale. Results: Fifty-four subjects completed the study with a mean age of 42 years (SD 18). Twenty-nine (54%) were female 31 (57%) Caucasian and 26 (50%) were college educated. Only 8 (15%) reported using a conversational assistant regularly while 22 (41%) had never used one and 24 (44%) had tried one  a few times. Forty-four (82%) used computers regularly. Subjects were only able to complete 168 (43%) of their 394 tasks. Of these 49 (29%) reported actions that could have resulted in some degree of patient harm including 27 (16%) that could have resulted in death. Conclusions: Reliance on conversational assistants for actionable medical information represents a safety risk for patients and consumers. Patients should be cautioned to not use these technologies for answers to medical questions they intend to act on without further consultation from a health care provider.;2018
Background: Healthcare services particularly in patient-provider interaction often involve highly emotional situations and it is important for physicians to understand and respond to their patients' emotions to best ensure their well-being. Methods: In order to model the emotion domain we have created the Visualized Emotion Ontology (VEO) to provide a semantic definition of 25 emotions based on established models as well as visual representations of emotions utilizing shapes lines and colors. Results: As determined by ontology evaluation metrics VEO exhibited bettermachine-readability (z = 1.12) linguistic quality (z = 0.61) and domain coverage (z = 0.39) compared to a sample of cognitive ontologies. Additionally a survey of 1082 participants through Amazon Mechanical Turk revealed that a significantly higher proportion of people agree than disagree with 17 out of our 25 emotion images validating the majority of our visualizations. Conclusion: From the development evaluation and serialization of the VEO we have defined a set of 25 emotions using OWL that linked surveyed visualizations to each emotion. In the future we plan to use the VEO in patient-facing software tools such as embodied conversational agents to enhance interactions between patients and providers in a clinical environment.;2018
Background: Recent years have seen an increase in the use of internet-based cognitive behavioral therapy in the area of mental health. Although lower effectiveness and higher dropout rates of unguided than those of guided internet-based cognitive behavioral therapy remain critical issues not incurring ongoing human clinical resources makes it highly advantageous. Objective: Current research in psychotherapy which acknowledges the importance of therapeutic alliance aims to evaluate the feasibility and acceptability in terms of mental health of an application that is embodied with a conversational agent. This application was enabled for use as an internet-based cognitive behavioral therapy preventative mental health measure. Methods: Analysis of the data from the 191 participants of the experimental group with a mean age of 38.07 (SD 10.75) years and the 263 participants of the control group with a mean age of 38.05 (SD 13.45) years using a 2-way factorial analysis of variance (group x time) was performed. Results: There was a significant main effect (P=.02) and interaction for time on the variable of positive mental health (P=.02) and for the treatment group a significant simple main effect was also found (P=.002). In addition there was a significant main effect (P=.02) and interaction for time on the variable of negative mental health (P=.005) and for the treatment group a significant simple main effect was also found (P=.001). Conclusions: This research can be seen to represent a certain level of evidence for the mental health application developed herein indicating empirically that internet-based cognitive behavioral therapy with the embodied conversational agent can be used in mental health care. In the pilot trial given the issues related to feasibility and acceptability it is necessary to pursue higher quality evidence while continuing to further improve the application based on the findings of the current research.;2018
Background: Students in need of mental health care face many barriers including cost location availability and stigma. Studies show that computer-assisted therapy and 1 conversational chatbot delivering cognitive behavioral therapy (CBT) offer a less-intensive and more cost-effective alternative for treating depression and anxiety. Although CBT is one of the most effective treatment methods applying an integrative approach has been linked to equally effective posttreatment improvement. Integrative psychological artificial intelligence (AI) offers a scalable solution as the demand for affordable convenient lasting and secure support grows. Objective: This study aimed to assess the feasibility and efficacy of using an integrative psychological AI Tess to reduce self-identified symptoms of depression and anxiety in college students. Methods: In this randomized controlled trial 75 participants were recruited from 15 universities across the United States. All participants completed Web-based surveys including the Patient Health Questionnaire (PHQ-9) Generalized Anxiety Disorder Scale (GAD-7) and Positive and Negative Affect Scale (PANAS) at baseline and 2 to 4 weeks later (T2). The 2 test groups consisted of 50 participants in total and were randomized to receive unlimited access to Tess for either 2 weeks (n=24) or 4 weeks (n=26). The information-only control group participants (n=24) received an electronic link to the National Institute of Mental Health's (NIMH) eBook on depression among college students and were only granted access to Tess after completion of the study. Results: A sample of 74 participants completed this study with 0% attrition from the test group and less than 1% attrition from the control group (1/24). The average age of participants was 22.9 years with 70% of participants being female (52/74) mostly Asian (37/74 51%) and white (32/74 41%). Group 1 received unlimited access to Tess with daily check-ins for 2 weeks. Group 2 received unlimited access to Tess with biweekly check-ins for 4 weeks. The information-only control group was provided with an electronic link to the NIMH's eBook. Multivariate analysis of covariance was conducted. We used an alpha level of .05 for all statistical tests. Results revealed a statistically significant difference between the control group and group 1 such that group 1 reported a significant reduction in symptoms of depression as measured by the PHQ-9 (P=.03) whereas those in the control group did not. A statistically significant difference was found between the control group and both test groups 1 and 2 for symptoms of anxiety as measured by the GAD-7. Group 1 (P=.045) and group 2 (P=.02) reported a significant reduction in symptoms of anxiety whereas the control group did not. A statistically significant difference was found on the PANAS between the control group and group 1 (P=.03) and suggests that Tess did impact scores. Conclusions: This study offers evidence that AI can serve as a cost-effective and accessible therapeutic agent. Although not designed to appropriate the role of a trained therapist integrative psychological AI emerges as a feasible option for delivering support. Trial Registration: International Standard Randomized Controlled Trial Number: ISRCTN61214172 https://doi.org/10.1186/ISRCTN61214172.;2018
Background: Substance use disorders are under-detected and not systematically diagnosed or screened for by primary care. In this study we present the acceptability and validity of an Embodied Conversational Agent (ECA) designed to screen tobacco and alcohol use disorder in individuals who did not seek medical help for these disorders. Methods: Individuals were included from June 2016 to May 2017 in the Outpatient Sleep Clinic of the University Hospital of Bordeaux. DSM-5 diagnoses of tobacco and alcohol use disorders were assessed by human interviewers. The ECA interview integrated items from the Cigarette Dependence Scale-5 (CDS-5) for tobacco use disorder screening and the Cut Down Annoyed Guilty Eye-opener (CAGE) questionnaire for alcohol use disorder screening. Paper version of CDS-5 and CAGE questionnaires and acceptability questionnaire was also self-administered. Results: Of the 139 participants in the study (mean age 43.0 [SD = 13.7] years) 71 were women and 68 were men. The ECA was well accepted by the patients. Paper self-administered CDS-5 and CAGE scores had a strong agreement with the ECA (p < 0.0001). The Receiver Operating Characteristic (ROC) analysis of the ECA interview showed AUC of 0.97 (95% CI 0.93-1.0) and 0.84 (95% CI 0.69-0.98) for CDS-5 and CAGE respectively with p-value < 0.0001. Conclusions: This ECA was acceptable and valid to screen tobacco or alcohol use disorder among patients not requesting treatment for addiction. The ECA could be used in hospitals and potentially in primary care settings to help clinicians to better screen their patients for alcohol and tobacco use disorders.;2018
Chatbots are computer programs designed to chat with users via text or voice through the use of techniques of Web services data analysis and artificial intelligence (AI). Currently the use of chatbot is becoming an important trend in the field of data science. An increasing number of chatbots are being built on social platforms such as Facebook LINE and Slack. This has led to the development of numerous tools and online platforms for the construction of chatbots however most of these services do not provide comprehensive support for the visual representation and control of conversational flows bi-directional Web service integration or the systematic reuse of conversations. Developing a complex chatbot with external Web services requires the writing of extensive conversation scripts and additional coding. In this paper we propose a visual flow-based approach to the construction of chatbots on the Node-RED platform referred to as FCF (Flow-based Chatbot Framework). This system is based on the newly-devised data format for Webhook thereby allowing bidirectional service integration for software applications. Five chatbot dialogue patterns and three chatbot application scenarios are provided to be components for the construction of complex chatbot applications.;2018
Communities are at risk from extreme events and natural disasters that can lead to dangerous situations for residents. Improving resilience by helping people learn how to better prepare for recover from and adapt to disasters is critical to reduce the impacts of these extreme events. This project presents an intelligent system Flood AI designed to improve societal preparedness for flooding by providing a knowledge engine that uses voice recognition artificial intelligence and natural language processing based on a generalized ontology for disasters with a primary focus on flooding. The knowledge engine uses flood ontology to connect user input to relevant knowledge discovery channels on flooding by developing a data acquisition and processing framework using environmental observations forecast models and knowledge bases. The framework's communication channels include web-based systems agent-based chatbots smartphone applications automated web workflows and smart home devices opening the knowledge discovery for flooding to many unique use cases.;2018
Conversational agents (CM) are becoming an increasingly common component in a wide range of information systems. A great deal of research to date has focused on enhancing traits that make CM more humanlike. However few studies have examined the influence such traits have on information disclosure. This research builds on self-disclosure social desirability and social presence theories to explain how CA anthropomorphism affects disclosure of personally sensitive information. Taken together these theories suggest that as CM become more humanlike the social desirability of user responses will increase. In this study we use a laboratory experiment to examine the influence of two elements of CA design-conversational relevance and embodiment on the answers people give in response to sensitive and non-sensitive questions. We compare the responses given to various CM to those given in a face-to-face interview and an online survey. The results show that for sensitive questions CAs with better conversational abilities elicit more socially desirable responses from participants with a less significant effect found for embodiment. These results suggest that for applications where eliciting honest answers to sensitive questions is important CAs that are better in terms of humanlike realism may not be better for eliciting truthful responses to sensitive questions.;2018
Conversational agents could provide timely and cost-effective social support to promote behavioral changes and improve healthcare outcomes. The authors evaluated the performance of their social media-based conversational agent in a smoking cessation program. Results showed that the presence of a conversational agent effectively increased participant engagement and enhanced their smoking cessation outcomes.;2018
Conversational robots which are used in the fields of education therapy and in expositions are expected to keep a user engaged in conversation. However these robots sometimes utter comments that are irrelevant topic to the current context owing to a failure in recognizing the human user's speech or intention. Such a sudden topic shift is considered to interfere with what we call the sense of conversation with which a person can feel as if he or she is participating in a conversation. In this paper to reduce the interferes of the sudden topic shift we propose to use multiple robots in a conversation in which even an actually irrelevant sudden topic shift sounds involving possible relevance to be shared with subjects in the ongoing conversation. To verify it we conducted an experiment in which subjects experienced a conversation with either one or two robots and then evaluated their impression of the conversations. The experimental results showed that the subjects who talked with two robots felt less ignored by the robots and had less difficulty in continuing the conversation with them than those who talked with a single robot. Further analysis considering subjects' social skills raised the possibility of an additional effect on robot coherence perception. Finally we discuss a new disruption-tolerant conversational system design using multiple robots based on the experimental results.;2018
Conversational systems have come a long way since their inception in the 1960s. After decades of research and development we have seen progress from Eliza and Parry in the 1960s and 1970s to task-completion systems as in the Defense Advanced Research Projects Agency (DARPA) communicator program in the 2000s to intelligent personal assistants such as Siri in the 2010s to today's social chatbots like XiaoIce. Social chatbots' appeal lies not only in their ability to respond to users' diverse requests but also in being able to establish an emotional connection with users. The latter is done by satisfying users' need for communication affection as well as social belonging. To further the advancement and adoption of social chatbots their design must focus on user engagement and take both intellectual quotient (IQ) and emotional quotient (EQ) into account. Users should want to engage with a social chatbot as such we define the success metric for social chatbots as conversation-turns per session (CPS). Using XiaoIce as an illustrative example we discuss key technologies in building social chatbots from core chat to visual awareness to skills. We also show how XiaoIce can dynamically recognize emotion and engage the user throughout long conversations with appropriate interpersonal responses. As we become the first generation of humans ever living with artificial intelligenc (AI) we have a responsibility to design social chatbots to be both useful and empathetic so they will become ubiquitous and help society as a whole.;2018
Current advances in the development of mobile and smart devices have generated a growing demand for natural human-machine interaction and favored the intelligent assistant metaphor in which a single interface gives access to a wide range of functionalities and services. Conversational systems constitute an important enabling technology in this paradigm. However they are usually defined to interact in semantic-restricted domains in which users are offered a limited number of options and functionalities. The design of multi-domain systems implies that a single conversational system is able to assist the user in a variety of tasks. In this paper we propose an architecture for the development of multi-domain conversational systems that allows: (1) integrating available multi and single domain speech recognition and understanding modules (2) combining available system in the different domains implied so that it is not necessary to generate new expensive resources for the multi-domain system (3) achieving better domain recognition rates to select the appropriate interaction management strategies. We have evaluated our proposal combining three systems in different domains to show that the proposed architecture can satisfactory deal with multi-domain dialogs. (C) 2017 Elsevier B.V. All rights reserved.;2018
Dependency analysis is vital for spoken language understanding in spoken dialogue systems. However existing research has mainly focused on western spoken languages Japanese and so on. Little research has been done for spoken Chinese in terms of dependency parsing. Therefore the new spoken corpus D-ESCSC (Dependency-Expressive Speech Corpus of Standard Chinese) is built by adding new dependency relations special to spoken Chinese based on a written Chinese annotation scheme. Since spoken Chinese contains typical ill-grammatical phenomena e.g. translocation repetition duplication and omission the new atom feature related to punctuation and three feature templates are proposed to improve a graph-based dependency parser. Experimental results on spoken Chinese corpus show that the atom feature and three templates really work and the new parser outperforms the baseline parser. To our best knowledge it is the first work to report dependency parsing results of spoken Chinese.;2018
Dialog state tracking in a spoken dialog system is the task that tracks the flow of a dialog and identifies accurately what a user wants from the utterance. Since the success of a dialog is influenced by the ability of the system to catch the requirements of the user accurate state tracking is important for spoken dialog systems. This paper proposes a two-step neural dialog state tracker which is composed of an informativeness classifier and a neural tracker. The informativeness classifier which is implemented by a CNN first filters out noninformative utterances in a dialog. Then the neural tracker estimates dialog states from the remaining informative utterances. The tracker adopts the attention mechanism and the hierarchical softmax for its performance and fast training. To prove the effectiveness of the proposed model we do experiments on dialog state tracking in the human-human task-oriented dialogs with the standard DSTC4 data set. Our experimental results prove the effectiveness of the proposed model by showing that the proposed model outperforms the neural trackers without the informativeness classifier the attention mechanism or the hierarchical softmax.;2018
Digitalization has advanced spreading to all industries. Companies are required to improve marketing efficiency and strengthen engagement with customers more than ever by utilizing digital technology. Promoting emotional value through the customers service user experience is important and contact centers play a key role in the experience as customer contact points for companies. However contact centers currently face a mountain of problems including labor shortages support for diversifying channels and the need to improve efficiency by making use of Al. To solve these problems Fujitsu has started offering the Customer Engagement Solution CHORDSHIP a contact point sophistication solution. The CHORDSHIP Digital Agent which is at the core of CHORDSHIP is equipped with an Al technology ideal for contact centers: conversation-machine learning hybrid Al. Its biggest feature is the capability to deliver highly accurate automatic answers simply by using existing FAQ data in addition to its realization of support for diversifying channels and 24/7 service availability. This paper outlines the contact point sophistication solution offered by Fujitsu and describes the Al chatbot technology behind the solution.;2018
Disclosing personal information to another person has beneficial emotional relational and psychological outcomes. When disclosers believe they are interacting with a computer instead of another person such as a chatbot that can simulate human-to-human conversation outcomes may be undermined enhanced or equivalent. Our experiment examined downstream effects after emotional versus factual disclosures in conversations with a supposed chatbot or person. The effects of emotional disclosure were equivalent whether participants thought they were disclosing to a chatbot or to a person. This study advances current understanding of disclosure and whether its impact is altered by technology providing support for media equivalency as a primary mechanism for the consequences of disclosing to a chatbot.;2018
Disembodied conversational agents in the form of chatbots are increasingly becoming a reality on social media and messaging applications and are a particularly pressing topic for service encounters with companies. Adopting an experimental design with actual chatbots powered with current technology this study explores the extent to which human-like cues such as language style and name and the framing used to introduce the chatbot to the consumer can influence perceptions about social presence as well as mindful and mindless anthropomorphism. Moreover this study investigates the relevance of anthropomorphism and social presence to important company-related outcomes such as attitudes satisfaction and the emotional connection that consumers feel with the company after interacting with the chatbot. (C) 2018 Elsevier Ltd. All rights reserved.;2018
Embodied Conversational Agent (ECA) offer a new means to support smokers as a virtual coach and motivate them to quit smoking. In this study we assess the feasibility and acceptability of an ECA to support quit smoking (aka ECA-Q). ECA-Q a 14-days program delivered through Tablet computers interacts with participants with supporting messages for quit smoking and motivates them to set a quit date. Study participants (n = 6) were Veterans receiving medical care at Boston VA Healthcare System who responded to an open advertisement. Participants completed a survey at baseline and after 14 days follow-up. All participants were satisfied with the ECA program and liked the features of the agent three out of six participants had set a quit date by the end of the 14 days. Participants reported several positive and less important features of the agent and made suggestions to improve the agent. This study shows that a conversation agent is acceptable to smoking veterans to help them in setting a quit date with an ultimate goal of quit smoking. Insights gained from this study would be useful to redesign the current version of ECA-Q program for a future randomized controlled trial to test the efficacy. (C) 2018 Atlantis Press International B.V.;2018
Embodied Conversational Agents (ECAs) are interactive characters that exhibit human-like qualities such as facial expressions lip-synch or emotional voice and are able to communicate with humans or with other ECAs by using natural human capabilities (speech gestures etc.). However to make current ECAs' dialogue management strategies more appealing and real to the user they should be aware of general knowledge about the external world. This factual knowledge which is independent of personal experience should be stored in their semantic memory. This paper presents a knowledge-based solution to improve learning through ECAs with factual knowledge based on semantics. In particular we build this semantic memory by means of a novel proposal known as Daira. Moreover we integrated Daira with Maxine a powerful animation engine for developing applications with embodied animated agents. To illustrate the potential of our approach we designed a proof of concept in which our system is able to provide data from the online Great Aragonese Encyclopedia (GEA) written in Spanish to engage students. The experiments performed show the feasibility and efficiency of our proposal. In particular we demonstrated that using enriched ECAS when searching information can enhance learning motivation and learning performance making the interaction process much more accurate simpler and near to the students.;2018
Empathy has been defined in the scientific literature as the capacity to relate another's emotional state and assigned to a broad spectrum of cognitive and behavioral abilities. Advances in neuroscience psychology and ethology made it possible to refine the defined functions of empathy to reach a working definition and a model of empathy. Recently cognitive science and artificial intelligence communities made attempts to model empathy in artificial agents which can provide means to test these models and hypotheses. A computational model of empathy not only would help to advance the technological artifacts to be more socially compatible but also understand the empathy mechanisms test theories and address the ethics and morality problems the Artificial Intelligence (AI) community is facing today. In this paper we will review the empathy research from various fields gather the requirements for empathic capacity and construct a model of empathy that is suitable for interactive conversational agents.;2018
Gaze is an important aspect of social communication. Previous research has concentrated mainly on the role of speaker gaze and listener gaze in isolation neglecting the effect of the listener's gaze behavior on the speaker's behavior. This paper presents an exploratory eye-tracking study involving an interactive human-like agent following participants' gaze. This study demonstrates that a rather simple gaze-following mechanism convincingly simulates active listening behavior engaging the speaker. The study also highlights how speakers rely on their interlocutors' gaze when establishing common references.;2018
In light of recent trends toward enhancing customer contact points companies must clarify the issues they face how they intend to solve them and their specific objectives while aiming for step-by-step improvements. To this end many companies are starting to provide chatbots to automate communication with people using computers as a service for interacting with customers. This movement is also being felt in the financial industry that handles a variety of complex products and services and there are already cases of using chatbots for customer support and sales. Fujitsu has developed FUJITSU Financial Services Solution Finplex Robot Agent Platform (hereafter FRAP) an AI-based enterprise chatbot service. FRAP achieves automatic robot support of financial-product sales and customer support by having users converse in a chat format with a robot having knowledge accumulated by machine learning. This paper first introduces trends in enterprise chatbot services and examples of using them in business applications. It then presents a case study of introducing FRAP in Sony Bank Inc. and describes its features.;2018
In recent times with the increasing interest in conversational agents for smart homes task-oriented dialog systems are being actively researched. However most of these studies are focused on the individual modules of such a system and there is an evident lack of research on a dialog framework that can integrate and manage the entire dialog system. Therefore in this study we propose a framework that enables the user to effectively develop an intelligent dialog system. The proposed framework ontologically expresses the knowledge required for the task-oriented dialog system's process and can build a dialog system by editing the dialog knowledge. In addition the framework provides a module router that can indirectly run externally developed modules. Further it enables a more intelligent conversation by providing a hierarchical argument structure (HAS) to manage the various argument representations included in natural language sentences. To verify the practicality of the framework an experiment was conducted in which developers without any previous experience in developing a dialog system developed task-oriented dialog systems using the proposed framework. The experimental results show that even beginner dialog system developers can develop a high-level task-oriented dialog system.;2018
In spoken dialogue systems we aim to deploy artificial intelligence to build automated dialogue agents that can converse with humans. A part of this effort is the policy optimization task which attempts to find a policy describing how to respond to humans in the form of a function taking the current state of the dialogue and returning the response of the system. In this paper we investigate deep reinforcement learning approaches to solve this problem. Particular attention is given to actor-critic methods off-policy reinforcement learning with experience replay and various methods aimed at reducing the bias and variance of estimators. When combined these methods result in the previously proposed ACER algorithm that gave competitive results in gaming environments. These environments however are fully observable and have a relatively small action set so in this paper we examine the application of ACER to dialogue policy optimization. We show that this method beats the current state of the art in deep learning approaches fir spoken dialogue systems. This not only leads to a more sample efficient algorithm that can train faster but also allows us to apply the algorithm in more difficult environments than before. We thus experiment with learning in a very large action space which has two orders of magnitude more actions than previously considered. We find that ACER trains significantly faster than the current state of the art.;2018
In this paper we highlight the different challenges in modeling communicative gestures for Embodied Conversational Agents (ECAs). We describe models whose aim is to capture and understand the specific characteristics of communicative gestures in order to envision how an automatic communicative gesture production mechanism could be built. The work is inspired by research on how human gesture characteristics (e.g. shape of the hand movement orientation and timing with respect to the speech) convey meaning. We present approaches to computing where to place a gesture which shape the gesture takes and how gesture shapes evolve through time. We focus on a particular model based on theoretical frameworks on metaphors and embodied cognition that argue that people can represent reason about and convey abstract concepts using physical representations and processes which can be conveyed through physical gestures.;2018
In this paper we present a software platform called Chatbot designed to introduce high school students to Computer Science (CS) concepts in an innovative way: by programming chatbots. A chatbot is a bot that can be programmed to have a conversation with a human or robotic partner in some natural language such as English or Spanish. While programming their chatbots students use fundamental CS constructs such as variables conditionals and finite state automata among others. Chatbot uses pattern matching state of the art lemmatization techniques and finite state automata in order to provide automatic formative assessment to the students. When an error is found the formative feedback generated is immediate and task-level. We evaluated Chatbot in two observational studies. An online nation-wide competition where more than 10000 students participated. And a mandatory in-class 15-lesson pilot course in three high schools. We measured indicators of student engagement (task completion participation self reported interest etc.) and found that girls' engagement with Chatbot was higher than boys' for most indicators. Also in the online competition the task completion rate for the students that decided to use Chatbot was five times higher than for the students that chose to use the renowned animation and game programming tool Alice. Our results suggest that the availability of automatic formative assessment may have an impact on task completion and other engagement indicators among high school students.;2018
In this paper a web-based spoken dialog generation environment which enables users to edit dialogs with a video virtual assistant is developed and to also select the 3D motions and tone of voice for the assistant. In our proposed system anyone can easily post/edit contents of the dialog for the dialog system. The dialog type corresponding to the system is limited to the question-and-answer type dialog in order to avoid editing conflicts caused by editing by multiple users. The spoken dialog sharing service and FST generator generates spoken dialog content for the MMDAgent spoken dialog system toolkit which includes a speech recognizer a dialog control unit a speech synthesizer and a virtual agent. For dialog content creation question-and-answer dialogs posted by users and FST templates are used. The proposed system was operated for more than a year in a student lounge at the Nagoya Institute of Technology where users added more than 500 dialogs during the experiment. Images were also registered to 65% of the postings. The most posted category is related to animation video games manga.The system was subjected to open examination by tourist information staff who had no prior experience with spoken dialog systems. Based on their impressions of tourist use of the dialog system they shortened the length of some of the system's responses and added pauses to the longer responses to make them easier to understand.;2018
In this paper we address issues in situated language understanding in a moving car. More specifically we propose a reference resolution method to identify user queries about specific target objects in their surroundings. We investigate methods of predicting which target object is likely to be queried given a visual scene and what kind of linguistic cues users naturally provide to describe a given target object in a situated environment. We propose methods to incorporate the visual saliency of the visual scene as a prior. Crowdsourced statistics of how people describe an object are also used as a prior. We have collected situated utterances from drivers using our research system which was embedded in a real vehicle. We demonstrate that the proposed algorithms improve target identification rate by 15.1% absolute over the baseline method that does not use visual saliency-based prior and depends on public database with a limited number of category information. (C) 2017 Elsevier Ltd. All rights reserved.;2018
In this paper we present a novel strategy to face the problem of dimensionality within datasets involved in conversational and feature selection systems. We base our work on a sound and complete logic along with an efficient attribute closure method to manage implications. All of them together allow us to reduce the overload of information we encounter when dealing with these kind of systems. An experiment carried out over a dataset containing real information comes to expose the benefits of our design. Copyright (c) 2017 John Wiley & Sons Ltd.;2018
In this paper we present a novel system for cognitive stimulation therapy to progressively assess cognitive impairment and emotional well-being of dementia patients in social care settings. The system assesses patients interactions and computes performance scores for different areas of cognitive stimulation. Patient interactions are initially classified into predefined performance categories through clustering of a sampled population. New personalized stimulation plans tailored to match the patient's changing level of impairment are generated automatically through a set of fuzzy rule based systems using quantitative attributes and the overall scores of patients interactions. Therapists can redefine evaluate and adjust the rules governing difficulty and activity levels for different stimulation areas to fine tune generated activity plans. The system can also be combined with an Internet of Things (IoT) enabled patient dialogue system for determining the affective state of participants during therapy sessions that could be used as a pervasive condition monitoring platform. Experiments consisting of therapy sessions of patients interacting with the system were performed in which the activity plans were automatically generated. Initial results showed that the system outputs were in agreement with the therapists own assessment in most of the stimulation areas. Simulation experiments were also conducted to analyse the system performance over multiple sessions. The results suggest that the system is able to adapt therapy plans overtime in response to changing levels of impairment/performance while supporting therapists to tune and evaluate therapy plans more effectively. (C) 2018 Elsevier B.V. All rights reserved.;2018
In this study we investigate if a digital coach for low-literate learners that provides cognitive learning support based on scaffolding can be improved by adding affective learning support based on motivational interviewing and social learning support based on small talk. Several knowledge gaps are identified: motivational interviewing and small talk must be translated to control rules for this coach a formal model of participant emotional states is needed to allow the coach to parse the learner's emotional state and various sensors must be used to let the coach detect and act on this state. We use the situated Cognitive Engineering (sCE) method to update an existing foundation of knowledge with emotional models motivational interviewing and small talk theory technology and a new exercise in the volunteer work domain. We use this foundation to create a design specification for an Embodied Conversational Agent (ECA) coach that provides cognitive affective and social learning support for this exercise. A prototype is created and compared to a prototype that only provides cognitive support in a within-and between-subjects experiment. Results show that both prototypes work as expected: learners interact with the coach and complete all exercises. Almost no significant differences are found between the two prototypes indicating that the affective and social support were not effective as designed. Potential improvements are provided for future work. Results also show significant differences between two subgroups of low-literate participants and between men and women reinforcing the importance of using individualized support measures with this demographic.;2018
In this work we present a morphological segmenter for the Mexican indigenous languageWixarika. Segmentation is fundamental for rich morphological languages a common aspect of the native American languages to improve other tasks like machine translation dialogue systems summarization etc. On top of the agglutinative nature of the language the low amount of resources and the lack of an orthographic standard among dialects add to the challenge. Our proposal is based on a probabilistic finite-state approach that exploits regular agglutinative patterns and requires little linguistic knowledge. We show that our approach outperforms unsupervised and semi-supervised methods in a low-resource context. The dataset used in this work was openly released for future work by the community.;2018
Integrating different perspectives is a sophisticated strategy for developing constructive interactions in collaborative problem solving. However cognitive aspects such as individuals' knowledge and bias often obscure group consensus and produce conflict. This study investigated collaborative problem solving focusing on a group member interacting with another member having a different perspective (a maverick). It was predicted that mavericks might mitigate disadvantages and facilitate perspective taking during problem solving. Thus 344 university students participated in two laboratory-based experiments by engaging in a simple rule-discovery task that raised conflicts among perspectives. They interacted with virtual partners whose conversations were controlled by multiple conversational agents. Results show that when participants interacted with a maverick during the task they were able to take others' perspectives and integrate different perspectives to solve the problem. Moreover when participants interacted in groups with a positive mood groups with a maverick outperformed groups having several perspectives.;2018
Miscommunication phenomena such as repair in dialogue are important indicators of the quality of communication. Automatic detection is therefore a key step toward tools that can characterize communication quality and thus help in applications from call center management to mental health monitoring. However most existing computational linguistic approaches to these phenomena are unsuitable for general use in this way and particularly for analyzing human-human dialogue: Although models of other-repair are common in human-computer dialogue systems they tend to focus on specific phenomena (e.g. repair initiation by systems) missing the range of repair and repair initiation forms used by humans and while self-repair models for speech recognition and understanding are advanced they tend to focus on removal of disfluent material important for full understanding of the discourse contribution and/or rely on domain-specific knowledge. We explain the requirements for more satisfactory models including incrementality of processing and robustness to sparsity. We then describe models for self- and other-repair detection that meet these requirements (for the former an adaptation of an existing repair model for the latter an adaptation of standard techniques) and investigate how they perform on datasets from a range of dialogue genres and domains with promising results. Purver et al. note that most models of repair in dialogue tend to focus on the system initiating repair but are not able to detect repair initiated by humans. They develop a repair detection model based on strict incrementalism and parallelism detecting the match between the turn that is repaired and the turn that is doing the repairing. Their model achieves state-of-the-art performance on most corpora of spoken English.;2018
Nonlife threatening chronic health conditions can significantly reduce the quality of life for the patient and their family. Given pressure on specialist services and lengthy wait times we propose a novel approach that involves awebsite and virtual specialist for patients while they are awaiting their specialist appointment. To capture patient history and provide tailored treatment advice an interactive website was developed. To increase adherence the website was enhanced with an empathic embodied conversational agent to allow discussion of the suggested treatment. A six-month trial with 74 children with urinary incontinence showed an overall improvement in 74% of patients with 38% those who used the program reporting a resolution of their wetting without needing a specialist appointment. Capturing the expertise of medical specialists to provide online tailored treatment advice and use of humanlike face-to-face conversations to educate and build rapport with the patient appeared to increase treatment adherence compared to an earlier text-based version without the empathic agent.;2018
Objective Self-anamnesis is a procedure in which a patient answers questions about the personal medical history without interacting directly with a doctor or medical assistant. If collected digitally the anamnesis data can be shared among the health care team. In this article we introduce a concept for digital anamnesis collection and assess the applicability of a conversational user interface (CUI) for realizing a mobile self-anamnesis application. Materials and Methods We implemented our concept for self-anamnesis for the concrete field of music therapy. We collected requirements with respect to the application from music therapists and by reviewing the literature. A rule-based approach was chosen for realizing the anamnesis conversation between the system and the user. The Artificial Intelligence Markup Language was exploited for encapsulating the questions and responses of the system. For studying the quality of the system and analyzing performance humanity effect and accessibility of the system we performed a usability test with 22 persons. Results The current version of the self-anamnesis application is equipped with 63 questions on the music biography of a patient that are asked subsequently to the user by means of a chatbot conversation. The usability study showed that a CUI is a practical way for collecting anamnesis data. Users felt engaged of answering the questions and liked the human characteristics of the chatbot. They suggested to extend the conversation capabilities of the chatbot so that the system can react appropriately in particular when the user is not feeling well. Conclusions We could demonstrate the applicability of a CUI for collecting anamnesis data. In contrast to digital anamnesis questionnaires the application of a CUI provides several benefits: the user can be encouraged to complete all queries and can ask clarifying questions in case something is unclear.;2018
Objective: Our objective was to review the characteristics current applications and evaluation measures of conversational agents with unconstrained natural language input capabilities used for health-related purposes. Methods: We searched PubMed Embase CINAHL PsycInfo and ACM Digital using a predefined search strategy. Studies were included if they focused on consumers or healthcare professionals involved a conversational agent using any unconstrained natural language input and reported evaluation measures resulting from user interaction with the system. Studies were screened by independent reviewers and Cohen's kappa measured inter-coder agreement. Results: The database search retrieved 1513 citations 17 articles (14 different conversational agents) met the inclusion criteria. Dialogue management strategies were mostly finite-state and frame-based (6 and 7 conversational agents respectively) agent-based strategies were present in one type of system. Two studies were randomized controlled trials (RCTs) 1 was cross-sectional and the remaining were quasi-experimental. Half of the conversational agents supported consumers with health tasks such as self-care. The only RCT evaluating the efficacy of a conversational agent found a significant effect in reducing depression symptoms (effect size d 1/4 0.44 p 1/4 .04). Patient safety was rarely evaluated in the included studies. Conclusions: The use of conversational agents with unconstrained natural language input capabilities for health-related purposes is an emerging field of research where the few published studies were mainly quasiexperimental and rarely evaluated efficacy or safety. Future studies would benefit from more robust experimental designs and standardized reporting.;2018
Objective: The PAL project develops a conversational agent with a physical (robot) and virtual (avatar) embodiment to support diabetes self-management of children ubiquitously. This paper assesses 1) the effect of perceived similarity between robot and avatar on children's' friendship towards the avatar and 2) the effect of this friendship on usability of a self-management application containing the avatar (a) and children's motivation to play with it (b). Methods: During a four-day diabetes camp in the Netherlands 21 children participated in interactions with both agent embodiments. Questionnaires measured perceived similarity friendship motivation to play with the app and its usability. Results: Children felt stronger friendship towards the physical robot than towards the avatar. The more children perceived the robot and its avatar as the same agency the stronger their friendship with the avatar was. The stronger their friendship with the avatar the more they were motivated to play with the app and the higher the app scored on usability. Conclusion: The combination of physical and virtual embodiments seems to provide a unique opportunity for building ubiquitous long-term child-agent friendships. Practice implications: an avatar complementing a physical robot in health care could increase children's motivation and adherence to use self-management support systems. (c) 2018 Elsevier B.V. All rights reserved.;2018
One of many ways in which spoken dialogue systems (SDS) are becoming more and more flexible is in their choice of words (e.g. alignment to the user's vocabulary). We examined how users perceive such adaptive and non-adaptive SDS regarding trustworthiness and usability. In Experiment 1 130 participants read out questions to an SDS that either made or did not make lexical alignment in its replies. They perceived higher cognitive demand when the SDS did not employ alignment. In Experiment 2135 participants listened to a conversation between a human and the same SDS in an online study. They judged the aligned SDS to have more integrity and to be more like-able. Implications for the design of SDS are discussed.;2018
Partially observable Markov decision process (POMDP) model has been demonstrated many times to be suited for developing robust spoken dialogue systems unreliable speech recognition. In this paper we propose a new factored POMDP model to describe a new application on building affective tutoring system (ATS). Different from previous models the user's state space is divided into three components: goals dialogue states and emotions. Moreover the system's action space is factored into two parts: goal response and emotion response in order to respond to the user's goal and emotion respectively. We further describe how to apply the proposed model to build an ATS in detail. Five experiments are designed to reveal the influence of some key parameters on the system performance and the simulation results demonstrate the validity and feasibility of the proposed model. (C) 2018 Institute of Electrical Engineers of Japan. Published by John Wiley & Sons Inc.;2018
People as members of a society and members of the intelligentsia are inevitably involved in discourse and conversational systems which define their diverse positions of power in the discourse. The term discourse is used mostly to label the forms of representation and routines of language that yield certain reactions and customarily located denotations. This article examines the unsuccessful discourse attempts by university management education authorities and students in South Africa during the #FeesMustFall campaign. It analyses the forms of engagement used by the parties involved in the campaign by means of Critical Discourse Analysis. It suggests that contradictory discourses may lead to conflict instability and intolerance amongst the parties involved.;2018
Pronouns are frequently dropped in Korean sentences especially in text messages in the mobile phone environment. Restoring dropped pronouns can be a beneficial preprocessing task for machine translation information extraction spoken dialog systems and many other applications. In this work we address the problem of dropped pronoun recovery by resolving two simultaneous subtasks: detecting zero-pronoun sentences and determining the type of dropped pronouns. The problems are statistically modeled by encoding the sentence and classifying types of dropped pronouns using a recurrent neural network (RNN) architecture. Various RNN-based encoding architectures were investigated and the stacked RNN was shown to be the best model for Korean zero-pronoun recovery. The proposed method does not require any manual features to be implemented nevertheless it shows good performance.;2018
Purpose - Recent technological and digital developments have opened new avenues for customer data utilization in insurance services. One form of this data transformation is automated chatbots that provide convenient access to data leveraged through a discussion-like interface. The purpose of this paper is to uncover how insurance chatbots support customers' value creation. Design/methodology/approach - Three complementary theoretical perspectives - artificial intelligence service logic and reverse use of customer data - are briefly discussed and integrated into a conceptual framework. The suggested framework is further shown through illustrative case examples that characterize different ways of supporting customers' value creation. Findings - Chatbots represent a new type of interaction through which companies can influence customers' value creation by providing them with additional resources. Based on the proposed conceptual framework and the illustrative case examples four metaphors are identified that characterize how insurance chatbots can support customers' value creation. Research limitations/implications - The study is conceptual in nature and the case examples are used for illustrative purposes. No representative data from those users who will eventually determine whether chatbots are of value was used. Practical implications - Using the suggested framework which is aligned with provider service logic insurance companies can consider what kind of a role they wish to play in customers' value-creating processes. Originality/value - Automated chatbots provide convenient access to data leveraged through a discussion-like interface. This study is among the earliest to address their value-creating potential in insurance.;2018
Purpose of review Demand for clinical genetics and genomics services is increasing. As discussed in this study the clinical genetics and genomics workforce is small. How to meet the demand with a limited workforce requires innovation. Recent findings Background data regarding the current state of clinical genetic services including volume of services and make-up of the clinical genetics workforce are presented. The study then identifies opportunities to increase access to clinical genetic service providers using new models of service and discusses examples of solutions which have been implemented in some practice settings. Creative uses of technology to increase providers' efficiency are highlighted. Summary Clinical genetics service providers need to rise to the occasion and lead the transformation of clinical genetic service delivery. Many of the examples of solutions described in the study can be implemented by other providers now. Additionally the described solutions may serve to inspire genetic providers to create their own new solutions which should then be shared with the provider community.;2018
Service providers from public institutions to primary care facilities need to constantly attend to clients' inquiries to provide useful information and directive guidelines. Ensuring high quality service is challenging as it not only demands detailed domain-specific knowledge but also the ability to quickly understand the clients' issues through their diverse and often casual descriptions. This paper aims to provide a framework for the development of an automated information broker agent who performs the task of a helper. The main task of the agent is to interact with the client and direct them to obtain further services that cater their personalized need. To do so the agent should accomplish a sequence of tasks that include natural language inquiry knowledge gathering reasoning and giving feedback in this way it simulates a human helper to engage in interaction with the client. The framework combines a question-answering reasoning mechanism while utilizing domain-specific knowledge base. When the users cannot describe clearly their needs the system tries to narrow down the possibilities by an iterative question-answering process until it eventually identifies the target. In realizing our framework we make a proof-of-concept project Mandy a primary care chatbot system created to assist healthcare staffs by automating the patient intake process. We describe in detail the system functionalities and design of the system and evaluate our proof-of-concept on benchmark case studies.;2018
Technological pedagogical content knowledge (TPACK) proposed by Mishra and Koehler is a theoretical construct of teacher knowledge that describes how teachers teach subject matter content using certain instructional methods with specific technology in particular contexts. This study aims to explore the interface between TPACK and SLA intending to examine (a) how a Taiwanese English teacher enhanced L2 interaction and (b) how her students perceived such teaching. While data regarding the teacher's TPACK-SLA knowledge was collected through lesson plans classroom observations and interviews data associated with students' perceptions was obtained through a questionnaire survey and focus-group interviews. The findings suggest that the teacher enhanced L2 interaction by(a) drawing students' attention to grammatical patterns through annotated animations (b) consolidating vocabulary use through image-based exercises and a bilingual concordancer and (c) evaluating the use of sentence patterns through text-chatting with a chatbot. While the students could improve learner-computer interaction through obtaining enhanced input they could also develop inter-personal communication competency through negotiating meaning. In addition the students appreciated the ways their teacher taught English using Cool English. This study contributes some empirical insights into how EFL teachers can draw upon practices explored in instructed SLA to develop TPACK.;2018
The aim of this paper is to illustrate an overview of the automatic speech recognition (ASR) module in a spoken dialog system and how it has evolved from the conventional GMM-HMM (Gaussian mixture model - hidden Markov model) architecture toward the recent nonlinear DNN-HMM (deep neural network) scheme. GMMs have dominated for a long time the baseline of speech recognition but in the past years with the resurgence of artificial neural networks (ANNs) the former models have been surpassed in most recognition tasks. An outstanding consideration for ANNs-based acoustic model is the fact that their weights can be adjusted in two training steps: i) initialization of the weights (with or without pre-training) and ii) fine-tuning. To exemplify these frameworks a case study is realized by using the Kaldi toolkit employing a mid-vocabulary with a personalized speaker-independent voice corpus on a connected-words phone dialing environment operated for recognition of digit strings and personal name lists in Spanish from Mexico. The obtained results show a reasonable accuracy in the speech recognition performance through the DNN acoustic modeling. A word error rate (WER) of 1.49% for context-dependent DNN-HMM is achieved providing a 30% relative improvement with regard to the best GMM-HMM result in these experiments (2.12% WER).;2018
The application of natural language to improve the interaction of human users with information systems is a growing trend in the recent years. Advances in cognitive computing enable a new way of interaction that accelerates insight from existing information sources. In this paper we propose a modular cognitive agent architecture for question answering featuring social dialogue improved for a specific knowledge domain. The proposed system has been implemented as a personal agent to assist students learning Java programming language. The developed prototype has been evaluated to analyze how users perceive the interaction with the system. We claim that including social dialogue in QA systems increases users satisfaction and makes them easily engage with the system. Finally we present the evaluation results that support our hypotheses. (C) 2018 The Authors. Published by Elsevier Ltd.;2018
The Gemini Planet Imager Exoplanet Survey (GPIES) is a multiyear direct imaging survey of 600 stars to discover and characterize young Jovian exoplanets and their environments. We have developed an automated data architecture to process and index all data related to the survey uniformly. An automated and flexible data processing framework which we term the Data Cruncher combines multiple data reduction pipelines (DRPs) together to process all spectroscopic polarimetric and calibration data taken with GPIES. With no human intervention fully reduced and calibrated data products are available less than an hour after the data are taken to expedite follow up on potential objects of interest. The Data Cruncher can run on a supercomputer to reprocess all GPIES data in a single day as improvements are made to our DRPs. A backend MySQL database indexes all files which are synced to the cloud and a front-end web server allows for easy browsing of all files associated with GPIES. To help observers quicklook displays show reduced data as they are processed in real time and chatbots on Slack post observing information as well as reduced data products. Together the GPIES automated data processing architecture reduces our workload provides real-time data reduction optimizes our observing strategy and maintains a homogeneously reduced dataset to study planet occurrence and instrument performance. (c) 2018 Society of Photo-Optical Instrumentation Engineers (SPIE);2018
The increasing popularity of chatbots as virtual assistants has lead to many organizations releasing If-This-Then-That frameworks to engineer such chatbots. However these frameworks often result in inflexible and difficult-to-maintain chatbots. This paper outlines a high-level conceptual framework for realizing flexible chatbots founded upon agent-oriented abstractions: goals plans and commitments.;2018
The need for experimentation of facial expression recognition in a more ecological manner necessitates the use of multimodal interactive experimental stimuli. At the same time the prerequisite of reproducibility of results and controlled conditions is still mandatory. An embodied conversational agent (ECA) is a pertinent framework that meets all these requirements. The VIB (Virtual Interactive Behavior) Platform is a SAIBA compliant system which supports the real-time generation of multimodal behavior for interacting with socio-emotional virtual agents. We created a new feature for this platform namely VIB-Ex which can be used for presenting real-time facial expressions and recording the user's reaction time and interaction while exporting data for statistical purposes. In this paper we present our proof of concept study in which a 3D male virtual character has been used to convey joyful or sad facial expressions. At the same time the same character pronounced joyful or sad words in congruence or incongruence with its facial expression in order to trigger an emotional Stroop effect. Only 12 adults were sufficient in order to obtain an emotional Stroop effect within our virtual agent. The results of this study confirmed that the VIB-Ex platform can replicate a robust effect of psychological phenomena concerning recognition of facial expressions. VIB-Ex proves itself to be a suitable and a pertinent tool to perform experiments on a human's automatic process of facial expression recognition. Finally we discuss the possible future research topics with VIB-Ex to carry out other type of experiments in the field of social cognition.;2018
This article becomes the first step towards technoscience as an opened and inter-penetrated enabler. For this the authors develop a theoretical and hermeneutical analysis of the techno-scientific system. A brief history of the modern occidental science is presented. Later this article offers the first approach to a trans-subjective or trans-personal theory within the Latin American context. The authors show different reactions to the so-called 'monologated scientific system' in relationship to the hermeneutic of the person. Later the authors show a more dialogistic system in which other epistemic views are considered. These are connected with the philosophy of wisdom the theory of personal care etc. In this sense and finally it is considered that the techno-scientific system could be inter-penetrated for the psychic and social scope. In fact this affirmation is defended to reach a scientific personal progress in a permanent dialogue with other wisdom knowledge.;2018
This article provides an overview and evaluation of the usesactual and potentialof automatic speech recognition (ASR) and spoken dialogue systems (SDS) related technologies that can be applied to second language speaking assessment given particular definitions of the construct. Both technologies have only gradually moved in the direction of supporting language learning and only more recently used for grading purposes. How the speaking construct is defined determines one's evaluation of the extent to which assessments using these technologies are adequate to the task given different test use contexts and what the challenges and future research requirements are. In any event there are many opportunities for their use in assessment and these would be facilitated by increased cross-disciplinary research among the language testing and speech technology communities.;2018
This article reports on the development of capabilities for (on-screen) virtual agents and robots to support isolated older adults in their homes. A real-time architecture was developed to use a virtual agent or a robot interchangeably to interact via dialog and gesture with a human user. Users could interact with either agent on 12 different activities some of which included on-screen games and forms to complete. The article reports on a pre-study that guided the choice of interaction activities. A month-long study with 44 adults between the ages of 55 and 91 assessed differences in the use of the robot and virtual agent.;2018
This article shares insights gathered from the design and implementation of an SMS chatbot-based virtual assistant to hotel guests in London. The author discusses challenges and first outcomes and makes recommendations based on this experience toward best practices for approaching the design of chatbots in the customer service domain.;2018
This letter focuses on a multimodal language understanding method for carry-and-place tasks with domestic service robots. We address the case of ambiguous instructions that is when the target area is not specified. For instance put away the milk and cereal is a natural instruction where there is ambiguity regarding the target area considering environments in daily life. Conventionally this instruction can he disambiguated from a dialogue system but at the cost of time and cumbersome interaction. Instead we propose a multimodal approach in which the instructions are disambiguated using the robot's state and environment context. We develop the Multi-Modal Classifier Generative Adversarial Network (MMC-GAN) to predict the likelihood of different target areas considering the robot's physical limitation and the target clutter. Our approach MMC-GAN significantly improves accuracy compared with baseline methods that use instructions only or simple deep neural networks.;2018
This paper focuses on the ethical challenges presented by direct-to-consumer (DTC) digital psychotherapy services that do not involve oversight by a professional mental health provider. DTC digital psychotherapy services can potentially assist in improving access to mental health care for the many people who would otherwise not have the resources or ability to connect with a therapist. However the lack of adequate regulation in this area exacerbates concerns over how safety privacy accountability and other ethical obligations to protect an individual in therapy are addressed within these services. In the traditional therapeutic relationship there are ethical obligations that serve to protect the interests of the client and provide warnings. In contrast in a DTC therapy app there are no clear lines of accountability or associated ethical obligations to protect the user seeking mental health services. The types of DTC services that present ethical challenges include apps that use a digital platform to connect users to minimally trained nonprofessional counselors as well as services that provide counseling steered by artificial intelligence and conversational agents. There is a need for adequate oversight of DTC nonprofessional psychotherapy services and additional empirical research to inform policy that will provide protection to the consumer.;2018
This paper presents a nonlinear control method for maximum power point tracking (MPPT) of doubly fed induction generator-based wind energy conversation systems. The proposed control structure is wind speed sensorless and independent from turbine characteristics and parameters such as optimal power-speed curve and optimum tip-speed-ratio. The presented MPPT scheme is designed based on adaptive backstepping control method and shown to be robust and stable against parametric uncertainties and wind speed disturbances. The validity effectiveness and robustness of the proposed MPPT control method is demonstrated through simulation studies in the MATLAB (R) software environment. (C) 2018 Karabuk University. Publishing services by Elsevier B.V.;2018
This paper studies response selection for human-computer conversation systems. Existing retrieval based human-computer conversation systems are intended to reply to user utterances based on existing utterance-response pairs. However collecting sufficient utterance-response pairs is intractable in practical situations especially for many specific domains. We introduce DocChat a novel information retrieval approach for human-computer conversation systems that can use unstructured documents rather than semi-structured utterance-response pairs to react to user utterances. The key of DocChat is a learning to rank model with features designed at various levels of granularity which is proposed to quantify the relevance between utterances and responses directly. We conduct comprehensive experiments on both sentence selection and real human-computer conversation scenarios. Empirical studies of sentence selection datasets shows reasonable improvements and the strong adaptability of our model. We compare DocChat with Xiaoice a famous open domain chitchat engine in China. Side-by-side evaluation shows that DocChat is a good complement for human-computer conversation systems using utterance-response pairs as the primary source of responses. Furthermore we release a large scale open-domain dataset for sentence selection which contains 304413 query-sentence pairs. (C) 2017 Elsevier B.V. All rights reserved.;2018
This paper studies the optimization and implementation of human-machine dialog system based on cloud computing technology. Firstly the coarse-perceived hash generation based on the formant frequency is studied and the detail-aware hash generation based on the energy difference in the time domain is studied. Then the combination of coarse-perceived hash and detail-aware hash is elaborated. Secondly the algorithm is tested and emulated. The algorithm matches the coarse-perceived hash sequence with fewer bits and returns the voice number with similar rough features to the index voice after matching successfully and matches the detail-aware hash sequence of the corresponding number voice. Then the exact match of the result is gotten. Finally it is concluded that the algorithm in this paper can effectively recognize the human voice.;2018
This project explores the recent censorship of two Chinese artificial intelligence (AI) chatbots on Tencent's popular WeChat messaging platform. Specifically I am advancing a technographic approach in ways that give agency to bots as not just computing units but as interlocutors and informants. I seek to understand these chatbots through their intended design-by chatting with them. I argue that this methodological inquiry of chatbots can potentially points to fissures and deficiencies within the Chinese censorship machine that allows for spaces of subversion. AI chatbot development China presents a rich site of study because it embodies the extremes of surveillance and censorship. This is all the more important as China have elevated disruptive technologies like AI and big data as critical part of state security and a key component to fulfilling the Chinese Dream of National Rejuvenation. Whether it is the implementation of a national social credit system or the ubiquitous use facial recognition systems much of Western fears about data security and state control have been already realized in China. Yet this also implies China is at the frontlines of potential points of resistance and fissures against the party-state-corporate machine. In doing so I not only seek to raise questions dealing with the limits of our humanity in the light of our AI-driven futures but also present methodological concerns related to human-machine interfacing in conceptualizing new modes of resistance.;2018
This study demonstrates that rumination is reflected in two behavioural signals that both play an important role in face-to-face interactions and provides evidence for the negative impact of rumination on social cognition. Sixty-one students were randomly assigned either to a condition in which rumination was induced or to a control condition. Their task was to play a speech-based word association game with an Embodied Conversational Agent during which their word associations pitch imitation and eye movements were measured. Two questionnaires assessed their ruminative tendencies and mind wandering thoughts respectively. Rumination predicted differences in task-related mind wandering polarity of lexical associations pitch imitation and blinks while mind wandering predicted differences in saccades. This outcome may show that rumination has a negative impact on certain aspects of social interactions.;2018
To address the problem of limited opportunities for practicing second language speaking in interaction especially delicate interactions requiring pragmatic competence we describe computer simulations designed for the oral practice of extended pragmatic routines and report on the affordances of such simulations for learning pragmatically appropriate communication. Twelve highly proficient learners of English completed six simulated conversations focused on making requests in academic contexts. Evidence of learning was examined microgenetically by comparing data across the simulated conversations and triangulated by written reflections surveys and interviews. Results showed that participants gained content and linguistic forms from expert speaker models and their interactions in scenario-based simulations indicated greater pragmatic awareness and changes in oral production over time. The majority of participants viewed the program positively commenting on features such as its authenticity and predictive accuracy.;2018
To advance the state of the art in conversational AI Amazon launched the Alexa Prize a $2.5 million competition that challenges university teams to build conversational agents or socialbots that can converse coherently and engagingly with humans on popular topics for 20 minutes. The Alexa Prize offers the academic community a unique opportunity to perform research at scale with real conversational data obtained by interacting with millions of Alexa users along with user-provided ratings and feedback over several months. This opportunity enables teams to effectively iterate improve and evaluate their socialbots throughout the competition. Eighteen teams were selected for the inaugural competition last year. To build their socialbots the students combined state-of-the-art techniques with their own novel strategies in the areas of natural language understanding and conversational AI. This article reports on the research conducted over the 2017-2018 year. While the 20-minute grand challenge was not achieved in the first year the competition produced several conversational agents that advanced the state of the art that are interesting for everyday users to interact with and that help form a baseline for the second year of the competition.;2018
Ubiquitous mobile computing offers innovative approaches in the delivery of information that can facilitate free roaming of the city informing and guiding the tourist as the city unfolds before them. However making frequent visual reference to mobile devices can be distracting the user having to interact via a small screen thus disrupting the explorative experience. This research reports on an EU funded project SpaceBook that explored the utility of a hands-free eyes-free virtual tour guide that could answer questions through a spoken dialogue user interface and notify the user of interesting features in view while guiding the tourist to various destinations. Visibility modelling was carried out in real-time based on a LiDAR sourced digital surface model fused with a variety of map and crowd sourced datasets (e.g. Ordnance Survey OpenStreetMap Flickr Foursquare) to establish the most interesting landmarks visible from the user's Iodation at any giVen moment. A number of variations of the SpaceBook system were trialled in Edinburgh (Scotland). The research highlighted the pleasure derived from this novel form of interaction and revealed the complexity of prioritising route guidance instruction alongside identification description and embellishment of landmark information there being a delicate balance between the level of information 'pushed' to the user and the user's requests for further inforrnation. Among a number of challenges were issues regarding the fidelity of spatial data and positioning information required for pedestrian based systems - the pedestrian having much greater freedom of movement than vehicles.;2018
Viewing dialogue management as a reinforcement learning task enables a system to learn to act optimally by maximising a reward function. This reward function is designed to induce the system behaviour required for the target application and for goal oriented applications this usually means fulfilling the user's goal as efficiently as possible. However in real-world spoken dialogue system applications the reward is hard to measure because the user's goal is frequently known only to the user. Of course the system can ask the user if the goal has been satisfied but this can be intrusive. Furthermore in practice the accuracy of the user's response has been found to be highly variable. This paper presents two approaches to tackling this problem. Firstly a recurrent neural network is utilised as a task success predictor which is pre-trained from off-line data to estimate task success during subsequent on-line dialogue policy learning. Secondly an on-line learning framework is described whereby a dialogue policy is jointly trained alongside a reward function modelled as a Gaussian process with active learning. This Gaussian process operates on a fixed dimension embedding which encodes each varying length dialogue. This dialogue embedding is generated in both a supervised and unsupervised fashion using different variants of a recurrent neural network. The experimental results demonstrate the effectiveness of both off-line and on-line methods. These methods enable practical on-line training of dialogue policies in real-world applications. (C) 2018 Published by Elsevier Ltd.;2018
We consider incorporating topic information into message-response matching to boost responses with rich content in retrieval-based chatbots. To this end we propose a topic aware attentive recurrent neural network in which representations of the message and the response are enhanced by the topic information. The model first leverages the message and the response represented by recurrent neural networks (RNNs) to weight topic words given by a pre-trained LDA model and forms topic vectors as linear combinations of the topic words. It then refines the representations of the message and the response with the topic vectors through an attention mechanism. The attention mechanism weights the hidden sequences of the message and the response not only by themselves but also by their topic vectors. Thus both the parts that are important to matching and the parts that are semantically related to the topics are highlighted in the representations.Empirical studies on public data and human annotated data show that our model can significantly outperform state-of-the-art methods and rank more responses with rich content in high positions. (C) 2018 Elsevier B.V. All rights reserved.;2018
We introduce an extension to Multiple Classification Ripple Down Rules (MCRDR) called Contextual MCRDR (C-MCRDR). We apply C-MCRDR knowledge-base systems (KBS) to the Textual Question Answering (TQA) and Natural Language Interface to Databases (NLIDB) paradigms in restricted domains as a type of spoken dialog system (SDS) or conversational agent (CA). C-MCRDR implicitly maintains topical conversational context and intra-dialog context is retained allowing explicit referencing in KB rule conditions and classifications. To facilitate NLIDB post-inference C-MCRDR classifications can include generic query referencing - query specificity is achieved by the binding of pre-identified context. In contrast to other scripted or syntactically complex systems the KB of the live system can easily be maintained courtesy of the RDR knowledge engineering approach. For evaluation we applied this system to a pedagogical domain that uses a production database for the generation of offline course-related documents. Our system complemented the domain by providing a spoken or textual question-answering alternative for undergraduates based on the same production database. The developed system incorporates a speech-enabled chatbot interface via Automatic Speech Recognition (ASR) and experimental results from a live integrated feedback rating system showed significant user acceptance indicating the approach is promising feasible and further work is warranted. Evaluation of the prototype's viability found the system responded appropriately for 80.3% of participant requests in the tested domain and it responded inappropriately for 19.7% of requests due to incorrect dialog classifications (4.4%) or out of scope requests (15.3%). Although the semantic range of the evaluated domain was relatively shallow we conjecture that the developed system is readily adoptable as a CA NLIDB tool in other more semantically-rich domains and it shows promise in single or multi-domain environments. (C) 2018 The Authors. Published by Elsevier Ltd.;2018
We investigate algorithms and tools for the semi-automatic authoring of grammars for spoken dialogue systems (SDS) proposing a framework that spans from corpora creation to grammar induction algorithms. A realistic human-in-the-loop approach is followed balancing automation and human intervention to optimize cost to performance ratio for grammar development. Web harvesting is the main approach investigated for eliciting spoken dialogue textual data while crowdsourcing is also proposed as an alternative method. Several techniques are presented for constructing web queries and filtering the acquired corpora. We also investigate how the harvested corpora can be used for the automatic and semi-automatic (human-in-the-loop) induction of grammar rules. SDS grammar rules and induction algorithms are grouped into two types namely low- and high-level. Two families of algorithms are investigated for rule induction: one based on semantic similarity and distributional semantic models and the other using more traditional statistical modeling approaches (e.g. slot-filling algorithms using Conditional Random Fields). Evaluation results are presented for two domains and languages. High-level induction precision scores up to 60% are obtained. Results advocate the portability of the proposed features and algorithms across languages and domains. (C) 2017 Elsevier Ltd. All rights reserved.;2018
We present an engagement-driven Topic Manager that enables a conversational agent to personalise the topics of interaction in human-agent information-giving chat. The Topic Selection component of this computational model decides what the agent should talk about and when. For this it takes into account the agent's dynamically updated perception of the user's engagement as well as the agent's own mental state. The Topic Transition component of the Topic Manager computes how the agent should introduce the topics in the ongoing interaction without loosing the coherence of the interaction. We have implemented the Topic Manager in a virtual agent endowing it with the ability to adapt the topics of the interaction on the fly to promote the user's engagement. By means of an evaluation study we have found that third party observers perceive the actions of the Topic Manager in the agent's behaviour.;2018
We propose a computational model that endows conversational agents with the capability to coordinate their speaking turns (turn-taking management) in the context of mixed-initiative two-party dialogs. In human conversations participants are continuously adjusting their verbal and non-verbal productions for ensuring the effective coordination of speaking turns. In our model the decision making is a continuous process based on the intrinsic current goal of the agent with respect to turn-taking namely its motivation to keep-or to leave-its current role (speaker or listener) and on its perception of the intentions of its partner. Concurrently the agent is also producing signals indicating its willingness to maintain or leave its current role. Our model is based on two models from cognitive psychology: the drift-diffusion model and the theory of behavioral dynamics. After presenting simulations showing how our model makes the coordination emerge from the interactions we propose a SAIBA-Compliant architecture named BeAware created to support the implementation of our model. Finally using our model we investigate how an agent's turn-taking strategy may impact the user's experience and the effectiveness of the coordination.;2018
When we ask a chatbot for advice about a personal problem should it simply provide informational support and refrain from offering emotional support? Or should it show sympathy and empathize with our situation? Although expression of caring and understanding is valued in supportive human communications do we want the same from a chatbot or do we simply reject it due to its artificiality and uncanniness? To answer this question we conducted two experiments with a chatbot providing online medical information advice about a sensitive personal issue. In Study 1 participants (N=158) simply read a dialogue between a chatbot and a human user. In Study 2 participants (N=88) interacted with a real chatbot. We tested the effect of three types of empathic expressionsympathy cognitive empathy and affective empathyon individuals' perceptions of the service and the chatbot. Data reveal that expression of sympathy and empathy is favored over unemotional provision of advice in support of the Computers are Social Actors (CASA) paradigm. This is particularly true for users who are initially skeptical about machines possessing social cognitive capabilities. Theoretical methodological and practical implications are discussed.;2018
With the recent advances of the sequence-to-sequence framework generation approaches for the short text conversation (STC) become attractive. The traditional sequence-to-sequence approaches for the STC often suffer from poor diversity and general reply without substantiality. It is also hard to control the topic or semantics of the selected reply from multiple generated candidates. In this paper a novel external-memory-driven sequence-to-sequence learning approach is proposed to address these problems. A tensor of the external memory is constructed to represent interpretable topics or semantics. During generation a controllable memory trigger is extracted given the input sequence and a reply is then generated using the memory trigger as well as the sequence-to-sequence model. Experiments show that the proposed approach can generate much richer diversity than the traditional sequence-to-sequence training with attention. Meanwhile it achieves better quality score in human evaluation. It is also observed that by manually manipulating the memory trigger it is possible to interpretably guide the topics or semantics of the reply.;2018
With the spread of smart devices people may obtain a variety of information on their surrounding environment thanks to sensing technologies. To design more context-aware systems psychological user context (e.g. emotional status) is a substantial factor for providing useful information in an appropriate timing. As a typical use case that has a high demand for context awareness but is not tackled widely yet we focus on the tourism domain. In this study we aim to estimate the emotional status and satisfaction level of tourists during sightseeing by using unconscious and natural tourist actions. As tourist actions behavioral cues (eye and head/body movement) and audiovisual data (facial/vocal expressions) were collected during sightseeing using an eye-gaze tracker physical-activity sensors and a smartphone. Then we derived high-level features e.g. head tilt and footsteps from behavioral cues. We also used existing databases of emotionally rich interactions to train emotion-recognition models and apply them in a cross-corpus fashion to generate emotional-state prediction for the audiovisual data. Finally the features from several modalities are fused to estimate the emotion of tourists during sightseeing. To evaluate our system we conducted experiments with 22 tourists in two different touristic areas located in Germany and Japan. As a result we confirmed the feasibility of estimating both the emotional status and satisfaction level of tourists. In addition we found that effective features used for emotion and satisfaction estimation are different among tourists with different cultural backgrounds.;2018
A barrier to incorporating genomics more broadly is limited access to providers with genomics expertise. Chatbots are a technology-based simulated conversation used in scaling communications. Geisinger and Clear Genetics Inc. have developed chatbots to facilitate communication with participants receiving clinically actionable genetic variants from the MyCode (R) Community Health Initiative (MyCode (R)). The consent chatbot walks patients through the consent allowing them to opt to receive more or less detail on key topics (goals benefits risks etc.). The follow-up chatbot reminds participants of suggested actions following result receipt and the cascade chatbot can be sent to at-risk relatives by participants to share their genetic test results and facilitate cascade testing. To explore the acceptability usability and understanding of the study consent post-result follow-up and cascade testing chatbots we conducted six focus groups with MyCode (R) participants. Sixty-two individuals participated in a focus group (n = 33 consent chatbot n = 29 follow-up and cascade chatbot). Participants were mostly female (n = 42 68%) Caucasian (n = 58 94%) college-educated (n = 3353%) retirees (n = 38 61%) and of age 56 years or older (n = 52 84%). Few participants reported that they knew what a chatbot was (n = 10 16%) and a small number reported that they had used a chatbot (n = 5 8%). Qualitative analysis of transcripts and notes from focus groups revealed four main themes: (a) overall impressions (b) suggested improvements (c) concerns and limitations and (d) implementation. Participants supported using chatbots to consent for genomics research and to interact with healthcare providers for care coordination following receipt of genomic results. Most expressed willingness to use a chatbot to share genetic information with relatives. The consent chatbot presents an engaging alternative to deliver content challenging to comprehend in traditional paper or in-person consent. The cascade and follow-up chatbots may be acceptable user-friendly scalable approaches to manage ancillary genetic counseling tasks.;2019
A dialog act represents the communicative function of an utterance in a conversation and thus provides informative cues for understanding managing and generating dialog. While most spoken dialog systems process user input and system output at the turn level a single turn can consist of multiple dialog acts in human conversations. Therefore segmenting turn-level tokens into a meaningful dialog act unit is just as important as recognizing the dialog act. Towards joint segmentation and recognition of dialog acts we propose an encoder-decoder model featuring joint coding and incorporate contextual information by means of an attentional mechanism. The proposed encoder-decoder outperforms other models in segmentation and the application of attentions significantly reduces recognition error rates. By combining the encoder-decoder model with contextual attention we achieve state-of-the-art performance in the joint evaluation of dialog act segmentation and recognition. (C) 2019 Elsevier Ltd. All rights reserved.;2019
A dialogue system will often ask followup clarification questions when interacting with a user if the agent is unsure how to respond. In this new study we explore deep reinforcement learning (RL) for asking followup questions when a user records a meal description and the system needs to narrow down the options for which foods the person has eaten. We build off of prior work in which we use novel convolutional neural network models to bypass the standard feature engineering used in dialogue systems to handle the text mismatch between natural language user queries and structured database entries demonstrating that our model learns semantically meaningful embedding representations of natural language. In this new nutrition domain the followup clarification questions consist of possible attributes for each food that was consumed for example if the user drinks a cup of milk the system should ask about the percent milkfat. We investigate an RL agent to dynamically follow up with the user which we compare to rule-based and entropy-based methods. On a held-out test set assuming the followup questions are answered correctly deep RL significantly boosts top five food recall from 54.9% without followup to 89.0%. We also demonstrate that a hybrid RL model achieves the hest perceived naturalness ratings in a human evaluation.;2019
Acquiring knowledge for conversation modeling is an important task in the process of building a Conversational Agent (Chatbot). However it is a quite difficult process that requires too much time and efforts. To overcome these difficulties in this paper we demonstrate a novel methodology for the automatic conversational knowledge extraction from an existing Chatbot. Extracted knowledge will be used as training dataset for building a Neural Network Conversational Agent. The experiments in the paper show that our proposed approach can be used for the automatic knowledge extraction from any type of Chatbot on the Internet. The experiment that is presented in this paper has two phases. In the first phase we present a methodology for the conversational knowledge extraction. In the second phase of the experiment we introduce a methodology for building a new Neural Conversational Agent using a deep learning Neural Network framework. The key novelty of our proposed approach is the automated machine-machine conversational knowledge sharing and reuse. This is an important step towards building the new conversational agents skipping the difficult and time-consuming procedure of knowledge acquisition. (C) 2019 Elsevier Ltd. All rights reserved.;2019
Activity recognition a key component in pervasive healthcare monitoring relies on classification algorithms that require labeled data of individuals performing the activity of interest to train accurate models. Labeling data can be performed in a lab setting where an individual enacts the activity under controlled conditions. The ubiquity of mobile and wearable sensors allows the collection of large datasets from individuals performing activities in naturalistic conditions. Gathering accurate data labels for activity recognition is typically an expensive and time-consuming process. In this paper we present two novel approaches for semi-automated online data labeling performed by the individual executing the activity of interest. The approaches have been designed to address two of the limitations of self-annotation: (i) The burden on the user performing and annotating the activity and (ii) the lack of accuracy due to the user labeling the data minutes or hours after the completion of an activity. The first approach is based on the recognition of subtle finger gestures performed in response to a data-labeling query. The second approach focuses on labeling activities that have an auditory manifestation and uses a classifier to have an initial estimation of the activity and a conversational agent to ask the participant for clarification or for additional data. Both approaches are described evaluated in controlled experiments to assess their feasibility and their advantages and limitations are discussed. Results show that while both studies have limitations they achieve 80% to 90% precision.;2019
Advanced attackers use online social networks in order to extract useful information about targeted organizations including the names of the organization's members their connections affiliations positions etc. Using artificial profiles (socialbots) attackers connect to real members of the organization thus establishing a foothold inside the organization and greatly increasing the amount of sensitive information they can collect. The connection methods used by attackers are versatile ranging from random friend requests to carefully crafted manually operated social engineering attempts. In this paper we provide an analysis of the cost-effectiveness of strategies used to monitor organizational social networks and detect the socialbots that penetrate a target organization. These strategies were evaluated against heterogeneous attackers with different levels of knowledge about the monitoring strategies using simulation on actual social network data and data from a real scenario of socialbot intrusion. The results demonstrate the efficacy of the monitoring strategies in detecting less sophisticated attackers and slowing down attackers that deliberately avoid the monitored profiles.;2019
Advances in technology are changing the ways cognitive-behavioral therapy (CBT) can be delivered. Through mobile technologies effective interventions exist that allow people to receive CBT without ever visiting a practitioner's office. Additionally mobile technologies are increasingly entering practitioners' offices combining technological and human elements to create hybrid forms of care. Although clinical research has demonstrated exciting possibilities for mobile technologies to deliver and support CBT for the most part clinical practice has been unchanged. We provide an overview of mobile CBT tools used either to deliver or to support CBT highlighting what works and noting current limitations of our understanding. We also discuss new avenues in mobile CBT that leverage peers artificial intelligence and chatbots and mobile sensing to create scalable personalized and context-aware interventions. The future of mobile CBT should not be confined to digitizing current practices but should leverage technological affordances to improve CBT as it exists today.;2019
Although current social machine technology cannot fully exhibit the hallmarks of human morality or agency popular culture representations and emerging technology make it increasingly important to examine human interlocutors' perception of social machines (e.g. digital assistants chatbots robots) as moral agents. To facilitate such scholarship the notion of perceived moral agency (PMA) is proposed and defined and a metric developed and validated through two studies: (1) a large-scale online survey featuring potential scale items and concurrent validation metrics for both machine and human targets and (2) a scale validation study with robots presented as variably agentic and moral. The PMA metric is shown to be reliable valid and exhibiting predictive utility.;2019
Although studies have explored the gender categorization effect in both face-to-face and mediated communication environments in relation to the use of gender-linked language whether the effect still holds in the context of human-machine communication (HMC) remains unknown. To examine this question in this study we asked 245 participants to assign gender categories to targets after viewing transcripts of the targets conversations with a chatbot and a human interlocutor. The results showed that the participants had a better-than-chance probability (68.98%) of correctly guessing the gender of the target based on the target-human conversation transcripts. However the predictive power of the language cues decreased sharply to a less-than-chance level (42.86%) based on target-chatbot conversation transcripts. We also examined the roles that social media use and demographics played in the gender categorization processes in both computer-mediated communication and HMC contexts. Although far from conclusive our results suggested that there were significant differences between the styles of conversation in the target-chatbot and target-human interlocutor transcripts. These findings imply that people use different approaches when communicating with human and non-human interlocutors.;2019
Although various methods have been developed to evaluate conversational interfaces there has been a lack of methods specifically focusing on evaluating user experience. This paper reviews the understandings of user experience (UX) in conversational interfaces literature and examines the six questionnaires commonly used for evaluating conversational systems in order to assess the potential suitability of these questionnaires to measure different UX dimensions in that context. The method to examine the questionnaires involved developing an assessment framework for main UX dimensions with relevant attributes and coding the items in the questionnaires according to the framework. The results show that (i) the understandings of UX notably differed in literature (ii) four questionnaires included assessment items in varying extents to measure hedonic aesthetic and pragmatic dimensions of UX (iii) while the dimension of affect was covered by two questionnaires playfulness motivation and frustration dimensions were covered by one questionnaire only. The largest coverage of UX dimensions has been provided by the Subjective Assessment of Speech System Interfaces (SASSI). We recommend using multiple questionnaires to obtain a more complete measurement of user experience or improve the assessment of a particular UX dimension. RESEARCH HIGHLIGHTS Varying understandings of UX in conversational interfaces literature. A UX assessment framework with UX dimensions and their relevant attributes. Descriptions of the six main questionnaires for evaluating conversational interfaces. A comparison of the six questionnaires based on their coverage of UX dimensions.;2019
Amazon Alexa is a voice-controlled application that is rapidly gaining popularity. We examined user interactions with this technology and focused on the types of tasks requested of Alexa the variables that affect user behaviors with Alexa and Alexa's alternatives. The data about Alexa usage were collected from 19 participants via the online questionnaire and diary methods over the course of several days. The results indicate that across all age groups Alexa was primarily used for checking weather forecasts playing music and controlling other devices. Several participants reported using Apple Siri and Google Now applications in addition to Alexa for similar purposes except for controlling other devices. Alexa uses over the weekends were more frequent than on weekdays but its overall usage tended to decrease over time. The users reported being satisfied with Alexa even when it did not produce sought information suggesting that the interaction experience is more important to the users than the interaction output. More work is required to understand whether users treat Alexa and similar voice-controlled applications as primarily a traditional information retrieval system a casual leisure system a control interface for smart home devices or simply a new toy.;2019
An embodied conversational agent can serve as a relational agent and provide information motivation and behavioral skills. To evaluate the feasibility acceptability and preliminary efficacy of My Personal Health Guide a theory-based mobile-delivered embodied conversational agent intervention to improve adherence to antiretroviral therapy in young African American men who have sex with men we conducted this prospective pilot study using a 3-month pre-post design. Outcome measures included adherence acceptability feasibility pre versus post health literacy and pre versus post self-efficacy. There were 43 participants. Pill count adherence > 80% improved from 62% at baseline to 88% at follow-up (p = .05). The acceptability of the app was high. Feasibility issues identified included loss of usage data from unplanned participant app deletion. Health literacy improved whereas self-efficacy was high at baseline and follow-up. This pilot study of My Personal Health Guide demonstrated acceptability and preliminary efficacy in improving adherence in this important population.;2019
Artificial Intelligence (AI) is increasingly prominent in public academic and clinical provinces. A widening research base is expanding AI's reach including to that of the counseling profession. This article defines AI and its relevant subfields provides a brief history of psychological AI and suggests four levels of implementation to counseling corresponding to time orientation and influence. Implications of AI are applicable to counseling ethics existentialism clinical practice and public policy.;2019
Artificial intelligence (Al) has transformed the world and the relationships among humans as the learning capabilities of machines have allowed for a new means of communication between humans and machines. In the field of health there is much interest in new technologies that help to improve and automate services in hospitals. This article aims to explore the literature related to conversational agents applied to health care searching for definitions patterns methods architectures and data types. Furthermore this work identifies an agent application taxonomy current challenges and research gaps. In this work we use a systematic literature review approach. We guide and refine this study and the research questions by applying Population Intervention Comparison Outcome and Context (PICOC) criteria. The present study investigated approximately 4145 articles involving conversational agents in health published over the last ten years. In this context we finally selected 40 articles based on their approaches and objectives as related to our main subject. As a result we developed a taxonomy identified the main challenges in the field and defined the main types of dialog and contexts related to conversational agents in health. These results contributed to discussions regarding conversational health agents and highlighted some research gaps for future study. (C) 2019 Elsevier Ltd. All rights reserved.;2019
As an important component in dialogue system Dialogue Act Recognition (DAR) has attracted much attention of researchers. Most of the existing approaches only focus on the information of utterances but relatively few investigate the roles of DA labels in different layers of a conversation and also some semantic inference in irregular conversations such as questions and answers skipping back and forth has not been probed properly so that some dialogue acts are not always recognized correctly. To overcome the aforementioned deficiencies we propose a hierarchical project method in which DA labels are embedded in three levels (word utterance and DA) to calculate the importance of each word provide contextual and pragmatic information and guide the model to generate the category of utterance respectively. Both multiple attention mechanism and semantic update mechanism are applied to infer the more accurate representation of utterance for DA recognition in a general case. Experimental results show that our model can achieve comparable performance to the state-of-the-art models with less extra information.;2019
As social media replace traditional communication channels we are often exposed to too much information to process. The presence of too many participants for example can turn online public spaces into noisy overcrowded fora where no meaningful conversation can be held. Here we analyse a large dataset of public chat logs from Twitch a popular video-streaming platform in order to examine how information overload affects online group communication. We measure structural and textual features of conversations such as user output interaction and information content per message across a wide range of information loads. Our analysis reveals the existence of a transition from a conversational state to a cacophony-a state with lower per capita participation more repetition and less information per message. This study provides a quantitative basis for further studies of the social effects of information overload and may guide the design of more resilient online conversation systems.;2019
As the uses of conversational agents increase the affective and social abilities of agents become important with their functional abilities. Agents that lack affective abilities could frustrate users during interaction. This study applied personality to implement the natural feedback of conversational agents referring to the concept of affective computing. Two types of feedback were used to express conversational agents' personality: (1) visual feedback and (2) verbal cues. For visual feedback participants (N = 45) watched visual feedback with different colors and motions. For verbal cues participants (N = 60) heard different conditions of agents' voices with different scripts. The results indicated that the motions of visual feedback were more significant than colors. Fast motions could express distinct and positive personalities. Different verbal cues were perceived as different personalities. The perceptions of personalities differed according to the vocal gender. This study provided design implications for personality expressions applicable to diverse interfaces.;2019
Automatic generation of texts with different sentiment labels has wide use in artificial intelligence applications such as conversational agents. It is an important problem to be addressed for achieving emotional intelligence. In this paper we propose two novel models SentiGAN and C-SentiGAN which have multiple generators and one multiclass discriminator to address this problem. In our models multiple generators are trained simultaneously aiming at generating texts of different sentiment labels without supervision. We propose a penalty-based objective in generators to force each of them to generate diversified examples of a specific sentiment label. Moreover the use of multiple generators and one multi-class discriminator can make each generator focus on generating its own texts of a specific sentiment label accurately. Experimental results on a variety of datasets demonstrate that our SentiGAN model consistently outperforms several state-of-the-art text generation models in the sentiment accuracy and quality of generated texts. In addition experiments on conditional text generation tasks show that our C-SentiGAN model has good prospects for specific text generation tasks. (C) 2019 Elsevier B.V. All rights reserved.;2019
Automation of journalistic tasks is growing with the development of increasingly sophisticated software for newsgathering production and distribution. Bots are one form of algorithmic technology that has found a place in the modern newsroom with chatbots leading the way as news organisations seek to attract new audiences using conversational forms of journalism. Recent advances in artificial intelligence (Al) and machine teaming (ML) have fuelled increasing experimentation with machine autonomy and there has been much hyperbole in the press about the extent and impact of this on journalism. Looking at on-the-ground trials in audience-facing bots at the UK's largest public broadcaster we find a significantly more restricted picture. News bots at The BBC to-date have been basic do not use ML and have rarely been integrated into news production. The organisation is laying groundwork for development of more interactive news formats with an increasingly conversational tone and individual mode of address as part of a strategy for increased personalisation which is likely to involve growing levels of ML In the process bots are reconfiguring working practices and infrastructure posing new editorial and technical challenges and redefining relationships with audiences. We discuss the implications of this for public service media.;2019
Autonomous speech-enabled applications such as speech-to-speech machine translation conversational agents and spoken dialogue systems need to be able to distinguish system-directed user input from off-talk to function appropriately. Off-talk occurs when users speak to themselves or to others often causing the system to mistakenly respond to speech that was not directed to it. Automatic detection of off-talk could help prevent such errors and make the user's interaction with the system more natural. It has been observed that speech in human-human dialogue and in soliloquy is prosodically different from speech directed at machines and that the right hemisphere of the human brain is the locus of control of speech prosody. In this study we explore human brain activity prior to speech articulation alone and in combination with prosodic features to create models for off-talk prediction. The proposed EEG based models are a step towards improving response time in detecting system-directed speech in comparison with audio-based methods of detection opening new possibilities for the integration of brain-computer interface techniques into interactive speech systems.;2019
Background Artificial intelligence (AI) is increasingly being used in healthcare. Here AI-based chatbot systems can act as automated conversational agents capable of promoting health providing education and potentially prompting behaviour change. Exploring the motivation to use health chatbots is required to predict uptake however few studies to date have explored their acceptability. This research aimed to explore participants' willingness to engage with AI-led health chatbots. Methods The study incorporated semi-structured interviews (N-29) which informed the development of an online survey (N-216) advertised via social media. Interviews were recorded transcribed verbatim and analysed thematically. A survey of 24 items explored demographic and attitudinal variables including acceptability and perceived utility. The quantitative data were analysed using binary regressions with a single categorical predictor. Results Three broad themes: 'Understanding of chatbots' 'AI hesitancy' and 'Motivations for health chatbots' were identified outlining concerns about accuracy cyber-security and the inability of AI-led services to empathise. The survey showed moderate acceptability (67%) correlated negatively with perceived poorer IT skills OR = 0.32 [CI95%:0.13-0.78] and dislike for talking to computers OR = 0.77 [CI95%:0.60-0.99] as well as positively correlated with perceived utility OR = 5.10 [CI95%:3.08-8.43] positive attitude OR = 2.71 [CI95%:1.77-4.16] and perceived trustworthiness OR = 1.92 [CI95%:1.13-3.25]. Conclusion Most internet users would be receptive to using health chatbots although hesitancy regarding this technology is likely to compromise engagement. Intervention designers focusing on AI-led health chatbots need to employ user-centred and theory-based approaches addressing patients' concerns and optimising user experience in order to achieve the best uptake and utilisation. Patients' perspectives motivation and capabilities need to be taken into account when developing and assessing the effectiveness of health chatbots.;2019
Background Health dialog systems have seen increased adoption by patients hospitals and universities due to the confluence of advancements in machine learning and the ubiquity of high-performance hardware that supports real-time speech recognition high-fidelity text-to-speech and semantic understanding of natural language. Objectives This review seeks to enumerate opportunities to apply dialog systems toward the improvement of health outcomes while identifying both gaps in the current literature that may impede their implementation and recommendations that may improve their success in medical practice. Methods A search over PubMed and the ACM Digital Library was conducted on September 12 2017 to collect all articles related to dialog systems within the domain of health care. These results were screened for eligibility with the main criteria being a peer-reviewed study of a system that includes both a natural language interface and either end-user testing or practical implementation. Results Forty-six studies met the inclusion criteria including 24 quasi-experimental studies 16 randomized control trials 2 case-control studies 2 prospective cohort studies 1 system description and 1 human-computer conversation analysis. These studies evaluated dialog systems in five application domains: medical education ( n = 20) clinical processes ( n = 14) mental health ( n = 5) personal health agents ( n = 5) and patient education ( n = 2). Conclusion We found that dialog systems have been widely applied to health care however most studies are not reproducible making direct comparison between systems and independent confirmation of findings difficult. Widespread adoption will also require the adoption of standard evaluation and reporting methods for health dialog systems to demonstrate clinical significance.;2019
Background In the United States and parts of the world the human papillomavirus vaccine uptake is below the prescribed coverage rate for the population. Some research have noted that dialogue that communicates the risks and benefits as well as patient concerns can improve the uptake levels. In this paper we introduce an application ontology for health information dialogue called Patient Health Information Dialogue Ontology for patient-level human papillomavirus vaccine counseling and potentially for any health-related counseling. Results The ontology's class level hierarchy is segmented into 4 basic levels - Discussion Goal Utterance and Speech Task. The ontology also defines core low-level utterance interaction for communicating human papillomavirus health information. We discuss the design of the ontology and the execution of the utterance interaction. Conclusion With an ontology that represents patient-centric dialogue to communicate health information we have an application-driven model that formalizes the structure for the communication of health information and a reusable scaffold that can be integrated for software agents. Our next step will to be develop the software engine that will utilize the ontology and automate the dialogue interaction of a software agent.;2019
Background: Almost two thirds of patients diagnosed with cancer are age 65 years or older. In order to follow up on older patients with cancer receiving chemotherapy at home we implemented remote phone monitoring conducted by skilled oncology nurses. However given the rising number of patients assessed and the limited time that hospital professionals can spend on their patients after discharge we needed to modernize this program. In this paper we present the preliminary results and the ongoing evaluation. Method: We implemented a semi-automated messaging application to upgrade the current follow-up procedures. The primary aim is to collect patient's key data over time and to free up nurses' time so that during phone calls they can focus on education and support. The Chatbot feasibility was assessed in a sub-sample of unselected patients before its wider dissemination and pragmatic evaluation. Main results: During the first deployment period 9 unselected patients benefited from the Chatbot (mean 83 y.o.) with a total of 52 completed remote evaluations. Each participant answered 6 questionnaires over 7 weeks with an 86% compliance rate. The average completion time for the questionnaires was 3.5 min and the answer rate was 100%. The 'free text' field was used in 58% of the questionnaires. The Chatbot solution is currently proposed to all eligible patients thanks to the regional cancer network support. We are measuring acceptability health outcomes and health network impact. Discussion and conclusion: The results of this first phase are encouraging. The integration of the solution into the health care organization was feasible and acceptable. Moreover the answers revealed serious health (e.g. fever) or adherence (e.g. blood test) issues that require timely interventions. The major strength of this solution is to rely on end-users' current knowledge of technologies (text-messaging) which allows a seamless integration into a complex clinical network.;2019
Background: Chatbots are systems that are able to converse and interact with human users using spoken written and visual languages. Chatbots have the potential to be useful tools for individuals with mental disorders especially those who are reluctant to seek mental health advice due to stigmatization. While numerous studies have been conducted about using chatbots for mental health there is a need to systematically bring this evidence together in order to inform mental health providers and potential users about the main features of chatbots and their potential uses and to inform future research about the main gaps of the previous literature. Objective: We aimed to provide an overview of the features of chatbots used by individuals for their mental health as reported in the empirical literature. Methods: Seven bibliographic databases (Medline Embase PsycINFO Cochrane Central Register of Controlled Trials IEEE Xplore ACM Digital Library and Google Scholar) were used in our search. In addition backward and forward reference list checking of the included studies and relevant reviews was conducted. Study selection and data extraction were carried out by two reviewers independently. Extracted data were synthesised using a narrative approach. Chatbots were classified according to their purposes platforms response generation dialogue initiative input and output modalities embodiment and targeted disorders. Results: Of 1039 citations retrieved 53 unique studies were included in this review. The included studies assessed 41 different chatbots. Common uses of chatbots were: therapy (n=17) training (n=12) and screening (n=10). Chatbots in most studies were rule-based (n=49) and implemented in stand-alone software (n=37). In 46 studies chatbots controlled and led the conversations. While the most frequently used input modality was written language only (n=26) the most frequently used output modality was a combination of written spoken and visual languages (n=28). In the majority of studies chatbots included virtual representations (n=44). The most common focus of chatbots was depression (n=16) or autism (n=10). Conclusion: Research regarding chatbots in mental health is nascent. There are numerous chatbots that are used for various mental disorders and purposes. Healthcare providers should compare chatbots found in this review to help guide potential users to the most appropriate chatbot to support their mental health needs. More reviews are needed to summarise the evidence regarding the effectiveness and acceptability of chatbots in mental health.;2019
Background: Conversational interfaces (CIs) in different modalities have been developed for health purposes such as health behavioral intervention patient self-management and clinical decision support. Despite growing research evidence supporting CIs' potential CI-related research is still in its infancy. There is a lack of systematic investigation that goes beyond publication review and presents the state of the art from perspectives of funding agencies academia and industry by incorporating CI-related public funding and patent activities. Objective: This study aimed to use data systematically extracted from multiple sources (ie grant publication and patent databases) to investigate the development research and fund application of health-related CIs and associated stakeholders (ie countries organizations and collaborators). Methods: A multifaceted search query was executed to retrieve records from 9 databases. Bibliometric analysis social network analysis and term co-occurrence analysis were conducted on the screened records. Results: This review included 42 funded projects 428 research publications and 162 patents. The total dollar amount of grants awarded was US $30297932 of which US $13513473 was awarded by US funding agencies and US $16784459 was funded by the Europe Commission. The top 3 funding agencies in the United States were the National Science Foundation National Institutes of Health and Agency for Healthcare Research and Quality. Boston Medical Center was awarded the largest combined grant size (US $2246437) for 4 projects. The authors of the publications were from 58 countries and 566 organizations the top 3 most productive organizations were Northeastern University (United States) Universiti Teknologi MARA (Malaysia) and the French National Center for Scientific Research (CNRS France). US researchers produced 114 publications. Although 82.0% (464/566) of the organizations engaged in interorganizational collaboration 2 organizational research-collaboration clusters were observed with Northeastern University and CNRS as the central nodes. About 112 organizations from the United States and China filed 87.7% patents. IBM filed most patents (N=17). Only 5 patents were co-owned by different organizations and there was no across-country collaboration on patenting activity. The terms patient child elderly and robot were frequently discussed in the 3 record types. The terms related to mental and chronic issues were discussed mainly in grants and publications. The terms regarding multimodal interactions were widely mentioned as users' communication modes with CIs in the identified records. Conclusions: Our findings provided an overview of the countries organizations and topic terms in funded projects as well as the authorship collaboration content and related information of research publications and patents. There is a lack of broad cross-sector partnerships among grant agencies academia and industry particularly in the United States. Our results suggest a need to improve collaboration among public and private sectors and health care organizations in research and patent activities.;2019
Background: Digital health interventions can fill gaps in mental healthcare provision. However autonomous e-mental health (AEMH) systems also present challenges for effective risk management. To balance autonomy and safety AEMH systems need to detect risk situations and act on these appropriately. One option is sending automatic alerts to carers but such 'auto-referral' could lead to missed cases or false alerts. Requiring users to actively self-refer offers an alternative but this can also be risky as it relies on their motivation to do so. This study set out with two objectives. Firstly to develop guidelines for risk detection and auto-referral systems. Secondly to understand how persuasive techniques mediated by a virtual agent can facilitate self-referral. Methods: In a formative phase interviews with experts alongside a literature review were used to develop a risk detection protocol. Two referral protocols were developed - one involving auto-referral the other motivating users to self-refer. This latter was tested via crowd-sourcing (n = 160). Participants were asked to imagine they had sleeping problems with differing severity and user stance on seeking help. They then chatted with a virtual agent who either directly facilitated referral tried to persuade the user or accepted that they did not want help. After the conversation participants rated their intention to self-refer to chat with the agent again and their feeling of being heard by the agent. Results: Whether the virtual agent facilitated persuaded or accepted influenced all of these measures. Users who were initially negative or doubtful about self-referral could be persuaded. For users who were initially positive about seeking human care this persuasion did not affect their intentions indicating that a simply facilitating referral without persuasion was sufficient. Conclusion: This paper presents a protocol that elucidates the steps and decisions involved in risk detection something that is relevant for all types of AEMH systems. In the case of self-referral our study shows that a virtual agent can increase users' intention to self-refer. Moreover the strategy of the agent influenced the intentions of the user afterwards. This highlights the importance of a personalised approach to promote the user's access to appropriate care.;2019
Background: Hospitalized older adults often experience isolation and disorientation while receiving care placing them at risk for many inpatient complications including loneliness depression delirium and falls. Embodied conversational agents (ECAs) are technological entities that can interact with people through spoken conversation. Some ECAs are also relational agents which build and maintain socioemotional relationships with people across multiple interactions. This study utilized a novel form of relational ECA provided by Care Coach (care.coach inc): an animated animal avatar on a tablet device monitored and controlled by live health advocates. The ECA implemented algorithm-based clinical protocols for hospitalized older adults such as reorienting patients to mitigate delirium risk eliciting toileting needs to prevent falls and engaging patients in social interaction to facilitate social engagement. Previous pilot studies of the Care Coach avatar have demonstrated the ECA's usability and efficacy in home-dwelling older adults. Further study among hospitalized older adults in a larger experimental trial is needed to demonstrate its effectiveness. Objective: The aim of the study was to examine the effect of a human-in-the-loop protocol-driven relational ECA on loneliness depression delirium and falls among diverse hospitalized older adults. Methods: This was a clinical trial of 95 adults over the age of 65 years hospitalized at an inner-city community hospital. Intervention participants received an avatar for the duration of their hospital stay participants on a control unit received a daily 15-min visit from a nursing student. Measures of loneliness (3-item University of California Los Angeles Loneliness Scale) depression (15-item Geriatric Depression Scale) and delirium (confusion assessment method) were administered upon study enrollment and before discharge. Results: Participants who received the avatar during hospitalization had lower frequency of delirium at discharge (P<.001) reported fewer symptoms of loneliness (P=.01) and experienced fewer falls than control participants. There were no significant differences in self-reported depressive symptoms. Conclusions: The study findings validate the use of human-in-the-loop relational ECAs among diverse hospitalized older adults.;2019
Background: In addition to addiction and substance abuse motivational interviewing (MI) is increasingly being integrated in treating other clinical issues such as mental health problems. Most of the many technological adaptations of MI however have focused on delivering the action-oriented treatment leaving its relational component unexplored or vaguely described. This study intended to design a conversational sequence that considers both technical and relational components of MI for a mental health concern. Objective: This case study aimed to design a conversational sequence for a brief motivational interview to be delivered by a Web-based text messaging application (chatbot) and to investigate its conversational experience with graduate students in their coping with stress. Methods: A brief conversational sequence was designed with varied combinations of MI skills to follow the 4 processes of MI. A Web-based text messaging application Bonobot was built as a research prototype to deliver the sequence in a conversation. A total of 30 full-time graduate students who self-reported stress with regard to their school life were recruited for a survey of demographic information and perceived stress and a semistructured interview. Interviews were transcribed verbatim and analyzed by Braun and Clarke's thematic method. The themes that reflect the process of impact of and needs for the conversational experience are reported. Results: Participants had a high level of perceived stress (mean 22.5 [SD 5.0]). Our findings included the following themes: Evocative Questions and Cliched Feedback Self-Reflection and Potential Consolation and Need for Information and Contextualized Feedback. Participants particularly favored the relay of evocative questions but were less satisfied with the agent-generated reflective and affirming feedback that filled in-between. Discussing the idea of change was a good means of reflecting on themselves and some of Bonobot's encouragements related to graduate school life were appreciated. Participants suggested the conversation provide informational support as well as more contextualized feedback. Conclusions: A conversational sequence for a brief motivational interview was presented in this case study. Participant feedback suggests sequencing questions and MI-adherent statements can facilitate a conversation for stress management which may encourage a chance of self-reflection. More diversified sequences along with more contextualized feedback should follow to offer a better conversational experience and to confirm any empirical effect.;2019
Background: In the last few years several studies have focused on describing and understanding how virtual coaches (ie coaching program or smart device aiming to provide coaching support through a variety of application contexts) could be key drivers for health promotion in home care settings. As there has been enormous technological progress in the field of artificial intelligence and data processing in the past decade the use of virtual coaches gains an augmented attention in the considerations of medical innovations. Objective: This scoping review aimed at providing an overview of the applications of a virtual coach in the clinical field. In particular the review focused on the papers that provide tangible information for coaching activities with an active implication for engaging and guiding patients who have an ongoing plan of care. Methods: We aimed to investigate the use of the term virtual coach in the clinical field performing a methodical review of the relevant literature indexed on PubMed Scopus and Embase databases to find virtual coach papers focused on specific activities dealing with clinical or medical contexts excluding those aimed at surgical settings or electronic learning purposes. Results: After a careful revision of the inclusion and exclusion criteria 46 records were selected for the full-text review. Most of the identified articles directly or indirectly addressed the topic of physical activity. Some papers were focused on the use of virtual coaching (VC) to manage overweight or nutritional issues. Other papers dealt with technological interfaces to facilitate interactions with patients suffering from different chronic clinical conditions such as heart failure chronic obstructive pulmonary disease depression and chronic pain. Conclusions: Although physical activity is a healthy practice that is most encouraged by a virtual coach system in the current scenario rehabilitation is the great absentee. This paper gives an overview of the tangible applications of this tool in the medical field and may inspire new ideas for future research on VC.;2019
Background: Many potential benefits for the uses of chatbots within the context of health care have been theorized such as improved patient education and treatment compliance. However little is known about the perspectives of practicing medical physicians on the use of chatbots in health care even though these individuals are the traditional benchmark of proper patient care. Objective: This study aimed to investigate the perceptions of physicians regarding the use of health care chatbots including their benefits challenges and risks to patients. Methods: A total of 100 practicing physicians across the United States completed a Web-based self-report survey to examine their opinions of chatbot technology in health care. Descriptive statistics and frequencies were used to examine the characteristics of participants. Results: A wide variety of positive and negative perspectives were reported on the use of health care chatbots including the importance to patients for managing their own health and the benefits on physical psychological and behavioral health outcomes. More consistent agreement occurred with regard to administrative benefits associated with chatbots many physicians believed that chatbots would be most beneficial for scheduling doctor appointments (78% 78/100) locating health clinics (76% 76/100) or providing medication information (71%71/100). Conversely many physicians believed that chatbots cannot effectively care for all of the patients' needs (76% 76/100) cannot display human emotion (72% 72/100) and cannot provide detailed diagnosis and treatment because of not knowing all of the personal factors associated with the patient (71% 71/100). Many physicians also stated that health care chatbots could be a risk to patients if they self-diagnose too often (714% 74/100) and do not accurately understand the diagnoses (74% 74/100). Conclusions: Physicians believed in both costs and benefits associated with chatbots depending on the logistics and specific roles of the technology. Chatbots may have a beneficial role to play in health care to support motivate and coach patients as well as for streamlining organizational tasks in essence chatbots could become a surrogate for nonmedical caregivers. However concerns remain on the inability of chatbots to comprehend the emotional state of humans as well as in areas where expert medical knowledge and intelligence is required.;2019
Background: Positive psychology interventions show promise for reducing psychosocial distress associated with health adversity and have the potential to be widely disseminated to young adults through technology. Objective: This pilot randomized controlled trial examined the feasibility of delivering positive psychology skills via the Vivibot chatbot and its effects on key psychosocial well-being outcomes in young adults treated for cancer. Methods: Young adults (age 18-29 years) were recruited within 5 years of completing active cancer treatment by using the Vivibot chatbot on Facebook messenger. Participants were randomized to either immediate access to Vivibot content (experimental group) or access to only daily emotion ratings and access to full chatbot content after 4 weeks (control). Created using a human-centered design process with young adults treated for cancer Vivibot content includes 4 weeks of positive psychology skills daily emotion ratings video and other material produced by survivors and periodic feedback check-ins. All participants were assessed for psychosocial well-being via online surveys at baseline and weeks 2 4 and 8. Analyses examined chatbot engagement and open-ended feedback on likability and perceived helpfulness and compared experimental and control groups with regard to anxiety and depression symptoms and positive and negative emotion changes between baseline and 4 weeks. To verify the main effects follow-up analyses compared changes in the main outcomes between 4 and 8 weeks in the control group once participants had access to all chatbot content. Results: Data from 45 young adults (36 women mean age: 25 [SD 2.9] experimental group: n=25 control group: n=20) were analyzed. Participants in the experimental group spent an average of 74 minutes across an average of 12 active sessions chatting with Vivibot and rated their experience as helpful (mean 2.0/3 SD 0.72) and would recommend it to a friend (mean 6.9/10 SD 2.6). Open-ended feedback noted its nonjudgmental nature as a particular benefit of the chatbot. After 4 weeks participants in the experimental group reported an average reduction in anxiety of 2.58 standardized t-score units while the control group reported an increase in anxiety of 0.7 units. A mixed-effects models revealed a trend-level (P=.09) interaction between group and time with an effect size of 0.41. Those in the experimental group also experienced greater reductions in anxiety when they engaged in more sessions (z=-1.9 P=.06). There were no significant (or trend level) effects by group on changes in depression positive emotion or negative emotion. Conclusions: The chatbot format provides a useful and acceptable way of delivering positive psychology skills to young adults who have undergone cancer treatment and supports anxiety reduction. Further analysis with a larger sample size is required to confirm this pattern.;2019
Background: The ability of nursing undergraduates to communicate effectively with health care providers patients and their family members is crucial to their nursing professions as these can affect patient outcomes. However the traditional use of didactic lectures for communication skills training is ineffective and the use of standardized patients is not time- or cost-effective. Given the abilities of virtual patients (VPs) to simulate interactive and authentic clinical scenarios in secured environments with unlimited training attempts a virtual counseling application is an ideal platform for nursing students to hone their communication skills before their clinical postings. Objective: The aim of this study was to develop and test the use of VPs to better prepare nursing undergraduates for communicating with real-life patients their family members and other health care professionals during their clinical postings. Methods: The stages of the creation of VPs included preparation design and development followed by a testing phase before the official implementation. An initial voice chatbot was trained using a natural language processing engine Google Cloud's Dialogflow and was later visualized into a three-dimensional (3D) avatar form using Unity 3D. Results: The VPs included four case scenarios that were congruent with the nursing undergraduates' semesters' learning objectives: (1) assessing the pain experienced by a pregnant woman (2) taking the history of a depressed patient (3) escalating a bleeding episode of a postoperative patient to a physician and (4) showing empathy to a stressed-out fellow final-year nursing student. Challenges arose in terms of content development technological limitations and expectations management which can be resolved by contingency planning open communication constant program updates refinement and training. Conclusions: The creation of VPs to assist in nursing students' communication skills training may provide authentic learning environments that enhance students' perceived self-efficacy and confidence in effective communication skills. However given the infancy stage of this project further refinement and constant enhancements are needed to train the VPs to simulate real-life conversations before the official implementation.;2019
Background: The data regarding the use of conversational agents in oncology are scarce. Objective: The aim of this study was to verify whether an artificial conversational agent was able to provide answers to patients with breast cancer with a level of satisfaction similar to the answers given by a group of physicians. Methods: This study is a blind noninferiority randomized controlled trial that compared the information given by the chatbot Vik with that given by a multidisciplinary group of physicians to patients with breast cancer. Patients were women with breast cancer in treatment or in remission. The European Organisation for Research and Treatment of Cancer Quality of Life Group information questionnaire (EORTC QLQ-INFO25) was adapted and used to compare the quality of the information provided to patients by the physician or the chatbot. The primary outcome was to show that the answers given by the Vik chatbot to common questions asked by patients with breast cancer about their therapy management are at least as satisfying as answers given by a multidisciplinary medical committee by comparing the success rate in each group (defined by a score above 3). The secondary objective was to compare the average scores obtained by the chatbot and physicians for each INFO25 item. Results: A total of 142 patients were included and randomized into two groups of 71. They were all female with a mean age of 42 years (SD 19). The success rates (as defined by a score >3) was 69% (49/71) in the chatbot group versus 64% (46/71) in the physicians group. The binomial test showed the noninferiority (P<.001) of the chatbot's answers. Conclusions: This is the first study that assessed an artificial conversational agent used to inform patients with cancer. The EORTC INFO25 scores from the chatbot were found to be noninferior to the scores of the physicians. Artificial conversational agents may save patients with minor health concerns from a visit to the doctor. This could allow clinicians to spend more time to treat patients who need a consultation the most.;2019
Background: The integration of new scientific discoveries into clinical practice costs considerable time and resources. With the increased use of social media for scientific communication new opportunities arise to bridge the gap in translational medicine. The present study aimed to investigate how medical professionals access scientific information and understand their view on the role of social media in translational medicine. Methods: A questionnaire regarding (i) the use of social media for scientific updates (ii) the opportunities and challenges of social media for translational medicine (iii) social media function Chatbot and (iv) participant demographics was developed. The survey link was posted online from February 2018 until April 2018. Results: A total of 555 professionals responded to the survey. Respondents identified themselves predominantly as researcher/scientists (27%) or medical/biomedical students (15%). The majority of participants was employed at a university or research institute (59%) and most practiced either in Europe (48%) or in Asia (37%). Seventy-eight percent of respondents reported receiving most of scientific news and updates via non-social media options such as journal websites and newspapers. Fifty-one percent of respondents believed that social media could contribute to closing the gap between scientific discovery and translation to medical application. The most crucial opportunity created by social media was found to be connecting the right scientist to the right clinician. Participants rated the translation of scientific finding to clinical practice is too fast before the safety is properly demonstrated as the most crucial challenge. Half of the respondents were aware of their institutions policy on the professional use of social media. Only 2% of respondents had previously used Chatbot. Conclusions: Overall medical professionals were positive about the idea that social media could contribute to the progress of translational medicine. However it is clear that they are still being cautious about using social media for professional purposes. To fully harness the potential of social media on translational medicine the medical community needs to be provided with educational programs guidelines and support infrastructure within social media.;2019
Background: The personalization of conversational agents with natural language user interfaces is seeing increasing use in health care applications shaping the content structure or purpose of the dialogue between humans and conversational agents. Objective: The goal of this systematic review was to understand the ways in which personalization has been used with conversational agents in health care and characterize the methods of its implementation. Methods: We searched on PubMed Embase CINAHL PsycInfo and ACM Digital Library using a predefined search strategy. The studies were included if they: (1) were primary research studies that focused on consumers caregivers or health care professionals (2) involved a conversational agent with an unconstrained natural language interface (3) tested the system with human subjects and (4) implemented personalization features. Results: The search found 1958 publications. After abstract and full-text screening 13 studies were included in the review. Common examples of personalized content included feedback daily health reports alerts warnings and recommendations. The personalization features were implemented without a theoretical framework of customization and with limited evaluation of its impact. While conversational agents with personalization features were reported to improve user satisfaction user engagement and dialogue quality the role of personalization in improving health outcomes was not assessed directly. Conclusions: Most of the studies in our review implemented the personalization features without theoretical or evidence-based support for them and did not leverage the recent developments in other domains of personalization. Future research could incorporate personalization as a distinct design factor with a more careful consideration of its impact on health outcomes and its implications on patient safety privacy and decision-making.;2019
Background: The use of chatbots has increased considerably in recent years. These are used in different areas and by a wide variety of users. Due to this fact it is essential to incorporate usability in their development. Aim: Our objective is to identify the state-of-the-art in chatbot usability and applied human-computer interaction techniques to analyze how to evaluate chatbot usability. Method: We have conducted a systematic mapping study by searching the main scientific databases. The search retrieved 170 references and 21 articles were retained as primary studies. Results: The works were categorized according to four criteria: usability techniques usability characteristics research methods and type of chatbots. Conclusions: Chatbot usability is still a very incipient field of research where the published studies are mainly surveys usability tests and rather informal experimental studies. Hence it becomes necessary to perform more formal experiments to measure user experience and exploit these results to provide usability-aware design guidelines.;2019
Background: The use of conversational agent interventions in mental health is growing at a fast pace. Recent existing reviews have focused exclusively on a subset of embodied conversational agent interventions despite other modalities aiming to achieve the common goal of improved mental health. Objective: This study aimed to review the use of conversational agent interventions in the treatment of mental health problems. Methods: We performed a systematic search using relevant databases (MEDLINE EMBASE PsycINFO Web of Science and Cochrane library). Studies that reported on an autonomous conversational agent that simulated conversation and reported on a mental health outcome were included. Results: A total of 13 studies were included in the review. Among them 4 full-scale randomized controlled trials (RCTs) were included. The rest were feasibility pilot RCTs and quasi-experimental studies. Interventions were diverse in design and targeted a range of mental health problems using a wide variety of therapeutic orientations. All included studies reported reductions in psychological distress postintervention. Furthermore 5 controlled studies demonstrated significant reductions in psychological distress compared with inactive control groups. In addition 3 controlled studies comparing interventions with active control groups failed to demonstrate superior effects. Broader utility in promoting well-being in nonclinical populations was unclear. Conclusions: The efficacy and acceptability of conversational agent interventions for mental health problems are promising. However a more robust experimental design is required to demonstrate efficacy and efficiency. A focus on streamlining interventions demonstrating equivalence to other treatment modalities and elucidating mechanisms of action has the potential to increase acceptance by users and clinicians and maximize reach.;2019
Background: The wide scale and severity of consequences of tobacco use benefits derived from cessation low rates of intervention by healthcare professionals and new opportunities stemming from novel communications technologies are the main factors motivating this project. Thus the purpose of this study is to assess the effectiveness of an intervention that helps people cease smoking and increase their nicotine abstinence rates in the long term via a chat-bot compared to usual practice utilizing a chemical validation at 6 months. Methods: Design: Randomized controlled multicentric pragmatic clinical trial with a 6-month follow-up. Setting: Healthcare centers in the public healthcare system of the Community of Madrid (Madrid Regional Health Service). Participants: Smokers > 18 years of age who attend a healthcare center and accept help to quit smoking in the following month. N = 460 smokers (230 per arm) who will be recruited prior to randomization. Intervention group: use of a chat-bot with evidence-based contents to help quit smoking. Control group: Usual treatment (according to the protocol for tobacco cessation by the Madrid Regional Health Service Main variable: Continuous nicotine withdrawal with chemical validation (carbon monoxide in exhaled air). Intention-to-treat analysis. Difference between groups in continuous abstinence rates at 6 months with their corresponding 95% confidence interval. A logistic regression model will be built to adjust for confounding factors. Results: First expected results in January 2020. Discussion: Providing science-based evidence on the effectiveness of clinical interventions via information technologies without the physical presence of a professional is essential. In addition to being more efficient the characteristics of these interventions can improve effectiveness accessibility and adherence to treatment. From an ethics perspective this new type of intervention must be backed by scientific evidence to circumvent pressures from the market or particular interests improve patient safety and follow the standards of correct practices for clinical interventions.;2019
Background: There are an estimated 800000 suicides per year globally and approximately 16000000 suicide attempts. Mobile apps may help address the unmet needs of people at risk. We assessed adherence of suicide prevention advice in depression management and suicide prevention apps to six evidence-based clinical guideline recommendations: mood and suicidal thought tracking safety plan development recommendation of activities to deter suicidal thoughts information and education access to support networks and access to emergency counseling. Methods: A systematic assessment of depression and suicide prevention apps available in Google Play and Apple's App Store was conducted. Apps were identified by searching 42matters in January 2019 for apps launched or updated since January 2017 using the terms depression depressed depress mood disorders suicide and self-harm. General characteristics of apps adherence with six suicide prevention strategies identified in evidence-based clinical guidelines using a 50-question checklist developed by the study team and trustworthiness of the app based on HONcode principles were appraised and reported as a narrative review using descriptive statistics. Results: The initial search yielded 2690 potentially relevant apps. Sixty-nine apps met inclusion criteria and were systematically assessed. There were 20 depression management apps (29%) 3 (4%) depression management and suicide prevention apps and 46 (67%) suicide prevention apps. Eight (12%) depression management apps were chatbots. Only 5/69 apps (7%) incorporated all six suicide prevention strategies. Six apps (6/69 9%) including two apps available in both app stores and downloaded more than one million times each provided an erroneous crisis helpline number. Most apps included emergency contact information (65/69 apps 94%) and direct access to a crisis helpline through the app (46/69 apps 67%). Conclusions: Non-existent or inaccurate suicide crisis helpline phone numbers were provided by mental health apps downloaded more than 2 million times. Only five out of 69 depression and suicide prevention apps offered all six evidence-based suicide prevention strategies. This demonstrates a failure of Apple and Google app stores and the health app industry in self-governance and quality and safety assurance. Governance levels should be stratified by the risks and benefits to users of the app such as when suicide prevention advice is provided.;2019
Background: Training therapists is both expensive and time-consuming. Degree-based training can require tens of thousands of dollars and hundreds of hours of expert instruction. Counseling skills practice often involves role-plays standardized patients or practice with real clients. Performance-based feedback is critical for skill development and expertise but trainee therapists often receive minimal and subjective feedback which is distal to their skill practice. Objective: In this study we developed and evaluated a patient-like neural conversational agent which provides real-time feedback to trainees via chat-based interaction. Methods: The text-based conversational agent was trained on an archive of 2354 psychotherapy transcripts and provided specific feedback on the use of basic interviewing and counseling skills (ie open questions and reflections-summary statements of what a client has said). A total of 151 nontherapists were randomized to either (1) immediate feedback on their use of open questions and reflections during practice session with ClientBot or (2) initial education and encouragement on the skills. Results: Participants in the ClientBot condition used 91% (21.4/11.2) more reflections during practice with feedback (P<.001) and 76% (14.1/8) more reflections after feedback was removed (P<.001) relative to the control group. The treatment group used more open questions during training but not after feedback was removed suggesting that certain skills may not improve with performance-based feedback. Finally after feedback was removed the ClientBot group used 31% (32.5/24.7) more listening skills overall (P<.001). Conclusions: This proof-of-concept study demonstrates that practice and feedback can improve trainee use of basic counseling skills.;2019
Behavioral intervention technologies (BITs) are unique ways to incorporate the benefits of technology and psychology to address differing health needs through various media including Internet interventions mobile apps and video games. BITs present several possible benefits including increased dissemination and accessibility cost-effectiveness increased engagement and decreased stigma especially among youth. A behavioral coaching chatbot Tess addresses different facets of behavioral health such as depression and anxiety. Available 24/7 Tess delivers customized integrative support psychoeducation and interventions through brief conversations via existing communication channels (i.e. SMS text messaging and Facebook Messenger). This study assessed the feasibility of integrating Tess in behavioral counseling of adolescent patients (n = 23 M-age = 15.20 years Range(age) = 9.78-18.54 years 57% female) coping with weight management and prediabetes symptoms. Tess engaged patients via a preferred method of communication (SMS text messaging) in individualized conversations to promote treatment adherence behavior change and overall wellness. Adolescent patients reported experiencing positive progress toward their goals 81% of the time. The 4123 messages exchanged and patients' reported usefulness ratings (96% of the time) illustrate that adolescents engaged with and viewed this chatbot as helpful. These results highlight the feasibility and benefit of support through artificial intelligence specifically in a pediatric setting which could be scaled to serve larger groups of patients. As a partner to clinicians Tess can continue the therapeutic interaction outside office hours while maintaining patient satisfaction. Due to Tess's capacity for continuous learning future iterations may have additional features to increase the user experience.;2019
Big Data and Deep Learning algorithms combined with enormous computing power have paved ways for significant technological advancements. Technology is evolving to anticipate understand and address our unmet needs. However to fully meet human needs machines or computers must deeply understand human behavior including emotions. Emotions are physiological states generated in humans as a reaction to internal or external events. They are complex and studied across numerous fields including computer science. As humans on reading Why don't you ever text me! we can either interpret it as a sad or an angry emotion and the same ambiguity exists for machines as well. Lack of facial expressions and voice modulations make detecting emotions in text a challenging problem. However in today's online world humans are increasingly communicating using text messaging applications and digital agents. Hence it is imperative for machines to understand emotions in textual dialogue to provide emotionally aware responses to users. In this paper we propose a novel Deep Learning based approach to detect emotions- Happy Sad and Angry in textual dialogues. The essence of our approach lies in combining both semantic and sentiment based representations for more accurate emotion detection. We use semi-automated techniques to gather large scale training data with diverse ways of expressing emotions to train our model. Evaluation of our approach on real world dialogue datasets reveals that it significantly outperforms traditional Machine Learning baselines as well as other off-the-shelf Deep Learning models.;2019
Building an empathic conversation agent in open-domain is a key step towards affective computing and intelligent interactions. However most current methods either focus on the consistency of content or the controllability of emotion and handling both factors are not yet properly solved. In this paper we propose the multi-task and dual attentions (MTDA) framework for generating an emotional response. The MTDA framework decomposes the input utterance into the content layer and emotional layer and then encodes and decodes them separately which makes this end-to-end model more interpretable and controllable. A multi-task learning based encoder is employed in the MTDA framework which can obtain the representation of the content and the emotion through unsupervised learning and supervised learning. A dual attention mechanism is adopted for decoding which ensures that specific emotional responses are coherent with the content and the emotion of the input. We also combine the MTDA framework with state of the art generative models to train emotional generation systems. Extensive experiments show that our model can not only adapt to different target emotion goals but also generate coherent and informative responses.;2019
Chatbots are predicted to play a key role in customer service. Users' trust in such chatbots is critical for their uptake. However there is a lack of knowledge concerning users' trust in chatbots. To bridge this knowledge gap we present a questionnaire study (N = 154) that investigated factors of relevance for trust in customer service chatbots. The study included two parts: an explanatory investigation of the relative importance of factors known to predict trust from the general literature on interactive systems and an exploratory identification of other factors of particular relevance for trust in chatbots. The participants were recruited as part of their dialogue with one of four chatbots for customer service. Based on the findings we propose an initial model of trust in chatbots for customer service including chatbot-related factors (perceived expertise and responsiveness) environment-related factors (risk and brand perceptions) and user-related factors (propensity to trust technology). RESEARCH HIGHLIGHTS We extend the current knowledge base on natural language interfaces by investigating factors affecting users' trust in chatbots for customer service. Chatbot-related factors specifically perceived expertise and responsiveness are found particularly important to users' trust in such chatbots but also environment-related factors such as brand perception and user-related factors such as propensity to trust technology. On the basis of the findings we propose an initial model of users' trust chatbots for customer service.;2019
Chatbots are replacing human agents in a number of domains from online tutoring to customer-service to even cognitive therapy. But they are often machine-like in their interactions. What can we do to humanize chatbots? Should they necessarily be driven by human operators for them to be considered human? Or will an anthropomorphic visual cue on the interface and/or a high-level of contingent message exchanges provide humanness to automated chatbots? We explored these questions with a 2 (anthropomorphic visual cues: high vs. low anthropomorphism) x 2 (message interactivity: high vs. low message interactivity) x 2 (identity cue: chat-bot vs. human) between-subjects experiment (N = 141) in which participants interacted with a chat agent on an e-commerce site about choosing a digital camera to purchase. Our findings show that a high level of message interactivity compensates for the impersonal nature of a chatbot that is low on anthropomorphic visual cues. Moreover identifying the agent as human raises user expectations for interactivity. Theoretical as well as practical implications of these findings are discussed.;2019
Chatbots are used frequently in business to facilitate various processes particularly those related to customer service and personalization. In this article we propose novel methods of tracking human-chatbot interactions and measuring chatbot performance that take into consideration ethical concerns particularly trust. Our proposed methodology links neuroscientific methods text mining and machine learning. We argue that trust is the focal point of successful human-chatbot interaction and assess how trust as a relevant category is being redefined with the advent of deep learning supported chatbots. We propose a novel method of analyzing the content of messages produced in human-chatbot interactions using the Condor Tribefinder system we developed for text mining that is based on a machine learning classification engine. Our results will help build better social bots for interaction in business or commercial environments. (C) 2019 Kelley School of Business Indiana University. Published by Elsevier Inc. All rights reserved.;2019
Chatbots are very much an emerging technology and there is still much to learn about how conversational user interfaces will affect the way in which humans communicate not only with computers but also with one another. Further studies on anthropomorphic agents and the projection of human characteristics onto a system are required to further develop this area. Gender stereotypes operate a profound effect on human behaviour. The application of gender to a conversational agent brings along with it the projection of user biases and preconceptions. These feelings and perceptions about an agent can be used to develop mental models of a system. Users can be inclined to measure the success of a system based on their biases and emotional connections with the agent rather than that of the system's performance. There have been many studies that show how gender affects human perceptions of a conversational agent. However there is limited research on the effect of gender when applied to a chatbot system. This chapter presents early results from a research study which indicate that chatbot gender does have an effect on users overall satisfaction and gender-stereotypical perception. Subsequent studies could focus on examining the ethical implications of the results and further expanding the research by increasing the sample size to validate statistical significance as well as recruiting a more diverse sample size from various backgrounds and experiences. RESEARCH HIGHLIGHTS Many studies have indicated how gender affects human perceptions of a conversational agent. However there is limited research on the effect of gender when applied to a chatbot system. This research study presents early results which indicate that chatbot gender does have an effect on users overall satisfaction and gender-stereotypical perception. Users are more likely to apply gender stereotypes when a chatbot system operates within a gender-stereotypical subject domain such as mechanics and when the chatbot gender does not conform to gender stereotypes. This study raise ethical issues. Should we exploit this result and perpetuate the bias and stereotyping? Should we really have a male chatbot for technical advice bots? Is this perpetuating stereotyping the dilemma being that a male version would elicit more trust?;2019
Chatbots on social networking sites are a recent innovation in computer-mediated marketing communication. In this study 245 Facebook users between 18 and 35 years of age (M-age = 25.97 SD = 4.92) were asked to order tickets for the movies through Cinebot a Facebook chatbot specifically built for the study. Afterwards they were asked to evaluate their experiences via an online survey. The first purpose of this article was to investigate whether and how perceived helpfulness and usefulness of a chatbot consulted on the Facebook Messenger platform affected perceived intrusiveness of chatbot-initiated advertising in a later stage. In a second analysis the relation between perceived intrusiveness and patronage intentions (i.e. purchase and recommendation intention of the product) was investigated. In addition the role of message acceptance as a mediator and perceived message relevance as a moderator in this latter model were explored. As to the best of our knowledge our study is the first to investigate chatbot advertising our research findings may hold important managerial implications.;2019
Chatbots also known as conversational agents or digital assistants are artificial intelligence-driven software programs designed to interact with people in a conversational manner. They are often used for user-friendly customer-service triaging. In healthcare chatbots can create bidirectional information exchange with patients which could be leveraged for follow-up screening treatment adherence or data-collection. They can be deployed over various modalities such as text-based services (text messaging mobile applications chat rooms) on any website or mobile applications or audio services such as Siri Alexa Cortana or Google Assistant. Potential applications are very promising particularly in the field of oncology. In this review we discuss the available publications and applications and the ongoing trials in that setting. (C) 2019 The Authors. Published by Elsevier B.V. on behalf of European Society for Radiotherapy and Oncology.;2019
Chat-oriented dialogue systems sometimes generate inappropriate response utterances to user utterances that cause dialogue breakdown. Detecting such inappropriate utterances and suppressing them will support the continuation of the dialogue. Although a previous state-of-the-art dialogue breakdown detector leveraged dialogue-act transitions and word-based similarities between utterance pairs these features are insufficient to evaluate the appropriateness of question-answering or relatedness between utterances that share few topic words. In this paper we propose novel features to assess these problems and examine their effectiveness for improving the performance of dialogue breakdown detection. (C) 2018 Elsevier Ltd. All rights reserved.;2019
Contemporary research on aging has provided mixed evidence for whether older adults are less effective than younger adults at designing and delivering spoken utterances. However mast of these studies have focused on only specific aspects of this process. In addition they tend to vary significantly in terms of the degree of complexity in their chosen stimuli or task. The present study compares younger and older adults' performance using a referential production paradigm involving simple everyday objects. We varied referential context such 5 that a target object was either unique in its category (e.g. one shirt) or was accompanied by a same-category object (e.g. two shirts). We evaluated whether speakers' descriptions provided listeners with sufficient information for identification and whether speakers spontaneously adapt their speech for different addressee types (younger adult older adult automated dialogue system). A variety of measures were included to provide a comprehensive perspective on adults' performance. Interestingly the results revealed few or no age differences in measures related to production performance (speech onset latency speech rate and fluency). In contrast consistent differences were observed for measures related to descriptive content both in terms of informativity and variability in lexical selection: Older adults not only provided more information than necessary for referential success (e.g. superfluous modifiers) but also exhibited greater variability in their selection of modifiers. The results show that although certain aspects of the production process are well-preserved across the adult lifespan meaningful age-related differences can still be found in simple referential tasks with everyday objects.;2019
Conversation practice while paramount for all language learners can be difficult to get enough of and very expensive. In this mobile age chatbots are an obvious means of filling this gap but have yet to realize their potential as practice partners. The current study was undertaken to examine why chatbots are not yet a substantial instrument for language learning engagement/practice and to provide direction for future practice and chatbot development. To this end building on a recent experimental study examining chatbot novelty effects students undertook a pair of conversation activities: human and human-chatbot (via speech-to-text software). Immediately following the practice conversations students' interest in the two partners was surveyed and open-ended textual feedback was collected. With these data sources and prior standardised test results regression and content analysis of the data was undertaken. Findings indicated: 1) prior interest in human conversation partners was the best single predictor of future interest in chatbot conversations 2) prior language competency was more strongly linked to interest in chatbot than human conversations 3) that the qualitative experience of having learned more with the chatbot was strongly connected to task interest even when reporting communication difficulties. Implications for practicing languages with currently available chatbots for chatbots and related educational technology as sources of student interest and directions for chatbots future development are discussed.;2019
Conversational agents (CAs) are software-based systems designed to interact with humans using natural language and have attracted considerable research interest in recent years. Following the Computers Are Social Actors paradigm many studies have shown that humans react socially to CAs when they display social cues such as small talk gender age gestures or facial expressions. However research on social cues for CAs is scattered across different fields often using their specific terminology which makes it challenging to identify classify and accumulate existing knowledge. To address this problem we conducted a systematic literature review to identify an initial set of social cues of CAs from existing research. Building on classifications from interpersonal communication theory we developed a taxonomy that classifies the identified social cues into four major categories (i.e. verbal visual auditory invisible) and ten subcategories. Subsequently we evaluated the mapping between the identified social cues and the categories using a card sorting approach in order to verify that the taxonomy is natural simple and parsimonious. Finally we demonstrate the usefulness of the taxonomy by classifying a broader and more generic set of social cues of CAs from existing research and practice. Our main contribution is a comprehensive taxonomy of social cues for CM. For researchers the taxonomy helps to systematically classify research about social cues into one of the taxonomy's categories and corresponding subcategories. Therefore it builds a bridge between different research fields and provides a starting point for interdisciplinary research and knowledge accumulation. For practitioners the taxonomy provides a systematic overview of relevant categories of social cues in order to identify implement and test their effects in the design of a CA.;2019
Conversational agents (CAs) play an important role in human computer interaction (HCI). Creating believable movements for CAs is challenging since the movements have to be meaningful and natural reflecting the coupling between gestures and speech. Studies in the past have mainly relied on rule-based or data-driven approaches. Rule-based methods focus on creating meaningful behaviors conveying the underlying message but the gestures cannot be easily synchronized with speech. Data-driven approaches especially speech-driven models can capture the relationship between speech and gestures. However they create behaviors disregarding the meaning of the message. This study proposes to bridge the gap between these two approaches overcoming their limitations. The approach builds a dynamic Bayesian network (DBN) where a discrete variable is added to constrain the behaviors on the underlying constraint. The study implements and evaluates the approach with two constraints: discourse functions and prototypical behaviors. By constraining on the discourse functions (e.g. questions) the model learns the characteristic behaviors associated with a given discourse class learning the rules from the data. By constraining on prototypical behaviors (e.g. head nods) the approach can be embedded in a rule-based system as a behavior realizer creating trajectories that are timely synchronized with speech. The study proposes a DBN structure and a training approach that (1) models the cause-effect relationship between the constraint and the gestures and (2) captures the differences in the behaviors across constraints by enforcing sparse transitions between shared and exclusive states per constraint. Objective and subjective evaluations demonstrate the benefits of the proposed approach over an unconstrained baseline model.;2019
Conversational agents (CM) are an integral component of many personal and business interactions. Many recent advancements in CA technology have attempted to make these interactions more natural and human-like. However it is currently unclear how human-like traits in a CA impact the way users respond to questions from the CA. In some applications where CAs may be used detecting deception is important. Design elements that make CA interactions more human-like may induce undesired strategic behaviors from human deceivers to mask their deception. To better understand this interaction this research investigates the effect of conversational skill-that is the ability of the CA to mimic human conversation-from CAs on behavioral indicators of deception. Our results show that cues of deception vary depending on CA conversational skill and that increased conversational skill leads to users engaging in strategic behaviors that are detrimental to deception detection. This fading suggests that for applications in which it is desirable to detect when individuals are lying the pursuit of more human-like interactions may be counter-productive.;2019
Conversational artificial intelligence (AI) is changing the way mental health care is delivered. By gathering diagnostic information facilitating treatment and reviewing clinician behavior conversational AI is poised to impact traditional approaches to delivering psychotherapy. While this transition is not disconnected from existing professional services specific formulations of clinician-AI collaboration and migration paths between forms remain vague. In this viewpoint we introduce four approaches to AI-human integration in mental health service delivery. To inform future research and policy these four approaches are addressed through four dimensions of impact: access to care quality clinician-patient relationship and patient self-disclosure and sharing. Although many research questions are yet to be investigated we view safety trust and oversight as crucial first steps. If conversational AI isn't safe it should not be used and if it isn't trusted it won't be. In order to assess safety trust interfaces procedures and system level workflows oversight and collaboration is needed between AI systems patients clinicians and administrators.;2019
Conversational data in social media contain a great deal of useful information and conversation anomaly detection is an important research direction in the field of sentiment analysis. Each user has his or her own specific emotional characteristic and by studying the distribution and sampling the users' emotional transitions we can simulate specific emotional transitions in the conversations. Anomaly detection in conversation data refers to detecting users' abnormal opinions and sentiment patterns as well as special temporal aspects of such patterns. This paper proposes a hybrid model that combines the convolutional neural network long short-term memory (CNN-LSTM) with a Markov chain Monte Carlo (MCMC) method to identify users' emotions sample users' emotional transition and detect anomalies according to the transition tensor. The emotional transition sampling is implemented by improving the MCMC algorithm and the anomalies are detected by calculating the similarity between the normal transition tensor and the current transition tensor of the user. The experiment was carried on four corpora and the results show that emotions can be well sampled to conform to user's characteristics and anomaly can be detected by the proposed method. The model proposed can be used in intelligent conversation systems such as simulating the emotional transition and detecting the abnormal emotions.;2019
Conversational robots have been used to convey information to people in the real world. Android robots which have a human-like appearance are expected to be able to convey not only objective information but also subjective information such as a robot's feelings. Meanwhile as an approach to realize attractive conversation multi-party conversation by multiple robots was the focus of this study. By collaborating among several robots the robots provide information while maintaining the naturalness of conversation. However the effectiveness of interaction with people has not been surveyed using this method. In this paper to develop more efficient media to convey information we propose a scenario-based semi-passive conversation system using two androids. To verify its effectiveness we conducted a subjective experiment comparing it to a system that does not include any interaction with people and we investigated how much information the proposed system successfully conveys by using a recall test and a questionnaire about the conversation and androids. The experimental results showed that participants who engaged with the proposed system recalled more content from the conversation and felt more empathic concern for androids.;2019
Customer services are critical to all companies as they may directly connect to the brand reputation. Due to a great number of customers e-commerce companies often employ multiple communication channels to answer customers' questions for example Chatbot and Hotline. On one hand each channel has limited capacity to respond to customers' requests on the other hand customers have different preferences over these channels. The current production systems are mainly built based on business rules that merely consider the tradeoffs between the resources and customers' satisfaction. To achieve the optimal tradeoff between the resources and customers' satisfaction we propose a new framework based on deep reinforcement learning that directly takes both resources and user model into account. In addition to the framework we also propose a new deep-reinforcement-learning-based routing method-double dueling deep Q-learning with prioritized experience replay (PER-DoDDQN). We evaluate our proposed framework and method using both synthetic and a real customer service log data from a large financial technology company. We show that our proposed deep-reinforcement-learning-based framework is superior to the existing production system. Moreover we also show that our proposed PER-DoDDQN is better than all other deep Q-learning variants in practice which provides a more optimal routing plan. These observations suggest that our proposed method can seek the tradeoff where both channel resources and customers' satisfaction are optimal.;2019
Data-driven untying of a recursive autoencoder (RAE) is proposed for utterance intent classification for spoken dialogue systems. Although an RAE expresses a nonlinear operation on two neighboring child nodes in a parse tree in the application of spoken language understanding (SLU) of spoken dialogue systems the nonlinear operation is considered to be intrinsically different depending on the types of child nodes. To reduce the gap between the single nonlinear operation of an RAE and intrinsically different operations depending on the node types a data-driven untying of autoencoders using part-of-speech (PoS) tags at leaf nodes is proposed. When using the proposed method the experimental results on two corpora: ATIS English data set and Japanese data set of a smartphone-based spoken dialogue system showed improved accuracies compared to when using the tied RAE as well as a reasonable difference in untying between two languages.;2019
Deep learning has revolutionized the field of conversation modeling. A lot of the research has been toward making the conversational agent more human-like. As a result overall the model size increases. Bigger models require more data and are costly to build and maintain. Often for some tasks high-quality responses are not necessary. In this paper a model that consumes fewer resources and a way to augment conversation data without increasing the size of the vocabulary is proposed. The proposed model uses a modified version of the GRU instead of the LSTM to encode and decode sequences of text.;2019
Designing dialogue policies that take user behavior into account is complicated due to user variability and behavioral uncertainty. Attributed probabilistic finite-state bi-automata (A-PFSBA) have proven to be a promising framework to develop dialogue managers that capture the users' actions in its structure and adapt to them online yet developing policies robust to high user uncertainty is still challenging. In this paper the theoretical A-PFSBA dialogue management framework is augmented by formally defining the notation of exploitation policies over its structure. Under such definition multiple path-based policies are implemented those that take into account external information and those which do not. These policies are evaluated on the Let's Go corpus before and after an online learning process whose goal is to update the initial model through the interaction with end users. In these experiments the impact of user uncertainty and the model structural learning is thoroughly analyzed.;2019
Despite deep reinforcement learning has attained performance beyond human beings in many domains including games dialogue systems and robotics sample inefficient is still a limitation in the application of deep reinforcement learning. This paper develops a novel and simple gradient-based meta learning method suitable for improving learning efficiency of deep reinforcement learning methods. Rather than designing complex network or adding excessive fine tuning parameters the proposed method is simple and does not introduce any learned parameters for meta learning. Specifically according to the characteristic of different trajectories this paper proposes to weight every trajectory in model-agnostic meta-learning for meta updating gradient effectively. The key idea underlying this method is to take advantage of the relationship between different trajectories and the direction of parameter update. Additionally an end-to-end training approach is also introduced so that the proposed model can attain good results with a small amount of training data on new tasks. The statistical results of the experiments indicate that the proposed algorithm delivers state-of-the-art performance on both discrete and continuous control tasks.;2019
Despite our best efforts pediatric obesity remains an important public health issue. Although many different approaches to address this condition have been utilized few have achieved long-term success. Technology is increasingly being explored as a convenient and accessible method for delivering behavioral interventions. Stephens and colleagues report the feasibility of using a behavioral coaching social chatbot Tess to extend a multicomponent pediatric obesity intervention for adolescents. We examine the pros and cons of this approach. Although social chatbots offer an interesting and novel method for promoting round-the-clock support important issues and decisions must be carefully considered during the design phase to help ensure a safe environment for a vulnerable population.;2019
Dialog agents like digital assistants and automated chat interfaces (e.g. chatbots) are becoming more and more popular as users adapt to conversing with their devices as they do with humans. In this paper we present approaches and available tools for dialog management (DM) a component of dialog agents that handles dialog context and decides the next action for the agent to take. In this paper we establish an overview of the field of DM compare approaches and state-of-the-art tools in industry and research work on a set of dimensions and identify directions for further research work.;2019
Dialog management plays an important role in the task-oriented dialog system. Most of the previous works divide dialog management into state tracker and action selector. The two parts are modeled separately and implemented in a pipelined way which suffers from the problem of error accumulation and the feedback signal from action selector cannot be propagated to state tracker and natural language understanding module. This paper proposes a word-based partially observable Markov decision processes' dialog management that integrates natural language understanding state tracker and action selector into an end-to-end architecture. Our proposed dialog management takes the words from user utterances as inputs and then produces optimal action as well as slot values of natural language understanding which are necessary for response generation. To this end we propose a hybrid learning method which integrates reinforcement learning and supervised learning to optimize the action selector and slot filler jointly. In addition we develop a high-return prioritized experience replay to speed up the convergence of the training process. The experimental results show that the proposed dialog management outperforms four strong baselines in a series of different dialog tasks. A human user's evaluation also shows the same results. The high-return prioritized experience replay accelerates the convergence effectively especially in the scenario in which the proposed dialog management works on more complex tasks.;2019
Dialog state tracking (DST) is the key component of goal-driven Spoken Dialog Systems. Almost all existing dialog state trackers are unable to handle unknown slot values. The continuous emergence of unknown slot values in dialogs is inevitable. If unknown slot values cannot be accurately detected and distinguished the dialog states cannot be correctly updated in real time. This paper proposes a hierarchical dialog state tracking framework to model the dialog state tracking with unknown slot values. Three levels are included in the framework. Unknown slot values are identified at the first-level by a two-layer cascaded neural network as well as known slot values. Distributions for unknown and known slot values are updated separately in the second level and integrated in the third level. Experimental results on DSTC and WOZ2.0 datasets show that the proposed framework achieves good performance. Especially the detection and distinction of unknown slot values greatly improve the final performance of dialog state tracking illustrating the effectiveness of our proposed framework for addressing the problem of unknown slot values.;2019
Dialogue breakdown is a significant problem in conversational agents. Timely breakdown detection helps the agents quickly recover from mistakes minimizing the impact on user experience. In this paper we focus on two problems: variations in determining a response that breakdowns a conversation i.e. subjectivity and variations in breakdown types due to designs of conversational agents i.e. variationality. To address the subjectivity which decreases the agreement rate among annotators our methods detect a dialogue breakdown by ensembling detectors trained by different sets of annotators that are grouped using a clustering algorithm. To address the variationality our methods apply two types of detector architectures to capture global and local breakdowns. The long short-term memory detector considers the global context and the convolutional neural networks detector is sensitive to the local characteristics. The ensemble of all detectors makes a final judgment. The results of the Japanese task in the Dialogue Breakdown Detection Challenge 3 (DBDC3) confirm that our approach significantly outperforms the baseline which uses the conventional conditional random field. Detailed error analysis reveals that our encoders based on a convolutional neural network and a long short-term memory have different characteristics. It also confirms the effects of annotator clustering. (C) 2018 Elsevier Ltd. All rights reserved.;2019
Dialogue management (DM) is responsible for predicting the next action of a dialogue system according to the current dialogue state and thus plays a central role in task-oriented dialogue systems. Since DM requires having access not only to local utterances but also to the global semantics of the entire dialogue session modeling the long-range history information is a critical issue. To this end we propose MAD a novel memory-augmented dialogue management model that employs a memory controller and two additional memory structures (i.e. a slot-value memory and an external memory). The slot-value memory tracks the dialogue state by memorizing and updating the values of semantic slots (i.e. cuisine price and location) and the external memory augments the representation of hidden states of traditional recurrent neural networks by storing more context information. To update the dialogue state efficiently we also propose slot-level attention on user utterances to extract specific semantic information for each slot. Experiments show that our model can obtain state-of-the-art performance and outperforms existing baselines.;2019
Dialogue policy plays an important role in task-oriented spoken dialogue systems. It determines how to respond to users. The recently proposed deep reinforcement learning (DRL) approaches have been used for policy optimization. However these deep models are still challenging for two reasons: first many DRL-based policies are not sample efficient and second most models do not have the capability of policy transfer between different domains. In this paper we propose a universal framework AgentGraph to tackle these two problems. The proposed AgentGraph is the combination of graph neural network (GNN) based architecture and DRL-based algorithm. It can be regarded as one of the multi-agent reinforcement learning approaches. Each agent corresponds to a node in a graph which is defined according to the dialogue domain ontology. When making a decision each agent can communicate with its neighbors on the graph. Under AgentGraph framework we further propose dual GNN-based dialogue policy which implicitly decomposes the decision in each turn into a high-level global decision and a low-level local decision. Experiments show that AgentGraph models significantly outperform traditional reinforcement learning approaches on most of the 18 tasks of the PyDial benchmark. Moreover when transferred from the source task to a target task these models not only have acceptable initial performance but also converge much faster on the target task.;2019
Digital family health history tools have been developed but few have been tested with non-English speakers and evaluated for acceptability and usability. This study describes the cultural and linguistic adaptation and evaluation of a family health history tool (VICKY: VIrtual Counselor for Knowing Your Family History) for Spanish speakers. In-depth interviews were conducted with 56 Spanish-speaking participants a subset of 30 also participated in a qualitative component to evaluate the acceptability and usability of Spanish VICKY. Overall agreement in family history assessment was moderate between VICKY and a genetic counselor (weighted kappa range: 0.4695 for stroke-0.6615 for heart disease) although this varied across disease subtypes. Participants felt comfortable using VICKY and noted that VICKY was very likeable and possessed human-like characteristics. They reported that VICKY was very easy to navigate felt that the instructions were very clear and thought that the time it took to use the tool was just right. Spanish VICKY may be useful as a tool to collect family health history and was viewed as acceptable and usable. The study results shed light on some cultural differences that may influence interactions with family history tools and inform future research aimed at designing and testing culturally and linguistically diverse digital systems.;2019
Domain adaptation using source domain data is preferable in the development of Deep Q Network (DQN) based dialog systems because of the training cost for additional target domains. However the inherent domain shift hinders feature-space level generalization which degrades performance. We introduce Adversarial Calibrator based Transfer learning (ACT) to aid the coherent training of the target domain feature extractor network. In ACT the feature extractor of the target domain is considered as a generator which is trained to be matched with a pre-stored latent feature set of the source domain with adversarial training losses. We verified ACT with the PyDial framework conducting domain adaptation experiment with the following domains: San Francisco Restaurant (SFR) Cambridge Restaurant (CR) and Laptop11 (LAP). The result demonstrates that ACT outperforms beta-VAE based adaptation between the pair of distinct domains (SFR-LAP) and even outperforms individual learning between the pair of similar domains (SFR-CR). (C) 2019 Elsevier B.V. All rights reserved.;2019
Domain-specific goal-oriented dialogue systems typically require modeling three types of inputs namely (i) the knowledge-base associated with the domain (ii) the history of the conversation which is a sequence of utterances and (iii) the current utterance for which the response needs to be generated. While modeling these inputs current state-of-the-art models such as Mem2Seq typically ignore the rich structure inherent in the knowledge graph and the sentences in the conversation context. Inspired by the recent success of structure-aware Graph Convolutional Networks (GCNs) for various NLP tasks such as machine translation semantic role labeling and document dating we propose a memory-augmented GCN for goal-oriented dialogues. Our model exploits (i) the entity relation graph in a knowledge-base and (ii) the dependency graph associated with an utterance to compute richer representations for words and entities. Further we take cognizance of the fact that in certain situations such as when the conversation is in a code-mixed language dependency parsers may not be available. We show that in such situations we could use the global word co-occurrence graph to enrich the representations of utterances. We experiment with four datasets: (i) the modified DSTC2 dataset (ii) recently released code-mixed versions of DSTC2 dataset in four languages (iii) Wizard-of-Oz style CAM676 dataset and (iv) Wizard-of-Oz style MultiWOZ dataset. On all four datasets our method outperforms existing methods on a wide range of evaluation metrics.;2019
Driven by 'success stories' reported by private sector firms government agencies have also started adopting various Artificial Intelligence (AI) technologies in diverse domains (e.g. health taxation and education) however extensive research is required in order to exploit the full potential of AI in the public sector and leverage various AI technologies to address important problems/needs. This paper makes a contribution in this direction: it presents a novel approach as well as the architecture of an ICT platform supporting it for the advanced exploitation of a specific AI technology namely chatbots in the public sector in order to address a crucial issue: the improvement of communication between government and citizens (which has for long time been problematic). The proposed approach builds on natural language processing machine learning and data mining technologies and leverages existing data of various forms (such as documents containing legislation and directives structured data from government agencies' operational systems social media data etc.) in order to develop a new digital channel of communication between citizens and government. Making use of appropriately structured and semantically annotated data this channel enables 'richer' and more expressive interaction of citizens with government in everyday language facilitating and advancing both information seeking and conducting of transactions. Compared to existing digital channels the proposed approach is appropriate for a wider range of citizens' interactions with higher levels of complexity ambiguity and uncertainty. In close co-operation with three Greek government agencies (the Ministry of Finance a social security organization and a big local government organization) this approach has been validated through a series of application scenarios.;2019
Emotion is intrinsic to humans and consequently emotion understanding is a key part of human-like artificial intelligence (AI). Emotion recognition in conversation (ERC) is becoming increasingly popular as a new research frontier in natural language processing (NLP) due to its ability to mine opinions from the plethora of publicly available conversational data on platforms such as Facebook Youtube Reddit Twitter and others. Moreover it has potential applications in health-care systems (as a tool for psychological analysis) education (understanding student frustration) and more. In Addition ERC is also extremely important for generating emotion-aware dialogues that require an understanding of the user's emotions. Catering to these needs calls for effective and scalable conversational emotion-recognition algorithms. However it is a difficult problem to solve because of several research challenges. In this paper we discuss these challenges and shed light on recent research in this field. We also describe the drawbacks of these approaches and discuss the reasons why they fail to successfully overcome the research challenges in ERC.;2019
Emotional conversation generation has elicited a wide interest in both academia and industry. However existing emotional neural conversation systems tend to ignore the necessity to combine topic and emotion in generating responses possibly leading to a decline in the quality of responses. This paper proposes a topic-enhanced emotional conversation generation model that incorporates emotional factors and topic information into the conversation system by using two mechanisms. First we use a Twitter latent Dirichlet allocation (LDA) model to obtain topic words of the input sequences as extra prior information ensuring the consistency of content between posts and responses for emotional conversation generation. Second the system uses a dynamic emotional attention mechanism to adaptively acquire content-related and affective information of the input texts and extra topics. The advantage of this study lies in the fact that the presented model can generate abundant emotional responses with the contents being related and diverse. To demonstrate the effectiveness of our method we conduct extensive experiments on large-scale Weibo post-response pairs. Experimental results show that our method achieves good performance even outperforming some existing models. (C) 2018 Elsevier B.V. All rights reserved.;2019
Empowered by artificial intelligence (AI) chatbots are surging as new technologies with both business potential and customer pushback. This study exploits field experiment data on more than 6200 customers who are randomized to receive highly structured outbound sales calls from chatbots or human workers. Results suggest that undisclosed chatbots are as effective as proficient workers and four times more effective than inexperienced workers in engendering customer purchases. However a disclosure of chatbot identity before the machine-customer conversation reduces purchase rates by more than 79.7%. Additional analyses find that these results are robust to nonresponse bias and hang-ups and the chatbot disclosure substantially decreases call length. Exploration of the mechanisms reveals that when customers know the conversational partner is not a human they are curt and purchase less because they perceive the disclosed bot as less knowledgeable and less empathetic. The negative disclosure effect seems to be driven by a subjective human perception against machines despite the objective competence of AI chatbots. Fortunately such negative impact can be mitigated by a late disclosure timing strategy and customer prior AI experience. These findings offer useful implications for chatbot applications customer targeting and advertising in conversational commerce.;2019
End-to-end dialog systems are gaining interest due to the recent advances of deep neural networks and the availability of large human-human dialog corpora. However in spite of being of fundamental importance to systematically improve the performance of this kind of systems automatic evaluation of the generated dialog utterances is still an unsolved problem. Indeed most of the proposed objective metrics shown low correlation with human evaluations. In this paper we evaluate a two-dimensional evaluation metric that is designed to operate at sentence level which considers the syntactic and semantic information carried along the answers generated by an end-to-end dialog system with respect to a set of references. The proposed metric when applied to outputs generated by the systems participating in track 2 of the DSTC-6 challenge shows a higher correlation with human evaluations (up to 12.8% relative improvement at the system level) than the best of the alternative state-of-the-art automatic metrics currently available. (C) 2018 Elsevier Ltd. All rights reserved.;2019
Even without speech recognition errors robots may face difficulties interpreting natural-language instructions. We present a method for robustly handling miscommunication between people and robots in task-oriented spoken dialogue. This capability is implemented in TeamTalk a conversational interface to robots that supports detection and recovery from the situated grounding problems of referential ambiguity and impossible actions. We introduce a representation that detects these problems and a nearest-neighbor learning algorithm that selects recovery strategies for a virtual robot. When the robot encounters a grounding problem it looks back on its interaction history to consider how it resolved similar situations. The learning method is trained initially on crowdsourced data but is then supplemented by interactions from a longitudinal user study in which six participants performed navigation tasks with the robot. We compare results collected using a general model to user-specific models and find that user-specific models perform best on measures of dialogue efficiency while the general model yields the highest agreement with human judges. Our overall contribution is a novel approach to detecting and recovering from miscommunication in dialogue by including situated context namely information from a robot's path planner and surroundings.;2019
For generative conversational agents especially service-oriented systems it is of great importance to improve the informativeness of generated responses and avoid bland results. In this paper we describe our attempt at generating natural and informative responses for customer service oriented dialog systems by incorporating dialog history related information and external knowledge. Two improved sequence-to-sequence frameworks are proposed to generate responses based on extra information in addition to the current user input one encodes the entire dialogue history while the other integrates external knowledge extracted from a search engine. The experimental results on the DSCT6-Track2 and Ubuntu Dialog corpora demonstrate that the proposed systems are promising to generate more informative responses. However case studies suggest that some particular features of the proposed systems and the datasets might restrict the systems to fully exploit such extra information. (C) 2018 Elsevier Ltd. All rights reserved.;2019
For many professional services advice adherence is a necessary condition for achieving service success for both customers and service providers. Despite their pivotal roles in value co-creation typical conversational interactions often lead to low adherence. We propose that enabling a dominance transition from provider dominance in the pre-advice stage to customer dominance in the post-advice stage enhances advice adherence because it increases customers' perceived common ground. Furthermore providers' consultation focus customers' prior knowledge and customers' perceived adherence effort moderate this process. Using mixed methods including both empirical modeling and controlled and field experiments we validate the proposed model in various contexts (healthcare financial services and fitness and wellness counseling). The findings establish several theoretical contributions and offer managerial implications for improving advice adherence by managing dominance transitions in conversational interactions more effectively through training service providers or even programming AI chatbots.;2019
Generative conversational systems consisting of a neural network-based structural model and a linguistic model have always been considered to be an attractive area. However conversational systems tend to generate single-turn responses with a lack of diversity and informativeness. For this reason the conversational system method is further developed by modeling and analyzing the joint structural and linguistic model as presented in the paper. Firstly we establish a novel dual-encoder structural model based on the new Convolutional Neural Network architecture and strengthened attention with intention. It is able to effectively extract the features of variable-length sequences and then mine their deep semantic information. Secondly a linguistic model combining the maximum mutual information with the foolish punishment mechanism is proposed. Thirdly the conversational system for the joint structural and linguistic model is observed and discussed. Then to validate the effectiveness of the proposed method some different models are tested evaluated and compared with respect to Response Coherence Response Diversity Length of Conversation and Human Evaluation. As these comparative results show the proposed method is able to effectively improve the response quality of the generative conversational system.;2019
Goal-oriented dialog systems require a different approach from chit-chat conversational systems in that they should perform various subtasks as well as continue the conversation itself. Since these systems typically interact with an external knowledge base that changes over time it is desirable to incorporate domain knowledge to deal with such changes yet with minimum human effort. This paper presents an extended version of the Hybrid Code Network (HCN) developed for the Facebook AI research (FAIR) dialog dataset used in the Sixth Dialog System Technology Challenge (DSTC6). Compared to the original HCN the system was more adaptable to changes in the knowledge base due to the modules that are extended to be learned from data. Using the proposed learning scheme with fairly elementary domain-specific rules the proposed model achieved 100% accuracy in all test datasets. (C) 2018 Elsevier Ltd. All rights reserved.;2019
Human-human interaction consists of various nonverbal behaviors that are often emotion-related. To establish rapport it is essential that the listener respond to reactive emotion in a way that makes sense given the speaker's emotional state. However human-robot interactions generally fail in this regard because most spoken dialogue systems play only a question-answer role. Aiming for natural conversation we examine an emotion processing module that consists of a user emotion recognition function and a reactive emotion expression function for a spoken dialogue system to improve human-robot interaction. For the emotion recognition function we propose a method that combines valence from prosody and sentiment from text by decision-level fusion which considerably improves the performance. Moreover this method reduces fatal recognition errors thereby improving the user experience. For the reactive emotion expression function the system's emotion is divided into emotion category and emotion level which are predicted using the parameters estimated by the recognition function on the basis of distributions inferred from human-human dialogue data. As a result the emotion processing module can recognize the user's emotion from his/her speech and expresses a reactive emotion that matches. Evaluation with ten participants demonstrated that the system enhanced by this module is effective to conduct natural conversation.;2019
In a Turing test a judge decides whether their conversation partner is either a machine or human. What cues does the judge use to determine this? In particular are presumably unique features of human language actually perceived as humanlike? Participants rated the humanness of a set of sentences that were manipulated for grammatical construction: linear right-branching or hierarchical center-embedded and their plausibility with regard to world knowledge. We found that center-embedded sentences are perceived as less humanlike than right-branching sentences and more plausible sentences are regarded as more humanlike. However the effect of plausibility of the sentence on perceived humanness is smaller for center-embedded sentences than for right-branching sentences. Participants also rated a conversation with either correct or incorrect use of the context by the agent. No effect of context use was found. Also participants rated a full transcript of either a real human or a real chatbot and we found that chatbots were reliably perceived as less humanlike than real humans in line with our expectation. We did however find individual differences between chatbots and humans. (C) 2018 Elsevier B.V. All rights reserved.;2019
In dialogue systems understanding the user utterances is crucial for providing appropriate responses. A traditional dialogue act classification (DA) task is to classify each user reply into ACCEPT REJECT PROPOSE and others. In contrast in this paper we define the DA task on multiple round conversations between humans. The re-defined task is to classify a full dialogue according to the intention of one participant. We term this task as intention classification (IC). We then propose a hybrid neural network-based ensemble model for solving this problem. Two novel ensemble schemes are introduced for combining the classification results or features from various classifiers. One is ensembling features from each individual classifier using stacking and we term this scheme as SEE. The other is adding wrong examples' weight to loss functions of each individual classifier using the AdaBoost scheme and we term this scheme as MN-Ada. We have empirically examined the performance of the proposed ensemble schemes by using three popular deep neural networks as well as one newly modified networks for IC. Extensive experiments have been conducted on a Chinese dialogue corpus. Our model can achieve state-of-the-art accuracy on the experimental dialogue corpus.;2019
In human-to-human conversations the context generally provides several backgrounds and strategic points for the following response. Therefore many response generation approaches have explored the methodologies to incorporate the context into the encoder-decoder architecture to generate context-aware responses that are remarkably relevant and cohesive to the given context. However most approaches pay less attention to semantic interactions implicitly existing within contextual utterances which are of great importance to capture semantic clues of the given dialog context indeed. This paper proposes a dynamic working memory mechanism to model long-term semantic hints in the conversation context by performing semantic interactions between utterances and updating context representation dynamically. Then the outputs of the dynamic working memory are employed to provide helpful clues for the encoder-decoder architecture to generate responses to the given dialog. We have evaluated the proposed approach on Twitter Customer Service Corpus and OpenSubtitles Corpus with several automatic evaluation metrics and the human evaluation and the empirical results show the effectiveness of the proposed method.;2019
In many applications Embodied Conversational Agents (ECAs) must be able to express various affects such as emotions or social attitudes. Non-verbal signals such as smiles or gestures contribute to the expression of attitudes. Social attitudes affect the whole behavior of a person: they are characteristic of an affective style that colors the entire interaction [1] . Moreover recent findings have demonstrated that non-verbal signals are not interpreted in isolation but along with surrounding signals. Non-verbal behavior planning models designed to allow ECAs to express attitudes should thus consider complete sequences of non-verbal signals and not only signals independently of one another. However existing models do not take this into account or in a limited manner. The contribution of this paper is a methodology for the automatic extraction of sequences of non-verbal signals characteristic of a social phenomenon from a multimodal corpus and a non-verbal behavior planning model that takes into account sequences of non-verbal signals rather than signals independently. This methodology is applied to design a virtual recruiter capable of expressing social attitudes which is then evaluated in and out of an interaction context.;2019
In recent years deep reinforcement learning methods have achieved impressive performance in many different fields including playing games robotics and dialogue systems. However there are still a lot of restrictions here one of which is the demand for massive amounts of sampled data. In this paper a hierarchical meta-learning method based on the actor-critic algorithm is proposed for sample efficient learning. This method provides the transferable knowledge that can efficiently train an actor on a new task with a few trials. Specifically a global basic critic meta critic and task specified network are shared within a distribution of tasks and are capable of criticizing any actor trying to solve any specified task. The hierarchical framework is applied to a critic network in the actor-critic algorithm for distilling meta-knowledge above the task level and addressing distinct tasks. The proposed method is evaluated on multiple classic control tasks with reinforcement learning algorithms including the start-of-the-art meta-learning methods. The experimental results statistically demonstrate that the proposed method achieves state-of-the-art performance and attains better results with more depth of meta critic network.;2019
In recent years mental health management of employees in companies has become increasingly important. As the number of psychotherapists is not enough it is necessary for employees to be able to keep their mental wellness on their own. A self-guided mental healthcare course using VR devices has been developed and its stress reduction effect has been validated previously. This study proposes a new version of the course using smartphones and chatbots to enhance its convenience for use and to maintain user motivation for daily and repeated use. The effects of stress reduction and motivation maintenance were acknowledged.;2019
In the era of the Internet of Things (IoT) IoT conversational agents (IoT-CAs) have become the gateways for smart spaces. Users will inevitably self-disclose some types of personal information while interacting with IoT-CAs. In this study users' willingness to disclose different types of information to IoT-CAs in two smart spaces (living space and workspace) and two user contexts (one user or two users) was investigated. One living space and one workspace were built for users to experience interactions with IoT-CAs. Subsequently users' willingness to self-disclose six types of personal information was measured. Two experiments were separately conducted for a single user (N = 36) and two users (N = 48). The results indicated that users were most willing to disclose information about their tastes and interests and least willing to disclose money information. Users in the living space were willing to disclose more information than those in the workspace which was mediated by users' expectations for the reciprocal services of IoT-CAs rather than the awareness of other persons or external factors. Participants had a high private self-awareness in the living space and workspace their attention was focused on themselves rather than on external factors in smart spaces.;2019
In the present study we tested a daily messaging intervention aimed at promoting the reduction of red and processed meat consumption (RPMC). We randomly allocated 180 young adults to three different message conditions. Participants in the informational condition read messages on the consequences of excessive RPMC on one's health and the environment. Participants in the emotional condition read messages eliciting anticipated regret for the consequences of excessive RPMC on ones health and the environment. Participants in the control condition read messages on the health and the environment consequences of sugar consumption. We sent messages through a chatbot every morning for two weeks. RPMC attitude intention and anticipated regret regarding RPMC were measured three times: before the two-week messaging intervention (baseline) immediately after the intervention (post intervention) and two months thereafter (follow up). RPMC was also measured through food diaries completed for two weeks after the intervention. Compared to the control condition participants exposed to emotional messages reduced RPMC at follow up while this was not the case for participants exposed to informational messages. In addition anticipated regret and intention mediated the effects of emotional messages on RPMC. Implications for devising effective messaging interventions to change RPMC are discussed.;2019
In this article we argue that journalism studies and particularly research focused on automated journalism has much to learn from Human-Machine Communication (HMC) an emerging conceptual framework and empirically grounded research domain that has formed in response to the growing number of technologies-such as chatbots sodas bots and other communicative agents enabled by developments in artificial intelligence (AI)-that are designed to function as message sources rather than as message channels. While the underlying but often unquestioned theoretical assumption in most communication research is that humans are communicators and machines are mediators within HMC this assumption is challenged by asking what happens when a machine steps into this formerly human role. More than merely a semantic move this theoretical reorientation opens up new questions about who or what constitutes a communicator how social relationships are established through exchange among humans and machines and what the resulting implications may be for self society and communication. In the particular case of automated journalism-in which software assumes a news-writing role that has long been considered a distinctly central and indeed human element of journalism-the introduction of HMC offers a generative starting point for theory development advancing our understanding of humans machines and news for an oncoming era of AI technologies.;2019
In this paper we propose to combine speech-based and linguistic classification in order to obtain better emotion recognition results for user spoken utterances. Usually these approaches are considered in isolation and even developed by different communities working on emotion recognition and sentiment analysis. We propose modeling the users emotional state by means of the fusion of the outputs generated with both approaches taking into account information that is usually neglected in the individual approaches such as the interaction context and errors and the peculiarities of transcribed spoken utterances. The fusion approach allows to employ different recognizers and can be integrated as an additional module in the architecture of a spoken conversational agent using the information generated as an additional input for the dialog manager to decide the next system response. We have evaluated our proposal using three emotionally-colored databases and obtained very positive results. (C) 2017 Elsevier B.V. All rights reserved.;2019
In this paper we introduce the Task Dependent Recurrent Entity Network (TDREN) to solve Dialogue System Technology Challenges 6 (DSTC 6) track 1. Traditionally there have been methods such as collecting the intent of the user in a conversation directly using rules. We design an end-to-end structure that properly models the restaurant pre-related user preferences that appear in the dialogue and gives appropriate responses. We perform experiments on the TDREN and achieved 97.7% at precision 1. We propose a new artificial neural network structure and recurrent cell for modeling user preference information. Then we show that task-oriented dialogue modeling experiment results using the structure and the recurrent cell. (C) 2018 Elsevier Ltd. All rights reserved.;2019
In this paper we present a methodology for the development of embodied conversational agents for social virtual worlds. The agents provide multimodal communication with their users in which speech interaction is included. Our proposal combines different techniques related to Artificial Intelligence Natural Language Processing Affective Computing and User Modeling. A statistical methodology has been developed to model the system conversational behavior which is learned from an initial corpus and improved with the knowledge acquired from the successive interactions. In addition the selection of the next system response is adapted considering information stored into user's profiles and also the emotional contents detected in the user's utterances. Our proposal has been evaluated with the successful development of an embodied conversational agent which has been placed in the Second Life social virtual world. The avatar includes the different models and interacts with the users who inhabit the virtual world in order to provide academic information. The experimental results show that the agent's conversational behavior adapts successfully to the specific characteristics of users interacting in such environments. (C) 2019 Elsevier B.V. All rights reserved.;2019
In this paper we propose a new natural language generation (NLG) method for spoken dialog systems and demonstrate its capacity. Studies on NLG often employ sequence decoding which generates the words comprising a sentence in sequential order and uses the input generated by each word in the previous step. In contrast we propose a decoding method that employs a sequence generated by traversing a dependency tree with feed input to a pair consisting of a parent and sibling in the dependency tree. As a result the most important words are generated first thereby enabling words with greater relevance to be fed into the process. At prediction time our model generates dependency trees and converts the trees into sentences. The proposed decoding method was evaluated by re-implementing a semantically controlled long short-term memory structure for NLG and the input and predicted sequence were converted to allow dependency tree decoding. The experimental results indicated that our suggested approach i.e. dependency tree decoding dramatically elevates the BLEU-score and naturalness. Furthermore when creating sentences with n-best using dependency tree decoding the word diversity of the output sentences was increased by approximately 6% offering a more diverse sentence pattern.;2019
Incorporating prior knowledge like lexical constraints into the model's output to generate meaningful and coherent sentences has many applications in dialogue system machine translation image captioning etc. However existing auto-regressive models incrementally generate sentences from left to right via beam search which makes it difficult to directly introduce lexical constraints into the generated sentences. In this paper we propose a new algorithmic framework dubbed BFGAN to address this challenge. Specifically we employ a backward generator and a forward generator to generate lexically constrained sentences together and use a discriminator to guide the joint training of two generators by assigning them reward signals. Due to the difficulty of BFGAN training we propose several training techniques to make the training process more stable and efficient. Our extensive experiments on three large-scale datasets with human evaluation demonstrate that BFGAN has significant improvements over previous methods.;2019
Integrating speech recondition technology into an electronic health record (EHR) has been studied in recent years. However the full adoption of the system still faces challenges such as handling speech errors transforming raw data into an understandable format and controlling the transition from one field to the next field with speech commands. To reduce errors cost and documentation time we propose a dialogue system care record (DSCR) based on a smartphone for nursing documentation. We describe the effects of DSCR on (1) documentation speed (2) document accuracy and (3) user satisfaction. We tested the application with 12 participants to examine the usability and feasibility of DSCR. The evaluation shows that DSCR can collect data efficiently by achieving 96% of documentation accuracy. Average documentation speed was increased by 15% (P = 0.012) compared to traditional electronic forms (e-forms). The participants' average satisfaction rating was 4.8 using DSCR compared to 3.6 using e-forms on a scale of 1-5 (P = 0.032).;2019
Intelligent agents built on the basis of the BDI (belief-desire-intention) architecture are known as BDI agents. Currently due to the increasing importance given to the affective capacities they have evolved giving way to the BDI emotional agents. These agents are generally characterized by affective states such as emotions mood or personality but sometimes also by affective capacities such as empathy or emotional regulation. In the paper a review of the most relevant proposals to include emotional aspects in the design of BDI agents is presented. Both BDI formalizations and BDI architecture extensions are covered. From the review common findings and good practices modeling affect empathy and regulatory capacities in BDI agents are extracted. In spite of the great advance in the area several open questions remain and are also discussed in the paper.;2019
Intelligent tutors and conversational agents (CAs) have proven to be useful learning tools. They have potential not only as stand-alone devices but also as integrable components to enrich and complement other educational resources. For this new authoring approaches and platforms are required. They should be accessible to non-programmers (such as most teachers) and they should be integrable into current web-based educational platforms. This paper proposes a new approach to define such agents through a visual domain-specific language based on Google Blockly (a scratch-like language). It also develops a web-based integrable authoring platform to serve as a prototype describing the requirements and architecture. To evaluate whether this novel approach is effective a multi-stage experiment was conducted. First participants learned to use the prototype authoring platform through an interactive tutorial. Second they created a CA with a specific domain model. Times and performance were measured. Finally they answered a standardized usability questionnaire (UMUX) and a purpose-specific survey. Results show that participants were able to learn to use the domain-specific language in a short time. Moreover the purpose-specific survey indicates that their perception of the approach (and its potential) is positive. The standardized questionnaire indicates that even in its prototype stage its usability is satisfactory.;2019
Introduction: Sentiment analysis may be a useful technique to derive a user's emotional state from free text input allowing for more empathic automated feedback in online cognitive behavioral therapy (iCBT) interventions for psychological disorders such as depression. As guided iCBT is considered more effective than unguided iCBT such automated feedback may help close the gap between the two. The accuracy of automated sentiment analysis is domain dependent and ft is unclear how well the technology is applicable to iCBT. This paper presents an empirical study in which automated sentiment analysis by an algorithm for the Dutch language is validated against human judgment. Methods: A total of 493 iCBT user texts were evaluated on overall sentiment and the presence of five specific emotions by an algorithm and by 52 psychology students who evaluated 75 randomly selected texts each providing about eight human evaluations per text. Inter-rater agreement (IRR) between algorithm and humans and humans among each other was analyzed by calculating the intra-class correlation under a numerical interpretation of the data and Cohen's kappa and Krippendorff's alpha under a categorical interpretation. Results: All analyses indicated moderate agreement between the algorithm and average human judgment with respect to evaluating overall sentiment and low agreement for the specific emotions. Somewhat surprisingly the same was the case for the IRR among human judges which means that the algorithm performed about as well as a randomly selected human judge. Thus considering average human judgment as a benchmark for the applicability of automated sentiment analysis the technique can be considered for practical application. Discussion/Conclusion: The low human-human agreement on the presence of emotions may be due to the nature of the texts it may simply be difficult for humans to agree on the presence of the selected emotions or perhaps trained therapists would have reached more consensus. Future research may focus on validating the algorithm against a more solid benchmark on applying the algorithm in an application in which empathic feedback is provided for example by an embodied conversational agent or on improving the algorithm for the iCBT domain with a bottom-up machine learning approach.;2019
Learning is challenging especially in the self-paced online learning environment. Not all the students start online learning with the skills to manage their learning plans balance work-study and find learning resources. Therefore as an online educational institution providing learner support services are essential to improving learning outcomes and student satisfaction. The existing studies have analyzed the impact of learner support services on student satisfaction learning outcomes and course retention. However the relationship between these services and student engagement in the long-term learning process has not been fully examined. To address this issue this paper investigates students' usage of two online learner support (OLS) services and their impact on student engagement. We examined four student groups categorized by their usage of two OLS services and analyzed student engagement with an online course using learning log data and visual analytics techniques. The findings indicate that the use of services and how many times the services are used are highly relevant to the pattern and level of student engagement which suggests that the use of OLS services can be added to the indicators that reflect student learning status.;2019
Loneliness is a growing public health issue that substantially increases the risk of morbidity and mortality. Artificial agents such as robots embodied conversational agents and chatbots present an innovation in care delivery and have been shown to reduce patient loneliness by providing social support. However similar to doctor and patient relationships the quality of a patient's relationship with an artificial agent can impact support effectiveness as well as care engagement. Incorporating mammalian attachment-building behavior in neural network processing as part of an agent's capabilities may improve relationship quality and engagement between patients and artificial agents. We encourage developers of artificial agents intended to relieve patient loneliness to incorporate design insights from evolutionary neuropsychiatry.;2019
Matching an appropriate response with its multi-turn context is a crucial challenge in retrieval-based chatbots. Current studies construct multiple representations of context and response to facilitate response selection but they use these representations in isolation and ignore the relationships among representations. To address these problems we propose a hierarchical aggregation network of multi-representation (HAMR) to leverage abundant representations sufficiently and enhance valuable information. First we employ bidirectional recurrent neural networks (BiRNN) to extract syntactic and semantic representations of sentences and use a self-aggregation mechanism to combine these representations. Second we design a matching aggregation mechanism for fusing different matching information between each utterance in context and response which is generated by an attention mechanism. By considering the candidate response as the real part of the context we try to integrate all of them in chronological order and then accumulate the vectors to calculate the final matching degree. An extensive empirical study on two multi-turn response selection data sets indicates that our proposed model achieves a new state-of-the-art result.;2019
Measuring the cognitive cost of interpreting the meaning of sentences in a conversation is a complex task but it is also at the core of Sperber and Wilson's Relevance Theory. In cognitive sciences the delay between a stimulus and its response is often used as an approximation of the cognitive cost. We have noticed that such a tool had not yet been used to measure the cognitive cost of interpreting the meaning of sentences in a free-flowing and interactive conversation. The following experiment tests the ability to discriminate between sentences with a high cognitive cost and sentences with a low cognitive cost using the response time of the participants during an online conversation in a protocol inspired by the Turing Test. We have used violations of Grice's Cooperative Principle to create conditions in which sentences with a high cognitive cost would be produced. We hypothesized that response times are directly correlated to the cognitive cost required to generate implicatures from a statement. Our results are coherent with the literature in the field and shed some new light on the effect of violations on the humanness of a conversational agent. We show that violations of the maxim of Relation had a particularly important impact on response times and the perceived humanness of a conversation partner. Violations of the first maxim of Quantity and the fourth maxim of Manner had a lesser impact and only on male participants.;2019
Multi-role dialogue is challenging in natural language processing (NLP) which needs not only to understand sentences but also to simulate interaction among roles. However the existing methods assume that only two speakers are present in a conversation. In real life this assumption is not always valid. More often there are multiple speakers involved. To address this issue we propose a multi-role interposition dialogue system (MIDS) that generates reasonable responses based on the dialogue context and next speaker prediction. The MIDS employs multiply role-defined encoders to understand each speaker and an independent sequence model to predict the next speaker. The independent sequence model also works as a controller to integrate encoders with weights. Then an attention-enhanced decoder generates responses based on the dialogue context speaker prediction and integrated encoders. Moreover with the help of unique speaker prediction the MIDS is able to generate diverse responses and allow itself to join (interpose) the conversation when appropriate. Furthermore a novel reward function and an updating policy of reinforcement learning (RL) are applied to the MIDS which further enable MIDS the ability to write drama scripts. The experimental results demonstrate that the MIDS offers a significant improvement to the accuracy of speaker prediction and the reduction of response generation perplexity. It is also able to interact with users without cues during real-life online conversations and avoid meaningless conversation loops while generating scripts. This paper marks the first step toward multi-role humorous dialogue generation.;2019
Multi-turn response selection is essential to retrieval-based chatbots. The task requires multi-turn response selection model to match a response candidate with a conversation context. Existing methods may lose relationship features in the context. In this article we propose an improved method that extends the learning granularity of the multi-turn response selection model to enhance the model's ability to learn relationship features of utterances in the context which is a key to understand a conversation context for multi-turn response selection in retrieval-based chatbots. The experimental results show that our proposed method significantly improves sequential matching network for multi-turn response selection in retrieval-based chatbots.;2019
Neural end-to-end goal-oriented dialog systems showed promise to reduce the workload of human agents for customer service as well as reduce wait time for users. However their inability to handle new user behavior at deployment has limited their usage in real world. In this work we propose an end-toend trainable method for neural goal-oriented dialog systems that handles new user behaviors at deployment by transferring the dialog to a human agent intelligently. The proposed method has three goals: 1) maximize user's task success by transferring to human agents 2) minimize the load on the human agents by transferring to them only when it is essential and 3) learn online from the human agent's responses to reduce human agents' load further. We evaluate our proposed method on a modified-bAbI dialog task1 which simulates the scenario of new user behaviors occurring at test time. Experimental results show that our proposed method is effective in achieving the desired goals.;2019
New decision-support systems are being built using AI services that draw insights from a large corpus of data and incorporate those insights in human-in-the-loop decision environments. They promise to transform businesses such as health care with better affordable and timely decisions. However it will be unreasonable to expect people to trust AI systems out of the box if they have been shown to exhibit discrimination across a variety of data usages: unstructured text structured data or images. Thus AI systems come with certain risks such as failing to recognize people or objects introducing errors in their output and leading to unintended harm. In response we propose ratings as a way to communicate bias risk and methods to rate AI services for bias in a black-box fashion without accessing services training data. Our method is designed not only to work on single services but also the composition of services which is how complex AI applications are built. Thus the proposed method can be used to rate a composite application like a chatbot for the severity of its bias by rating its constituent services and then composing the rating rather than rating the whole system.;2019
News media organisations are experimenting with a new generation of newsbots that move beyond automated headline delivery to the delivery of news according to a conversational format within the context of private messaging services. To build the newsbot journalists craft statements and answers to users' questions that mimic a natural conversation between a journalist and user. In so doing journalists are experimenting with styles of communication that reflect very particular journalistic personas. We investigate the persona of the news chatbot created by the Australian Broadcasting Corporation (ABC) the better to understand how the public broadcaster's forays into social media service delivery and automation are shaping new relationships between public service broadcasters and their audiences. We find that for a section of the audience that uses it the friendly newsbot contrasts favourably with their previous experience with news and the journalists who produce it. The public service journalists who operate the bot are in turn using the bot to try to reach new audiences by experimenting with a more informal intimate relationship with citizen users. The supposedly intelligent (but in actual fact very much human-crafted) newsbot is the vehicle through which this new relationship is being forged.;2019
Nowadays most end-to-end task-oriented dialog systems are based on sequence-to-sequence (Seq2seq) which is an encoder-decoder framework. These systems sometimes produce grammatically correct but logically incorrect responses. This phenomenon is usually due to information mismatching. To solve this problem we introduce hierarchical attention and knowledge matching networks with information enhancement (HAMI) for task-oriented dialog systems. It contains a hierarchical attention dialog encoder (HADE) that models dialogs at the word and sentence level separately. HADE can focus on important words in a dialog history and generate context-aware representations. HAMI also contains a unique knowledge matching module to detect entities and interact with a knowledge base (KB). Then dialog history and KB result representations serve as guidance for system response generation. Finally HAMI's loss function is designed with an information regularization term to emphasize the importance of entities. The experimental results show that HAMI improves 9.8% in entity F1 compared with vanilla Seq2seq. HAMI also outperforms state-of-the-art models in both the entity F1 and dialog accuracy metrics.;2019
Objective Poor lifestyle represents a health risk factor and is the leading cause of morbidity and chronic conditions. The impact of poor lifestyle can be significantly altered by individual's behavioral modification. Although there are abundant lifestyle promotion applications and tools they are still limited in providing tailored social support that goes beyond their predefined functionalities. In addition virtual coaching approaches are still unable to handle user emotional needs. Our approach presents a human-virtual agent mediated system that leverages the conversational agent to handle menial caregiver's works by engaging users (e.g. patients) in a conversation with the conversational agent. The dialog used a natural conversation to interact with users delivered by the conversational agent and handled with a finite state machine automaton. Our research differs from existing approaches that replace a human coach with a fully automated assistant on user support. The methodology allows users to interact with the technology and access health-related interventions. To assist physicians the conversational agent gives weighting to user's adherence based on prior defined conditions. Materials and Methods This article describes the design and validation of CoachAI a conversational agent-assisted health coaching system to support health intervention delivery to individuals or groups. CoachAI instantiates a text-based health care conversational agent system that bridges the remote human coach and the users. Results We will discuss our approach and highlight the outcome of a 1-month validation study on physical activity healthy diet and stress coping. The study validates technology aspects of our human-virtual agent mediated health coaching system. We present the intervention settings and findings from the study. In addition we present some user-experience validation results gathered during or after the experimentation. Conclusions The study provided a set of dimensions when building a human-conversational agent powered health intervention tool. The results provided interesting insights when using human-conversational agent mediated approach in health coaching systems. The findings revealed that users who were highly engaged were also more adherent to conversational-agent activities. This research made key contributions to the literature on techniques in providing social yet tailored health coaching support: (1) identifying habitual patterns to understand user preferences (2) the role of a conversational agent in delivering health promoting microactivities (3) building the technology while adhering to individuals' daily messaging routine and (4) a socio-technical system that fits with the role of conversational agent as an assistive component. Future Work Future improvements will consider building the activity recommender based on users' interaction data and integrating users' dietary pattern and emotional wellbeing into the initial user clustering by leveraging information and communication technology approaches (e.g. machine learning). We will integrate a sentiment analysis capability to gather further data about individuals and report these data to the caregiver.;2019
Objective The objective of this study was to assess whether a version of the Smoke Free app with a supportive chatbot powered by artificial intelligence (versus a version without the chatbot) led to increased engagement and short-term quit success. Methods Daily or non-daily smokers aged >= 18 years who purchased the 'pro' version of the app and set a quit date were randomly assigned (unequal allocation) to receive the app with or without the chatbot. The outcomes were engagement (i.e. total number of logins over the study period) and self-reported abstinence at a one-month follow-up. Unadjusted and adjusted negative binomial and logistic regression models were fitted to estimate incidence rate ratios (IRRs) and odds ratios (ORs) for the associations of interest. Results A total of 57214 smokers were included (intervention: 9.3% (5339) control: 90.7% (51875). The app with the chatbot compared with the standard version led to a 101% increase in engagement (IRRadj = 2.01 95% confidence interval (CI) = 1.92-2.11 p < .001). The one-month follow-up rate was 10.6% (intervention: 19.9% (1061/5339) control: 9.7% (5050/51875). Smokers allocated to the intervention had greater odds of quit success (missing equals smoking: 844/5339 vs. 3704/51875 ORadj = 2.38 95% CI = 2.19-2.58 p < .001 follow-up only: 844/1061 vs. 3704/5050 ORadj = 1.36 95% CI = 1.16-1.61 p < .001). Conclusion The addition of a supportive chatbot to a popular smoking cessation app more than doubled user engagement. In view of very low follow-up rates there is low quality evidence that the addition also increased self-reported smoking cessation.;2019
Objective: The AAP AFP and ACP have authored statements and recommendations to clinicians about the importance of the transition from pediatric to adult care. The Got Transition program provides a framework and resources based on AAP AFP and ACP recommendations to promote skill attainment in self-care. Engaging adolescents along the transition journey has proven challenging. Use of smartphones text messaging and social media are prevalent among teenagers offering a unique opportunity to engage teenagers in their preferred channel to provide tools and resources to help them successfully transition to adult focused care. Methods: A multidisciplinary team of clinicians quality improvement facilitators and human-centered designers at the University of Vermont (UVM) Children's Hospital designed tools for teens with chronic conditions that support the Got Transition recommendations. Using a co-creative design process we created a novel tool to increase engagement among teenagers. We conducted a pilot study of 13 teenagers with a chronic medical condition using a text messaging platform (chatbot) with scripted interactions to increase engagement and deliver educational content according to Got Transition. Results: Mean engagement was 97% during the study period. Qualitative feedback from study participants suggests our chatbot should be extended and shows promise to help teenagers attain self-care skills on the transition journey. Conclusions: A scripted text messaging platform is feasible and appears to be well-received by patients and caregivers. Furthermore our approach emphasizes the need to engage teenagers through multiple platforms to effectively serve as coaches during the transition to adult care. (c) 2019 Elsevier Inc. All rights reserved.;2019
Objective: The aim of this review was to explore the current evidence for conversational agents or chatbots in the field of psychiatry and their role in screening diagnosis and treatment of mental illnesses. Methods: A systematic literature search in June 2018 was conducted in PubMed EmBase PsycINFO Cochrane Web of Science and IEEE Xplore. Studies were included that involved a chatbot in a mental health setting focusing on populations with or at high risk of developing depression anxiety schizophrenia bipolar and substance abuse disorders. Results: From the selected databases 1466 records were retrieved and 8 studies met the inclusion criteria. Two additional studies were included from reference list screening for a total of 10 included studies. Overall potential for conversational agents in psychiatric use was reported to be high across all studies. In particular conversational agents showed potential for benefit in psychoeducation and self-adherence. In addition satisfaction rating of chatbots was high across all studies suggesting that they would be an effective and enjoyable tool in psychiatric treatment. Conclusion: Preliminary evidence for psychiatric use of chatbots is favourable. However given the heterogeneity of the reviewed studies further research with standardized outcomes reporting is required to more thoroughly examine the effectiveness of conversational agents. Regardless early evidence shows that with the proper approach and research the mental health field could use conversational agents in psychiatric treatment.;2019
Observed influences of system response delay in spoken human-machine dialogues are rather ambiguous and mainly focus on perceived system quality. Studies that systematically inspect effects on cognitive performance are still lacking and effects of individual characteristics are also often neglected. Building on benefits of cognitive training for decelerating cognitive decline this Wizard-of-Oz study addresses both issues by testing 62 elderly participants in a dialogue-based memory training with a virtual agent. Participants acquired the method of loci with fading instructional guidance and applied it afterward to memorizing and recalling lists of German nouns. System response delays were randomly assigned and training performance was included as potential mediator. Participants' age gender and subscales of affinity for technology (enthusiasm competence positive and negative perception of technology) were inspected as potential moderators. The results indicated positive effects on recall performance with higher training performance female gender and less negative perception of technology. Additionally memory retention and facets of affinity for technology moderated increasing system response delays. Participants also provided higher ratings in perceived system quality with higher enthusiasm for technology but reported increasing frustration with a more positive perception of technology. Potential explanations and implications for the design of spoken dialogue systems are discussed.;2019
Online learning environments could be well understood as a multifaceted phenomenon affected by different aspects of learner participation including synchronous/asynchronous interactions. The aim of this study was to investigate learners' participation in online courses synchronous interaction with a conversational virtual agent their relationships with learner performance and the participation/interaction factor identification. To examine learner participation we collected learning management system (LMS) log data that included the frequency and length of course access discussion board postings and final grades. To examine synchronous learner interaction we collected learners' conversation logs from the conversational agent. We calculated the quantity and quality of discussion postings and conversations with the agent. The results showed that the frequency and length of course access the quantity and quality of discussion postings and the quality of conversation with the agent were significantly associated with the learner achievement. This study also identified two factors that comprise online learning participation and interaction: interaction quality and LMS-oriented interaction.;2019
Over the next decade one issue which will dominate sociotechnical studies in health informatics is the extent to which the promise of artificial intelligence in health care will be realized along with the social and ethical issues which accompany it. A useful thought experiment is the application of the Turing test to user-facing artificial intelligence systems in health care. In this paper I argue that many medical decisions require value judgements and the doctor-patient relationship requires empathy and understanding to arrive at a shared decision often handling large areas of uncertainty and balancing competing risks. Arguably medicine requires wisdom more than intelligence artificial or otherwise. Artificial intelligence therefore needs to supplement rather than replace medical professionals and identifying the complementary positioning of artificial intelligence in medical consultation is a key challenge for the future. In health care artificial intelligence needs to pass the implementation game not the imitation game.;2019
Paying attention to the rising popularity of virtual assistants (VAs) that offer unique user experiences through voice-centered interaction this study examined the effects of modality device and task differences on perceived human likeness of and attitudes toward voice-activated VAs. To do so a 2 (modality: voice vs. text) x 2 (device: mobile vs. laptop) x 2 (task type: hedonic vs. utilitarian) mixed factorial experimental design was employed. Findings suggest that voice (vs. text) interaction leads to more positive attitudes toward the VA system mediated by heightened perceived human likeness of the VA but only with utilitarian (vs. hedonic) tasks. Interestingly laptop (vs. mobile phone) interaction also enhanced perceived human likeness of the VA. This study offers theoretical and practical implications for VA research by exploring the combinational effects of modality device and task differences on user perceptions through human-like interactions.;2019
Prior research has shown that the more patients know about their disease health and lifestyle the better the health outcomes are. Patients who are suffering from either a physical disease with mental consequences or from mental illnesses can contribute to their own feeling of mental well-being by following evidence-based online self-guided therapeutic interventions. These self-guided therapeutic interventions during which there is no contact with a care provider have shown high effectiveness. However users (patients) of self-guided eHealth interventions have difficulties fulfilling the entire trajectory as is mirrored in high non-adherence rates. Users have reported a need for support that is traditionally provided by human care providers. This study investigates the opportunities from within the technology to increase its support level toward the user. We deployed a pedagogical agent acting as an adjunct to a self-guided positive psychology psycho-education intervention. This agent provided instructions and user support in between and explicitly not during the online learning modules as to mitigate the risk of distraction. By setting up a between-subjects design and deploying three versions of a pedagogical agent (also known as Embodied Conversational Agent) varying the features of animation speech and visibility we investigated whether users felt more supported than by a fourth text-only control condition. All four conditions provided similar task-related support and emotion-related support to the user. Our results showed that our pedagogical agent made users feel guided and supported with respect to fulfilling their tasks. However no effects were found of emotion-related support resulting in higher user motivation and an improved learning experience. Significant effects of visibility and voice were found but animation of our pedagogical agent had no effect. On the feedback outcome variable we found a gender effect. Male participants graded the visible Embodied Conversational Agent (ECA) higher than female participants and graded the non-visible ECA lower than female participants. In our view ECA's should not necessarily be deployed with the ambition to compete with the profound human potential to deliver support and guidance. Exploring ECA capabilities merits further attention from the stance that the technology itself can support users and potentially make them adhere.;2019
Purpose Performing tasks in public spaces can be demanding due to task complexity. Systems that can keep track of the current task state may help their users to successfully fulfill a task. These systems however require major implementation effort. The purpose of this paper is to investigate if and how a mobile information assistant which has only basic task-tracking capabilities can support users by employing a least effort approach. This means we are interested in whether such a system is able to have an impact on the way a workflow in public space is perceived. Design/methodology/approach The authors implement and test AIRBOT a mobile chatbot application that can assist air passengers in successfully boarding a plane. The authors apply a three-tier approach and first conduct expert and passenger interviews to understand the workflow and the information needs occurring therein second the authors implement a mobile chatbot application providing minimum task-tracking capabilities to support travelers by providing boarding-relevant information in a proactive manner. Finally the authors evaluate this application by means of an in situ study (n = 101 passengers) at a major European airport. Findings The authors provide evidence that basic task-tracking capabilities are sufficient to affect the users' task perception. AIRBOT is able to decrease the perceived workload airport services impose on users. It has a negative impact on satisfaction with non-personalized information offered by the airport though. Originality/value The study shows that the number of features is not the most important means to successfully provide assistance in public space workflows. The study can moreover serve as a blueprint to design task-based assistants for other contexts.;2019
Purpose Smart technologies and connected objects are rapidly changing the organizational frontline. Yet our understanding of how these technologies infuse service encounters remains limited. Therefore the purpose of this paper is to update existing classifications of Frontline Service Technology (FST) infusion. Moreover the authors discuss three promising smart and connected technologies - conversational agents extended reality (XR) and blockchain technology - and their respective implications for customers frontline employees and service organizations. Design/methodology/approach This paper uses a conceptual approach integrating existing work on FST infusion with artificial intelligence robotics XR and blockchain literature while also building on insights gathered through expert interviews and focus group conversations with members of two service research centers. Findings The authors define FST and propose a set of FST infusion archetypes at the organizational frontline. Additionally the authors develop future research directions focused on understanding how conversational agents XR and blockchain technology will impact service. Originality/value This paper updates and extends existing classifications of FST while paving the road for further work on FST infusion.;2019
Purpose The purpose of this paper is to understand motivation of young consumers to use artificial intelligence (AI) tools such as chatbots voice assistants and augmented reality in shopping by generating Vroom's expectancy theory of motivation using grounded theory approach. Design/methodology/approach Grounded theory approach has been used to develop the Vroom's expectancy theory. Initially data were collected through participant interviews using theoretical sampling. These data were analyzed and coded using the three step process i.e. open coding axial coding and selective coding. The categories created during coding were integrated to generate Vroom's expectancy theory of motivation. Findings The findings indicate that Vroom's expectancy theory of motivation can be used to explain motivation of young consumers to use AI tools as an aid in taking shopping decisions. The motivation may be intrinsic motivation extrinsic motivation or force choice motivation. Expectancy represents the ease of using the tools instrumentality represents competence of tools in performing desired tasks while valence represents satisfaction rewarding experience and trust in using of tools. Research limitations/implications The findings of the study are based on grounded theory approach which is an inductive approach. Alternate research methodologies both inductive and deductive need to be employed to strengthen the external validity and generalize the results. The study is limited to shopping motives of young consumers in India. A comparison with other consumer motivational studies has not been done. Hence no claim is made regarding the advantage of Vroom's theory over other motivational theories. Practical implications The study has strong implications for retailers in developing countries which are seen as an emerging market for retail and have introduced AI tools in recent years. The Vroom's expectancy theory will help retailers to understand consumer motivation in using AI tools or shopping. Originality/value Vroom's expectancy theory to understand consumer motivation to use AI tools in shopping was generated using the grounded theory approach.;2019
Purpose: To evaluate the effects of iDecide on prostate cancer knowledge informed decision-making self-efficacy technology use self-efficacy and intention to engage in informed decision-making among African American men. Design: One-group pretest/posttest. Setting: Community settings in South Carolina. Participants: African American men ages 40 years + without a prior prostate cancer diagnosis (n = 354). Intervention: iDecide an embodied conversational agent-led computer-based prostate cancer screening decision aid. Measures: Prostate cancer knowledge informed decision-making self-efficacy technology use self-efficacy and intention to engage in informed decision-making. Analysis: Descriptive statistics paired t tests general linear modeling Spearman correlations. Results: On average participants experienced significant improvements in their prostate cancer knowledge (P <= .001) informed decision-making self-efficacy (P <= .001) and technology use self-efficacy (P <= .001) postintervention. Additionally 67% of participants reported an intention to engage in informed decision-making. Conclusion: Given the significant improvements across all measures this research demonstrates that embodied conversational agent-led decision aids can be used to enhance the capacity for making informed prostate cancer screening decisions among African American men and increase their technology use self-efficacy. One critical limitation of this study is that most men had received prostate cancer screening prior to engaging in our intervention so the implications of this intervention may be different for men who do not have a history of screening. Additionally actual engagement in informed decision-making postintervention was not assessed.;2019
Recent CALL technology reviews cover a plethora of technologies available to language learners to improve a variety of skills including speaking. However few technology-enhanced self-access tools are available for pragmatic development especially in oral modality. Recognizing the benefits of structured practice for second language development we demonstrate how such practice can be incorporated into three recently developed simulated speaking environments that vary on the targeted L2 (French English) domain of use (academic or everyday interaction) emphasis on higher-order and/or lower-order skills and accommodation of multiple L2 varieties. In the spirit of finding synergies and learning from each other's experiences in specific local contexts we address the following research questions: (1) How does the local context researcher and learner goals and technological possibilities influence the design of each computer application? (2) Based on the examination of the three programs what can we learn in view of redesign options and suggest to future developers of such programs?;2019
Recently real-time affect-awareness has been applied in several commercial systems such as dialogue systems and computer games. Real-time recognition of affective states however requires the application of costly feature extraction methods and/or labor-intensive annotation of large datasets especially in the case of Asian languages where large annotated datasets are seldom available. To improve recognition accuracy we propose the use of cognitive context in the form of emotion-sensitive intentions. Intentions are often represented through dialogue acts and as an emotion-sensitive model of dialogue acts a tagset of interpersonal-relations-directing interpersonal acts (the IA model) is proposed. The model's adequacy is assessed using a sentiment classification task in comparison with two well-known dialogue act models the SWBD-DAMSL and the DIT++. For the assessment five Japanese in-game dialogues were annotated with labels of sentiments and the tags of all three dialogue act models which were used to enhance a baseline sentiment classifier system. The adequacy of the IA tagset is demonstrated by a 9% improvement to the baseline sentiment classifier's recognition accuracy outperforming the other two models by more than 5%.;2019
Recently the rapid development of mobile multimedia intelligent voice systems has affected the rapid changes in user interaction. Meanwhile the continuous optimization of recommended algorithms makes the change of interaction mode from the original user's active search to the machine actively recommending continuously. It is an inevitable trend that multimedia intelligent voice dialogue system brings more efficient content services to users through active recommendation. However the existing multimedia intelligent voice dialogue systems are mainly based on the user's expression content to analyze the user's subject willingness and then provide the reply contents to user. This kind of interaction only drives the topic through the user which will cause some problems like single chat topic and missing points of interest. In order to address these problems this paper proposes an interactive topic guiding model. This model uses the surrounding similar users and user context information to guide users' topics and taking into account the harmony of human-computer interaction the game method is adopted to select the optimal content response strategy by considering the user's and robot's emotional friendliness and content friendliness. The experiments show that the model proposed in this paper can effectively guide topics. Moreover it has significant improvement in content richness compared with other models in human-machine natural interaction which can provide some research ideas for guiding the topic in the mobile multimedia intelligent voice system.;2019
Recurrent Neural Network (RNN) based approaches have recently shown promising in tackling Natural Language Generation (NLG) problems. This paper presents an approach to leverage gating mechanisms in which we incrementally propose three additional semantic cells into a traditional RNN model: a Refinement cell to filter the sequential inputs before RNN computations an Adjustment cell and an Output cell to select semantic elements and gate a feature vector during generation. The proposed gating-based generators can learn from unaligned data by jointly training both sentence planning and surface realization to generate natural language utterances. We conducted extensive experiments on four different NLG domains in which the results empirically show that the proposed methods not only achieved better performance on all the NLG domains in comparison with previous gating-based attention-based methods but also obtained highly competitive results compared to a hybrid generator. (C) 2018 Elsevier B.V. All rights reserved.;2019
Research regarding source orientation has demonstrated that when interacting with computers people direct their communication toward and react toward the technology itself. Users perceive technology to be a source in human-machine communication (HMC). This study provides a new dimension to those findings with regard to source orientation with voice-based mobile virtual assistants enabled by artificial intelligence (AI). In qualitative interviews regarding their conceptualizations of mobile conversational agents (Apple's Siri Google Voice Samsung S-Voice) and their perceptions of interactions with these specific technologies some participants describe the agent they can hear but not see as a voice in the mobile phone (assistant as distinct entity) while others perceive the technology that they command to be the voice of the phone (assistant as the device). Therefore congruent with existing research users of mobile assistants orient toward a technology instead of thinking they are interacting with a human but in contrast to existing research attend to different technologies. When technologies possess a disembodied voice and are designed with various social cues and degrees of intelligence the locus and nature of the digital interlocutor is not uniform in people's minds.;2019
Self-help and automated technologies can be useful for behavioral and mental health education and interventions. These technologies include interactive media online courses artificial intelligence powered chatbots voice assistants and video games. Self-help media can include books videos audible media like podcasts blog and print articles and self-contained Internet sites. Social media online courses and mass-market mobile apps also can include such media. These technologies serve to decrease geospatial temporal and financial barriers. This article describes different self-help and automated technologies how to implement such technologies in existing clinical services and how to implement according to patient needs.;2019
Software is usually studied in terms of the changes triggered by its operations in the material world. Yet to understand its social and cultural impact one needs to examine also the different narratives that circulate about it. Software's opacity in fact makes it prone to being translated into a plurality of narratives that help people make sense of its functioning and presence. Drawing from the case of Joseph Weizenbaum's ELIZA widely considered the first chatbot ever created this article proposes a theoretical framework based on the concept of 'biographies of media' to illuminate the dynamics and implications of software's discursive life. The case of ELIZA is particularly relevant in this regard because it became the centre of competing narratives whose trajectories transcended the actual functioning of this programme and shaped key controversies about the implications of computing and artificial intelligence.;2019
Speech synthesis also known as text-to-speech (TTS) has attracted increasingly more attention. Recent advances on speech synthesis are overwhelmingly contributed by deep learning or even end-to-end techniques which have been utilized to enhance a wide range of application scenarios such as intelligent speech interaction chatbot or conversational artificial intelligence (AI). For speech synthesis deep learning based techniques can leverage a large scale of <text speech> pairs to learn effective feature representations to bridge the gap between text and speech thus better characterizing the properties of events. To better understand the research dynamics in the speech synthesis field this paper firstly introduces the traditional speech synthesis methods and highlights the importance of the acoustic modeling from the composition of the statistical parametric speech synthesis (SPSS) system. It then gives an overview of the advances on deep learning based speech synthesis including the end-to-end approaches which have achieved start-of-the-art performance in recent years. Finally it discusses the problems of the deep learning methods for speech synthesis and also points out some appealing research directions that can bring the speech synthesis research into a new frontier.;2019
Speech technologies have been developed for decades as a typical signal processing area while the last decade has brought a huge progress based on new machine learning paradigms. Owing not only to their intrinsic complexity but also to their relation with cognitive sciences speech technologies are now viewed as a prime example of interdisciplinary knowledge area. This review article on speech signal analysis and processing corresponding machine learning algorithms and applied computational intelligence aims to give an insight into several fields covering speech production and auditory perception cognitive aspects of speech communication and language understanding both speech recognition and text-to-speech synthesis in more details and consequently the main directions in development of spoken dialogue systems. Additionally the article discusses the concepts and recent advances in speech signal compression coding and transmission including cognitive speech coding. To conclude the main intention of this article is to highlight recent achievements and challenges based on new machine learning paradigms that over the last decade had an immense impact in the field of speech signal processing.;2019
Spoken language understanding (SLU) plays an integral part in every dialogue system. To understand the intention of the user and extract the necessary information to help the user achieve desired goals is a challenging task. In this work we propose an end-to-end hierarchical multi-task model that can jointly perform both intent detection and slot filling tasks for the datasets of varying domains. The primary aim is to capture context information in a dialogue to help the SLU module in a dialogue system to correctly understand the user and assist the user in achieving the desired goals. It is vital for the SLU module to capture the past information along with the present utterance said by the user to retrieve correct information. The dependency and correlation between the two tasks i.e. intent detection and slot filling makes the multi-task learning framework effective in capturing the desired information provided by the user. We use Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) to capture contextual information for the utterances. We employ Conditional Random Field (CRF) to model label dependency. Both character and word level embeddings are provided as input to the models. We create a benchmark corpus for the SLU tasks on TRAINS and FRAMES dataset for capturing more realistic and natural utterances spoken by the speakers in a human/machine dialogue system. Experimental results on multiple datasets of various domains (ATIS SNIP TRAINS and FRAMES) show that our proposed approach is effective compared to the individual models and the state-of-the-art methods. (C) 2019 Elsevier B.V. All rights reserved.;2019
Teams need to co-construct meaning to establish shared understanding of crowdsourced ideas. This is challenging because team members are often faced with an excessive amount of ideas they have no access to the ideator to clarify ideas have limited meeting duration and do not necessarily share a common working history. Facilitation interventions can aid the co-construction of meaning. However it is uncertain if facilitation interventions that were successful in traditional convergence settings can be applied to convergence with crowdsourced ideas and what mechanisms can explain the positive association between facilitation interventions and co-creation of meaning. In this study I tested three facilitation techniques and the mediating role of evaluation and coordination in a laboratory experiment involving 199 participants. The participants were given an IT-supported convergence task with crowdsourced ideas. The findings show that facilitated teams receiving high attention guidance and discussion encouragement outperform non-facilitated teams and that evaluation and coordination are the mechanisms through which these effects come about. The findings are beneficial for the design of conversational agents in convergence settings and for team leaders who want to establish shared understanding in convergence settings with crowdsourced ideas.;2019
The authors propose methods to learn symbolic processing with deep learning and to build question answering systems by means of learned models. Symbolic processing performed by the Prolog processing systems which execute unification resolution and list operations is learned by a combination of deep learning models Neural Machine Translation (NMT) and Word2Vec training. To our knowledge the implementation of a Prolog-like processing system using deep learning is a new experiment that has not been conducted in the past. The results of their experiments revealed that the proposed methods are superior to the conventional methods because symbolic processing (1) has rich representations (2) can interpret inputs even if they include unknown symbols and (3) can be learned with a small amount of training data. In particular (2) handling of unknown data which is a major task in artificial intelligence research is solved using Word2Vec. Furthermore question answering systems can be built from knowledge bases written in Prolog with learned symbolic processing which with conventional methods is extremely difficult to accomplish. Their proposed systems can not only answer questions through powerful inferences by utilizing facts that harbor unknown data but also have the potential to build knowledge bases from a large amount of data including unknown data on the Web. The proposed systems are a completely new trial there is no state-of-the-art methods in the sense of newest. Therefore to evaluate their efficiency they are compared with the most traditional and robust system i.e. the Prolog system. This is new research that encompasses the subjects of conventional artificial intelligence and neural network and their systems have higher potential to build applications such as FAQ chatbots decision support systems and energy-efficient estimation using a large amount of information on the Web. Mining hidden information through these applications will provide great value.;2019
The breakthrough of nonprecious metal catalysts replacing platinum-based catalysts toward the oxygen reduction reaction (ORR) is extremely urgent for the development of high-efficiency energy conversation systems. Herein a solution-processed condensation polymerization using cyanuric chloride and piperazine as the monomers was proposed for the synthesis of a nitrogen-rich covalent organic polymer (COP). High contents of precisely tailored pyridinicN within the COP facilitate the formation of the Co/N coordination between Co ions and N species. As a result the subsequent carbonization of the Co-coordinated COP led to the formation of the cobalt nitrogen dual-doped porous carbon nanosheet-assembled flowers (Co/N-PCNF). The as obtained Co/N-PCNF catalyst with a nearly 4-electron oxygen reduction pathway exhibits an excellent ORR catalytic activity with a half-wave potential of 0.835 V comparable to the commercial Pt/C catalysts (0.865 V). Most impressively the Co/N-PCNF catalyst displays a long-term stability and a much better resistance to methanol than the Pt/C catalyst because of its high surface area well-defined porous structure and homogeneous distributions of active sites within the carbon matrix. Therefore this work establishes an operating rule for tailored synthesis of COP-derived nonprecious metal catalysts offering high activity for the ORR in electrochemical energy conversations.;2019
The data science technologies of artificial intelligence (AI) Internet of Things (IoT) big data and behavioral/predictive analytics and blockchain are poised to revolutionize government and create a new generation of GovTech start-ups. The impact from the smartification' of public services and the national infrastructure will be much more significant in comparison to any other sector given government's function and importance to every institution and individual. Potential GovTech systems include Chatbots and intelligent assistants for public engagement Robo-advisors to support civil servants real-time management of the national infrastructure using IoT and blockchain automated compliance/regulation public records securely stored in blockchain distributed ledgers online judicial and dispute resolution systems and laws/statutes encoded as blockchain smart contracts. Government is potentially the major client' and also public champion' for these new data technologies. This review paper uses our simple taxonomy of government services to provide an overview of data science automation being deployed by governments world-wide. The goal of this review paper is to encourage the Computer Science community to engage with government to develop these new systems to transform public services and support the work of civil servants.;2019
The dialog state tracker is one of the most important modules on task-oriented dialog systems its accuracy strongly affects the quality of the system response. The architecture of the tracker has been changed from pipeline processing to an end-to-end approach that directly estimates a user's intention from each current utterance and a dialog history because of the growth in the use of the neural-network-based classifier. However tracking appropriate slot-value pairs of dialog states that are not explicitly mentioned in user utterances is still a difficult problem. In this research we propose creating feature vectors by using inference results on an external knowledge base. This inference process predicts associative entities in the knowledge base which contribute to the dialog state tracker for unseen entities of utterances. We extracted a part of a graph structure from an external knowledge base (Wikidata). Label propagation was used for inferring associative nodes (entities) on the graph structure to produce feature vectors. We used the vectors for the input of a fully connected neural network (FCNN) based tracker. We also introduce a convolutional neural network (CNN) tracker as a state-of-the-art tracker and ensemble models of FCNN and CNN trackers. We used a common test bed Dialog State Tracking Challenge 4 for experiments. We confirmed the effectiveness of the associative knowledge feature vector and one ensemble model outperformed other models. (C) 2018 Elsevier Ltd. All rights reserved.;2019
The dialogue response generation is a challenging task in chatbot applications. Recently neuralnetwork-based dialogue models including the sequence-to-sequence model and the RNN language models are able to generate fluent and grammatically compliant responses while there is a major limitation that most of the responses generated by these models are of chit-chat style instead of being informative. After investigating the currently used models we found that one primary challenge is to model and generate informative words such as named entities especially when the entities have sparsely existed in training corpus. To address this problem we propose to augment neural network-based generative architecture with knowledge embedding and knowledge attentive reader to incorporate external textual knowledge into the dialogue model to facilitate the dialogue modeling and generation. We evaluate the model with the Ubuntu dataset through automatic evaluation metrics and human evaluation. The experimental study has shown our methods outperform strong baselines in multiple metrics. We also visualize how the attention works in the dialogue context to verify the effectiveness of knowledge attentive reader mechanism.;2019
The general role of personal assistants in form of anthropomorphised conversational virtual or robotic agents in cars is subject to research since a few years and the first results indicate numerous positive effects of these anthropomorphised interfaces. However no comprehensive review of the conducted studies has been comprised yet. Furthermore existing studies on the effect of anthropomorphism mainly focus on passenger cars. This article provides a comprehensive review and summary of the conducted studies and investigates the applicability to commercial transportation in particular to anthropomorphised interaction between truck driver and truck. In the first part of the article a literature review describes the details aspects and various forms of anthropomorphism as well as its observed positives effects. The review focusses on studies referring to anthropomorphism in passenger cars complemented by relevant research results from non-automotive disciplines. The second part of this article aims to derive innovative and applicable concepts for the anthropomorphised driver-truck interfaces using the Design-Thinking approach: building on a comprehensive literature review to identify user needs and problems an interdisciplinary expert workshop developed the two first anthropomorphised driver-truck interaction concepts. The paper finishes with carving out the differences between anthropomorphised car-driver and truck-driver interaction. The next step of research will then be the implementation of the developed interaction concepts in a first prototype followed by the respective user evaluation.;2019
The goal of automating complex human activities dates to antiquity. The mental health field has also made use of advances in technology to assist patients in need. Artificial Intelligence (Al) is the study of agents that receive percepts from the environment and perform actions. Al is increasingly being incorporated into the development of chatbots that can be deployed in both clinical and nonclinical settings. Chatbots are a computer program that simulates human conversation through voice commands or text chats or both. The collaboration between Al therapists and more traditional providers of such care will only grow.;2019
The paper reviews the state of the art of natural language engineering (NLE) around 1995 when this journal first appeared and makes a critical comparison with the current state of the art in 2018 as we prepare the 25th Volume. Specifically the then state of the art in parsing information extraction chatbots and dialogue systems speech processing and machine translation are briefly reviewed. The emergence in the 1980s and 1990s of machine learning (ML) and statistical methods (SM) is noted. Important trends and areas of progress in the subsequent years are identified. In particular the move to the use of n-grams or skip grams and/or chunking with part of speech tagging and away from whole sentence parsing is noted as is the increasing dominance of SM and ML. Some outstanding issues which merit further research are briefly pointed out including metaphor processing and the ethical implications of NLE.;2019
The present paper surveys neural approaches to conversational AI that have been developed in the last few years. We group conversational systems into three categories: (1) question answering agents (2) task-oriented dialogue agents and (3) chatbots. For each category we present a review of state-of-the-art neural approaches draw the connection between them and traditional approaches and discuss the progress that has been made and challenges still being faced using specific systems and models as case studies.;2019
The use of embodied conversational agents in mental health has increased in the last years. Several studies exist describing the benefits and advantages of this technology as a complement to psychotherapeutic interventions for the prevention and treatment of depression anxiety or post-traumatic stress disorder to name a few. A small number of these works implement capabilities in the virtual agent focused on the detection and prevention of suicidality risks. The work presented in this paper describes the development of an embodied conversational agent used as the main interface in HelPath a mobile-based application addressed to individuals detected with any of the suicidal behaviours: ideation planning or attempt. The main objective of HelPath is to continuously collect user's information that complemented with data from the electronic health record supports the identification of risks associated with suicidality. Through the virtual agent the users also receive information and suggestions based on cognitive behaviour therapy that would help them to maintain a healthy condition. The paper also presents the execution of an exploratory pilot to assess the acceptability perception and adherence of users towards the virtual agent. The obtained results are presented and discussed and some actions for further improvement of the embodied conversational agent are also identified.;2019
The way doctors deliver bad news has a significant impact on the therapeutic process. In order to facilitate doctor's training we have developed an embodied conversational agent simulating a patient to train doctors to break bad news. In this article we present an evaluation of the virtual reality training platform comparing the users' experience depending on the virtual environment displays: a PC desktop a virtual reality headset and four wall fully immersive systems. The results of the experience including both real doctors and naive participants reveal a significant impact of the environment display on the perception of the user (sense of presence sense of co-presence perception of the believability of the virtual patient) showing moreover the different perceptions of the participants depending on their level of expertise.;2019
The workshop program of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19) was held in Honolulu Hawaii on Sunday and Monday January 27 and 28 2019. There were 16 workshops in the program: Affective Content Analysis: Modeling Affect-in-Action Agile Robotics for Industrial Automation Competition Artificial Intelligence for Cyber Security Artificial Intelligence Safety Dialog System Technology Challenge Engineering Dependable and Secure Machine Learning Systems Games and Simulations for Artificial Intelligence Health Intelligence Knowledge Extraction from Games Network Interpretability for Deep Learning Plan Activity and Intent Recognition Reasoning and Learning for Human-Machine Dialogues Reasoning for Complex Question Answering Recommender Systems Meet Natural Language Processing Reinforcement Learning in Games and Reproducible AI. This report contains brief summaries of all the workshops that were held.;2019
This article explores questions about chatbots in particular and artificial intelligence (AI) in general from a Pauline that is a Christian theological perspective. It does so in a way that focuses on a particular scene in the New Testament: Paul in the Athenian Areopagus considering an altar to an unknown God quoting Greek poets and philosophers and sharing curious theology as he dialogues with Stoic and Epicurean thinkers (Acts 17:16-34). By examining the sociohistorical nuances of this scene and their philosophical and theological implications this article shows how the altar Paul considers philosophically and theologically becomes the focal point for an important dialogue about apocalyptic ends or ideas about who we are where we are going and who or what is responsible for that who-ness and where-ness. In turn this can teach us how to ask practical questions which can uncover the unsuspected apocalyptic ends represented by or even contained within common technological objects such as chatbots.;2019
This article presents the results of a systematic review of the literature on dialogue-based CALL resulting in a conceptual framework for research on the matter. Applications allowing a learner to have a conversation in a foreign language with a computer have been studied from various perspectives and under different names (dialogue systems conversational agents chatbots horizontal ellipsis ). Considering the fragmentation of what we identify under the term dialogue-based CALL we attempt to offer a structured overview of these efforts into a conceptual framework. Through a methodical search strategy we collected a corpus of 343 publications. From this corpus we formalized an operational definition of dialogue-based CALL which allowed us to identify 96 relevant systems. Analyzing the type of dialogue they offer on a continuum of constraints on form and meaning we propose to classify those systems into four groups. We have called these branching form-focused goal-oriented and reactive systems and we describe their corresponding interactional instructional and technological traits. We summarize the main results from empirical studies on such systems distinguishing observational survey and experimental studies and discuss the impact of dialogue-based CALL on motivation and L2 development identifying positive evidence on both outcomes. Finally we propose two main avenues for future research: relative effectiveness of dialogue-based CALL approaches and dialogue systems as an environment for testing SLA hypotheses.;2019
This commentary for the special issue on the automation of journalism highlights the progress made in this area of study before advocating for researchers to pay greater attention to the audience and its perceptions of the technologies of automation including algorithms artificial intelligence chatbots recommender and personalization systems and automated news-writing software.;2019
This paper describes the experimental setups and the evaluation results of the sixth Dialog System Technology Challenges (DSTC6) aiming to develop end-to-end dialogue systems. Neural network models have become a recent focus of investigation in dialogue technologies. Previous models required training data to be manually annotated with word meanings and dialogue states but end-to-end neural network dialogue systems learn to directly output natural-language system responses without needing training data to be manually annotated. Thus this approach allows us to scale up the size of training data and cover more dialog domains. In addition dialogue systems require a meta-function to avoid deploying inappropriate responses generated by themselves. To challenge such issues the DSTC6 consists of three tracks (1). End-to-End Goal Oriented dialogue Learning to select system responses (2). End-to-End Conversation Modeling to generate system responses using Natural Language Generation (NLG) and (3). Dialogue Breakdown Detection. Since each domain has different issues to be addressed to develop dialogue systems we targeted restaurant retrieval dialogues to fill slot-value in Track 1 customer services on Twitter by combining goal-oriented dialogues and ChitChat in Track 2 and human-machine dialogue data for ChitChat in Track 3. DSTC6 had 141 people declaring their interests and 23 teams submitted their final results. 18 scientific papers were presented in the wrap-up workshop. We find the blending end-to-end trainable models associated to meaningful prior knowledge performs the best for the restaurant retrieval for Track 1. Indeed Hybrid Code Network and Memory Network have been the best models for this task. In Track 2 78.5% of the system responses automatically generated by the best system were rated better than acceptable by humans and this achieves 89% of the number of the human responses rated in the same class. In Track3 the dialogue breakdown detection technologies performed as well as human agreements in both data-sets of English and Japanese. (C) 2018 Elsevier Ltd. All rights reserved.;2019
This paper explores the potential of using chatbots to improve the academic research experience for university students with a literature-based discussion reflecting on a prototype being developed at the University of Technology Sydney (UTS). The paper proposes that information professionals need to adapt emerging technologies such as chatbots to innovate improve and support library services. Designing a positive experience for the user is essential to ensure that such technological solutions are sustainable. In this exploratory paper we argue that it is important that librarians engage with the conversational design of the library chatbot in collaboration with the technology developers in order to make it useful friendly trustworthy and customisable for university students.;2019
This paper presents adversarial training and decoding methods for neural conversation models that can generate natural responses given dialog contexts. In our prior work we built several end-to-end conversation systems for the 6th Dialog System Technology Challenges (DSTC6) Twitter help-desk dialog task. These systems included novel extensions of sequence adversarial training example-based response extraction and Minimum Bayes-Risk based system combination. In DSTC6 our systems achieved the best performance in most objective measures such as BLEU and METEOR scores and decent performance in a subjective measure based on human rating. In this paper we provide a complete set of our experiments for DSTC6 and further extend the training and decoding strategies more focusing on improving the subjective measure where we combine responses of three adversarial models. Experimental results demonstrate that the extended methods improve the human rating score and outperform the best score in DSTC6. (C) 2018 Elsevier Ltd. All rights reserved.;2019
This paper reports on an experiment that investigates the effect of interacting with a personality-driven embodied conversational agent (ECA) on the perceived social presence and game experience of people in a VR social simulator. Furthermore the dynamics between the different metrics of game experience and social presence of people are explored to determine which game experience metrics are the strongest predictors of perceived social presence in this context. A personality-based emotional model is used for personifying the employed ECA which governs the manifestation of its non-verbal behaviors. Three experimental conditions manipulating the existence and intensity of non-verbal behaviors exhibited by the ECA were used to investigate the effect of this proposed approach. The results of the experiment with 41 participants indicate that people who were exposed to an extrovert ECA experienced significantly higher levels of behavioral involvement as part of their social presence compared to the other conditions. These results suggest that incorporating personality by means of non-verbal behavior in the emotional model of an ECA influences users perceived feeling of social presence. Furthermore our results reveal that there is a bidirectional relationship between game experience metrics and perceived social presence of people as each predict the other.;2019
This project has been carried out in the context of recent major developments in botics and more widespread usage of virtual agents in personal and professional sphere. The general purpose of the experiment was to thoroughly examine the character of the human-non-human interaction process. Thus in the paper we present a study of human-chatbot interaction focusing on the affective responses of users to different types of interfaces with which they interact. The experiment consisted of two parts: measurement of psychophysiological reactions of chatbot users and a detailed questionnaire that focused on assessing interactions and willingness to collaborate with a bot. In the first quantitative stage participants interacted with a chatbot either with a simple text chatbot (control group) or an avatar reading its responses in addition to only presenting them on the screen (experimental group. We gathered the following psychophysiological data from participants: electromyography (EMG) respirometer (RSP) electrocardiography (ECG) and electrodermal activity (EDA). In the last declarative stage participants filled out a series of questionnaires related to the experience of interacting with (chat)bots and to the overall human-(chat)bot collaboration assessment. The theory of planned behaviour survey investigated attitude towards cooperation with chatbots in the future. The social presence survey checked how much the chatbot was considered to be a real person. The anthropomorphism scale measured the extent to which the chatbot seems humanlike. Our particular focus was on the so-called uncanny valley effect consisting of the feeling of eeriness and discomfort towards a given medium or technology that frequently appears in various kinds of human-machine interactions. Our results show that participants were experiencing lesser uncanny effects and less negative affect in cooperation with a simpler text chatbot than with the more complex animated avatar chatbot. The simple chatbot have also induced less intense psychophysiological reactions. Despite major developments in botics the user's affective responses towards bots have frequently been neglected. In our view understanding the user's side may be crucial for designing better chatbots in the future and thus can contribute to advancing the field of human-computer interaction. (C) 2018 Elsevier B.V. All rights reserved.;2019
This research aims to develop a dialogue system for eliminating difficulties encountered in the efficient and accurate utilization of information for decision makers at emergency operation centers (EOC). The rapid growth in the amount of data has caused complications in decision making tasks in disaster management. This has increased the difficulty for decision makers when they try to accomplish their mission accurately and efficiently. In our preliminary work we attempted to develop a chatbot for decision makers and staff at an EOC to assist them in the utilization selection and processing of information efficiently and accurately. A user experience test revealed that a better adaption of the dialogue system to the characteristics of disaster management and the EOC was required. Thus we specifically focused on the development of a technique of language understanding (LU) to be able to analyze the user's demands. As a solution we developed a framework for a dialogue system combining question answering features a knowledge base as the knowledge provider and a search module that can handle the relatively difficult querying tasks. To improve the performance of the system we focused on enhancing the capability in understanding users' questions. The construction of the question analysis and knowledge base were both adapted to the characteristics of disaster management. The validation shows that our method can analyze and process the user's questions into a machine-acceptable form with a success rate of approximately 70%.;2019
This research developed a keyword-based chatbot system Ask Diana for water-related disaster management. Disaster management has been considered difficult and tedious due to the complex characteristics of disaster-related data. To deal with this problem this research developed a chatbot system with a water-related disaster database a user intent mechanism and an intuitive mobile-device-based user interface. With such a system users are able to access important data or information they need for decision making by directly asking the proposed chatbot or operating the image-based menus. The system was validated through a usability test and a six-month field test. The results demonstrated that Ask Diana can help related personnel access disaster data intuitively and develop corresponding response strategies efficiently.;2019
This review positions current conceptions of interest and its development as a critical and (importantly) sustainable source of motivation for learning a new language across formal education. We begin with the gap in our understanding of motivation to learn a new language generated by the longstanding dominance of applied linguistics identity/sociocultural theoretical frameworks in school learning environments. The Four-Phase Model (Hidi & Renninger 2006) and an extension with specific relevance for the highly structured nature of formal education is reviewed and implications for second and foreign language learning classrooms are drawn. This review concludes with future directions for interested language learning researchers and essential first steps for instructors seeking to support the initiation and continued development of students' interest in their languagelearning classrooms. (c) 2019 Elsevier Ltd. All rights reserved.;2019
This special issue examines the growing importance of algorithms and automation in the gathering composition and distribution of news. It connects a long line of research on journalism and computation with scholarly and professional terrain yet to be explored. Taken as a whole these articles share some of the noble ambitions of the pioneering publications on 'reporting algorithms' such as a desire to see computing help journalists in their watchdog role by holding power to account. However they also go further firstly by addressing the fuller range of technologies that computational journalism now consists of: from chatbots and recommender systems to artificial intelligence and atomised journalism. Secondly they advance the literature by demonstrating the increased variety of uses for these technologies including engaging underserved audiences selling subscriptions and recombining and re-using content. Thirdly they problematize computational journalism by for example pointing out some of the challenges inherent in applying AI to investigative journalism and in trying to preserve public service values. Fourthly they offer suggestions for future research and practice including by presenting a framework for developing democratic news recommenders and another that may help us think about computational journalism in a more integrated structured manner.;2019
This study aimed to identify and describe the fundamental characteristics of spoken dialogue systems and their role in supporting human-robot interaction and enabling the communication between socially assistive robots and patients with dementia. First this work provides an overview of spoken dialogue systems by considering the underlying technologies approaches methods and general issues. Then the analysis focuses on studies systems and approaches that have investigated the role of dialogue systems and conversational agents in the interaction with elderly people with dementia by presenting the results of a literature review. While the overview of spoken dialogue systems relies on existing surveys and reviews a research was conducted to identify existing works in the literature that have investigated the role of conversational agents and dialogue systems in the elderly and people with cognitive impairments. Inclusion criteria were as follows: (1) use of conversational agents dialogue systems or language processing tools for people with cognitive impairments (2) age 60 years (3) diagnosis of dementia according to National Institute on Aging-Alzheimer's Association (NIAAA) criteria (4) presence of tests or experiments with qualitative or quantitative results. Initially 125 studies published between 2000 and 2017 were identified of which 12 met the inclusion criteria. The review identifies the issues and challenges that are reported when conversational agents and speech-based interfaces have been used for interacting with people with cognitive impairments. In addition the review led to the identification of studies that have investigated speech processing and natural language processing capabilities to assess the cognitive status of people with dementia.;2019
This study conducts a mapping study to survey the landscape of health chatbots along three research questions: What illnesses are chatbots tackling? What patient competences are chatbots aimed at? Which chatbot technical enablers are of most interest in the health domain? We identify 30 articles related to health chatbots from 2014 to 2018. We analyze the selected articles qualitatively and extract a triplet <technicalEnablers competence illness> for each of them. This data serves to provide a first overview of chatbot-mediated behavior change on the health domain. Main insights include: nutritional disorders and neurological disorders as the main illness areas being tackled affect as the human competence most pursued by chatbots to attain change behavior and personalization and consumability as the most appreciated technical enablers. On the other hand main limitations include lack of adherence to good practices to case-study reporting and a deeper look at the broader sociological implications brought by this technology.;2019
This study examined effects of self-disclosure on relationship closeness with an Internet of Things (IoT) conversational agent (IoT-CA) and attributions of responsibility. Participants and IoT-CAs worked as dyads for two interdependent-outcome tasks: a creativity and a learning task (for measuring dyadic creativity ability and IoT-CAs' understanding of people's preferences respectively). Dyadic success or failure feedback was determined. Results showed in contrast to self-serving bias (SSB) people did not credit personal responsibility for dyadic success or blame the IoT-CA for dyadic failure. However when people had previously engaged in self-disclosure with IoT-CAs they showed reversed SSB and tended to attribute success to the IoT-CA and accept more personal responsibility for failure. The effect of self-disclosure on attributions of responsibility was mediated by closeness of the relationship. In terms of attributions of responsibility between tasks people who engaged in self-disclosure with IoT-CAs believed IoT-CAs understood them more and were more likely to attribute success to the learning task.;2019
This study experimentally investigated the design of effective interactions using pedagogical conversational agents (PCAs) in a learner-learner collaborative learning activity. While dyads engaged in a concept explanation task (explaining the mechanism of computer processing) PCAs served as facilitators and provided metacognitive suggestions to better improve learning performance. Previous studies have shown that learners who received several types of suggestions from multiple PCAs were motivated to produce effective explanations this study then further explored the effects of using multiple PCAs in different roles providing different types of facilitation. It was predicted that by using two different PCAs to offer suggestions with a delay learners may be able to process information more efficiently for example by paying closer attention to each type of suggestion. To investigate this possibility two types of facilitating content namely provision of metacognitive suggestions and advice on effective coordination were each implemented into two role-playing PCAs named the explanation adviser and the communication adviser respectively. The results show that when learners used PCAs playing different roles and offering suggestions corresponding to these roles learners generated explanations related to the suggestions and improved performance (efficacy of explanations) in several areas including learning performance for example better understanding the concept and becoming able to explain it using a greater range of technical words. This study shows empirically how multiple PCAs can be effectively designed to implement roles yielding different types of suggestions. The advantages of using such methods and implementing such functions of PCAs are further discussed. (C) 2018 Published by Elsevier B.V.;2019
This study presents a learning-by-imitation technique that learns social robot interaction behaviors from natural human-human interaction data and requires minimum input from a designer. To solve the problem of responding to ambiguous human actions a novel topic clustering algorithm based on action co-occurrence frequencies is introduced. The system learns human-readable rules that dictate which action the robot should take based on the most recent human action and the current estimated topic of conversation. The technique is demonstrated in a scenario where the robot learns to play the role of a travel agent. The proposed technique outperformed several baseline techniques in qualitative and quantitative evaluations. It responded more accurately to ambiguous questions and participants found it was easier to understand provided more information and required less effort to interact with.;2019
This study presents a reference model (RM) and the architecture of a cognitive health advisor (CHA) that integrates information with ambient intelligence. By controlling the information using the CHA platform the reference model can provide various ambient intelligent solutions to a user. Herein a novel approach to a CHA RM based on evolutional cyber-physical systems is proposed. The objective of the CHA RM is to improve personal health by managing data integration from many devices as well as conduct a new feedback cycle which includes training and consulting to improve quality of life. The RM can provide an overview of the basis for implementing concrete software architectures. The proposed RM provides a standardized clarification for developers and service designers in the design and implementation process. The CHA RM provides a new approach to developing a digital healthcare model that includes integrated systems subsystems and components. New features for chatbots and feedback functions set the position of the conversational interface system to improve human health by integrating information analytics and decisions and feedback as an advisor on the CHA platform.;2019
To generate proper responses to user queries multi-turn chatbot models should selectively consider dialogue histories. However previous chatbot models have simply concatenated or averaged vector representations of all previous utterances without considering contextual importance. To mitigate this problem we propose a multi-turn chatbot model in which previous utterances participate in response generation using different weights. The proposed model calculates the contextual importance of previous utterances by using an attention mechanism. In addition we propose a training method that uses two types of Wasserstein generative adversarial networks to improve the quality of responses. In experiments with the DailyDialog dataset the proposed model outperformed the previous state-of-the-art models based on various performance measures.;2019
Today's common practice in developing conversational agents is pipelining off-the-shelf modularized services as ready-made building blocks. However the discrete and sequential nature of the modules yields long response latency. We introduce Sci-Fii a speculative inference framework accelerating conversational agent systems built with off-the-shelf modules while keeping the modules unchanged.;2019
Trainable chatbots that exhibit fluent and human-like conversations remain a big challenge in artificial intelligence. Deep Reinforcement Learning (DRL) is promising for addressing this challenge but its successful application remains an open question. This article describes a novel ensemble-based approach applied to value-based DRL chatbots which use finite action sets as a form of meaning representation. In our approach while dialogue actions are derived from sentence clustering the training datasets in our ensemble are derived from dialogue clustering. The latter aim to induce specialised agents that learn to interact in a particular style. In order to facilitate neural chatbot training using our proposed approach we assume dialogue data in raw text only - without any manually-labelled data. Experimental results using chitchat data reveal that (1) near human-like dialogue policies can be induced (2) generalisation to unseen data is a difficult problem and (3) training an ensemble of chatbot agents is essential for improved performance over using a single agent. In addition to evaluations using held-out data our results are further supported by a human evaluation that rated dialogues in terms of fluency engagingness and consistency - which revealed that our proposed dialogue rewards strongly correlate with human judgements. (C) 2019 Elsevier B.V. All rights reserved.;2019
Voice has become a widespread and commercially viable interaction mechanism with the introduction of voice assistants (VAs) such as Amazon's Alexa Apple's Ski Google Assistant and Microsoft's Cortana. Despite their prevalence we do not have a detailed understanding of how these technologies are used in domestic spaces. To understand how people use VAs we conducted interviews with 19 users and analyzed the log files of 82 Amazon Alexa devices totaling 193665 commands and 88 Google Home Devices totaling 65499 commands. In our analysis we identified music search and IoT usage as the command categories most used by VA users. We explored how VAs are used in the home investigated the role of VAs as scaffolding for Internet of Things device control and characterized emergent issues of privacy for VA users. We conclude with implications for the design of VAs and for future research studies of VAs.;2019
We aim to draw on an important overlooked potential of affective dialogue systems-their application to promote positive emotional states similar to that of emotional support between humans. This can be achieved by eliciting a more positive emotional valence throughout a dialogue system interaction i.e. positive emotion elicitation. Existing works on emotion elicitation have not yet paid attention to the emotional benefit for the users. Moreover a positive emotion elicitation corpus does not yet exist despite the growing number of emotion-rich corpora. Towards this goal first we propose a response retrieval approach for positive emotion elicitation by utilizing examples of emotion appraisal from a dialogue corpus. Second we efficiently construct a corpus using the proposed retrieval method by replacing responses in a dialogue with those that elicit a more positive emotion. We validate the corpus through crowdsourcing to ensure its quality. Finally we propose a novel neural network architecture for an emotion-sensitive neural chat-based dialogue system optimized on the constructed corpus to elicit positive emotion. Objective and subjective evaluations show that the proposed methods result in dialogue responses that are more natural and elicit a more positive emotional response. Further analyses of the results are discussed in this paper.;2019
We develop a model to satisfy the requirements of Dialog System Technology Challenge 6 (DSTC6) Track 1: building an end-to-end dialog systems for goal-oriented applications. This task involves learning a dialog policy from transactional dialogs in a given domain. Automatic system responses are generated using given task-oriented dialog data (http://workshop.colips.org/dstc6/index.html). As this task has a similar structure to a question answering task (Weston et al. 2015) we employ the MemN2N architecture (Sukhbaatar et al. 2015) which outperforms models based on recurrent neural networks or long short-term memory (LSTM). However two problems arise when applying this model to the DSTC6 task. First we encounter an out-of-vocabulary problem which we resolve by categorizing the metadata types of words that exist in the knowledge base the metadata is similar to the named entity. Second the original memory network model has a weak ability to reflect sufficient temporal information because it only uses sentence-level embeddings. Therefore we add bidirectional LSTM (Bi-LSTM) at the beginning of the model to better reflect temporal information. The experimental results demonstrate that our model reflects temporal features well. Furthermore our model achieves state-of-the-art performance among the memory networks and is comparable to hybrid code networks (Ham et al. 2017) and hierarchical LSTM model (Bai et al. 2017) which is not an end-to-end architecture. (C) 2018 Elsevier Ltd. All rights reserved.;2019
We have developed MMDAgent (a fully open-source toolkit for voice interaction systems) which runs on a variety of platforms such as personal computers and smartphones. From this the editing environment of the dialog scenario also needs to be operated on various platforms. So we develop a scenario editor that is implemented on a Web browser. The purpose of this paper also includes making it easy to edit the scenario. Experiments were conducted for subjects using the proposed scenario editor. It was found that our proposed system provides better readability of a scenario and allows easier editing. (C) 2018 The Korean Institute of Communications and Information Sciences (KICS). Publishing Services by Elsevier B.V.;2019
We introduce the task of Visual Dialog which requires an Al agent to hold a meaningful dialog with humans in natural conversational language about visual content. Specifically given an image a dialog history and a question about the image the agent has to ground the question in image infer context from history and answer the question accurately. Visual Dialog is disentangled enough from a specific downstream task so as to serve as a general test of machine intelligence while being sufficiently grounded in vision to allow objective evaluation of individual responses and benchmark progress. We develop a novel two-person real-time chat data-collection protocol to curate a large-scale Visual Dialog dataset (VisDial). VisDial v0.9 has been released and consists of similar to 1.2M dialog question-answer pairs from 10-round human-human dialogs grounded in similar to 120k images from the COCO dataset. We introduce a family of neural encoder-decoder models for Visual Dialog with 3 encoders-Late Fusion Hierarchical Recurrent Encoder and Memory Network (optionally with attention over image features)-and 2 decoders (generative and discriminative) which outperform a number of sophisticated baselines. We propose a retrieval-based evaluation protocol for Visual Dialog where the Al agent is asked to sort a set of candidate answers and evaluated on metrics such as mean-reciprocal-rank and recall@k of human response. We quantify the gap between machine and human performance on the Visual Dialog task via human studies. Putting it all together we demonstrate the first 'visual chatbot'! Our dataset code pretrained models and visual chatbot are available on https://visualdialog.org.;2019
We present artificial intelligent (AI) agents that act as interviewers to engage with a user in a text-based conversation and automatically infer the user's personality traits. We investigate how the personality of an AI interviewer and the inferred personality of a user influences the user's trust in the AI interviewer from two perspectives: the user's willingness to confide in and listen to an AI interviewer. We have developed two AI interviewers with distinct personalities and deployed them in a series of real-world events. We present findings from four such deployments involving 1280 users including 606 actual job applicants. Notably users are more willing to confide in and listen to an AI interviewer with a serious assertive personality in a high-stakes job interview. Moreover users' personality traits inferred from their chat text along with interview context influence their perception of and their willingness to confide in and listen to an AI interviewer. Finally we discuss the design implications of our work on building hyper-personalized intelligent agents.;2019
We present VICA a Visual Counseling Agent designed to create an engaging multimedia face-to-face interaction. VICA is a human-friendly agent equipped with high-performance voice conversation designed to help psychologically stressed users to offload their emotional burden. Such users specifically include non-computer-savvy elderly persons or clients. Our agent builds replies exploiting interlocutor's utterances expressing such as wishes obstacles emotions etc. Statements asking for confirmation details emotional summary or relations among such expressions are added to the utterances. We claim that VICA is suitable for positive counseling scenarios where multimedia specifically high-performance voice communication is instrumental for even the old or digital divided users to continue dialogue towards their self-awareness. To prove this claim VICA's effect is evaluated with respect to a previous text-based counseling agent CRECA and ELIZA including its successors. An experiment involving 14 subjects shows VICA effects as follows: (i) the dialogue continuation (CPS: Conversation-turns Per Session) of VICA for the older half (age>40) substantially improved 53% to CRECA and 71% to ELIZA. (ii) VICA's capability to foster peace of mind and other positive feelings was assessed with a very high score of 5 or 6 mostly out of 7 stages of the Likert scale again by the older. Compared on average such capability of VICA for the older is 5.14 while CRECA (all subjects are young students age<25) is 4.50 ELIZA is 3.50 and the best of ELIZA's successors for the older (>25) is 4.41.;2019
We propose novel interpersonal assistants a next-generation conversational agent which is always-on unobtrusively serving natural human-to-human conversations. We deepen the motivation and design insights with real practices in language delays and parent-child conflicts. We then present a common platform initiative to effectively support rapid development of interpersonal assistant applications with a highlight on the key functional element of turn isolations and technical insights on microstructural dynamics.;2019
We propose Quantized Dialog a novel approach for the development of conversational systems. The methodology relies on the semantic quantization and clustering of the dialog utterances in order to reduce the dialog interaction space making prediction of the next utterance more tractable. The effectiveness of this method is showcased using the goal-oriented dataset of the sixth Dialog System Technology Challenge (DSTC6). We compare the performance of Quantized Dialog based on an n-gram language model for next-utterance prediction against other models that employ popular deep-learning architectures such as multi-layer neural network classifiers memory networks long short-term memory recurrent neural networks and convolutional neural networks. The experimental results demonstrate the promising potential of the new quantized approach in goal-oriented dialog prediction. (C) 2018 Elsevier Ltd. All rights reserved.;2019
We study the problem of response selection for multi-turn conversation in retrieval-based chatbots. The task involves matching a response candidate with a conversation context the challenges for which include how to recognize important parts of the context and how to model the relationships among utterances in the context. Existing matching methods may lose important information in contexts as we can interpret them with a unified framework in which contexts are transformed to fixed-length vectors without any interaction with responses before matching. This motivates us to propose a new matching framework that can sufficiently carry important information in contexts to matching and model relationships among utterances at the same time. The new framework which we call a sequential matching framework (SMF) lets each utterance in a context interact with a response candidate at the first step and transforms the pair to a matching vector. The matching vectors are then accumulated following the order of the utterances in the context with a recurrent neural network (RNN) that models relationships among utterances. Context-response matching is then calculated with the hidden states of the RNN. Under SMF we propose a sequential convolutional network and sequential attention network and conduct experiments on two public data sets to test their performance. Experiment results show that both models can significantly outperform state-of-the-art matching methods. We also show that the models are interpretable with visualizations that provide us insights on how they capture and leverage important information in contexts for matching.;2019
Wearable biometric monitoring devices (BMDs) and artificial intelligence (Al) enable the remote measurement and analysis of patient data in real time. These technologies have generated a lot of hype but their real-world effectiveness will depend on patients' uptake. Our objective was to describe patients' perceptions of the use of BMDs and Al in healthcare. We recruited adult patients with chronic conditions in France from the Community of Patients for Research (ComPaRe). Participants (1) answered quantitative and open-ended questions about the potential benefits and dangers of using of these new technologies and (2) participated in a case-vignette experiment to assess their readiness for using BMD5 and Al in healthcare. Vignettes covered the use of Al to screen for skin cancer remote monitoring of chronic conditions to predict exacerbations smart clothes to guide physical therapy and Al chatbots to answer emergency calls. A total of 1183 patients (51% response rate) were enrolled between May and June 2018. Overall 20% considered that the benefits of technology (e.g. improving the reactivity in care and reducing the burden of treatment) greatly outweighed the dangers. Only 3% of participants felt that negative aspects (inadequate replacement of human intelligence risks of hacking and misuse of private patient data) greatly outweighed potential benefits. We found that 35% of patients would refuse to integrate at least one existing or soon-to-be available intervention using BMD5 and Al-based tools in their care. Accounting for patients' perspectives will help make the most of technology without impairing the human aspects of care generating a burden or intruding on patients' lives.;2019
Web API recommendations have recently been studied extensively. However recommending an API for a service is different than service intelligence. Web API automatic calls are widely used in question-answer dialog applications and service-composed workflow systems to achieve intelligent services. To finish an automatic Web API call not only requires the Web API ID but also its input parameters. In this paper we propose an end-to-end Web API automatic calls approach named WAAC that translates a goal's natural language sentences directly to the Web API invoking sequences including its ID and parameters. This end-to-end approach based on the seq2seq encoder-decoder framework adopts character-level RNN for the Chinese sentences and introduces a copying mechanism to retrieve API parameters. To train the network a Chinese version dataset of over 1 million natural sentences and API invoking sequence pairs are generated with some manually labeled data and 72 real Web API invoking logs. Experiments obtain a 96% precision on predicting API invoking sequences and show that the character-level RNN and copying mechanism both contribute considerably to achieving a high precision Web API automatic call system for goal-oriented services.;2019
Why do we perceive virtual assistants as something radically new? Our hypothesis is that today virtual assistants are raising an expectation for natural interaction with the human. Human interaction is by nature cognitive and collaborative. Human sciences help to flesh the ingredients of such cognitive interaction. Uttering a sentence is at the same time: producing sound making a well-formed sentence giving meaning enriching a common background of beliefs and intentions making something together. In this paper we remind the basics of human cognitive communication as developed by human sciences particularly philosophy of mind. We propose a definition of this way of interacting with computer as 'cognitive interaction' and we summarize the main characteristics of this interaction mode into a layered model. Finally we develop case studies to illustrate concretely the concepts. We analyze in light of our theoretical model three approaches of conversational systems in Al to illustrate the different available options to implement the pragmatic dimension of cognitive interaction. We analyze first the seminal approach of Grosz and Sidner [20] and then we describe how the now classical approach of discourse structure developed by Asher and Lascarides [5] could capture the pragmatic dimension of interaction with an intelligent virtual assistant. Finally we wonder whether a state-of-the-art chat bot framework actually implements the needed level of cognitive interaction. The contribution of this paper is: to remind and summarize essential ideas from other disciplines which are relevant to understand what should be the interaction with virtual assistants should be to explain why the cooperation with virtual assistants is something special to delineate the challenges we have to solve if we are to develop truly collaborative virtual assistants. (C) 2019 Elsevier B.V. All rights reserved.;2019
With the growing use of information technology in all life domains hacking has become more negatively effective than ever before. Also with developing technologies attacks numbers are growing exponentially every few months and become more sophisticated so that traditional IDS becomes inefficient detecting them. This paper proposes a solution to detect not only new threats with higher detection rate and lower false positive than already used IDS but also it could detect collective and contextual security attacks. We achieve those results by using Networking Chatbot a deep recurrent neural network: Long Short Term Memory (LSTM) on top of Apache Spark Framework that has an input of flow traffic and traffic aggregation and the output is a language of two words normal or abnormal. We propose merging the concepts of language processing contextual analysis distributed deep learning big data anomaly detection of flow analysis. We propose a model that describes the network abstract normal behavior from a sequence of millions of packets within their context and analyzes them in near real-time to detect point collective and contextual anomalies. Experiments are done on MAWI dataset and it shows better detection rate not only than signature IDS but also better than traditional anomaly IDS. The experiment shows lower false positive higher detection rate and better point anomalies detection. As for prove of contextual and collective anomalies detection we discuss our claim and the reason behind our hypothesis. But the experiment is done on random small subsets of the dataset because of hardware limitations so we share experiment and our future vision thoughts as we wish that full prove will be done in future by other interested researchers who have better hardware infrastructure than ours.;2019
With the maturity and popularity of dialogue systems detecting user's unknown intent in dialogue systems has become an important task. It is also one of the most challenging tasks since we can hardly get examples prior knowledge or the exact numbers of unknown intents. In this paper we propose SofterMax and deep novelty detection (SMDN) a simple yet effective post-processing method for detecting unknown intent in dialogue systems based on pre-trained deep neural network classifiers. Our method can be flexibly applied on top of any classifiers trained in deep neural networks without changing the model architecture. We calibrate the confidence of the softmax outputs to compute the calibrated confidence score (i.e. SofterMax) and use it to calculate the decision boundary for unknown intent detection. Furthermore we feed the feature representations learned by the deep neural networks into traditional novelty detection algorithm to detect unknown intents from different perspectives. Finally we combine the methods above to perform the joint prediction. Our method classifies examples that differ from known intents as unknown and does not require any examples or prior knowledge of it. We have conducted extensive experiments on three benchmark dialogue datasets. The results show that our method can yield significant improvements compared with the state-of-the-art baselines(1). (C) 2019 Published by Elsevier B.V.;2019
With the recent increase in the interest of individuals in health lifecare and disease hospital medical services have been shifting from a treatment focus to prevention and health management. The medical industry is creating additional services for health- and life-promotion programs. This change represents a medical-service paradigm shift due to the prolonged life expectancy aging lifestyle changes and income increases and consequently the concept of the smart health service has emerged as a major issue. Due to smart health the existing health-promotion medical services that typically have been operated by large hospitals have been developing into remote medical-treatment services where personal health records are used in small hospitals moreover a further expansion has been occurring in the direction of u-Healthcare in which health conditions are continuously monitored in the everyday lives of the users. However as the amount of data is increasing and the medical-data complexity is intensifying the limitations of the previous approaches are increasingly problematic furthermore since even the same disease can show different symptoms depending on the personal health conditions lifestyle and genome information universal healthcare is not effective for some patients and it can even generate severe side effects. Thus research on the AI-based healthcare that is in the form of mining-based smart health which is a convergence technology of the 4IR is actively being carried out. Particularly the introduction of various smart medical equipment for which healthcare big data and a running machine have been combined and the expansion of the distribution of smartphone wearable devices have led to innovations such as personalized diagnostic and treatment services and chronic-disease management and prevention services. In addition various already launched applications allow users to check their own health conditions and receive the corresponding feedback in real time. Based on these innovations the preparation of a way to determine a user's current health conditions and to respond properly through contextual feedback in the case of unsound health conditions is underway. However since the previously made healthcare-related applications need to be linked to a wearable device and they provide medical feedback to users based solely on specific biometric data inaccurate information can be provided. In addition the user interfaces of some healthcare applications are very complicated causing user inconvenience regarding the attainment of desired information. Therefore we propose a chatbot-based healthcare service with a knowledge base for cloud computing. The proposed method is a mobile health service in the form of a chatbot for the provision of fast treatment in response to accidents that may occur in everyday life and also in response to changes of the conditions of patients with chronic diseases. A chatbot is an intelligent conversation platform that interacts with users via a chatting interface and since its use can be facilitated by linkages with the major social network service messengers general users can easily access and receive various health services. The proposed framework enables a smooth human-robot interaction that supports the efficient implementation of the chatbot healthcare service. The design of the framework comprises the following four levels: data level information level knowledge level and service level.;2019
With the rise of robotics and artificial intelligence good communication between humans and machines becomes more important. However users with language and hearing disadvantages may find synthetic speech systems to be difficult to understand. In this study we explore the types of sentence structure and level of word complexity that affect intelligibility of speech in unfamiliar context. Using semantically unpredictable sentences we found that sentence with more complex syntax such as relative pronouns and question words are harder to comprehend while on the word level it is the shorter and simpler words that contribute to misunderstandings. We found that although word frequency affects how well a word is recognised the effect from the occurring frequency is much less than the effect of how phonetically distinctive the word is. There was also evidence of significant difference between native speakers and non-native speakers on how well they could understand the sentences. These results may help us in designing better dialogue system for machine to human interactions especially in the healthcare arena where often users have disadvantages in language and hearing abilities. (C) 2019 Elsevier Ltd. All rights reserved.;2019
A chatbot equipped with a conversational user interface often allows its users to feel as if they are conversing with a human being. The current study examined whether users' perception of a mind within a chatbot is associated with their feeling of co-presence closeness and intention to use and whether the influence of mind perception is reinforced when the chatbot presents social cues in its language. A laboratory experiment (N = 64) revealed that the more participants perceived a mind behind a chatbot the more co-presence and interpersonal closeness they experienced with the chatbot. The associations with co-presence and closeness became stronger when the chatbot used social cues. Furthermore mind perception had an indirect effect on intention to use via closeness when social cues were presented. These findings imply the importance of mind perception and social cues in a chatbot's language in creating a positive chatbot experience.;2020
A conversation-based system is proposed for supporting assessors in performing existing school building inspections. School building safety is a pressing issue however some difficulties in the overall process require solutions or improvements including the complexity of building inspection tasks the restrictions posed by the paperwork process and the ineffectiveness of the management of existing school building inspections. In this study we developed a conversation-based building inspection support system to reduce such problems with the proposed system notifying and guiding assessors to complete building inspections combined with a dashboard for managers to consume reports to determine whether further assessments or retrofits are required. The process of school building inspections was digitalized with a chatbot implemented that features notifications either according to a routine inspection schedule or postseismic events a conversation-based interface for guiding nonprofessional assessors the integration of intuitive activation of inspections after receiving notifications the use of multimedia to show damage directly without the possibility of mistakes and data visualization for supporting managerial decision-making to enhance the quality and accuracy of budget allocation.;2020
A satisfying experience is critical for the user to feel motivated over time especially in mobile health (m-Health) applications. Long-term user experience (UX) assesses more extended periods of use which may reveal the possible impact of a set of experiences. In this study using an in-app embed questionnaire available through a conversational interface we investigated long-term UX on an m-Health application to identify how it occurs over time. The methods were developed in 4 phases which included problem characterization search for UX aspects elaboration and verification of the questionnaire test period with questionnaire applied before during and after use interview with users and information mapping. For 3 months 37 users reported their experiences with the application describing their impressions regarding usage. Results demonstrated that the most satisfying experiences occurred mainly within the first weeks of the study and were associated with the app's features charts and visual resources and the practicality of treatment monitoring. For the less satisfactory experiences the main reasons identified were technical problems on the application and the effort and difficulty of use. All users appreciated the use of a character in the conversational interface as a gatherer of the answers to the assessment questionnaire.;2020
A synthetic voice personifies the system using it. In this work we examine the impact text content voice quality and synthesis system have on the perceived personality of two synthetic voices. Subjects rated synthetic utterances based on the Big-Five personality traits and naturalness. The naturalness rating of synthesis output did not correlate significantly with any Big-Five characteristic except for a marginal correlation with openness. Although text content is dominant in personality judgments results showed that voice quality change implemented using a unit selection synthesis system significantly affected the perception of the Big-Five for example tense voice being associated with being disagreeable and lax voice with lower conscientiousness. In addition a comparison between a parametric implementation and unit selection implementation of the same voices showed that parametric voices were rated as significantly less neurotic than both the text alone and the unit selection system while the unit selection was rated as more open than both the text alone and the parametric system. The results have implications for synthesis voice and system type selection for applications such as personal assistants and embodied conversational agents where developing an emotional relationship with the user or developing a branding experience is important.;2020
Accurate generative chatbots are usually trained on large datasets of question-answer pairs. Despite such datasets not existing for some languages it does not reduce the need for companies to have chatbot technology in their websites. However companies usually own small domain-specific datasets (at least in the form of an FAQ) about their products services or used technologies. In this research we seek effective solutions to create generative seq2seq-based chatbots from very small data. Since experiments are carried out in English and morphologically complex Lithuanian languages we have an opportunity to compare results for languages with very different characteristics. We experimentally explore three encoder-decoder LSTM-based approaches (simple LSTM stacked LSTM and BiLSTM) three word embedding types (one-hot encoding fastText and BERT embeddings) and five encoder-decoder architectures based on different encoder and decoder vectorization units. Furthermore all offered approaches are applied to the pre-processed datasets with removed and separated punctuation. The experimental investigation revealed the advantages of the stacked LSTM and BiLSTM encoder architectures and BERT embedding vectorization (especially for the encoder). The best achieved BLUE on English/Lithuanian datasets with removed and separated punctuation was similar to 0.513/similar to 0.505 and similar to 0.488/similar to 0.439 respectively. Better results were achieved with the English language because generating different inflection forms for the morphologically complex Lithuanian is a harder task. The BLUE scores fell into the range defining the quality of the generated answers as good or very good for both languages. This research was performed with very small datasets having little variety in covered topics which makes this research not only more difficult but also more interesting. Moreover to our knowledge it is the first attempt to train generative chatbots for a morphologically complex language.;2020
Accurate intent detection-based chatbots are usually trained on larger datasets that are not available for some languages. Seeking the most accurate models three English benchmark datasets that were human-translated into four morphologically complex languages (i.e. Estonian Latvian Lithuanian Russian) were used. Two types of word embeddings (fastText and BERT) three types of deep neural network (DNN) classifiers (convolutional neural network (CNN) long short-term memory method (LSTM) and bidirectional LSTM (BiLSTM)) different DNN architectures (shallower and deeper) and various DNN hyperparameter values were investigated. DNN architecture and hyperparameter values were optimized automatically using the Bayesian method and random search. On three datasets of 2/5/8 intents for English Estonian Latvian Lithuanian and Russian languages accuracies of 0.991/0.890/0.712 0.972/0.890/0.644 1.000/0.890/0.644 0.981/0.872/0.712 and 0.972/0.881/0.661 were achieved respectively. The BERT multilingual vectorization with the CNN classifier was proven to be a good choice for all datasets for all languages. Moreover in the majority of models the same set of optimal hyperparameter values was determined. The results obtained in this research were also compared with the previously reported values (where hyperparameter values of DNN models were selected by an expert). This comparison revealed that automatically optimized models are competitive or even more accurate when created with larger training datasets.;2020
Adoption of intelligent personal assistants (IPA) is on the rise. Published studies on IPAs often focus on the analysis and critique of existing IPA features without understanding specific user needs that the technology aims to address. We present an exploratory study that gathered user recommendations for the design of their ideal IPA. The study relied on focus group and content analysis methods for data collection and analysis. Major themes in participants' recommendations for IPA design were identified and included feature improvements (e.g. speech recognition input/output modalities device feedback) customizability and increased control over IPA features and functions transparency and understanding of IPA hardware software and data management processes personification compatibility with third-party platforms accessibility and aesthetics. Many of these recommendations are rooted in basic user experience design principles and have been previously discussed in the context of PDAs (personal digital assistants) and other technology. Addressing these recommendations would advance IPA technology and improve user experiences with it.;2020
Along with the development of social media on the internet dialogue systems are becoming more and more intelligent to meet users' needs for communication emotion and social intercourse. Previous studies usually use sequence-to-sequence learning with recurrent neural networks for response generation. However recurrent-based learning models heavily suffer from the problem of long-distance dependencies in sequences. Moreover some models neglect crucial information in the dialogue contexts which leads to uninformative and inflexible responses. To address these issues we present a bichannel transformer with context encoding (BCTCE) for document-driven conversation. This conversational generator consists of a context encoder an utterance encoder and a decoder with attention mechanism. The encoders aim to learn the distributed representation of input texts. The multihop attention mechanism is used in BCTCE to capture the interaction between documents and dialogues. We evaluate the proposed BCTCE by both automatic evaluation and human judgment. The experimental results on the dataset CMU_DoG indicate that the proposed model yields significant improvements over the state-of-the-art baselines on most of the evaluation metrics and the generated responses of BCTCE are more informative and more relevant to dialogues than baselines.;2020
Although listening to a conversation partner is a key factor in the success of dialogue systems or conversational agents recent neural conversation systems have no interest in generating listening-oriented responses. In this paper we propose an end-to-end dialogue system that generates listening-oriented responses which make users disclose themselves and feel positive emotions. Our model uses 'self disclosure' and 'positiveness' as listening features and generate responses in an appropriate manner to the features. Furthermore the model infers a user response that will be brought out at the end of the dialogue and uses the inferred user response for generating a system response. By utilizing both listening features and user responses our model becomes capable of generating listening-oriented responses. In quantitative and qualitative experiments our model turned out to be capable of generating listening oriented responses that induce users to disclose themselves and talk positively. The results also show that the model utilizing user responses generates more listening-oriented responses than those only using listening features. (C) 2020 Elsevier B.V. All rights reserved.;2020
An excellent dialogue system needs to not only generate rich and diverse logical responses but also meet the needs of users for emotional communication. However despite much work these two problems have not been solved. In this paper we propose a model based on conditional variational autoencoder and dual emotion framework (CVAE-DE) to generate emotional responses. In our model latent variables of the conditional variational autoencoder are adopted to promote the diversity of conversation. A dual emotion framework is adopted to control the explicit emotion of the response and prevent the conversation from generating emotion drift indicating that the emotion of the response is not related to the input sentence. A multiclass emotion classifier based on the Bidirectional Encoder Representations from Transformers (BERT) model is employed to obtain emotion labels which promotes the accuracy of emotion recognition and emotion expression. A large number of experiments show that our model not only generates rich and diverse responses but also is emotionally coherent and controllable.;2020
An important aspect of developing dialogue agents involves endowing a conversation system with emotion perception and interaction. Most existing emotion dialogue models lack the adaptability and extensibility of different scenes because of their limitation to require a specified emotion category or their reliance on a fixed emotional dictionary. To overcome these limitations we propose a neural conversation generation with auxiliary emotional supervised model (nCG-FSM) comprising a sequence-to-sequence (Seq2Seq) generation model and an emotional classifier used as an auxiliary model. The emotional classifier was trained to predict the emotion distributions of the dialogues which were then used as emotion supervised signals to guide the generation model to generate diverse emotional responses. The proposed nCG-ESM is flexible enough to generate responses with emotional diversity including specified or unspecified emotions which can be adapted and extended to different scenarios. We conducted extensive experiments on the popular dataset of Weibo post-response pairs. Experimental results showed that the proposed model was capable of producing more diverse appropriate and emotionally rich responses yielding substantial gains in diversity scores and human evaluations.;2020
Argumentation is a process of reaching a consensus through premises and rebuttals. If an artificial dialogue system can perform argumentation it can improve users' decisions and ability to negotiate with the others. Previously researchers have studied argumentative dialogue systems through a structured database regarding argumentation structure and evaluated the logical consistency of the dialogue. However these systems could not change its response based on the user's agreement or disagreement to its last utterance. Furthermore the persuasiveness of the generated dialogue has not been evaluated. In this study a method is proposed to generate persuasive arguments through a hierarchical argumentation structure that considers human agreement and disagreement. Persuasiveness is evaluated through a crowd sourcing platform wherein participants' written impressions of shown dialogue texts are scored via a third person Likert scale evaluation. The proposed method was compared to the baseline method wherein argument response texts were generated without consideration of the user's agreement or disagreement. Experiment results suggest that the proposed method can generate a more persuasive dialogue than the baseline method. Further analysis implied that perceived persuasiveness was induced by evaluations of the behavior of the dialogue system which was inherent in the hierarchical argumentation structure.;2020
Artificial Intelligence (AI) and its real-life applications are among the most effervescent research topics of the last couple of years. In the past decade stakeholders such as private companies public institutions non-profit entities and even individuals have developed and used various AI algorithms to solve a wide range of problems. Given the extended applicability and the disruption potential of this technology it was just a matter of time until it connected to the field of cultural heritage. This paper presents the development of an intelligent conversational agent which was built to improve the accessibility to information inside a history museum. We present the cultural context the application architecture the implementation challenges and the visitors' feedback. We created a smart virtual agent that interacts with users in natural spoken language. This involved the design and implementation of the artificial intelligence-based core responsible for understanding the Romanian language. A short survey regarding the tourist acceptance of the system was conducted at the premises of our partners the Museum Casa Muresenilor from Brasov shows good acceptance levels from both visitors and museum staff. Given the flexibility of the implementation the system can be used by a large array of stakeholders with minor modifications.;2020
Artificial Intelligence (AI) personal assistant has attracted much attention from both academia and industry. Almost all existing AI personal assistants serve as service terminals to chat with human users for certain tasks. We are instead interested in building AI personal assistants for a different yet important dialog scenario where they chat with people to fulfill specific tasks on behalf of their human users. As the personal assistants are playing a requester role instead of a service terminal role the conversation goal becomes delivering or requesting information according to specific user requests precisely and efficiently. The challenge for the conversation policy is that all user requests must be delivered precisely while the challenge for the response generation is that it's generally expected for machine generated responses to cover multiple information slots either requesting or delivering to make the conversation efficient. In this paper we present Table-to-Dialogue a novel approach to address the above challenges when building a requester role AI personal assistant. We employ an encoder-decoder network to learn explicit conversation policy which generates the corresponding information slots based on the conversation context and the user request table. We further integrate a novel Multi-Slot Constrained Bi-directional Decoder (MS-CBD) into the above encoder-decoder network to generate machine response according to the multiple slot values and their intermediate representations from the policy decoder. Different from the existing single direction text decoder approaches MS-CBD leverage the bi-directional context of the response when generating it to enhance the semantic coherence. The experiments shows that our approach significantly outperform the state-of-the-art conversation approaches on automatic and human evaluation metrics.;2020
Artificial intelligence (AI) and machine learning (ML) may save money and improve the efficiency of business processes but these technologies can also destroy business value sometimes with grave consequences. The inability to identify and manage that risk can lead some managers to delay the adoption of these technologies and thus prevent them from realizing their potential. This article proposes a new framework by which to map the components of an AI solution and to identify and manage the value-destruction potential of AI and ML for businesses. We show how the defining characteristics of AI and ML can threaten the integrity of the AI system's inputs processes and outcomes. We then draw from the concepts of value-creation content and value-creation process to show how these risks may hinder value creation or even result in value destruction. Finally we illustrate the application of our framework with an example of the deployment of an AI powered chatbot in customer service and we discuss how to remedy the problems that arise. (C) 2019 Kelley School of Business Indiana University. Published by Elsevier Inc. All rights reserved.;2020
Artificial intelligence (AI) and people's interactions with it-through virtual agents socialbots and language-generation software-do not fit neatly into paradigms of communication theory that have long focused on human-human communication. To address this disconnect between communication theory and emerging technology this article provides a starting point for articulating the differences between communicative AI and previous technologies and introduces a theoretical basis for navigating these conditions in the form of scholarship within human-machine communication (HMC). Drawing on an HMC framework we outline a research agenda built around three key aspects of communicative AI technologies: (1) the functional dimensions through which people make sense of these devices and applications as communicators (2) the relational dynamics through which people associate with these technologies and in turn relate to themselves and others and (3) the metaphysical implications called up by blurring ontological boundaries surrounding what constitutes human machine and communication.;2020
Artificial intelligence (AI) is bringing about enormous changes in everyday life and today's society. Interest in AI is continuously increasing as many countries are creating new AI-related degrees short-term intensive courses and secondary school programs. This study was conducted with the aim of identifying the interrelationships among topics based on the understanding of various bodies of knowledge and to provide a foundation for topic compositions to construct an academic body of knowledge of AI. To this end machine learning-based sentence similarity measurement models used in machine translation chatbots and document summarization were applied to the body of knowledge of AI. Consequently several similar topics related to agent designing in AI such as algorithm complexity discrete structures fundamentals of software development and parallel and distributed computing were identified. The results of this study provide the knowledge necessary to cultivate talent by identifying relationships with other fields in the edutech field.;2020
Artificial intelligence applications in cognitive computing systems can be found in organizations across every market including chatbots that help customers navigate websites predictive analytics systems used for fraud detection and augmented decision-support systems for knowledge workers. In this article we share reflections and insights from our experience with AI projects in the public sector that can add value to any organization. We organized our findings into four thematic domains-(1) data (2) technology (3) organizational and (4) environmental-and examine them relative to the phases of AI. We conclude with best practices for capturing value with cognitive computing systems. (C) 2019 Kelley School of Business Indiana University. Published by Elsevier Inc. All rights reserved.;2020
Artificial intelligence virtual health assistants are a promising emerging technology. This study is a process evaluation of a 12-week pilot physical activity and diet program delivered by virtual assistant Paola. This single-arm repeated measures study (n = 28 aged 45-75 years) was evaluated on technical performance (accuracy of conversational exchanges) engagement (number of weekly check-ins completed) adherence (percentage of step goal and recommended food servings) and user feedback. Paola correctly asked scripted questions and responded to participants during the check-ins 97% and 96% of the time respectively but correctly responded to spontaneous exchanges only 21% of the time. Participants completed 63% of weekly check-ins and conducted a total of 3648 exchanges. Mean dietary adherence was 91% and was lowest for discretionary foods grains red meat and vegetables. Participants met their step goal 59% of the time. Participants enjoyed the program and found Paola useful during check-ins but not for spontaneous exchanges. More in-depth knowledge personalized advice and spontaneity were identified as important improvements. Virtual health assistants should ensure an adequate knowledge base and ability to recognize intents and entities include personality and spontaneity and provide ongoing technical troubleshooting of the virtual assistant to ensure the assistant remains effective.;2020
As a crucial task in conversation systems response generation for multi-turn conversation aims to generate a coherent informative and diverse response according to the conversation context. Existing models of this task are limited in their ability to capture long-term dependencies within and between utterances and to identify pertinent or important information in the context. Inspired by the Transformer neural network based solely on attention mechanisms recently proposed in machine translation we propose a novel hierarchical structured multi-head attention network (HMAN) model to address both problems. Specifically the context sequences are encoded in a hierarchical structure in which multi-head self-attention is first employed to compute the representation matrix of each utterance and then these utterance matrices are integrated to form a context representation with the complicated dependencies learned using multi-head attention. The experimental results on two public conversation datasets demonstrate that our proposed model significantly outperforms several state-of-the-art baselines with respect to both automatic evaluation and human evaluation and can generate more diverse and informative responses.;2020
As agents social robots are expected to increase opportunities for dialogue with the elderly. However it is difficult to sustain a dialogue with an elderly user because speech recognition frequently fails during the dialogue. Here to overcome this problem regardless of speech recognition failure we developed a question-answer-response dialogue model. In this model a robot took initiative in the dialogue by asking the user various questions. Moreover to improve user experience during dialogue we extended the model such that two robots could participate in the dialogue. Implementing these features we conducted a field trial in a nursing home to evaluate the twin-robot dialogue system. The average word error rate of speech recognition was 0.778. Despite the frequently high number of errors participants talked for 14 min in a dialogue with two robots and felt slightly strange during the dialogue. Although we found no significant difference between a dialogue with one robot and that with two robots the effect size of the difference in the dialogue time with one robot and that with two robots was medium (Cohen's d = -0.519). The results suggested that the presence of two robots might likely encourage elderly people to sustain the talk. Our results will contribute to the design of social robots to engage in dialogues with the elderly.;2020
As life expectancy increases it has become more necessary to find ways to support healthy ageing. A number of active ageing initiatives are being developed nowadays to foster healthy habits in the population. This paper presents our contribution to these initiatives in the form of a multimodal conversational coach that acts as a coach for physical activities. The agent can be developed as an Android app running on smartphones and coupled with cheap widely available sport sensors in order to provide meaningful coaching. It can be employed to prepare exercise sessions provide feedback during the sessions and discuss the results after the exercise. It incorporates an affective component that informs dynamic user models to produce adaptive interaction strategies.;2020
As the coronavirus disease 2019 (COVID-19) pandemic rages on the mental health of both the infected and non-infected is a rising concern. We used administrative survey data (16402 responses in the last two weeks) using a chatbot on LINE the most popular social networking service (SNS) in Japan to show that people with COVID-19 patients in a close setting had higher psychological distress level than those without. We believe that the results indicate an urgent need to prioritize the establishment and implementation of mental health and psychosocial support tailored to family close relatives and friends of COVID-19 patients.;2020
As the inclusion of users in the design process receives greater attention designers need to not only understand users but also further cooperate with them. Therefore engineering design education should also follow this trend in order to enhance students' ability to communicate and cooperate with users in the design practice. However it is difficult to find users on teaching sites to cooperate with students because of time and budgetary constraints. With the development of artificial intelligence (AI) technology in recent years chatbots may be the solution to finding specific users to participate in teaching. This study used Dialogflow and Google Assistant to build a system architecture and applied methods of persona and semi-structured interviews to develop AI virtual product users. The system has a compound dialog mode (combining intent- and flow-based dialog modes) with which multiple chatbots can cooperate with students in the form of oral dialog. After four college students interacted with AI userbots it was proven that this system can effectively participate in student design activities in the early stage of design. In the future more AI userbots could be developed based on this system according to different engineering design projects for engineering design teaching.;2020
Automatically generating meaningful and coherent text has many applications such as machine translation dialogue systems BOT application etc. Text generation technology has attracted more attention over the past decades. A bunch of excellent methods are proposed however there are still challenges to generate text rivals the real one by human such as most machines output fixed length text or can only generate text quite the same with the input training text. In this paper we put forward a novel text generation system called customizable conditional text generative adversarial network which is capable of generating diverse text content of variable length with customizable emotion label. It is more convenient for generating actual original text with specific sensitive orientation. We propose a conditional text generative adversarial network (CTGAN) in which emotion label is adopted as an input channel to specify the output text and variable length text generation strategy is put forward. After generating initial texts by CTGAN to make the generated text data match the real scene we design an automated word-level replacement strategy which extracts the keywords (e.g. nouns) from the training texts and replaces the specific keywords in the generated texts. Finally we design a comprehensive evaluation metric based on various text evaluations called mixed evaluation metric. Comprehensive experiments on real-world datasets testify that our proposed CTGAN behaves better than other text generation methods i.e. generated text are more real compared with the real text than other generation methods achieving state-of-the-art generation performance. (C) 2019 Elsevier B.V. All rights reserved.;2020
Background Artificial Intelligent Virtual Assistants (AIVA) is a segment of artificial intelligence that is rapidly developing. However its utilization to address patients' frequently asked questions remains unexplored. Methods We developed an AIVA to answer questions related to 10 frequent topics asked by plastic surgery patients in our institution. Between July 27 2018 and August 10 of 2018 we recruited subjects with administrative positions at our health care institution to chat with the virtual assistant. They asked with their own words 1 question for each topic and filled out a satisfaction questionnaire. Postsurvey analysis of questions and answers allowed assessment of the virtual assistant's accuracy. Results Thirty participants completed the survey. The majority was female (70%) and the mean age was 27.76 years (SD 8.68 [19-51] years). The overall accuracy of the plastic surgery AIVA was 92.3% (277/294 questions) and participants considered the answer correct in 83.3% of the time (250/294 answers). Most of the participants considered the AIVA easy to use answered adequately and could be helpful for patients. However when asked if this technology could replace a human assistant they stayed neutral.;2020
Background Artificial intelligence (AI) is said to be transforming mental health. AI-based technologies and technique are now considered to have uses in almost every domain of mental health care: including decision-making assessment and healthcare management. What remains underexplored is whether/how mental health recovery is situated within these discussions and practices. Method Taking conversational agents as our point of departure we explore the ways official online materials explain and make sense of chatbots their imagined functionality and value for (potential) users. We focus on three chatbots for mental health: Woebot Wysa and Tess. Findings Recovery is largely missing as an overt focus across materials. However analysis does reveal themes that speak to the struggles over practice expertise and evidence that the concept of recovery articulates. We discuss these under the headings troubled clinical responsibility extended virtue of (technological) self-care and altered ontologies and psychopathologies of time. Conclusions Ultimately we argue that alongside more traditional forms of recovery chatbots may be shaped by and shaping an increasingly individualised form of a personal recovery imperative.;2020
Background For patients with cancer being well informed by their oncologist about treatment options and the implications thereof is highly relevant. Communication skills training (CST) programs have shown to be effective in improving clinicians' communication skills yet CSTs are time-consuming inconvenient to schedule and costly. Online education enables new ways of accessible learning in a safe and personalised environment. Aim and methods We describe the design of a digital CST-tool for information provision skills that meets oncologists' learning needs. We used the CeHRes Roadmap for user-centred design as a guiding framework. Phase 1 (Contextual Inquiry) involved consultation of the literature and a focus group interview study to uncover the learning needs and training preferences of clinicians' regarding a digital training for the skill of information-provision. In phase 2 (Value Specification) two multidisciplinary expert panels specified the learning content and format of a digital training. Phase 3 (Design) encompassed an iterative development process including two user group assessment sessions and 5 individual user sessions in which prototypes were tested. All sessions were recorded and independently analyzed by two researchers. Results Based on literature and consultation of the users in the inquiry phase of the development process and on expert opinion in the value specification phase relevant (sub) skills and user requirements were defined to consider for the digital training format. It was decided to develop a conventional e-learning and a chatbot. Personalization and interactivity were integrated in the prototypes by including features that allow for e.g. choosing text video or animation to upload video-recorded consultations to receive peer-feedback and to consult a communication expert. Results revealed that overall participants expressed a willingness to use a digital training tool to acquire information-provision skills. Individual user testing (including junior clinicians) indicated a preference for the chatbot over the e-learning. Conclusion We offer a description of extensive development work which was conducted in collaboration with multiple health care professionals to iteratively develop two innovative prototypes of digital tools that would appropriately engage oncologists in learning effective information giving skills. The resulting prototypes were well appreciated and thus provide a solid basis for further development and testing.;2020
Background Preconception care focuses on improving women's health before pregnancy as a means to improve their health and future pregnancy outcomes. How to effectively deliver such care is unknown. The aim of this research was to assess the impact of an embodied conversational agent system on preconception risks among African American and Black women. Methods We did an open-label randomised controlled trial of women aged 18-34 years self-identified as African American or Black or both and not pregnant recruited from 35 states in the USA. Sealed allocation envelopes (in permuted blocks of six and eight prepared using a random number generator) were opened after enrolment. Intervention participants received an online conversational agent called Gabby that assessed 102 preconception risks and delivered 12 months of tailored dialogue using synthesised speech non-verbal behaviour visual aids and health behaviour change techniques such as motivational interviewing. The control group received a letter listing their preconception risks and encouraging them to talk with a clinician. The primary outcome was the proportion of identified risks at the action or maintenance stage of change at months 6 and 12. The study is registered with ClinicalTrials.gov NCT01827215. Findings From March 11 2014 through July 8 2018 528 women recruited from 35 states and 242 cities across the USA received the Gabby intervention (n=262) or were assigned to the control group (n=266). Participants identified a mean of 21 preconception risks per woman (SD 9.9). In the intention-to-treat analysis at 6 months intervention women reported reaching the action or maintenance stage of change for 50.0% (SD 28.9) of those preconception risks identified compared with 42.7% (28.3) in the control group (incidence rate ratio 1.16 95% CI 1.07-1.26 p=0.0004). This result persisted at 12 months. Interpretation The Gabby system has the potential to improve women's preconception health. Further research is needed to determine if improving preconception risks impacts outcomes such as preterm delivery. Copyright (c) 2020 The Author(s). Published by Elsevier Ltd.;2020
Background Previously we introduced our Patient Health Information Dialogue Ontology (PHIDO) that manages the dialogue and contextual information of the session between an agent and a health consumer. In this study we take the next step and introduce the Conversational Ontology Operator (COO) the software engine harnessing PHIDO. We also developed a question-answering subsystem called Frankenstein Ontology Question-Answering for User-centric Systems (FOQUS) to support the dialogue interaction. Methods We tested both the dialogue engine and the question-answering system using application-based competency questions and questions furnished from our previous Wizard of OZ simulation trials. Results Our results revealed that the dialogue engine is able to perform the core tasks of communicating health information and conversational flow. Inter-rater agreement and accuracy scores among four reviewers indicated perceived acceptable responses to the questions asked by participants from the simulation studies yet the composition of the responses was deemed mediocre by our evaluators. Conclusions Overall we present some preliminary evidence of a functioning ontology-based system to manage dialogue and consumer questions. Future plans for this work will involve deploying this system in a speech-enabled agent to assess its usage with potential health consumer users.;2020
Background The Assistant to Lift your Level of activitY (Ally) app is a smartphone application that combines financial incentives with chatbot-guided interventions to encourage users to reach personalized daily step goals. Purpose To evaluate the effects of incentives weekly planning and daily self-monitoring prompts that were used as intervention components as part of the Ally app. Methods We conducted an 8 week optimization trial with n = 274 insurees of a health insurance company in Switzerland. At baseline participants were randomized to different incentive conditions (cash incentives vs. charity incentives vs. no incentives). Over the course of the study participants were randomized weekly to different planning conditions (action planning vs. coping planning vs. no planning) and daily to receiving or not receiving a self-monitoring prompt. Primary outcome was the achievement of personalized daily step goals. Results Study participants were more active and healthier than the general Swiss population. Daily cash incentives increased step-goal achievement by 8.1% 95% confidence interval (CI): [2.1 14.1] and only in the no-incentive control group action planning increased step-goal achievement by 5.8% 95% CI: [1.2 10.4]. Charity incentives self-monitoring prompts and coping planning did not affect physical activity. Engagement with planning interventions and self-monitoring prompts was low and 30% of participants stopped using the app over the course of the study. Conclusions Daily cash incentives increased physical activity in the short term. Planning interventions and self-monitoring prompts require revision before they can be included in future versions of the app. Selection effects and engagement can be important challenges for physical-activity apps.;2020
Background The digital assistant Vigo is a computer-generated artificial intelligence-based application that serves as a digital assistant to a stroke patient and his family. With its conversational chatbot and gamification elements it counsels educates and trains the stroke patient and patient's family on stroke rehabilitation care and other related issues. Aim This study describes insights about The digital assitant Vigo usability from a patients' perspective. Methods Twelve patients tested the application at their home environment. Three semi-structured interviews were conducted with each participant to obtain information on the usability of the application. Deductive thematic analyses were used to analyze trancripts. Results Participants expressed their opinions on music pictures video and audio files chat options layout text name of application and stand that is used for placement of devices on which Vigo is installed on. All participants generally evaluated application as transparent understandable and handy. The overall design of the application was rated as good. Participants were mostly unsatisfied with difficulty level and diversity of exercises. Conclusions Participants had a positive attitude towards using tablet tehchnologies in their home environment. Users of digital assistant Vigo acknowledged its ability to support give educational information and increase participation in therapeutic activities.;2020
Background: A large number of web-based COVID-19 symptom checkers and chatbots have been developed however anecdotal evidence suggests that their conclusions are highly variable. To our knowledge no study has evaluated the accuracy of COVID-19 symptom checkers in a statistically rigorous manner. Objective: The aim of this study is to evaluate and compare the diagnostic accuracies of web-based COVID-19 symptom checkers. Methods: We identified 10 web-based COVID-19 symptom checkers all of which were included in the study. We evaluated the COVID-19 symptom checkers by assessing 50 COVID-19 case reports alongside 410 non-COVID-19 control cases. A bootstrapping method was used to counter the unbalanced sample sizes and obtain confidence intervals (CIs). Results are reported as sensitivity specificity F1 score and Matthews correlation coefficient (MCC). Results: The classification task between COVID-19-positive and COVID-19-negative for high risk cases among the 460 test cases yielded (sorted by F1 score): Symptoma (F1=0.92 MCC=0.85) Infermedica (F1=0.80 MCC=0.61) US Centers for Disease Control and Prevention (CDC) (F1=0.71 MCC=0.30) Babylon (F1=0.70 MCC=0.29) Cleveland Clinic (F1=0.40 MCC=0.07) Providence (F1=0.40 MCC=0.05) Apple (F1=0.29 MCC=-0.10) Docyet (F1=0.27 MCC=0.29) Ada (F1=0.24 MCC=0.27) and Your.MD (F1=0.24 MCC=0.27). For high risk and medium risk combined the performance was: Symptoma (F1=0.91 MCC=0.83) Infermedica (F1=0.80 MCC=0.61) Cleveland Clinic (F1=0.76 MCC=0.47) Providence (F1=0.75 MCC=0.45) Your.MD (F1=0.72 MCC=0.33) CDC (F1=0.71 MCC=0.30) Babylon (F1=0.70 MCC=0.29) Apple (F1=0.70 MCC=0.25) Ada (F1=0.42 MCC=0.03) and Docyet (F1=0.27 MCC=0.29). Conclusions: We found that the number of correctly assessed COVID-19 and control cases varies considerably between symptom checkers with different symptom checkers showing different strengths with respect to sensitivity and specificity. A good balance between sensitivity and specificity was only achieved by two symptom checkers.;2020
Background: A rising number of conversational agents or chatbots are equipped with artificial intelligence (AI) architecture. They are increasingly prevalent in health care applications such as those providing education and support to patients with chronic diseases one of the leading causes of death in the 21st century. AI-based chatbots enable more effective and frequent interactions with such patients. Objective: The goal of this systematic literature review is to review the characteristics health care conditions and AI architectures of AI-based conversational agents designed specifically for chronic diseases. Methods: We conducted a systematic literature review using PubMed MEDLINE EMBASE PyscInfo CINAHL ACM Digital Library ScienceDirect and Web of Science. We applied a predefined search strategy using the terms conversational agent healthcare artificial intelligence and their synonyms. We updated the search results using Google alerts and screened reference lists for other relevant articles. We included primary research studies that involved the prevention treatment or rehabilitation of chronic diseases involved a conversational agent and included any kind of AI architecture. Two independent reviewers conducted screening and data extraction and Cohen kappa was used to measure interrater agreement.A narrative approach was applied for data synthesis. Results: The literature search found 2052 articles out of which 10 papers met the inclusion criteria. The small number of identified studies together with the prevalence of quasi-experimental studies (n=7) and prevailing prototype nature of the chatbots (n=7) revealed the immaturity of the field. The reported chatbots addressed a broad variety of chronic diseases (n=6) showcasing a tendency to develop specialized conversational agents for individual chronic conditions. However there lacks comparison of these chatbots within and between chronic diseases. In addition the reported evaluation measures were not standardized and the addressed health goals showed a large range. Together these study characteristics complicated comparability and open room for future research. While natural language processing represented the most used AI technique (n=7) and the majority of conversational agents allowed for multimodal interaction (n=6) the identified studies demonstrated broad heterogeneity lack of depth of reported AI techniques and systems and inconsistent usage of taxonomy of the underlying AI software further aggravating comparability and generalizability of study results. Conclusions: The literature on AI-based conversational agents for chronic conditions is scarce and mostly consists of quasi-experimental studies with chatbots in prototype stage that use natural language processing and allow for multimodal user interaction. Future research could profit from evidence-based evaluation of the AI-based conversational agents and comparison thereof within and between different chronic health conditions. Besides increased comparability the quality of chatbots developed for specific chronic conditions and their subsequent impact on the target patients could be enhanced by more structured development and standardized evaluation processes.;2020
Background: Acceptance and commitment therapy (ACT) is a pragmatic approach to help individuals decrease avoidable pain. Objective: This study aims to evaluate the effects of ACT delivered via an automated mobile messaging robot on postoperative opioid use and patient-reported outcomes (PROs) in patients with orthopedic trauma who underwent operative intervention for their injuries. Methods: Adult patients presenting to a level 1 trauma center who underwent operative fixation of a traumatic upper or lower extremity fracture and who used mobile phone text messaging were eligible for the study. Patients were randomized in a 1:1 ratio to either the intervention group who received twice-daily mobile phone messages communicating an ACT-based intervention for the first 2 weeks after surgery or the control group who received no messages. Baseline PROs were completed. Two weeks after the operative intervention follow-up was performed in the form of an opioid medication pill count and postoperative administration of PROs. The mean number of opioid tablets used by patients was calculated and compared between groups. The mean PRO scores were also compared between the groups. Results: A total of 82 subjects were enrolled in the study. Of the 82 participants 76 (38 ACT and 38 controls) completed the study. No differences between groups in demographic factors were identified. The intervention group used an average of 26.1 (SD 21.4) opioid tablets whereas the control group used 41.1 (SD 22.0) tablets resulting in 36.5% ([41.1-26.1]/41.1) less tablets used by subjects receiving the mobile phone based ACT intervention (P=.004). The intervention group subjects reported a lower postoperative Patient-Reported Outcome Measure Information System Pain Intensity score (mean 45.9 SD 7.2) than control group subjects (mean 49.7 SD 8.8 P=.04). Conclusions: In this study the delivery of an ACT-based intervention via an automated mobile messaging robot in the acute postoperative period decreased opioid use in selected patients with orthopedic trauma. Participants receiving the ACT-based intervention also reported lower pain intensity after 2 weeks although this may not represent a clinically important difference.;2020
Background: Almost half (46%) of Americans have used a smart assistant of some kind (eg Apple Siri) and 25% have used a stand-alone smart assistant (eg Amazon Echo). This positions smart assistants as potentially useful modalities for retrieving health-related information however the accuracy of smart assistant responses lacks rigorous evaluation. Objective: This study aimed to evaluate the levels of accuracy misinformation and sentiment in smart assistant responses to human papillomavirus (HPV) vaccination-related questions. Methods: We systematically examined responses to questions about the HPV vaccine from the following four most popular smart assistants: Apple Siri Google Assistant Amazon Alexa and Microsoft Cortana. One team member posed 10 questions to each smart assistant and recorded all queries and responses. Two raters independently coded all responses (k=0.85). We then assessed differences among the smart assistants in terms of response accuracy presence of misinformation and sentiment regarding the HPV vaccine. Results: A total of 103 responses were obtained from the 10 questions posed across the smart assistants. Google Assistant data were excluded owing to nonresponse. Over half (n=63 61%) of the responses of the remaining three smart assistants were accurate. We found statistically significant differences across the smart assistants (N=103 chi(2)(2) =7.807 P=.02) with Cortana yielding the greatest proportion of misinformation. Siri yielded the greatest proportion of accurate responses (n=26 72%) whereas Cortana yielded the lowest proportion of accurate responses (n=33 54%). Most response sentiments across smart assistants were positive (n=65 64%) or neutral (n=18 18%) but Cortana's responses yielded the largest proportion of negative sentiment (n=7 12%). Conclusions: Smart assistants appear to be average-quality sources for HPV vaccination information with Alexa responding most reliably. Cortana returned the largest proportion of inaccurate responses the most misinformation and the greatest proportion of results with negative sentiments. More collaboration between technology companies and public health entities is necessary to improve the retrieval of accurate health information via smart assistants.;2020
Background: At any given time most smokers in a population are ambivalent with no motivation to quit. Motivational interviewing (MI) is an evidence-based technique that aims to elicit change in ambivalent smokers. MI practitioners are scarce and expensive and smokers are difficult to reach. Smokers are potentially reachable through the web and if an automated chatbot could emulate an MI conversation it could form the basis of a low-cost and scalable intervention motivating smokers to quit. Objective: The primary goal of this study is to design train and test an automated MI-based chatbot capable of eliciting reflection in a conversation with cigarette smokers. This study describes the process of collecting training data to improve the chatbot's ability to generate MI-oriented responses particularly reflections and summary statements. The secondary goal of this study is to observe the effects on participants through voluntary feedback given after completing a conversation with the chatbot. Methods: An interdisciplinary collaboration between an MI expert and experts in computer engineering and natural language processing (NLP) co-designed the conversation and algorithms underlying the chatbot. A sample of 121 adult cigarette smokers in 11 successive groups were recruited from a web-based platform for a single-arm prospective iterative design study. The chatbot was designed to stimulate reflections on the pros and cons of smoking using MI's running head start technique. Participants were also asked to confirm the chatbot's classification of their free-form responses to measure the classification accuracy of the underlying NLP models. Each group provided responses that were used to train the chatbot for the next group. Results: A total of 6568 responses from 121 participants in 11 successive groups over 14 weeks were received. From these responses we were able to isolate 21 unique reasons for and against smoking and the relative frequency of each. The gradual collection of responses as inputs and smoking reasons as labels over the 11 iterations improved the Fl score of the classification within the chatbot from 0.63 in the first group to 0.82 in the final group. The mean time spent by each participant interacting with the chatbot was 21.3 (SD 14.0) min (minimum 6 4 and maximum 89.2). We also found that 34.7% (42/121) of participants enjoyed the interaction with the chatbot and 8.3% (10/121) of participants noted explicit smoking cessation benefits from the conversation in voluntary feedback that did not solicit this explicitly. Conclusions: Recruiting ambivalent smokers through the web is a viable method to train a chatbot to increase accuracy in reflection and summary statements the building blocks of MI. A new set of 21 smoking reasons (both for and against) has been identified. Initial feedback from smokers on the experience shows promise toward using it in an intervention.;2020
Background: Chatbots are applications that can conduct natural language conversations with users. In the medical field chatbots have been developed and used to serve different purposes. They provide patients with timely information that can be critical in some scenarios such as access to mental health resources. Since the development of the first chatbot ELIZA in the late 1960s much effort has followed to produce chatbots for various health purposes developed in different ways. Objective: This study aimed to explore the technical aspects and development methodologies associated with chatbots used in the medical field to explain the best methods of development and support chatbot development researchers on their future work. Methods: We searched for relevant articles in 8 literature databases (IEEE ACM Springer ScienceDirect Embase MEDLINE PsycINFO and Google Scholar). We also performed forward and backward reference checking of the selected articles. Study selection was performed by one reviewer and 50% of the selected studies were randomly checked by a second reviewer. A narrative approach was used for result synthesis. Chatbots were classified based on the different technical aspects of their development. The main chatbot components were identified in addition to the different techniques for implementing each module. Results: The original search returned 2481 publications of which we identified 45 studies that matched our inclusion and exclusion criteria. The most common language of communication between users and chatbots was English (n=23). We identified 4 main modules: text understanding module dialog management module database layer and text generation module. The most common technique for developing text understanding and dialogue management is the pattern matching method (n=18 and n=25 respectively). The most common text generation is fixed output (n=36). Very few studies relied on generating original output. Most studies kept a medical knowledge base to be used by the chatbot for different purposes throughout the conversations. A few studies kept conversation scripts and collected user data and previous conversations. Conclusions: Many chatbots have been developed for medical use at an increasing rate. There is a recent apparent shift in adopting machine learning-based approaches for developing chatbot systems. Further research can be conducted to link clinical outcomes to different chatbot development techniques and technical characteristics.;2020
Background: Chatbots empowered by artificial intelligence (AI) can increasingly engage in natural conversations and build relationships with users. Applying AI chatbots to lifestyle modification programs is one of the promising areas to develop cost-effective and feasible behavior interventions to promote physical activity and a healthy diet. Objective: The purposes of this perspective paper are to present a brief literature review of chatbot use in promoting physical activity and a healthy diet describe the AI chatbot behavior change model our research team developed based on extensive interdisciplinary research and discuss ethical principles and considerations. Methods: We conducted a preliminary search of studies reporting chatbots for improving physical activity and/or diet in four databases in July 2020. We summarized the characteristics of the chatbot studies and reviewed recent developments in human-AI communication research and innovations in natural language processing. Based on the identified gaps and opportunities as well as our own clinical and research experience and findings we propose an AI chatbot behavior change model. Results: Our review found a lack of understanding around theoretical guidance and practical recommendations on designing AI chatbots for lifestyle modification programs. The proposed AI chatbot behavior change model consists of the following four components to provide such guidance: (1) designing chatbot characteristics and understanding user background (2) building relational capacity (3) building persuasive conversational capacity and (4) evaluating mechanisms and outcomes. The rationale and evidence supporting the design and evaluation choices for this model are presented in this paper. Conclusions: As AI chatbots become increasingly integrated into various digital communications our proposed theoretical framework is the first step to conceptualize the scope of utilization in health behavior change domains and to synthesize all possible dimensions of chatbot features to inform intervention design and evaluation. There is a need for more interdisciplinary work to continue developing AI techniques to improve a chatbot's relational and persuasive capacities to change physical activity and diet behaviors with strong ethical principles.;2020
Background: Cognitive behavioral therapy (CBT) is a well-established treatment for panic disorder but many fewer patients receive this treatment compared to medication-based therapy. Mobile app-based interactive CBT using a chatbot can increase patient access to CBT. We performed a preliminary study to determine whether short-term use of a newly developed chatbot is feasible and effective for relieving panic symptoms. Method: Forty-one patients were randomly assigned to either a chatbot group (n = 21) or control group (n = 20) for a period of 4 weeks. The chatbot group was guided in the use of the chatbot application while the control group was provided with a book on panic disorder. Main results: The severity of panic disorder was significantly decreased in the chatbot group but not in the control group. The social phobia score was significantly decreased and the control helplessness score was significantly increased in the chatbot group compared to the control group. Discussion and conclusion: We found that mobile app-based interactive CBT using the chatbot was feasible and effective for reducing the severity of panic symptoms. Using this novel approach to provide CBT would allow clinicians to effect positive therapeutic outcomes with easy accessibility interactivity and self-management for patients with panic symptoms.;2020
Background: Conversational agents (CAs) are systems that mimic human conversations using text or spoken language. Their widely used examples include voice-activated systems such as Apple Siri Google Assistant Amazon Alexa and Microsoft Cortana. The use of CAs in health care has been on the rise but concerns about their potential safety risks often remain understudied. Objective: This study aimed to analyze how commonly available general-purpose CAs on smartphones and smart speakers respond to health and lifestyle prompts (questions and open-ended statements) by examining their responses in terms of content and structure alike. Methods: We followed a piloted script to present health- and lifestyle-related prompts to 8 CAs. The CAs' responses were assessed for their appropriateness on the basis of the prompt type: responses to safety-critical prompts were deemed appropriate if they included a referral to a health professional or service whereas responses to lifestyle prompts were deemed appropriate if they provided relevant information to address the problem prompted. The response structure was also examined according to information sources (Web search-based or precoded) response content style (informative and/or directive) confirmation of prompt recognition and empathy. Results: The 8 studied CAs provided in total 240 responses to 30 prompts. They collectively responded appropriately to 41% (46/112) of the safety-critical and 39% (37/96) of the lifestyle prompts. The ratio of appropriate responses deteriorated when safety-critical prompts were rephrased or when the agent used a voice-only interface. The appropriate responses included mostly directive content and empathy statements for the safety-critical prompts and a mix of informative and directive content for the lifestyle prompts. Conclusions: Our results suggest that the commonly available general-purpose CAs on smartphones and smart speakers with unconstrained natural language interfaces are limited in their ability to advise on both the safety-critical health prompts and lifestyle prompts. Our study also identified some response structures the CAs employed to present their appropriate responses. Further investigation is needed to establish guidelines for designing suitable response structures for different prompt types.;2020
Background: Conversational agents also known as chatbots are computer programs designed to simulate human text or verbal conversations. They are increasingly used in a range of fields including health care. By enabling better accessibility personalization and efficiency conversational agents have the potential to improve patient care. Objective: This study aimed to review the current applications gaps and challenges in the literature on conversational agents in health care and provide recommendations for their future research design and application. Methods: We performed a scoping review. A broad literature search was performed in MEDLINE (Medical Literature Analysis and Retrieval System Online Ovid) EMBASE (Excerpta Medica database Ovid) PubMed Scopus and Cochrane Central with the search terms conversational agents conversational AI chatbots and associated synonyms. We also searched the gray literature using sources such as the OCLC (Online Computer Library Center) WorldCat database and ResearchGate in April 2019. Reference lists of relevant articles were checked for further articles. Screening and data extraction were performed in parallel by 2 reviewers. The included evidence was analyzed narratively by employing the principles of thematic analysis. Results: The literature search yielded 47 study reports (45 articles and 2 ongoing clinical trials) that matched the inclusion criteria. The identified conversational agents were largely delivered via smartphone apps (n=23) and used free text only as the main input (n=19) and output (n=30) modality. Case studies describing chatbot development (n=18) were the most prevalent and only 11 randomized controlled trials were identified. The 3 most commonly reported conversational agent applications in the literature were treatment and monitoring health care service support and patient education. Conclusions: The literature on conversational agents in health care is largely descriptive and aimed at treatment and monitoring and health service support. It mostly reports on text-based artificial intelligence-driven and smartphone app-delivered conversational agents. There is an urgent need for a robust evaluation of diverse health care conversational agents' formats focusing on their acceptability safety and effectiveness.;2020
Background: Delivering self-management support to people with type 2 diabetes mellitus is essential to reduce the health system burden and to empower people with the skills knowledge and confidence needed to take an active role in managing their own health. Objective: This study aims to evaluate the adoption use and effectiveness of the My Diabetes Coach (MDC) program an app-based interactive embodied conversational agent Laura designed to support diabetes self-management in the home setting over 12 months. Methods: This randomized controlled trial evaluated both the implementation and effectiveness of the MDC program. Adults with type 2 diabetes in Australia were recruited and randomized to the intervention arm (MDC) or the control arm (usual care). Program use was tracked over 12 months. Coprimary outcomes included changes in glycated hemoglobin (HbA(1c)) and health-related quality of life (HRQoL). Data were assessed at baseline and at 6 and 12 months and analyzed using linear mixed-effects regression models. Results: A total of 187 adults with type 2 diabetes (mean 57 years SD 10 years 41.7% women) were recruited and randomly allocated to the intervention (n=93) and control (n=94) arms. MDC program users (92/93 participants) completed 1942 chats with Laura averaging 243 min (SD 212) per person over 12 months. Compared with baseline the mean estimated HbA1c decreased in both arms at 12 months (intervention: 0.33% and control: 0.20%) but the net differences between the two arms in change of HbA(1c) (-0.04% 95% CI -0.45 to 0.36 P=.83) was not statistically significant. At 12 months HRQoL utility scores improved in the intervention arm compared with the control arm (between-arm difference: 0.04 95% CI 0.00 to 0.07 P=.04). Conclusions: The MDC program was successfully adopted and used by individuals with type 2 diabetes and significantly improved the users' HRQoL. These findings suggest the potential for wider implementation of technology-enabled conversation-based programs for supporting diabetes self-management. Future studies should focus on strategies to maintain program usage and HbA(1c) improvement.;2020
Background: Dialog agents (chatbots) have a long history of application in health care where they have been used for tasks such as supporting patient self-management and providing counseling. Their use is expected to grow with increasing demands on health systems and improving artificial intelligence (AI) capability. Approaches to the evaluation of health care chatbots however appear to be diverse and haphazard resulting in a potential barrier to the advancement of the field. Objective: This study aims to identify the technical (nonclinical) metrics used by previous studies to evaluate health care chatbots. Methods: Studies were identified by searching 7 bibliographic databases (eg MEDLINE and PsycINFO) in addition to conducting backward and forward reference list checking of the included studies and relevant reviews. The studies were independently selected by two reviewers who then extracted data from the included studies. Extracted data were synthesized narratively by grouping the identified metrics into categories based on the aspect of chatbots that the metrics evaluated. Results: Of the 1498 citations retrieved 65 studies were included in this review. Chatbots were evaluated using 27 technical metrics which were related to chatbots as a whole (eg usability classifier performance speed) response generation (eg comprehensibility realism repetitiveness) response understanding (eg chatbot understanding as assessed by users word error rate concept error rate) and esthetics (eg appearance of the virtual agent background color and content). Conclusions: The technical metrics of health chatbot studies were diverse with survey designs and global usability metrics dominating The lack of standardization and paucity of objective measures make it difficult to compare the performance of health chatbots and could inhibit advancement of the field. We suggest that researchers more frequently include metrics computed from conversation logs. In addition we recommend the development of a framework of technical metrics with recommendations for specific circumstances for their inclusion in chatbot studies.;2020
Background: Due to time limitations the preanesthetic consultation (PAC) is not the best time for patients to integrate information specific to their perioperative care pathway. Objective: The main objectives of this study were to evaluate the effectiveness of a digital companion on patients' knowledge of anesthesia and their satisfaction after real-life implementation. Methods: We conducted a prospective monocentric comparative study using a before-and-after design. In phase 1 a 9-item self-reported anesthesia knowledge test (Delphi method) was administered to patients before and after their PAC (control group: PAC group). In phase 2 the study was repeated immediately after the implementation of a digital conversational agent MyAnesth (@+PAC group). Patients' satisfaction and their representations for anesthesia were also assessed using a Likert scale and the Abric method of hierarchized evocation. Results: A total of 600 tests were distributed 205 patients and 98 patients were included in the PAC group and @+PAC group respectively. Demographic characteristics and mean scores on the 9-point preinformation test (PAC group: 4.2 points 95% CI 3.9-4.4 @+PAC: 4.3 points 95% CI 4-4.7 P=.37) were similar in the two groups. The mean score after receiving information was better in the @+PAC group than in the PAC group (6.1 points 95% CI 5.8-6.4 points versus 5.2 points 95% CI 5.0-5.4 points respectively P<.001) with an added value of 0.7 points (95% CI 0.3-1.1 P<.001). Among the respondents in the @+PAC group 82% found the information to be clear and appropriate and 74% found it easily accessible. Before receiving information the central core of patients' representations for anesthesia was focused on the fear of being put to sleep and thereafter on caregiver skills and comfort. Conclusions: The implementation of our digital conversational agent in addition to the PAC improved patients' knowledge about their perioperative care pathway. This innovative audiovisual support seemed clear adapted easily accessible and reassuring. Future studies should focus on adapting both the content and delivery of a digital conversational agent for the PAC in order to maximize its benefit to patients.;2020
Background: Embodied conversational agents (ECAs) are animated computer characters that simulate face-to-face counseling. Owing to their capacity to establish and maintain an empathic relationship they are deemed to be a promising tool for starting and maintaining a healthy lifestyle. Objective: This review aimed to identify the current practices in designing and evaluating ECAs for coaching people in a healthy lifestyle and provide an overview of their efficacy (on behavioral knowledge and motivational parameters) and use (on usability usage and user satisfaction parameters). Methods: We used the Arksey and O'Malley framework to conduct a scoping review. PsycINFO Medical Literature Analysis and Retrieval System Online and Scopus were searched with a combination of terms related to ECA and lifestyle. Initially 1789 unique studies were identified 20 studies were included. Results: Most often ECAs targeted physical activity (n=16) and had the appearance of a middle-aged African American woman (n=13). Multiple behavior change techniques (median=3) and theories or principles (median=3) were applied but their interpretation and application were usually not reported. ECAs seemed to be designed for the end user rather than with the end user. Stakeholders were usually not involved. A total of 7 out of 15 studies reported better efficacy outcomes for the intervention group and 5 out of 8 studies reported better use-related outcomes as compared with the control group. Conclusions: ECAs are a promising tool for persuasive communication in the health domain This review provided valuable insights into the current developmental processes and it recommends the use of human-centered stakeholder-inclusive design approaches along with reporting on the design activities in a systematic and comprehensive manner. The gaps in knowledge were identified on the working mechanisms of intervention components and the right timing and frequency of coaching.;2020
Background: Embodied conversational agents (ECAs) are increasingly used in health care apps however their acceptability in type 2 diabetes (T2D) self-management apps has not yet been investigated. Objective: This study aimed to evaluate the acceptability of the ECA (Laura) used to deliver diabetes self-management education and support in the My Diabetes Coach (MDC) app. Methods: A sequential mixed methods design was applied. Adults with T2D allocated to the intervention arm of the MDC trial used the MDC app over a period of 12 months. At 6 months they completed questions assessing their interaction with and attitudes toward the ECA. In-depth qualitative interviews were conducted with a subsample of the participants from the intervention arm to explore their experiences of using the ECA. The interview questions included the participants' perceptions of Laura including their initial impression of her (and how this changed over time) her personality and human character. The quantitative and qualitative data were interpreted using integrated synthesis. Results: Of the 93 intervention participants 44 (47%) were women the mean (SD) age of the participants was 55 (SD 10) years and the baseline glycated hemoglobin A1c level was 7.3% (SD 1.5%). Overall 66 of the 93 participants (71%) provided survey responses. Of these most described Laura as being helpful (57/66 86%) friendly (57/66 86%) competent (56/66 85%) trustworthy (48/66 73%) and likable (40/66 61%). Some described Laura as not real (18/66 27%) boring (26/66 39%) and annoying (20/66 30%). Participants reported that interacting with Laura made them feel more motivated (29/66 44%) comfortable (24/66 36%) confident (14/66 21%) happy (11/66 17%) and hopeful (8/66 12%). Furthermore 20% (13/66) of the participants were frustrated by their interaction with Laura and 17% (11/66) of the participants reported that interacting with Laura made them feel guilty. A total of 4 themes emerged from the qualitative data (N=19): (1) perceived role: a friendly coach rather than a health professional (2) perceived support: emotional and motivational support (3) embodiment preference acceptability of a human-like character and (4) room for improvement: need for greater congruence between Laura's words and actions. Conclusions: These findings suggest that an ECA is an acceptable means to deliver T2D self-management education and support. A human-like character providing ongoing friendly nonjudgmental emotional and motivational support is well received. Nevertheless the ECA can be improved by increasing congruence between its verbal and nonverbal communication and accommodating user preferences.;2020
Background: In the absence of widespread testing symptomatic monitoring efforts may allow for understanding the epidemiological situation of the spread of coronavirus disease 2019 (COVID-19) in Japan. We obtained data from a social networking service (SNS) messaging application that monitors self-reported COVID-19 related symptoms in real time in Fukuoka Prefecture Japan. We aimed at not only understanding the epidemiological situation of COVID-19 in the prefecture but also highlighting the usefulness of symptomatic monitoring approaches that rely on self-reporting using SNS during a pandemic and informing the assessment of Japan's emergency declaration over COVID-19. Methods: We analysed symptoms data (fever over 37.5 degrees and a strong feeling of weariness or shortness of breath) reported voluntarily via SNS chatbot by 227898 residents of Fukuoka Prefecture during March 27 to May 3 2020 including April 7 when a state of emergency was declared. We estimated the spatial correlation coefficient between the number of the self-reported cases of COVID-19 related symptoms and the number of PCR confirmed COVID-19 cases in the period (obtained from the prefecture website) and estimated the empirical Bayes age- and sex-standardised incidence ratio (EBSIR) of the symptoms in the period compared before and after the declaration. The number of symptom cases was weighted by age and sex to reflect the regional population distribution according to the 2015 national census. Findings: Of the participants 3.47% reported symptoms. There was a strong spatial correlation of 0.847 (p < 0.001) at municipality level between the weighted number of self-reported symptoms and the number of COVID-19 cases for both symptoms. The EBSIR at post-code level was not likely to change remarkably before and after the declaration of the emergency but the gap in EBSIR between high-risk and low-risk areas appeared to have increased after the declaration. Interpretation: While caution is necessary as the data was limited to SNS users the self-reported COVID-19 related symptoms considered in the study had high epidemiological evaluation ability. In addition though based on visual assessment after the declaration of the emergency regional containment of the infection risk might have strengthened to some extent. SNS which can provide a high level of real-time voluntary symptom data collection can be used to assess the epidemiology of a pandemic as well as to assist in policy assessments such as emergency declarations. (C) 2020 Published by Elsevier Ltd.;2020
Background: In the four months after the discovery of the index case of coronavirus disease (COVID-19) several studies highlighted the psychological impact of COVID-19 on frontline health care workers and on members of the general public. It is evident from these studies that individuals experienced elevated levels of anxiety and depression in the acute phase when they first became aware of the pandemic and that the psychological distress persisted into subsequent weeks. It is becoming apparent that technological tools such as SMS text messages web-based interventions mobile interventions and conversational agents can help ameliorate psychological distress in the workplace and in society. To our knowledge there are few publications describing how digital tools have been used to ameliorate psychological symptoms among individuals. Objective: The aim of this review was to identify existing SMS text message web-based mobile and conversational agents that the general public can access to ameliorate the psychological symptoms they are experiencing during the COVID-19 pandemic. Methods: To identify digital tools that were published specifically for COVID-19 a search was performed in the PubMed and MEDLINE databases from the inception of the databases through June 17 2020. The following search strings were used: NCOV OR 2019-nCoV OR SARS-CoV-2 OR Coronavims OR COVID19 OR COVID and mHealth OR eHealth OR text. Another search was conducted in PubMed and MEDLINE to identify existing digital tools for depression and anxiety disorders. A web-based search engine (Google) was used to identify if the cited web-based interventions could be accessed. A mobile app search engine App Annie was used to determine if the identified mobile apps were commercially available. Results: A total of 6 studies were identified. Of the 6 identified web based interventions 5 websites (83%) could be accessed. Of the 32 identified mobile interventions 7 apps (22%) could be accessed. Of the 7 identified conversational agents only 2 (29%) could be accessed. Results: A total of 6 studies were identified. Of the 6 identified web-based interventions 5 websites (83%) could be accessed. Of the 32 identified mobile interventions 7 apps (22%) could be accessed. Of the 7 identified conversational agents only 2 (29%) could be accessed. Conclusions: The COVID-19 pandemic has caused significant psychological distress. Digital tools that are commercially available may be useful for at-risk individuals or individuals with pre-existing psychiatric symptoms.;2020
Background: Internet-based cognitive-behavioral therapy (iCBT) is more effective when it is guided by human support than when it is unguided. This may be attributable to higher adherence rates that result from a positive effect of the accompanying support on motivation and on engagement with the intervention. This protocol presents the design of a pilot randomized controlled trial that aims to start bridging the gap between guided and unguided interventions. It will test an intervention that includes automated support delivered by an embodied conversational agent (ECA) in the form of a virtual coach. Methods/design: The study will employ a pilot two-armed randomized controlled trial design. The primary outcomes of the trial will be (1) the effectiveness of iCBT as supported by a virtual coach in terms of improved intervention adherence in comparison with unguided iCBT and (2) the feasibility of a future larger-scale trial in terms of recruitment acceptability and sample size calculation. Secondary aims will be to assess the virtual coach's effect on motivation users' perceptions of the virtual coach and general feasibility of the intervention as supported by a virtual coach. We will recruitN = 70 participants from the general population who wish to learn how they can improve their mood by using Moodbuster Lite a 4-week cognitive-behavioral therapy course. Candidates with symptoms of moderate to severe depression will be excluded from study participation. Included participants will be randomized in a 1:1 ratio to either (1) Moodbuster Lite with automated support delivered by a virtual coach or (2) Moodbuster Lite without automated support. Assessments will be taken at baseline and post-study 4 weeks later. Discussion: The study will assess the preliminary effectiveness of a virtual coach in improving adherence and will determine the feasibility of a larger-scale RCT. It could represent a significant step in bridging the gap between guided and unguided iCBT interventions.;2020
Background: Lack of time for exercise is common among office workers given their busy lives. Because of occupational restrictions and difficulty in taking time off it is necessary to suggest effective ways for workers to exercise regularly. Sustaining lifestyle habits that increase nonexercise activity in daily life can solve the issue of lack of exercise time. Healthy Lifestyle Coaching Chatbot is a messenger app based on the habit formation model that can be used as a tool to provide a health behavior intervention that emphasizes the importance of sustainability and involvement. Objective: This study aimed to assess the efficacy of the Healthy Lifestyle Coaching Chatbot intervention presented via a messenger app aimed at stair-climbing habit formation for office workers. Methods: From February 1 2018 to April 30 2018 a total of 106 people participated in the trial after online recruitment. Participants were randomly assigned to the intervention group (n=57) or the control group (n=49). The intervention group received cues and intrinsic and extrinsic rewards for the entire 12 weeks. However the control group did not receive intrinsic rewards for the first 4 weeks and only received all rewards as in the intervention group from the fifth to twelfth week. The Self-Report Habit Index (SRHI) of participants was evaluated every week and the level of physical activity was measured at the beginning and end of the trial. SPSS Statistics version 21 (IBM Corp) was used for statistical analysis. Results: After 4 weeks of intervention without providing the intrinsic rewards in the control group the change in SRHI scores was 13.54 (SD 14.99) in the intervention group and 6.42 (SD 9.42) in the control group indicating a significant difference between the groups (P=.04). When all rewards were given to both groups from the fifth to twelfth week the change in SRHI scores of the intervention and control groups was comparable at 12.08 (SD 10.87) and 15.88 (SD 13.29) respectively (P=.21). However the level of physical activity showed a significant difference between the groups after 12 weeks of intervention (P=.045). Conclusions: This study provides evidence that intrinsic rewards are important to enhance the sustainability and effectiveness of an intervention. The Healthy Lifestyle Coaching Chatbot program can be a cost-effective method for healthy habit formation.;2020
Background: On April 7 2020 the Japanese government declared a state of emergency regarding the novel coronavirus (COVID-19). Given the nation-wide spread of the coronavirus in major Japanese cities and the rapid increase in the number of cases with untraceable infection routes large-scale monitoring for capturing the current epidemiological situation of COVID-19 in Japan is urgently required. Methods: A chatbot-based healthcare system named COOPERA (COvid-19: Operation for Personalized Empowerment to Render smart prevention And AN care seeking) was developed to surveil the Japanese epidemiological situation in real-time. COOPERA asked questions regarding personal information location preventive actions COVID-19 related symptoms and their residence. Empirical Bayes estimates of the age-sex-standardized incidence rate and disease mapping approach using scan statistics were utilized to identify the geographical distribution of the symptoms in Tokyo and their spatial correlation r with the identified COVID-19 cases. Findings: We analyzed 353010 participants from Tokyo recruited from 27th March to 6th April 2020. The mean (SD) age of participants was 42.7 (12.3) and 63.4% 36.4% or 0.2% were female male or others respectively. 95.6% of participants had no subjective symptoms. We identified several geographical clusters with high spatial correlation (r = 0.9) especially in downtown areas in central Tokyo such as Shibuya and Shinjuku. Interpretation: With the global spread of COVID-19 medical resources are being depleted. A new system to monitor the epidemiological situation COOPERA can provide insights to assist political decision to tackle the epidemic. In addition given that Japan has not had a strong lockdown policy to weaken the spread of the infection our result would be useful for preparing for the second wave in other countries during the next flu season without a strong lockdown. (C) 2020 The Authors. Published by Elsevier Ltd.;2020
Background: Ongoing pain is one of the most common diseases and has major physical psychological social and economic impacts. A mobile health intervention utilizing a fully automated text-based health care chatbot (TBHC) may offer an innovative way not only to deliver coping strategies and psychoeducation for pain management but also to build a working alliance between a participant and the TBHC. Objective: The objectives of this study are twofold: (1) to describe the design and implementation to promote the chatbot painSELfMAnagement (SELMA) a 2-month smartphone-based cognitive behavior therapy (CBT) TBHC intervention for pain self-management in patients with ongoing or cyclic pain and (2) to present findings from a pilot randomized controlled trial in which effectiveness influence of intention to change behavior pain duration working alliance acceptance and adherence were evaluated. Methods: Participants were recruited online and in collaboration with pain experts and were randomized to interact with SELMA for 8 weeks either every day or every other day concerning CBT-based pain management (n=59) or weekly concerning content not related to pain management (n=43). Pain-related impairment (primary outcome) general well-being pain intensity and the bond scale of working alliance were measured at baseline and postintervention. Intention to change behavior and pain duration were measured at baseline only and acceptance postintervention was assessed via self-reporting instruments. Adherence was assessed via usage data. Results: From May 2018 to August 2018 311 adults downloaded the SELMA app 102 of whom consented to participate and met the inclusion criteria. The average age of the women (88/102 86.4%) and men (14/102 13.6%) participating was 43.7 (SD 12.7) years. Baseline group comparison did not differ with respect to any demographic or clinical variable. The intervention group reported no significant change in pain-related impairment (P=.68) compared to the control group postintervention. The intention to change behavior was positively related to pain-related impairment (P=.01) and pain intensity (P=.01). Working alliance with the TBHC SELMA was comparable to that obtained in guided internet therapies with human coaches. Participants enjoyed using the app perceiving it as useful and easy to use. Participants of the intervention group replied with an average answer ratio of 0.71 (SD 0.20) to 200 (SD 58.45) conversations initiated by SELMA. Participants' comments revealed an appreciation of the empathic and responsible interaction with the TBHC SELMA. A main criticism was that there was no option to enter free text for the patients' own comments. Conclusions: SELMA is feasible as revealed mainly by positive feedback and valuable suggestions for future revisions. For example the participants' intention to change behavior or a more homogenous sample (eg with a specific type of chronic pain) should be considered in further tailoring of SELMA.;2020
Background: Patient follow-up is an essential part of hospital ward management. With the development of deep learning algorithms individual follow-up assignments might be completed by artificial intelligence (AI). We developed an AI-assisted follow-up conversational agent that can simulate the human voice and select an appropriate follow-up time for quantitative automatic and personalized patient follow-up. Patient feedback and voice information could be collected and converted into text data automatically. Objective: The primary objective of this study was to compare the cost-effectiveness of AI-assisted follow-up to manual follow-up of patients after surgery. The secondary objective was to compare the feedback from AI-assisted follow-up to feedback from manual follow-up. Methods: The AI-assisted follow-up system was adopted in the Orthopedic Department of Peking Union Medical College Hospital in April 2019. A total of 270 patients were followed up through this system. Prior to that 2656 patients were followed up by phone calls manually Patient characteristics telephone connection rate follow-up rate feedback collection rate time spent and feedback composition were compared between the two groups of patients. Results: There was no statistically significant difference in age gender or disease between the two groups. There was no significant difference in telephone connection rate (manual . 2478/2656 93.3% AI-assisted: 249/270 92.2% P=.50) or successful follow-up rate (manual: 2301/2478 92.9% AI-assisted: 231/249 92.8% P=.96) between the two groups. The time spent on 100 patients in the manual follow-up group was about 9.3 hours. In contrast the time spent on the AI-assisted follow-up was close to 0 hours. The feedback rate in the AI-assisted follow-up group was higher than that in the manual follow-up group (manual: 68/2656 2.5% AI-assisted: 28/270 10.3% P<.001). The composition of feedback was different in the two groups. Feedback from the AI-assisted follow-up group mainly included nursing health education and hospital environment content while feedback from the manual follow-up group mostly included medical consultation content. Conclusions: The effectiveness of AI-assisted follow-up was not inferior to that of manual follow-up. Human resource costs are saved by AI. AI can help obtain comprehensive feedback from patients although its depth and pertinence of communication need to be improved.;2020
Background: People have insufficient knowledge and many misconceptions about the blood donation process which hampers donors recruitment. Therefore novel strategies and resources are needed to provide information and improve these circumstances. Objective: We aimed at an interactive conversational agent to explain about blood donation. Methods: We used the Dialogflow framework to develop a conversational agent and deployed it publicly. Afterward we conducted an assessment of user experience (UX) with 50 participants who interacted with the agent. We analyzed participants' opinions the different UX scales and their association with participants' demographic variables. Results: The conversational agent is available on the Google Assistant platform in Brazil. It is capable of responding to utterances related to 30 common questions and concerns about donating blood. The user can interact and explore freely and in any order by typing speaking and selecting interface elements. The agent responds by speaking and displaying visual information some multimedia content and suggestions for continuing the dialogue. It enables a conversational sequence in which knowledge is imparted to the user in stages as the dialogue evolves. The overall UX assessed was very satisfactory and people with specific demographic characteristics were more likely to have better UX. All participants had positive opinions and attitudes towards the conversational agent. Conclusions: A conversational agent is a creative and captivating strategy of imparting knowledge and engage people regarding blood donation. The findings reaffirm the potential of using this technology for information outreach especially for socially relevant purposes.;2020
Background: Poor diet and physical inactivity are leading modifiable causes of death and disease. Advances in artificial intelligence technology present tantalizing opportunities for creating virtual health coaches capable of providing personalized support at scale. Objective: This proof of concept study aimed to test the feasibility (recruitment and retention) and preliminary efficacy of physical activity and Mediterranean-style dietary intervention (MedLiPal) delivered via artificially intelligent virtual health coach. Methods: This 12-week single-arm pre-post study took place in Adelaide Australia from March to August 2019. Participants were inactive community-dwelling adults aged 45 to 75 years recruited through news stories social media posts and flyers. The program included access to an artificially intelligent chatbot Paola who guided participants through a computer-based individualized introductory session weekly check-ins and goal setting and was available 24/7 to answer questions. Participants used a Garmin Vivofit4 tracker to monitor daily steps a website with educational materials and recipes and a printed diet and activity log sheet. Primary outcomes included feasibility (based on recruitment and retention) and preliminary efficacy for changing physical activity and diet. Secondary outcomes were body composition (based on height weight and waist circumference) and blood pressure. Results: Over 4 weeks 99 potential participants registered expressions of interest with 81 of those screened meeting eligibility criteria. Participants completed a mean of 109.8 (95% CI 1.9-217.7) more minutes of physical activity at week 12 compared with baseline. Mediterranean diet scores increased from a mean of 3.8 out of 14 at baseline to 9.6 at 12 weeks (mean improvement 5.7 points 95% CI 4.2-7.3). After 12 weeks participants lost an average 1.3 kg (95% CI -0.1 to -2.5 kg) and 2.1 cm from their waist circumference (95% CI -3.5 to -0.7 cm). There were no significant changes in blood pressure. Feasibility was excellent in terms of recruitment retention (90% at 12 weeks) and safety (no adverse events). Conclusions: An artificially intelligent virtual assistant-led lifestyle-modification intervention was feasible and achieved measurable improvements in physical activity diet and body composition at 12 weeks. Future research examining artificially intelligent interventions at scale and for other health purposes is warranted.;2020
Background: Pressure on the US health care system has been increasing due to a combination of aging populations rising health care expenditures and most recently the COVID-19 pandemic. Responses to this pressure are hindered in part by reliance on a limited supply of highly trained health care professionals creating a need for scalable technological solutions. Digital symptom checkers are artificial intelligence-supported software tools that use a conversational chatbot format to support rapid diagnosis and consistent triage. The COVID-19 pandemic has brought new attention to these tools due to the need to avoid face-to-face contact and preserve urgent care capacity. However evidence-based deployment of these chatbots requires an understanding of user demographics and associated triage recommendations generated by a large general population. Objective: In this study we evaluate the user demographics and levels of triage acuity provided by a symptom checker chatbot deployed in partnership with a large integrated health system in the United States. Methods: This population-based descriptive study included all web-based symptom assessments completed on the website and patient portal of the Sutter Health system (24 hospitals in Northern California) from April 24 2019 to February 1 2020. User demographics were compared to relevant US Census population data. Results: A total of 26646 symptom assessments were completed during the study period. Most assessments (17816/26646 66.9%) were completed by female users. The mean user age was 34.3 years (SD 14.4 years) compared to a median age of 37.3 years of the general population. The most common initial symptom was abdominal pain (2060/26646 7.7%). A substantial number of assessments (12357/26646 46.4%) were completed outside of typical physician office hours. Most users were advised to seek medical care on the same day (7299/26646 27.4%) or within 2-3 days (6301/26646 23.6%). Over a quarter of the assessments indicated a high degree of urgency (7723/26646 29.0%). Conclusions: Users of the symptom checker chatbot were broadly representative of our patient population although they skewed toward younger and female users. The triage recommendations were comparable to those of nurse-staffed telephone triage lines. Although the emergence of COVID-19 has increased the interest in remote medical assessment tools it is important to take an evidence-based approach to their deployment.;2020
Background: Previous research suggests that artificial agents may be a promising source of social support for humans However the bulk of this research has been conducted in the context of social support interventions that specifically address stressful situations or health improvements. Little research has examined social support received from artificial agents in everyday contexts. Objective: Considering that social support manifests in not only crises but also everyday situations and that everyday social support forms the basis of support received during more stressful events we aimed to investigate the types of everyday social support that can be received from artificial agents. Methods: In Study 1 we examined publicly available user reviews (N=1854) of Replika a popular companion chatbot. In Study 2 a sample (n=66) of Replika users provided detailed open-ended responses regarding their experiences of using Replika. We conducted thematic analysis on both datasets to gain insight into the kind of everyday social support that users receive through interactions with Replika. Results: Replika provides some level of companionship that can help curtail loneliness provide a safe space in which users can discuss any topic without the fear of judgment or retaliation increase positive affect through uplifting and nurturing messages and provide helpful information/advice when normal sources of informational support are not available. Conclusions: Artificial agents may be a promising source of everyday social support particularly companionship emotional informational and appraisal support but not as tangible support. Future studies are needed to determine who might benefit from these types of everyday social support the most and why. These results could potentially be used to help address global health issues or other crises early on in everyday situations before they potentially manifest into larger issues.;2020
Background: Recent advances in natural language processing and artificial intelligence have led to widespread adoption of speech recognition technologies. In consumer health applications speech recognition is usually applied to support interactions with conversational agents for data collection decision support and patient monitoring. However little is known about the use of speech recognition in consumer health applications and few studies have evaluated the efficacy of conversational agents in the hands of consumers. In other consumer-facing tools cognitive load has been observed to be an important factor affecting the use of speech recognition technologies in tasks involving problem solving and recall. Users find it more difficult to think and speak at the same time when compared to typing pointing and clicking. However the effects of speech recognition on cognitive load when performing health tasks has not yet been explored. Objective: The aim of this study was to evaluate the use of speech recognition for documentation in consumer digital health tasks involving problem solving and recall. Methods: Fifty university staff and students were recruited to undertake four documentation tasks with a simulated conversational agent in a computer laboratory. The tasks varied in complexity determined by the amount of problem solving and recall required (simple and complex) and the input modality (speech recognition vs keyboard and mouse). Cognitive load task completion time error rate and usability were measured. Results: Compared to using a keyboard and mouse speech recognition significantly increased the cognitive load for complex tasks (Z=-4.08 P<.001) and simple tasks (Z=-2.24 P=.03). Complex tasks took significantly longer to complete (Z=-2.52 P=.01) and speech recognition was found to be overall less usable than a keyboard and mouse (Z=-3.30 P=.001). However there was no effect on errors. Conclusions: Use of a keyboard and mouse was preferable to speech recognition for complex tasks involving problem solving and recall. Further studies using a broader variety of consumer digital health tasks of varying complexity are needed to investigate the contexts in which use of speech recognition is most appropriate. The effects of cognitive load on task performance and its significance also need to be investigated.;2020
Background: Respondent engagement of questionnaires in health care is fundamental to ensure adequate response rates for the evaluation of services and quality of care. Conventional survey designs are often perceived as dull and unengaging resulting in negative respondent behavior. It is necessary to make completing a questionnaire attractive and motivating. Objective: The aim of this study is to compare the user experience of a chatbot questionnaire which mimics intelligent conversation with a regular computer questionnaire. Methods: The research took place at the preoperative outpatient clinic. Patients completed both the standard computer questionnaire and the new chatbot questionnaire Afterward patients gave their feedback on both questionnaires by the User Experience Questionnaire which consists of 26 terms to score. Results: The mean age of the 40 included patients (25 [63%] women) was 49 (SD 18-79) years 46.73% (486/1040) of all terms were scored positive for the chatbot. Patients preferred the computer for 7.98% (83/1040) of the terms and for 47.88% (498/1040) of the terms there were no differences. Completion (mean time) of the computer questionnaire took 9.00 minutes by men (SD 2.72) and 7.72 minutes by women (SD 2.60 P=.148). For the chatbot completion by men took 8.33 minutes (SD 2.99) and by women 7.36 minutes (SD 2.61 P=.287). Conclusions: Patients preferred the chatbot questionnaire over the computer questionnaire Time to completion of both questionnaires did not differ though the chatbot questionnaire on a tablet felt more rapid compared to the computer questionnaire This is an important finding because it could lead to higher response rates and to qualitatively better responses in future questionnaires.;2020
Background: Seeking medical information can be an issue for physicians. In the specific context of medical practice chatbots are hypothesized to present additional value for providing information quickly particularly as far as drug risk minimization measures are concerned. Objective: This qualitative study aimed to elicit physicians' perceptions of a pilot version of a chatbot used in the context of drug information and risk minimization measures. Methods: General practitioners and specialists were recruited across France to participate in individual semistructured interviews. Interviews were recorded transcribed and analyzed using a horizontal thematic analysis approach. Results: Eight general practitioners and 2 specialists participated. The tone and ergonomics of the pilot version were appreciated by physicians. However all participants emphasized the importance of getting exhaustive trustworthy answers when interacting with a chatbot. Conclusions: The chatbot was perceived as a useful and innovative tool that could easily be integrated into routine medical practice and could help health professionals when seeking information on drug and risk minimization measures.;2020
Background: The clinical application of voice technology provides novel opportunities in the field of telehealth. However patients' readiness for this solution has not been investigated among patients with cardiovascular diseases (CVD). Objective: This paper aims to evaluate patients' anticipated experiences regarding telemedicine including voice conversational agents combined with provider-driven support delivered by phone. Methods: A cross-sectional study enrolled patients with chronic CVD who were surveyed using a validated investigator-designed questionnaire combining 19 questions (eg demographic data medical history preferences for using telehealth services). Prior to the survey respondents were educated on the telemedicine services presented in the questionnaire while being assisted by a medical doctor. Responses were then collected and analyzed and multivariate logistic regression was used to identify predictors of willingness to use voice technology. Results: In total 249 patients (mean age 65.3 SD 13.8 years 158 [63.5%] men) completed the questionnaire which showed good repeatability in the validation procedure. Of the 249 total participants 209 (83.9%) reported high readiness to receive services allowing for remote contact with a cardiologist (176/249 70.7%) and telemonitoring of vital signs (168/249 67.5%). The voice conversational agents combined with provider-driven support delivered by phone were shown to be highly anticipated by patients with CVD. The readiness to use telehealth was statistically higher in people with previous difficulties accessing health care (OR 2.920 95% CI 1.377-6.192) and was most frequent in city residents and individuals reporting a higher education level. The age and sex of the respondents did not impact the intention to use voice technology (P=.20 and P=.50 respectively). Conclusions: Patients with cardiovascular diseases including both younger and older individuals declared high readiness for voice technology.;2020
Background: The emergence of chatbots in health care is fast approaching. Data on the feasibility of chatbots for chronic disease management are scarce. Objective: This study aimed to explore the feasibility of utilizing natural language processing (NLP) for the categorization of electronic dialog data of patients with inflammatory bowel diseases (IBD) for use in the development of a chatbot. Methods: Electronic dialog data collected between 2013 and 2018 from a care management platform (UCLA eIBD) at a tertiary referral center for IBD at the University of California Los Angeles were used. Part of the data was manually reviewed and an algorithm for categorization was created. The algorithm categorized all relevant dialogs into a set number of categories using NLP. In addition 3 independent physicians evaluated the appropriateness of the categorization. Results: A total of 16453 lines of dialog were collected and analyzed. We categorized 8324 messages from 424 patients into seven categories. As there was an overlap in these categories their frequencies were measured independently as symptoms (2033/6193 32.83%) medications (2397/6193 38.70%) appointments (1518/6193 24.51%) laboratory investigations (2106/6193 34.01%) finance or insurance (447/6193 7.22%) communications (2161/6193 34.89%) procedures (617/6193 9.96%) and miscellaneous (624/6193 10.08%). Furthermore in 95.0% (285/300) of cases there were minor or no differences in categorization between the algorithm and the three independent physicians. Conclusions: With increased adaptation of electronic health technologies chatbots could have great potential in interacting with patients collecting data and increasing efficiency. Our categorization showcases the feasibility of using NLP in large amounts of electronic dialog for the development of a chatbot algorithm. Chatbots could allow for the monitoring of patients beyond consultations and potentially empower and educate patients and improve clinical outcomes.;2020
Background: The global shortage of mental health workers has prompted the utilization of technological advancements such as chatbots to meet the needs of people with mental health conditions. Chatbots are systems that are able to converse and interact with human users using spoken written and visual language. While numerous studies have assessed the effectiveness and safety of using chatbots in mental health no reviews have pooled the results of those studies. Objective: This study aimed to assess the effectiveness and safety of using chatbots to improve mental health through summarizing and pooling the results of previous studies. Methods: A systematic review was carried out to achieve this objective. The search sources were 7 bibliographic databases (eg MEDLINE EMBASE PsycINFO) the search engine Google Scholar and backward and forward reference list checking of the included studies and relevant reviews. Two reviewers independently selected the studies extracted data from the included studies and assessed the risk of bias. Data extracted from studies were synthesized using narrative and statistical methods as appropriate. Results: Of 1048 citations retrieved we identified 12 studies examining the effect of using chatbots on 8 outcomes. Weak evidence demonstrated that chatbots were effective in improving depression distress stress and acrophobia. In contrast according to similar evidence there was no statistically significant effect of using chatbots on subjective psychological wellbeing. Results were conflicting regarding the effect of chatbots on the severity of anxiety and positive and negative affect. Only two studies assessed the safety of chatbots and concluded that they are safe in mental health as no adverse events or harms were reported. Conclusions: Chatbots have the potential to improve mental health. However the evidence in this review was not sufficient to definitely conclude this due to lack of evidence that their effect is clinically important a lack of studies assessing each outcome high risk of bias in those studies and conflicting results for some outcomes. Further studies are required to draw solid conclusions about the effectiveness and safety of chatbots.;2020
Background: The high demand for health care services and the growing capability of artificial intelligence have led to the development of conversational agents designed to support a variety of health-related activities including behavior change treatment support health monitoring training triage and screening support. Automation of these tasks could free clinicians to focus on more complex work and increase the accessibility to health care services for the public. An overarching assessment of the acceptability usability and effectiveness of these agents in health care is needed to collate the evidence so that future development can target areas for improvement and potential for sustainable adoption. Objective: This systematic review aims to assess the effectiveness and usability of conversational agents in health care and identify the elements that users like and dislike to inform future research and development of these agents. Methods: PubMed Medline (Ovid) EMBASE (Excerpta Medica dataBASE) CINAHL (Cumulative Index to Nursing and Allied Health Literature) Web of Science and the Association for Computing Machinery Digital Library were systematically searched for articles published since 2008 that evaluated unconstrained natural language processing conversational agents used in health care. EndNote (version X9 Clarivate Analytics) reference management software was used for initial screening and full-text screening was conducted by 1 reviewer. Data were extracted and the risk of bias was assessed by one reviewer and validated by another. Results: A total of 31 studies were selected and included a variety of conversational agents including 14 chatbots (2 of which were voice chatbots) 6 embodied conversational agents (3 of which were interactive voice response calls virtual patients and speech recognition screening systems) 1 contextual question-answering agent and 1 voice recognition triage system. Overall the evidence reported was mostly positive or mixed. Usability and satisfaction performed well (27/30 and 26/31) and positive or mixed effectiveness was found in three-quarters of the studies (23/30). However there were several limitations of the agents highlighted in specific qualitative feedback. Conclusions: The studies generally reported positive or mixed evidence for the effectiveness usability and satisfactoriness of the conversational agents investigated but qualitative user perceptions were more mixed. The quality of many of the studies was limited and improved study design and reporting are necessary to more accurately evaluate the usefulness of the agents in health care and identify key areas for improvement. Further research should also analyze the cost-effectiveness privacy and security of the agents.;2020
Background: The progressive development of Minimally Invasive Surgery (MIS) implies the need to train health professionals in such field for which e-learning and blended learning methods are increasingly been used. Most nurses lack experience and training in MIS so a laparoscopic blended learning course for nursing has been created. Objectives: To perform the validation of the online theoretical module of such course to evaluate student perception and satisfaction sociability and usability metrics and also the interest of nurses in blended learning. Design: A quantitative design has been used. Participants: 24 nurses participated in the validation tests performing the online module of the course. Methods: Subjective (questionnaires) and objective (performance statistics) metrics were analysed. Results: The e-learning environment has ease of access good layout consistency and intuitive navigation. Chat and forums have not been used and nurses miss a moderator. Participants consider that videos provide added value to the course and contents are easily understandable and of high quality. However questionnaires are not well balanced in difficulty and few interactive 3D designs have been viewed. Participants consider blended learning as the most effective training method for its flexibility in time and place. Conclusions: This study suggests that a simple easy-to-use and attractive e-learning environment has been developed to train nurses in MIS. However installation of additional software should be avoided. A moderator/tutor should manage forums to encourage user participation using conversational agents. But nevertheless chats have no interest. Questionnaires for content evaluation should be designed with efficiency and equity. Videos designed according to micro-learning with audio and interactivity should be included. These courses should be designed to meet factors to promote the engagement of students. Blended learning is considered by nurses as ideal method for training but further research to assess whether it improves learning outcomes is needed.;2020
Background: The usability and effectiveness of conversational agents (chatbots) that deliver psychological therapies is under-researched. Objective: This study aimed to compare the system usability acceptability and effectiveness in older adults of 2 Web-based conversational agents that differ in theoretical orientation and approach. Methods: In a randomized study 112 older adults were allocated to 1 of the following 2 fully automated interventions: Manage Your Life Online (MYLO ie a chatbot that mimics a therapist using a method of levels approach) and ELIZA (a chatbot that mimics a therapist using a humanistic counseling approach). The primary outcome was problem distress and resolution with secondary outcome measures of system usability and clinical outcome. Results: MYLO participants spent significantly longer interacting with the conversational agent. Posthoc tests indicated that MYLO participants had significantly lower problem distress at follow-up. There were no differences between MYLO and ELIZA in terms of problem resolution. MYLO was rated as significantly more helpful and likely to be used again. System usability of both the conversational agents was associated with helpfulness of the agents and the willingness of the participants to reuse. Adherence was high. A total of 12% (7/59) of the MYLO group did not carry out their conversation with the chatbot. Conclusions: Controlled studies of chatbots need to be conducted in clinical populations across different age groups. The potential integration of chatbots into psychological care in routine services is discussed.;2020
Background: The World Health Organization declared the novel coronavirus outbreak (COVID-19) to be a pandemic on March 11. 2020. Large-scale monitoring for capturing the current epidemiological situation of COVID-19 in Japan would improve preparation for and prevention of a massive outbreak. Methods: A chatbot-based healthcare system named COOPERA (COvid-19: Operation for Personalized Empowerment to Render smart prevention And care seeking) was developed using the LINE app to evaluate the current Japanese epidemiological situation. LINE users could participate in the system either though a QR code page in the prefectures' websites or a banner at the top of the LINE app screen. COOPERA asked participants questions regarding personal information preventive actions and non-specific symptoms related to COVID-19 and their duration. We calculated daily cross correlation functions between the reported number of infected cases confirmed using polymerase chain reaction and the symptom-positive group captured by COOPERA. Results: We analyzed 206218 participants from three prefectures reported between March 5 and 30 2020. The mean age of participants was 44.2 (standard deviation 13.2) years. No symptoms were reported by 96.93% of participants but there was a significantly positive correlation between the reported number of COVID-19 cases and self-reported fevers suggesting that massive monitoring of fever might help to estimate the scale of the COVID-19 epidemic in real time. Conclusions: COOPERA is the first real-time system being used to monitor trends in COVID-19 in Japan and provides useful insights to assist political decisions to tackle the epidemic.;2020
Background: There has recently been exponential growth in the development and use of health apps on mobile phones. As with most mobile apps however the majority of users abandon them quickly and after minimal use. One of the most critical factors for the success of a health app is how to support users' commitment to their health. Despite increased interest from researchers in mobile health few studies have examined the measurement of user engagement with health apps. Objective: User engagement is a multidimensional complex phenomenon. The aim of this study was to understand the concept of user engagement and in particular to demonstrate the applicability of a user engagement scale (UES) to mobile health apps. Methods: To determine the measurability of user engagement in a mobile health context a UES was employed which is a psychometric tool to measure user engagement with a digital system. This was adapted to Ada developed by Ada Health an artificial intelligence-powered personalized health guide that helps people understand their health. A principal component analysis (PCA) with varimax rotation was conducted on 30 items. In addition sum scores as means of each subscale were calculated. Results: Survey data from 73 Ada users were analyzed. PCA was determined to be suitable as verified by the sampling adequacy of Kaiser-Meyer-Olkin=0.858 a significant Bartlett test of sphericity (chi(2)(300) =1127.1 P<.001) and communalities mostly within the 0.7 range. Although 5 items had to be removed because of low factor loadings the results of the remaining 25 items revealed 4 attributes: perceived usability aesthetic appeal reward and focused attention. Ada users showed the highest engagement level with perceived usability with a value of 294 followed by aesthetic appeal reward and focused attention. Conclusions: Although the UES was deployed in German and adapted to another digital domain PCA yielded consistent subscales and a 4-factor structure. This indicates that user engagement with health apps can be assessed with the German version of the UES. These results can benefit related mobile health app engagement research and may be of importance to marketers and app developers.;2020
Background: There is increasing interest in finding novel approaches to improve the preparation of children for hospital procedures such as surgery x-rays and blood tests. Well-prepared and informed children have better outcomes (less procedural anxiety and higher satisfaction). A digital therapeutic (DTx) platform (Xploro) was developed with children to provide health information through gamification serious games a chatbot and an augmented reality avatar. Objective: This before and after evaluation study aims to assess the acceptability of the Xploro DTx and examine its impact on children and their parent's procedural knowledge procedural anxiety and reported experiences when attending a hospital for a planned procedure. Methods: We used a mixed methods design with quantitative measures and qualitative data collected sequentially from a group of children who received standard hospital information (before group) and a group of children who received the DTx intervention (after group). Participants were children aged between 8 and 14 years and their parents who attended a hospital for a planned clinical procedure at a children's hospital in North West England. Children and their parents completed self-report measures (perceived knowledge procedural anxiety procedural satisfaction and procedural involvement) at baseline preprocedure and postprocedure. Results: A total of 80 children (n=40 standard care group and n=40 intervention group) and their parents participated in the study the children were aged between 8 and 14 years (average 10.4 SD 2.27 years) and were attending a hospital for a range of procedures. The children in the intervention group reported significantly lower levels of procedural anxiety before the procedure than those in the standard group (two-tailed t63.64=2.740 P=.008). The children in the intervention group also felt more involved in their procedure than those in the standard group (t75=-2.238 P=.03). The children in the intervention group also reported significantly higher levels of perceived procedural knowledge preprocedure (t59.98=-4.892 P=.001) than those in the standard group. As for parents those with access to the Xploro intervention reported significantly lower levels of procedural anxiety preprocedure than those who did not (t68.51=1.985 P=.05). During the semistructured write and tell interviews children stated that they enjoyed using the intervention it was fun and easy to use and they felt that it had positively influenced their experiences of coming to the hospital for a procedure. Conclusions: This study has shown that the DTx platform Xploro has a positive impact on children attending a hospital for a procedure by reducing levels of procedural anxiety. The children and parents in the intervention group described Xploro as improving their experiences and being easy and fun to use.;2020
Background: Until recently developing health technologies was time-consuming and expensive and often involved patients doctors and other health care professionals only as passive recipients of the end product. So far users have been minimally involved in the ideation and creation stages of digital health technologies. In order to best address users' unmet needs a transdisciplinary and user-led approach involving cocreation and direct user feedback is required. In this context hackathon events have become increasingly popular in generating enthusiasm for user-centered innovation. Objective: This case study describes preparatory steps and the performance of a health hackathon directly involving patients and health care professionals at all stages. Feasibility and outcomes were assessed leading to the development of systematic recommendations for future hackathons as a vehicle for bottom-up innovation in health care. Methods: A 2-day hackathon was conducted in February 2017 in Berlin Germany. Data were collected through a field study. Collected field notes were subsequently discussed in 15 informal meetings among the research team. Experiences of conducting two further hackathons in December 2017 and November 2018 were included. Results: In total 30 participants took part with 63% (19/30) of participants between 25 and 34 years of age 30% (9/30) between 35 and 44 years of age and 7% (2/30) younger than 25 years of age. A total of 43% (13/30) of the participants were female. The participation rate of medical experts including patients and health care professionals was 30% (9/30). Five multidisciplinary teams were formed and each tackled a specific health care problem. All presented projects were apps: a chatbot for skin cancer recognition an augmented reality exposure-based therapy (eg for arachnophobia) an app for medical neighborhood connectivity a doctor appointment platform and a self-care app for people suffering from depression. Patients and health care professionals initiated all of the projects. Conducting the hackathon resulted in significant growth of the digital health community of Berlin and was followed up by larger hackathons. Systematic recommendations for conducting cost-efficient hackathons (n <= 30) were developed including aspects of community building stakeholder engagement mentoring themes announcements follow-up and timing for each step. Conclusions: This study shows that hackathons are effective in bringing innovation to health care and are more cost- and time-efficient and potentially more sustainable than traditional medical device and digital product development. Our systematic recommendations can be useful to other individuals and organizations that want to establish user-led innovation in academic hospitals by conducting transdisciplinary hackathons.;2020
Background: Virtual humans (VH) are computer-generated characters that appear humanlike and simulate face-to-face conversations using verbal and nonverbal cues. Unlike formless conversational agents like smart speakers or chatbots VH bring together the capabilities of both a conversational agent and an interactive avatar (computer-represented digital characters). Although their use in patient-facing systems has garnered substantial interest it is unknown to what extent VH are effective in health applications. Objective: The purpose of this review was to examine the effectiveness of VH in patient-facing systems. The design and implementation characteristics of these systems were also examined. Methods: Electronic bibliographic databases were searched for peer-reviewed articles with relevant key terms. Studies were included in the systematic review if they designed or evaluated VH in patient-facing systems. Of the included studies studies that used a randomized controlled trial to evaluate VH were included in the meta-analysis they were then summarized using the PICOTS framework (population intervention comparison group outcomes time frame setting) Summary effect sizes using random-effects models were calculated and the risk of bias was assessed. Results: Among the 8125 unique records identified 53 articles describing 33 unique systems were qualitatively systematically reviewed. Two distinct design categories emerged - simple VH and VH augmented with health sensors and trackers. Of the 53 articles 16 (26 studies) with 44 primary and 22 secondary outcomes were included in the meta-analysis. Meta-analysis of the 44 primary outcome measures revealed a significant difference between intervention and control conditions favoring the VH intervention (SMD = .166 95% CI .039-.292 P=.012) but with evidence of some heterogeneity I-2=49.3% There were more cross-sectional (k= 15) than longitudinal studies (k= 11). The intervention was delivered using a personal computer in most studies (k=18) followed by a tablet (k=4) mobile kiosk (k=2) head-mounted display (k=1) and a desktop computer in a community center (k=1). Conclusions: We offer evidence for the efficacy of VH in patient-facing systems. Considering that studies included different population and outcome types more focused analysis is needed in the future. Future studies also need to identify what features of virtual human interventions contribute toward their effectiveness.;2020
BackgroundA large proportion of apprentices shows addictive behaviours like cigarette smoking alcohol cannabis or compulsive Internet use others do not show such behaviours at all. ready4life is a smartphone application-based coaching program for apprentices which takes into account the heterogeneity of adolescent addictive behaviour by promoting life skills and reducing risk behaviours. The main objective of the planned study is to test the efficacy of ready4life for addiction prevention among apprentices in Switzerland within a controlled trial.Methods/designThe efficacy of the ready4life coaching program will be tested in comparison to an assessment only control group within a cluster-randomised controlled trial with one follow-up assessment after 6months. At the beginning of the program participants of the intervention group will receive an individual profile showing areas in which they have sufficient resources and in which there is a need for coaching. Based on this feedback they can select two out of the following six program modules: stress social skills Internet use tobacco/e-cigarettes cannabis and alcohol. Participants of the intervention group will receive individualised coaching by a conversational agent (chatbot) for a period of four months. The coaching relies on motivational and social-cognitive principles of behaviour change. Within weekly dialogues the coach provides individually tailored information in different formats such as videoclips texts or pictures. Study participants will be 1318 apprentices with a minimum age of 15 recruited in approximately 100 vocational school classes in Switzerland. Primary outcome will be a composite measure for addictive behaviours including (1) at risk-drinking (2) tobacco/e-cigarette smoking (3) cannabis use and (4) problematic Internet use.DiscussionThe study will reveal whether this universally implementable but individually tailored intervention approach is effective in preventing the onset and escalation of addictive behaviors among apprentices.Trial registrationISRCTN59908406 (registration date: 21/10/2020).;2020
Balinese calendar is defined as a unique calendar system for combining solar-based and lunar-based system and assuming local system. It is considered as guidance of Balinese societies' activities management starting from meeting arrangement wedding ceremony to religious ceremonies. Practically it has developed in the form of printed Balinese calendar and electronic Balinese calendar either web or mobile application. The core of the function is to find out the day with its various characteristics in the Balinese Calendar. In general society usually asks the religious leader to find out the day in detail. The technology of NLP combined with models of pattern discoveries supports the arrangement of the interaction model in searching the good day in Balinese Calendar to equip the conventional searching system in the previous applications. This study will design a dialog model with AIML method in multi-parameter basis therefore the users will be dynamically able to use the searching content in various ways by chatting in similar with consulting to a religious leader. This model will be applied in a chatbot basis service in telegram machine. The addition of the context recognition section into 4 paterns has been successfully improve the ability of AIML to recognize input patterns with many criteria. Based on the testing with 50 random input patterns obtained a success rate of 92.5%.;2020
Bots are destined to dominate how humans interact with the internet of things that continues to grow around them. Despite their still budding intellectual capacity major companies (e.g. Apple Google and Amazon) have already placed (chat)bots at the centre of their flagship devices. (Chat)Bots currently fill the internet acting as guides merchants and assistants. Chatbots designed as communicators however have yet to make a meaningful contribution to perhaps their most natural vocation: foreign language learning partners. This review engages in three questions that surround this issue: 1. Why are chatbots not already at the centre of foreign language learning? 2. What are two key developers of chatbots working towards that might push chatbots into the language learning spotlight? 3. What might researchers educators and developers together do to support chatbots as foreign language learning partners right now?;2020
Building a personalized task-oriented dialogue system is an important but challenging task. Significant success has been achieved in the template selection responses. However preparing a massive response template is time-consuming and human-labor intensive. In this paper we propose an end-to-end framework based on memory networks for response generation in a personalized task-oriented dialogue system. Our model consists of three parts: a retrieval module a memory encoder network and a memory decoder network. Retrieval module employs the user utterances and user attributes to collect relevant responses from other users. Memory encoder is trained with textual features to obtain dialogue representation. Memory decoder is composed of an RNN and a rule-memory network for response generation. Experiments on the benchmark dataset show that our model achieves better performance than strong baselines in personalized task-oriented dialogue generation. (C) 2020 Elsevier B.V. All rights reserved.;2020
Building dialogue systems plays an important role in modern life. amongst them task-oriented dialogue for resolving problems in actual life is most worth exploring. Motivated by the development of end-to-end approaches a task-oriented dialogue model based on bidirectional LSTM and self-attention mechanism is proposed. It not only makes good use of context and effectively solves the long-term dependency but also identifies the relationship between sentences optimizes feature vectors and has good parallelism. In our method the dialogue state tracker(DST) is firstly improved. Our dialogue state tracker can identify the multiple slot key-value pairs involved in the utterance without manual label. In addition we apply the data augmentation of merging machine translation and bilingual dictionary to create more diversified data sets. Finally in the experimental part the enhanced data and the results of DST are fed into the proposed B&Anet (bidirectional long and short memory network and self-attention mechanism network) model. The evaluation results on DSTC2 (dialogue state tracking chanllenge2) show that our method achieves competitive performance.;2020
Business intelligence (BI) applications play an important role in the enterprise to make critical business decisions. Conversational interfaces enable non-technical enterprise users to explore their data democratizing access to data significantly. In this paper we describe an ontology-based framework for creating a conversation system for BI applications termed as Conversational BI. We create an ontology from a business model underlying the BI application and use this ontology to automatically generate various artifacts of the conversation system. These include the intents entities as well as the training samples for each intent. Our approach builds upon our earlier work and exploits common BI access patterns to generate intents their training examples and adapt the dialog structure to support typical BI operations. We have implemented our techniques in Health Insights (HI) an IBM Watson Healthcare offering providing analysis over insurance data on claims. Our user study demonstrates that our system is quite intuitive for gaining business insights from data. We also show that our approach not only captures the analysis available in the fixed application dashboards but also enables new queries and explorations.;2020
Cancer is a disease of evolutionary origin in which a group of cells in the body initiate evolutionary changes under certain circumstances that can lead to the formation of a tumor. It is currently believed that a hostile cell environment can lead to the cells of an organ or tissue initiating a whole series of physiological changes that will lead to the transformation of healthy cells into cancerous ones. During the process of transformation cells evolve under a paradigm known as somatic evolution. In this work the first stages of the formation of a cancerous tumor have been simulated assuming that the cause of the formation is the genetic instability of the cells being the cause of this instability the presence of chronic inflammation phenomenon responsible for the appearance of a hostile cellular environment. The model simulates a virtual patient where an altered state of mind whether depressive stressed or similar will lead to disturbed hormone levels that will eventually lead to a condition of chronic inflammation. A novelty of the work is the design of a genetic algorithm oriented to the simulation of somatic evolution representing the cells by means of a vector that encodes the nodes of a stochastic network. These nodes represent the states of the genes hallmarks of the cancer and genetic stability of a cell simulating the formation of a tumor in the caverns of the colon. Another novelty of the model is the design of a virtual patient in which a chatbot for the simulation of the state of mind is hybridized with differential equations simulating both the hormones of the so-called hypothalamic-pituitary-adrenal axis and the cytokines involved in the mechanism of cellular inflammation. The work is a first step in the design of models that under a holistic vision allow the simulation and therefore a greater understanding of the different facets of a disease as complex as cancer.;2020
Challenges in attaining deliberative democratic ideals - such as inclusion authenticity and consequentiality - in wider political systems have driven the development of artificially-designed citizen deliberation. These designed deliberations however are expert-driven. Whereas they may achieve 'deliberativeness' their design and implementation are undemocratic and limit deliberative democracy's emancipatory goals. This is relevant in respect to the role of facilitation. In online deliberation algorithms and artificial actors replace the central role of human facilitators. The detachment of such designed settings from wider contexts is particularly troubling from a democratic perspective. Digital technologies in online deliberation are not developed in a manner consistent with democratic ideals and are not being amenable to scrutiny by citizens. I discuss the theoretical and the practical blind spots of algorithmic facilitation. Based on these I present recommendations to democratise the design and implementation of online deliberation with a focus on chatbots as facilitators.;2020
Chatbot (and voicebot) applications are increasingly adopted in various domains such as e-commerce or customer services as a direct communication channel between companies and end-users. Multiple frameworks have been developed to ease their definition and deployment. While these frameworks are efficient to design simple chatbot applications they still require advanced technical knowledge to define complex interactions and are difficult to evolve along with the company needs (e.g. it is typically impossible to change the NL engine provider). In addition the deployment of a chatbot application usually requires a deep understanding of the targeted platforms especially back-end connections increasing the development and maintenance costs. In this paper we introduce the Xatkit framework. Xatkit tackles these issues by providing a set of Domain Specific Languages to define chatbots (and voicebots and bots in general) in a platform-independent way. Xatkit also comes with a runtime engine that automatically deploys the chatbot application and manages the defined conversation logic over the platforms of choice. Xatkits modular architecture facilitates the separate evolution of any of its components. Xatkit is open source and fully available online.;2020
Chatbot communication in which a robot communicates with a human being in natural language in an open domain has achieved significant progress. However it still suffers from problems such as a lack of diversity and contextual relevance. In this paper we propose a retrieval-polished (RP) model for response generation that polishes a draft response based on a retrieved prototype. In particular we first adopt a prototype selector to retrieve a contextually similar prototype. Then a generation-based polisher is designed to obtain a polished response. Finally we introduce a polished response filter to choose whether the final reply should be the retrieved response or the polished response. Extensive experiments on a dialog corpus show that our method outperforms retrieval-based and generation-based chatbots with respect to fluency contextual relevance and response diversity. Specifically our model achieves substantial improvement compared with several strong baselines.;2020
ChatBot has potential as a language learning tool especially for learning Chinese vocabulary. This study aimed to investigate the impact of using a newly developed ChatBot to learn Chinese vocabulary by comparing how it works in different learning environments and to explore the ChatBot with reference to the Technology Acceptance Model (TAM). This study was conducted with 58 students divided into two independent groups. The control group used ChatBot in a one-on-many classroom. The experimental group applied the ChatBot in one-on-one tutor sessions. A pretest and a posttest were used to measure the effect of the ChatBot while TAM was explored through questionnaire and interview. Data analysis includes a paired-samplettest analysis of covariance and levels of effect. The results indicated that the ChatBot significantly improved the students' learning achievement and that having a one-on-one environment may lead to better outcome than what could be achieved in a classroom. The TAM model was tested using partial least square. The result showed that perceived usefulness was the predictor of behavioral intention whereas perceived ease of use was not. The students agreed that the ChatBot benefited their learning of Chinese vocabulary with several adjustments need to be made for further progress.;2020
Chatbots are able to provide support to patients suffering from very different conditions. Patients with chronic diseases or comorbidities could benefit the most from chatbots which can keep track of their condition provide specific information encourage adherence to medication etc. To perform these functions chatbots need a suitable underlying software architecture. In this paper we introduce a chatbot architecture for chronic patient support grounded on three pillars: scalability by means of microservices standard data sharing models through HL7 FHIR and standard conversation modeling using AIML. We also propose an innovative automation mechanism to convert FHIR resources into AIML files thus facilitating the interaction and data gathering of medical and personal information that ends up in patient health records. To align the way people interact with each other using messaging platforms with the chatbot architecture we propose these very same channels for the chatbot-patient interaction paying special attention to security and privacy issues. Finally we present a monitored-data study performed in different chronic diseases and we present a prototype implementation tailored for one specific chronic disease psoriasis showing how this new architecture allows the change the addition or the improvement of different parts of the chatbot in a dynamic and flexible way providing a substantial improvement in the development of chatbots used as virtual assistants for chronic patients.;2020
Chatbots are gaining their popularity in society and have triggered heated discussions in academia as well. Currently few studies explored the applications of AI-powered mental health chatbots in a mass-shooting disaster context. Via integrating literature from multi-disciplines such as crisis management mental health and digital communication this quantitative study intends to contribute to close this gap and explore the associations between perceived gratifications and protection motivations of using mental health chatbot services active communicative action and online and offline engagement behaviours of solving mental health problems after disasters. This study surveyed 1114 US participants who ever used chatbot services from top healthcare companies. Implications of the results enhance theoretical discussions on how artificial intelligence has shaped individuals' motivations communicative action and engagement behaviour to treat mental health problems. This study also benefits professionals who want to learn more about chatbots for mental healthcare crisis management and customer engagement.;2020
Chatbots are mainly text-based conversational agents that simulate conversations with users. This study aims to investigate drivers of users' satisfaction and continuance intention toward chatbot-based customer service. We propose an analytical framework combining the expectation-confirmation model (ECM) information system success (ISS) model TAM and the need for interaction with a service employee (NFI-SE). Analysis of data collected from 370 actual chatbot users reveals that information quality (IQ) and service quality (SQ) positively influence consumers' satisfaction and that perceived enjoyment (PE) perceived usefulness (PU) and perceived ease of use (PEOU) are significant predictors of continuance intention (CI). The need for interaction with an employee moderates the effects of PEOU and PU on satisfaction. The findings also revealed that satisfaction with chatbot e-service is a strong determinant and predictor of users' CI toward chatbots. Thus chatbots should enhance their information and service quality to increase users' satisfaction. The findings imply that digital technologies services such as chatbots could be combined with human service employees to satisfy digital users.;2020
Chatbots have become the go-to platform for users to receive answers to their queries. They are now being used by many businesses too to provide their customers with a virtual assistant to answer their queries. But when it comes to engaging with a user in a dialogue existing chatbots have several shortcomings with issues such as failing to provide a meaningful response to the user offering semantically incorrect information etc. This paper studies the working styles of existing chatbots in generating a response and then identifies their shortcomings from the viewpoint of engaging in a dialogue with a user. It then proposes a domain-specific chatbot named IntelliBot which is a response-generating dialogue-based chatbot that uses multiple strategies to generate a response. IntelliBot was trained on two datasets namely the Cornell movie dialogue and a custom-built insurance dataset so it has domain-specific knowledge. The performance of IntelliBot was then validated and compared with three other chatbots from the literature namely RootyAI ChatterBot and DeepQA. The results demonstrate IntelliBot's superiority in engaging with the user and providing a complete answer in the insurance domain. (C) 2020 Elsevier B.V. All rights reserved.;2020
Chatbots have been around for years and have been used in many areas such as medicine or commerce. Our focus is on the development and current uses of chatbots in the field of education where they can function as service assistants or as educational agents. In this research paper we attempt to make a systematic review of the literature on educational chatbots that address various issues. From 485 sources 80 studies on chatbots and their application in education were selected through a step-by-step procedure based on the guidelines of the PRISMA framework using a set of predefined criteria. The results obtained demonstrate the existence of different types of educational chatbots currently in use that affect student learning or improve services in various areas. This paper also examines the type of technology used to unravel the learning outcome that can be obtained from each type of chatbots. Finally our results identify instances where a chatbot can assist in learning under conditions similar to those of a human tutor while exploring other possibilities and techniques for assessing the quality of chatbots. Our analysis details these findings and can provide a solid framework for research and development of chatbots for the educational field.;2020
Chatbots such as Xiaoice have gained huge popularity in recent years. Users frequently mention their favorite works such as songs and movies in conversations with chatbots. Detecting these entities can help design better chat strategies and improve user experience. Existing named entity recognition methods are mainly designed for formal texts and their performance on the informal chatbot conversation texts may not be optimal In addition these methods rely on massive manually annotated data for model training. In this article we propose a neural approach to detect entities of works for Chinese chatbot. Our approach is based on a language model (LM) long-short term memory (LSTM) convolutional neural network (CNN) conditional random value (CRF) or LM-LSTM-CNN-CRF framework which contains a language model to generate context-aware character embeddings a Bi-LSTM network to learn contextual character representations from global contexts a CNN to learn character representations from local contexts and a CRF layer to jointly decode the character label sequence. In addition we propose an automatic text annotation method via quote marks to reduce the effort of manual annotation. Besides we propose an iterative data purification method to improve the quality of the automatically constructed labeled data. Massive experiments on a real-world dataset validate that our approach can achieve good performance on entity detection for Chinese chatbots.;2020
Commonsense Machine Comprehension (CMC) is a popular natural language understanding task. CMC enables computers to learn about causal and temporal reasoning by exploiting implicit commonsense knowledge and can be applied to Question Answering Search Engine and Dialogue System. Previous methods for CMC limit the vision on CMC task neglecting that Recognizing Textual Entailment(RTE) task has much similarities with CMC task. In this paper we propose a transfer learning model which can take advantage of commonsense knowledge in RTE task by mapping CMC examples and RTE examples to a shared feature space and comprehending in this feature space. Specifically we first establish a transfer learning framework which has three components: (1) source and target mappings (2) domain regularization and (3) CMC score function. Then we make selection for each component in our transfer learning framework and propose the Domain Transfer Comprehension(DTC) model. Experiments on Story Cloze Test show that our model outperforms most previous approaches and provides competitive results with state-of-art methods. We also show each components of our model have positive effect on performance. (C) 2019 Published by Elsevier B.V.;2020
Conversational agents (CAs)-frequently operationalized as chatbots-are computer systems that leverage natural language processing to engage in conversations with human users. CAs are often operationalized as chatbots which are used for many applications including technical support customer service and digital personal assistants. Despite their widespread use little research to date has investigated how improving the conversational skill of a CA impacts user perceptions of the agent. To elucidate this relationship this research uses Social Presence Theory to describe how conversational skill influences perceived social presence and ultimately anthropomorphism of a chatbot. We conducted a series of studies in which 450 participants interacted with CAs exhibiting varying levels of conversational skill. We show that people perceive a more skilled CA to be more socially present and anthropomorphic than a less skilled CA. This research advances the knowledge of computer-human interface in information systems as CA research to date has largely focused on the technical challenges rather than the behavioral questions of how users interact with CAs.;2020
Conversational agents are gaining huge popularity in industrial applications such as digital assistants chatbots and particularly systems for natural language understanding (NLU). However a major drawback is the unavailability of a common metric to evaluate the replies against human judgement for conversational agents. In this paper we develop a benchmark dataset with human annotations and diverse replies that can be used to develop such metric for conversational agents. The paper introduces a high-quality human annotated movie dialogue dataset HUMOD that is developed from the Cornell movie dialogues dataset. This new dataset comprises 28500 human responses from 9500 multi-turn dialogue history-reply pairs. Human responses include: (i) ratings of the dialogue reply in relevance to the dialogue history and (ii) unique dialogue replies for each dialogue history from the users. Such unique dialogue replies enable researchers in evaluating their models against six unique human responses for each given history. Detailed analysis on how dialogues are structured and human perception on dialogue score in comparison with existing models are also presented.;2020
Conversational interfaces are currently on the rise: more and more applications rely on a chat-like interaction pattern to increase their acceptability and to improve user experience. Also in the area of questionnaire design and administration interaction design is increasingly looked at as an important ingredient of a digital solution. For those reasons we designed and developed a conversational survey tool to administer questionnaires with a colloquial form through a chat-like Web interface. In this paper we present the evaluation results of our approach taking into account both the user point of view - by assessing user acceptance and preferences in terms of survey compilation experience - and the survey design perspective - by investigating the effectiveness of a conversational survey in comparison to a traditional questionnaire. We show that users clearly appreciate the conversational form and prefer it over a traditional approach and that from a data collection point of view the conversational method shows the same reliability and a higher response quality with respect to a traditional questionnaire.;2020
Conversational Recommender Systems (CoRSs) implement a paradigm that allows users to interact in natural language with the system for defining their preferences and discovering items that best fit their needs. CoRSs can be straightforwardly implemented as chatbots that nowadays are becoming more and more popular for several applications such as customer care health care and medical diagnoses. Chatbots implement an interaction based on natural language buttons or both. The implementation of a chatbot is a challenging task since it requires knowledge about natural language processing and human-computer interaction. A CoRS might be particularly useful in the music domain since music is generally enjoyed in contexts when a standard interface cannot be exploited (driving doing homeworks running). However there is no work in the literature that analytically compares different interaction modes for a conversational music recommender system. In this paper we focus on the design and implementation of a CoRS for the music domain. Our CoRS consists of different components. The system implements content-based recommendation critiquing and adaptive strategies as well as explanation facilities. The main innovative contribution is that the user can interact through different interaction modes: natural language buttons and mixed. Due to the lack of available datasets for testing CoRSs we carried out an in vivo experimental evaluation with the goal of investigating the impact of the different interaction modes on the recommendation accuracy and on the cost of interaction for the final user. The experiment involved 110 people and 54 completed the whole process. The analysis of the results shows that the best interaction mode is based on a mixed strategy that combines buttons and natural language. In addition the results allow to clearly understand which are the steps in the dialog that are particularly strenuous for the user.;2020
Critical for the early diagnosis of genetic disorders a Family Health History (FHx) can be collected in several ways including electronic FHx tools which aid easy editing and sharing by linking with other information management portals. The user acceptance of such systems is critical especially among older adults experiencing motor and cognitive issues. This study investigated two types of FHx interfaces standard and Virtual Conversational Agent (VCA) using 30 young (between 18 and 30) and 24 older participants (over 60). Workload usability and performance data were collected. Even though participants required less time to complete three of five tasks on the standard interface the VCA interface performed better in terms of subjective workload and usability. Additionally 67% of the older adults preferred the VCA interface since it provided context-based guidance during the data collection process. The results from this study have implications for the use of virtual assistants in FHx and other areas of data collection.;2020
Cultural competence - i.e. the capability to adapt verbal and non-verbal interaction to the user's cultural background - may be a key element for social robots to increase the user experience. However designing and implementing culturally competent social robots is a complex task given that advanced conversational skills are required. In this context Cloud services may be useful for helping robots in generating appropriate interaction patterns in a culture-aware manner. In this letter we present the design and the implementation of the CARESSES Cloud a set of robotic services aimed at endowing robots with cultural competence in verbal interaction. A preliminary evaluation of the Cloud services as a general dialoguing system for culture-aware social robots has been performed analyzing the feasibility of the architecture in terms of communication and data processing delays.;2020
Cultural heritage is an important resource that allows us to know and promote a territory. In this respect it is important to experiment with the enhancement of cultural heritage by adopting approaches that meet the dynamic needs of various types of users. The aim of this paper is to introduce a recommender system capable of developing adaptive tourist routes. In fact the proposed system suggests points of interest and related services according to both the profile of the tourist and contextual aspects. In particular the interaction of the user with the system occurs through a chatbot that allows to build a real dialog. In order to show the potential of the proposed approach a prototype was developed to support the user in building a customized tourist route related to some of the most important cultural sites in Campania (a region in Southern Italy): Herculaneum Paestum and Pompeii. (c) 2020 Elsevier B.V. All rights reserved.;2020
Currently online retailers evaluate whether chatbots-software programs that interact with users using natural languages-could improve their customers' satisfaction. In a retail context chatbots allow humans to pose shopping-related questions and receive answers in natural language without waiting for a salesperson or using other automated communication forms. However until now it has been unclear which customers accept this new communication form and which factors determine their acceptance. In this paper we contrast the well-known technology acceptance model (TAM) with the lesser known uses and gratifications (U&G) theory applying both approaches to measure the acceptance of the text-based Emma chatbot by its target segment. Emma was developed for the prepurchase phase of online fashion retailing and integrated into Facebook Messenger by the major German online retailer Zalando. Data were collected from 205 German Millennial respondents in a usability study. The results show that both utilitarian factors such as authenticity of conversation and perceived usefulness as well as hedonic factors such as perceived enjoyment positively influence the acceptance of Emma. However privacy concerns and the immaturity of the technology had a negative effect on usage intention and frequency. The predictive power of both models was similar showing little deviation but U&G gives alternative insights into the customers' motivation to use Emma compared to the TAM.;2020
Currently there are many types of conversational agents whose goal is to emulate human behavior. These agents offer more believable conversations when their responses come from a deliberative process that mimics individuals' character. Conversational agents are mainly used for response selection linguistics and context situated strategies. These approaches usually build rules to find answers in dialogues however this is not the best alternative when the communicative intentions are not literal and context dependent. Deliberative Agents can solve these issues and improve their selection process through the integration of preferences and personality in their cognitive process. Hence this work investigates how to drive the expression of dialogues of a Conversational Deliberative Agent (CDA) through personality and fuzzy outranking relations for this it proposes the characterization of context and corpus through speech acts theory and also a selection process based on fuzzy outranking relations to compare corpus phrases and context to choose the best response. The main contributions of this work are (1) the agent architecture that integrates preferences and personality of an individual in the response selection cognitive process (2) a characterization model of speech acting through criteria based on belief desires and intentions to define a more human behavior expression and (3) the use of fuzzy outranking relations to select phrases from a corpus to match dialogue intentions. An experimental design demonstrated the aptitude of the developed CDA to offer quality responses on a tutor application. Also the results showed the capacity of speech acts to handle contexts in dialogues.;2020
Cutting-edge visualization and interaction technologies are increasingly used in museum exhibitions providing novel ways to engage visitors and enhance their cultural experience. Existing applications are commonly built upon a single technology focusing on visualization motion or verbal interaction (e.g. high-resolution projections gesture interfaces chatbots). This aspect limits their potential since museums are highly heterogeneous in terms of visitors profiles and interests requiring multi-channel customizable interaction modalities. To this aim this work describes and evaluates an artificial intelligence powered interactive holographic stand aimed at describing Leonardo Da Vinci's art. This system provides the users with accurate 3D representations of Leonardo's machines which can be interactively manipulated through a touchless user interface. It is also able to dialog with the users in natural language about Leonardo's art while keeping the context of conversation and interactions. Furthermore the results of a large user study carried out during art and tech exhibitions are presented and discussed. The goal was to assess how users of different ages and interests perceive understand and explore cultural objects when holograms and artificial intelligence are used as instruments of knowledge and analysis. (c) 2020 Elsevier B.V. All rights reserved.;2020
Deep reinforcement learning (RL) has become one of the most popular topics in artificial intelligence research. It has been widely used in various fields such as end-to-end control robotic control recommendation systems and natural language dialogue systems. In this survey we systematically categorize the deep RL algorithms and applications and provide a detailed review over existing deep RL algorithms by dividing them into modelbased methods model-free methods and advanced RL methods. We thoroughly analyze the advances including exploration inverse RL and transfer RL. Finally we outline the current representative applications and analyze four open problems for future research.;2020
Developing a dialogue response generation system is one of important topics in natural language processing but many obstacles are yet to be overcome before autogenerated dialogues with a human-like quality can become possible. A good evaluation method will help narrow the gap between machines and humans in dialogue generation. Unfortunately the existing automatic evaluation methods are biased and correlate very poorly with human judgments of response quality. Such methods are incapable of assessing whether a dialogue response generation system can produce high-quality knowledge-related and informative dialogues. In response to this challenge we design an information-oriented framework to simulate human subjective evaluation. Using this framework we implement a learning-based metric to evaluate the quality of a dialogue. An experimental validation demonstrates our proposed metric's effectiveness in dialogue selection and model evaluation on a Twitter dataset (in English) and a Weibo dataset (in Chinese). In addition the metric is more relevant than the existing methods of dialogue evaluation to human subjective judgment.;2020
Development of conversational systems is one of the most challenging tasks in natural language processing and it is especially hard in the case of open-domain dialogue. The main factors that hinder progress in this area are lack of training data and difficulty of automatic evaluation. Thus to reliably evaluate the quality of such models one needs to resort to time-consuming and expensive human evaluation. We tackle these problems by organizing the Conversational Intelligence Challenge (ConvAI) - open competition of dialogue systems. Our goals are threefold: to work out a good design for human evaluation of open-domain dialogue to grow open-source code base for conversational systems and to harvest and publish new datasets. Over the course of ConvAI1 and ConvAI2 competitions we developed a framework for evaluation of chatbots in messaging platforms and used it to evaluate over 30 dialogue systems in two conversational tasks - discussion of short text snippets from Wikipedia and personalized small talk. These large-scale evaluation experiments were performed by recruiting volunteers as well as paid workers. As a result we succeeded in collecting a dataset of around 5000 long meaningful human-to-bot dialogues and got many insights into the organization of human evaluation. This dataset can be used to train an automatic evaluation model or to improve the quality of dialogue systans. Our analysis of ConvAI1 and ConvAI2 competitions shows that the future work in this area should be centered around the more active participation of volunteers in the assessment of dialogue systems. To achieve that we plan to make the evaluation setup more engaging.;2020
Dialogue is a very active area o f research currently both in developing new computational techniques for robust dialogue systems and in the active fielding of commercial conversational assistants such as Apple's Sin and Amazon's Alexa. This article argues that while current techniques can be used to design effective dialogue-based systems for very simple tasks they are unlikely to generalize to conversational interfaces that enhance human ability to solve complex tasks by interacting with artificial intelligence reasoning and modeling systems. We explore some of the challenges of tackling such complex tasks and describe a dialogue model designed to meet these challenges. We illustrate our approach with examples of several implemented systems that use this framework.;2020
Dialogue management plays a vital role in task-oriented dialogue systems which has become an active area of research in recent years. Despite the promising results brought from deep reinforcement learning most of the studies need to develop a manual user simulator additionally. To address the time-consuming development of simulator policy we propose a multi-agent dialogue model where an end-to-end dialogue manager and a user simulator are optimized simultaneously. Different from prior work we optimize the two-agents from scratch and apply the reward shaping technology based on adjacency pairs constraints in conversational analysis to speed up learning and to avoid the derivation from normal human-human conversation. In addition we generalize the one-to-one learning strategy to one-to-many learning strategy where a dialogue manager can be concurrently optimized with various user simulators to improve the performance of trained dialogue manager. The experimental results show that one-to-one agents trained with adjacency pairs constraints can converge faster and avoid derivation. In cross-model evaluation with human users involved the dialogue manager trained in one-to-many strategy achieves the best performance.;2020
Dialogue systems have achieved growing success in many areas thanks to the rapid advances of machine learning techniques. In the quest for generating more human-like conversations one of the major challenges is to learn to generate responses in a more empathetic manner. In this review article we focus on the literature of empathetic dialogue systems whose goal is to enhance the perception and expression of emotional states personal preference and knowledge. Accordingly we identify three key features that underpin such systems: emotion-awareness personality-awareness and knowledge-accessibility. The main goal of this review is to serve as a comprehensive guide to research and development on empathetic dialogue systems and to suggest future directions in this domain.;2020
Dialogue-based systems often consist of several components such as communication analysis dialogue management domain reasoning and language generation. In this paper we present Converness an ontology-driven rule-based framework to facilitate domain reasoning for conversational awareness in multimodal dialogue-based agents. Converness uses Web Ontology Language 2 (OWL 2) ontologies to capture and combine the conversational modalities of the domain for example deictic gestures and spoken utterances fuelling conversational topic understanding and interpretation using description logics and rules. At the same time defeasible rules are used to couple domain and user-centred knowledge to further assist the interaction with end users facilitating advanced conflict resolution and personalised context disambiguation. We illustrate the capabilities of the framework through its integration into a multimodal dialogue-based agent that serves as an intelligent interface between users (elderly caregivers and health experts) and an ambient assistive living platform in real home settings.;2020
Digital and agile companies widely use chatbots in the form of integrations into enterprise messengers such as Slack and Microsoft Teams. However there is a lack of empirical evidence about their action possibilities (i.e. affordances) for example to link social interactions with third-party systems and processes. Therefore we adopt a three-stage process. Grounded in a preliminary study and a qualitative study with 29 interviews from 17 organizations we inductively derive rich contextual insights of 14 affordances and constraints which serve as input for a Q-Methodology study that highlights five perceptional differences. We find that actualizing these affordances leads to higher-level affordances of chatbots that augment social information systems with affordances of traditional enterprise systems. Crossing the chasm between these so far detached systems contributes a novel perspective on how to balance novel digital with traditional systems flexibility and malleability with stability and control exploration with exploitation and agility with discipline.;2020
Digital Assistants (DA) such as Amazon Alexa Siri or Google Assistant are now gaining great diffusion since they allow users to execute a wide range of actions through messages in natural language. Even though DAs are able to complete tasks such as sending texts making phone calls or playing songs they do not yet implement recommendation facilities. In this paper we investigate the combination of Digital Assistants and Conversational Recommender Systems (CoRSs) by designing and implementing a framework named ConveRSE (Conversational Recommender System framEwork) for building chatbots that can recommend items from different domains and interact with the user through natural language. Since a CoRS architecture is generally composed of different elements we performed an in-vitro experiment with two synthetic datasets to investigate the impact that each component has on the CoRS in terms of recommendation accuracy. Additionally an in-vivo experiment was carried out to understand how natural language influences both the cost of interaction and recommendation accuracy of a CoRS. Experimental results have revealed the most critical components in a CoRS architecture especially in cold-start situations and the main issues of the natural-language-based interaction. All the dialogues have been collected in a public available dataset.;2020
Digital health tools and technologies are transforming health care and making significant impacts on how health and care information are collected used and shared to achieve best outcomes. As most of the efforts are still focused on clinical settings the wealth of health information generated outside of clinical settings is not being fully tapped. This is especially true for children with medical complexity (CMC) and their families as they frequently spend significant hours providing hands-on medical care within the home setting and coordinating activities among multiple providers and other caregivers. In this paper a multidisciplinary team of stakeholders discusses the value of health information generated at home how technology can enhance care coordination and challenges of technology adoption from a patient-centered perspective. Voice interactive technology has been identified to have the potential to transform care coordination for CMC. This paper shares opinions on the promises limitations recommended approaches and challenges of adopting voice technology in health care especially for the targeted patient population of CMC.;2020
Digital records from chat transcripts to social media posts are being used to create chatbots that recreate the conversational style of deceased individuals. Some maintain that this is merely a new form of digital memorial while others argue that they pose a variety of moral hazards. To resolve this I turn to classical Chinese philosophy to make use of a debate over the ethics of funerals and mourning. This ancient argument includes much of interest for the contemporary issue at hand including the use of impersonators of the dead to help the bereaved to deal well with their grief. I connect this historical discussion with a modern trend in clinical psychology that reframes therapeutic interventions with bereaved individuals. The trend directs practitioners away from facilitating detachment and toward affirming continuing bonds. I conclude that these chatbots can offer an important source of support to mourners but also discuss parameters and features of social context that will be important to avoid the moral hazards identified by sceptics.;2020
Distributed intelligent systems (DIS) appear where natural intelligence agents (humans) and artificial intelligence agents (algorithms) interact exchanging data and decisions and learning how to evolve toward a better quality of solutions. The networked dynamics of distributed natural and artificial intelligence agents leads to emerging complexity different from the ones observed before. In this study we review and systematize different approaches in the distributed intelligence field including the quantum domain. A definition and mathematical model of DIS (as a new class of systems) and its components including a general model of DIS dynamics are introduced. In particular the suggested new model of DIS contains both natural (humans) and artificial (computer programs chatbots etc.) intelligence agents which take into account their interactions and communications. We present the case study of domain-oriented DIS based on different agents' classes and show that DIS dynamics shows complexity effects observed in other well-studied complex systems. We examine our model by means of the platform of personal self-adaptive educational assistants (avatars) especially designed in our University. Avatars interact with each other and with their owners. Our experiment allows finding an answer to the vital question: How quickly will DIS adapt to owners' preferences so that they are satisfied? We introduce and examine in detail learning time as a function of network topology. We have shown that DIS has an intrinsic source of complexity that needs to be addressed while developing predictable and trustworthy systems of natural and artificial intelligence agents. Remarkably our research and findings promoted the improvement of the educational process at our university in the presence of COVID-19 pandemic conditions.;2020
Due to the advance of indoor positioning technology it is now possible to trace mobile medical equipment (such as electrocardiography machines patient monitors and so on) being moved around a hospital ward. With the support of an object tracking system nurses can easily locate and find a device especially when they prepare for a shift change or a medical treatment. As nurses usually face high workloads it is highly desirable to provide nurses with a user-friendly search interface integrated into a popular mobile app that they use daily. For this DBOS a dialog-based object query system is proposed which simulates a real conversation with users via the Line messaging app's chatbot interface. A hybrid method that combines cosine similarity (CS) and term frequency-inverse document frequency (TF-IDF) is used to determine user intent. The result is returned to the user through Line's interface. To evaluate the applicability of DBOS 70 search queries given by a head nurse were tested. DBOS was compared with CS TF-IDF and Facebook Wit.ai respectively. The experiment results show that DBOS outperforms the abovementioned methods and can achieve a 92.8% accuracy in identifying user intent.;2020
Due to the significance and value in human-computer interaction and natural language processing task-oriented dialog systems are attracting more and more attention in both academic and industrial communities. In this paper we survey recent advances and challenges in task-oriented dialog systems. We also discuss three critical topics for task-oriented dialog systems: (1) improving data efficiency to facilitate dialog modeling in low-resource settings (2) modeling multi-turn dynamics for dialog policy learning to achieve better task-completion performance and (3) integrating domain ontology knowledge into the dialog model. Besides we review the recent progresses in dialog evaluation and some widely-used corpora. We believe that this survey though incomplete can shed a light on future research in task-oriented dialog systems.;2020
E-Learning has become more and more popular in recent years with the advance of new technologies. Using their mobile devices people can expand their knowledge anytime and anywhere. E-Learning also makes it possible for people to manage their learning progression freely and follow their own learning style. However studies show that E-Learning can cause the user to experience feelings of isolation and detachment due to the lack of human-like interactions in most E-Learning platforms. These feelings could reduce the user & x2019s motivation to learn. In this paper we explore and evaluate how well current chatbot technologies assist users & x2019 learning on E-Learning platforms and how these technologies could possibly reduce problems such as feelings of isolation and detachment. For evaluation we specifically designed a chatbot to be an E-Learning assistant. The NLP core of our chatbot is based on two different models: a retrieval-based model and a QANet model. We designed this two-model hybrid chatbot to be used alongside an E-Learning platform. The core response context of our chatbot is not only designed with course materials in mind but also everyday conversation and chitchat which make it feel more like a human companion. Experiment and questionnaire evaluation results show that chatbots could be helpful in learning and could potentially reduce E-Learning users & x2019 feelings of isolation and detachment. Our chatbot also performed better than the teacher counselling service in the E-Learning platform on which the chatbot is based.;2020
Embodied conversational agents (ECAs) are gaining interest to elicit user engagement and stimulate actual use of eHealth applications. In this literature review we identify the researched design features for ECAs in eHealth the outcome variables that were used to measure the effect of these design features and what the found effects for each variable were. Searches were performed in Scopus ACM Digital Library PsychINFO Pubmed and IEEE Xplore Digital Library resulting in 1284 identified articles of which 33 articles were included. The agents speech and/or textual output and its facial and gaze expressions were the most common design features. Little research was performed on the agent's looks. The measured effect of these design features was often on the perception of the agent's and user's characteristics relation with the agent system usage intention to use usability and behaviour change. Results show that emotion and relational behaviour seem to positively affect the perception of the agents characteristics and that relational behaviour also seems to positively affect the relation with the agent usability and intention to use. However these design features do not necessarily lead to behaviour change. This review showed that consensus on design features of ECAs in eHealth is far from established. Follow-up research should include more research on the effects of all design features especially research on the effects in a long-term daily life setting and replication of studies on the effects of design features performed in other contexts than eHealth.;2020
Embodied conversational agents (ECAs) are increasingly used in healthcare and other settings to improve self-management and provide companionship. Their ability to form close relationships with people is important for enhancing effectiveness and engagement. Several studies have looked at enhancing relationships with ECAs through design features focused on behaviours appearance or language. However this evidence is yet to be systematically synthesized. This systematic review evaluates the effect of different design features on relationship quality with ECAs. A systematic search was conducted on electronic databases EMBASE PsychInfo PubMed MEDLINE Cochrane Library SCOPUS and Web of Science in January-February 2019. 43 studies were included for review that evaluated the effect of a design feature on relationship quality and social perceptions or behaviours towards an ECA. Results synthesize effective design features and lay a scientific framework for improving relationships with ECAs in healthcare and other applications. Risk of bias for included studies was generally low however there were some limitations in the research quality pertaining to outcome measurement and the reporting of statistics. Further research is needed to understand how to make ECAs effective and engaging for all consumers.;2020
Embodied conversational agents may be used to engage users in adopting eHealth applications. The aim of this research is to investigate which design features establish a positive first impression of an agent in this context. A set of eight static agent images different in age gender and role were subjected to testing in an online questionnaire. Respondents (n = 155) selected their preferred design and rated the characteristics - friendliness expertise reliability involvement and authority - and the likeliness of following the agent's advice for all designs. In addition focus groups (n = 13) were conducted for detailed understandings supporting these impressions. Our results show that for both a general and elderly population (1) people seem to prefer images of young female agents over old male agents (2) the (a) age (b) gender and (c) role of the agent image affect the perception of the agent's characteristics and the likeliness of following the agent's advice and that (3) both the general and elderly population prefer an agent image that is similar in (a) age and (b) gender. A next step would be to investigate how the characteristics of the agent designs are perceived after interaction with the agent.;2020
Emotion detection is a hot topic nowadays for its potential application to intelligent systems in different fields such as neuromarketing dialogue systems friendly robotics vending platforms and amiable banking. Nevertheless the lack of a benchmarking standard makes it difficult to compare results produced by different methodologies which could help the research community improve existing approaches and design new ones. Besides there is the added problem of accurate dataset production. Most of the emotional speech databases and associated documentation are either privative or not publicly available. Therefore in this work two stress-elicited databases containing speech from male and female speakers were recruited and four classification methods are compared in order to detect and classify speech under stress. Results from each method are presented to show their quality performance besides the final scores attained in what is a novel approach to the field of study.;2020
Emotion intelligence plays an important role in building a successful human-machine dialogue system. However the extreme difficulty of capturing emotional information of social text as well as the weakness of generative models for learning emotional expression limits the performance of existing dialogue system. Combining dictionary matching and machine learning this paper proposes a generative model which fuses the word- and sentence-level emotions to model the dialogue text and learn emotional expression. The model first obtains the emotional embedding of each word through dictionary matching then concatenates the emotional word embedding with its traditional word embedding and the finally formed vector is taken as the input of the encoder. In order to control the emotional feature of the generated response our model employs a BernoulliNB-based classifier to extract the emotional feature of the post which is used as the attribute of the original text and subsequently adds it to the decoder. For further significantly improving the emotional expression of the response the model leverages a discriminator to constrain the latent variable which enables the latent variable to encode better the information of emotional feature of the post. With this model we can generate the dialogue text that is consistent with the original emotion. Experimental results on our Twitter dataset demonstrate that our model outperforms several state-of-the-art methods in the emotion accuracy and quality of generated texts. (C) 2019 Elsevier B.V. All rights reserved.;2020
Empathy is a complex socio-emotional behavior that results from the interaction between affective and cognitive mechanisms. Equipping embodied conversational agents (ECAs) with empathic capacity can benefit from the integration and evaluation of these low and high level capabilities in a hierarchical manner. Following the theoretical background on empathic behavior in humans this paper presents a framework to equip ECAs with real time multi-modal empathic interaction capabilities. We present the implementation of this framework which includes basic dialogue capabilities as well as three levels of empathic behavior in a conversational scenario. Our approach is an inclusive stand on modeling levels of empathy and provides a baseline behavior for empathic interaction. (C) 2019 Elsevier B.V. All rights reserved.;2020
End-to-end neural-based dialogue systems can potentially generate tailored and coherent responses for user inputs. However most of existing systems produce universal and non-informative responses and they have not gone beyond chitchat yet. To tackle these problems 7th Dialog System Technology Challenges (DSTC7-Track2) was developed to focus on building a dialogue system that produces informational responses that are grounded on external knowledge. In this study we propose a Memory-augmented Hierarchical Recurrent Encoder-Decoder called MHRED that grounded on both multi-turn dialogue context and external knowledge. Furthermore we apply a combination of multiple dialogue systems. Our final system is an ensemble that combines three modules: a generation-based module a retrieval-based module and a reranking module. First responses are generated by MHRED and retrieved from a pre-defined database focusing on informativeness. Next the reranking module sorts these candidates using several hand-crafted features and finally it selects a response with the highest score. Therefore this system can return diverse and meaningful responses from various perspectives. Experimental results show that our proposed MHRED outperforms strong baseline models and combining multiple dialogue systems significantly improves the automatic evaluation and human evaluations. (C) 2020 The Author(s). Published by Elsevier Ltd.;2020
End-to-end task-oriented dialog systems have attracted vast amounts of attention in recent years mainly because of their ease of training. However such an end-to-end model requires a large number of labeled dialogs to train. Labeled dialogs are always difficult to obtain in real-world settings. We propose a domain adaptive end-to-end task-oriented dialog model that transfers knowledge in source domains to a target domain with limited training samples. Specifically we design a domain adaptive filter in the encoder-decoder model to reduce useless features in source domains and preserve common features. A domain adaptive amplifier is designed to enhance the target domain impact. We evaluate our method on both synthetic dialog and human-human dialog datasets and achieve state-of-the-art results.;2020
Engaging in positive healthy lifestyle behaviors continues to be a public health challenge requiring innovative solutions. As the market for voice assistants (Amazon Alexa Google Assistant and Apple Siri) grows and people increasingly use them to assist their daily tasks there is a pressing need to explore how voice assistant (VA) technology may be used in behavioral health interventions. A scoping review of literature was conducted to address a PICO (Population Intervention Comparison and Outcome) question: across populations how does the use of voice assistants in behavioral health research/interventions influence healthy lifestyle behaviors versus control or comparison interventions? To inform the science a secondary aim of this review was to explore characteristics of VAs used in behavioral health research. The review was conducted following Preferred Reporting Items for Systematic Review and Meta-Analysis guidelines with scoping review extension (PRISMA-ScR). Ten studies satisfied the inclusion criteria representing research published through February 2019. Studies spanned pediatric to elderly populations covering a vast array of self-management and healthy lifestyle behaviors. The majority of interventions were multicomponent involving more than one of the following behavior change techniques grouped by cluster: shaping knowledge self-belief repetition and substitution feedback and monitoring goals and planning antecedents natural consequences comparison of behavior and identification. However most studies were in early stages of development with limited efficacy trials. VA technology continues to evolve and support behavioral interventions using various platforms (e.g. Interactive Voice Response [IVR] systems smartphones and smart speakers) which are used alone or in conjunction with other platforms. Feasibility usability preliminary efficacy along with high user satisfaction of research adapted VAs in contrast to standalone commercially available VAs suggest a role for VAs in behavioral health intervention research.;2020
Entrainment is the tendency of interlocutors to become more similar to each other in their way of speaking. This phenomenon has been repeatedly documented and is associated with multiple social aspects of human-human conversations. However there is a dearth of research on the effects of spoken dialogue systems (SDSs) with implemented acoustic-prosodic (dis)entrainment policies. The goal of the present work is to provide further empirical evidence on how acoustic-prosodic (dis)entraining policies affect users. In particular this article fo-cuses on its effects on users' trust toward the SDSs. In the experiments reported here we analyze if and how different acoustic-prosodic (dis)entrainment policies affect users' perception of a system's ability. We collected data from 98 unique participants all native speakers of Argentine Spanish. Our results suggest that acoustic prosodic (dis)entrainment in spoken dialogue systems is effectively associated with the way users perceive the capabilities of such systems. Characterizing these effects remains a challenging task. Overall we observe a positive effect on trust of entrainment on intensity and a negative effect of entrainment on pitch. Estimated effect sizes are far from negligible.;2020
External keywords are crucial for response generation models to address the generic response problems in open-domain conversational systems. The occurrence of keywords in a response depends heavily on the order of the keywords as they are generated sequentially. Meanwhile the order of keywords also affects the semantics of a response. Previous keywords based methods mainly focus on the composite of keywords while the order of keywords has not been sufficiently discussed. In this work we propose an order-sensitive keywords based model to explore the influence of the order of keywords in open-domain response generation. It automatically inferences the most suitable order that is optimized to generate a natural and relevant response and subsequently generates the response using the ordered keywords as building blocks. We conducted experiments on a public Twitter dataset and the results show that our approach outperforms the state-of-the-art baselines in both automatic and human evaluations.;2020
Eye typing is a hands-free method of human computer interaction which is especially useful for people with upper limb disabilities. Users select a desired key by gazing at it in an image of a keyboard for a fixed dwell time. There is a tradeoff in selecting the dwell time shorter dwell times lead to errors due to unintentional selections while longer dwell times lead to a slow input speed. We propose to speed up eye typing while maintaining low error by dynamically adjusting the dwell time for each letter based on the past input history. More likely letters are assigned shorter dwell times. Our method is based on a probabilistic generative model of gaze which enables us to assign dwell times using a principled model that requires only a few free parameters. We evaluate our model on both able-bodied subjects and subjects with a spinal cord injury (SCI). Compared to the standard dwell time method we find consistent increases in typing speed in both cases. e.g. 41.8% faster typing for able-bodied subjects on a transcription task and 49.5% faster typing for SCI subjects in a chatbot task. We observed more inter-subject variability for SCI subjects.;2020
Family health history (FHx) is one of the simplest and most cost-effective and efficient ways to collect health information that could help diagnose and treat genetic diseases at an early stage. This study evaluated the efficacy of collecting such family health histories through a virtual conversational agent (VCA) interface a new method for collecting this information. Standard and VCA interfaces for FHx collection were investigated with 50 participants recruited via email and word of mouth using a within-subject experimental design with the order of the interfaces randomized and counterbalanced. Interface workload usability preference and satisfaction were assessed using the NASA Task Load Index workload instrument the IBM Computer System Usability Questionnaire and a brief questionnaire derived from the Technology Acceptance Model. The researchers also recorded the number of errors and the total task completion time. It was found that the completion times for 2 of the 5 tasks were shorter for the VCA interface than for the standard one but the overall completion time was longer (17 min 44 s vs. 16 min 51 s p = .019). We also found the overall workload to be significantly lower (34.32 vs. 42.64 p = .003) for the VCA interface and usability metrics including overall satisfaction (5.62 vs. 4.72 p < .001) system usefulness (5.76 vs. 4.84 p = .001) information quality (5.43 vs. 4.62 p < .001) and interface quality (5.66 vs. 4.64 p < .001) to be significantly higher for this interface as well. Approximately 3 out of 4 participants preferred the VCA interface to the standard one. Although the overall time taken was slightly longer than with standard interface the VCA interface was rated significantly better across all other measures and was preferred by the participants. These findings demonstrate the advantages of an innovative VCA interface for collecting FHx validating the efficacy of using VCAs to collect complex patient-specific data in health care.;2020
Featured Application Core technology for intelligent virtual assistants. Abstract A conversation is based on internal knowledge that the participants already know or external knowledge that they have gained during the conversation. A chatbot that communicates with humans by using its internal and external knowledge is called a knowledge-grounded chatbot. Although previous studies on knowledge-grounded chatbots have achieved reasonable performance they may still generate unsuitable responses that are not associated with the given knowledge. To address this problem we propose a knowledge-grounded chatbot model that effectively reflects the dialogue context and given knowledge by using well-designed attention mechanisms. The proposed model uses three kinds of attention: Query-context attention query-knowledge attention and context-knowledge attention. In our experiments with the Wizard-of-Wikipedia dataset the proposed model showed better performances than the state-of-the-art model in a variety of measures.;2020
Firms are deploying chatbots to automate customer service. However miscommunication is a frequent occurrence in human-chatbot interaction. This study investigates the relationship between miscommunication and adoption for customer service chatbots. Anthropomorphism is tested as an account for the relationship. Two experiments compare the perceived humanness and adoption scores for (a) an error-free chatbot (b) a chatbot seeking clarification regarding a consumer input and (c) a chatbot which fails to discern context. The results suggest that unresolved errors are sufficient to reduce anthropomorphism and adoption intent. However there is no perceptual difference between an error-free chatbot and one which seeks clarification. The ability to resolve miscommunication (clarification) appears as effective as avoiding it (error-free). Furthermore the higher a consumer's need for human interaction the stronger the anthropomorphism - adoption relationship. Thus anthropomorphic chatbots may satisfy the social desires of consumers high in need for human interaction.;2020
Following the outbreak of what would become the COVID-19 pandemic social distancing measures were quickly introduced across East Asia-including drastic shelter-in-place orders in some cities-drawing on experience with the outbreak of severe acute respiratory syndrome (SARS) almost two decades ago. Smart City technologies and other digital tools were quickly deployed for infection control purposes ranging from conventional thermal scanning cameras to digital tracing in the surveillance of at-risk individuals. Chatbots endowed with artificial intelligence have also been deployed to shift part of healthcare provision away from hospitals and to support a number of programmes for self-management of chronic disease in the community. With the closure of schools and adults working from home digital technologies have also sustained many aspects of both professional and social life at a pace and scale not considered to be practicable before the outbreak. This paper considers how these new experiences with digital technologies in public health surveillance are spurring digitalization in East Asian societies beyond the conventional public health context. It also considers some of the concerns and challenges that are likely to arise with rapid digitalization particularly in healthcare.;2020
From past research it is well known that social exclusion has detrimental consequences for mental health. To deal with these adverse effects socially excluded individuals frequently turn to other humans for emotional support. While chatbots can elicit social and emotional responses on the part of the human interlocutor their effectiveness in the context of social exclusion has not been investigated. In the present study we examined whether an empathic chatbot can serve as a buffer against the adverse effects of social ostracism. After experiencing exclusion on social media participants were randomly assigned to either talk with an empathetic chatbot about it (e.g. I'm sorry that this happened to you) or a control condition where their responses were merely acknowledged (e.g. Thank you for your feedback). Replicating previous research results revealed that experiences of social exclusion dampened the mood of participants. Interacting with an empathetic chatbot however appeared to have a mitigating impact. In particular participants in the chatbot intervention condition reported higher mood than those in the control condition. Theoretical methodological and practical implications as well as directions for future research are discussed.;2020
Generating response with both coherence and diversity is a challenging task in generation-based chatbots. It is more difficult to improve the coherence and diversity of dialog generation at the same time in the response generation model. In this article we propose an improved method that improves the coherence and diversity of dialog generation by changing the model to use gamma sampling and adding attention mechanism to the knowledge-guided conditional variational autoencoder. The experimental results demonstrate that our proposed method can significantly improve the coherence and diversity of knowledge-guided conditional variational autoencoder for response generation in generation-based chatbots at the same time.;2020
How authentic are inquiry calls made by simulated clients or 'mystery shoppers' to service organizations when compared to real callers? We analysed 48 simulated and 63 real inquiry calls to different veterinary practices in the United Kingdom and Ireland. The data were transcribed for conversation analysis as well as coded for a variety of call categories including reason for the call call outcome and turn design features. Analysis revealed systematic differences between real and simulated calls in terms of (1) reasons for the call call outcome and call duration and (2) how callers refer to their pets in service requests and follow-up questions about their animal. Our qualitative analyses were supported with statistical summaries and tests. The findings reveal the limitations of mystery shopper methodology for the assessment of service provision. We also discuss the implications of the findings for the use of simulated encounters and the development of conversational agents.;2020
Human-computer conversation is an active research topic in natural language processing. One of the representative methods to build conversation systems uses the sequence-to-sequence (Seq2seq) model through neural networks. However with limited input information the Seq2seq model tends to generate meaningless and trivial responses. It can be greatly enhanced if more supplementary information is provided in the generation process. In this work we propose to utilize retrieved responses to boost the Seq2seq model for generating more informative replies. Our method called ReBoost incorporates retrieved results in the Seq2seq model by a hierarchical structure. The input message and retrieved results can influence the generation process jointly. Experiments on two benchmark datasets demonstrate that our model is able to generate more informative responses in both automatic and human evaluations and outperforms the state-of-the-art response generation models.;2020
Human-machine addressee detection (H-M AD) is a modern paralinguistics and dialogue challenge that arises in multiparty conversations between several people and a spoken dialogue system (SDS) since the users may also talk to each other and even to themselves while interacting with the system. The SDS is supposed to determine whether it is being addressed or not. All existing studies on acoustic H-M AD were conducted on corpora designed in such a way that a human addressee and a machine played different dialogue roles. This peculiarity influences speakers' behaviour and increases vocal differences between human- and machine-directed utterances. In the present study we consider the Restaurant Booking Corpus (RBC) that consists of complexity-identical human- and machine-directed phone calls and allows us to eliminate most of the factors influencing speakers' behaviour implicitly. The only remaining factor is the speakers' explicit awareness of their interlocutor (technical system or human being). Although complexity-identical H-M AD is essentially more challenging than the classical one we managed to achieve significant improvements using data augmentation (unweighted average recall (UAR) = 0.628) over native listeners (UAR = 0.596) and a baseline classifier presented by the RBC developers (UAR = 0.539).;2020
Imagine walking into a department store to shop for various products. Based on the social heuristics related to expertise you would likely favor and trust the advice conveyed by a product specialist dedicated to his/her product base than by a generalist advisor who opines on all product categories. As per the computers are social actors theory this effect should also apply to people's interaction with embodied conversational agents simulating product advisors in a multi-product category e-commerce. This study evaluated the effects of specialist agent design using surfaces cues that were 1) agents' self-introduction as product specialists and 2) agents' assignment to dedicated product categories in a multi-product category e-commerce website. An experiment (n = 122) was conducted to compare the effects of the specialist agent design against the conventional generalist agent design where one agent advised on all product categories. Consistent with source credibility theory and multiple source effect theory the results demonstrated that specialist agent design increased the perceived agent's expertise message trustworthiness social presence website trust and purchase intention. Further mediation analyses revealed that perceived agent's expertise and message trustworthiness mediated the effects of specialist agent design on purchase intention thus affirming the source credibility model. As predicted by multiple source theory the implementation of multiple agents in the specialist agent design prompted a higher social presence which was found to be a mediating factor that led to higher perceived website trust ability and benevolence. Finally the effects of specialist agent design on purchase intentions were also mediated by perceived website trust ability and benevolence. Theoretical and practical implications are discussed in this paper.;2020
In dialogue speakers produce and perceive acoustic/prosodic turn-taking cues which are fundamental for negotiating turn exchanges with their interlocutors. However little of the temporal dynamics and cross-linguistic validity of these cues is known. In this work we explore a set of acoustic/prosodic cues preceding three turn-ransition types (hold switch and backchannel) in three different languages (Slovak American English and Argentine Spanish). For this we use and refine a set of machine learning techniques that enable a finer-grained temporal analysis of such cues as well as a comparison of their relative explanatory power. Our results suggest that the three languages despite belonging to distinct linguistic families share the general usage of a handful of acoustic/prosodic features to signal turn transitions. We conclude that exploiting features such as speech rate final-word lengthening the pitch track over the final 200 ms the intensity track over the final 1000 ms and noise-to-harmonics ratio (a voice-quality feature) might prove useful for further improving the accuracy of the turn-taking modules found in modern spoken dialogue systems.;2020
IN MARCH 2011 the catastrophic accident known as The Fukushima Daiichi nuclear disaster took place initiated by the Tohoku earthquake and tsunami in Japan. The only nuclear accident to receive a Level-7 classification on the International Nuclear Event Scale since the Chernobyl nuclear power plant disaster in 1986 the Fukushima event triggered global concerns and rumors regarding radiation leaks. Among the false rumors was an image which had been described as a map of radioactive discharge emanating into the Pacific Ocean as illustrated in the accompanying figure. In fact this figure depicting the wave height of the tsunami that followed still to this date circulates on social media with the inaccurate description. Social media is ideal for spreading rumors because it lacks censorship. Confirmation bias and filter-bubble effects further amplify the spread of unconfirmed information. Upon public outcry independent fact-checking organizations have emerged globally and many platforms are making efforts to fight against fake news. For example the state-run Factually website in Singapore has been known to clarify falsehoods since its inception in May 2012 which was followed recently by the implementation of the Protection from Online Falsehoods and Manipulation Act (POFMA) in October 2019. In Taiwan the government officially created a feature on the website of the Executive Yuan (the executive branch of Taiwan's government) to identify erroneous reporting and combat the spread of fake news. Taiwan's Open Culture Foundation has also developed and introduced the well-known anti-fake fact-checking chatbot Cofacts in May 2018. The Indonesia government since 2018 has held weekly briefings on hoax news that same year the country revised its Criminal Code to permit the imprisonment for up to six years of anyone spreading fake news. Governments in the Asia and Oceania region including South Korea Singapore Japan Taiwan Philippines Cambodia Malaysia have enacted relevant laws to prevent fake news from spreading. Nonetheless fact-checking of fake news remains daunting and requires tremendous time and effort in terms of human investigation. Moreover it is prone to low efficiency and inadequate coverage due to the complexity of the topics being checked and is incapable of keeping up with the fast production and diffusion of falsehoods online. This article will review some of the latest techniques to automatically debunk fake news many of which were initiated in the Asia and Oceania region.;2020
In order to realize real-time marriage legal consultation automatically a marriage legal dialogue system based on the parallel C4.5 decision tree was designed in this paper. Firstly the legal consultation problem is transformed into a classification task. Secondly a legal consultation classification prediction model based on the parallel C4.5 decision tree algorithm was trained with MapReduce by collected data. Finally a model based on the SVM algorithm which has a strategy that was designed to provide automatic interaction for users was designed to extract attribute value from the user's input. When a new user comes to consult an automatic legal dialogue is launched to respond to user intelligently. The proposed system works well in some real applications such as the divorce problem and the experimental results show that it is outperforming the SVM and NB algorithm and more applicable than the other two algorithms. Moreover the system can return consultation results with fewer questions asked to the user than some automatic legal consultation websites which improves the efficiency of consultation.;2020
In recent decades many researchers pay a lot of attention on generating informative responses in end-to-end neural dialogue systems. In order to output the responses with knowledge and fact many works leverage external knowledge to guide the process of response generation. However human dialogue is not a simple sequence to sequence task but a process heavily relying on their background knowledge about the topic. Thus the key of generating informative responses is leveraging the appropriate knowledge associated with current topic. This paper focus on addressing incorporating the appropriate knowledge in response generation. We adopt the reinforcement learning to select the most proper knowledge as the input information of the response generation part. Then we design an end-to-end dialogue model consisting of the knowledge decision part and the response generation part. The proposed model is able to effectively complete the knowledge driven dialogue task with specific topic. Our experiments clearly demonstrate the superior performance of our model over other baselines.;2020
In recent times Electronic Learning (E-Learning) and Massive Open Online Courses (MOOC) are more popular among the current generation of learners. Coursera Edx Simplilearn Byjus and many other E-Learning service providers are available to deliver various courses. A recent study in online courses it has been found by Massachusetts Institute of Technology (MIT) that an astronomical dropout rate of about 96 per cent was found for the last five years. Educational researchers are attempting to decrease the dropout rate of E-Learning courses using various methods. Human Computer Interface (HCI) researchers are attempting to use Brain Computer Interface (BCI) to increase the efficiency of the E-Learning. Beta waves (14-30 Hz) are generated when the learners are more alert. Neil Fleming & x2019s VARK (Visual Auditory Read and Write and Kinesthetic) questionnaires are used by many researchers to classify the learners. Carl Jung explored that Introverts and Extraverts are the personality traits among the humans. Soomin Kim's study shows that for gathering of quantitative data Chatbot may be a promising method. The proposed research work in this paper is to find out a correlation between Introvert and Extravert personality types and their learning styles. Initially modified VARK questionnaires are implemented as a Chatbot to classify individuals as Introverts or Extraverts. After the classifications by the Chatbot two minutes of visual and auditory contents are given to Introverts and Extraverts and learners' Beta brain waves are recorded and a dataset is created at an interval of one second. The dataset is validated using Machine Learning (ML) algorithms like Naive Bayes N48 and Canopy. The proposed method is found to improve the accuracy of classification of learners. Bio-Inspired learning style Brain Computing Interface (BIL-BCI) framework proposed in this paper is a recommendation system to increase the accuracy of the classification among the E-Learners.;2020
In recent years we have witnessed a surge in machine learning methods that provide machines with conversational abilities. Most notably neural-network-based systems have set the state of the art for difficult tasks such as speech recognition semantic understanding dialogue management language generation and speech synthesis. Still unlike for the ancient game of Go for instance we are far from achieving human-level performance in dialogue. The reasons for this are numerous. One property of human-human dialogue that stands out is the infinite number of possibilities of expressing oneself during the conversation even when the topic of the conversation is restricted. A typical solution to this problem was scaling-up the data. The most prominent mantra in speech and language technology has been There is no data like more data. However the researchers now are focused on building smarter algorithms - algorithms that can learn efficiently from just a few examples. This is an intrinsic property of human behavior: an average human sees during their lifetime a fraction of data that we nowadays present to machines. A human can even have an intuition about a solution before ever experiencing an example solution. The human-inspired ability to adapt may just be one of the keys in pushing dialogue systems toward human performance. This article reviews advancements in dialogue systems research with a focus on the adaptation methods for dialogue modeling and ventures to have a glance at the future of research on adaptable conversational machines.;2020
In recent years teaching machines to ask meaningful and coherent questions has attracted considerable attention in natural language processing. Question generation has found wide applications in areas such as education (testing knowledge) and chatbots (enhancing interaction). Following previous studies on conversational question generation we propose a pretrained encoder-decoder model that can incorporate the semantic information from both passage and hidden conversation representations. We adopt BERT as the encoder to combine external text and dialogue history and we design a multi-head attention-based decoder to incorporate the semantic information from both text and hidden dialogue representations into the decoding process thereby generating coherent questions. Experiments with conversational question generation and document-grounded dialogue response generation tasks indicate that the proposed model is superior to baseline models in terms of both standard metrics and human evaluations.;2020
In the continuous development of the Internet the amount of information storage is getting larger and larger. People's standards for information demand are getting higher and higher. In the face of a large amount of data in the Internet fast and accurate data acquisition has become the most urgent demand at present. At the same time with the deepening of environmental awareness in all walks of life the contradiction between the shortcomings of traditional energy and the requirements of environmental protection becomes more and more obvious. New clean energy has many advantages such as cleanness high efficiency and renewability which has gradually become the main trend of environmental energy development. Therefore based on the development principle of green environmental protection economy environmental protection new energy can be combined with the design of intelligent robot so as to finally design a special clean and environmental protection robot. According to the principle of the construction of Q&A System it used octopus to collect environmental protection knowledge build library and use the Vector Space Model (VSM) for text similarity calculation. Raspberry Pi was used to develop hardware and ultimately a voice chatbot about environmental protection knowledge had been achieved. It can answer the problems of environmental protection knowledge and make environmental knowledge and environmental protection concept deeply rooted in the hearts of the people. It is a contribution to environmental causes.;2020
In the development of commercial promotion chatbot is known as one of significant skill by application of natural language processing (NLP). Conventional design methods are using bag-of-words model (BOW) alone based on Google database and other online corpus. For one thing in the bag-of-words model the vectors are Irrelevant to one another. Even though this method is friendly to discrete features it is not conducive to the machine to understand continuous statements due to the loss of the connection between words in the encoded word vector. For other thing existing methods are used to test in state-of-the-art online corpus but it is hard to apply in real applications such as telemarketing data. In this paper we propose an improved chatbot design way using hybrid bag-of-words model and skip-gram model based on the real telemarketing data. Specifically we first collect the real data in the telemarketing field and perform data cleaning and data classification on the constructed corpus. Second the word representation is adopted hybrid bag-of-words model and skip-gram model. The skip-gram model maps synonyms in the vicinity of vector space. The correlation between words is expressed so the amount of information contained in the word vector is increased making up for the shortcomings caused by using bag-of-words model alone. Third we use the term frequency-inverse document frequency (TF-IDF) weighting method to improve the weight of key words then output the final word expression. At last the answer is produced using hybrid retrieval model and generate model. The retrieval model can accurately answer questions in the field. The generate model can supplement the question of answering the open domain in which the answer to the final reply is completed by long-short term memory (LSTM) training and prediction. Experimental results show which the hybrid word vector expression model can improve the accuracy of the response and the whole system can communicate with humans.;2020
In the past decade public institutions and private entities have launched large campaigns of digitization of cultural artefacts leading to the creation of massive digital collections like Europeana Europe's digital cultural library museum and archive. It offers public access to millions of digital objects from thousands of contributing heritage collections all across the European Union using a multilingual interface built upon the principles of the Semantic Web. However such large digital libraries suffer due to low accessibility for the general public and difficult search and navigation through their items. Intelligent conversational agents have the potential of facilitating user-friendly access to the vast amount of information in the Semantic Web by natural language interaction and by providing structured answers to the user's queries. More recently new technologies additionally fostered the development of intelligent conversational agents for a wide range of applications. Following this approach we propose a solution to improve the accessibility and search accuracy of digital cultural heritage resources from Europeana through a system which integrates artificial intelligence natural language technologies web services and APIs. (C) 2019 Elsevier Masson SAS. All rights reserved.;2020
In the present study we developed a chatbot that helps teachers to deliver writing instructions. By working with the chatbot the post-secondary writers developed a thesis statement for their argumentative essay outlines and the chatbot helped the writers to refine their peer review feedback. We conducted a preliminary analysis of the effect of a chatbot on these writers' writing achievement. We also collected several student testimonials about their chatbot experiences. Several important pedagogical and research implications for chatbot-guided writing instructions and the use of learning technology have been addressed.;2020
In this article we present HealthAssistantBot an intelligent virtual assistant able to talk with patients in order to understand their symptomatology suggest doctors and monitor treatments and health parameters. In a simple way by exploiting a natural language-based interaction the system allows the user to create her health profile to describe her symptoms to search for doctors or to simply remember a treatment to follow. Specifically our methodology exploits machine learning techniques to process users symptoms and to automatically infer her diseases. Next the information obtained is used by our recommendation algorithm to identify the nearest doctor who can best treat the user& x2019s condition considering the community data. In the experimental session we evaluated our HealthAssistantBot with both an offline and online evaluation. In the first case we assessed the performance of our internal components while in the second one we carried out a study involving 102 subjects who interacted with the conversational agent in a daily use scenario. Results are encouraging and showed the effectiveness of the strategy in supporting the patients in taking care of their health.;2020
In this paper we introduce a game-based approach for Collaborative Problem Solving (CPS) Skills assessment and provide preliminary evidence from a validation pilot study. To date educational assessments have focused more heavily on the concrete and accessible aspects of CPS with a diminished representation of the social aspects of CPS. We addressed this issue through the integration of our CPS construct into the game-based assessment Circuit Runner in which participants interact with a virtual agent to solve a series of challenges in a first-person maze environment (von Davier 2017). Circuit Runner provides an environment that allows for controlled interdependence between a user and a virtual agent that facilitates the demonstration of the broad range of cognitive and social skills required for effective CPS. Tasks are designed to incorporate telemetry-based (e.g. log file clickstream interaction-based) and item response data to provide a more comprehensive measure of CPS skills. Our study included 500 participants on Amazon Mechanical Turk who completed Circuit Runner pre- and post-game surveys and a CPS situational judgment test (CPS-SJT). These elements in conjunction with the game-play allowed for an expanded exploration of CPS skills with different modalities and types of instruments. The findings support and extend efforts to provide a stronger theoretical and empirical foundation for insights regarding CPS as a skillset as well as the design of scalable game-based CPS assessments.;2020
In this series we explore technology-related themes and topics. This series aims to discuss and demystify what may be new areas for some readers and to consider their relevance for English language teachers.;2020
In this work we have enhanced the perception of a humanoid robot by integrating it with a social state estimation system. We present a user study of the humanoid Nao robot as a social mediator comprising two sets of experiments. In the first sets of experiments the participants rate their understanding of feedback messages delivered via the Nao robot. They also assess two modalities to deliver the feedback: audio only and audio combined with gestures. In almost all cases there is an improvement of 10% or more when audio and gesture modalities are combined to deliver feedback messages. For the second sets of experiments the sociofeedback system was integrated with the Nao robot. The participants engage in two-person scenario-based conversations while the Nao robot acts as a mediator. The sociofeedback system analyzes the conversations and provides feedback via Nao. Subsequently the participants assess the received sociofeedback with respect to various aspects including its content appropriateness and timing. Participants also evaluate their overall perception of Nao as social mediator via the Godspeed questionnaire. The results indicate that the social feedback system is able to detect the social scenario with 93.8% accuracy and that Nao can be effectively used to provide sociofeedback in discussions. The results of this paper pave the way to natural human-robot interactions for social mediators in multi-party dialog systems.;2020
In this work we present a model for the automatic generation of written dialogues through the use of grammatical inference. This model allows the automatic recognition of grammars from a set dialogues employed as a training set. The inferred grammars are then used to generate templates of responses within the dialogues. The final objective is to apply this model in a specific domain dialogue system that answers questions in Spanish with the use of a knowledge base. The experiments carried out have been performend using the DIHANA project corpus which contains dialogues written in Spanish about schedules and prices of a rail system.;2020
Intelligent tutoring systems (ITSs) are computer programs that provide instruction adapted to the needs of individual students. Dialog systems are computer programs that communicate with human users by using natural language. This paper presents a systematic literature review to address ITSs that incorporate dialog systems and have been implemented in the last twenty years. The review found 33 ITSs and focused on answering the following five research questions. a) What ITSs with natural language dialogue have been developed? b) What is the main purpose of the tutoring dialogue in each system? c) What are the pedagogical features of the teaching process performed by the ITSs with natural language dialogue? d) What natural language understanding approach does each system employ to understand students' utterances? e) What evidence exists related to the evaluation of ITSs with natural language dialogue? The results of this review reveal that most ITSs are directed toward science technology engineering and mathematics (STEM) domains at the university level and the majority of the selected ITSs implement the expectations and misconceptions tailored approach. Furthermore most ITSs use dialog to help students learn how to solve a problem by applying rules laws etc. (the apply level in Bloom's taxonomy). With regard to the instructional approach the selected ITSs help students write correct explanations or answers for deep questions assist students in problem solving or support a reflective dialogue motivated by either previously provided content or the result of a simulation. Additionally we found empirical evaluations for 90.91% of the selected ITSs that measure the learning gains and/or assess the impacts of different tutoring strategies.;2020
Intent detection (ID) and slot filling (SF) are important components in spoken language understanding (SLU) of a dialogue system. The most widely used method is pipeline manner which detects the user's intent at first then labels the slots. For the purpose of addressing error propagate some researchers combine these two tasks together by ID and SF joint model. However the joint models usually perform well only on one of these tasks due to the different values of the trade-off-parameter. We therefore propose an encoder-decoder model with a new tag scheme which unifies these two tasks into one sequence labeling task. In our model the process of slot filling can receive an intent information and the performance about multiple tags of a word has been improved. Moreover we show a length-variable attention which can selectively look at a subset of source sentence in the sequence labeling model. Experimental results on two datasets display that the proposed model with length-variable attention outperforms over other joint models. Besides our method will automatically find the balance between two tasks and achieve better overall performances. (C) 2019 Elsevier B.V. All rights reserved.;2020
Interactions with embodied conversational agents can be enhanced using human-like co-speech gestures. Traditionally rule-based co-speech gesture mapping has been utilized for this purpose. However the creation of this mapping is laborious and often requires human experts. Moreover human-created mapping tends to be limited therefore prone to generate repeated gestures. In this article we present an approach to automate the generation of rule-based co-speech gesture mapping from publicly available large video data set without the intervention of human experts. At run-time word embedding is utilized for rule searching to get the semantic-aware meaningful and accurate rule. The evaluation indicated that our method achieved comparable performance with the manual map generated by human experts with a more variety of gestures activated. Moreover synergy effects were observed in users' perception of generated co-speech gestures when combined with the manual map.;2020
Interest and self-efficacy are crucial to academic success. This study addresses two gaps in our understanding of their development and support during university courses: how prior self-efficacy and interest plays a role in and how different classroom activities build toward the development of students' future interest and self-efficacy. In this study the interplay between ability-beliefs (self-efficacy/self-concept) and interest at three levels of specificity (Domain Course and Task) were tested across a Japanese university language course (n = 128). Within this test students' interest in two language practice tasks (i.e. Human and then Chatbot partners) were assessed and compared. Prior interest was a robust predictor of all future task/course interest. Only Human-Human task interest directly predicted future course self-efficacy but was mediated by course interest for future domain interest. For future interest Human practice partners are superior to AIs. Supporting prior domain and later course interest should be a focus for university educators.;2020
Internet-delivered intervention may be an acceptable alternative for the more than 90% of problem gamblers who are reluctant to seek face-to-face support. Thus we aimed to (1) develop a low-dropout unguided intervention named GAMBOT integrated with a messaging app and (2) investigate its effect. The present study was a randomised quadruple-blind controlled trial. We set pre-to-post change in the Problem Gambling Severity Index (PGSI) as the primary outcome and pre-to-post change in the Gambling Symptom Assessment Scale (G-SAS) as a secondary outcome. Daily monitoring personalised feedback and private messages based on cognitive behavioural theory were offered to participants in the intervention group through a messaging app for 28 days (GAMBOT). Participants in the control group received biweekly messages only for assessments for 28 days (assessments only). A total of 197 problem gamblers were included in the primary analysis. We failed to demonstrate a significant between-group difference in the primary outcome (PGSI - 1.14 95% CI - 2.75 to 0.47p = 0.162) but in the secondary outcome (G-SAS - 3.14 95% CI - 0.24 to - 6.04p = 0.03). Only 6.7% of the participants dropped out during follow-up and 77% of the GAMBOT group participants (74/96) continued to participate in the intervention throughout the 28-day period. Integrating intervention into a chatbot feature on a frequently used messaging app shows promise in helping to overcome the high dropout rate of unguided internet-delivered interventions. More effective and sophisticated contents delivered by a chatbot should be sought to engage over 90% of problem gamblers who are reluctant to seek face-to-face support.;2020
INTRODUCTION: Numerous issues in mental health benefit from technological innovation. An example involves the mental health challenges of long-duration spaceflight (such as a Mars mission) including prolonged confinement microgravity and different sunlight exposure lengths. Persisting on Earth are global mental health challenges stemming from disease burdens limited interview-based diagnostic systems trial-and-error treatment approaches and suboptimal access. There is potential for cross-pollinating solutions between these seemingly disparate challenges using a range of emerging technologies such as sensors'omics' and big data. In this review we highlight the bidirectional value of mental health technology transfer aimed to address issues both on Earth and in space. METHODS: We prepared a systematic review of studies pertaining to mental health technological innovation and space medicine. RESULTS: For Earth mental health technologies translatable to long-duration space missions we cite several example technologies including device-based psychotherapy and social support conversational agents 'aka chatbots' and nutritional and physical activity focused mental health. Space technologies translatable to Earth mental health include remote sensing devices global navigation satellite systems satellite communications chronotherapies and nutritional advances. DISCUSSION: There is a rich history of space technologies informing Earth technological trends including general health care on Earth and vice versa. To avoid the traditional happenstance approach that results in delays missed opportunities and increased cost and to improve outcomes for both Earth and space utilization of these technologies we propose increased dialogue and training opportunities to enhance innovation and outcomes.;2020
Introduction:People with disabilities or special needs can benefit from AI-based conversational agents (i.e. chatbots) that are used for competence training and well-being management. Assessing the quality of interactions with these chatbots is key to being able to reduce dissatisfaction with them and to understanding their potential long-term benefit. This in turn will help to increase adherence to their use thereby improving the quality of life of the large population of end-users that they are able to serve. Methods:Following Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) methodology we systematically reviewed the literature on methods of assessing the perceived quality of interactions with chatbots using the from Scopus and the Web of Science electronic databases. Using the Boolean operators (AND/OR) the keywords chatbot* conversational agent* special needs disability were combined. Results:Revealed that only 15 of 192 papers on this topic included people with disabilities or special needs in their assessments. The results also highlighted the lack of a shared theoretical framework for assessing the perceived quality of interactions with chatbots. Conclusion:Systematic procedures based on reliable and valid methodologies continue to be needed in this field. The current lack of reliable tools and systematic methods to assess chatbots for people with disabilities and special needs is concerning and ultimately it may also lead to unreliable systems entering the market with disruptive consequences for people.;2020
Listening skills are critical for human communication. Social skills training (SST) performed by human trainers is a well-established method for obtaining appropriate skills in social interaction. Previous work automated the process of social skills training by developing a dialogue system that teaches speaking skills through interaction with a computer agent. Even though previous work that simulated social skills training considered speaking skills the SST framework incorporates other skills such as listening asking questions and expressing discomfort. In this paper we extend our automated social skills training by considering user listening skills during conversations with computer agents. We prepared two scenarios: Listening 1 and Listening 2 which respectively assume small talk and job training. A female agent spoke to the participants about a recent story and how to make a telephone call and the participants listened. We recorded the data of 27 Japanese graduate students who interacted with the agent. Two expert external raters assessed the participants' listening skills. We manually extracted features that might be related to the eye fixation and behavioral cues of the participants and confirmed that a simple linear regression with selected features correctly predicted listening skills with a correlation coefficient above 0.50 in both scenarios. The number of noddings and backchannels within the utterances contributes to the predictions because we found that just using these two features predicted listening skills with a correlation coefficient above 0.43. Since these two features are easier to understand for users we plan to integrate them into the framework of automated social skills training.;2020
Machine learning holds great promise for lowering product and service costs speeding up business processes and serving customers better. It is recognized as one of the most important application areas in this era of unprecedented technological development and its adoption is gaining momentum across almost all industries. In view of this we offer a brief discussion of categories of machine learning and then present three types of machine-learning usage at enterprises. We then discuss the trade-off between the accuracy and interpretability of machine-learning algorithms a crucial consideration in selecting the right algorithm for the task at hand. We next outline three cases of machine-learning development in financial services. Finally we discuss challenges all managers must confront in deploying machine-learning applications. (C) 2019 Kelley School of Business Indiana University. Published by Elsevier Inc. All rights reserved.;2020
Metacognitive skill training may rest within any kind of social interaction that requires awareness of what an individual and others think in social educational and organizational settings alike. This work is an extensive study of multimodal application interaction (virtual agent spoken dialogue visual communication of progress) for metacognitive skill training via negotiation skill training scenarios. Human behaviour as effected by civic action and interpersonal and problem-solving skill training is investigated through interaction sessions with a virtual agent on multimodal multiparty negotiation. This work reports on the results of the user-system evaluation sessions involving 41 participants before and after interaction with the system integrating macro- (dialogue system performance) and micro- (metacognitive-related and individual- and community-level-related attitudes and skills) factors. Findings indicate significant and positive relationships between user and system evaluation questions after interaction with the dialogue system and between self-efficacy self-regulation individual readiness to change mastery goal orientation interpersonal and problem-solving skills and civic action before and after the interaction experience. Implications limitations and further research issues are discussed in light of context of the multimodal interaction and its effects on the human behaviour during metacognitive skill training.;2020
Multimodal dialogue system due to its many-fold applications has gained much attention to the researchers and developers in recent times. With the release of large-scale multimodal dialog dataset Saha et al. 2018 on the fashion domain it has been possible to investigate the dialogue systems having both textual and visual modalities. Response generation is an essential aspect of every dialogue system and making the responses diverse is an important problem. For any goal-oriented conversational agent the system's responses must be informative diverse and polite that may lead to better user experiences. In this paper we propose an end-to-end neural framework for generating varied responses in a multimodal dialogue setup capturing information from both the text and image. Multimodal encoder with co-attention between the text and image is used for focusing on the different modalities to obtain better contextual information. For effective information sharing across the modalities we combine the information of text and images using the BLOCK fusion technique that helps in learning an improved multimodal representation. We employ stochastic beam search with Gumble Top K-tricks to achieve diversified responses while preserving the content and politeness in the responses. Experimental results show that our proposed approach performs significantly better compared to the existing and baseline methods in terms of distinct metrics and thereby generates more diverse responses that are informative interesting and polite without any loss of information. Empirical evaluation also reveals that images while used along with the text improve the efficiency of the model in generating diversified responses.;2020
Natural Language Generation (NLG) is a critical component of spoken dialogue systems and it has a significant impact both on usability and perceived quality. Most existing NLG approaches in common use employ rules and heuristics and tend to generate rigid and stylised responses without the natural variation of human language. Moreover these limitations also add significantly to development costs and make the delivery of cross-domain cross-lingual dialogue systems especially complex and expensive. The first contribution of this paper is to present RNNLG a Recurrent Neural Network (RNN)-based statistical natural language generator that can learn to generate utterances directly from dialogue act - utterance pairs without any predefined syntaxes or semantic alignments. The presentation includes a systematic comparison of the principal RNN-based NLG models available. The second contribution is to test the scalability of the proposed system by adapting models from one domain to another. We show that by pairing RNN-based NLG models with a proposed data counterfeiting method and a discriminative objective function a pretrained model can be quickly adapted to different domains with only a few examples. All of the findings presented are supported by both corpus-based and human evaluations. (C) 2019 Published by Elsevier Ltd.;2020
Natural language generation has become a fundamental task in dialogue systems. RNN-based natural response generation methods encode the dialogue context and decode it into a response. However they tend to generate dull and simple responses. In this article we propose a novel framework called KAWA-DRG (Knowledge-aware Attentive Wasserstein Adversarial Dialogue Response Generation) to model conversation-specific external knowledge and the importance variances of dialogue context in a unified adversarial encoder-decoder learning framework. In KAWA-DRG a co-attention mechanism attends to important parts within and among context utterances with word-utterance-level attention. Prior knowledge is integrated into the conditional Wasserstein auto-encoder for learning the latent variable space. The posterior and prior distribution of latent variables are generated and trained through adversarial learning. We evaluate our model on Switchboard DailyDialog In-Car Assistant and Ubuntu Dialogue Corpus. Experimental results show that KAWA-DRG outperforms the existing methods.;2020
Natural Language Interfaces allow human-computer interaction through the translation of human intention into devices' control commands analyzing the user's speech or gestures. This novel interaction mode arises from advancements of artificial intelligence expert systems speech recognition semantic web dialog systems and natural language processing bringing the concept of Intelligent Personal Assistant (IPA). There is currently a vast literature on this subject. However in the best of our knowledge there is no thorough analysis of the state-of-the-art in the field. In this context we present in this article a survey of the field discussing the main trends critical areas and challenges of an IPA. Another contribution is the proposition of a taxonomy for IPA classification. The method used to achieve these objectives consisted of a systematic literature review based on the population intervention comparison outcome and context (PICOC) criteria. As a result we started from more than 3472 scientific articles published in the last six years searched on a set of databases chosen to increase the probability of finding highly relevant articles. The review selected the 58 most significant articles identifying challenges and open questions. We also discuss in the article the current status usage security and privacy issues types and architectures regarding an IPA. We conclude that usability security and privacy directly affect the confidence of the user in adopting an IPA. (C) 2020 Elsevier Ltd. All rights reserved.;2020
Natural language provides an intuitive and effective interaction interface between human beings and robots. Currently multiple approaches are presented to address natural language visual grounding for human-robot interaction. However most of the existing approaches handle the ambiguity of natural language queries and achieve target objects grounding via dialogue systems which make the interactions cumbersome and time-consuming. In contrast we address interactive natural language grounding without auxiliary information. Specifically we first propose a referring expression comprehension network to ground natural referring expressions. The referring expression comprehension network excavates the visual semantics via a visual semantic-aware network and exploits the rich linguistic contexts in expressions by a language attention network. Furthermore we combine the referring expression comprehension network with scene graph parsing to achieve unrestricted and complicated natural language grounding. Finally we validate the performance of the referring expression comprehension network on three public datasets and we also evaluate the effectiveness of the interactive natural language grounding architecture by conducting extensive natural language query groundings in different household scenarios.;2020
Natural Language Understanding (NLU) is a vital component of dialogue systems and its ability to detect Out-of-Domain (OOD) inputs is critical in practical applications since the acceptance of the OOD input that is unsupported by the current system may lead to catastrophic failure. However most existing OOD detection methods rely heavily on manually labeled OOD samples and cannot take full advantage of unlabeled data. This limits the feasibility of these models in practical applications. In this paper we propose a novel model to generate high-quality pseudo OOD samples that are akin to IN-Domain (IND) input utterances and thereby improves the performance of OOD detection. To this end an autoencoder is trained to map an input utterance into a latent code. Moreover the codes of IND and OOD samples are trained to be indistinguishable by utilizing a generative adversarial network. To provide more supervision signals an auxiliary classifier is introduced to regularize the generated OOD samples to have indistinguishable intent labels. Experiments show that these pseudo OOD samples generated by our model can be used to effectively improve OOD detection in NLU. Besides we also demonstrate that the effectiveness of these pseudo OOD data can be further improved by efficiently utilizing unlabeled data.;2020
New technologies such as Internet of Things (IoT) Augmented Reality (AR) Virtual Reality (VR) Mixed Reality (MR) virtual assistants chatbots. and robots which are typically powered by Artificial Intelligence (AI) are dramatically transforming the customer experience. In this paper we offer a fresh typology of new technologies powered by AI and propose a new framework for understanding the role of new technologies on the customer/shopper journey. Specifically we discuss the impact and implications of these technologies on each broad stage of the shopping journey (pre-transaction transaction and post-transaction) and advance a new conceptualization for managing these new AI technologies along customer experience dimensions to create experiential value. We discuss future research ideas emanating from our framework and outline interdisciplinary research avenues. (C) 2020 Direct Marketing Educational Foundation Inc. dba Marketing EDGE. All rights reserved.;2020
New technology such as fully-automated interactive spoken dialogue systems (SDS) which allow learners to engage in multi-turn conversations with an automated agent could provide a means for second and foreign language learners (L2) to practice form-function-context mappings in oral interaction. In this study we investigated how learners interacted with an automated agent as they engaged in an SDS task that required them to make two requests. We examined the requests employed by 107 L2 learners exploring in particular the request strategies and modifications used. We first transcribed verbatim all audio-recorded dialogues. Then all turns were coded as to whether they contained a request or not. All turns that were identified as including requests were then coded for four categories adopted from Cross-cultural Speech Act Realization Patterns project: (1) Level of directness (2) Request strategy (3) External modifiers and (4) Internal modifiers. Direct requests were most frequently used and learners' preferred request strategies were want-statements and query preparatories. Additionally they employed more internal than external modifications - a finding that seems contrary to most interlanguage studies on request realization. Moreover we found distinct request realizations when comparing L1 Hungarian and L1 Japanese learners of English. We discuss the findings with regard to previous interlanguage studies on request realization the potential impact of an automated agent and ways automated spoken dialog systems might be used to implement individualized feedback to raise learners' pragmatic awareness.;2020
Objective The Pharma Collaboration for Transparent Medical Information (phactMI (TM)) benchmarking survey was conducted to evaluate the use of technology and websites associated with the medical information (MI) departments of 27 biopharmaceutical companies in the United States. Methods The e-survey was administered to phactMI (TM) members between December 2017 and February 2018 and included closed and open-ended questions with 7 distinct categories: existence of a MI website content type available following a search query website functions search engine optimization (SEO) website traffic internal communications/analytics and additional technology capabilities. Results Survey findings noted that 20 companies own a MI-specific website through which MI services are provided to healthcare providers (HCPs). When asked about the dissemination of MI content through varying formats survey results indicated Portable Document Format (PDF) to be the most common (18/27) followed by videos (8/27) presentations (5/27) infographics (3/27) and Hypertext Markup Language (3/27). Many companies have a responsive design website (19/25) webform (24/25) and a 1-800 number (22/25) for MI services. Few companies have a live chat (10/25) or a chatbot (1/25) and 9 of 25 said that content is searchable on Google (TM). Although website traffic varied among companies a significant driver of this appeared to be whether the site is indexed. Conclusion While most of the member companies have a MI website there is significant room for improvement in content formats available as part of a search. Traditional website features such as search functionality and webform are commonly available on websites however newer technologies such as chatbot and live chat are less featured. Across most member companies there is also a need for improvement in increasing website traffic Google (TM) indexing and SEO.;2020
Objective: To understand the therapeutic processes associated with the helpfulness of an online relational agent intervention Manage Your Life Online (MYLO). Methods: Fifteen participants experiencing a mental health related problem used Manage Your Life Online for 2 weeks. At follow-up the participants each identified two helpful and two unhelpful questions posed by Manage Your Life Online within a single intervention session. Qualitative interviews were conducted and analyzed using thematic and content analysis to gain insight into the process of therapy with Manage Your Life Online. Results: MYLO appeared acceptable to participants with a range of presenting problems. Questions enabling free expression increased awareness and new insights were key to a helpful intervention. The findings were consistent with the core processes of therapeutic change according to Perceptual Control Theory a unifying theory of psychological distress. Questions that elicited intense emotions were repetitive confusing or inappropriate were identified as unhelpful and were associated with disengagement or loss of faith in Manage Your Life Online. Conclusions: The findings provide insight into the likely core therapy processes experienced as helpful or hindering and outlines further ways to optimize acceptability of Manage Your Life Online.;2020
Objectives Sexual and reproductive health (SRH) services are undergoing a digital transformation. This study explored the acceptability of three digital services (i) video consultations via Skype (ii) live webchats with a health advisor and (iii) artificial intelligence (AI)-enabled chatbots as potential platforms for SRH advice. Methods A pencil-and-paper 33-item survey was distributed in three clinics in Hampshire UK for patients attending SRH services. Logistic regressions were performed to identify the correlates of acceptability. Results In total 257 patients (57% women 50% aged <25 years) completed the survey. As the first point of contact 70% preferred face-to-face consultations 17% telephone consultation 10% webchats and 3% video consultations. Most would be willing to use video consultations (58%) and webchat facilities (73%) for ongoing care but only 40% found AI chatbots acceptable. Younger age (<25 years) (OR 2.43 95% CI 1.35 to 4.38) White ethnicity (OR 2.87 95% CI 1.30 to 6.34) past sexually transmitted infection (STI) diagnosis (OR 2.05 95% CI 1.07 to 3.95) self-reported STI symptoms (OR 0.58 95% CI 0.34 to 0.97) smartphone ownership (OR 16.0 95% CI 3.64 to 70.5) and the preference for a SRH smartphone application (OR 1.95 95% CI 1.13 to 3.35) were associated with video consultations webchats or chatbots acceptability. Conclusions Although video consultations and webchat services appear acceptable there is currently little support for SRH chatbots. The findings demonstrate a preference for human interaction in SRH services. Policymakers and intervention developers need to ensure that digital transformation is not only cost-effective but also acceptable to users easily accessible and equitable to all populations using SRH services.;2020
Objectives: The objective was to understand how people respond to coronavirus disease 2019 (COVID-19) screening chatbots. Materials and Methods: We conducted an online experiment with 371 participants who viewed a COVID-19 screening session between a hotline agent (chatbot or human) and a user with mild or severe symptoms. Results: The primary factor driving user response to screening hotlines (human or chatbot) is perceptions of the agent's ability. When ability is the same users view chatbots no differently or more positively than human agents. The primary factor driving perceptions of ability is the user's trust in the hotline provider with a slight negative bias against chatbots' ability. Asian individuals perceived higher ability and benevolence than did White individuals. Conclusions: Ensuring that COVID-19 screening chatbots provide high-quality service is critical but not sufficient for widespread adoption. The key is to emphasize the chatbot's ability and assure users that it delivers the same quality as human agents.;2020
Once artificial intelligence (AI) is indistinguishable from human intelligence and robots are highly similar in appearance and behavior to humans there should be no reason to treat AI and robots differently from humans. However even perfect AI and robots may still be subject to a bias (referred to as speciesism in this article) which will disadvantage them and be a barrier to their commercial adoption as chatbots decision and recommendation systems and staff in retail and service settings. The author calls for future research that determines causes and psychological consequences of speciesism assesses the effect of speciesism on the adoption of new products and technologies and identifies ways to overcome it.;2020
One in three university students experiences mental health problems during their study. A similar percentage leaves higher education without obtaining the degree for which they enrolled. Research suggests that both mental health problems and academic underperformance could be caused by students lacking control and purpose while they are adjusting to tertiary education. Currently universities are not designed to cater to all the personal needs and mental health problems of large numbers of students at the start of their studies. Within the literature aimed at preventing mental health problems among students (e.g. anxiety or depression) digital forms of therapy recently have been suggested as potentially scalable solutions to address these problems. Integrative psychological artificial intelligence (AI) in the form of a chatbot for example shows great potential as an evidence-based solution. At the same time within the literature aimed at improving academic performance the online life-crafting intervention in which students write about values and passions goals and goal-attainment plans has shown to improve the academic performance and retention rates of students. Because the life-crafting intervention is delivered through the curriculum and doesn't bear the stigma that is associated with therapy it can reach larger populations of students. But life-crafting lacks the means for follow-up or the interactiveness that online AI-guided therapy can offer. In this narrative review we propose to integrate the current literature on chatbot interventions aimed at the mental health of students with research about a life-crafting intervention that uses an inclusive curriculum-wide approach. When a chatbot asks students to prioritize both academic as well as social and health-related goals and provides personalized follow-up coaching this can prevent -often interrelated- academic and mental health problems. Right on-time delivery and personalized follow-up questions enhance the effects of both -originally separated- intervention types. Research on this new combination of interventions should use design principles that increase user-friendliness and monitor the technology acceptance of its participants.;2020
One of the important criteria used in judging the performance of a chatbot is the ability to provide meaningful and informative responses that correspond with the context of a user's utterance. Nowadays the number of enterprises adopting and relying on task-oriented chatbots for profit is increasing. Dialog errors and inappropriate response to user queries by chatbots can result in huge cost implications. To achieve high performance recent AI chatbot models are increasingly adopting the Transformer positional encoding and the attention-based architecture. While the transformer performs optimally in sequential generative chatbot models recent studies has pointed out the occurrence of logical inconsistency and fuzzy error problems when the Transformer technique is adopted in retrieval-based chatbot models. Our investigation discovers that the encountered errors are caused by information losses. Therefore in this paper we address this problem by augmenting the Transformer-based retrieval chatbot architecture with a memory-based deep neural attention (mDNA) model by using an approach similar to late data fusion. The mDNA is a simple encoder-decoder neural architecture that comprises of bidirectional long short-term memory (Bi-LSTM) attention mechanism and a memory for information retention in the encoder. In our experiments we trained the model extensively on a large Ubuntu dialog corpus and the results from recall evaluation scores show that the mDNA augmentation approach slightly outperforms selected state-of-the-art retrieval chatbot models. The results from the mDNA augmentation approach are quite impressive.;2020
Online Social Networks (OSNs) are the modern communication media at the peak of Internet technology that facilitate users' ability to connect with friends and celebrities and to disseminate breaking news and updates on real-life events. Connections and interactions among OSN users generate a massive amount of data containing a rich collection of knowledge that could be useful to various realworld data modeling and predictive analytics problems like open-source intelligence business intelligence event prediction and product recommendations. On the Web adversaries explore and target products and services for misuse and vulnerabilities and OSNs are no exception. Their large user base easy-to-use functionality and open nature further attract antisocial elements to these OSNs. In OSNs cybercrimes and illicit activities are generally committed using various forms of fake profiles such as clone profiles(1) sybil(2) and bots.;2020
Online users are increasingly exposed to chatbots as one form of AI-enabled media technologies employed for persuasive purposes e.g. making product/service recommendations. However the persuasive potential of chatbots has not yet been fully explored. Using an online experiment (N = 242) we investigate the extent to which communicating with a stand-alone chatbot influences affective and behavioral responses compared to interactive Web sites. Several underlying mechanisms are studied showing that enjoyment is the key mechanism explaining the positive effect of chatbots (vs. Web sites) on recommendation adherence and attitudes. Contrary to expectations perceived anthropomorphism seems not to be particularly relevant in this comparison.;2020
Open-domain generative dialogue systems have attracted considerable attention over the past few years. Currently how to automatically evaluate them is still a big challenge. As far as we know there are three kinds of automatic evaluations for open-domain generative dialogue systems: (1) Word-overlap-based metrics (2) Embedding-based metrics (3) Learning-based metrics. Due to the lack of systematic comparison it is not clear which kind of metrics is more effective. In this article we first measure systematically all kinds of metrics to check which kind is best. Extensive experiments demonstrate that learning-based metrics are the most effective evaluation metrics for open-domain generative dialogue systems. Moreover we observe that nearly all learning-based metrics depend on the negative sampling mechanism which obtains extremely unbalanced and low-quality samples to train a score model. To address this issue we propose a novel learning-based metric that significantly improves the correlation with human judgments by using augmented POsitive samples and valuable NEgative samples called PONE. Extensive experiments demonstrate that PONE significantly outperforms the state-of-the-art learning-based evaluation method. Besides we have publicly released the codes of our proposed metric and state-of-the-art baselines.(1);2020
Personal interviews are widely used to collect open-ended data in an array of settings many of which require solicitation of data that may be regarded as sensitive or threatening by interviewees. The high costs of employing human interviewers can be mitigated by utilizing computer-generated human-like interviewers at least in scripted interview conditions. However the effects of replacing humans with human-like interviewers on interviewees' level of actual disclosure has not been well-researched. This experiment compared disclosure of sensitive information obtained from personal interviews utilizing various interviewer modes. One-hundred and fifty-eight students from a southwestern university were randomly assigned to answer a series of open-ended questions in one of three different personal interview modes: 1) audio-only computer-assisted self-interview (i.e. ACASI) 2) human-like embodied conversational agent (i.e. ECA) or 3) a human interviewer. Disclosure was measured using both self-report and objective scores derived from trained judges. Disclosure levels were significantly higher in the faceless ACASI condition than in the combined virtual and human interviewer conditions both of which were embodied with a face. There was no significant difference between the ECA and human interviewer conditions. This suggests that the mere presence of a human face can inhibit disclosure.;2020
Prevention of cybercrime is one of the missions of Law Enforcement Agencies (LEA) aiming to protect and guarantee sovereignty in the cyberspace. In this regard online sex crimes are among the principal ones to prevent especially those where a child is abused. The paper at hand proposes C3-Sex a smart chatbot that uses Natural Language Processing (NLP) to interact with suspects in order to profile their interest regarding online child sexual abuse. This solution is based on our Artificial Conversational Entity (ACE) that connects to different online chat services to start a conversation. The ACE is designed using generative and rule-based models in charge of generating the posts and replies that constitute the conversation from the chatbot side. The proposed solution also includes a module to analyze the conversations performed by the chatbot and calculate a set of 25 features that describes the suspect's behavior. After 50 days of experiments the chatbot generated a dataset with 7199 profiling vectors with the features associated to each suspect. Afterward we applied an unsupervised method to describe the results that differentiate three groups which we categorize as indifferent interested and pervert. Exhaustive analysis is conducted to validate the applicability and advantages of our solution.;2020
Privacy breaches are one of the biggest concerns on Online Social Networks (OSNs) especially with an introduction of automated attacks by socialbots which can automatically extract victims' private content by exploiting social behavior to befriend them. The key insight of this attack is that by intelligently sending friend requests to a small subset of users called the Critical Friending Set (CFS) such a bot can evade current defense mechanisms. We study the vulnerability of OSNs to socialbot attacks. Specifically we introduce a new optimization problem Min-Friending which identifies a minimum CFS to friend in order to obtain at least Q benefit which quantifies the amount of private information the bot obtains. The two main challenges of this problem are how to cope with incomplete knowledge of network topology and how to model users' responses to friend requests. In this paper we show that Min-Friending is inapproximable within a factor of (1 - o(1) lnQ and present an adaptive approximation algorithm using adaptive stochastic optimization. The key feature of our solution lies in the adaptive method where partial network topology is revealed after each successful friend request. Thus the decision of whom to send a friend request to next is made with the outcomes of past decisions taken into account. Traditional tools break down when attempting to place a bound on the performance of this technique with realistic user models. Therefore we additionally introduce a novel curvature-based technique to construct an approximation ratio of lnQ for a model of user behavior learned from empirical measurements on Facebook.;2020
Professional embodied conversational agents (ECAs) are increasingly present in society. Beyond these virtual agents' professional expertise they must have a social dimension to build long-term relationships with users. Interpersonal intimacy is at the core of the most gratifying social exchanges and we claim that it could constitute a remarkable means to reinforce the social dimension of ECAs. This paper presents an experimental study that compares the perception of intimacy in human and human-agent interactions. Are nature and social expressiveness critical factors for the perception of intimacy? To answer this question we created two corpora of videos showing a human or a virtual tourism information (TI) counselor using or not using intimate behaviors in the course of an interaction with a human tourist. Using the Virtual Intimacy Scale (VIS) designed in previous work we asked observers to judge the intimacy level of the TI counselor during the interaction. We demonstrate that intimate behaviors expressed by the virtual counselor and the human counselor are equally perceived by participants which supposes a common model of intimacy for human and human-agent dyads. Participants perceive the human counselor less intimate than the virtual counselor when having non intimate behaviors. We posit that humans and agents elicit different expectations regarding social abilities which directly affect their perceived level of intimacy. Our work raises questions regarding the expression of social behaviors and questions social representations.;2020
Proteins of the cyclin family have divergent sequences and execute diverse roles within the cell while sharing a common fold: the cyclin box domain. Structural studies of cyclins have played a key role in our characterization and understanding of cellular processes that they control though to date only ten of the 29 CDK-activating cyclins have been structurally characterized by X-ray crystallography or cryo-electron microscopy with or without their cognate kinases. In this review we survey the available structures of human cyclins highlighting their molecular features in the context of their cellular roles. We pay particular attention to how cyclin activity is regulated through fine control of degradation motif recognition and ubiquitination. Finally we discuss the emergent roles of cyclins independent of their roles as cyclin-dependent protein kinase activators demonstrating the cyclin box domain to be a versatile and generalized scaffolding domain for protein-protein interactions across the cellular machinery.;2020
Purpose By adopting a social presence theory perspective this study aims investigate the influence of perceived usefulness of live chat services and of their unique human attributes on customer attitudes beliefs and behaviours in the context of online travel shopping. Design/methodology/approach Based on a cross-sectional survey research involving 8 travel provider websites and 631 travel consumers this work applies structural equation modelling to analyse the data. Findings The results illustrate that the perceived usefulness from the communication with a human live chat assistant positively influences customer attitudes and trust towards the website as well as increasing purchase intention. The findings further illustrate the role of the human social cues conveyed by live chat facilities namely human warmth human assurance human attentiveness and human customised content in positively moderating this effect. Research limitations/implications - The study is limited to specific human attributes. Future research could investigate the role of other human characteristics as well as assess the ability of artificial intelligent powered chatbots in replicating the human elements outlined in this research. Originality/value The study provides a unique contribution to the travel literature by offering empirical insights and conceptual clarity into the usefulness of human operated live chat communication on travellers' attitudes trust towards the website and purchase intentions.;2020
Purpose Chatbots represent an innovative channel for retailers to meet young customers' needs anywhere and at any time. Being an emergent technology however it is important to investigate more thoroughly how users perceive it and which are the variables that enhance a positive attitude towards this technology. On this premise this study applies a social relationship perspective to the design of chatbots addressed to younger consumers. Design/methodology/approach The study adopts a between-participants factorial design to investigate the effects of visual cues (avatar presence vs avatar absence) and interaction styles (social-oriented vs task-oriented) on social presence and how this in turn enhances millennials' perceived enjoyment trust and ultimately attitude towards the chatbot. A survey experiment was employed to conduct the study on data collected from 193 Italian millennials. Findings The results show that applying a social-oriented interaction style increases users' perception of social presence while an insignificant effect was found for avatar presence. The partial least square structural equation modeling (PLS-SEM) analysis further confirms the hypothesised model. Originality/value The adoption of new digital technologies such as chatbots is likely to have a far reaching effect on retailers consumers employees and society. For this reason a broad understanding of the phenomenon is needed. To the best of our knowledge this is the first study to provide results from an experimental design in which both interaction style (social- vs task-oriented) and avatar (presence vs absence) of a chatbot are manipulated to directly explore social presence and its effect on trust perceived enjoyment and millennials' attitude towards a chatbot applied for retailing purposes.;2020
Purpose Conversational agents (chatbots avatars and robots) are increasingly substituting human employees in service encounters. Their presence offers many potential benefits but customers are reluctant to engage with them. A possible explanation is that conversational agents do not make optimal use of communicative behaviors that enhance relational outcomes. The purpose of this paper is to identify which human-like communicative behaviors used by conversational agents have positive effects on relational outcomes and which additional behaviors could be investigated in future research. Design/methodology/approach This paper presents a systematic review of 61 articles that investigated the effects of communicative behaviors used by conversational agents on relational outcomes. A taxonomy is created of all behaviors investigated in these studies and a research agenda is constructed on the basis of an analysis of their effects and a comparison with the literature on human-to-human service encounters. Findings The communicative behaviors can be classified along two dimensions: modality (verbal nonverbal appearance) and footing (similarity responsiveness). Regarding the research agenda it is noteworthy that some categories of behaviors show mixed results and some behaviors that are effective in human-to-human interactions have not yet been investigated in conversational agents. Practical implications By identifying potentially effective communicative behaviors in conversational agents this study assists managers in optimizing encounters between conversational agents and customers. Originality/value This is the first study that develops a taxonomy of communicative behaviors in conversational agents and uses it to identify avenues for future research.;2020
Purpose Developing a Dialogue/Virtual Agent (VA) that can handle complex tasks (need) of the user pertaining to multiple intents of a domain is challenging as it requires the agent to simultaneously deal with multiple subtasks. However majority of these end-to-end dialogue systems incorporate only user semantics as inputs in the learning process and ignore other useful user behavior and information. Sentiment of the user at the time of conversation plays an important role in securing maximum user gratification. So incorporating sentiment of the user during the policy learning becomes even more crucial more so when serving composite tasks of the user. Methodology As a first step towards enabling the development of sentiment aided VA for multi-intent conversations this paper proposes a new dataset annotated with its corresponding intents slot and sentiment (considering the entire dialogue history) labels namedSentiVA collected from open-sourced dialogue datasets. In order to integrate these multiple aspects a Hierarchical Reinforcement Learning (HRL) specificallyoptionsbased VA is proposed to learn strategies for managing multi-intent conversations. Along with task success based immediate rewards sentiment based immediate rewards are also incorporated in the hierarchical value functions to make the VA user adaptive. Findings Empirically the paper shows that task based and sentiment based immediate rewards cumulatively are required to ensure successful task completion and attain maximum user satisfaction in a multi-intent scenario instead of any of these rewards alone. Practical implications The eventual evaluators and consumers of dialogue systems are users. Thus to ensure a fulfilling conversational experience involving maximum user satisfaction requires VA to consider user sentiment at every time-step in its decision making policy. Originality This work is the first attempt in incorporating sentiment based rewards in the HRL framework.;2020
Purpose For decades artificial intelligence (AI) has been utilized within the field of mental healthcare. This paper aims to examine AI chatbots specifically as offered through mobile applications for mental healthcare (MHapps) with attention to the social implications of these technologies. For example AI chatbots in MHapps are programmed with therapeutic techniques to assist people with anxiety and depression but the promise of this technology is tempered by concerns about the apps' efficacy privacy safety and security. Design/methodology/approach Utilizing a social informatics perspective a literature review covering MHapps with a focus on AI chatbots was conducted from the period of January-April 2019. A borrowed theory approach pairing information science and social work was applied to analyze the literature. Findings Rising needs for mental healthcare combined with expanding technological developments indicate continued growth of MHapps and chatbots. While an AI chatbot may provide a person with a place to access tools and a forum to discuss issues as well as a way to track moods and increase mental health literacy AI is not a replacement for a therapist or other mental health clinician. Ultimately if AI chatbots and other MHapps are to have a positive impact they must be regulated and society must avoid techno-fundamentalism in relation to AI for mental health. Originality/value This study adds to a small but growing body of information science research into the role of AI in the support of mental health.;2020
Purpose of review Family caregivers of patients with cancer often spend a great deal of effort on physically and emotionally demanding work while taking care of patients. However the majority of caregivers are not properly equipped for their role as caregivers which may lead to increased distress in both caregivers and patients. Herein we reviewed the recent literature (last 3 years) examining online interventions that seek to support caregiver resilience and decrease distress. Recent findings Our search identified interventions involving three main themes: informational support positive activities and social support. These are mostly in the form of web-based tools and mobile apps targeting both usability and quality of life. Social network services are also considered in this review as a new environment for caregivers to connect with other individuals with lived experience in similar circumstances. Summary Existing studies on online interventions to support caregivers is still at a formative development stage and pilot tests of feasibility rather than a substantive body of randomized controlled trials to assess the impact in different user populations or to determine specific factors that impact caregiver distress level or resilience. More research is needed to further assess the long-term effects of online interventions on caregiver stress and resilience. Also the role of different types of social network services and new forms of interaction such as conversational agents has not yet been fully investigated in caregiver populations. Future research should strive to seek new modes of providing services that may present novel opportunities to enhance caregiver resilience and reduce distress.;2020
Purpose of Review The purpose of this review is to contextualize the topic of patient engagement in orthopedic surgery. There will be a specific focus on patient engagement platforms and the impact on outcomes and orthopedic clinical workflows. Recent Findings In an attempt to engage patients and optimize the orthopedic perioperative surgical home patient engagement platforms have emerged in the form of portals mobile health applications and chatbots. Collectively these platforms have improved patient satisfaction scores and outcomes. Patient portals mobile health applications and chatbots can engage orthopedic patients and improve the effectiveness of the perioperative orthopedic surgical home. There are specific differences in these applications that should be noted and accounted for. When deciding to incorporate one of these systems into your practice it is paramount to identify what you are looking to improve upon within your health system and choose a platform accordingly.;2020
Purpose of Review We review applications of artificial intelligence (AI) including machine learning (ML) in the field of HIV prevention. Recent Findings ML approaches have been used to identify potential candidates for preexposure prophylaxis (PrEP) in healthcare settings in the USA and Denmark and in a population-based research setting in Eastern Africa. Although still in the proof-of-concept stage other applications include ML with smartphone-collected and social media data to promote real-time HIV risk reduction virtual reality tools to facilitate HIV serodisclosure and chatbots for HIV education. ML has also been used for causal inference in HIV prevention studies. ML has strong potential to improve delivery of PrEP with this approach moving from development to implementation. Development and evaluation of AI and ML strategies for HIV prevention may benefit from an implementation science approach including qualitative assessments with end users and should be developed and evaluated with attention to equity.;2020
Purpose The main purpose of our study is to analyze the influence of Artificial Intelligence (AI) on firm performance notably by building on the business value of AI-based transformation projects. This study was conducted using a four-step sequential approach: (1) analysis of AI and AI concepts/technologies (2) in-depth exploration of case studies from a great number of industrial sectors (3) data collection from the databases (websites) of AI-based solution providers and (4) a review of AI literature to identify their impact on the performance of organizations while highlighting the business value of AI-enabled projects transformation within organizations. Design/methodology/approach This study has called on the theory of IT capabilities to seize the influence of AI business value on firm performance (at the organizational and process levels). The research process (responding to the research question making discussions interpretations and comparisons and formulating recommendations) was based on a review of 500 case studies from IBM AWS Cloudera Nvidia Conversica Universal Robots websites etc. Studying the influence of AI on the performance of organizations and more specifically of the business value of such organizations' AI-enabled transformation projects required us to make an archival data analysis following the three steps namely the conceptual phase the refinement and development phase and the assessment phase. Findings AI covers a wide range of technologies including machine translation chatbots and self-learning algorithms all of which can allow individuals to better understand their environment and act accordingly. Organizations have been adopting AI technological innovations with a view to adapting to or disrupting their ecosystem while developing and optimizing their strategic and competitive advantages. AI fully expresses its potential through its ability to optimize existing processes and improve automation information and transformation effects but also to detect predict and interact with humans. Thus the results of our study have highlighted such AI benefits in organizations and more specifically its ability to improve on performance at both the organizational (financial marketing and administrative) and process levels. By building on these AI attributes organizations can therefore enhance the business value of their transformed projects. The same results also showed that organizations achieve performance through AI capabilities only when they use their features/technologies to reconfigure their processes. Research limitations/implications AI obviously influences the way businesses are done today. Therefore practitioners and researchers need to consider AI as a valuable support or even a pilot for a new business model. For the purpose of our study we adopted a research framework geared toward a more inclusive and comprehensive approach so as to better account for the intangible benefits of AI within organizations. In terms of interest this study nurtures a scientific interest which aims at proposing a model for analyzing the influence of AI on the performance of organizations and at the same time filling the associated gap in the literature. As for the managerial interest our study aims to provide managers with elements to be reconfigured or added in order to take advantage of the full benefits of AI and therefore improve organizations' performance the profitability of their investments in AI transformation projects and some competitive advantage. This study also allows managers to consider AI not as a single technology but as a set/combination of several different configurations of IT in the various company's business areas because multiple key elements must be brought together to ensure the success of AI: data talent mix domain knowledge key decisions external partnerships and scalable infrastructure. Originality/value This article analyses case studies on the reuse of secondary data from AI deployment reports in organizations. The transformation of projects based on the use of AI focuses mainly on business process innovations and indirectly on those occurring at the organizational level. Thus 500 case studies are being examined to provide significant and tangible evidence about the business value of AI-based projects and the impact of AI on firm performance. More specifically this article through these case studies exposes the influence of AI at both the organizational and process performance levels while considering it not as a single technology but as a set/combination of the several different configurations of IT in various industries.;2020
Purpose The purpose of this paper is to contribute to the special issue theme by exploring customer response to automated relationship management tactics on social media channels. Design/methodology/approach A total of 17 in-depth interviews of young adults ranging from the age of 19 to 26 were conducted. From this customer journey maps were compiled incorporating socialbots as a valuable touch point along the service delivery cycle. Findings The research frames the socialbot as a valued customer service agent to young adults with some favouring this over telephone and email communication methods. Younger consumers respond positively to the quick resolution offered by the socialbot mechanism with most acknowledging that the bot is only able to manage simplified requests. Human-to-human customer relationship management is preferential when the query reaches critical mass. Research limitations/implications Socialbots on Facebook Messenger provided the research context for this study therefore other platforms and owned website bots should be considered in future studies. Practical implications This research identifies the younger generation as a key target market for the development of customer service-related bots. Originality/value To the best of the authors' knowledge this is the first study to examine the socialbot as an automated touch point in the customer journey and contributes knowledge to the growing body of literature focussed on artificial intelligence in customer service. Moreover it provides valuable qualitative insights into how socialbots influence the customer experience and related outcome measures.;2020
Purpose This article reports the results from a panel discussion held at the 2019 European Conference on Information Systems (ECIS) on the use of technology-based autonomous agents in collaborative work. Design/methodology/approach The panelists (Drs Izak Benbasat Paul Benjamin Lowry Stefan Morana and Stefan Seidel) presented ideas related to affective and cognitive implications of using autonomous technology-based agents in terms of (1) emotional connection with these agents (2) decision-making and (3) knowledge and learning in settings with autonomous agents. These ideas provided the basis for a moderated panel discussion (the moderators were Drs Isabella Seeber and Lena Waizenegger) during which the initial position statements were elaborated on and additional issues were raised. Findings Through the discussion a set of additional issues were identified. These issues related to (1) the design of autonomous technology-based agents in terms of human-machine workplace configurations as well as transparency and explainability and (2) the unintended consequences of using autonomous technology-based agents in terms of de-evolution of social interaction prioritization of machine teammates psychological health and biased algorithms. Originality/value Key issues related to the affective and cognitive implications of using autonomous technology-based agents design issues and unintended consequences highlight key contemporary research challenges that allow researchers in this area to leverage compelling questions that can guide further research in this field.;2020
Purpose This study aims to investigate the customers' behavioral intention and actual usage (AUE) of artificial intelligence (AI)-powered chatbots for hospitality and tourism in India by extending the technology adoption model (TAM) with context-specific variables. Design/methodology/approach To understand the customers' behavioral intention and AUE of AI-powered chatbots for tourism the mixed-method design was used whereby qualitative and quantitative techniques were combined. A total of 36 senior managers and executives from the travel agencies were interviewed and the analysis of interview data was done using NVivo 8.0 software. A total of 1480 customers were surveyed and the partial least squares structural equation modeling technique was used for data analysis. Findings As per the results the predictors of chatbot adoption intention (AIN) are perceived ease of use perceived usefulness perceived trust (PTR) perceived intelligence (PNT) and anthropomorphism (ANM). Technological anxiety (TXN) does not influence the chatbot AIN. Stickiness to traditional human travel agents negatively moderates the relation of AIN and AUE of chatbots in tourism and provides deeper insights into manager's commitment to providing travel planning services using AI-based chatbots. Practical implications This research presents unique practical insights to the practitioners managers and executives in the tourism industry system designers and developers of AI-based chatbot technologies to understand the antecedents of chatbot adoption by travelers. TXN is a vital concern for the customers so designers and developers should ensure that chatbots are easily accessible have a user-friendly interface be more human-like and communicate in various native languages with the customers. Originality/value This study contributes theoretically by extending the TAM to provide better explanatory power with human-robot interaction context-specific constructs - PTR PNT ANM and TXN - to examine the customers' chatbot AIN. This is the first step in the direction to empirically test and validate a theoretical model for chatbots' adoption and usage which is a disruptive technology in the hospitality and tourism sector in an emerging economy such as India.;2020
Purpose While customer experience (CE) is recognized as a critical determinant of business success both academics and managers are yet to find a means to gain a comprehensive understanding of CE cost-effectively. The authors argue that the application of relevant AI technology could help address this challenge. Employing interactively prompted narrative storytelling and the authors investigate the effectiveness of sentiment analysis (SA) on extracting valuable CE insights from primary qualitative data generated via chatbot interviews. Design/methodology/approach Drawing on a granular and semantically clear framework for studying CE feelings an artificial intelligence (AI) augmented chatbot was designed. The chatbot interviewed a crowdsourced sample of consumers about their recalled service experience feelings. By combining free-text and closed-ended questions the authors were able to compare extracted sentiment polarities against established measurement scales and empirically validate our novel approach. Findings The authors demonstrate that SA can effectively extract CE feelings from primary chatbot data. This findings also suggest that further enhancement in accuracy can be achieved via improvements in the interplay between the chatbot interviewer and SA extraction algorithms. Research limitations/implications The proposed customer-centric approach can help service companies to study and better understand CE feelings in a cost-effective and scalable manner. The AI-augmented chatbots can also help companies to foster immersive and engaging relationships with customers. This study focuses on feelings warranting further research on AI's value in studying other CE elements. Originality/value The unique inquisitive role of AI-infused chatbots in conducting interviews and analyzing data in realtime offers considerable potential for studying CE and other subjective constructs.;2020
Purpose: Preconception care is important for all women to improve infant and maternal health outcomes and may be especially important for adolescents and young adults. This study assesses the acceptance usability and use of an automated intervention to screen women on 108 preconception care risks and address them over the course of a year via a Web-based virtual animated health counselor and compares these measures for the adolescent and young adult users aged 18-25 years with those of users aged 26-34 years. We hypothesize that the younger cohort will have significantly greater use of and satisfaction with the online intervention. Methods: A randomized controlled trial involving a national sample of 528 women was conducted. We present a secondary data analysis on the system use and self-reported usability and satisfaction of the 79 women aged 18-25 years randomized to the intervention group compared with the 183 women aged 26-34 years in the intervention group. Participants were required to self-identify as female black or African American aged 18-34 years not pregnant and English-speaking and were recruited through a variety of advertisements and outreach activities. Results: Of the adolescent and young adult participants (aged 18-25 years) enrolled and randomized to the intervention 20.25% of participants accessed the system 0 times 29.11% 1-3 times and 50.63% >3 times over the course of a year. At the end of the year almost all (96.4%) indicated they had either acted on recommendations made by the agent or planned to. Most (75.0%) said they would recommend the system to someone they knew. There were no significant differences between the two age groups on intervention use or satisfaction. Conclusions: Web-based conversational agents are a viable medium for delivering longitudinal preconception care counseling to adolescents and young adults. (C) 2019 Published by Elsevier Inc. on behalf of Society for Adolescent Health and Medicine. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).;2020
Quality of life (QoL) is an effective index of well-being including physical health aspect of social activity and mental state of individuals. A new approach that uses a deep-learning architecture to estimate the score of a user's QoL is presented. This system was built using a combination of a 3D convolutional neural network and a support vector machine for multimodal data. In order to evaluate the accuracy of the estimation system three experiments were conducted. Before these experiments ten hours of audio and video data were collected from healthy participants during a natural-language conversation with a conversational agent we implemented. In the first experiment the QoL question-answer estimation experiment the accuracy of Physical functioning which is one of the eight scales that constitute QoL reached 84.0%. In the second experiment the QoL-score-regression experiment in which the scores of each scale were directly estimated the distribution of the difference between the actual score and the estimated results known as error was investigated. These results imply that the features necessary for QoL estimation can be extracted from audio and video data except for the Mental Health domain. One of the reasons why it was difficult to estimate the Mental Health scale may be that the learning framework could not extract an appropriate feature for estimation. Therefore we estimated Mental Health by focusing on eye movement. From the result it was proven that estimation is possible and the proposed system using multimodal data demonstrated its effectiveness for estimation for all eight scales that constitute QoL and for extracting high-dimensional information regarding the QoL of a human including their satisfaction level towards daily life and social activities. Finally suggestions and discussions regarding the plausible behavior of the estimation results were made from the viewpoint of human-agent interaction in the field of elderly welfare. (C) 2020 The Author(s). Published by Elsevier B.V.;2020
Question Answering (QA) systems aim at supplying precise answers to questions posed by users in a natural language form. They are used in a wide range of application areas from bio-medicine to tourism. Their underlying knowledge source can be structured data (e.g. RDF graphs and SQL databases) unstructured data in the form of plain text (e.g. textual excerpts from Wikipedia) or combinations of the above. In this paper we survey the recent work that has been done in the area of stateless QA systems with emphasis on methods that have been applied in RDF and Linked Data documents and mixtures of these. We identify the main challenges we categorize the existing approaches according to various aspects we review 21 recent systems and 23 evaluation and training datasets that are most commonly used in the literature categorized according to the type of the domain the underlying knowledge source the provided tasks and the associated evaluation metrics.;2020
Question-and-answering (QA) systems are popularly applied and deployed in many fields and industries such as e-commerce platforms government departments and educational industry. However the requirement for QA systems in healthcare industry has still not been satisfied especially the requirement for mobile QA systems. In this article we develop a healthcare-oriented mobile QA system for smart cities. The developed system is constructed with artificial intelligence and mobile computing techniques including natural language processing information retrieval and service computing. To meet the strict requirement of healthcare-oriented information systems we design a series of models algorithms and computation methods. The designed QA system contains three modules which are classifier QA engine and chatbots API. We study the performance of different classifiers including neural network-based classifier support vector machine (SVM) and AdaBoost-based classifier. The QA engine consists of two submodules that is semantic processing and answers retrieval. Semantic processing contains part-of-speech tagging and dependency parsing. The answers retrieval module contains index building and searching. We perform a series of experiments to evaluate the performance of our system and present the experimental results. The built mobile QA system has been applied in real-world hospitals and communities and receives satisfied user experience.;2020
Recent technological advances introduced conversational agents into homes. Many researchers have investigated how people utilize and perceive them. However only a small number of studies have focused on how older adults interact with these agents. This study presents a 14-day user study of 19 participants who experienced a conversational agent in a real-life environment. We grouped them into two groups by age and compared their experiences. From a log study and semi-structured interviews we identified several differences between the two groups. Compared to younger adults older adults used the agent more. They used it primarily for listening to music and reported satisfaction with it. Younger adults mainly used utility skills like weather report checks and setting of alarms which streamlined their daily lives. Moreover older adults tended to view the agent as a companion while younger adults saw it as a tool. Based on these empirical findings we suggest that conversational agents should be designed with consideration of the different usage patterns and perceptions across age groups.;2020
Recent technological advances make it possible to create automated virtual interviewers called embodied conversational agents (ECAs). We study how an ECA compares to a human interviewer in three experiments. In experiment 1 we show that two theoretically motivated factors-making the ECA facially and vocally similar to the interviewee-result in the ECA performing similarly to or better than human interviewers for six antecedents of disclosure quality. In two additional experiments we show that employees are on average 21 to 32 percent more likely to disclose violating internal controls to an ECA than to a human even if the human interviewer has significant interviewing experience. These findings contribute to the ECA design literature by showing that similarity-enhancing features of ECAs increase the antecedents of disclosure. The findings also contribute to the accounting literature by demonstrating that ECA technology can increase the scope of interviewing in accounting without reducing interview quality.;2020
Recently conversational agents effectively improve their understanding capabilities by neural networks. Such deep neural models however do not apply to most human languages due to the lack of annotated training data for various NLP tasks. In this paper we propose a multi-level cross-lingual transfer model with language shared and specific knowledge to improve the spoken language understanding of low-resource languages. Our method explicitly separates the model into the language-shared part and language-specific part to transfer cross-lingual knowledge and improve the monolingual slot tagging especially for low-resource languages. To refine the shared knowledge we add a language discriminator and employ adversarial training to reinforce information separation. Besides we adopt novel multi-level knowledge transfer in an incremental and progressive way to acquire multi-granularity shared knowledge rather than a single layer. To mitigate the discrepancies between the feature distributions of language specific and shared knowledge we propose the neural adapters to fuse knowledge automatically. Experiments show that our proposed model consistently outperforms monolingual baseline with a statistically significant margin up to 2.09 even higher improvement of 12.21 in the zero-shot setting.;2020
Recommender systems have been attracting much attention from both academia and industry because of their ability to capture user interests and generate personalized item recommendations. As the life pace in contemporary society speeds up traditional recommender systems are inevitably limited by their disconnected interaction styles and low adaptivity to users' evolving demands. Consequently conversational recommender systems emerge as a prospective research area where an intelligent dialogue agent is integrated with a recommender system. Conversational recommender systems possess the ability to accurately understand end-users' intent or request and generate human-like dialogue responses when performing recommendations. However existing conversational recommender systems only allow the systems to ask users for more preference information while users' further questions and concerns about the recommended items (e.g. enquiring the location of a recommended restaurant) can hardly be addressed. Though the recent task-oriented dialogue systems allow for two-way communications they are not easy to train because of their high dependence on human guidance in terms of user intent recognition and system response generation. Hence to enable two-way human-machine communications and tackle the challenges brought by manually crafted rules we propose Conversational Recommender System with Adversarial Learning (CRSAL) a novel end-to-end system to tackle the task of conversational recommendation. In CRSAL we innovatively design a fully statistical dialogue state tracker coupled with a neural policy agent to precisely capture each user's intent from limited dialogue data and generate conversational recommendation actions. We further develop an adversarial Actor-Critic reinforcement learning approach to adaptively refine the quality of generated system actions thus ensuring coherent human-like dialogue responses. Extensive experiments on two benchmark datasets fully demonstrate the superiority of CRSAL on conversational recommendation tasks.;2020
Regulations play an important role in assuring the quality of a building's construction and minimizing its adverse environmental impacts. Engineers and the like need to retrieve regulatory information to ensure a building conforms to specified standards. Despite the availability of search engines and digital databases that can be used to store regulations engineers for example are unable to retrieve information for domain-specific needs in a timely manner. As a consequence users often have to deal with the burden of browsing and filtering information which can be a time-consuming process. This research develops a robust end-to-end methodology to improve the efficiency and effectiveness of retrieving queries pertaining to building regulations. The developed methodology integrates information retrieval with a deep learning model of Natural Language Processing (NLP) to provide precise and rapid answers to user's questions from a collection of building regulations. The methodology is evaluated and a prototype system to retrieve queries is developed. The paper's contribution is therefore twofold as it develops a: (1) methodology that combines NLP and deep learning to be able to address queries raised about the building regulations and (2) chatbot of question answering system which we refer to as QAS4CQAR. Our proposed methodology has powerful feature representation and learning capability and therefore can potentially be adopted to building regulations in other jurisdictions.;2020
Research on building dialogue systems that converse with humans naturally has recently attracted a lot of attention. Most work on this area assumes text-based conversation where the user message is modeled as a sequence of words in a vocabulary. Real-world human conversation in contrast involves other modalities such as voice facial expression and body language which can influence the conversation significantly in certain scenarios. In this work we explore the impact of incorporating the audio features of the user message into generative dialogue systems. Specifically we first design an auxiliary response retrieval task for audio representation learning. Then we use word-level modality fusion to incorporate the audio features as additional context to our main generative model. Experiments show that our audioaugmented model outperforms the audio-free counterpart on perplexity response diversity and human evaluation. (C) 2020 Elsevier B.V. All rights reserved.;2020
Research on collaborative learning has revealed that peer-collaboration explanation activities facilitate reflection and metacognition and that establishing common ground and successful coordination are keys to realizing effective knowledge-sharing in collaborative learning tasks. Studies on computer-supported collaborative learning have investigated how awareness tools can facilitate coordination within a group and how the use of external facilitation scripts can elicit elaborated knowledge during collaboration. However the separate and joint effects of these tools on the nature of the collaborative process and performance have rarely been investigated. This study investigates how two facilitation methods-coordination support via learner gaze-awareness feedback and metacognitive suggestion provision via a pedagogical conversational agent (PCA)-are able to enhance the learning process and learning gains. Eighty participants organized into dyads were enrolled in a 2 x 2 between-subject study. The first and second factors were the presence of real-time gaze feedback (no vs. visible gaze) and that of a suggestion-providing PCA (no vs. visible agent) respectively. Two evaluation methods were used: namely dialog analysis of the collaborative process and evaluation of learning gains. The real-time gaze feedback and PCA suggestions facilitated the coordination process while gaze was relatively more effective in improving the learning gains. Learners in the Gaze-feedback condition achieved superior learning gains upon receiving PCA suggestions. A successful coordination/high learning performance correlation was noted solely for learners receiving visible gaze feedback and PCA suggestions simultaneously (visible gaze/visible agent). This finding has the potential to yield improved collaborative processes and learning gains through integration of these two methods as well as contributing towards design principles for collaborative-learning support systems more generally.;2020
Research question: What are the effects of using a fertility education chatbot i.e. automatic conversation programme on knowledge intentions to improve preconception behaviour and anxiety? Design: A three-armed randomized controlled trial was conducted using an online social research panel. Participants included 927 women aged 20-34 years who were randomly allocated to one of three groups: a fertility education chatbot (intervention group) a document about fertility and preconception health (control group 1) or a document about an irrelevant topic (control group 2). Participants' scores on the Cardiff Fertility Knowledge Scale and the State-Trait Anxiety Inventory their intentions to optimize preconception behaviours e.g. taking folic acid and the free-text feedback provided by chatbot users were assessed. Results: A repeated-measures analysis of variance showed significant fertility knowledge gains after the intervention in the intervention group (+9.1 points) and control group 1 (+14.9 points) but no significant change in control group 2 (+1.1 points). Post-test increases in the intentions to optimize behaviours were significantly higher in the intervention group than in control group 2 and were similar to those in control group 1. Post-test state anxiety scores were significantly lower in the intervention group than in control group 1 and control group 2. User feedbacks about the chatbot suggested technical limitations e.g. low comprehension of users' words and pros and cons of using the chatbot e.g. convenient versus coldness. Conclusions: Providing fertility education using a chatbot improved fertility knowledge and intentions to optimize preconception behaviour without increasing anxiety but the improvement in knowledge was small. Further technical development and exploration of personal affinity for technology is required.;2020
Rhetorical structure theory (RST) is a significant theory about discourse organization. With an increasing number of research interests focus on RST many novel parsing approaches have been proposed and motivated many brand new applications such as chatbots and other expert and intelligent systems. However the work on RST dates back many years and there remains a lack of comprehensive literature reviews. The aim of this study is therefore to provide a comprehensive overview of RST parsing methods and applications. In this paper we first give a detailed introduction to RST. Then the commonly used discourse treebank: RST-DT is elaborated. We propose a new taxonomy to divide the RST parsing methods into different categories. With a focus on the classical and latest methods that have recently been developed we review the pros and cons of these approaches along with the performance analysis of them. We then summarize the applications of RST across various domains. Moreover we present a comparative study of RST with other discourse structure theories. Finally we discuss some implications of our findings and outline future research directions in this challenging and fast-growing field. (C) 2020 Elsevier Ltd. All rights reserved.;2020
Several domain-specific assistants in the form of chatbots have conquered many commercial and private areas. However there is still a limited level of systematic knowledge of the distinctive characteristics of design elements for chatbots to facilitate development adoption implementation and further research. To close this gap the paper outlines a taxonomy of design elements for chatbots with 17 dimensions organized into the perspectives intelligence interaction and context. The conceptually grounded design elements of the taxonomy are used to analyze 103 chatbots from 23 different application domains. Through a clustering-based approach five chatbot archetypes that currently exist for domain-specific chatbots are identified. The developed taxonomy provides a structure to differentiate and categorize domain-specific chatbots according to archetypal qualities that guide practitioners when taking design decisions. Moreover the taxonomy serves academics as a foundation for conducting further research on chatbot design while integrating scientific and practical knowledge.;2020
Simple Summary All of the veterinary schools in Australia and New Zealand worked together to develop the online One Welfare learning and teaching portal (OWP) for sharing teaching resources to assist veterinary graduates to become leaders in animal welfare and ethics (AWE). The materials in the portal are organised around eight key themes including two overarching themes of animal ethics and animal welfare science and six context-specific themes: companion animals animals used in research and teaching livestock/production animals animals used for sport recreation or display animals in the wild and aquatic animals. The arrangement of these resources aligns with those of the Australian Animal Welfare Strategy (AAWS). As part of the OWP development animal welfare educators from the eight veterinary schools met and used modified deliberative polling to prioritise resource development. Surveys of students and educators in all participating schools investigated their attitudes to current AWE issues across six context-specific themes: companion animals animals used in research and teaching livestock/production animals animals used for sport recreation or display animals in the wild and aquatic animals. The prioritised resources include (1) student AWE essays arranged by subject (2) an online reflection tool that can be used repeatedly to gain understanding of change in attitudes over time (3) eight overarching themes that host a group of interactive scenarios (4) research papers for each context-specific theme (5) a bank of multiple choice questions with feedback to support AWE assessment (6) a novel online discussion tool 'Chatterbox' and (7) a 'toolbox' containing directions to the doglogbook an owner app designed to monitor management practices and evaluate quality of life in dogs. This article introduces the online One Welfare learning and teaching portal (OWP) and describes its development use importance and relevance to animal welfare and ethics (AWE) stakeholders. As animal welfare issues increase in importance veterinarians must be trained to lead the science that underpins AWE discourses. The OWP is a collection of resources designed to engage and challenge veterinary science students as they become advocates for animals. It was developed collaboratively by all eight veterinary schools in Australia and New Zealand and funded by the Australian Government Office for Learning and Teaching. Surveys to investigate the attitudes of students and educators to AWE issues in six context-specific themes based on the Australian Animal Welfare Strategy (AAWS) (companion animals animals used in research and teaching livestock/production animals animals used for sport recreation or display animals in the wild and aquatic animals) were administered through all participating schools. Students assigned more importance to Day One competence in knowledge of welfare concepts than did educators for the following groups: production animals companion animals animals in the wild aquatic animals animals used in research and teaching and animals used for sport recreation or display (allp< 0.01). Agreement between educators and students was closer regarding the importance of Day One competence for euthanasia for all six context-specific themes (p< 0.01-0.03). Students assigned more importance than educators tosocial economic and cultural driversof welfare outcomes in production animals (p< 0.01)slaughter and preslaughter inspectionsin production animals (p< 0.01)animal abuse and hoardingin companion animals (p< 0. 01)shelter medicinein companion animals (p< 0.01)disaster preparednessin wildlife animals (p< 0.01)pain and distress caused by fishingin aquatic animals (p< 0.01)conscientious objectionrelated to animals held for research and teaching (p< 0.01)behaviour selection and trainingof animals used for sport recreation and display (p= 0.046) andeducating the publicaround sporting animal welfare (p< 0.01). Agreement between educators and students was closer forstrategies to address painful husbandryproceduresin production animals (p= 0.03)behaviour and trainingof companion animals (p= 0.03)veterinarians' duties to wild animalsin wildlife (p= 0.02)the 3Rsin animals held for research and teaching (p= 0.03) andownership responsibilityin sporting animals (p= 0.01). This report discusses the reasons for differences among students and educators as they approach these issues. The portal is expected to gather more content as veterinary schools in other countries use its resources and users submit scenarios and discussion topics that reflect local needs.;2020
Since the discovery of the Coronavirus (nCOV-19) it has become a global pandemic. At the same time it has been a great challenge to hospitals or healthcare staff to manage the flow of the high number of cases. Especially in remote areas it is becoming more difficult to consult a medical specialist when the immediate hit of the epidemic has occurred. Thus it becomes obvious that if effectively designed and deployed chatbot can help patients living in remote areas by promoting preventive measures virus updates and reducing psychological damage caused by isolation and fear. This study presents the design of a sophisticated artificial intelligence (AI) chatbot for the purpose of diagnostic evaluation and recommending immediate measures when patients are exposed to nCOV-19. In addition presenting a virtual assistant can also measure the infection severity and connects with registered doctors when symptoms become serious.;2020
Social media bots (automated accounts) attacks are organized crimes that pose potential threats to public opinion democracy public health stock market and other disciplines. While researchers are building many models to detect social media bot accounts attackers on the other hand evolve their bots to evade detection. This everlasting cat and mouse game makes this field vibrant and demands continuous development. To guide and enhance future solutions this work provides an overview of social media bots attacks current detection methods and challenges in this area. To the best of our knowledge this paper is the first systematic review based on a predefined search strategy which includes literature concerned about social media bots detection methods published between 2010 and 2019. The results of this review include a refined taxonomy of detection methods a highlight of the techniques used to detect bots in social media and a comparison between current detection methods. Some of the gaps identified by this work are: the literature mostly focus on Twitter platform only and rarely use methods other than supervised machine learning most of the public datasets are not accurate or large enough integrated systems and real-time detection are required and efforts to spread awareness are needed to arm legitimate users with knowledge.;2020
Socialbots are intelligent software that controls all behaviour of fake accounts in an online social network. Since they are armed with detection evasion techniques it is valuable to be able to determine the effectiveness of these techniques. In this study an analytical model is developed to estimate a lower bound for the cost of automatic establishment of a socialbot network. Moreover by considering fake accounts purchasing as an establishment strategy an upper bound is suggested for acceptable costs. These two boundaries are compared to decide on the economic feasibility of a socialbot network design strategy. To demonstrate the practicality and effectiveness of the model two case studies are investigated. They show that although designing a fully stealthy socialbot network is economically feasible the infiltration time would be unacceptable. Thus this ideal situation in which the establishment is fully stealthy performs in a tolerable time and satisfactory infiltration scale is impractical. A possible solution could be achieved by reducing the time and cost in exchange for less stealthy behaviour while the infiltration scale kept unchanged. Since the model presents a trade-off between stealthiness time and cost it is a useful tool facilitating the design of a possible strategy.;2020
Software robots tend to increasingly take over organizational processes. However little is known about principles of building and implementing as opposed to using robotic systems such as bots for process automation (RPA) and chatbots. Therefore based on an empirically illustrated theoretical conceptualization of routine automation and affordance actualization this paper develops a framework that guides how different types of software robots can be built and implemented through transforming a human-executed routine into a robot-automated routine by applying specific implementation guidelines.;2020
Speech endpoint detection (EPD) benefits from the decoder state features (DSFs) of online automatic speech recognition (ASR) system. However the DSFs are obtained via the ASR decoding process which can become prohibitively expensive especially in limited-resource scenarios such as the embedded devices. To address this problem this paper proposes a language model (LM)-based end-of-utterance (EOU) predictor which is trained to determine the framewise probabilities of the EOU token conditioned on the previous word history obtained from the 1-best decoding hypothesis of the ASR system in an end-to-end manner without an actual decoding process in the test step. Further a novel end-to-end EPD strategy is presented to incorporate a phonetic embedding (PE)-based acoustic modeling knowledge and the proposed EOU predictor-based language modeling knowledge into an acoustic feature embedding (AFE)-based EPD approach within the recurrent neural networks (RNN)-based EPD framework. The proposed EPD algorithm is built upon the ensemble RNNs which are independently trained for the three parts which are the proposed LM-based EOU predictor AFE-based EPD and PE-based acoustic model (AM) in accordance with each target. The ensemble RNNs are concatenated at the level of the last hidden layers and then attached into the fully-connected deep neural networks (DNN)-based EPD classifier which is trained in accordance with the ultimate EPD target. Thereafter they are jointly retrained at the second step of the DNN training to yield the lower endpoint error. The proposed EPD framework was evaluated in terms of the endpoint accuracy and word error rate for the CHiME-3 and large-scale ASR tasks. The experimental results turn out that the proposed EPD algorithm efficiently outperforms the conventional EPD approaches.;2020
Spoken language understanding (SLU) in human machine conversational systems is the process of interpreting the semantic meaning conveyed by a user's spoken utterance. Traditional SLU approaches transform the word string transcribed by an automatic speech recognition (ASR) system into a semantic label that determines the machine's subsequent response. However the robustness of SLU results can suffer in the context of a human-machine conversation-based language learning system due to the presence of ambient noise heavily accented pronunciation ungrammatical utterances etc. To address these issues this paper proposes an end-to-end (E2E) modeling approach for SLU and evaluates the semantic labeling performance of a bidirectional LSTM-RNN with input at three different levels: acoustic (filterbank features) phonetic (subphone posteriorgrams) and lexical (ASR hypotheses). Experimental results for spoken responses collected in a dialog application designed for English learners to practice job interviewing skills show that multi-level BLSTM-RNNs can utilize complementary information from the three different levels to improve the semantic labeling performance. An analysis of results on OOV utterances which can be common in a conversation-based dialog system also indicates that using subphone posteriorgrams outperforms ASR hypotheses and incorporating the lower-level features for semantic labeling can be advantageous to improving the final SLU performance.;2020
Technological progress provides health professionals with an excellent opportunity to take advantage of these developments and contribute to the development of efficient ways of diagnosing monitoring treating and assisting users. The purpose of this work is to present the results of a study conducted to examine the quantitative equivalence of paper-and-pencil and a voice-based conversational assistant popularly known as a chatbot as means to administer tests. One hundred and eight undergraduate university students completed both versions of the De Jong Gierveld Loneliness Scale. The interval between the first and second administration was set at four days. Validity internal structure internal consistency and equivalence of chatbot administration mode were assessed. A confirmatory factor analysis was used to verify the factor structure and provided a two-factor structure. Validity and internal consistency are adequate. These results support the feasibility of using chatbots for loneliness assessment in a sample of undergraduate university students and other populations in future.;2020
Technology has played an important role in responding to the novel coronavirus (SARS-CoV-2) and subsequent COVID-19 pandemic. The virus's blend of lethality and transmissibility have challenged officials and exposed critical limitations of the traditional public health apparatus. However throughout this pandemic technology has answered the call for a new form of public health that illustrates opportunities for enhanced agility scale and responsiveness. The authors share the Microsoft perspective and illustrate how technology has helped transform the public health landscape with new and refined capabilities - the efficacy and impact of which will be determined by history. Technologies like chatbot and virtualized patient care offer a mechanism to triage and distribute care at scale. Artificial intelligence and high-performance computing have accelerated research into understanding the virus and developing targeted therapeutics to treat infection and prevent transmission. New mobile contact tracing protocols that preserve patient privacy and civil liberties were developed in response to public concerns creating new opportunities for privacy-sensitive technologies that aid efforts to prevent and control outbreaks. While much progress is still needed the COVID-19 pandemic has highlighted technology's importance to public health security and pandemic preparedness. Future multi-stakeholder collaborations including those with technology organizations are needed to facilitate progress in overcoming the current pandemic setting the stage for improved pandemic preparedness in the future. As lessons are assessed from the current pandemic public officials should consider technology's role and continue to seek opportunities to supplement and improve on traditional approaches.;2020
Text generation is a basic work of natural language processing which plays an important role in dialogue system and intelligent translation. As a kind of deep learning framework Generative Adversarial Networks (GAN) has been widely used in text generation. In combination with reinforcement learning GAN uses the output of discriminator as reward signal of reinforcement learning to guide generator training but the reward signal is a scalar and the guidance is weak. This paper proposes a text generation model named Feature-Guiding Generative Adversarial Networks (FGGAN). To solve the problem of insufficient feedback guidance from the discriminator network FGGAN uses a feature guidance module to extract text features from the discriminator network convert them into feature guidance vectors and feed them into the generator network for guidance. In addition sampling is required to complete the sequence before feeding it into the discriminator to get feedback signal in text generation. However the randomness and insufficiency of the sampling method lead to poor quality of generated text. This paper formulates text semantic rules to restrict the token of the next time step in the sequence generation process and remove semantically unreasonable tokens to improve the quality of generated text. Finally text generation experiments are performed on different datasets and the results verify the effectiveness and superiority of FGGAN.;2020
The aim of this paper is to provide a systematic route of information retrieval from a knowledge-based database (or domain knowledge) through a dialog system of natural language interaction. The application is about a comprehensive building at a university with classrooms laboratory rooms meeting rooms research rooms and offices and is to present related information the user asks for. First the domain knowledge is expressed with predicate expressions based on the ontology structure then the vocabulary is presented distributedly with word embedding enhanced with the domain knowledge queries from the user arc then converted into the intent (general) and slot elements (specific) with the help of trained recurrent neural network (RNN). The system works smoothly. The key point is integrating the two methods of knowledge-based and data-driven natural language processing into one system and the domain knowledge is in the central part which is incorporated into the word embedding to make it specifically fit the natural language in this application. (C) 2020 The Authors. Published by Atlantis Press SARL.;2020
The aim of this study was to examine the effects of an anti-bullying activity that utilizes conversational virtual agents (called conversation-bots or chatbots) on students' attitudes toward bullying problems. An experimental pre- or posttest design with a three-group setting was used. Eighty-nine fifth-grade students were assigned to one of three groups: Conversation with a virtual agent of (a) bully's role (b) victim's role and (c) teacher's role. All agents are conversation-bots designed to support learner-computer interactions. The bully agent defends the notion that bullying behaviors are acceptable whereas the victim agent argues that bullying behavior cannot be tolerated. The teacher agent teaches students the types of bullying and its negative aspects. The participants completed an anti-bullying attitude test at pre- and posttest which included students' anti-bully intention pro-victim behavior and self-efficacy factors. The results show that students' attitudes toward bullying problems changed to more positive responses after the implementation that used the conversation-bot. In addition the results revealed that the agent's role had an impact on the students' attitudes toward the anti-bully factor. Implications and future research regarding the use of conversation-bots in education are discussed.;2020
The application of natural language to improve students' interaction with information systems is demonstrated to be beneficial. In particular advances in cognitive computing enable a new way of interaction that accelerates insight from existing information sources thereby contributing to the process of learning. This work aims at researching the application of cognitive computing in blended learning environments. We propose a modular cognitive agent architecture for pedagogical question answering featuring social dialogue (small talk) improved for a specific knowledge domain. This system has been implemented as a personal agent to assist students in learning Data Science and Machine Learning techniques. Its implementation includes the training of machine learning models and natural language understanding algorithms in a human-like interface. The effectiveness of the system has been validated through an experiment.;2020
The combination of machine learning with healthcare services is emerging. However when machine learning functions are executed on resource-constrained mobile consumer devices the computing overhead will increase and the user experience will deteriorate. In essence the existing approaches delegate such tasks to a central cloud data center. However data processing on remote cloud servers results in a long response latency. Therefore this article proposes a machine learning-based smart recipe recommendation system that uses a local mobile edge computing server. The proposed system delegates the machine learning and recipe search tasks to the mobile edge computing server thereby reducing the response latency for data processing and the computational burden placed on mobile user devices.;2020
The COVID-19 pandemic has created unique challenges for the U.S. healthcare system due to the staggering mismatch between healthcare system capacity and patient demand. The healthcare industry has been a relatively slow adopter of digital innovation due to the conventional belief that humans need to be at the center of healthcare delivery tasks. However in the setting of the COVID-19 pandemic artificial intelligence (AI) may be used to carry out specific tasks such as pre-hospital triage and enable clinicians to deliver care at scale. Recognizing that the majority of COVID-19 cases are mild and do not require hospitalization Partners HealthCare (now Mass General Brigham) implemented a digitally-automated pre-hospital triage solution to direct patients to the appropriate care setting before they showed up at the emergency department and clinics which would otherwise consume resources expose other patients and staff to potential viral transmission and further exacerbate supply-and-demand mismatching. Although the use of AI has been well-established in other industries to optimize supply and demand matching the introduction of AI to perform tasks remotely that were traditionally performed in-person by clinical staff represents a significant milestone in healthcare operations strategy.;2020
The dialogue system has always been one of the important topics in the domain of artificial intelligence. So far most of the mature dialogue systems are task-oriented based while non-task-oriented dialogue systems still have a lot of room for improvement. We propose a data-driven non-task-oriented dialogue generator CERG based on neural networks. This model has the emotion recognition capability and can generate corresponding responses. The data set we adopt comes from the NTCIR-14 STC-3 CECG subtask which contains more than 1.7 million Chinese Weibo post-response pairs and 6 emotion categories. We try to concatenate the post and the response with the emotion then mask the response part of the input text character by character to emulate the encoder-decoder framework. We use the improved transformer blocks as the core to build the model and add regularization methods to alleviate the problems of overcorrection and exposure bias. We introduce the retrieval method to the inference process to improve the semantic relevance of generated responses. The results of the manual evaluation show that our proposed model can make different responses to different emotions to improve the human-computer interaction experience. This model can be applied to lots of domains such as automatic reply robots of social application.;2020
The end-to-end open-domain dialogue system is a challenging task since the existing neural models suffer from the issue of trivial responses. Employing background knowledge as a major solution has been proven to be effective to improve the responses quality. However less attention was paid to the selection of the appropriate knowledge in scenarios where the utterance subject drifts between two partners which could prohibit the model from learning to access knowledge correctly. In this paper we propose a novel Knowledge Augmented Dialogue Generation (KADG) model to facilitate both knowledge selection and incorporation in open-domain dialogue systems. The core components of KADG consist of Divergent Knowledge Selector (DKS) and Knowledge Aware Decoder (KAD). DKS performs a one-hop subject reasoning over knowledge by pre-optimizing each knowledge candidate with inferred drift clue. Drift clue implies the potential subjects association of the current conversation and is served to bridge the subject gap in the knowledge selection. Thereafter KAD makes full use of this selected knowledge to generate responses contextual coherently as well as knowledgeably. Comprehensive experiments on a newly released knowledge-grounded conversation dataset Wizard-of-Wikipedia have verified the superiority of our model than previous baselines and shown that our method can refer to the knowledge properly and generate diverse and informative responses. (C) 2020 Elsevier B.V. All rights reserved.;2020
The field of business shows an increasing interest in exploring conversational agents to improve service quality and market competitiveness. Furthermore the advances in machine learning capabilities leverage the natural language processing towards natural and straightforward dialogue experiences for industries. However in the best of our knowledge no literature review outlines conversational agents in the business industry primarily taking into account computational learning capabilities. This article presents a systematic literature review that encompasses these areas looking through the use of machine learning to improve the field of business. The review followed a guideline for systematic reviews to present the literature of the last decade emphasizing business perspectives such as domains goals and challenges and computational methods for self-learning personalization and response generation of conversational agents. As a result the article provides the answers of three general three focused and two statistical questions to address the role of artificial intelligence in conversational agents applied to business domains. In this regard the results show that no study combines self-learning personalization and generative-based responses for the same business solution. Additionally the article describes the organization of the state-of-the-art highlighting the correlation of business perspectives and machine learning methods. The contributions of this review focus on opportunities and future research directions towards human-like conversational agents for business. (c) 2020 Elsevier Inc. All rights reserved.;2020
The growing number of voice-controlled devices (VCDs) i.e. Google Home Amazon Alexa etc. has resulted in automation of home appliances smart gadgets and next generation vehicles etc. However VCDs and voice-activated services i.e. chatbots are vulnerable to audio replay attacks. Our vulnerability analysis of VCDs shows that these replays could be exploited in multi-hop scenarios to maliciously access the devices/nodes attached to the Internet of Things. To protect these VCDs and voice-activated services there is an urgent need to develop reliable and computationally efficient solutions to detect the replay attacks. This paper models replay attacks as a nonlinear process that introduces higher-order harmonic distortions. To detect these harmonic distortions we propose the acoustic ternary patterns-gammatone cepstral coefficient (ATP-GTCC) features that are capable of capturing distortions due to replay attacks. Error correcting output codes model is used to train a multi-class SVM classifier using the proposed ATP-GTCC feature space and tested for voice replay attack detection. Performance of the proposed framework is evaluated on ASVspoof 2019 dataset and our own created voice spoofing detection corpus (VSDC) consisting of bona-fide first-order replay (replayed once) and second-order replay (replayed twice) audio recordings. Experimental results signify that the proposed audio replay detection framework reliably detects both first and second-order replay attacks and can be used in resource constrained devices.;2020
The increasing capabilities of conversational agents (CAs) offer manifold opportunities to assist users in a variety of tasks. In an organizational context particularly their potential to simulate a human-like interaction via natural language currently attracts attention both at the customer interface as well as for internal purposes often in the form of chatbots. Emerging experimental studies on CAs look into the impact of anthropomorphic design elements so-called social cues on user perception. However while these studies provide valuable prescriptive knowledge of selected social cues they neglect the potential detrimental influence of the limited responsiveness of present-day conversational agents. In practice many CAs fail to continuously provide meaningful responses in a conversation due to the open nature of natural language interaction which negatively influences user perception and often led to CAs being discontinued in the past. Thus designing a CA that provides a human-like interaction experience while minimizing the risks associated with limited conversational capabilities represents a substantial design problem. This study addresses the aforementioned problem by proposing and evaluating a design for a CA that offers a human-like interaction experience while mitigating negative effects due to limited responsiveness. Through the presentation of the artifact and the synthesis of prescriptive knowledge in the form of a nascent design theory for anthropomorphic enterprise CAs this research adds to the growing knowledge base for designing human-like assistants and supports practitioners seeking to introduce them into their organizations.;2020
The integration of digital voice assistants in nursing residences is becoming increasingly important to facilitate nursing productivity with documentation. A key idea behind this system is training natural language understanding (NLU) modules that enable the machine to classify the purpose of the user utterance (intent) and extract pieces of valuable information present in the utterance (entity). One of the main obstacles when creating robust NLU is the lack of sufficient labeled data which generally relies on human labeling. This process is cost-intensive and time-consuming particularly in the high-level nursing care domain which requires abstract knowledge. In this paper we propose an automatic dialogue labeling framework of NLU tasks specifically for nursing record systems. First we apply data augmentation techniques to create a collection of variant sample utterances. The individual evaluation result strongly shows a stratification rate with regard to both fluency and accuracy in utterances. We also investigate the possibility of applying deep generative models for our augmented dataset. The preliminary character-based model based on long short-term memory (LSTM) obtains an accuracy of 90% and generates various reasonable texts with BLEU scores of 0.76. Secondly we introduce an idea for intent and entity labeling by using feature embeddings and semantic similarity-based clustering. We also empirically evaluate different embedding methods for learning good representations that are most suitable to use with our data and clustering tasks. Experimental results show that fastText embeddings produce strong performances both for intent labeling and on entity labeling which achieves an accuracy level of 0.79 and 0.78 f1-scores and 0.67 and 0.61 silhouette scores respectively.;2020
The natural interaction between human and robot is full of challenges but indispensable. In this article a human-robot interactive system is designed for humanoid robot SHFR-III. The system consists of three subsystems: multi-sensor positioning subsystem emotional interaction subsystem and dialogue subsystem. The multi-sensor positioning subsystem is designed to improve the positioning accuracy the emotional interaction subsystem uses bimodal emotional recognition model and fuzzy emotional decision-making model to realize the emotion recognition and expression feedback to the interactive objects and the dialogue subsystem with personal information can complete the response consistent with the default information and avoid conflicting responses .The experimental results show that the multi-sensor positioning subsystem has good environmental adaptability and positioning accuracy the emotional interaction subsystem can achieve human-like emotional feedback and the dialogue subsystem can achieve more natural logical and consistent responses.;2020
The nature of industrial manufacturing processes and the continuous need to adapt production systems to new demands require tools to support workers during transitions to new processes. At the early stage of transitions human error rate is often high and the impact in quality and production loss can be significant. Over the past years eXtended Reality (XR) technologies (such as virtual augmented immersive and mixed reality) have become a popular approach to enhance operators' capabilities in the Industry 4.0 paradigm. The purpose of this research is to explore the usability of dialogue-based XR enhancement to ease the cognitive burden associated with manufacturing tasks through the augmentation of linked multi-modal information available to support operators. The proposed Interactive XR architecture using the Spoken Dialogue Systems' modular and user-centred architecture as a basis was tested in two use case scenarios: the maintenance of a robotic gripper and as a shop-floor assistant for electric panel assembly. In both cases we have confirmed a high user acceptance rate with an efficient knowledge communication and distribution even for operators without prior experience or with cognitive impairments therefore demonstrating the suitability of the solution for assisting human workers in industrial manufacturing processes. The results endorse an initial validation of the Interactive XR architecture to achieve a multi-device and user-friendly experience to solve industrial processes which is flexible enough to encompass multiple tasks.;2020
The noetic end-to-end response selection challenge as one track in the 7th Dialog System Technology Challenges (DSTC7) aims to push the state of the art of utterance classification for real world goal-oriented dialog systems for which participants need to select the correct next utterances from a set of candidates for the multi-turn context. This paper presents our systems that are ranked top 1 on both datasets under this challenge one focused and small (Advising) and the other more diverse and large (Ubuntu). Previous state-of-the-art models use hierarchy-based (utterance-level and token-level) neural networks to explicitly model the interactions among different turns' utterances for context modeling. In this paper we investigate a sequential matching model based only on chain sequence for multi-turn response selection. Our results demonstrate that the potentials of sequential matching approaches have not yet been fully exploited in the past for multi-turn response selection. In addition to ranking top 1 in the challenge the proposed model outperforms all previous models including state-of-the-art hierarchy-based models on two large-scale public multi-turn response selection benchmark datasets. (C) 2020 Elsevier Ltd. All rights reserved.;2020
The popularity and application of artificial intelligence (AI) are increasing rapidly all around the world-where in simple terms AI is a technology which mimics the behaviors commonly associated with human intelligence. Today various AI applications are being used in areas ranging from marketing to banking and finance from agriculture to healthcare and security from space exploration to robotics and transport and from chatbots to artificial creativity and manufacturing. More recently AI applications have also started to become an integral part of many urban services. Urban artificial intelligences manage the transport systems of cities run restaurants and shops where every day urbanity is expressed repair urban infrastructure and govern multiple urban domains such as traffic air quality monitoring garbage collection and energy. In the age of uncertainty and complexity that is upon us the increasing adoption of AI is expected to continue and so its impact on the sustainability of our cities. This viewpoint explores and questions the sustainability of AI from the lens of smart and sustainable cities and generates insights into emerging urban artificial intelligences and the potential symbiosis between AI and a smart and sustainable urbanism. In terms of methodology this viewpoint deploys a thorough review of the current status of AI and smart and sustainable cities literature research developments trends and applications. In so doing it contributes to existing academic debates in the fields of smart and sustainable cities and AI. In addition by shedding light on the uptake of AI in cities the viewpoint seeks to help urban policymakers planners and citizens make informed decisions about a sustainable adoption of AI.;2020
The popularity of mobile devices and conversational agents in recent years has seen wide use of chatbots in different educational scenarios. In relation to the advances in mobile devices and conversational agents there are few research works concerning the design and evaluation of domain-specific chatbots to fulfill the demand of mobile learning. To address this issue we propose an agent-based conceptual architecture to develop a domain-specific chatbot for mobile learning. We extend the open-domain DeepQA agent to make it sensitive to restricted domain questions by building a domain-specific gate and employ WeChat as user interface. To evaluate our chatbot subjective and objective criteria are employed to assess its effectiveness. Additionally its usability evaluation proceeds with system usability scale questionnaire and net promoter score simultaneously. In total 18 domain experts participated in the evaluation of effectiveness and 52 participants were involved in the evaluation of usability. Based on the evaluation results we conclude that our chatbot can serve as an effective information retrieval tool in a specific domain. The perceived usability of our chatbot tends to be moderate and marginal and has positively affected the promotion of our chatbot for mobile learning. This paper contributes to the educative application of chatbots in specific subject fields.;2020
The purpose of this study was to assess the impact of Artificial Intelligence (AI) on education. Premised on a narrative and framework for assessing AI identified from a preliminary analysis the scope of the study was limited to the application and effects of AI in administration instruction and learning. A qualitative research approach leveraging the use of literature review as a research design and approach was used and effectively facilitated the realization of the study purpose. Artificial intelligence is a field of study and the resulting innovations and developments that have culminated in computers machines and other artifacts having human-like intelligence characterized by cognitive abilities learning adaptability and decision-making capabilities. The study ascertained that AI has extensively been adopted and used in education particularly by education institutions in different forms. AI initially took the form of computer and computer related technologies transitioning to web-based and online intelligent education systems and ultimately with the use of embedded computer systems together with other technologies the use of humanoid robots and web-based chatbots to perform instructors' duties and functions independently or with instructors. Using these platforms instructors have been able to perform different administrative functions such as reviewing and grading students' assignments more effectively and efficiently and achieve higher quality in their teaching activities. On the other hand because the systems leverage machine learning and adaptability curriculum and content has been customized and personalized in line with students' needs which has fostered uptake and retention thereby improving learners experience and overall quality of learning.;2020
The purpose of this study was to explore customers' perceptions and behaviors when using chatbots in restaurant takeout orders. Built on the social presence theory this study conducted a lab experiment to examine and compare three ordering methods in quick-service and full-service restaurants. Results revealed that phone ordering and online ordering were both better than chatbot ordering in terms of satisfaction and behavioral outcomes. The phone ordering method elicited best social presence and cognitive attitudes while the online ordering method generated highest order amounts. Chatbot ordering is better suited for use in quick-service restaurants due to their simpler menus. In terms of order items chatbot method was used for simple menu items and core products phone method for specials and more complicated items while online method for more expensive items and add-ons. The findings offer new insight for restaurant practitioners into designing and adopting chatbots.;2020
The response selection has been an emerging research topic due to the growing interest in dialogue modeling where the goal of the task is to select an appropriate response for continuing dialogues. To further push the end-to-end dialogue model toward real-world scenarios the seventh Dialog System Technology Challenge (DSTC7) proposed a challenge track based on real chatlog datasets. The competition focuses on dialogue modeling with several advanced characteristics: (1) natural language diversity (2) capability of precisely selecting a proper response from a large set of candidates or the scenario without any correct answer and (3) knowledge grounding. This paper introduces recurrent attention pooling networks (RAP-Net) a novel framework for response selection which can well estimate the relevance between the dialogue contexts and the candidates. The proposed RAP-Net is shown to be effective and can be generalize across different datasets and settings in the DSTC7 experiments. (c) 2020 Elsevier Ltd. All rights reserved.;2020
The rise of increasingly more powerful chatbots offers a new way to collect information through conversational surveys where a chatbot asks open-ended questions interprets a user's free-text responses and probes answers whenever needed. To investigate the effectiveness and limitations of such a chatbot in conducting surveys we conducted a field study involving about 600 participants. In this study with mostly open-ended questions half of the participants took a typical online survey on Qualtrics and the other half interacted with an AI-powered chatbot to complete a conversational survey. Our detailed analysis of over 5200 free-text responses revealed that the chatbot drove a significantly higher level of participant engagement and elicited significantly better quality responses measured by Gricean Maxims in terms of their informativeness relevance specificity and clarity. Based on our results we discuss design implications for creating AI-powered chatbots to conduct effective surveys and beyond.;2020
The screening of healthcare workers for COVID-19 (coronavirus disease 2019) symptoms and exposures prior to every clinical shift is important for preventing nosocomial spread of infection but creates a major logistical challenge. To make the screening process simple and efficient University of California San Francisco Health designed and implemented a digital chatbot-based workflow. Within 1 week of forming a team we conducted a product development sprint and deployed the digital screening process. In the first 2 months of use over 270 000 digital screens have been conducted. This process has reduced wait times for employees entering our hospitals during shift changes allowed for physical distancing at hospital entrances prevented higher-risk individuals from coming to work and provided our healthcare leaders with robust real-time data for make staffing decisions.;2020
The study examined humorous interactions with intelligent personal assistants (IPAs including Google Assistant Amazon Alexa Microsoft Cortana Apple Siri) with the aim of classifying user utterances IPA responses and user reactions of system responses. Data from online diaries and paper questionnaires were collected and analyzed using content analysis method. The findings suggest that the most frequent types of utterances include questions that test system personality and opinions. Joke requests are also frequent and produce pre-programmed humor that users generally find funny. The initial classification of humorous utterances has been validated and expanded using published datasets of humorous utterances for the four investigated IPAs. The findings can be used for immediate improvements to IPA performance as well as long-term development of IPA personas.;2020
The task of dialogue generation has attracted increasing attention due to its diverse downstream applications such as question-answering systems and chatbots. Recently the deep neural network (DNN)-based dialogue generation models have achieved superior performance against conventional models utilizing statistical machine learning methods. However despite that an enormous number of state-of-the-art DNN-based models have been proposed there lacks detailed empirical comparative analysis for them on the open Chinese corpus. As a result relevant researchers and engineers might find it hard to get an intuitive understanding of the current research progress. To address this challenge we conducted an empirical study for state-of-the-art DNN-based dialogue generation models in various Chinese corpora. Specifically extensive experiments were performed on several well-known single-turn and multi-turn dialogue corpora including KdConv Weibo and Douban to evaluate a wide range of dialogue generation models that are based on the symmetrical architecture of Seq2Seq RNNSearch transformer generative adversarial nets and reinforcement learning respectively. Moreover we paid special attention to the prevalent pre-trained model for the quality of dialogue generation. Their performances were evaluated by four widely-used metrics in this area: BLEU pseudo distinct and rouge. Finally we report a case study to show example responses generated by these models separately.;2020
The terrible cost of injuries and sudden illnesses does have fatal consequences that exposes the limitations of the current prehospital processes in terms of time for emergency staff to arrive on scene and lack of first aid skills among the available incident witnesses. In this paper we aim at developing a smart pervasive chatbot for emergency case assistance based on cloud computing called SPeCECA that assists victims or incident witnesses to help avoiding deterioration of the subject's condition and maintaining his/her physical integrity until the aid arrives which could dramatically increase the victim's survivability chances. Therefore even a person with no first aid skills can help the victim to survive by performing first aid support as suggested by the virtual assistant. Furthermore thanks to its connectivity with the emergency medical service trusted person(s) and the access to social media SPeCECA has its own way of alarming the emergency case in parallel after having released the degree of the emergency situation's severity. The proposed method is a mobile pervasive healthcare service in the form of a connected mobile application as a virtual assistant for the benefit of anyone facing an emergency case. The proposed chatbot allows an online human-bot interaction that supports different scenarios for every single emergency case. The design of the system is introduced by its six interdependent components: information pre-processing component (IPPC) natural language processing component (NLPC) context component (CC) information post-processing component (IPoPC) response generator component (RGC) and alert message constructor component (AMCC).;2020
The use of natural language processing (NLP) methods and their application to developing conversational systems for health diagnosis increases patients' access to medical knowledge. In this study a chatbot service was developed for the Covenant University Doctor (CUDoctor) telehealth system based on fuzzy logic rules and fuzzy inference. The service focuses on assessing the symptoms of tropical diseases in Nigeria. Telegram Bot Application Programming Interface (API) was used to create the interconnection between the chatbot and the system while Twilio API was used for interconnectivity between the system and a short messaging service (SMS) subscriber. The service uses the knowledge base consisting of known facts on diseases and symptoms acquired from medical ontologies. A fuzzy support vector machine (SVM) is used to effectively predict the disease based on the symptoms inputted. The inputs of the users are recognized by NLP and are forwarded to the CUDoctor for decision support. Finally a notification message displaying the end of the diagnosis process is sent to the user. The result is a medical diagnosis system which provides a personalized diagnosis utilizing self-input from users to effectively diagnose diseases. The usability of the developed system was evaluated using the system usability scale (SUS) yielding a mean SUS score of 80.4 which indicates the overall positive evaluation.;2020
The use of Reinforcement Learning (RL) approaches for dialogue policy optimization has been the new trend for dialogue management systems. Several methods have been proposed which are trained on dialogue data to provide optimal system response. However most of these approaches exhibit performance degradation in the presence of noise poor scalability to other domains as well as performance instabilities. To overcome these problems we propose a novel approach based on the incremental sample-efficient Least-Squares Policy Iteration (LSPI) algorithm which is trained on compact fixed-size dialogue state encodings obtained from deep Variational Denoising Autoencoders (VDAE). The proposed scheme exhibits stable and noise-robust performance which significantly outperforms the current state-of-the-art even in mismatched noise environments.;2020
The Web is a constantly evolving complex system with important implications for both marketers and consumers. In this paper we contend that over the next five to ten years society will see a shift in the nature of the Web as consumers firms and regulators become increasingly concerned about privacy. In particular we predict that as a result of this privacy-focus various information sharing and protection practices currently found on the Dark Web will be increasingly adapted in the overall Web and in the process firms will lose much of their ability to fuel a modern marketing machinery that relies on abundant rich and timely consumer data. In this type of controlled information-sharing environment we foresee the emersion of two distinct types of consumers: (1) those generally willing to share their information with marketers (Buffs) and (2) those who generally deny access to their personal information (Ghosts). We argue that one way marketers can navigate this new environment is by effectively designing and deploying conversational agents (CAs) often referred to as chatbots. In particular we propose that CAs may be used to understand and engage both types of consumers while providing personalization and serving both as a form of differentiation and as an important strategic asset for the firm-one capable of eliciting self-disclosure of otherwise private consumer information.;2020
The WebRTC protocol can provide live streaming of peer-to-peer connections via JavaScript (JS) application programming interface (API) calls to a web browser. However the protocol is restricted to a small number of peers because there is no simple way to mix real-time streams from multiple peers and then distribute the mixed stream to a large number of audiences. For example it is necessary to mix audio and video streams from peers in a conversation and broadcast the real-time mixed stream to more than 10k audiences who only watch the video. It is also necessary to blend synchronous content (e.g. logos music) to the live conversation stream. WebRTC does not currently provide a mechanism to easily support these cases. This paper proposes a method for the synchronized mixing of real-time audio/video streams from multiple peers while minimizing latency. This method enables the implementation of an online live conversation system that is able to mix live conversation streams from multiple peers and then rebroadcast the mixed stream to a large number of audiences.;2020
The wecoach is a web-application that builds the capacities of team leaders to improve working conditions that are positively related to the psychological health and well-being of their team members. The web-application works through an automated rule-based chat enhanced by machine learning. This so-called conversational agent guides the team leader through a systematic project cycle providing a mind map of work and health training materials self-assessments and online tools to conduct team surveys and workshops as well as self-evaluation of progress and effectiveness. In this paper we present the development process of this web-application which resulted in (1) a comprehensive intervention approach (2) the prototype and (3) the implementation of an evaluation design for a multi-level randomized controlled trial.;2020
There has been a lot of recent interest in the natural language processing (NLP) community in the computational processing of language varieties and dialects with the aim to improve the performance of applications such as machine translation speech recognition and dialogue systems. Here we attempt to survey this growing field of research with focus on computational methods for processing similar languages varieties and dialects. In particular we discuss the most important challenges when dealing with diatopic language variation and we present some of the available datasets the process of data collection and the most common data collection strategies used to compile datasets for similar languages varieties and dialects. We further present a number of studies on computational methods developed and/or adapted for preprocessing normalization part-of-speech tagging and parsing similar languages language varieties and dialects. Finally we discuss relevant applications such as language and dialect identification and machine translation for closely related languages language varieties and dialects.;2020
There is a great interest shown by academic researchers to continuously improve the sequence-to-sequence (Seq2Seq) model for natural answer generation (NAG) in chatbots. The Seq2Seq model shows a weakness whereby the model tends to generate answers that are generic meaningless and inconsistent with the questions. However a comprehensive literature review on the factors contributing to the weakness and potential solutions are still missing. Therefore this review article fills the gap by reviewing Seq2Seq based natural answer generation-based literature to identify those factors and proposed methods to address the weakness. This literature review identified several factors such as input question is not sufficient to determine a meaningful output usage of cross-entropy function as the loss function during training infrequent words in training data language model influence which generates answers not relevant to the question utilization of teacher forcing method during training which results in exposure bias long sentences and inability to consider dialogue history as the factors. Additionally this literature review also identified and reviewed the methods proposed to address the weakness such as utilizing additional embedding and encoders using different loss functions and training approaches as well as utilizing other mechanisms like copying source word(s) and paying attention to a certain portion of the input. For discussion these methods are categorized into four broad categories which are Structural Modifications Augmented Learning Beam Search and Complementary Mechanisms. Additionally the paper highlights unexplored areas in Seq2Seq modeling and proposes potential future works for natural answer generation.;2020
There is a resurgent interest in developing intelligent open-domain dialog systems due to the availability of large amounts of conversational data and the recent progress on neural approaches to conversational Al [33]. Unlike traditional task-oriented bots an open-domain dialog system aims to establish long-term connections with users by satisfying the human need for communication affection and social belonging. This article reviews the recent work on neural approaches that are devoted to addressing three challenges in developing such systems: semantics consistency and Interactiveness. Semantics requires a dialog system to not only understand the content of the dialog but also identify users' emotional and social needs during the conversation. Consistency requires the system to demonstrate a consistent personality to win users' trust and gain their long-term confidence. Interactiveness refers to the system's ability to generate interpersonal responses to achieve particular social goals such as entertainment and conforming. The studies we select to present in this survey are based on our unique views and are by no means complete. Nevertheless we hope that the discussion will inspire new research in developing more intelligent open-domain dialog systems.;2020
This article describes the development of Microsoft XiaoIce the most popular social chatbot in the world. XiaoIce is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication affection and social belonging. We take into account both intelligent quotient and emotional quotient in system design cast human-machine social chat as decision-making over Markov Decision Processes and optimize XiaoIce for long-term user engagement measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components including dialogue manager core chat skills and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states understands user intent and responds to user needs throughout long conversations. Since the release in 2014 XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of large-scale online logs shows that XiaoIce has achieved an average CPS of 23 which is significantly higher than that of other chatbots and even human conversations.;2020
This article explores the impact of digital technologies including tele-health teleconsultations wireless devices and chatbots in pediatrics. Automated digital health with the Internet of things will allow better collection of real-world data for generation of real-world evidence to improve child health. Artificial intelligence with predictive analytics in turn will drive evidence-based decision-support systems and deliver personalized care to children. This technology creates building blocks for a learning child health and health care ecosystem.;2020
This article explores the institutional logics of intrapreneurial units or groups within organizations that are designated to foster organizational innovation. Drawing on interviews with news intrapreneurs developing chatbots in news media organizations this study shows that innovation can be stymied because of conflicting institutional logics. News intrapreneurs adopt a logic of experimentation audience orientation and efficiency-seeking but that approach clashes with a journalistic logic prioritizing news workflows formats and associated autonomy for newsworkers. These clashing logics limit the adoption and influence of chatbots. This study illustrates the shaping influence of competing institutional logics and their negotiation in the development deployment and success or failure of intrapreneurial activities within organizations. The lesson is not that the existence of competing logics is by default a defeating proposition for innovation. Rather this study advances scholarly understanding of the role of institutional logics in frustrating or facilitating technological adoption in organizations.;2020
This article explores the potential of Artificial Intelligence (AI) chatbots for creating positive change by supporting customers in the digital realm. Our study which focuses on the customer and his/her declarative psychological responses to an interaction with a virtual assistant will fill a gap in the digital marketing research where little attention has been paid to the impact of Error and Gender as well as the extent to which Social Presence and Perceived Competence mediate the relationships between Anthropomorphic design cues and Trust. We provide consistent evidence of the significant negative effect of erroneous conversational interfaces on several constructs considered in our conceptual model such as: perceived competence trust as well as positive consumer responses. We also provide support to previous research findings and confirm that people employ a biased thinking across gender and this categorization also influences their acceptance of chatbots taking social roles. The results of an empirical study demonstrated that highly anthropomorphized female chatbots that engage in social behaviors are significantly shaping positive consumer responses even in the error condition. Moreover female virtual assistants are much more commonly forgiven when committing errors compared to male chatbots.;2020
This article presents the framework Capability Sensitive Design (CSD) which consists of merging the design methodology Value Sensitive Design (VSD) with Martha Nussbaum's capability theory. CSD aims to normatively assess technology design in general and technology design for health and wellbeing in particular. Unique to CSD is its ability to account for human diversity and to counter (structural) injustices that manifest in technology design. The basic framework of CSD is demonstrated by applying it to the hypothetical design case of a therapy chatbot for mental health. By applying CSD to a design case the merits of this new framework over the standard VSD approach become apparent. Also the application demonstrates what a technology design would look like when attention is paid to capabilities right from the start of the design process.;2020
This article proposes a computer-based approach to effectively enhance second language learners' willingness to communicate in the target language. To do so we implemented a conversational agent embedding a dialogue management model based on two conversational strategies (i.e. communication strategies and affective backchannels) serving as scaffolds for enhancing learners' willingness to communicate in the target language. Here we report on differences observed among second language learners' preferences for both conversational strategies according to their initial level of willingness to communicate and on variations of their willingness with respect to such differences. Although we found that most students generally preferred a combination of both strategies learners' preferences and the effects of the support provided by these strategies varied according to their level of willingness to communicate. Learners with lower willingness to communicate tended to prefer affective backchannels whereas those with higher willingness to communicate seemed to favor communication strategies. These results were consistent with post-test results which showed that learners' expected willingness to communicate tended to be higher after interacting with systems embedding their preferred strategies. In sum these results are preliminary evidence of the meaningfulness of accounting for such learners' preferences in adaptively using and fading the strategies employed by conversational agents to motivate second language learners to communicate in the target language.;2020
This article proposes an approach to response generation using a Parallel Double Q-learning algorithm for dialog policy decision in a conversational system. First a new semantic representation of the user's input sentence is presented by using the CKIP parser to derive the semantic dependency sequence of the input sentence. Then a Gated Recurrent Unit-based Autoencoder is used to obtain the user's turn representation as well as context representation. A Parallel Double Q-learning algorithm with a Deep Neural Network (PD-DQN) combining two Double DQNs in parallel for the contextual and semantic information in the user's message respectively are proposed to determine the dialog act. Finally the user's input and the determined dialog act are fed to an attention-based Transformer model to generate the response template. With the generated response template the semantic slots are filled with their corresponding values to obtain the final sentence response. This article collects a multi-turn conversation database consisting of 4186 turns in the travel domain and 447 chitchat question-answer pairs as the evaluation corpus. Five-fold cross validation is employed for performance evaluation. Experimental results show that the proposed approach based on semantic dependency for intent detection increases the accuracy by 4.3%. For dialog policy decision the PD-DQN achieves 87.57% task success rate which is 13.9% higher than the baseline Double DQN (73.67%). Finally using the attention-based Transformer for response template generation obtains a Bleu score of 13.6 improved by 1.5 compared to the Sequence-to-Sequence model. In subjective evaluation both the dialog policy and sentence generation model achieve a higher appropriateness and grammatical correctness scores than the baseline system.;2020
This article proposes an utterance-to-utterance interactive matching network (U2U-IMN) for multi-turn response selection in retrieval-based chatbots. Different from previous methods following context-to-response matching or utterance-to-response matching frameworks this model treats both contexts and responses as sequences of utterances when calculating the matching degrees between them. For a context-response pair the U2U-IMN model first encodes each utterance separately using recurrent and self-attention layers. Then a global and bidirectional interaction between the context and the response is conducted using the attention mechanism to collect the matching information between them. The distances between context and response utterances are employed as a prior component when calculating the attention weights. Finally sentence-level aggregation and context-response-level aggregation are executed in turn to obtain the feature vector for matching degree prediction. Experiments on four public datasets showed that our proposed method outperformed baseline methods on all metrics achieving a new state-of-the-art performance and demonstrating compatibility across domains for multi-turn response selection.;2020
This paper describes a solution for the Noetic End-to-End Response Selection challenge - one of the tasks of the 7th Dialog System Technology Challenge. The goal of the task is to select the most appropriate continuation of a dialogue from a given set of responses. We approach this problem by building an ensemble of supervised neural network based classifiers and unsupervised similarity models. The dialogue continuation is selected according to a score that aggregates the rankings of candidate responses determined by the models in the ensemble. (C) 2020 The Author(s). Published by Elsevier Ltd.;2020
This paper discusses how a microlevel linguistic analysis using interactional sociolinguistics as an umbrella framework and drawing on analytical concepts from politeness theory and conversation analysis can be used to advise chatbot designers on the interactional features contributing to problematic human user engagement as part of a consultancy project. Existing research using a microlevel linguistic analysis has analysed human user:bot interactions using natural language. This research has identified a central role for language which promotes sociability between the machine and users in the alignment of their goals and practices. However there is no research currently which discusses how a microlevel linguistic analysis can help identify how the discursive construction of alignment and affiliation within prompt:response chatbots supports social presence and trust. This paper addresses this gap through an analysis of a database of prompt:response chatbot interactions which identified problematic sequences involving misalignment and disaffiliation undermining human users' trust and sense of social presence within the interaction. It also reports on how the consultancy project suggested changes to the programming of the chatbot which have potential to lead to improved user engagement and satisfaction. (C) 2020 Elsevier Ltd. All rights reserved.;2020
This paper introduces an approach to automatic domain modeling for human-robot interaction. The proposed approach is symbolic and intended for semantically unconstrained task-oriented human-robot interaction domains. At the specification level it is cognitively inspired addressing selected cognitive mechanisms of the human memory system (e.g. integration semantic categorization associative learning etc.) that are relevant for natural language human-robot interaction. We discuss a corpus-based validation of the introduced approach and report on its particular implementation within the conversational agent integrated with a human-like robot.;2020
This paper introduces our systems built for Track 2 of Dialog System Technology Challenge 7 (DSTC7). This challenge track aimed to evaluate the response generation methods using fully data-driven conversation models in a knowledge-grounded setting where textual facts were provided as the knowledge for each context-response pair. The sequence-to-sequence models have achieved impressive results in machine translation and have also been widely used for end-to-end generative conversation modelling. However they tended to output dull and repeated responses in previous studies. Our work aims to promote the diversity of end-to-end conversation response generation by adopting a two-stage pipeline. 1) Create multiple responses for an input context together with its textual facts. At this stage two different models are designed i.e. a variational generative (VariGen) model and a retrieval-based (Retrieval) model. 2) Rank and return the most relevant response by training a topic coherence discrimination (TCD) model for calculating ranking scores. In our experiments we demonstrated the effectiveness of the response ranking strategy and the external textual knowledge for generating better responses. According to the official evaluation results our Retrieval and VariGen systems ranked first and second respectively among all participant systems on Entropy metrics which measured the objective diversity of generated responses. Besides the VariGen system ranked second on NIST and METEOR metrics which measured the objective quality of generated responses. (C) 2020 Elsevier Ltd. All rights reserved.;2020
This paper presents a study about communicability of conversational interfaces (namely chatbots) under a semiotic perspective. A chatbot is a software system that allows you to simulate real conversations between devices and users by means of a conversational interface (CI). After introducing the chatbot concept focusing on its advantages and issues we will present two domains of use in which chatbot interfaces can be effective: healthcare and smart home. For carrying out simple tasks such as finding information or triggering operations users need an easy-to-use and to an easy-to-learn system to communicate with. To face this conversational interfaces represent the latest trend in the field of digital design. For studying the communicability aspects of a CI we carried out a user test to compare traditional and chatbot interfaces. This paper aims at evaluating the benefits at the communicability level of a chatbot in comparison to traditional GUI for incrementing the effectiveness and efficacy of communication between users and the system specifically for users with poor attitude in using technologies. In details we evaluated the communicability of two prototypes that can be used to solve simple tasks in order to favour user inclusion including everyone with very little exposure to technologies.;2020
This paper presents an exploratory study on using conversational interfaces (CIs) to support physicians in conducting occupational health consultations. The CI was achieved through a web-based information dashboard with a chatbot assistant for providing real-time suggestions through text messages. Two system designs were developed: the first using a proactive chatbot the second using an on-demand type of interaction. The effectiveness of the proposed CI and the two types of chatbot designs were investigated in a field study consisted of eight healthcare consultations. Quantitative results showed that the CI was positively evaluated as a reliable tool to be used during medical consultations and that occupational health physicians were eager to use this technology in their work. The qualitative data analysis suggested that our design concept might improve the workflow during the consultation particularly with respect to the access to relevant information and structured decision-making processes using valuable references. The on-demand lightweight type of chatbot interaction was better perceived than the proactive one. Based on these findings we discuss implications for the future development of occupational health consultation based on CI and their potential contribution to computer-assisted data-driven healthcare.;2020
This paper presents DisBot the first Portuguese speaking chatbot that uses social media retrieved knowledge to support citizens and first-responders in disaster scenarios in order to improve community resilience and decision-making. It was developed and tested using Design Science Research Methodology (DSRM) being progressively matured with field specialists through several design and development iterations. DisBot uses a state-of-the-art Dual Intent Entity Transformer (DIET) architecture to classify user intents and makes use of several dialogue policies for managing user conversations as well as storing relevant information to be used in further dialogue turns. To generate responses it uses real-world safety knowledge and infers a dynamic knowledge graph that is dynamically updated in real-time by a disaster-related knowledge extraction tool presented in previous works. Through its development iterations DisBot has been validated by field specialists who have considered it to be a valuable asset in disaster management.;2020
This paper presents HRIChat a framework for developing closed-domain chat dialogue systems. Being able to engage in chat dialogues has been found effective for improving communication between humans and dialogue systems. This paper focuses on closed-domain systems because they would be useful when combined with task-oriented dialogue systems in the same domain. HRIChat enables domain-dependent language understanding so that it can deal well with domain-specific utterances. In addition HRIChat makes it possible to integrate state transition network-based dialogue management and reaction-based dialogue management. FoodChatbot which is an application in the food and restaurant domain has been developed and evaluated through a user study. Its results suggest that reasonably good systems can be developed with HRIChat. This paper also reports lessons learned from the development and evaluation of FoodChatbot. (C) 2020 The Authors. Published by Elsevier B.V.;2020
This paper presents our work on the Dialog System Technology Challenges 7 (DSTC7). We took part in Track 1 on sentence selection which evaluates response retrieving in dialog systems on more realistic test scenarios compared to the state-of-the-art evaluations. Our proposed dialog system matches the context with the best response by computing their semantic similarity on word and sequence levels. Evaluation results on the datasets provided show the effectiveness of our system by achieving higher performance compared to the provided baseline system. Our system enjoys the advantages of its simple and end-to-end architecture making its training and adaptation to other domains easier. (c) 2020 Elsevier Ltd. All rights reserved.;2020
This paper provides an overview of the literature concerning Seniors' psychological perspective in exploiting assistive robots and the embodied conversational agents. The main theoretical models devoted to assess user's technology acceptance are briefly reviewed along with a description of the main factors empirically found to be positively/negatively associated with Seniors' acceptance level. Special attention is reserved to barriers generated by Seniors' representations of social assistive technologies such as a stigma or threat to their autonomy infantilization privacy interferences fear of dehumanization and isolation.;2020
This paper provides detailed information about the seventh Dialog System Technology Challenge (DSTC7) and its three tracks aimed to explore the problem of building robust and accurate end-to-end dialog systems. In more detail DSTC7 focuses on developing and exploring end-to-end technologies for the following three pragmatic challenges: (1) sentence selection for multiple domains (2) generation of informational responses grounded in external knowledge and (3) audio visual scene-aware dialog to allow conversations with users about objects and events around them. This paper summarizes the overall setup and results of DSTC7 including detailed descriptions of the different tracks provided datasets and annotations overview of the submitted systems and their final results. For Track 1 LSTM-based models performed best across both datasets allowing teams to effectively handle task variants where no correct answer was present or when multiple paraphrases were included. For Track 2 RNN-based architectures augmented to incorporate facts by using two types of encoders: a dialog encoder and a fact encoder plus using attention mechanisms and a pointer-generator approach provided the best results. Finally for Track 3 the best model used Hierarchical Attention mechanisms to combine the text and vision information obtaining a 22% better result than the baseline LSTM system for the human rating score. More than 220 participants were registered and about 40 teams participated in the final challenge. 32 scientific papers reporting the systems submitted to DSTC7 and 3 general technical papers for dialog technologies were presented during the one-day wrap-up workshop at AAAI-19. During the workshop we reviewed the state-of-the-art systems shared novel approaches to the DSTC7 tasks and discussed the future directions for the challenge (DSTC8). (C) 2020 Elsevier Ltd. All rights reserved.;2020
This paper(1) presents a study on understanding what the users say in chatbot systems: the situation where users input utterances bots would hopefully (1) detect intents and (2) recognize corresponding contexts implied by utterances. This helps bots better understand what users are saying and act upon a much wider range of actions. To this end we propose a framework which models the first task as a classification problem and the second one as a two-layer sequence labeling problem. The framework explores deep neural networks to automatically learn useful features at both character and word levels. We apply this framework to building a chatbot in a Vietnamese e-commerce domain to help retail brands better communicate with their customers. Experimental results on four newly-built datasets demonstrate that deep neural networks could be able to outperform strong conventional machine-learning methods. In detecting intents we achieve the best F-measure of 82.32%. In extracting contexts the proposed method yields promising F-measures ranging from 78% to 91% depending on specific types of contexts.;2020
This research aims to build a Mandarin named entity recognition (NER) module using transfer learning to facilitate damage information gathering and analysis in disaster management. The hybrid NER approach proposed in this research includes three modules: (1) data augmentation which constructs a concise data set for disaster management (2) reference model which utilizes the bidirectional long short-term memory-conditional random field framework to implement NER and (3) the augmented model built by integrating the first two modules via cross-domain transfer with disparate label sets. Through the combination of established rules and learned sentence patterns the hybrid approach performs well in NER tasks for disaster management and recognizes unfamiliar words successfully. This research applied the proposed NER module to disaster management. In the application we favorably handled the NER tasks of our related work and achieved our desired outcomes. Through proper transfer the results of this work can be extended to other fields and consequently bring valuable advantages in diverse applications.;2020
This study examined how artificial intelligence (AI)-driven chatbots impact user experience. It collected survey data from 1064 consumers who used any chatbot service from the top 30 brands in the U.S. Results indicated that utilitarian (information) hedonic (entertainment) technology (media appeal) and social (social presence) gratifications obtained from chatbot use positively predicted users' satisfaction with chatbot services of their selected brand. In contrast perceived privacy risk associated with chatbot use reduced user satisfaction. Data also demonstrated that user satisfaction positively affected both the continued use intention of chatbot services and customer loyalty. Implications of this study are discussed.;2020
This study examines the persuasion mechanism in product recommendations made by a voice-based conversational agent and explores whether the personalized content reflecting the customer's preferences and the agent's social role of a friend rather than a secretary generate a more positive attitude toward the product in the context of voice shopping. With the framework of dual modes of information-processing models we hypothesized that the personalization of messages would be a central mute with a greater impact on attitude for products with high involvement. By contrast the social role of the conversational agent was expected to represent a peripheral route with a greater impact on products with low involvement. An experimental study was designed to test the effects of personalized content that reflected individual preferences for product attributes and a friend role of a voice agent with high and low product involvement. The results showed main effects of both personalization and the social role on building attitudes toward the product. Although no interaction effect for personalization and involvement was found there was a significant interaction effect for the social role and involvement. This study contributes to persuasion theory by extending it to the interaction with a conversational agent. For practitioners the study provides insights into the importance of the personalized content of recommendations and the need for consideration of an alternative social role in the design of voice shopping through a conversational agent.;2020
This study explores TV viewers' user experience (UX) of the conversational agent (CA) assisted interactions while watching TV. In the human-computer interaction field the user experience is primarily measured through performance and subjective self-reported data. But TV is an entertainment medium the user experience of TV viewers should be determined based on how much the TV viewers enjoyed and immersed rather than productivity or performance. It is also necessary to collect objective data as well as subjective self-report results of emotional experiences. Although the CA is becoming increasingly common in everyday life the user satisfaction is still not high. However this is mainly a result of evaluation in the performance aspect and few studies have been carried out on the overall user experience including emotional aspects. To comparatively analyze the user experience with the CA interface and remote control unit (RCU) interface we adopted physiological measurements for objective data as well as self-report questionnaires. Among the physiological measurement results skin conductance (SC) differed between CA and RCU interactions. SC was high at the beginning of the CA interaction but decreased over time. In RCU sessions SC maintained a constant value or rather increased. In the self-reporting results the ergonomic quality of the RCU was higher than that of the CA. However CA was evaluated more positively in terms of hedonic quality. CA had a greater effect on the overall attractiveness while having more emotional appeal. Additionally a partial correlation between objective data and self-report results could be observed. In sum subjective self-reports showed that CA provides a more positive TV UX with regard to emotional aspects. Physiological measurement results provide objective data for further understanding user experience by showing specific differences in cognitive involvement and emotional response changes during user interactions.;2020
This study investigates the public's initial trust in so-called artificial intelligence (AI) chatbots about to be introduced into use in the public sector. While the societal impacts of AI are widely speculated about empirical testing remains rare. To narrow this gap this study builds on theories of operators' trust in machines in industrial settings and proposes that initial public trust in chatbot responses depends on (i) the area of enquiry since expectations about a chatbot's performance vary with the topic and (ii) the purposes that governments communicate to the public for introducing the use of chatbots. Analyses based on an experimental online survey in Japan generated results indicating that if a government were to announce its intention to use AI chatbots to answer public enquiries the public's initial trust in their responses would be lower in the area of parental support than in the area of waste separation with a moderate effect size. Communicating purposes that would directly benefit citizens such as achieving uniformity in response quality and timeliness in responding would enhance public trust in chatbots. Although the effect sizes are small communicating these purposes might be still worthwhile as it would be an inexpensive measure for a government to take.;2020
This study was undertaken to analyze whether luxury fashion retail brands can adhere to their core essence of providing personalized care through e-services rather than through traditional face-to-face interactions particularly through Chatbot an emerging digital tool offering convenient personal and unique customer assistance. The authors use customer data to test a five-dimension model measuring Chatbot for customer perceptions of interaction entertainment trendiness customization and problem-solving. The study reveals that Chatbot e-service provides interactive and engaging brand/customer service encounters. Marketers and managers in the luxury context can adopt the instrument to measure whether e-service agents provide desired outcomes and to determine whether they should adopt Chatbot virtual assistance.;2020
This work is extended from our participation in the 7th Dialogue System Technology Challenge (DSTC7) where we participated in the Audio Visual Scene-aware Dialogue System (AVSD) track. The AVSD track evaluates how dialogue systems understand video scenes and responds to users about the video visual and audio content. We propose a hierarchical attention approach on user queries video caption audio and visual features that contribute to improved evaluation results. We also apply a nonlinear feature fusion approach to combine the visual and audio features for better knowledge representation. Our proposed model shows superior performance in terms of both objective evaluation and human rating as compared to the baselines. In this extended work we also provide a more extensive review of the related work conduct additional experiments with word-level and context-level pretrained embeddings and investigate different qualitative aspects of the generated responses. (c) 2020 Elsevier Ltd. All rights reserved.;2020
This work takes us through the literature on applications of genetic programming to problems of natural language processing. The purpose of natural language processing is to allow us to communicate with computers in natural language. Among the problems addressed in the area is for example the extraction of information which draws relevant data from unstructured texts written in natural language. There are also domains of application of particular relevance because of the difficulty in dealing with the corresponding documents such as opinion mining in social networks or because of the need for high precision in the information extracted such as the biomedical domain. There have been proposals to apply genetic programming techniques in several of these areas. This tour allows us to observe the potential-not yet fully exploited-of such applications. We also review some cases in which genetic programming can provide information that is absent from other approaches revealing its ability to provide easy to interpret results in form of programs or functions. Finally we identify some important challenges in the area.;2020
Through online tools virtual assistants and other technology governments increasingly rely on artificial intelligence to help the public understand and apply the law. The Internal Revenue Service for example encourages taxpayers to seek answers regarding various tax credits and deductions through its online Interactive Tax Assistant. The U.S. Army directs individuals with questions about enlistment to its virtual guide Sgt. Star. And the U.S. Citizenship and Immigration Services suggests that potential green card holders and citizens speak with its interactive chatbot Emma. Through such automated legal guidance the government seeks to provide advice to the public at a fraction of the cost of employing human beings to perform these same tasks. This Article offers one of the first critiques of these new systems of artificial intelligence. It shows that automated legal guidance currently relies upon the concept of simplexity whereby complex law is presented as though it is simple without actually engaging in simplification of the underlying law. While this approach offers potential gains in terms of efficiency and ease of use it also causes the government to present the law as simpler than it is leading to less precise advice and potentially inaccurate legal positions. Using the Interactive Tax Assistant as a case study the Article shows that the use of simplexity in automated legal guidance is more powerful and pervasive than in static publications because it is personalized non-qualified and instantaneous. Further it argues that understanding the costs as well as the benefits of current forms of automated legal guidance is essential to evaluating even more sophisticated but also more opaque automated systems that governments are likely to adopt in the future. With these considerations in mind the Article offers three recommendations to policymakers. First it argues that governments should prevent automated legal guidance from widening the gap between access to legal advice enjoyed by high-income and by low-income individuals. Second it argues that governments should introduce more robust oversight and review processes for automated legal guidance. Finally it argues that the government should allow individuals to avoid certain penalties and sanctions when they have taken actions or claimed legal positions in reliance upon automated legal guidance. Unless these steps are taken we believe that the costs of these automated legal guidance systems may soon come to outweigh their benefits.;2020
To advance multi-domain (cross-domain) dialogue modeling as well as alleviate the shortage of Chinese task-oriented datasets we propose CrossWOZ the first large-scale Chinese Cross-Domain Wizard-of-Oz task-oriented dataset. It contains 6K dialogue sessions and 102K utterances for 5 domains including hotel restaurant attraction metro and taxi. Moreover the corpus contains rich annotation of dialogue states and dialogue acts on both user and system sides. About 60% of the dialogues have cross-domain user goals that favor inter-domain dependency and encourage natural transition across domains in conversation. We also provide a user simulator and several benchmark models for pipelined task-oriented dialogue systems which will facilitate researchers to compare and evaluate their models on this corpus. The large size and rich annotation of CrossWOZ make it suitable to investigate a variety of tasks in cross-domain dialogue modeling such as dialogue state tracking policy learning user simulation etc.;2020
To be really effective conversational agents must integrate well with the characteristics of the humans with whom they interact. This exploratory study focuses on a method for integrating well-assessed methods from the field of social psychology in the design of task-oriented conversational agents in which the dialogue management module is developed through machine learning. In particular the aim is to achieve agents whose policies could take into account the psychological features of the human interactants to deliver personalized and more effective messages. The paper presents the psychological study performed and outlines the overall theoretical architecture of the software framework proposed. On the psychosocial side we first assessed the effectiveness of differently framed messages aimed to reducing red meat consumption taking the Theory of Planned Behavior (TPB) as the psychosocial model of reference. Turning to the machine learning field the resulting Structural Equation Model (SEM) was first translated into a probabilistic predictor using Dynamic Bayesian Network (DBN). In turn such DBN became the fundamental element of a Partially Observable Markov Decision Processes (POMDP) in a reinforcement learning setting. The possibility to elicit complete interaction policies was then studied by applying Neural Monte Carlo Tree Search (Neural MCTS) methods. The results thus obtained introduce the possibility to develop new multidisciplinary and integrated techniques for the development of automated dialogue managing systems.;2020
To combat the pandemic of the coronavirus disease 2019 (COVID-19) numerous governments have established phone hotlines to prescreen potential cases. These hotlines have struggled with the volume of callers leading to wait times of hours or even an inability to contact health authorities. Symptoma is a symptom-to-disease digital health assistant that can differentiate more than 20000 diseases with an accuracy of more than 90%. We tested the accuracy of Symptoma to identify COVID-19 using a set of diverse clinical cases combined with case reports of COVID-19. We showed that Symptoma can accurately distinguish COVID-19 in 96.32% of clinical cases. When considering only COVID-19 symptoms and risk factors Symptoma identified 100% of those infected when presented with only three signs. Lastly we showed that Symptoma's accuracy far exceeds that of simple yes-no questionnaires widely available online. In summary Symptoma provides unparalleled accuracy in systematically identifying cases of COVID-19 while also considering over 20000 other diseases. Furthermore Symptoma allows free text input furthered with disease-specific follow up questions in 36 languages. Combined these results and accessibility give Symptoma the potential to be a key tool in the global fight against COVID-19.;2020
To gain competitive advantages and sustainable service innovation hotels are considering artificial intelligence technologies (AI) including robots kiosks for service automation and chatbots. However due to the change of the service process and unfamiliar communication interface hotel customers may have difficulties in adopting the new change. In this paper we tried to find out if the failure of AI-based services would affect customers' perception. For this we designed the experiment by separating AI (i.e. chatbot) services and self-service technology (SST i.e. pad) services and service failures and successful cases respectively. As a result SST showed more positive perceptions and revisit intention in the successful service situation. The service failure situation showed no differences between chatbot and SST. In addition novelty and the need for interaction characteristics of customers showed significant differences between groups in terms of service success and failure respectively. Additionally we explored negative word-of-mouth (WOM) to learn further effects by service failures and successes.;2020
To mitigate the ambiguity of spoken language understanding (SLU) of an utterance we propose contextual models that can consider the relevant context by using temporal and content-related information effectively. We first propose two axes: 'Awareness' and 'Attention Level'. Awareness includes three methods that consider the timing or content-similarity of context. The Attention Level includes three methods that consider speaker roles to calculate the importance of each historic utterance. By combining one method from each axis we build various contextual models. The proposed models are designed to use a dataset to automatically learn the importance of previous utterances in terms of time and content. We also propose various speaker information that would be helpful to improve SLU accuracy. The proposed models achieved state-of-the-art F1 scores in experiments on the Dialog State Tracking Challenge (DSTC) 4 and Loqui benchmark datasets. We applied in-depth analysis to verify that the proposed methods are effective to improve SLU accuracy. The analysis also demonstrated the effectiveness of the proposed methods. (C) 2019 Published by Elsevier Ltd.;2020
To overcome novel challenges in complex domestic environments humanoid robots can learn from human teachers. We propose that the capability for social interaction should be a key factor in this teaching process and benefits both the subjective experience of the human user and the learning process itself. To support our hypothesis we present a Human-Robot Interaction study on human-assisted visuomotor learning with the robot NICO the Neuro-Inspired COmpanion a child-sized humanoid. NICO is a flexible social platform with sensing and manipulation abilities. We give a detailed description of NICO's design and a comprehensive overview of studies that use or evaluate NICO. To engage in social interaction NICO can express stylized facial expressions and utter speech via an Embodied Dialogue System. NICO is characterized in particular by combining these social interaction capabilities with the abilities for human-like object manipulation and crossmodal perception. In the presented study NICO acquires visuomotor grasping skills by interacting with its environment. In contrast to methods like motor babbling the learning process is in part supported by a human teacher. To begin the learning process an object is placed into NICO's hand and if this object is accidentally dropped the human assistant has to recover it. The study is conducted with 24 participants with little or no prior experience with robots. In therobot-guidedexperimental condition assistance is actively requested by NICO via the Embodied Dialogue System. In thehuman-guidedcondition instructions are given by a human experimenter while NICO remains silent. Evaluation using established questionnaires like Godspeed Mind Perception and Uncanny Valley Indices along with a structured interview and video analysis of the interaction show that the robot's active requests for assistance foster the participant's engagement and benefit the learning process. This result supports the hypothesis that the ability for social interaction is a key factor for companion robots that learn with the help of non-expert teachers as these robots become capable of communicating active requests or questions that are vital to their learning process. We also show how the design of NICO both enables and is driven by this approach.;2020
To prevent the spread of COVID-19 and to continue responding to healthcare needs hospitals are rapidly adopting telehealth and other digital health tools to deliver care remotely. Intelligent conversational agents and virtual assistants such as chatbots and voice assistants have been utilized to augment health service capacity to screen symptoms deliver healthcare information and reduce exposure. In this commentary we examined the state of voice assistants (e.g. Google Assistant Apple Siri Amazon Alexa) as an emerging tool for remote healthcare delivery service and discussed the readiness of the health system and technology providers to adapt voice assistants as an alternative healthcare delivery modality during a health crisis and pandemic.;2020
Today breast cancer survivability prediction becomes one of the challenging tasks among medical practitioners and researchers as it is the most frequent cancer-affecting females globally. In healthcare domain usually clinical data are high dimensional sparse and complex and sometimes there exists few amounts of time-to-event instances. Moreover building an accurate survival model from electronic health records is another herculean task. This study aimed to predict survivability of breast cancer patients by using data analytics model and development of Chatbot for providing recommendation to user. This research work addresses the aforementioned issues by providing a novel survival analysis framework by using data analytics model. First this approach provides a better understanding of breast cancer survivability in presence of missing data then establishing associates of patients that share similar properties by using K-means unsupervised learning algorithm. In addition a simple effective recommendation approach based on Artificial neural network (ANN) and Linear regression model is developed for breast cancer survival analysis. The obtained results showed that ANN has a greater effect on survival performance improvement in the case that have corpus of data because of stronger unsupervised feature learning.;2020
Today the knowledge base question answering (KB-QA) system is promising to achieve a large-scale high-quality reply in the e-commerce industry. However there exist two major challenges to efficiently support large-scale KB-QA systems. On the one hand it is difficult to serve tens of thousands of online stores (i.e. constrained by the tuning and deployment time) and it would perform poorly if the systems start without a sufficient number of chat records. On the other hand current KB-QA systems cannot be updated in an efficient way due to the high cost of knowledge base (KB) updating. In this article we propose an automatic learning scheme for KB-QA systems called ALKB-QA using a vector modeling method to address the preceding two main challenges. The ALKB-QA system provides online stores with basic KB templates that are suitable for many common occasions and this feature enables the ability to deploy chatbots for a large number of online stores in a short time. Then the KBs are further updated automatically to adapt to their own businesses (meet different specific needs) leading to increased reply accuracy. Our work has three main contributions. First the proposed ALKB-QA system has a good business model in the e-commerce industry (serving tens of thousands of online stores with low cost) breaking the scalability limitations of existing KB-QA systems. Second we assess the reply accuracy of the proposed ALKB-QA system using human evaluations and the results show that it outperforms human annotation-base approaches. Third we launched our ALKB-QA system as a real-world business application and it supports tens of thousands of online stores.;2020
Traditional teaching based on masterclasses or techniques where the student develops a passive role has proven to be inefficient methods in the learning process. The use of technology in universities helps to generate active learning where the student's interest improves making him the main actor in his education. However implementing an environment where active learning takes place requires a great deal of effort given the number of variables involved in this objective. To identify these variables it is necessary to analyze the data generated by the students in search of patterns that allow them to be classified according to their needs. Once these needs are identified it is possible to make decisions that contribute to the learning of each student for this the use of artificial intelligence is considered. These techniques emulate the processes of human thought using structures that contain knowledge and experience of human experts.;2020
Twitter is a popular microblogging platform which facilitates users to express views and thoughts on day-today events using short texts limited to a maximum of 280 characters. However it is generally targeted by socialbots for political astroturfing advertising spamming and other illicit activities due to its open and real-time information sharing and dissemination nature. In this paper we present a socialbots analysis-driven graph-based approach for identifying coordinated campaigns among Twitter users. To this end we first present statistical insights derived from the analysis of logged data of 98 socialbots which were injected in Twitter and associated with top-six Twitter using countries. In the analysis we study and present the impact of socialbots' profile features such as age and gender on infiltration. We also present a multi-attributed graph-based approach to model the profile attributes and interaction behavior of users as a similarity graph for identifying different groups of synchronized users involved in coordinated campaigns. The proposed approach is experimentally evaluated using four different evaluation parameters over a real dataset containing socialbots' trapped user profiles. The evaluation of identified campaigns in the form of clusters reveals the traces of spammers botnets and other malicious users.;2020
Understanding the user & x2019s intention is an essential task for the spoken language understanding (SLU) module in the dialogue system which further illustrates vital information for managing and generating future action and response. In this paper we propose a triplet training framework based on the multiclass classification approach to conduct the training for the intention detection task. Precisely we utilize a Siamese neural network architecture with metric learning to construct a robust and discriminative utterance feature embedding model. We modified the RMCNN model and fine-tuned BERT model as Siamese encoders to train utterance triplets from different semantic aspects. The triplet loss can effectively distinguish the details of two input data by learning a mapping from sequence utterances to a compact Euclidean space. After generating the mapping the intention detection task can be easily implemented using standard techniques with pre-trained embeddings as feature vectors. Besides we use the fusion strategy to enhance utterance feature representation in the downstream of intention detection task. We conduct experiments on several benchmark datasets of intention detection task: Snips dataset ATIS dataset Facebook multilingual task-oriented datasets Daily Dialogue dataset and MRDA dataset. The results illustrate that the proposed method can effectively improve the recognition performance of these datasets and achieves new state-of-the-art results on single-turn task-oriented datasets (Snips dataset Facebook dataset) and a multi-turn dataset (Daily Dialogue dataset).;2020
User intent classification is a vital component of a question-answering system or a task-based dialogue system. In order to understand the goals of users' questions or discourses the system categorizes user text into a set of pre-defined user intent categories. User questions or discourses are usually short in length and lack sufficient context thus it is difficult to extract deep semantic information from these types of text and the accuracy of user intent classification may be affected. To better identify user intents this paper proposes a BERT-Cap hybrid neural network model with focal loss for user intent classification to capture user intents in dialogue. The model uses multiple transformer encoder blocks to encode user utterances and initializes encoder parameters with a pre-trained BERT. Then it extracts essential features using a capsule network with dynamic routing after utterances encoding. Experiment results on four publicly available datasets show that our model BERT-Cap achieves a F1 score of 0.967 and an accuracy of 0.967 outperforming a number of baseline methods indicating its effectiveness in user intent classification.;2020
Using the technology acceptance model and diffusion of innovations theory this study evaluated the intention of consumers to use chatbots on smartphones for shopping. Chatbot is a relatively new technology and is expected to dominate mobile commerce and shopping applications in future. Hence this study aimed to determine the association of perceived usefulness perceived ease of use perceived enjoyment price consciousness perceived risk trust and personal innovativeness with attitude and intention to use chatbots for shopping. Respondents were asked to fill a questionnaire after using a Facebook e-commerce chatbot that was specifically created for this study. In total 350 responses were analyzed using partial least squares structural equation modeling. Results indicated that attitude toward chatbots was considerably influenced by the variables perceived usefulness perceived ease of use perceived enjoyment price consciousness perceived risk and personal innovativeness. However intention to use was directly influenced only by trust personal innovativeness and attitude. Mediation analysis indicated that full mediation occurs through the attitude variable for most direct relationships. Moderation analysis by using age gender and prior experience with mobile shopping applications indicated considerable differences between the groups in terms of the strength of certain relationships and the mean responses between the variables.;2020
Virtual agents have demonstrated their ability to conduct clinical interviews. However the factors influencing patients' engagement with these agents have not yet been assessed. The objective of this study is to assess in outpatients the trust and acceptance of virtual agents performing medical interviews and to explore their influence on outpatients' engagement. In all 318 outpatients were enroled. The agent was perceived as trustworthy and well accepted by the patients confirming the good engagement of patients in the interaction. Older and less-educated patients accepted the virtual medical agent (VMA) more than younger and well-educated ones. Credibility of the agent appeared to main dimension enabling engaged and non-engaged outpatients to be classified. Our results show a high rate of engagement with the virtual agent that was mainly related to high trust and acceptance of the agent. These results open new paths for the future use of VMAs in medicine.;2020
Virtual Coaches also known as e-coaches are a disruptive technology in healthcare. Indeed among other usages they might provide cost-effective solutions for increasing human wellbeing in different domains such as physical nutritional cognitive social and emotional. This paper presents a systematic review of virtual coaches specifically aimed at improving or maintaining older adults' health in the aforementioned domains. Such digital systems assume various forms from classic apps to more advanced conversational agents or robots. Fifty-six articles describing a virtual coach for older adults and aimed at improving their wellbeing were identified and further analyzed. In particular we presented how previous studies defined their virtual coaches which behavioral change models and techniques they adopted and the overall system architecture in terms of monitoring solutions processing methods and modalities for intervention delivery. Our results show that few thorough evaluations of e-coaching systems have been conducted especially regarding multi-domain coaching approaches. Through our analysis we identified the wellbeing domains that should be addressed in future studies as well as the most promising behavior change models and techniques and coaching interfaces. Previous work illustrates that older adults often appreciate conversational agents and robots. However the lack of a multidomain intervention approach in the current literature motivates us to seek to define future solutions.;2020
Virtual patient software allows health professionals to practise their skills by interacting with tools simulating clinical scenarios. A natural language dialogue system can provide natural interaction for medical history-taking. However the large number of concepts and terms in the medical domain makes the creation of such a system a demanding task. We designed a dialogue system that stands out from current research by its ability to handle a wide variety of medical specialties and clinical cases. To address the task we designed a patient record model a knowledge model for the task and a termino-ontological model that hosts structured thesauri with linguistic terminological and ontological knowledge. We used a frame- and rule-based approach and terminology-rich resources to handle the medical dialogue. This work focuses on the termino-ontological model the challenges involved and how the system manages resources for the French language. We adopted a comprehensive approach to collect terms and ontological knowledge and dictionaries of affixes synonyms and derivational variants. Resources include domain lists containing over 161000 terms and dictionaries with over 959000 word/concept entries. We assessed our approach by having 71 participants (39 medical doctors and 32 non-medical evaluators) interact with the system and use 35 cases from 18 specialities. We conducted a quantitative evaluation of all components by analysing interaction logs (11834 turns). Natural language understanding achieved an F-measure of 95.8%. Dialogue management provided on average 74.3 (+/- 9.5)% of correct answers. We performed a qualitative evaluation by collecting 171 five-point Likert scale questionnaires. All evaluated aspects obtained mean scores above the Likert mid-scale point. We analysed the vocabulary coverage with regard to unseen cases: the system covered 97.8% of their terms. Evaluations showed that the system achieved high vocabulary coverage on unseen cases and was assessed as relevant for the task.;2020
Virtual tutors are a promising technology providing a rich interactive environment for children to learn in. However the question of how they should behave in order to enhance pupils' motivation remains unanswered. Using an embodied conversational agent platform we tested human-computer interactions with 22 children aged 9-11 years. Children performed several numeracy exercises set by two different virtual agents. One agent provided solely verbal feedback (unimodal) while the other one combined facial expressions based on real muscle contractions with its verbal feedback (bimodal). Children then completed a perceived social support questionnaire. Qualitative and quantitative data were subjected to inferential statistical tests. Results showed that the overall duration of agent-pupil interactions varied children found the bimodal agent more empathic and produced significantly more correct answers. Moreover there was a positive correlation between accuracy and mean reaction times for correct answers with the bimodal agent. The lack of a correlation for the unimodal agent is discussed in the light of empathy and motivation in social cognition.;2020
Visual conversation is a dialog in which parties exchange visual information. The key novelty presented in this paper is an artificial intelligence-driven visual conversation automation method. We will present a state of the art Artificial Intelligence Snapchat Visual Conversation Agent (AISVCA). AISVCA uses our proposed artificial intelligence-driven visual conversation automation method to create received image caption and generate an appropriate reasonable visual response. These functionalities are achieved by using a combination of Convolutional Neural Network (CNN) Long Short-Term Memory Neural Network (LSTM) and Latent Semantic Indexing method (LSI). CNN and LSTM are used to create image captions and LSI is used to assess the semantic similarity between captions generated from personalized image dataset and captions that are extracted from the received image content. We will show that AISVCA using the proposed method can generate a visual response that is basically indistinguishable from a human visual response. To evaluate the proposed approach we measured the accuracy of the proposed system and conducted a user study to test communication quality. In the user study we analyzed source credibility and interpersonal attraction of the AISVCA. The user study results showed that there are no significant differences in communication quality between a visual conversation with AISVCA and visual conversation with the human agent.;2020
Voice assistants embodied in smart speakers (e.g. Amazon Echo Google Home) enable voice-based interaction that does not necessarily rely on expertise with mobile or desktop computing. Hence these voice assistants offer new opportunities to different populations including individuals who are not interested or able to use traditional computing devices such as computers and smartphones. To understand how older adults who use technology infrequently perceive and use these voice assistants we conducted a 3-week field deployment of the Amazon Echo Dot in the homes of seven older adults. While some types of usage dropped over the 3-week period (e.g. playing music) we observed consistent usage for finding online information. Given that much of this information was health-related this finding emphasizes the need to revisit concerns about credibility of information with this new interaction medium. Although features to support memory (e.g. setting timers reminders) were initially perceived as useful the actual usage was unexpectedly low due to reliability concerns. We discuss how these findings apply to other user groups along with design implications and recommendations for future work on voice-user interfaces.;2020
We have developed an adaptation method which allows the customization of example-based dialog systems for individual users by applying plus and minus operations to the distributed representations obtained using the word2vec method. After retrieving user-related profile information from the Web named entity extraction is applied to the retrieval results. Words with a high term frequency-inverse document frequency (TF-IDF) score are then adopted as user related words. Next we calculate the similarity between the distrubuted representations of selected user-related words and nouns in the existing example phrases using word2vec embedding. We then generate phrases adapted to the user by substituting user-related words for highly similar words in the original example phrases. Word2vec also has a special property which allows the arithmetic operations plus and minus to be applied to distributed word representations. By applying these operations to words used in the original phrases we are able to determine which user-related words can be used to replace the original words. The user-related words are then substituted to create customized example phrases. We evaluated the naturalness of the generated phrases and found that the system could generate natural phrases.;2020
We introduce a new semantics for a family of logics of explicit and implicit belief based on the concept of multi-agent belief base. Differently from standard semantics for epistemic logic in which the notions of possible world and doxastic/epistemic alternative are primitive in our semantics they are non-primitive but are computed from the concept of belief base. We provide complete axiomatizations and prove decidability for our logics via finite model arguments. Furthermore we provide polynomial embeddings of our logics into Fagin & Halpern's logic of general awareness and establish complexity results via the embeddings. We also present variants of the logics incorporating different forms of epistemic introspection for explicit and/or implicit belief and provide complexity results for some of these variants. Finally we present a number of dynamic extensions of the static framework by informative actions of both public and private type including public announcement belief base expansion and forgetting. We illustrate the application potential of the logical framework with the aid of a concrete example taken from the domain of conversational agents. (C) 2020 Elsevier B.V. All rights reserved.;2020
We propose an end-to-end dialogue model based on a hierarchical encoder-decoder which employed a discrete latent variable to learn underlying dialogue intentions. The system is able to model the structure of utterances dominated by statistics of the language and the dependencies among utterances in dialogues without manual dialogue state design. We argue that the latent discrete variable interprets the intentions that guide machine responses generation. We also propose a model which can be refined autonomously with reinforcement learning due to that intention selection at each dialogue turn can be formulated as a sequential decision-making process. Our experiments show that exact MLE optimized model is much more robust than neural variational inference on dialogue success rate with limited BLEU sacrifice.;2020
We study the problem of policy adaptation for reinforcement-learning-based dialog management. Policy adaptation is a commonly used technique to alleviate the problem of data sparsity when training a goal-oriented dialog system for a new task (the target task) by using knowledge when learning policies in an existing task. The methods used by current works in dialog policy adaptation need much time and effort for adapting because they use reinforcement learning algorithms to train a new policy for the target task from scratch. In this paper we show that a dialog policy can be learned without training by reinforcement learning in the target task. In contrast to existing works our proposed method learns the relation in the form of probability distribution between the action sets of the source and the target tasks. Thus we can immediately derive a policy for the target task which significantly reduces the adaptation time. Our experiments show that the proposed method learns a new policy for the target task much more quickly. In addition the learned policy achieves higher performance than policies created by fine-tuning when the amount of available data on the target task is limited.;2020
When attempting to solve a problem humans call upon cognitive resources. These resources are limited and the degree of their utilisation is described as cognitive load. While the number of parameters to be taken into account and to be processed by modern-day knowledge workers increases their cognitive resources do not. Research shows that too high a load can increase stress and failure rates and decrease the work satisfaction and performance of employees. It is thus in the interest of organisations to reduce the cognitive load of their employees and keep it at a moderate level. One way to achieve this may be the application of virtual assistants (VAs) software programs that can be addressed via voice or text commands and respond to the users' input. This study uses a laboratory experiment with N = 91 participants comparing two groups in their ability to solve a task. One group was able to make use of a VA while the other could not. Besides task performance the cognitive load of the participants was measured. Results show that (a) cognitive load is negatively related to task performance (b) the group using the VA performed better at the task and (c) the group using the VA had a lower cognitive load. These findings show that VAs are a viable way to support employees and can increase their performance. It adds to the growing field of IS research on VAs by expanding the field for the concept of cognitive load.;2020
While there have been significant advances in detecting emotions in text in the field of utterance-level emotion recognition (ULER) there are still many problems to be solved. In this paper we address some challenges in ULER in dialog systems. (1) The same utterance can deliver different emotions when it is in different contexts. (2) Long-range contextual information is hard to effectively capture. (3) Unlike the traditional text classification problem for most datasets of this task they contain inadequate conversations or speech. (4) To better model the emotional interaction between speakers speaker information is necessary. To address the problems of (1) and (2) we propose a hierarchical transformer framework (apart from the description of other studies the transformer in this paper usually refers to the encoder part of the transformer) with a lower-level transformer to model the word-level input and an upper-level transformer to capture the context of utterance-level embeddings. For problem (3) we use bidirectional encoder representations from transformers (BERT) a pretrained language model as the lower-level transformer which is equivalent to introducing external data into the model and solves the problem of data shortage to some extent. For problem (4) we add speaker embeddings to the model for the first time which enables our model to capture the interaction between speakers. Experiments on three dialog emotion datasets Friends EmotionPush and EmoryNLP demonstrate that our proposed hierarchical transformer network models obtain competitive results compared with the state-of-the-art methods in terms of the macro-averaged F1-score (macro-F1).;2020
Willingness to communicate (WTC) is considered to be an important factor contributing to successful foreign language learning. Many studies aim at finding effective tools for enhancing WTC. With the support of AI and Automatic Speech Recognition technology intelligent personal assistants (IPAs) seem to have potentials in improving foreign language learners' WTC. However few empirical studies focus on the possible impact of IPAs on learners' WTC. This study was conducted to investigate the potentials of an IPA Google Assistant for developing adolescent EFL learners' WTC and their perceptions of IPAs for EFL learning. This study recruited 112 eighth-grade EFL learners who engaged in Google-Assistant-language-learning activities for two weeks. Two WTC questionnaires were administered at the beginning and end of the intervention. The results demonstrated that Google Assistant significantly promoted EFL learners' WTC enhanced communicative confidence and reduced speaking anxiety. Analyses of interviews revealed that participants enjoyed playing games with Google Assistant and talking to chatbots which helped them feel less anxious and motivated to use English for real and meaningful communication. The findings indicated that IPA-based interaction provided a less threatening environment in which learners displayed higher levels of engagement motivation confidence and in turn their WTC in the target language.;2020
Wind power generation is the clean energy source by which the pollution in the environment can be reduced to an extent and also it can be installed in and around the cities for electrical supply. The wind energy generated at the level of distributed generation also reduces the impact on the transmission system in terms of loss in the line and improves the efficiency of the power system. The increase in the level of penetration of wind power generation into an island power system network causing severe threat in the system in terms of protection and security. The decrease in system inertia by means of increasing in Renewable Energy Sources (RES) causes an impact on the stability of the system and further may lead to a blackout of the system. The protection and control of this system are becoming more complicated due to the penetration of RES into the system. So in order to solve these issues an intelligent control technique is implemented between the robust energy storage system and wind energy system. The Load Frequency Control (LFC) is required to emulate the virtual inertia into the island power system to stabilize the frequency variations and power variations. Furthermore a digital frequency relay is implemented to protect the system from large power fluctuations for longer duration and a security system is implemented for protecting the whole island system from cyber-attacks. To verify the effectiveness of controller as well as protection system robustness it is tested for different load disturbances and by increasing the penetration level of wind power the digital relay has been tested for large frequency variation in the system by using MATLAB/Simulink.;2020
With increasing research interests in dialogue modeling there is an emerging branch that formulates this task as next sentence selection where given the partial dialogue context the goal is to determine the most probable next sentence. To model natural language information recurrent models have been applied to sequence modeling and shown promising results in various NLP tasks (Sutskever et al. 2014). Recently the Transformer (Vaswani et al. 2017) has advanced modeling semantics for natural language sentences via attention achieving improvement for sequence modeling. However the Transformer focuses on modeling the intra-sentence attention but ignores inter-sentence information. In terms of dialogue modeling the cross-sentence information is salient to understand dialogue content so that the response selection can be better determined. Therefore this paper proposes a novel attention mechanism based on multi-head attention called highway attention in order to allow the model to pass information through multiple sentences and then builds a recurrent model based on the Transformer and the proposed highway attention. We call this model Highway Recurrent Transformer. This model focuses on not only intra-sentence dependency but also inter-sentence dependency in the structure of dialogues. Experiments on the response selection task of the seventh Dialog System Technology Challenge (DSTC7) demonstrate that the proposed Highway Recurrent Transformer is capable of modeling both utterance-level and dialogue-level information for achieving better performance than the original Transformer in the single positive response scenario. (c) 2020 Elsevier Ltd. All rights reserved.;2020
With the advent of digital approaches to mental health modern artificial intelligence (AI) and machine learning in particular is being used in the development of prediction detection and treatment solutions for mental health care. In terms of treatment AI is being incorporated into digital interventions particularly web and smartphone apps to enhance user experience and optimise personalised mental health care. In terms of prediction and detection modern streams of abundant data mean that data-driven AI methods can be employed to develop prediction/detection models for mental health conditions. In particular an individual's 'digital exhaust' the data gathered from their numerous personal digital device and social media interactions can be mined for behavioural or mental health insights. Language long considered a window into the human mind can now be quantitatively harnessed as data with powerful computer-based natural language processing to also provide a method of inferring mental health. Furthermore natural language processing can also be used to develop conversational agents used for therapeutic intervention.;2020
With the advent of the 5G and Artificial Intelligence of Things (AIoT) era related technologies such as the Internet of Things big data analysis cloud applications and artificial intelligence have brought broad prospects to many application fields such as smart homes autonomous vehicles smart cities healthcare and smart campus. At present most university campus app is presented in the form of static web pages or app menus. This study mainly developed a Deep Neural Network (DNN) based emotionally aware campus virtual assistant. The main contributions of this research are: (1) This study introduces the Chinese Word Embedding to the robot dialogue system effectively improving dialogue tolerance and semantic interpretation. (2) The traditional method of emotion identification must first tokenize the Chinese sentence analyze the clauses and part of speech and capture the emotional keywords before being interpreted by the expert system. Different from the traditional method this study classifies the input directly through the convolutional neural network after the input sentence is converted into a spectrogram by Fourier Transform. (3) This study is presented in App mode which is easier to use and economical. (4) This system provides a simple voice response interface without the need for users to find information in complex web pages or app menus.;2020
With the development of deep learning the method of large-scale dialogue generation based on deep learning has received extensive attention. The current research has aimed to solve the problem of the quality of generated dialogue content but has failed to fully consider the emotional factors of generated dialogue content. In order to solve the problem of emotional response in the open domain dialogue system we proposed a dynamic emotional session generation model (DESG). On the basis of the Seq2Seq (sequence-to-sequence) framework the model abbreviation incorporates a dictionary-based attention mechanism that encourages the substitution of words in response with synonyms in emotion dictionaries. Meanwhile in order to improve the model internal emotion regulator and emotion classifier mechanisms are introduced in order to build a large-scale emotion-session generation model. Experimental results show that our DESG model can not only produce an appropriate output sequence in terms of content (related grammar) for a given post and emotion category but can also express the expected emotional response explicitly or implicitly.;2020
With the development of technology the importance of the research on speech emotion recognition and semantic analysis has increased. The research is primarily applied in companion robot technology products and medical purpose. In this research a communication system with speech emotion recognition is proposed. The system pre-process speech with sound data enhancing method in speech emotion recognition and transform the sound into spectrogram by MFCC (Mel Frequency Cepstral Coefficient). Then GoogLeNet of CNN (Convolutional Neural Network) is applied to recognize the five emotions which are peace happy sad angry and fear and the top accuracy of recognition is 79.81%. When applying semantic analysis the training texts are divided into two categories positive and negative and the chatting conversations are conducted in the framework Seq2Seq of RNN (Recurrent Neural Network). The systematic framework of this research has two parts the client and the server. The former one is developed on Android system to be used in Application and the latter one is established by Ubuntu Linux system and combined with the web server. With the bi-terminal framework system the users can record voice in APP one his/her cellphone and upload the voice file to the server. Then the voice undergoes speech emotion recognition by CNN and semantic analysis by RNN to function as a chatting machine that can respond positively or negatively based on the detected emotion and show the results on APP of the user's cell phone. The main contributions of this research are: 1) This study introduces the Chinese word vector to the robot dialogue system effectively improving dialogue tolerance and semantic interpretation 2) The traditional method of emotion identification must first tokenize the Chinese words analyze the clauses and part of speech and capture the emotional keywords before being interpreted by the expert system. Different from the traditional method this study classifies the input directly through the convolutional neural network after the input sentence is converted into a spectrogram by MFCC and 3) in addition to implementing the companion robot the user's emotional index can be collected for analysis by the back-end care organization. In addition compared with other commercial humanoid companion robots this study is presented in an App which is easier to use and economical.;2020
With the exponential growth in the mobile device market over the last decade chatbots are becoming an increasingly popular option to interact with users and their popularity and adoption are rapidly spreading. These mobile devices change the way we communicate and allow ever-present learning in various environments. This study examined educational chatbots for Facebook Messenger to support learning. The independent web directory was screened to assess chatbots for this study resulting in the identification of 89 unique chatbots. Each chatbot was classified by language subject matter and developer's platform. Finally we evaluated 47 educational chatbots using the Facebook Messenger platform based on the analytic hierarchy process against the quality attributes of teaching humanity affect and accessibility. We found that educational chatbots on the Facebook Messenger platform vary from the basic level of sending personalized messages to recommending learning content. Results show that chatbots which are part of the instant messaging application are still in its early stages to become artificial intelligence teaching assistants. The findings provide tips for teachers to integrate chatbots into classroom practice and advice what types of chatbots they can try out.;2020
With the increasing pervasiveness of smart phones and smart devices dialogue systems are gaining ever growing attention from both academic and industry. These systems can be broadly classified into two categories one that is aimed at helping user to gain new knowledge and one that can chat with users without completing any specific tasks. Although dialogue systems are improving substantially the user experience of such systems are still unsatisfactory as there are no specific rules covering all possible situations of real human-machine dialogue resulting in breakdowns. There are two technical issues affecting the detection of dialogue breakdown in an open domain conversation: human resources to prepare and annotate a large chunk of conversation data and dialogue histories containing words that don't appear directly in training data. To tackle these issues we propose a novel encoding method for temporal utterances with memory attention based on end-to-end dialogue breakdown detection. Specifically long short-term memory (LSTM) is employed to encode each word of all previous user and system utterances. Encoded vectors from LSTM (user and system utterances) along with system and user utterances from sentence embedding are then stored in memory wherein an attention mechanism is applied to select the most relevant piece of words from system and user utterances for breakdown detection. An evaluation of the proposed approach on a breakdown detection task (DBDC3) showed that the model for single-labeled breakdown detection outperforms other state-of-the-art methods in a classification task. In conclusion a more effective knowledge gain and management can be achieved by integration of our proposed breakdown detection into dialogue systems.;2020
With the rapid progress of the semantic web a huge amount of structured data has become available on the web in the form of knowledge bases (KBs). Making these data accessible and useful for end-users is one of the main objectives of chatbots over linked data. Building a chatbot over linked data raises different challenges including user queries understanding multiple knowledge base support and multilingual aspect. To address these challenges we first design and develop an architecture to provide an interactive user interface. Secondly we propose a machine learning approach based on intent classification and natural language understanding to understand user intents and generate SPARQL queries. We especially process a new social network dataset (i.e. myPersonality) and add it to the existing knowledge bases to extend the chatbot capabilities by understanding analytical queries. The system can be extended with a new domain on-demand flexible multiple knowledge base multilingual and allows intuitive creation and execution of different tasks for an extensive range of topics. Furthermore evaluation and application cases in the chatbot are provided to show how it facilitates interactive semantic data towards different real application scenarios and showcase the proposed approach for a knowledge graph and data-driven chatbot.;2020
With the success of new speech-based human-computer interfaces there is a great need for effective and friendly dialogue agents that can communicate with people naturally and continuously. However the lack of personality and consistency is one of critical problems in neural dialogue systems. In this paper we aim to generate consistent response with fixed profile and background information for building a realistic dialogue system. Based on the encoder-decoder model we propose a retrieval mechanism to deliver natural and fluent response with proper information from a profile database. Moreover in order to improve the efficiency of training the dataset related to profile information we adopt a method of pre-training and adjustment for general dataset and profile dataset. Our model is trained by social dialogue data from Weibo. According to both automatic and human evaluation metrics the proposed model significantly outperforms standard encoder-decoder model and other improved models on providing the correct profile and high-quality responses.;2020
Within the area of intelligent User Interfaces we propose what we call Sentient Embodied Conversational Agents (SECAs): virtual characters able to engage users in complex conversations and to incorporate sentient capabilities similar to the ones humans have. This paper introduces SECAs together with their architecture and a publicly available software library that facilitates their inclusion in applications -such as educational and elder-care- requiring proactive and sensitive agent behaviours. In fact we illustrate our proposal with a virtual tutor embedded in an educational application for children. The evaluation was performed in two stages: firstly we tested a version with basic textual processing capabilities and secondly we evaluated a SECA with Machine-Learning-enhanced user understanding capabilities. The results show a significant improvement in users' perception of the agent's understanding capability. Indeed the Response Error Rate decreased from 22.31% to 11.46% using ML techniques. Moreover 99.33% of the participants consider the global experience of talking with the virtual tutor with sentient capabilities to be satisfactory. (C) 2019 Elsevier B.V. All rights reserved.;2020
(1) Background. Early nutrition and lifestyle before and during pregnancy breastfeeding infancy and early childhood can affect the risk of developing common non-communicable diseases during adulthood such as obesity and metabolic syndrome. To support positive long-term outcomes it is essential to debunk fake news and provide evidence-based nutritional recommendations. Nutripedia-Informati per Crescere is a new tool delivering information and education on appropriate nutrition of mothers and babies during pregnancy and the first years of life. (2) Methods. Nutripedia provides the readers with evidence-based scientific contents in an easy-to-access fashion through a website a social media page and a personalized advice app called Nutripedia Chatbot. (3) Results. Forty articles were published on Nutripedia website with more than 220000 total views. Social channel activation via bloggers reached over 9 million parents. 14698 users downloaded Nutripedia chatbot through which a total of 1930 questions were directed to experts while over 24000 responses were provided by the app. (4) Conclusions. The use of different communication tools delivering evidence-based nutritional information such as Nutripedia is increasing and could offer supportive strategies to provide scientific information to large audiences and contribute fighting fake news. Future research could investigate the effectiveness of this important health campaign.;2021
(1) Background: Follow-up management of workers' general health examination (WGHE) is important but it is not currently well done. Chatbot a type of digital healthcare tool is used in various medical fields but has never been developed for follow-up management of WGHE in Korea. (2) Methods: The database containing results and explanations related to WGHE was constructed. Then the channel which connects users with the database was created. A user survey regarding effectiveness was administered to 23 healthcare providers. Additionally interviews on applicability for occupational health services were conducted with six nurses in the agency of occupational health management. (3) Results: Chatbot was implemented on a small scale on the Amazon cloud service (AWS) EC2 using KaKaoTalk and Web Chat as user channels. Regarding the effectiveness 21 (91.30%) rated the need for chatbots as very high however 11 (47.83%) rated the usability as not high. Of the 23 participants 14 (60.87%) expressed overall satisfaction. Nurses appreciated the chatbot program as a method for resolving accessibility and as an aid for explaining examination results and follow-up management. (4) Conclusions: The effectiveness of WGHE and the applicability in the occupational health service of the chatbot program for follow-up management can be confirmed.;2021
6G-Enabled Internet of Things (IoT) is about to open a new era of Internet of Everything (IoE). It creates favorable conditions for new application services. The human-machine dialogue system one of the most important forms of human-machine interaction is expected to replace mobile applications in the future. This article proposes a dialogue generation scheme named background knowledge-aware dialogue generation model with pretrained encoders (BKADGPE). Dialogue generation which takes the context as input and response as output is a sequence-to-sequence (Seq2Seq) task. Instead of only generating the response based on the previous sequence of utterances background knowledge-aware dialogue generation is also relying on background knowledge documents. This is because people often communicate based on their background knowledge. This article divides it into two tasks: 1) a knowledge selection task and 2) a response generation task. One of the latest language pretraining models a lite bidirectional encoder representations from transformers (ALBERT) is applied as the encoder. In the knowledge selection task ALBERT adds the linear layer and softmax layer to predict the content-related knowledge span. In the response generation task the ALBERT after fine-tuning through the knowledge selection task adds the left-context-only transformer with a copy mechanism to incorporate background knowledge span into the generated response. Empirical studies on the HOLL-E dataset show that the result of BKADGPE is better than the related works.;2021
A challenge of large-scale oral communication assessments is to feasibly assess a broad construct that includes interactional competence. One possible approach in addressing this challenge is to use a spoken dialog system (SDS) with the computer acting as a peer to elicit a ratable speech sample. With this aim an SDS was built and four trained human raters assessed the discourse elicited from 40 test takers that completed a paired oral task with both a human and a computer partner. The test takers were evaluated based on the analytic operational oral communication rating scales which included interactional competence fluency pronunciation and grammar/vocabulary. Repeated-measures ANOVA indicated that fluency pronunciation and grammar and vocabulary were scored similarly across the two conditions while interactional competence was scored substantially higher in the human partner condition. A g-study indicated that the computer partner was more reliable in assessing interactional competence and rater questionnaire and interview data suggested the computer provided a more standardized assessment. Conversely raters generally favored the human partner in part because of its perceived authenticity and naturalness.;2021
A chatbot is a useful tool for communicating with users to extract necessary information. An intelligent chatbot requires an effective knowledge base as materials to adequately organize the knowledge domain and process many kinds of inputted queries as natural text. Ontology technology is effective for use in learning technology systems. In this paper a model that uses ontology technology for relational knowledge to integrate a structure of scripts is presented. This integrated model called the Rela-Scripts model is used to organize the knowledge material of a chatbot to search for knowledge in education. Some problems in searching for knowledge by this chatbot are proposed and solved on the basis of the Rela-Scripts model. The proposed method is applied to build an intelligent chatbot for answering questions on contents of the Introduction to Programming course in a university. This chatbot acts as a tutor by communicating with students in Vietnamese and gives explanations that meet the requirements of students. Its instructions are useful for their self-learning to enhance their programming skills.;2021
A knowledge graph is a structured graph in which data obtained from multiple sources are standardized to acquire and integrate human knowledge. Research is being actively conducted to cover a wide variety of knowledge as it can be applied to applications that help humans. However existing researches are constructing knowledge graphs without the time information that knowledge implies. Knowledge stored without time information becomes outdated over time and in the future the possibility of knowledge being false or meaningful changes is excluded. As a result they can't reflect information that changes dynamically and they can't accept information that has newly emerged. To solve this problem this paper proposes Time-Aware PolarisX an automatically extended knowledge graph including time information. Time Aware PolarisX constructed a BERT model with a relation extractor and an ensemble NER model including a time tag with an entity extractor to extract knowledge consisting of subject relation and object from unstructured text. Through two application experiments it shows that the proposed system overcomes the limitations of existing systems that do not consider time information when applied to an application such as a chatbot. Also we verify that the accuracy of the extraction model is improved through a comparative experiment with the existing model.;2021
A large percentage of adults throughout the world have low reading skills. Computer technologies can potentially help these adults improve their literacy in addition to instructors at literacy centers. AutoTutor was designed to teach comprehension strategies by implementing conversational 'trialogues' in which two computer agents (tutor and peer) hold spoken interactions with the adult about words sentences and text in digital lessons. The agents model comprehension strategies ask questions and give feedback on adult answers. AutoTutor records in log files the adults' performance namely the time and accuracy of answering questions in the conversation. We assessed the value of AutoTutor in a study with 52 adult literacy students in the United States and Canada who interacted with AutoTutor as part of a 4-month intervention with human instructors. Performance in AutoTutor was tracked at four theoretical discourse levels (words explicit textbase conceptual situation model rhetorical structure) and also engagement with an objective psychometric measure of comprehension skill both before and after the intervention. The results showed that AutoTutor provides nuanced performance and engagement measures that predicted comprehension improvements and can be used to guide formative assessment for instructors.;2021
A LINE Bot System to diagnose rice diseases from actual paddy field images was developed and presented in this paper. It was easy-to-use and automatic system designed to help rice farmers improve the rice yield and quality. The targeted images were taken from the actual paddy environment without special sample preparation. We used a deep learning neural networks technique to detect rice diseases from the images. We developed an object detection model training and refinement process to improve the performance of our previous research on rice leave diseases detection. The process was based on analyzing the model's predictive results and could be repeatedly used to improve the quality of the database in the next training of the model. The deployment model for our LINE Bot system was created from the selected best performance technique in our previous paper YOLOv3 trained by refined training data set. The performance of the deployment model was measured on 5 target classes and found that the Average True Positive Point improved from 91.1% in the previous paper to 95.6% in this study. Therefore we used this deployment model for Rice Disease LINE Bot system. Our system worked automatically real-time to suggest primary diagnosis results to the users in the LINE group which included rice farmers and rice disease specialists. They could communicate freely via chat. In the real LINE Bot deployment the model's performance was measured by our own defined measurement Average True Positive Point and was found to be an average of 78.86%. The system was fast and took only 2-3 s for detection process in our system server.;2021
A personal intelligent agent (PIA) is a system that acts intelligently to assist a human using natural language. Examples include Siri and Alexa. These agents are powerful computer programs that operate autonomously and proactively learn and adapt to change react to the environment complete tasks within a favorable timeframe and communicate with the user using natural language to process commands and compose replies. PIAs are different from other systems previously explored in Information Systems (IS) due to their personalized intelligent and human-like behavior. Drawing on research in IS and Artificial Intelligence we build and test a model of user adoption of PIAs leveraging their uique characteristics. Analysis of data collected from an interactive lab-based study for new PIA users confirms that both perceived intelligence and anthropomorphism are significant antecedents of PIA adoption. Our findings contribute to the understanding of a quickly-changing and fast-growing set of technologies that extend users' capabilities and their sense of self .;2021
A psychiatric diagnosis involves the physician's ability to create an empathic interaction with the patient in order to accurately extract symptomatology (i.e. clinical manifestations). Virtual patients (VPs) can be used to train these skills but need to propose a structured and multimodal interaction situation in order to simulate a realistic psychiatric interview. In this study we present a simulated psychiatric interview with a virtual patient suffering from major depressive disorders. We suggested some design guidelines based on psychiatry theories and medicine education standards. We evaluated our VP with user testing with 35 4th year medical students and probed their opinion during debriefing interviews. All students showed good abilities to communicate empathetically with the VP and managed to extract symptomatology from VP's simulation. Students provided positive feedbacks regarding pedagogic usefulness realism and enjoyment in the interaction which suggests that our design guidelines are consistent and that such technologies are acceptable to medical students. To conclude this study is the first to simulate a realistic psychiatric interview and to measure both skills needed by future psychiatrists: symptomatology extraction and empathic communication. Results provide evidence for the use of VPs to complement existing tools and to train and evaluate healthcare professionals in the future.;2021
A starting point of many digital health interventions informed by the Stages of Change Model of behavior change is assessing a person's readiness to change. In this paper we use the concept of readiness to develop and validate a prediction model of health-seeking behavior in the context of family planning. We conducted a secondary analysis of routinely collected anonymized health data submitted by 4088 female users of a free health chatbot in Kenya. We developed a prediction model of (future) self-reported action by randomly splitting the data into training and test data sets (80/20 stratified by the outcome). We further split the training data into 10 folds for cross-validating the hyperparameter tuning step in model selection. We fit nine different classification models and selected the model that maximized the area under the receiver operator curve. We then fit the selected model to the full training dataset and evaluated the performance of this model on the holdout test data. The model predicted who will visit a family planning provider in the future with high precision (0.93) and moderate recall (0.75). Using the Stages of Change framework we concluded that 29% of women were in the Preparation stage 21% were in the Contemplation stage and 50% were in the Pre-Contemplation stage. We demonstrated that it is possible to accurately predict future healthcare-seeking behavior based on information learned during the initial encounter. Models like this may help intervention developers to tailor strategies and content in real-time.;2021
Advances in artificial intelligence algorithms and expansion of straightforward cloud-based platforms have enabled the adoption of conversational assistants by both medium and large companies to facilitate interaction between clients and employees. The interactions are possible through the use of ubiquitous devices (e.g. Amazon Echo Apple HomePod Google Nest) virtual assistants (e.g. Apple Siri Google Assistant Samsung Bixby or Microsoft Cortana) chat windows on the corporate website or social network applications (e.g. Facebook Messenger Telegram Slack WeChat). Creating a useful personalized conversational agent that is also robust and pop-ular is nonetheless challenging work. It requires picking the right algorithm framework and/or communication channel but perhaps more importantly con-sideration of the specific task user needs environment available training data budget and a thoughtful design. In this paper we will consider the elements necessary to create a conversational agent for different types of users environments and tasks. The elements will account for the limited amount of data available for specific tasks within a com-pany and for non-English languages. We are confident that we can provide a useful resource for the new practitioner developing an agent. We can point out novice problems/traps to avoid create consciousness that the development of the technology is achievable despite comprehensive and significant challenges and raise awareness about different ethical issues that may be associated with this technology. We have compiled our experience with deploying conversational sys-tems for daily use in multicultural multilingual and intergenerational settings. Additionally we will give insight on how to scale the proposed solutions.;2021
Advances in artificial intelligence provide new tools of digital assistance that retailers can use to support consumers while shopping. The aim of this research is to examine how consumers react as a function of assistants' appearance (human- vs. not human-like) and activation (automatic vs. human-initiated). We advance a model of sequential mediation whose empirical validation on 400 participants in two studies shows that nonanthropomorphic digital assistants lead to higher psychological reactance. In turn reactance affects perceived choice difficulty which positively reflects on choice certainty perceived performance and-ultimately-satisfaction. Thus although reactance might appear as a negative outcome it eventually leads to higher satisfaction. Furthermore initiation (system vs. user initiation) does not activate the chain of effects but significantly interacts with anthropomorphism so that individuals exhibit lower reactance when confronted with human-like digital assistants activated by the consumer. Overall reactance is highest for non-human like digital assistants that are computer-initiated.;2021
AI combined with NLP techniques has promoted the use of Virtual Assistants and have made people rely on them for many diverse uses. Conversational Agents are the most promising technique that assists computer users through their operation. An important challenge in developing Conversational Agents globally is transferring the groundbreaking expertise obtained in English to other languages. AI is making it possible to transfer this learning. There is a dire need to develop systems that understand secular languages. One such difficult language is Hindi which is the fourth most spoken language in the world. Semantic similarity is an important part of Natural Language Processing which involves applications such as ontology learning and information extraction for developing conversational agents. Most of the research is concentrated on English and other European languages. This paper presents a Corpus-based word semantic similarity measure for Hindi. An experiment involving the translation of the English benchmark dataset to Hindi is performed investigating the incorporation of the corpus with human and machine similarity ratings. A significant correlation to the human intuition and the algorithm ratings has been calculated for analyzing the accuracy of the proposed similarity measures. The method can be adapted in various applications of word semantic similarity or module for any other language.;2021
AI-chatbots as frontline agents promise innovative opportunities for shaping service offerings that benefit customers and retailers. Examining current practice through the lens of agency as defined by Social Cognitive Theory we present a 3-level classification of AI-chatbot design (anthropomorphic role appearance and interactivity) and examine how the combination of these three aspects of chatbot design impacts on the complementarities of agency. Recognizing current implementation challenges we advance that the complementarities of agency at each level are the lynchpin mechanism that translates AI-chatbot design into service relevant outcomes. We develop a research agenda focused on the emotion interface resolution of the proxy agency dilemma and development of collective agency to support the implementation of AI-chatbots as frontline service agents.;2021
AI-enabled virtual and robot therapy is increasingly being integrated into psychotherapeutic practice supporting a host of emotional cognitive and social processes in the therapeutic encounter. Given the speed of research and development trajectories of AI-enabled applications in psychotherapy and the practice of mental healthcare it is likely that therapeutic chatbots avatars and socially assistive devices will soon translate into clinical applications much more broadly. While AI applications offer many potential opportunities for psychotherapy they also raise important ethical social and clinical questions that have not yet been adequately considered for clinical practice. In this article we begin to address one of these considerations: the role of transference in the psychotherapeutic relationship. Drawing on Karen Barad's conceptual approach to theorizing human-non-human relations we show that the concept of transference is necessarily reconfigured within AI-human psychotherapeutic encounters. This has implications for understanding how AI-driven technologies introduce changes in the field of traditional psychotherapy and other forms of mental healthcare and how this may change clinical psychotherapeutic practice and AI development alike. As more AI-enabled apps and platforms for psychotherapy are developed it becomes necessary to re-think AI-human interaction as more nuanced and richer than a simple exchange of information between human and nonhuman actors alone.;2021
Alignment of communicative behaviour is an important feature of Human-Human interaction that directly affects the collaboration and the social connection of conversational partners. With the aim of improving the communicative abilities of a virtual agent and in particular its strategies related to (lexical) verbal alignment this article focuses on the alignment of linguistic productions of dialogue participants in task-oriented dialogues. We propose a new framework to quantify both the lexical alignment and the self-repetition behaviours of dialogue participants from dyadic dialogue transcripts. The framework involves easily computable measures based on repetition of lexical patterns automatically extracted via a sequential pattern mining approach. These measures allow the characterisation of the nature of these processes by addressing various informative aspects such as their variety complexity and strength. This framework is implemented in the freely available and open-source software dialign. Using these measures we present a contrastive study between Human-Human and Human-Agent dialogues on various corpora that reveals major differences in the lexical alignment and self-repetition behaviours. Lastly we address the challenge of integrating lexical alignment capabilities in artificial agents. To this end we describe guidelines and we discuss the integration of the proposed framework in a real-time dialogue system.;2021
Although emotional conversation generation has attracted widespread attention in recent years research works on the emotional interactional mechanism are still scarce which makes it difficult for existing emotional dialogue system to automatically determine a suitable emotion type for conversation generation. Such a response emotion planning task is often difficult due to the gap problem: we need to predict the emotional probability distribution of the upcoming responses which have not yet been generated. In this article we propose a novel method namely interactional emotion learning (IEL) which adopts an intuitive way to eliminate the gap problem: we design a variational learning network called potential response learning to learn the latent distribution of responses for given conversation in a semantic space. Then we predict an appropriate emotion for response generation based on both the dialogue context and the learned latent distribution. Extensive experiments have been performed on three off-the-shelf conversation datasets and the experimental results show that the proposed variational learning network significantly boosts the prediction ability of our approach and our IEL method outperforms the state-of-the-art dialogue classification methods in the emotion planning task.;2021
Although quite natural for human beings to communicate based on their own personality in daily life it is rather challenging for neural dialog systems to do the same. This is because the general dialog systems are difficult to generate diverse responses while at the same time maintaining consistent persona information. Existing methods basically focus on merely one of them ignoring either of them will reduce the quality of dialog. In this work we propose a two-stage generation framework to promote the persona-consistency and diversity of responses. In the first stage we propose a persona-guided conditional variational autoencoder (persona-guided CVAE) to generate diverse responses and the main difference when compared with general CVAE-based model is that we use additional dialog attribute to assist the latent variables to encode the effective information in the response and further use it as a guiding vector for response generation. In the second stage we employ persona-consistency checking module and the response rewriting module to mask the inconsistent word in the generated response prototype and rewrite it to more consistent. Automatic evaluation results demonstrate that the proposed model is able to generate diverse and persona-consistent responses.;2021
An End-Of-Turn Detection Module (EOTD-M) is an essential component of automatic Spoken Dialogue Systems. The capability of correctly detecting whether a user?s utterance has ended or not improves the accuracy in interpreting the meaning of the message and decreases the latency in the answer. Usually in dialogue systems an EOTD-M is coupled with an Automatic Speech Recognition Module (ASR-M) to transmit complete utterances to the Natural Language Understanding unit. Mistakes in the ASR-M transcription can have a strong effect on the performance of the EOTD-M. The actual extent of this effect depends on the particular combination of ASR M transcription errors and the sentence featurization techniques implemented as part of the EOTD-M. In this paper we investigate this important relationship for an EOTD-M based on semantic information and particular characteristics of the speakers (speech profiles). We introduce an Automatic Speech Recognition Simulator (ASR-SIM) that models different types of semantic mistakes in the ASR-M transcription as well as different speech profiles. We use the simulator to evaluate the sensitivity to ASR-M mistakes of a Long Short-Term Memory network classifier trained in EOTD with different featurization techniques. Our experiments reveal the different ways in which the performance of the model is influenced by the ASR-M errors. We corroborate that not only is the ASR-SIM useful to estimate the performance of an EOTD-M in customized noisy scenarios but it can also be used to generate training datasets with the expected error rates of real working conditions which leads to better performance.;2021
An essential component of any dialogue system is understanding the language which is known as spoken language understanding (SLU). Dialogue act classification (DAC) intent detection (ID) and slot filling (SF) are significant aspects of every dialogue system. In this paper we propose a deep learning-based multi-task model that can perform DAC ID and SF tasks together. We use a deep bi-directional recurrent neural network (RNN) with long short-term memory (LSTM) and gated recurrent unit (GRU) as the frameworks in our multi-task model. We use attention on the LSTM/GRU output for DAC and ID. The attention outputs are fed to individual task-specific dense layers for DAC and ID. The output of LSTM/GRU is fed to softmax layer for slot filling as well. Experiments on three datasets i.e. ATIS TRAINS and FRAMES show that our proposed multi-task model performs better than the individual models as well as all the pipeline models. The experimental results prove that our attention-based multi-task model outperforms the state-of-the-art approaches for the SLU tasks. For DAC in relation to the individual model we achieve an improvement of more than 2% for all the datasets. Similarly for ID we get an improvement of 1% on the ATIS dataset while for TRAINS and FRAMES dataset there is a significant improvement of more than 3% compared to individual models. We also get a 0.8% enhancement for ATIS and a 4% enhancement for TRAINS and FRAMES dataset for SF with respect to individual models. Results obtained clearly show that our approach is better than existing methods. The validation of the obtained results is also demonstrated using statistical significance t tests.;2021
An important goal in open-domain dialogue research is to make chatbot generate emotional responses given a context. To achieve this some researchers have attempted to introduce affective information into neural dialogue models. However these neural dialogue models containing affective information still suf-fer from the problem of generating safe but meaningless responses such as I don't know which makes users lose interest in chatting quickly. Fortunately the latest research has proven that conditional vari-ational auto-encoder (CVAE) can solve this problem and enhance the responses' diversity. In this paper we combine affective knowledge into the CVAE-based model to generate diverse and affective responses. First we use an affective lexicon to understand each word's emotion in the input sentences and feed the affective vector with its embedding vector together into the CVAE-based model. Next we construct semantic and affective loss functions enabling the model to simultaneously learn the response's seman-tic and affective distributions. Additionally we formulate a ranking rule to help rank the candidate responses according to their syntax semantics and affection scores thereby enhancing the emotion and relevance while retaining the response's diversity. Finally we evaluate the proposed model on the DailyDialog dataset and Reddit dataset. The experimental results show that our model can generate more emotional diverse and context-relevant responses compared to the baselines. (c) 2021 Elsevier B.V. All rights reserved.;2021
An increasing number of firms introduce service robots such as physical robots and virtual chatbots to provide services to customers. While some firms use robots that resemble human beings by looking and acting humanlike to increase customers' use intention of this technology others employ machinelike robots to avoid uncanny valley effects assuming that very humanlike robots may induce feelings of eeriness. There is no consensus in the service literature regarding whether customers' anthropomorphism of robots facilitates or constrains their use intention. The present meta-analysis synthesizes data from 11053 individuals interacting with service robots reported in 108 independent samples. The study synthesizes previous research to clarify this issue and enhance understanding of the construct. We develop a comprehensive model to investigate relationships between anthropomorphism and its antecedents and consequences. Customer traits and predispositions (e.g. computer anxiety) sociodemographics (e.g. gender) and robot design features (e.g. physical nonphysical) are identified as triggers of anthropomorphism. Robot characteristics (e.g. intelligence) and functional characteristics (e.g. usefulness) are identified as important mediators although relational characteristics (e.g. rapport) receive less support as mediators. The findings clarify contextual circumstances in which anthropomorphism impacts customer intention to use a robot. The moderator analysis indicates that the impact depends on robot type (i.e. robot gender) and service type (i.e. possession-processing service mental stimulus-processing service). Based on these findings we develop a comprehensive agenda for future research on service robots in marketing.;2021
Approaches for developing Dialogue Systems (DSs) are typically categorized into rule-based and data-driven. Data-driven DSs require a massive quantity of training data while rule-based DSs rely on a predefined set of rules and keywords that are to be detected in the user's utterances. The data-driven approaches show more promising results but owing to a lack of available training data for Arabic task-oriented DSs development of an Arabic task-oriented DS has typically been conducted using the rule-based approach. In this article we propose a hybrid rule-based and data-driven approach in a text-based flight booking DS capable of handling customer's utterances. The proposed DS was built through utilizing the Wit.ai natural language interface. The conversation flow was configured using the Wizard of Oz technique and the DS intents and entities were developed through the use of crowdsourcing training examples. The evaluation results show that the system developed was able to understand user utterances and to self-feed efficiently.;2021
Artificial agents such as embodied virtual agents chatbots voice user interface agents and robots simulate human roles for dispensing information to people. According to the computers-are social-actors paradigm people respond to these technological artifacts with the same social rules originated from human-to-human social routines despite recognizing the artificiality of the entities' intents motivations or emotions. Among the various applications of social rules in human-agent interactions this study focuses on the social cues signaling expertise or competence (i.e. expertise cues) that can evoke social affective behavioral and cognitive responses toward the artificial agents through activation of social stereotypes or heuristics. Based on a systematic review of experimental studies featuring artificial agents with expertise cues published between 2005 and July 2021 (n = 63) this study proposed a classification model categorizing expertise cues into Demographics Appearance Social prestige Specialization Communication style and Information quality (DASSCI). The DASSCI model can guide designers to logically devise and infuse relevant expertise cues into the designs of artificial agents. As per the computers-are-social actors paradigm this study also outlined the social and communication theories underpinning the implementations and effects of artificial agents' expertise cues. The implications and recommendations for future directions regarding artificial agents with expertise cues across diverse application domains are discussed in this paper.;2021
Artificial Intelligence (AI) and Extended Reality (XR) have been employed in several foreign language education applications to increase the availability of experiential learning methods akin to international immersion programs. However research in multi-modal spoken dialogue in L2 combined with immersive technologies and collaborative learning is thin limiting students' experiences to solo interactions focused mostly on vocabulary and grammar in such settings. We intend to fill this gap as we present the Cognitive Immersive Language Learning Environment (CILLE). The AI in CILLE can hear see and understand its users and can engage with them in non-dyadic multimodal conversations. The XR offers students a feeling of being somewhere else without the use of intrusive devices and supports multi-party multi-modal interactions. Together AI and XR create naturalistic conversational interactions targeted towards comprehensive foreign language acquisition. We evaluate CILLE as a Chinese-as-a-foreign-language (CFL) education tool through a seven-week mixed-methods study with university students (N = 10). Results display statistical significance and retained improvement in CFL vocabulary comprehension and conversation skills. Coupled with an analysis of student feedback and researcher observations we show how CILLE is designed and experienced by students to learn CFL.;2021
Artificial Intelligence is increasingly becoming integrated in many aspects of human life. One particular AI comes in the form of conversational agents (CAs) such as Siri Alexa and chatbots used for customer service on websites and other information systems. It is widely accepted that humans treat systems as social actors. Leveraging this bias companies sometimes attempt to masquerade a CA as a human customer service representative. In addition to the ethical and legal questions around this practice the benefits and drawbacks of a CA pretending to be human are unclear due to a lack of study. While more human-like interactions can improve outcomes when users find out that the CA is not human they may have a negative reaction that may cause reputation harm in the company. In this research we use Expectation Violation Theory to explain what happens when users have high or low expectations of a conversation. We conducted an experiment with 175 participants where some participants were told they were interacting with a CA while others were told they were interacting with a human. We further divided the groups so that some participants interacted with a CA with low conversational capability while others interacted with a CA with high conversational capability. The results show that expectations formed by the user before the interaction change how the user evaluates the CA beyond the actual performance of the CA. These findings provide guidance to developers not just of conversational agents but also for other technologies where users may be uncertain of a system?s capabilities.;2021
Artificial Intelligence is revolutionising our communication practices and the ways in which we interact with each other. This revolution does not only impact how we communicate but it affects the nature of the partners with whom we communicate. Online discussion platforms now allow humans to communicate with artificial agents in the form of socialbots. Such agents have the potential to moderate online discussions and even manipulate and alter public opinions. In this paper we propose to study this phenomenon using a constructed large-scale agent platform. At the heart of the platform lies an artificial agent that can moderate online discussions using argumentative messages. We investigate the influence of the agent on the evolution of an online debate involving human participants. The agent will dynamically react to their messages by moderating supporting or attacking their stances. We conducted two experiments to evaluate the platform while looking at the effects of the conversational agent. The first experiment is a large-scale discussion with 1076 citizens from Afghanistan discussing urban policy-making in the city of Kabul. The goal of the experiment was to increase the citizen involvement in implementing Sustainable Development Goals. The second experiment is a small-scale debate between a group of 16 students about globalisation and taxation in Myanmar. In the first experiment we found that the agent improved the responsiveness of the participants and increased the number of identified ideas and issues. In the second experiment we found that the agent polarised the debate by reinforcing the initial stances of the participant.;2021
Artificial intelligence (AI) applications have been introduced in humanitarian operations in order to help with the significant challenges the sector is facing. This article focuses on chatbots which have been proposed as an efficient method to improve communication with and accountability to affected communities. Chatbots together with other humanitarian AI applications such as biometrics satellite imaging predictive modelling and data visualisations are often understood as part of the wider phenomenon of 'AI for social good'. The article develops a decolonial critique of humanitarianism and critical algorithm studies which focuses on the power asymmetries underpinning both humanitarianism and AI. The article asks whether chatbots as exemplars of 'AI for good' reproduce inequalities in the global context. Drawing on a mixed methods study that includes interviews with seven groups of stakeholders the analysis observes that humanitarian chatbots do not fulfil claims such as 'intelligence'. Yet AI applications still have powerful consequences. Apart from the risks associated with misinformation and data safeguarding chatbots reduce communication to its barest instrumental forms which creates disconnects between affected communities and aid agencies. This disconnect is compounded by the extraction of value from data and experimentation with untested technologies. By reflecting the values of their designers and by asserting Eurocentric values in their programmed interactions chatbots reproduce the coloniality of power. The article concludes that 'AI for good' is an 'enchantment of technology' that reworks the colonial legacies of humanitarianism whilst also occluding the power dynamics at play.;2021
Artificial intelligence (AI) has been widely used in various industries. In this work we concentrate on what AI is capable of doing in manufacturing in the form of a chatbot. We designed a chatbot that helps users complete an assembly task that simulates those in manufacturing settings. In order to recreate this setting we have users assemble a Meccanoid robot through multiple stages with the help of an interactive dialogue system. Based on classifying users' intent the chatbot is able to provide answers or instructions to the user when the user encounters problems during the assembly process. Our goal is to improve our system so that it can capture users' needs by detecting their intent and therefore provide relevant and helpful information to the user. However in a multiple-step task we cannot rely on intent classification with user question utterance as the only input as user questions raised from different steps may share the same intent but require different responses. In this paper we proposed two methods to address this problem. One is that we capture not only textual features but also visual features through the YOLO-based Masker with CNN (YMC) model. Another is the usage of an Autoencoder to encode multi-modal features for user intent classification. By incorporating visual information we have significantly improved the chatbot's performance from the experiments conducted on different dataset.;2021
Artificial intelligence (AI)-powered chatbots are changing the nature of service interfaces from being human-driven to technology-dominant. As a result customers are expected to resolve issues themselves before reaching out to customer service representatives ultimately becoming a central element of service production as co-creators of value. However AI-powered interactions can also fail potentially leading to anger confusion and customer dissatisfaction. We draw on the value co-creation literature to investigate the process of co-destruction in AI-powered service interactions. We adopt an exploratory approach based on in-depth interviews with 27 customers who have interacted with AI-powered chatbots in customer service settings. We find five antecedents of failed interactions between customers and chatbots: authenticity issues cognition challenges affective issues functionality issues and integration conflicts. We observe that although customers do accept part of the responsibility for co-destruction they largely attribute the problems they experience to resource misintegration by service providers. Our findings contribute a better understanding of value co-destruction in AI-powered service settings and provide a richer conceptualization of the link between customer resource loss attributions of resource loss and subsequent customer coping strategies. Our findings also offer service managers insights into how to avoid and mitigate value co-destruction in AI service settings.;2021
Artificial intelligence increasingly forms an essential context for the distribution of power within workplaces. Using the case study of an AI-enabled chatbot initially created by IBM and subsequently developed by an alt-labour network in the United States and a traditional union in Australia this article outlines several distinctive ways in which the chatbot increased union resources and capabilities. Once reconfigured to reflect an 'organising' rather than 'servicing' ethos the chatbot became an infrastructural resource that enabled otherwise marginal workers to receive basic information in a manner that reinforced union narratives of power and worker solidarity and workplaces to be mapped more efficiently. The chatbot did not act as a labour saving tool but stimulated wide-ranging learning by bringing implicit tensions between 'servicing' and 'organising' conceptions of knowledge power and expertise to the surface. Chatbots thus offer distinctive potential affordances to unions in enhancing their resources and capabilities as 'orchestrators' of worker power.;2021
Artificial intelligence(AI) systems that interact with humans such as chatbots and language translators have many useful applications. However care must be put in addressing some concerns such as the presence of bias possible abusive language and information leakage that could hamper public trust in them. In this article we focus on gender bias in online translators as recognized and rated by a third-party assessment who does not have access to the training data and we propose a visualization approach for such rating. We then conduct a survey of how users perceive bias in translators whether they appreciate the proposed bias rating visualization and how they may use it to reason about bias-accuracy trade-offs.;2021
Artificial intelligence-driven voice technology deployed on mobile phones and smart speakers has the potential to improve patient management and organizational workflow. Voice chatbots have been already implemented in health care-leveraging innovative telehealth solutions during the COVID-19 pandemic. They allow for automatic acute care triaging and chronic disease management including remote monitoring preventive care patient intake and referral assistance. This paper focuses on the current clinical needs and applications of artificial intelligence-driven voice chatbots to drive operational effectiveness and improve patient experience and outcomes.;2021
Artificial Neural Networks have reached grandmaster and even super-human performance across a variety of games from those involving perfect information such as Go to those involving imperfect information such as Starcraft. Such technological developments from artificial intelligence (AI) labs have ushered concomitant applications across the world of business where an AI brand-tag is quickly becoming ubiquitous. A corollary of such widespread commercial deployment is that when AI gets things wrong-an autonomous vehicle crashes a chatbot exhibits racist behavior automated credit-scoring processes discriminate on gender etc.-there are often significant financial legal and brand consequences and the incident becomes major news. As Judea Pearl sees it the underlying reason for such mistakes is that ... all the impressive achievements of deep learning amount to just curve fitting. The key as Pearl suggests is to replace reasoning by association with causal reasoning -the ability to infer causes from observed phenomena. It is a point that was echoed by Gary Marcus and Ernest Davis in a recent piece for the New York Times: we need to stop building computer systems that merely get better and better at detecting statistical patterns in data sets-often using an approach known as 'Deep Learning'-and start building computer systems that from the moment of their assembly innately grasp three basic concepts: time space and causality. In this paper foregrounding what in 1949 Gilbert Ryle termed a category mistake I will offer an alternative explanation for AI errors it is not so much that AI machinery cannot grasp causality but that AI machinery (qua computation) cannot understand anything at all.;2021
As a representative technique in natural language processing (NLP) named entity recognition is used in many tasks such as dialogue systems machine translation and information extraction. In dialogue systems there is a common case for named entity recognition where a lot of entities are composed of numbers and are segmented to be located in different places. For example in multiple rounds of dialogue systems a phone number is likely to be divided into several parts because the phone number is usually long and is emphasized. In this paper the entity consisting of numbers is named as number entity. The discontinuous positions of number entities result from many reasons. We find two reasons from real-world dialogue systems. The first reason is the repetitive confirmation of different components of a number entity and the second reason is the interception of mood words. The extraction of number entities is quite useful in many tasks such as user information completion and service requests correction. However the existing entity extraction methods cannot extract entities consisting of discontinuous entity blocks. To address these problems in this paper we propose a comprehensive method for number entity recognition which is capable of extracting number entities in multiple rounds of dialogues systems. We conduct extensive experiments on a real-world dataset and the experimental results demonstrate the high performance of our method.;2021
As a virtual human is provided with more human-like characteristics will it elicit stronger social responses from people? Two experiments were conducted to address these questions. The first experiment investigated whether virtual humans can evoke a social facilitation response and how strong that response is when people are given different cognitive tasks that vary in difficulty. The second experiment investigated whether people apply politeness norms to virtual humans. Participants were tutored either by a human tutor or a virtual human tutor that varied in features and then evaluated the tutor's performance. Results indicate that virtual humans can produce social facilitation not only with facial appearance but also with voice. In addition performance in the presence of voice synced facial appearance seems to elicit stronger social facilitation than in the presence of voice only or face only. Similar findings were observed with the politeness norm experiment. Participants who evaluated their tutor directly reported the tutor's performance more favorably than participants who evaluated their tutor indirectly. This valence toward the voice synced facial appearance had no statistical difference compared to the valence toward the human tutor condition. The results suggest that designers of virtual humans should be mindful about the social nature of virtual humans.;2021
As artificially intelligent conversational agents (ICAs) become a popular customer service solution for businesses understanding the drivers of user acceptance of ICAs is critical to ensure its successful implementation. To provide a comprehensive review of factors affecting consumers' adoption and use of ICAs this study performs a systematic literature review of extant empirical research on this topic. Based on a literature search performed in July 2019 followed by a snowballing approach 18 relevant articles were analyzed. Factors found to influence human-machine cognitive engagement were categorized into usage-related agent-related user-related attitude and evaluation and other factors. This study proposed a collective model of users' acceptance and use of ICAs whereby user acceptance is driven mainly by usage benefits which are influenced by agent and user characteristics. The study emphasizes the proposed model's context-dependency as relevant factors depend on usage settings and provides several strategic business implications including service design personalization and customer relationship management.;2021
As conversational agents like Ski and Alexa gain in popularity and use conversation is becoming a more and more important mode of interaction for search. Conversational search shares some features with traditional search but differs in some important respects: conversational search systems are less likely to return ranked lists of results (a SERP) more likely to involve iterated interactions and more likely to feature longer well-formed user queries in the form of natural language questions. Because of these differences traditional methods for search evaluation (such as the Cranfield paradigm) do not translate easily to conversational search. In this work we propose a framework for offline evaluation of conversational search which includes a methodology for creating test collections with relevance judgments an evaluation measure based on a user interaction model and an approach to collecting user interaction data to train the model. The framework is based on the idea of subtopics often used to model novelty and diversity in search and recommendation and the user model is similar to the geometric browsing model introduced by RBP and used in ERR. As far as we know this is the first work to combine these ideas into a comprehensive framework for offline evaluation of conversational search.;2021
As COVID-19 hounds the world the common cause of finding a swift solution to manage the pandemic has brought together researchers institutions governments and society at large. The Internet of Things (IoT) artificial intelligence (AI)-including machine learning (ML) and Big Data analytics-as well as Robotics and Blockchain are the four decisive areas of technological innovation that have been ingenuity harnessed to fight this pandemic and future ones. While these highly interrelated smart and connected health technologies cannot resolve the pandemic overnight and may not be the only answer to the crisis they can provide greater insight into the disease and support frontline efforts to prevent and control the pandemic. This article provides a blend of discussions on the contribution of these digital technologies propose several complementary and multidisciplinary techniques to combat COVID-19 offer opportunities for more holistic studies and accelerate knowledge acquisition and scientific discoveries in pandemic research. First four areas where IoT can contribute are discussed namely: 1) tracking and tracing 2) remote patient monitoring (RPM) by wearable IoT (WIoT) 3) personal digital twins (PDTs) and 4) real-life use case: ICT/IoT solution in South Korea. Second the role and novel applications of AI are explained namely: 1) diagnosis and prognosis 2) risk prediction 3) vaccine and drug development 4) research data set 5) early warnings and alerts 6) social control and fake news detection and 7) communication and chatbot. Third the main uses of robotics and drone technology are analyzed including: 1) crowd surveillance 2) public announcements 3) screening and diagnosis and 4) essential supply delivery. Finally we discuss how distributed ledger technologies (DLTs) of which blockchain is a common example can be combined with other technologies for tackling COVID-19.;2021
As our understanding of the construct of oral communication (OC) has evolved so have the possibilities of computer technology undertaking the delivery of tests that measure this ability. It is paramount to understand to what extent such developments lead to accurate comprehensive and useful assessment of OC. In this paper we discuss five models of technology-delivered OC assessment that have appeared in the past three decades. We evaluate these models in terms of how well their respective methods aid in assessing OC. To achieve this aim we use a framework which takes into account a contemporary view of OC ability including the call for incorporating English as a lingua franca (ELF) considerations into English language assessment. The evaluation of the five models suggests strengths and weaknesses of each that should be considered when determining which is used for a particular purpose.;2021
As the COVID-19 pandemic continues the need for a better health care facility is highlighted more than ever. Besides physical health mental health conditions have become a significant concern. Unfortunately there are few opportunities for people to receive mental health care. There are inadequate facilities for seeking mental health support even in big cities let alone remote areas. This paper presents the structure and implementation procedures for a mental health support system combining technology and professionals. The system is a web platform where mental health seekers can register and use functionalities like NLP-based chatbot for personality assessment chatting with like-minded people and one-to-one video conferencing with a mental health professional. The video calling feature of the system has emotion detection capabilities using computer vision. The system also includes downloadable prescription facilities and a payment gateway for secure transactions. From a technological aspect the conversational NLP-based chatbot and computer vision-powered video calling are the system's most important features. The system has a documentation facility to analyze the mental health condition over time. The web platform is built using React.js for the frontend and Express.js for the backend. MongoDB is used as the database of the platform. The NLP chatbot is built on a three-layered deep neural network model that is programmed in the Python language and uses the NLTK TensorFlow and Keras sequential API. Video conference is one of the most important features of the platform. To create the video calling feature Express.js Socket.io and Socket.io-client have been used. The emotion detection feature is implemented on video conferences using computer vision Haar Cascade and TensorFlow. All the implemented features are tested and work fine. The targeted users for the platform are teenagers youth and the middle-aged population. Mental health-seeking is still considered taboo in some societies today. Apart from basic established facilities this social dilemma of undergoing treatment for mental health is causing severe damage to individuals. A solution to this problem can be a remote platform for mental health support. With this goal in mind this system is designed to provide mental health support to people remotely from anywhere worldwide.;2021
As the COVID-19 pandemic has largely increased the utilization of telehealth mobile mental health technologies - such as smartphone apps vir-tual reality chatbots and social media - have also gained attention. These digital health technologies offer the potential of accessible and scalable interventions that can augment traditional care. In this paper we provide a comprehensive update on the overall field of digital psychiatry covering three areas. First we outline the relevance of recent technological advances to mental health research and care by detailing how smartphones social media artificial intelligence and virtual reality present new opportunities for digital phenotyping and remote intervention. Second we review the current evidence for the use of these new technological approaches across different mental health contexts covering their emerging efficacy in self-management of psychological well-being and early intervention along with more nascent research supporting their use in clinical management of long-term psychiatric conditions - including major depression anxiety bipolar and psychotic disorders and eating and substance use disorders - as well as in child and adolescent mental health care. Third we discuss the most pressing challenges and opportunities towards real-world implementation using the Integrated Promoting Action on Research Implementation in Health Services (i-PARIHS) framework to explain how the innovations themselves the recipients of these innovations and the context surrounding innovations all must be considered to facilitate their adoption and use in mental health care systems. We conclude that the new technological capabilities of smartphones artificial intelligence social media and virtual reality are already changing mental health care in unforeseen and exciting ways each accompanied by an early but promising evidence base. We point out that further efforts towards strengthening implementation are needed and detail the key issues at the patient provider and policy levels which must now be addressed for digital health technologies to truly improve mental health research and treatment in the future.;2021
As the dual task of question answering question generation (QG) is a significant and challenging task that aims to generate valid and fluent questions from a given paragraph. The QG task is of great significance to question answering systems conversational systems and machine reading comprehension systems. Recent sequence to sequence neural models have achieved outstanding performance in English and Chinese QG tasks. However the task of Tibetan QG is rarely mentioned. The key factor impeding its development is the lack of a public Tibetan QG dataset. Faced with this challenge the present paper first collects 425 articles from the Tibetan Wikipedia website and constructs 7234 question-answer pairs through crowdsourcing. Next we propose a Tibetan QG model based on the sequence to sequence framework to generate Tibetan questions from given paragraphs. Secondly in order to generate answer-aware questions we introduce an attention mechanism that can capture the key semantic information related to the answer. Meanwhile we adopt a copy mechanism to copy some words in the paragraph to avoid generating unknown or rare words in the question. Finally experiments show that our model achieves higher performance than baseline models. We also further explore the attention and copy mechanisms and prove their effectiveness through experiments.;2021
As with other businesses tourist companies are taking advantage of modern technologies. Chatbots are a recent technology that hotels travel agencies and airline companies are adopting. Despite this industry-wide implementation there is no evidence about the factors that explain why consumers are willing to interact with chatbots. This work proposes a model to explain chatbot usage intention. The model and its hypotheses were tested by structural equations with the PLS technique. The study was conducted on a sample of 476 individuals who had travelled on vacation in the previous 12 months. The study reveals that the intentions behind using chatbots are directly influenced by the following factors: the chatbots' expected performance the habit of using chatbots the hedonic component in using them the predisposition to using self-service technologies the social influences and the fact that the chatbot behaves like a human. The inconvenience and problems related to communicating with the chatbot were found to have a negative influence. Lastly the possibility that chatbots could replace jobs had a surprisingly positive influence and not a negative one.;2021
Aspired to build intelligent agents that can assist humans in daily life researchers and engineers both from academia and industry have kept advancing the state-of-the-art in domestic robotics. With the rapid advancement of both hardware (e.g. high performance computing smaller and cheaper sensors) and software (e.g. deep learning techniques and computational intelligence technologies) robotic products have become available to ordinary household users. For instance domestic robots have assisted humans in various daily life scenarios to provide: (1) physical assistance such as floor vacuuming (2) social assistance such as chatting and (3) education and cognitive assistance such as offering partnerships. Crucial to the success of domestic robots is their ability to understand and carry out designated tasks from human users via natural and intuitive human-like interactions because ordinary users usually have no expertise in robotics. To investigate whether and to what extent existing domestic robots can participate in intuitive and natural interactions we survey existing domestic robots in terms of their interaction ability and discuss the state-of-the-art research on multi-modal human-machine interaction from various domains including natural language processing and multi-modal dialogue systems. We relate domestic robot application scenarios with state-of-the-art computational techniques of human-machine interaction and discuss promising future directions towards building more reliable capable and human-like domestic robots.;2021
Audio-Visual Scene-Aware Dialog (AVSD) is a task to generate responses when chatting about a given video which is organized as a track of the 8th Dialog System Technology Challenge (DSTC8). There are two challenges in this task: 1) making effective interaction among different modalities 2) better understanding dialogues and generating informative responses. To tackle the challenges we propose a universal multimodal transformer and introduce the multi-task learning method to learn joint representations among different modalities as well as generate informative and fluent responses by leveraging the pre-trained language model. Our method extends the natural language generation pre-trained model to multimodal dialogue generation task which allows fine-tuning language models to capture information across both visual and textual modalities. Our system achieves the best performance in the objective evaluation in both DSTC7-AVSD and DSTC8-AVSD dataset and achieves an impressive 98.4% of the human performance based on human ratings in the DSTC8-AVSD challenge.;2021
Augmented Reality (AR) headsets extended with eye-tracking a promising input technology for its natural and implicit nature open a wide range of new interaction capabilities for everyday use. In this paper we present ARtention a design space for gaze interaction specifically tailored for in-situ AR information interfaces. It highlights three important dimensions to consider in the UI design of such gaze-enabled applications: transitions from reality to the virtual interface from single-to multi-layer content and from information consumption to selection tasks. Such transitional aspects bring previously isolated gaze interaction concepts together to form a unified AR space enabling more advanced application control seamlessly mediated by gaze. We describe these factors in detail. To illustrate how the design space can be used we present three prototype applications and report informal user feedback obtained from different scenarios: a conversational UI viewing a 3D visualization and browsing items for shopping. We conclude with design considerations derived from our development and evaluation of the prototypes. We expect these to be valuable for researchers and designers investigating the use of gaze input in AR systems and applications. (c) 2021 Elsevier Ltd. All rights reserved. Augmented Reality (AR) headsets extended with eye-tracking a promising input technology for its natural and implicit nature open a wide range of new interaction capabilities for everyday use. In this paper we present ARtention a design space for gaze interaction specifically tailored for in-situ AR information interfaces. It highlights three important dimensions to consider in the UI design of such gaze-enabled applications: transitions from reality to the virtual interface from single- to multi-layer content and from information consumption to selection tasks. Such transitional aspects bring previously isolated gaze interaction concepts together to form a unified AR space enabling more advanced application control seamlessly mediated by gaze. We describe these factors in detail. To illustrate how the design space can be used we present three prototype applications and report informal user feedback obtained from different scenarios: a conversational UI viewing a 3D visualization and browsing items for shopping. We conclude with design considerations derived from our development and evaluation of the prototypes. We expect these to be valuable for researchers and designers investigating the use of gaze input in AR systems and applications.;2021
Autism spectrum disorder (ASD) is a life-long neurological disability and a cure has not yet been found. ASD begins early in childhood and lasts throughout a person's life. Through early intervention many actions can be taken to improve the quality of life of children. Robots are one of the best choices for accompanying children with autism. However for most robots the dialogue system uses traditional techniques to produce responses. Robots cannot produce meaningful answers when the conversations have not been recorded in a database. The main contribution of our work is the incorporation of a conversation model into an actual robot system for supporting children with autism. We present the use a neural network model as the generative conversational agent which aimed at generating meaningful and coherent dialogue responses given the dialogue history. The proposed model shares an embedding layer between the encoding and decoding processes through adoption. The model is different from the canonical Seq2Seq model in which the encoder output is used only to set-up the initial state of the decoder to avoid favoring short and unconditional responses with high prior probability. In order to improve the sensitivity to context we changed the input method of the model to better adapt to the utterances of children with autism. We adopted transfer learning to make the proposed model learn the characteristics of dialogue with autistic children and to solve the problem of the insufficient corpus of dialogue. Experiments showed that the proposed method was superior to the canonical Seq2sSeq model and the GAN-based dialogue model in both automatic evaluation indicators and human evaluation including pushing the BLEU precision to 0.23 the greedy matching score to 0.69 the embedding average score to 0.82 the vector extrema score to 0.55 the skip-thought score to 0.65 the KL divergence score to 5.73 and the EMD score to 12.21.;2021
Autonomous and interactive healthcare applications exist for providing patients with customized services through user equipment (UE). For user interaction these applications take the form of chatbots or physical robots. A user's request/query is fed as input for fetching and delivering user services. Due to the wide range of connectivity and application services heavy data traffic can deteriorate the quality of application service. This paper proposes a relative traffic management scheme (RTMS) to address traffic issues in applications involving delicate healthcare data. The proposed scheme uses healthcare data flow and query processing to improve the responsiveness of autonomous robot-based services. Dilated traffic at any interconnecting edge is identified based on flow concentration for this purpose ant colony optimization (ACO) is used. The premature convergence issue in ACO is addressed by using a linear sigmoid function which identifies the converging points based on the query processing factor to reinitiate the application service discovery and responsive deliveries. This helps to reduce both outages in healthcare service provisioning and processing time. It additionally improves response with controlled processing complexity.;2021
Background and Aim: Loneliness is a common problem in older adults and contributes to poor health. This scoping review aimed to synthesize and report evidence on the effectiveness of interventions using social robots or computer agents to reduce loneliness in older adults and to explore intervention strategies. Methods: The review adhered to the Arksey and O'Malley process for conducting scoping reviews. The SCOPUS PUBMED Web of Science EMBASE CINAHL PsycINFO ACM Digital Library and IEEE Xplore databases were searched in November 2020. A two-step selection process identified eligible research. Information was extracted from papers and entered into an Excel coding sheet and summarised. Quality assessments were conducted using the Mixed Methods Appraisal Tool. Results: Twenty-nine studies were included of which most were of moderate to high quality. Eighteen were observational and 11 were experimental. Twenty-four used robots four used computer agents and one study used both. The majority of results showed that robots or computer agents positively impacted at least one loneliness outcome measure. Some unintended negative consequences on social outcomes were reported such as sadness when the robot was removed. Overall the interventions helped to combat loneliness by acting as a direct companion (69%) a catalyst for social interaction (41%) facilitating remote communication with others (10%) and reminding users of upcoming social engagements (3%). Conclusion: Evidence to date suggests that robots can help combat loneliness in older adults but there is insufficient research on computer agents. Common strategies for reducing loneliness include direct companionship and enabling social interactions. Future research could investigate other strategies used in human interventions (eg addressing maladaptive social cognition and improving social skills) and the effects of design features on efficacy. It is recommended that more robust experimental and mixed methods research be conducted using a combination of validated self-report observational and interview measures of loneliness.;2021
Background and Objective: This study describes the integration of a spoken dialogue system and nursing records on an Android smartphone application intending to help nurses reduce documentation time and improve the overall experience of a healthcare setting. The application also incorporates with collecting personal sensor data and activity labels for activity recognition. Methods: We developed a joint model based on a bidirectional long-short term memory and conditional random fields (Bi-LSTM-CRF) to identify user intention and extract record details from user utterances. Then we transformed unstructured data into record inputs on the smartphone application. Results: The joint model achieved the highest F1-score at 96.79%. Moreover we conducted an experiment to demonstrate the proposed model's capability and feasibility in recording in realistic settings. Our preliminary evaluation results indicate that when using the dialogue-based we could increase the percentage of documentation speed to 58.13% compared to the traditional keyboard-based. Conclusions: Based on our findings we highlight critical and promising future research directions regarding the design of the efficient spoken dialogue system and nursing records. (c) 2021 Elsevier B.V. All rights reserved.;2021
Background Artificial intelligence (AI) is one of the most promising areas in medicine with many possibilities for improving health and wellness. Already today diagnostic decision support systems may help patients to estimate the severity of their complaints. This fictional case study aimed to test the diagnostic potential of an AI algorithm for common sports injuries and pathologies. Methods Based on a literature review and clinical expert experience five fictional common cases of acute and subacute injuries or chronic sport-related pathologies were created: Concussion ankle sprain muscle pain chronic knee instability (after ACL rupture) and tennis elbow. The symptoms of these cases were entered into a freely available chatbot-guided AI app and its diagnoses were compared to the pre-defined injuries and pathologies. Results A mean of 25-36 questions were asked by the app per patient with optional explanations of certain questions or illustrative photos on demand. It was stressed that the symptom analysis would not replace a doctor's consultation. A 23-yr-old male patient case with a mild concussion was correctly diagnosed. An ankle sprain of a 27-yr-old female without ligament or bony lesions was also detected and an ER visit was suggested. Muscle pain in the thigh of a 19-yr-old male was correctly diagnosed. In the case of a 26-yr-old male with chronic ACL instability the algorithm did not sufficiently cover the chronic aspect of the pathology but the given recommendation of seeing a doctor would have helped the patient. Finally the condition of the chronic epicondylitis in a 41-yr-old male was correctly detected. Conclusions All chosen injuries and pathologies were either correctly diagnosed or at least tagged with the right advice of when it is urgent for seeking a medical specialist. However the quality of AI-based results could presumably depend on the data-driven experience of these programs as well as on the understanding of their users. Further studies should compare existing AI programs and their diagnostic accuracy for medical injuries and pathologies.;2021
Background Chatbots and virtual voice assistants are increasingly common in primary care without sufficient evidence for their feasibility and effectiveness. We aimed to assess how perceived stigma and severity of various health issues are associated with the acceptability for three sources of health information and consultation: an automated chatbot a General Practitioner (GP) or a combination of both. Methods Between May and June 2019 we conducted an online study advertised via Facebook for UK citizens. It was a factorial simulation experiment with three within-subject factors (perceived health issue stigma severity and consultation source) and six between-subject covariates. Acceptability rating for each consultation source was the dependant variable. A single mixed-model ANOVA was performed. Results Amongst 237 participants (65% aged over 45 years old 73% women) GP consultations were seen as most acceptable followed by GP-chatbot service. Chatbots were seen least acceptable as a consultation source for severe health issues while the acceptability was significantly higher for stigmatised health issues. No associations between participants' characteristics and acceptability were found. Conclusions Although healthcare professionals are perceived as the most desired sources of health information chatbots may be useful for sensitive health issues in which disclosure of personal information is challenging. However chatbots are less acceptable for health issues of higher severity and should not be recommended for use within that context. Policymakers and digital service designers need to recognise the limitations of health chatbots. Future research should establish a set of health topics most suitable for chatbot-led interventions and primary healthcare services.;2021
Background Family health history (FHx) is an effective tool for identifying patients at risk of hereditary cancer. Hereditary cancer clinical practice guidelines (CPG) contain criteria used to evaluate FHx and to make recommendations for genetic consultation. Comparing different CPGs used to evaluate a common set of FHx provides insight into how well the CPGs perform the extent of agreement across guidelines and how well they identify patients who should consider a cancer genetic consultation. Methods We compare the American College of Medical Genetics and Genomics (ACMG) and the National Comprehensive Cancer Networks (NCCN) (2019) CPG criteria for FHx collected by a chatbot and evaluated by ontologies and web services in a previous study. Collected FHx met criteria from seven groups: Gene Mutation Breast and Ovarian Li-Fraumeni syndrome (LFS) Colorectal and Endometrial Relative Meets Criteria ACMG Only Criteria and NCCN Testing. CPG Criteria were coded and matched across 12 ACMG sub-guidelines and 6 NCCN sub-guidelines for comparison purposes. Results The dataset contains 4915 records of which 2221 met either ACMG or NCCN criteria and 2694 did not. There was significant overlap-1179 probands met both ACMG and NCCN criteria. The greatest similarities were for Gene Mutation and Breast and Ovarian criteria and the greatest disparity existed among Colorectal and Endometrial criteria. Only 156 positive gene mutations were reported and of the 2694 probands who did not meet criteria 90.6% of them reported at least one cancer in their personal or family cancer history. Conclusion Hereditary cancer CPGs are useful for identifying patients at risk of developing cancer based on FHx. This comparison shows that with the aid of chatbots ontologies and web services CPGs can be more efficiently applied to identify patients at risk of hereditary cancer. Additionally this comparison examines similarities and differences between ACMG and NCCN and shows the importance of using both guidelines when evaluating hereditary cancer risk.;2021
Background Hereditary colorectal cancer (HCRC) syndromes account for 10% of colorectal cancers but remain underdiagnosed. This feasibility project tested the utility of an artificial intelligence-based chatbot deployed to patients scheduled for colonoscopy to identify HCRC risk factors educate participants about HCRC and obtain consent to genetic testing as an extension of genetic counselling of appropriate subjects. Genetic counsellor (GC) and genetic counselling assistant (GCA) time spent per subject was also measured. Methods Patients scheduled for colonoscopy at Cleveland Clinic were invited via electronic medical record patient portal or letter prior to colonoscopy with a link to a chatbot administering the Colon Cancer Risk Assessment Tool (CCRAT) to screen for HCRC syndromes. Those with >= 1 positive response to a CCRAT question received chatbot-deployed genetic education and the option to receive genetic testing. An order for a 55-gene pan-cancer panel was placed for those consenting and the subject had blood drawn on the day of colonoscopy. Results were disclosed by a GC or GCA by telephone. Subject demographics progression through the chat responses to CCRAT personal and family history genetic test results and communication with the subject were recorded. Descriptive statistics and two-tailed unpaired t-test and Fisher's exact test were used. Results 506/4254 (11.9%) initiated and 487 (96.2%) completed the chat with the chatbot. 215 (44.1%) answered 'yes' to >= 1 CCRAT question and all completed pretest education. 129/181 (71.3%) subjects who consented completed testing and 12 (9.3%) were found to have a germline pathogenic variant. Per subject the GC spent a mean of 14.3 (SD 7.3) and the GCA a mean of 19.2 (SD 9.8) minutes. Conclusion The use of a chatbot in this setting was a novel and feasible method with the potential of increasing genetic screening and testing in individuals at risk of HCRC syndromes.;2021
Background In recent years an increasing number of health chatbots has been published in app stores and described in research literature. Given the sensitive data they are processing and the care settings for which they are developed evaluation is essential to avoid harm to users. However evaluations of those systems are reported inconsistently and without using a standardized set of evaluation metrics. Missing standards in health chatbot evaluation prevent comparisons of systems and this may hamper acceptability since their reliability is unclear. Objectives The objective of this paper is to make an important step toward developing a health-specific chatbot evaluation framework by finding consensus on relevant metrics. Methods We used an adapted Delphi study design to verify and select potential metrics that we retrieved initially from a scoping review. We invited researchers health professionals and health informaticians to score each metric for inclusion in the final evaluation framework over three survey rounds. We distinguished metrics scored relevant with high moderate and low consensus. The initial set of metrics comprised 26 metrics (categorized as global metrics metrics related to response generation response understanding and aesthetics). Results Twenty-eight experts joined the first round and 22 (75%) persisted to the third round. Twenty-four metrics achieved high consensus and three metrics achieved moderate consensus. The core set for our framework comprises mainly global metrics (e.g. ease of use security content accuracy) metrics related to response generation (e.g. appropriateness of responses) and related to response understanding. Metrics on aesthetics (font type and size color) are less well agreed upon-only moderate or low consensus was achieved for those metrics. Conclusion The results indicate that experts largely agree on metrics and that the consensus set is broad. This implies that health chatbot evaluation must be multifaceted to ensure acceptability.;2021
Background Less than 2% of overweight children and adolescents in Switzerland can participate in multi-component behaviour changing interventions (BCI) due to costs and lack of time. Stress often hinders positive health outcomes in youth with obesity. Digital health interventions with fewer on-site visits promise health care access in remote regions however evidence for their effectiveness is scarce. Methods This randomized controlled not blinded trial (1:1) was conducted in a childhood obesity center in Switzerland. Forty-one youth aged 10-18 years with body mass index (BMI) > P.90 with risk factors or co-morbidities or BMI > P.97 were recruited. During 5.5 months the PathMate2 group (PM) received daily conversational agent counselling via mobile app combined with standardized counselling (4 on-site visits). Controls (CON) participated in a BCI (7 on-site visits). We compared the outcomes of both groups after 5.5 (T1) and 12 (T2) months. Primary outcome was reduction in BMI-SDS (BMI standard deviation score: BMI adjusted for age and sex). Secondary outcomes were changes in body fat and muscle mass (bioelectrical impedance analysis) waist-to-height ratio physical capacities (modified Dordel-Koch-Test) blood pressure and pulse. Additionally we hypothesized that less stressed children would lose more weight. Thus children performed biofeedback relaxation exercises while stress parameters (plasma cortisol stress questionnaires) were evaluated. Results At intervention start median BMI-SDS of all patients (18 PM 13 CON) was 2.61 (obesity > + 2SD). BMI-SDS decreased significantly in CON at T1 but not at T2 and did not decrease in PM during the study. Muscle mass strength and agility improved significantly in both groups at T2 only PM reduced significantly their body fat at T1 and T2. Average daily PM app usage rate was 71.5%. Cortisol serum levels decreased significantly after biofeedback but with no association between stress parameters and BMI-SDS. No side effects were observed. Conclusions Equally to BCI PathMate2 intervention resulted in significant and lasting improvements of physical capacities and body composition but not in sustained BMI-SDS decrease. This youth-appealing mobile health intervention provides an interesting approach for youth with obesity who have limited access to health care. Biofeedback reduces acute stress and could be an innovative adjunct to usual care.;2021
Background Polycystic ovary syndrome (PCOS) is a complex and multi-faceted endocrine disorder that affects 5-20% of women. Literature is limited regarding potentially differing PCOS phenotypes among women around the world. Objective To use Flo app technology to understand the multifaceted characteristics of PCOS across several countries and identify contributing risk factors to the development of this condition. Study design Flo is a widely used female health and wellbeing app with period tracking functionality that provides a globally representative and medically unbiased perspective on PCOS symptomatology. A chatbot dialog on PCOS was subsequently administered on the Flo application (app) to users from 142 countries (with at least 100 respondents) who have the app running in English during September-October 2019. Results For analyses we selected the five countries with the greatest number of respondents: US (n = 243238) UK (n = 68325) India (n = 40092) Philippines (n = 35131) and Australia (n = 29926). Bloating was the most frequently reported symptom among PCOS-positive women and appeared to be the main predictor of PCOS in our model (odds ratio 3 center dot 76 [95% CI 3 center dot 60-3 center dot 94] p < 0 center dot 0001). Additional top predictors of PCOS are high blood cholesterol and glucose levels. As BMI increased the percentage of women who reported a physician-confirmed PCOS diagnosis also increased. However women in India did not follow this trend. Conclusion Our findings are based on the largest known PCOS dataset and indicate that symptoms are more complex than previously understood. The most frequently reported symptoms (bloating facial hirsutism irregular cycles hyperpigmentation and baldness) are broader than those included in the Rotterdam criteria. Future work should reevaluate and refine the criteria utilized in PCOS diagnosis.;2021
Background Semantic textual similarity (STS) captures the degree of semantic similarity between texts. It plays an important role in many natural language processing applications such as text summarization question answering machine translation information retrieval dialog systems plagiarism detection and query ranking. STS has been widely studied in the general English domain. However there exists few resources for STS tasks in the clinical domain and in languages other than English such as Japanese. Objective The objective of this study is to capture semantic similarity between Japanese clinical texts (Japanese clinical STS) by creating a Japanese dataset that is publicly available. Materials We created two datasets for Japanese clinical STS: (1) Japanese case reports (CR dataset) and (2) Japanese electronic medical records (EMR dataset). The CR dataset was created from publicly available case reports extracted from the CiNii database. The EMR dataset was created from Japanese electronic medical records. Methods We used an approach based on bidirectional encoder representations from transformers (BERT) to capture the semantic similarity between the clinical domain texts. BERT is a popular approach for transfer learning and has been proven to be effective in achieving high accuracy for small datasets. We implemented two Japanese pretrained BERT models: a general Japanese BERT and a clinical Japanese BERT. The general Japanese BERT is pretrained on Japanese Wikipedia texts while the clinical Japanese BERT is pretrained on Japanese clinical texts. Results The BERT models performed well in capturing semantic similarity in our datasets. The general Japanese BERT outperformed the clinical Japanese BERT and achieved a high correlation with human score (0.904 in the CR dataset and 0.875 in the EMR dataset). It was unexpected that the general Japanese BERT outperformed the clinical Japanese BERT on clinical domain dataset. This could be due to the fact that the general Japanese BERT is pretrained on a wide range of texts compared with the clinical Japanese BERT.;2021
Background Text Matching (TM) is a fundamental task of natural language processing widely used in many application systems such as information retrieval automatic question answering machine translation dialogue system reading comprehension etc. In recent years a large number of deep learning neural networks have been applied to TM and have refreshed benchmarks of TM repeatedly. Among the deep learning neural networks convolutional neural network (CNN) is one of the most popular networks which suffers from difficulties in dealing with small samples and keeping relative structures of features. In this paper we propose a novel deep learning architecture based on capsule network for TM called CapsTM where capsule network is a new type of neural network architecture proposed to address some of the short comings of CNN and shows great potential in many tasks. Methods CapsTM is a five-layer neural network including an input layer a representation layer an aggregation layer a capsule layer and a prediction layer. In CapsTM two pieces of text are first individually converted into sequences of embeddings and are further transformed by a highway network in the input layer. Then Bidirectional Long Short-Term Memory (BiLSTM) is used to represent each piece of text and attention-based interaction matrix is used to represent interactive information of the two pieces of text in the representation layer. Subsequently the two kinds of representations are fused together by BiLSTM in the aggregation layer and are further represented with capsules (vectors) in the capsule layer. Finally the prediction layer is a connected network used for classification. CapsTM is an extension of ESIM by adding a capsule layer before the prediction layer. Results We construct a corpus of Chinese medical question matching which contains 36360 question pairs. This corpus is randomly split into three parts: a training set of 32360 question pairs a development set of 2000 question pairs and a test set of 2000 question pairs. On this corpus we conduct a series of experiments to evaluate the proposed CapsTM and compare it with other state-of-the-art methods. CapsTM achieves the highest F-score of 0.8666. Conclusion The experimental results demonstrate that CapsTM is effective for Chinese medical question matching and outperforms other state-of-the-art methods for comparison.;2021
Background. The emergence of artificial intelligence (AI) provides opportunities for demand management of sexual and reproductive health services. Conversational agents/chatbots are increasingly common although little is known about how this technology could aid services. This study aimed to identify barriers and facilitators for engagement with sexual health chatbots to advise service developers and related health professionals. Methods. In January-June 2020 we conducted face-to-face semi-structured and online interviews to explore views on sexual health chatbots. Participants were asked to interact with a chatbot offering advice on sexually transmitted infections (STIs) and relevant services. Participants were UK-based and recruited via social media. Data were recorded transcribed verbatim and analysed thematically. Results. Forty participants (aged 18-50 years 64% women 77% heterosexual 58% white) took part. Many thought chatbots could aid sex education providing useful information about STIs and sign-posting to sexual health services in a convenient anonymous and non-judgemental way. Some compared chatbots to health professionals or Internet search engines and perceived this technology as inferior offering constrained content and interactivity limiting disclosure of personal information trust and perceived accuracy of chatbot responses. Conclusions. Despite mixed attitudes towards chatbots this technology was seen as useful for anonymous sex education but less suitable for matters requiring empathy. Chatbots may increase access to clinical services but their effectiveness and safety need to be established. Future research should identify which chatbots designs and functions lead to optimal engagement with this innovation.;2021
Background: A voice assistant (VA) is inanimate audio-interfaced software augmented with artificial intelligence capable of 2-way dialogue and increasingly used to access health care advice. Postpartum depression (PPD) is a common perinatal mood disorder with an annual estimated cost of $14.2 billion. Only a small percentage of PPD patients seek care due to lack of screening and insufficient knowledge of the disease and this is therefore a prime candidate for a VA-based digital health intervention. Objective: In order to understand the capability of VAs our aim was to assess VA responses to PPD questions in terms of accuracy verbal response and clinically appropriate advice given. Methods: This cross-sectional study examined four VAs (Apple Siri Amazon Alexa Google Assistant and Microsoft Cortana) installed on two mobile devices in early 2020. We posed 14 questions to each VA that were retrieved from the American College of Obstetricians and Gynecologists (ACOG) patient-focused Frequently Asked Questions (FAQ) on PPD. We scored the VA responses according to accuracy of speech recognition presence of a verbal response and clinically appropriate advice in accordance with ACOG FAQ which were assessed by two board-certified physicians. Results: Accurate recognition of the query ranged from 79% to 100%. Verbal response ranged from 36% to 79%. If no verbal response was given queries were treated like a web search between 33% and 89% of the time. Clinically appropriate advice given by VA ranged from 14% to 29%. We compared the category proportions using the Fisher exact test. No single VA statistically outperformed other VAs in the three performance categories. Additional observations showed that two VAs (Google Assistant and Microsoft Cortana) included advertisements in their responses. Conclusions: While the best performing VA gave clinically appropriate advice to 29% of the PPD questions all four VAs taken together achieved 64% clinically appropriate advice. All four VAs performed well in accurately recognizing a PPD query but no VA achieved even a 30% threshold for providing clinically appropriate PPD information. Technology companies and clinical organizations should partner to improve guidance screen patients for mental health disorders and educate patients on potential treatment.;2021
Background: Advances in natural language processing and other machine learning techniques have led to the development of automated agents (chatbots) that mimic human conversation. These systems have mainly been used in commercial settings and within medicine for symptom checking and psychotherapy. The aim of this systematic review was to determine the acceptability and implementation success of chatbots in the follow-up of patients who have undergone a physical healthcare intervention. Methods: A systematic review of MEDLINE MEDLINE In-process EMBASE PsychINFO CINAHL CENTRAL and the grey literature using a PRISMA-compliant methodology up to September 2020 was conducted. Abstract screening and data extraction were performed in duplicate. Risk of bias and quality assessments were performed for each study. Results: The search identified 904 studies of which 10 met full inclusion criteria: three randomised control trials one non-randomised clinical trial and six cohort studies. Chatbots were used for monitoring after the management of cancer hypertension and asthma orthopaedic intervention ureteroscopy and intervention for varicose veins. All chatbots were deployed on mobile devices. A number of metrics were identified and ranged from a 31 per cent chatbot engagement rate to a 97 per cent response rate for system-generated questions. No study examined patient safety. Conclusion: A range of chatbot builds and uses was identified. Further investigation of acceptability efficacy and mechanistic evaluation in outpatient care pathways may lend support to implementation in routine clinical care.;2021
Background: Artificial intelligence (AI)-driven chatbots are increasingly being used in health care but most chatbots are designed for a specific population and evaluated in controlled settings. There is little research documenting how health consumers (eg patients and caregivers) use chatbots for self-diagnosis purposes in real-world scenarios. Objective: The aim of this research was to understand how health chatbots are used in a real-world context what issues and barriers exist in their usage and how the user experience of this novel technology can be improved. Methods: We employed a data-driven approach to analyze the system log of a widely deployed self-diagnosis chatbot in China. Our data set consisted of 47684 consultation sessions initiated by 16519 users over 6 months. The log data included a variety of information including users' nonidentifiable demographic information consultation details diagnostic reports and user feedback. We conducted both statistical analysis and content analysis on this heterogeneous data set. Results: The chatbot users spanned all age groups including middle-aged and older adults. Users consulted the chatbot on a wide range of medical conditions including those that often entail considerable privacy and social stigma issues. Furthermore we distilled 2 prominent issues in the use of the chatbot: (1) a considerable number of users dropped out in the middle of their consultation sessions and (2) some users pretended to have health concerns and used the chatbot for nontherapeutic purposes. Finally we identified a set of user concerns regarding the use of the chatbot including insufficient actionable information and perceived inaccurate diagnostic suggestions. Conclusions: Although health chatbots are considered to be convenient tools for enhancing patient-centered care there are issues and barriers impeding the optimal use of this novel technology. Designers and developers should employ user-centered approaches to address the issues and user concerns to achieve the best uptake and utilization. We conclude the paper by discussing several design implications including making the chatbots more informative easy-to-use and trustworthy as well as improving the onboarding experience to enhance user engagement.;2021
Background: Artificial intelligence (AI)-driven symptom checkers are available to millions of users globally and are advocated as a tool to deliver health care more efficiently. To achieve the promoted benefits of a symptom checker laypeople must trust and subsequently follow its instructions. In AI explanations are seen as a tool to communicate the rationale behind black-box decisions to encourage trust and adoption. However the effectiveness of the types of explanations used in AI-driven symptom checkers has not yet been studied. Explanations can follow many forms including why-explanations and how-explanations. Social theories suggest that why-explanations are better at communicating knowledge and cultivating trust among laypeople. Objective: The aim of this study is to ascertain whether explanations provided by a symptom checker affect explanatory trust among laypeople and whether this trust is impacted by their existing knowledge of disease. Methods: A cross-sectional survey of 750 healthy participants was conducted. The participants were shown a video of a chatbot simulation that resulted in the diagnosis of either a migraine or temporal arteritis chosen for their differing levels of epidemiological prevalence. These diagnoses were accompanied by one of four types of explanations. Each explanation type was selected either because of its current use in symptom checkers or because it was informed by theories of contrastive explanation. Exploratory factor analysis of participants' responses followed by comparison-of-means tests were used to evaluate group differences in trust. Results: Depending on the treatment group two or three variables were generated reflecting the prior knowledge and subsequent mental model that the participants held. When varying explanation type by disease migraine was found to be nonsignificant (P=.65) and temporal arteritis marginally significant (P=.09). Varying disease by explanation type resulted in statistical significance for input influence (P=.001) social proof (P=.049) and no explanation (P=.006) with counterfactual explanation (P=.053). The results suggest that trust in explanations is significantly affected by the disease being explained. When laypeople have existing knowledge of a disease explanations have little impact on trust. Where the need for information is greater different explanation types engender significantly different levels of trust. These results indicate that to be successful symptom checkers need to tailor explanations to each user's specific question and discount the diseases that they may also be aware of. Conclusions: System builders developing explanations for symptom-checking apps should consider the recipient's knowledge of a disease and tailor explanations to each user's specific need. Effort should be placed on generating explanations that are personalized to each user of a symptom checker to fully discount the diseases that they may be aware of and to close their information gap.;2021
Background: As the world's population rapidly ages the number of older adults with cognitive impairment will also increase. Several studies have identified numerous complex needs of people with dementia which assistive technologies still fail to support. Recent trends have led to an increasing focus on the use of embodied conversational agents (ECAs) as virtual entities able to interact with a person through natural and familiar verbal and nonverbal communication. The use of ECAs could improve the accessibility and acceptance of assistive technologies matching those high-level needs that are not well covered to date. Objective: The aim of this thematic literature analysis was to map current studies in the field of designing ECAs for patients with dementia in order to identify the existing research trend and possible gaps that need to be covered in the near future. The review questions in this study were as follows: (1) what research frameworks are used to study the interaction between patients with dementia and ECAs? (2) what are the findings? and (3) what are the barriers reported in these studies? Methods: Separate literature searches were conducted in PubMed Web of Science Scopus and Embase databases by using specific umbrella phrases to target the population (patients with dementia) and the technology-based intervention (embodied conversational agent). Studies that met the inclusion criteria were appraised through the Mixed Methods Appraisal Tool and then discussed in a thematic analysis. Results: The search process identified 115 records from the databases and study references. After duplicates (n=45) were removed 70 papers remained for the initial screening. A total of 7 studies were finally included in the qualitative synthesis. A thematic analysis of the reviewed studies identified major themes and subthemes: the research frameworks used to gather users' perspectives on ECAs (theme 1) the insights shared by the 7 studies as well as the value of user involvement in the development phases and the challenge of matching the system functionalities with the users' needs (theme 2) and the main methodological and technical problems faced by each study team (theme 3). Conclusions: Our thematic literature analysis shows that the field of ECAs is novel and poorly discussed in the scientific community and that more sophisticated study designs and proofs of efficacy of the approach are required. Therefore by analyzing the main topic of the narrative review this study underscores the challenge of synchronizing and harmonizing knowledge efforts and challenges in the dementia care field and its person-centered paradigm through the user-centered design approach. Enabling strict collaboration between interdisciplinary research networks medical scientists technology developers patients and their formal and informal caregivers is still a great challenge in the field of technologies for older adults.;2021
Background: Attention deficit is a growing problem in adults and early diagnosis and treatment are needed. Previous studies have shown that cognitive behavioral therapy (CBT) is effective in improving attention deficit symptoms. However many patients are not receiving adequate treatment due to time space and cost constraints. Recently in other mental illnesses mobile-based chatbots delivering CBT and psychoeducation have been used for symptom mitigation and treatment. Objective: This study aimed to investigate the feasibility and usability of a short-term intervention specifically a mobile-based interactive chatbot application in alleviating attention deficit symptoms. Methods: This was a randomized non-blind parallel-group pilot study conducted from September 2019 to March 2020. Forty-six individuals with attention deficit aged 19-60 were randomly allocated to the chatbot (n = 23) and information-only control groups (n = 23) for 4 weeks. The former group was instructed to use the chatbot application Todaki while the latter group was provided with a book on managing attention deficit symptoms. Participants were administered questionnaires to assess their symptoms of attention deficit depression and anxiety and evaluated at baseline and 4 weeks after the intervention. The post-intervention survey assessed the chatbot's usability acceptability and side effects. Results: The average age of the participants was 25.1 years (standard deviation [SD] 7.5 years) and 56.5 % (26/ 46) participants were female. Intention-to-treat analysis (chatbot n = 23 control n = 23) revealed a significant reduction of attention deficit symptoms only in the chatbot group which is represented by group-by-time interaction in Conner's Adult ADHD Rating Scale subscales of Diagnostic and Statistical Manual-IV AttentionDeficit/Hyperactivity Disorder (ADHD) Hyperactive-Impulsive symptoms (F = 4.39 p = .04) and ADHD symptoms total (F = 6.74 p = .01). Further the results of the paired t-test were significant only in the chatbot group. The average number of times the chatbots were used in 4 weeks was 20.32 (SD 12.89). The total average usage time was 1 h 15 min (SD 1 h 20 min). The degree of improvement in the ADHD symptoms total score was correlated with the number of times the psychoeducation program was used. According to the participants the empathic/friendly character and unnatural flow of conversation were the best and worst features of the chatbot respectively. Conclusions: This study identified the feasibility and usability of using the mobile-based chatbot to improve attention deficit and its associated psychiatric symptoms. Using this novel intervention to conduct CBT would provide a useful digital therapeutic tool that allows easy accessibility and self-guided management for people with attention deficit which should be verified through the large scale randomized controlled trial.;2021
BACKGROUND: Avatars in Virtual Reality (VR) can not only represent humans but also embody intelligent software agents that communicate with humans thus enabling a new paradigm of human-machine interaction. OBJECTIVE: The research agenda proposed in this paper by an interdisciplinary team is motivated by the premise that a conversation with a smart agent avatar in VR means more than giving a face and body to a chatbot. Using the concrete communication task of patient education this research agenda is rather intended to explore which patterns and practices must be constructed visually verbally para- and nonverbally between humans and embodied machines in a counselling context so that humans can integrate counselling by an embodied VR smart agent into their thinking and acting in one way or another. METHODS: The scientific literature in different bibliographical databases was reviewed. A qualitative narrative approach was applied for analysis. RESULTS: A research agenda is proposed which investigates how recurring consultations of patients with healthcare professionals are currently conducted and how they could be conducted with an embodied smart agent in immersive VR. CONCLUSIONS: Interdisciplinary teams consisting of linguists computer scientists visual designers and health care professionals are required which need to go beyond a technology-centric solution design approach. Linguists' insights from discourse analysis drive the explorative experiments to identify test and discover what capabilities and attributes the smart agent in VR must have in order to communicate effectively with a human being.;2021
Background: Behavioral eHealth and mobile health interventions have been moderately successful in increasing physical activity although opportunities for further improvement remain to be discussed. Chatbots equipped with natural language processing can interact and engage with users and help continuously monitor physical activity by using data from wearable sensors and smartphones. However a limited number of studies have evaluated the effectiveness of chatbot interventions on physical activity. Objective: This study aims to investigate the feasibility usability and effectiveness of a machine learning-based physical activity chatbot. Methods: A quasi-experimental design without a control group was conducted with outcomes evaluated at baseline and 6 weeks. Participants wore a Fitbit Flex 1 (Fitbit LLC) and connected to the chatbot via the Messenger app. The chatbot provided daily updates on the physical activity level for self-monitoring sent out daily motivational messages in relation to goal achievement and automatically adjusted the daily goals based on physical activity levels in the last 7 days. When requested by the participants the chatbot also provided sources of information on the benefits of physical activity sent general motivational messages and checked participants' activity history (ie the step counts/min that were achieved on any day). Information about usability and acceptability was self-reported. The main outcomes were daily step counts recorded by the Fitbit and self-reported physical activity. Results: Among 116 participants 95 (81.9%) were female 85 (73.3%) were in a relationship 101 (87.1%) were White and 82 (70.7%) were full-time workers. Their average age was 49.1 (SD 9.3) years with an average BMI of 32.5 (SD 8.0) kg/m2. Most experienced technical issues were due to an unexpected change in Facebook policy (93/113 82.3%). Most of the participants scored the usability of the chatbot (101/113 89.4%) and the Fitbit (99/113 87.6%) as at least OK. About one-third (40/113 35.4%) would continue to use the chatbot in the future and 53.1% (60/113) agreed that the chatbot helped them become more active. On average 6.7 (SD 7.0) messages/week were sent to the chatbot and 5.1 (SD 7.4) min/day were spent using the chatbot. At follow-up participants recorded more steps (increase of 627 95% CI 219-1035 steps/day) and total physical activity (increase of 154.2 min/week 3.58 times higher at follow-up 95% CI 2.28-5.63). Participants were also more likely to meet the physical activity guidelines (odds ratio 6.37 95% CI 3.31-12.27) at follow-up. Conclusions: The machine learning-based physical activity chatbot was able to significantly increase participants' physical activity and was moderately accepted by the participants. However the Facebook policy change undermined the chatbot functionality and indicated the need to use independent platforms for chatbot deployment to ensure successful delivery of this type of intervention.;2021
Background: Body image and eating disorders represent a significant public health concern however many affected individuals never access appropriate treatment. Conversational agents or chatbots reflect a unique opportunity to target those affected online by providing psychoeducation and coping skills thus filling the gap in service provision. Objective: A world-first body image chatbot called KIT was designed. The aim of this study was to assess preliminary acceptability and feasibility via the collection of qualitative feedback from young people and parents/carers regarding the content structure and design of the chatbot in accordance with an agile methodology strategy. The chatbot was developed in collaboration with Australia's national eating disorder support organization the Butterfly Foundation. Methods: A conversation decision tree was designed that offered psychoeducational information on body image and eating disorders as well as evidence-based coping strategies. A version of KIT was built as a research prototype to deliver these conversations. Six focus groups were conducted using online semistructured interviews to seek feedback on the KIT prototype. This included four groups of people seeking help for themselves (n=17 age 13-18 years) and two groups of parents/carers (n=8 age 46-57 years). Participants provided feedback on the cartoon chatbot character design as well as the content structure and design of the chatbot webchat. Results: Thematic analyses identified the following three main themes from the six focus groups: (1) chatbot character and design (2) content presentation and (3) flow. Overall the participants provided positive feedback regarding KIT with both young people and parents/carers generally providing similar reflections. The participants approved of KIT's character and engagement. Specific suggestions were made regarding the brevity and tone to increase KIT's interactivity. Conclusions: Focus groups provided overall positive qualitative feedback regarding the content structure and design of the body image chatbot. Incorporating the feedback of lived experience from both individuals and parents/carers allowed the refinement of KIT in the development phase as per an iterative agile methodology. Further research is required to evaluate KIT's efficacy.;2021
Background: Body image concerns are prevalent among Brazilian adolescents and can lead to poor psychological and physical health. Yet there is a scarcity of culturally-appropriate evidence-based interventions that have been evaluated and made widely available. Chatbot technology (i.e. software that mimics written or spoken human speech) offers an innovative method to increase the scalability of mental health interventions for adolescents. The present protocol outlines the co-creation and evaluation of a body image chatbot for Brazilian adolescents via a partnership between academics industry organisations and the United Nations Children's Fund (UNICEF). Methods: A two-armed fully remote randomised controlled trial will evaluate the chatbot's effectiveness at improving body image and well-being. Adolescent girls and boys (N = 2800) aged 13-18 years recruited online will be randomly allocated (1:1) into either: 1) a body image chatbot or 2) an assessment-only control condition. Adolescents will engage with the chatbot over a 72-hour period on Facebook Messenger. Primary outcomes will assess the immediate and shortterm impact of the chatbot on state- and trait-based body image respectively. Secondary outcomes will include stateand trait-based affect trait self-efficacy and treatment adherence. Discussion: This research is the first to develop an evidence-informed body image chatbot for Brazilian adolescents with the proposed efficacy trial aiming to provide support for accessible scalable and cost-effective interventions that address disparities in body image prevalence and readily available resources.;2021
Background: Cancer genetic testing to assess an individual's cancer risk and to enable genomics-informed cancer treatment has grown exponentially in the past decade. Because of this continued growth and a shortage of health care workers there is a need for automated strategies that provide high-quality genetics services to patients to reduce the clinical demand for genetics providers. Conversational agents have shown promise in managing mental health pain and other chronic conditions and are increasingly being used in cancer genetic services. However research on how patients interact with these agents to satisfy their information needs is limited. Objective: Our primary aim is to assess user interactions with a conversational agent for pretest genetics education. Methods: We conducted a feasibility study of user interactions with a conversational agent who delivers pretest genetics education to primary care patients without cancer who are eligible for cancer genetic evaluation. The conversational agent provided scripted content similar to that delivered in a pretest genetic counseling visit for cancer genetic testing. Outside of a core set of information delivered to all patients users were able to navigate within the chat to request additional content in their areas of interest. An artificial intelligence-based preprogrammed library was also established to allow users to ask open-ended questions to the conversational agent. Transcripts of the interactions were recorded. Here we describe the information selected time spent to complete the chat and use of the open-ended question feature. Descriptive statistics were used for quantitative measures and thematic analyses were used for qualitative responses. Results: We invited 103 patients to participate of which 88.3% (91/103) were offered access to the conversational agent 39% (36/91) started the chat and 32% (30/91) completed the chat. Most users who completed the chat indicated that they wanted to continue with genetic testing (21/30 70%) few were unsure (9/30 30%) and no patient declined to move forward with testing. Those who decided to test spent an average of 10 (SD 2.57) minutes on the chat selected an average of 1.87 (SD 1.2) additional pieces of information and generally did not ask open-ended questions. Those who were unsure spent 4 more minutes on average (mean 14.1 SD 7.41 P=.03) on the chat selected an average of 3.67 (SD 2.9) additional pieces of information and asked at least one open-ended question. Conclusions: The pretest chat provided enough information for most patients to decide on cancer genetic testing as indicated by the small number of open-ended questions. A subset of participants were still unsure about receiving genetic testing and may require additional education or interpersonal support before making a testing decision. Conversational agents have the potential to become a scalable alternative for pretest genetics education reducing the clinical demand on genetics providers.;2021
Background: Chatbots have been used in the last decade to improve access to mental health care services. Perceptions and opinions of patients influence the adoption of chatbots for health care. Many studies have been conducted to assess the perceptions and opinions of patients about mental health chatbots. To the best of our knowledge there has been no review of the evidence surrounding perceptions and opinions of patients about mental health chatbots. Objective: This study aims to conduct a scoping review of the perceptions and opinions of patients about chatbots for mental health. Methods: The scoping review was carried out in line with the PRISMA (Preferred Reporting Items for Systematic reviews and Meta-Analyses) extension for scoping reviews guidelines. Studies were identified by searching 8 electronic databases (eg MEDLINE and Embase) in addition to conducting backward and forward reference list checking of the included studies and relevant reviews. In total 2 reviewers independently selected studies and extracted data from the included studies. Data were synthesized using thematic analysis. Results: Of 1072 citations retrieved 37 unique studies were included in the review. The thematic analysis generated 10 themes from the findings of the studies: usefulness ease of use responsiveness understandability acceptability attractiveness trustworthiness enjoyability content and comparisons. Conclusions: The results demonstrated overall positive perceptions and opinions of patients about chatbots for mental health. Important issues to be addressed in the future are the linguistic capabilities of the chatbots: they have to be able to deal adequately with unexpected user input provide high-quality responses and have to show high variability in responses. To be useful for clinical practice we have to find ways to harmonize chatbot content with individual treatment recommendations that is a personalization of chatbot conversations is required.;2021
Background: Chronic and mental health conditions are increasingly prevalent worldwide. As devices in our everyday lives offer more and more voice-based self-service voice-based conversational agents (VCAs) have the potential to support the prevention and management of these conditions in a scalable manner. However evidence on VCAs dedicated to the prevention and management of chronic and mental health conditions is unclear. Objective: This study provides a better understanding of the current methods used in the evaluation of health interventions for the prevention and management of chronic and mental health conditions delivered through VCAs. Methods: We conducted a systematic literature review using PubMed MEDLINE Embase PsycINFO Scopus and Web of Science databases. We included primary research involving the prevention or management of chronic or mental health conditions through a VCA and reporting an empirical evaluation of the system either in terms of system accuracy technology acceptance or both. A total of 2 independent reviewers conducted the screening and data extraction and agreement between them was measured using Cohen kappa. A narrative approach was used to synthesize the selected records. Results: Of 7170 prescreened papers 12 met the inclusion criteria. All studies were nonexperimental. The VCAs provided behavioral support (n=5) health monitoring services (n=3) or both (n=4). The interventions were delivered via smartphones (n=5) tablets (n=2) or smart speakers (n=3). In 2 cases no device was specified. A total of 3 VCAs targeted cancer whereas 2 VCAs targeted diabetes and heart failure. The other VCAs targeted hearing impairment asthma Parkinson disease dementia autism intellectual disability and depression. The majority of the studies (n=7) assessed technology acceptance but only few studies (n=3) used validated instruments. Half of the studies (n=6) reported either performance measures on speech recognition or on the ability of VCAs to respond to health-related queries. Only a minority of the studies (n=2) reported behavioral measures or a measure of attitudes toward intervention-targeted health behavior. Moreover only a minority of studies (n=4) reported controlling for participants' previous experience with technology. Finally risk bias varied markedly. Conclusions: The heterogeneity in the methods the limited number of studies identified and the high risk of bias show that research on VCAs for chronic and mental health conditions is still in its infancy. Although the results of system accuracy and technology acceptance are encouraging there is still a need to establish more conclusive evidence on the efficacy of VCAs for the prevention and management of chronic and mental health conditions both in absolute terms and in comparison with standard health care.;2021
Background: Chronic Obstructive Pulmonary Disease (COPD) is a leading cause of morbidity and mortality despite evidence there is a high proportion of underdiagnosis. Online screening assessments are low-cost solutions to identify high-risk adults who may benefit from confirmatory screening (ie spirometry test). Little evidence exists to support whether high-risk adults seek advice after completing COPD screening assessments and from whom. The purpose of this study is to examine how the perceived quality of an online screening assessment influences high-risk adults to seek advice from a healthcare provider or other online resources. Methods: Adults without a prior COPD diagnosis (N = 199) completed an online survey that included a computer-tailored assessment programmed with the clinically validated COPD Population Screener (COPD-PS). Results: An elevated COPD risk score was associated with expectations to talk with a healthcare provider (P < 0.05) or go on the Internet (P < 0.05) to get advice controlling for statistically significant covariates. Positive perceptions about the quality of the risk score was associated with strengthened expectations to speak with a healthcare provider but only among high-risk adults (P < 0.01). Conclusions: Results of this study support the use of computer-tailored screening assessments as a scalable solution to encourage high-risk adults to learn more about COPD. Strengthened perceptions about the quality of an online COPD screening assessment increased the likelihood that high-risk adults will speak with their healthcare provider about the condition. Implications are discussed for leveraging telehealth solutions such as conversational agents (ie chatbots) to disseminate COPD screening assessments and alleviate its underdiagnosis.;2021
Background: Conversational agents (CAs) for chronic disease management are receiving increasing attention in academia and the industry. However long-term adherence to CAs is still a challenge and needs to be explored. Personalization of CAs has the potential to improve long-term adherence and with it user satisfaction task efficiency perceived benefits and intended behavior change. Research on personalized CAs has already addressed different aspects such as personalized recommendations and anthropomorphic cues. However detailed information on interaction styles between patients and CAs in the role of medical health care professionals is scant. Such interaction styles play essential roles for patient satisfaction treatment adherence and outcome as has been shown for physician-patient interactions. Currently it is not clear (1) whether chronically ill patients prefer a CA with a paternalistic informative interpretive or deliberative interaction style and (2) which factors influence these preferences. Objective: We aimed to investigate the preferences of chronically ill patients for CA-delivered interaction styles. Methods: We conducted two studies. The first study included a paper-based approach and explored the preferences of chronic obstructive pulmonary disease (COPD) patients for paternalistic informative interpretive and deliberative CA-delivered interaction styles. Based on these results a second study assessed the effects of the paternalistic and deliberative interaction styles on the relationship quality between the CA and patients via hierarchical multiple linear regression analyses in an online experiment with COPD patients. Patients' sociodemographic and disease-specific characteristics served as moderator variables. Results: Study 1 with 117 COPD patients revealed a preference for the deliberative (50/117) and informative (34/117) interaction styles across demographic characteristics. All patients who preferred the paternalistic style over the other interaction styles had more severe COPD (three patients Global Initiative for Chronic Obstructive Lung Disease class 3 or 4). In Study 2 with 123 newly recruited COPD patients younger participants and participants with a less recent COPD diagnosis scored higher on interaction-related outcomes when interacting with a CA that delivered the deliberative interaction style (interaction between age and CA type: relationship quality: b=-0.77 95% CI -1.37 to -0.18 intention to continue interaction: b=-0.49 95% CI -0.97 to -0.01 working alliance attachment bond: b=-0.65 95% CI -1.26 to -0.04 working alliance goal agreement: b=-0.59 95% CI -1.18 to -0.01 interaction between recency of COPD diagnosis and CA type: working alliance goal agreement: b=0.57 95% CI 0.01 to 1.13). Conclusions: Our results indicate that age and a patient's personal disease experience inform which CA interaction style the patient should be paired with to achieve increased interaction-related outcomes with the CA. These results allow the design of personalized health care CAs with the goal to increase long-term adherence to health-promoting behavior.;2021
Background: Digital health agents - embodied conversational agents designed specifically for health interventions - provide a promising alternative or supplement to behavioral health services by reducing barriers to access to care. Objective: Our goals were to (1) develop an expressive speech-enabled digital health agent operating in a 3-dimensional virtual environment to deliver a brief behavioral health intervention over the internet to reduce alcohol use and to (2) understand its acceptability feasibility and utility with its end users. Methods: We developed an expressive speech-enabled digital health agent with facial expressions and body gestures operating in a 3-dimensional virtual office and able to deliver a brief behavioral health intervention over the internet to reduce alcohol use. We then asked 51 alcohol users to report on the digital health agent acceptability feasibility and utility. Results: The developed digital health agent uses speech recognition and a model of empathetic verbal and nonverbal behaviors to engage the user and its performance enabled it to successfully deliver a brief behavioral health intervention over the internet to reduce alcohol use. Descriptive statistics indicated that participants had overwhelmingly positive experiences with the digital health agent including engagement with the technology acceptance perceived utility and intent to use the technology. Illustrative qualitative quotes provided further insight about the potential reach and impact of digital health agents in behavioral health care. Conclusions: Web-delivered interventions delivered by expressive speech-enabled digital health agents may provide an exciting complement or alternative to traditional one-on-one treatment. They may be especially helpful for hard-to-reach communities with behavioral workforce shortages.;2021
Background: Digital therapeutics are evidence-based therapeutic interventions driven by high-quality software programs for the treatment prevention or management of a medical disorder or disease. Many studies in the western population have shown the effectiveness of mobile app-based digital therapeutics for improving glycemic control in patients with type 2 diabetes (T2D). However few studies have assessed similar outcomes in the South Asian population. Objective: This study aims to investigate the real-world effectiveness of the Wellthy CARE digital therapeutic for improving glycemic control among the South Asian population of Indian origin. Methods: We analyzed deidentified data from 102 patients with T2D from India enrolled in a 16-week structured self-management program delivered using the Wellthy CARE mobile app. Patients recorded their meals weight physical activity and blood sugar in the app and they received lessons on self-care behaviors (healthy eating being active monitoring medication adherence problem solving healthy coping and reducing risks) feedback provided by an artificial intelligence-powered chatbot and periodic interactions with certified diabetes educators via voice calls and chats. The primary outcome of the program was a change in glycated hemoglobin A(1c) (HbA(1c)). Secondary outcomes included the difference between preintervention and postintervention fasting blood glucose (FBG) and postprandial blood glucose (PPBG) levels changes in BMI and weight at the completion of 16 weeks and the association between program engagement and the changes in HbA(1c) FBG and PPBG levels. Results: At the end of 16 weeks the average change in HbA(1c) was -0.49% (n=102 95% CI -0.73 to 0.25 P<.001). Of all the patients 63.7% (65/102) had improved HbA(1c) levels with a mean change of -1.16% (n=65 95% CI -1.40 to -0.92 P<.001). The mean preintervention and postintervention FBG levels were 145 mg/dL (n=51 95% CI 135-155) and 134 mg/dL (n=51 95% CI 122-146 P=.02) and PPBG levels were 188 mg/dL (n=51 95% CI 172-203) and 166 mg/dL (n=51 95% CI 153-180 P=.03) respectively. The mean changes in BMI and weight were -0.47 kg/m(2) (n=59 95% CI -0.22 to -0.71 P<.001) and -1.32 kg (n=59 95% CI -0.63 to -2.01 P<.001) respectively. There was a stepwise decrease in HbA(1c) FBG and PPBG levels as the program engagement increased. Patients in the highest tertile of program engagement had a significantly higher reduction in HbA(1c) (-0.84% vs -0.06% P=.02) FBG (-21.4 mg/dL vs -0.18 mg/dL P=.02) and PPBG levels (-22.03 mg/dL vs 2.35 mg/dL P=.002) than those in the lowest tertile. Conclusions: The use of the Wellthy CARE digital therapeutic for patients with T2D showed a significant reduction in the levels of HbA(1c) FBG and PPBG after 16 weeks. A higher level of participation showed improved glycemic control suggesting the potential of the Wellthy CARE platform for better management of the disease.;2021
Background: During the current COVID-19 pandemic alcohol and tobacco are the most available substances for managing stress and can induce a risk of addiction. KANOPEE is a smartphone application available to the general population using an embodied conversational agent (ECA) to screen for experiences of problems with alcohol/tobacco use and to provide follow-up tools for brief intervention. Objectives: This study aimed to determine if the smartphone KANOPEE application could identify people at risk for alcohol and/or tobacco use disorders in the context of the current COVID-19 pandemic to assess adherence to a 7-day follow-up use diary and to evaluate trust and acceptance of the application. Methods: The conversational agent named Jeanne interviewed participants about perceived problems with the use of alcohol and tobacco since the pandemic and explored risk for tobacco and alcohol use disorder with the five-item Cigarette Dependence Scale (CDS-5) and Cut Down Annoyed Guilty Eye-opener  (CAGE) questionnaire and experience of craving for each substance. Descriptive univariate and multivariate analyses were performed to specify personalized associations with reporting a problem with alcohol/tobacco use descriptive analysis reported the experience with the intervention and acceptance and trust in the application. Results: From April 22 to October 26 2020 1588 French participants completed the KANOPEE interview and 318 answered the acceptance and trust scales. Forty-two percent of tobacco users and 27% of alcohol users reported problem use since the pandemic. Positive screening with CDS-5 and CAGE and craving were associated with reported problem use (p < 0.0001). Lockdown period influenced alcohol (p < 0.0005) but not tobacco use (p > 0.05). Eighty-eight percent of users reported that KANOPEE was easy to use and 82% found Jeanne to be trustworthy and credible. Conclusion: KANOPEE was able to screen for risk factors for substance use disorder (SUD) and was acceptable to users. Reporting craving and being at risk for SUD seem to be early markers to be identified. Alcohol problem use seems to be more reliant on contextual conditions such as confinement. This method is able to offer acceptable brief and early intervention with minimal delay for vulnerable people.;2021
Background: Effective treatments for various conditions such as obesity cardiac heart diseases or low back pain require not only personal on-site coaching sessions by health care experts but also a significant amount of home exercises. However nonadherence to home exercises is still a serious problem as it leads to increased costs due to prolonged treatments. Objective: To improve adherence to home exercises we propose implement and assess the novel coaching concept of hybrid ubiquitous coaching (HUC). In HUC health care experts are complemented by a conversational agent (CA) that delivers psychoeducation and personalized motivational messages via a smartphone as well as real-time exercise support monitoring and feedback in a hands-free augmented reality environment. Methods: We applied HUC to the field of physiotherapy and conducted 4 design-and-evaluate loops with an interdisciplinary team to assess how HUC is perceived by patients and physiotherapists and whether HUC leads to treatment adherence. A first version of HUC was evaluated by 35 physiotherapy patients in a lab setting to identify patients' perceptions of HUC. In addition 11 physiotherapists were interviewed about HUC and assessed whether the CA could help them build up a working alliance with their patients. A second version was then tested by 15 patients in a within-subject experiment to identify the ability of HUC to address adherence and to build a working alliance between the patient and the CA. Finally a 4-week n-of-1 trial was conducted with 1 patient to show one experience with HUC in depth and thereby potentially reveal real-world benefits and challenges. Results: Patients perceived HUC to be useful easy to use and enjoyable preferred it to state-of-the-art approaches and expressed their intentions to use it. Moreover patients built a working alliance with the CA. Physiotherapists saw a relative advantage of HUC compared to current approaches but initially did not see the potential in terms of a working alliance which changed after seeing the results of HUC in the field. Qualitative feedback from patients indicated that they enjoyed doing the exercise with an augmented reality based CA and understood better how to do the exercise correctly with HUC. Moreover physiotherapists highlighted that HUC would be helpful to use in the therapy process. The longitudinal field study resulted in an adherence rate of 92% (11/12 sessions 330/360 repetitions 33/36 sets) and a substantial increase in exercise accuracy during the 4 weeks. Conclusions: The overall positive assessments from both patients and health care experts suggest that HUC is a promising tool to be applied in various disorders with a relevant set of home exercises. Future research however must implement a variety of exercises and test HUC with patients suffering from different disorders.;2021
Background: Healthy behaviors are crucial for maintaining a person's health and well-being. The effects of health behavior interventions are mediated by individual and contextual factors that vary over time. Recently emerging smartphone-based ecological momentary interventions (EMIs) can use real-time user reports (ecological momentary assessments [EMAs]) to trigger appropriate support when needed in daily life. Objective: This systematic review aims to assess the characteristics of smartphone-delivered EMIs using self-reported EMAs in relation to their effects on health behaviors user engagement and user perspectives. Methods: We searched MEDLINE Embase PsycINFO and CINAHL in June 2019 and updated the search in March 2020. We included experimental studies that incorporated EMIs based on EMAs delivered through smartphone apps to promote health behaviors in any health domain. Studies were independently screened. The PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines were followed. We performed a narrative synthesis of intervention effects user perspectives and engagement and intervention design and characteristics. Quality appraisal was conducted for all included studies. Results: We included 19 papers describing 17 unique studies and comprising 652 participants. Most studies were quasi-experimental (13/17 76%) had small sample sizes and great heterogeneity in intervention designs and measurements. EMIs were most popular in the mental health domain (8/17 47%) followed by substance abuse (3/17 18%) diet weight loss physical activity (4/17 24%) and smoking (2/17 12%). Of the 17 studies the 4 (24%) included randomized controlled trials reported nonstatistically significant effects on health behaviors and 4 (24%) quasi-experimental studies reported statistically significant pre-post improvements in self-reported primary outcomes namely depressive (P<.001) and psychotic symptoms (P=.03) drinking frequency (P<.001) and eating patterns (P=.01). EMA was commonly used to capture subjective experiences as well as behaviors whereas sensors were rarely used. Generally users perceived EMIs to be helpful. Common suggestions for improvement included enhancing personalization multimedia and interactive capabilities (eg voice recording) and lowering the EMA reporting burden. EMI and EMA components were rarely reported and were not described in a standardized manner across studies hampering progress in this field. A reporting checklist was developed to facilitate the interpretation and comparison of findings and enhance the transparency and replicability of future studies using EMAs and EMIs. Conclusions: The use of smartphone-delivered EMIs using self-reported EMAs to promote behavior change is an emerging area of research with few studies evaluating efficacy. Such interventions could present an opportunity to enhance health but need further assessment in larger participant cohorts and well-designed evaluations following reporting checklists. Future research should explore combining self-reported EMAs of subjective experiences with objective data passively collected via sensors to promote personalization while minimizing user burden as well as explore different EMA data collection methods (eg chatbots). Trial Registration: PROSPERO CRD42019138739 https://www.crd.york.ac.uk/prospero/display_record.php?RecordID=138739;2021
Background: Heart failure (HF) is associated with high mortality rates and high costs and self-care is crucial in the management of the condition. Telehealth can promote patients' self-care while providing frequent feedback to their health care providers about the patient's compliance and symptoms. A number of technologies have been considered in the literature to facilitate telehealth in patients with HF. An important factor in the adoption of these technologies is their ease of use. Conversational agent technologies using a voice interface can be a good option because they use speech recognition to communicate with patients. Objective: The aim of this paper is to study the engagement of patients with HF with voice interface technology. In particular we investigate which patient characteristics are linked to increased technology use. Methods: We used data from two separate HF patient groups that used different telehealth technologies over a 90-day period. Each group used a different type of voice interface however the scripts followed by the two technologies were identical. One technology was based on Amazon's Alexa (Alexa+) and in the other technology patients used a tablet to interact with a visually animated and voice-enabled avatar (Avatar). Patient engagement was measured as the number of days on which the patients used the technology during the study period. We used multiple linear regression to model engagement with the technology based on patients' demographic and clinical characteristics and past technology use. Results: In both populations the patients were predominantly male and Black had an average age of 55 years and had HF for an average of 7 years. The only patient characteristic that was statistically different (P=.008) between the two populations was the number of medications they took to manage HF with a mean of 8.7 (SD 4.0) for Alexa+ and 5.8 (SD 3.4) for Avatar patients. The regression model on the combined population shows that older patients used the technology more frequently (an additional 1.19 days of use for each additional year of age P=.004). The number of medications to manage HF was negatively associated with use (-5.49 P=.005) and Black patients used the technology less frequently than other patients with similar characteristics (-15.96 P=.08). Conclusions: Older patients' higher engagement with telehealth is consistent with findings from previous studies confirming the acceptability of technology in this subset of patients with HF. However we also found that a higher number of HF medications which may be correlated with a higher disease burden is negatively associated with telehealth use. Finally the lower engagement of Black patients highlights the need for further study to identify the reasons behind this lower engagement including the possible role of social determinants of health and potentially create technologies that are better tailored for this population.;2021
Background: HIV self-testing (HIVST) is recommended by the WHO as an innovative strategy to reach UNAIDS targets to end HIV by 2030. HIVST with digital supports is defined as the use of digital interventions (e.g. website-based social media mobile HIVST applications (apps) text messaging (SMS) digital vending machines (digital VMs)) to improve the efficiency and impact of HIVST. HIVST deployment and integration in health services is an emerging priority. We conducted a systematic review aiming to close the gap in evidence that summarizes the impact of digitally supported HIVST and to inform policy recommendations. Methods: We searched PubMed and Embase for articles and abstracts on HIVST with digital supports published during the period February 1st 2010 to June 15th 2021 following Cochrane guidelines and PRISMA methodology. We assessed feasibility acceptability preference and impact outcomes across all populations and study designs. Metrics reported were willingness to use HIVST preferences for HIVST delivery proportion of first-time testers HIVST uptake HIVST kit return rate and linkage to care. Heterogeneity of the interventions and reported metrics precluded us from conducting a meta-analysis. Findings: 46 studies were narratively synthesized of which 72% were observational and 28% were RCTs. Half of all studies (54% 25/46) assessed web-based innovations (e.g. study websites videos chatbots) followed by social media (26% 12/46) HIVST-specific apps (7% 3/46) SMS (9% 4/46) and digital VMs (4% 2/46). Web based innovations were found to be acceptable (77-97%) preferred over in-person and hybrid options by more first-time testers (47-48%) highly feasible (93-95%) and were overall effective in supporting linkage to care (53-100%). Social media and app-based innovations also had high acceptability (87-95%) and linkage to care proportions (80-100%). SMS innovations increased kit return rates (54-94%) and HIVST uptake among hard-to-reach groups. Finally digital VMs were highly acceptable (54-93%) and HIVST uptake was six times greater when using digital VMs compared to distribution by community workers. Interpretation: HIVST with digital supports was deemed feasible acceptable preferable and was shown to increase uptake engage first-time testers and hard-to-reach populations and successfully link participants to treatment. Findings pave the way for greater use of HIVST interventions with digital supports globally. Funding: This work was funded by the Foundation for Innovative New Diagnostics. The agency had no role in the decision to submit it for publication however the funders contributing to the writing of the manuscript. NPP also acknowledges support from the Fonds de recherche du Quebec Sante (Senior scientist scholar award) The Canadian Institutes of Health Research (PJT 153149 and HBR 422155) Grand Challenges Canada (Transition to Scale award 071005) the India-Canada centre for Innovative Multidisciplinary Partnerships to Accelerate Community Transformation and Sustainability (IC-IMPACTS) and the MUHC Foundation. (c) 2021 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/);2021
Background: In recent years digital tools have become a viable means for patients to address their health and information needs. Governments and health care organizations are offering digital tools such as self-assessment tools symptom tracking tools or chatbots. Other sources of digital tools such as those offered through patient platforms are available on the internet free of charge. We define patient platforms as health-specific websites that offer tools to anyone with internet access to engage them in their health care process with peer networks to support their learning. Although numerous social media platforms engage users without up-front charges patient platforms are specific to health. As little is known about their business model there is a need to understand what else these platforms are trying to achieve beyond supporting patients so that patients can make informed decisions about the benefits and risks of using the digital tools they offer. Objective: The aim of this study is to explore what patient platforms are trying to achieve beyond supporting patients and how their digital tools can be used to generate income. Methods: Textual and visual data collected from a purposeful selection of 11 patient platforms from September 2013 to August 2014 were analyzed using framework analysis. Data were systematically and rigorously coded and categorized according to key issues and themes by following 5 steps . familiarizing identifying a thematic framework indexing charting and mapping and interpretation. We used open coding to identify additional concepts not captured in the initial thematic framework. This paper reports on emergent findings on the business models of the platforms and their income-generating processes. Results: Our analysis revealed that in addition to patients the platforms support other parties with interests in health and information exchanges. Patient platforms did not charge up-front fees but generated income from other sources such as advertising sponsorship marketing (eg sending information to users on behalf of sponsors or providing means for sponsors to reach patients directly) supporting other portals and providing research services. Conclusions: This study reports on the mechanisms by which some patient platforms generate income to support their operations gain profit or both. Although income-generating processes exist elsewhere on social media platforms in general they pose unique challenges in the health context because digital tools engage patients in health and information exchanges. This study highlights the need to minimize the potential for unintended consequences that can pose health risks to patients or can lead to increased health expenses. By understanding other interests that patient platforms support our findings point to important policy implications such as whether (and how) authorities might protect users from processes that may not always be in their best interests and can potentially incur costs to the health system.;2021
Background: Information and communication technologies are tools that are able to support cognitive functions monitor health and movements provide reminders to maintain residual memory abilities and promote social support especially among patients with dementia. Among these technologies embodied conversational agents (ECAs) are seen as screen-based entities designed to stimulate human face-to-face conversation skills allowing for natural human-machine interaction. Unfortunately the evidence that such agents deliver care benefits in supporting people affected by dementia and their caregivers has not yet been well studied. Therefore research in this area is essential for the entire scientific community. Objective: This study aims to evaluate the usability and acceptability of the virtual agent Anne by people living with dementia. The study is also designed to assess the ability of target users to use the system independently and receive valuable information from it. Methods: We conducted a 4-week trial that involved 20 older adults living with dementia and 14 family caregivers in home environment settings in Italy. This study used a mixed methods approach balancing quantitative and qualitative instruments to gather data from users. Telemetry data were also collected. Results: Older users were particularly engaged in providing significant responses and participating in system improvements. Some of them clearly discussed how technical problems related to speech recognition had a negative impact on the intention to use adaptiveness usefulness and trust. Moreover the usability of the system achieved an encouraging score and half of the sample recognized a role of the agent Anne. This study confirms that the quality of automatic speech recognition and synthesis is still a technical issue and has room for improvement whereas the touch screen modality is almost stable and positively used by patients with dementia. Conclusions: This study demonstrated the ability of target users to use the system independently in their home environment overall the involved participants shared good engagement with the system approaching the virtual agents as a companion able to support memory and enjoyment needs. Therefore this research provides data that sustain the use of ECAs as future eHealth systems that are able to address the basic and higher-level needs of people living with dementia. This specific field of research is novel and poorly discussed in the scientific community. This could be because of its novelty yet there is an urgent need to strengthen data research and innovation to accelerate the implementation of ECAs as a future method to offer nonpharmacological support to community-dwelling people with dementia.;2021
Background: It is encouraging to see a substantial increase in individuals surviving cancer. Even more so since most of them will have a positive effect on society by returning to work. However many cancer survivors have unmet needs especially when it comes to improving their quality of life (QoL). Only few survivors are able to meet all of the recommendations regarding well-being and there is a body of evidence that cancer survivors' needs often remain neglected from health policy and national cancer control plans. This increases the impact of inequalities in cancer care and adds a dangerous component to it. The inequalities affect the individual survivor their career along with their relatives and society as a whole. The current study will evaluate the impact of the use of big data analytics and artificial intelligence on the self-efficacy of participants following intervention supported by digital tools. The secondary endpoints include evaluation of the impact of patient trajectories (from retrospective data) and patient gathered health data on prediction and improved intervention against possible secondary disease or negative outcomes (e.g. late toxicities fatal events). Methods/design: The study is designed as a single-case experimental prospective study where each individual serves as its own control group with basal measurements obtained at the recruitment and subsequent measurements performed every 6 months during follow ups. The measurement will involve CASE-cancer Patient Activation Measure and System Usability Scale. The study will involve 160 survivors (80 survivors of Breast Cancer and 80 survivors of Colorectal Cancer) from four countries Belgium Latvia Slovenia and Spain. The intervention will be implemented via a digital tool (mHealthApplication) collecting objective biomarkers (vital signs) and subjective biomarkers (PROs) with the support of a (embodied) conversational agent. Additionally the Clinical Decision Support system (CDSS) including visualization of cohorts and trajectories will enable oncologists to personalize treatment for an efficient care plan and follow-up management. Discussion: We expect that cancer survivors will significantly increase their self-efficacy following the personalized intervention supported by the m-HealthApplication compared to control measurements at recruitment. We expect to observe improvement in healthy habits disease self-management and self-perceived QoL.;2021
Background: Loneliness is a growing public health issue that has been exacerbated in vulnerable groups during the COVID-19 pandemic. Computer agents are capable of delivering psychological therapies through the internet however there is limited research on their acceptability to date. Objective: The objectives of this study were to evaluate (1) the feasibility and acceptability of a remote loneliness and stress intervention with digital human delivery to at-risk adults and (2) the feasibility of the study methods in preparation for a randomized controlled trial. Methods: A parallel randomized pilot trial with a mixed design was conducted. Participants were adults aged 18 to 69 years with an underlying medical condition or aged 70 years or older with a Mini-Mental State Examination score of >24 (ie at greater risk of developing severe COVID-19). Participants took part from their place of residence (independent living retirement village 20 community dwelling 7 nursing home 3). Participants were randomly allocated to the intervention or waitlist control group that received the intervention 1 week later. The intervention involved completing cognitive behavioral and positive psychology exercises with a digital human facilitator on a website for at least 15 minutes per day over 1 week. The exercises targeted loneliness stress and psychological well-being. Feasibility was evaluated using dropout rates and behavioral observation data. Acceptability was evaluated from behavioral engagement data the Friendship Questionnaire (adapted) self-report items and qualitative questions. Psychological measures were administered to evaluate the feasibility of the trial methods and included the UCLA Loneliness Scale the 4-item Perceived Stress Scale a 1-item COVID-19 distress measure the Flourishing Scale and the Scale of Positive and Negative Experiences. Results: The study recruited 30 participants (15 per group). Participants were 22 older adults and 8 younger adults with a health condition. Six participants dropped out of the study. Thus the data of 24 participants were analyzed (intervention group 12 waitlist group 12). The digital human intervention and trial methods were generally found to be feasible and acceptable in younger and older adults living independently based on intervention completion and behavioral qualitative and some self-report data. The intervention and trial methods were less feasible to nursing home residents who required caregiver assistance. Acceptability could be improved with additional content tailoring to the population and changes to the digital human's design. Conclusions: Digital humans are a promising and novel technological solution for providing at-risk adults with access to remote psychological support during the COVID-19 pandemic. Research should further examine design techniques to improve their acceptability in this application and investigate intervention effectiveness in a randomized controlled trial.;2021
Background: Misuse of substances is common can be serious and costly to society and often goes untreated due to barriers to accessing care. Woebot is a mental health digital solution informed by cognitive behavioral therapy and built upon an artificial intelligence-driven platform to deliver tailored content to users. In a previous 2-week randomized controlled trial Woebot alleviated depressive symptoms. Objective: This study aims to adapt Woebot for the treatment of substance use disorders (W-SUDs) and examine its feasibility acceptability and preliminary efficacy. Methods: American adults (aged 18-65 years) who screened positive for substance misuse without major health contraindications were recruited from online sources and flyers and enrolled between March 27 and May 6 2020. In a single-group pre/postdesign all participants received W-SUDs for 8 weeks. W-SUDs provided mood craving and pain tracking and modules (psychoeducational lessons and psychotherapeutic tools) using elements of dialectical behavior therapy and motivational interviewing. Paired samples t tests and McNemar nonparametric tests were used to examine within-subject changes from pre- to posttreatment on measures of substance use confidence cravings mood and pain. Results: The sample (N=101) had a mean age of 36.8 years (SD 10.0) and 75.2% (76/101) of the participants were female 78.2% (79/101) were non-Hispanic White and 72.3% (73/101) were employed. Participants' W-SUDs use averaged 15.7 (SD 14.2) days 12.1 (SD 8.3) modules and 600.7 (SD 556.5) sent messages. About 94% (562/598) of all completed psychoeducational lessons were rated positively. From treatment start to end in-app craving ratings were reduced by half (87/101 86.1% reporting cravings in the app odds ratio 0.48 95% CI 0.32-0.73). Posttreatment assessment completion was 50.5% (51/101) with better retention among those who initially screened higher on substance misuse. From pre- to posttreatment confidence to resist urges to use substances significantly increased (mean score change +16.9 SD 21.4 P<.001) whereas past month substance use occasions (mean change -9.3 SD 14.1 P<.001) and scores on the Alcohol Use Disorders Identification Test-Concise (mean change -1.3 SD 2.6 P<.001) 10-item Drug Abuse Screening Test (mean change -1.2 SD 2.0 P<.001) Patient Health Questionnaire-8 item (mean change 2.1 SD 5.2 P=.005) Generalized Anxiety Disorder-7 (mean change -2.3 SD 4.7 P=.001) and cravings scale (68.6% vs 47.1% moderate to extreme P=.01) significantly decreased. Most participants would recommend W-SUDs to a friend (39/51 76%) and reported receiving the service they desired (41/51 80%). Fewer felt W-SUDs met most or all of their needs (22/51 43%). Conclusions: W-SUDs was feasible to deliver engaging and acceptable and was associated with significant improvements in substance use confidence cravings depression and anxiety. Study attrition was high. Future research will evaluate W-SUDs in a randomized controlled trial with a more diverse sample and with the use of greater study retention strategies.;2021
Background: Musculoskeletal symptoms such as neck and shoulder pain/stiffness and low back pain are common health problems in the working population. They are the leading causes of presenteeism (employees being physically present at work but unable to be fully engaged). Recently digital interventions have begun to be used to manage health but their effectiveness has not yet been fully verified and adherence to such programs is always a problem. Objective: This study aimed to evaluate the improvements in musculoskeletal symptoms in workers with neck/shoulder stiffness/pain and low back pain after the use of an exercise-based artificial intelligence (AI)-assisted interactive health promotion system that operates through a mobile messaging app (the AI-assisted health program). We expected that this program would support participants' adherence to exercises. Methods: We conducted a two-armed randomized controlled and unblinded trial in workers with either neck/shoulder stiffness/pain or low back pain or both. We recruited participants with these symptoms through email notifications. The intervention group received the AI-assisted health program in which the chatbot sent messages to users with the exercise instructions at a fixed time every day through the smartphone's chatting app (LINE) for 12 weeks. The program was fully automated. The control group continued with their usual care routines. We assessed the subjective severity of the neck and shoulder pain/stiffness and low back pain of the participants by using a scoring scale of 1 to 5 for both the intervention group and the control group at baseline and after 12 weeks of intervention by using a web-based form. We used a logistic regression model to calculate the odds ratios (ORs) of the intervention group to achieve to reduce pain scores with those of the control group and the ORs of the subjective assessment of the improvement of the symptoms compared to the intervention and control groups which were performed using Stata software (version 16 StataCorp LLC). Results: We analyzed 48 participants in the intervention group and 46 participants in the control group. The adherence rate was 92% (44/48) during the intervention. The participants in the intervention group showed significant improvements in the severity of the neck/shoulder pain/stiffness and low back pain compared to those in the control group (OR 6.36 95% CI 2.57-15.73 P<.001). Based on the subjective assessment of the improvement of the pain/stiffness at 12 weeks 36 (75%) out of 48 participants in the intervention group and 3 (7%) out of 46 participants in the control group showed improvements (improved slightly improved) (OR 43.00 95% CI 11.25-164.28 P<.001). Conclusions: This study shows that the short exercises provided by the AI-assisted health program improved both neck/shoulder pain/stiffness and low back pain in 12 weeks. Further studies are needed to identify the elements contributing to the successful outcome of the AI-assisted health program.;2021
Background: Noncommunicable diseases (NCDs) constitute a burden on public health. These are best controlled through self-management practices such as self-information. Fostering patients' access to health-related information through efficient and accessible channels such as commercial voice assistants (VAs) may support the patients' ability to make health-related decisions and manage their chronic conditions. Objective: This study aims to evaluate the reliability of the most common VAs (ie Amazon Alexa Apple Siri and Google Assistant) in responding to questions about management of the main NCD. Methods: We generated health-related questions based on frequently asked questions from health organization government medical nonprofit and other recognized health-related websites about conditions associated with Alzheimer's disease (AD) lung cancer (LCA) chronic obstructive pulmonary disease diabetes mellitus (DM) cardiovascular disease chronic kidney disease (CKD) and cerebrovascular accident (CVA). We then validated them with practicing medical specialists selecting the 10 most frequent ones. Given the low average frequency of the AD-related questions we excluded such questions. This resulted in a pool of 60 questions. We submitted the selected questions to VAs in a 3x3x6 fractional factorial design experiment with 3 developers (ie Amazon Apple and Google) 3 modalities (ie voice only voice and display display only) and 6 diseases. We assessed the rate of error-free voice responses and classified the web sources based on previous research (ie expert commercial crowdsourced or not stated). Results: Google showed the highest total response rate followed by Amazon and Apple. Moreover although Amazon and Apple showed a comparable response rate in both voice-and-display and voice-only modalities Google showed a slightly higher response rate in voice only. The same pattern was observed for the rate of expert sources. When considering the response and expert source rate across diseases we observed that although Google remained comparable with a slight advantage for LCA and CKD both Amazon and Apple showed the highest response rate for LCA. However both Google and Apple showed most often expert sources for CVA while Amazon did so for DM. Conclusions: Google showed the highest response rate and the highest rate of expert sources leading to the conclusion that Google Assistant would be the most reliable tool in responding to questions about NCD management. However the rate of expert sources differed across diseases. We urge health organizations to collaborate with Google Amazon and Apple to allow their VAs to consistently provide reliable answers to health-related questions on NCD management across the different diseases.;2021
Background: Obesity and overweight are a serious health problem worldwide with multiple and connected causes. Simultaneously chatbots are becoming increasingly popular as a way to interact with users in mobile health apps. Objective: This study reports the user-centered design and feasibility study of a chatbot to collect linked data to support the study of individual and social overweight and obesity causes in populations. Methods: We first studied the users' needs and gathered users' graphical preferences through an open survey on 52 wireframes designed by 150 design students it also included questions about sociodemographics diet and activity habits the need for overweight and obesity apps and desired functionality. We also interviewed an expert panel. We then designed and developed a chatbot. Finally we conducted a pilot study to test feasibility. Results: We collected 452 answers to the survey and interviewed 4 specialists. Based on this research we developed a Telegram chatbot named Wakamola structured in six sections: personal diet physical activity social network user's status score and project information. We defined a user's status score as a normalized sum (0-100) of scores about diet (frequency of eating 50 foods) physical activity BMI and social network. We performed a pilot to evaluate the chatbot implementation among 85 healthy volunteers. Of 74 participants who completed all sections we found 8 underweight people (11%) 5 overweight people (7%) and no obesity cases. The mean BMI was 21.4 kg/m(2) (normal weight). The most consumed foods were olive oil milk and derivatives cereals vegetables and fruits. People walked 10 minutes on 5.8 days per week slept 7.02 hours per day and were sitting 30.57 hours per week. Moreover we were able to create a social network with 74 users 178 relations and 12 communities. Conclusions: The Telegram chatbot Wakamola is a feasible tool to collect data from a population about sociodemographics diet patterns physical activity BMI and specific diseases. Besides the chatbot allows the connection of users in a social network to study overweight and obesity causes from both individual and social perspectives.;2021
Background: Patients with irritable bowel syndrome (IBS) experience abdominal pain altered bowel habits and defecation-related anxiety which can result in reduced productivity and impaired health-related quality of life (HRQL). Cognitive behavioral therapy (CBT) has been shown to reduce symptoms of IBS and to improve HRQL but access to qualified therapists is limited. Smartphone-based digital therapeutic interventions have potential to increase access to guided CBT at scale but require careful study to assess their benefits and risks. Objective: The aim of this study was to test the efficacy of a novel app Zemedy as a mobile digital therapeutic that delivers a comprehensive CBT program to individuals with IBS. Methods: This was a crossover randomized controlled trial. Participants were recruited online and randomly allocated to either immediate treatment (n=62) or waitlist control (n=59) groups. The Zemedy app consists of 8 modules focusing on psychoeducation relaxation training exercise the cognitive model of stress management applying CBT to IBS symptoms reducing avoidance through exposure therapy behavioral experiments and information about diet. Users interact with a chatbot that presents the information and encourages specific plans homework and exercises. The treatment was fully automated with no therapist involvement or communication. At baseline and after 8 weeks participants were asked to complete the battery of primary (Irritable Bowel Syndrome Quality of Life [IBS-QOL] Gastrointestinal Symptom Rating Scale [GSRS]) and secondary (Fear of Food Questionnaire [FFQ] Visceral Sensitivity Index [VSI] Gastrointestinal Cognition Questionnaire [GI-COG] Depression Anxiety Stress Scale [DASS] and Patient Health Questionnaire-9 [PHQ-9]) outcome measures. Waitlist controls were then offered the opportunity to crossover to treatment. All participants were assessed once more at 3 months posttreatment. Results: Both intention-to-treat and completer analyses at posttreatment revealed significant improvement for the immediate treatment group compared to the waitlist control group on both primary and secondary outcome measures. Gains were generally maintained at 3 months posttreatment. Scores on the GSRS IBS-QoL GI-COG VSI and FFQ all improved significantly more in the treatment group (F-1F-79=20.49 P<.001 Cohen d=1.01 F-1F-79=20.12 P<.001 d=1.25 F-1F-79=34.71 P<.001 d=1.47 F-1F-79=18.7 P<.001 d=1.07 and F-1F-79=12.13 P=.001 d=0.62 respectively). Depression improved significantly as measured by the PHQ-9 (F-1F-79=10.5 P=.002 d=1.07) and the DASS Depression (F-1F-79=6.03 P=.02 d=.83) and Stress (F-1F-79=4.47 P=.04 d=0.65) subscales in the completer analysis but not in the intention-to-treat analysis. The impact of treatment on HRQL was mediated by reductions in catastrophizing and visceral sensitivity. Conclusions: Despite its relatively benign physical profile IBS can be an extraordinarily debilitating condition. Zemedy is an effective modality to deliver CBT for individuals with IBS and could increase accessibility of this evidence-based treatment.;2021
Background: Prior studies have demonstrated the safety risks when patients and consumers use conversational assistants such as Apple's Sin and Amazon's Alexa for obtaining medical information. Objective: The aim of this study is to evaluate two approaches to reducing the likelihood that patients or consumers will act on the potentially harmful medical information they receive from conversational assistants. Methods: Participants were given medical problems to pose to conversational assistants that had been previously demonstrated to result in potentially harmful recommendations. Each conversational assistant's response was randomly varied to include either a correct or incorrect paraphrase of the query or a disclaimer message-or not-telling the participants that they should not act on the advice without first talking to a physician. The participants were then asked what actions they would take based on their interaction along with the likelihood of taking the action. The reported actions were recorded and analyzed and the participants were interviewed at the end of each interaction. Results: A total of 32 participants completed the study each interacting with 4 conversational assistants. The participants were on average aged 42.44 (SD 14.08) years 53% (17/32) were women and 66% (21/32) were college educated. Those participants who heard a correct paraphrase of their query were significantly more likely to state that they would follow the medical advice provided by the conversational assistant (chi(2)(1)=3.1 P=.04). Those participants who heard a disclaimer message were significantly more likely to say that they would contact a physician or health professional before acting on the medical advice received (chi(2)(1)=43.5 P=.001). Conclusions: Designers of conversational systems should consider incorporating both disclaimers and feedback on query understanding in response to user queries for medical advice. Unconstrained natural language input should not be used in systems designed specifically to provide medical advice.;2021
Background: Recent years have witnessed a constant increase in the number of people with chronic conditions requiring ongoing medical support in their everyday lives. However global health systems are not adequately equipped for this extraordinarily time-consuming and cost-intensive development. Here conversational agents (CAs) can offer easily scalable and ubiquitous support. Moreover different aspects of CAs have not yet been sufficiently investigated to fully exploit their potential. One such trait is the interaction style between patients and CAs. In human-to-human settings the interaction style is an imperative part of the interaction between patients and physicians. Patient-physician interaction is recognized as a critical success factor for patient satisfaction treatment adherence and subsequent treatment outcomes. However so far it remains effectively unknown how different interaction styles can be implemented into CA interactions and whether these styles are recognizable by users. Objective: The objective of this study was to develop an approach to reproducibly induce 2 specific interaction styles into CA-patient dialogs and subsequently test and validate them in a chronic health care context. Methods: On the basis of the Roter Interaction Analysis System and iterative evaluations by scientific experts and medical health care professionals we identified 10 communication components that characterize the 2 developed interaction styles: deliberative and paternalistic interaction styles. These communication components were used to develop 2 CA variations each representing one of the 2 interaction styles. We assessed them in a web-based between-subject experiment. The participants were asked to put themselves in the position of a patient with chronic obstructive pulmonary disease. These participants were randomly assigned to interact with one of the 2 CAs and subsequently asked to identify the respective interaction style. Chi-square test was used to assess the correct identification of the CA-patient interaction style. Results: A total of 88 individuals (42/88 48% female mean age 31.5 years SD 10.1 years) fulfilled the inclusion criteria and participated in the web-based experiment. The participants in both the paternalistic and deliberative conditions correctly identified the underlying interaction styles of the CAs in more than 80% of the assessments (X-1(8)8(2)=38.2 P<.001 phi coefficient r(phi)=0.68). The validation of the procedure was hence successful. Conclusions: We developed an approach that is tailored for a medical context to induce a paternalistic and deliberative interaction style into a written interaction between a patient and a CA. We successfully tested and validated the procedure in a web-based experiment involving 88 participants. Future research should implement and test this approach among actual patients with chronic diseases and compare the results in different medical conditions. This approach can further be used as a starting point to develop dynamic CAs that adapt their interaction styles to their users.;2021
Background: Regular physical activity (PA) is crucial for well-being however healthy habits are difficult to create and maintain. Interventions delivered via conversational agents (eg chatbots or virtual agents) are a novel and potentially accessible way to promote PA. Thus it is important to understand the evolving landscape of research that uses conversational agents. Objective: This mixed methods systematic review aims to summarize the usability and effectiveness of conversational agents in promoting PA describe common theories and intervention components used and identify areas for further development. Methods: We conducted a mixed methods systematic review. We searched seven electronic databases (PsycINFO PubMed Embase CINAHL ACM Digital Library Scopus and Web of Science) for quantitative qualitative and mixed methods studies that conveyed primary research on automated conversational agents designed to increase PA. The studies were independently screened and their methodological quality was assessed using the Mixed Methods Appraisal Tool by 2 reviewers. Data on intervention impact and effectiveness treatment characteristics and challenges were extracted and analyzed using parallel-results convergent synthesis and narrative summary. Results: In total 255 studies were identified 7.8% (20) of which met our inclusion criteria. The methodological quality of the studies was varied. Overall conversational agents had moderate usability and feasibility. Those that were evaluated through randomized controlled trials were found to be effective in promoting PA. Common challenges facing interventions were repetitive program content high attrition technical issues and safety and privacy concerns. Conclusions: Conversational agents hold promise for PA interventions. However there is a lack of rigorous research on long-term intervention effectiveness and patient safety. Future interventions should be based on evidence-informed theories and treatment approaches and should address users' desires for program variety natural language processing delivery via mobile devices and safety and privacy concerns.;2021
Background: Retirement is recognized as a factor influencing the ageing process. Today virtual health coaching systems can play a pivotal role in supporting older adults' active and healthy ageing. This study wants to answer two research questions: (1) What are the user requirements of a virtual coach (VC) based on an Embodied Conversational Agent (ECA) for motivating older adults in transition to retirement to adopt a healthy lifestyle? (2) How could a VC address the active and healthy ageing dimensions even during COVID-19 times? Methods: Two-wave focus-groups with 60 end-users aged 55 and over and 27 follow-up telephone interviews were carried out in Austria Italy and the Netherlands in 2019-2020. Qualitative data were analysed by way of framework analysis. Results: End-users suggest the VC should motivate older workers and retirees to practice physical activity maintain social contacts and emotional well-being. The ECA should be reactive customizable expressive sympathetic not directive nor patronizing with a pleasant and motivating language. The COVID-19 outbreak increased the users' need for functions boosting community relationships and promoting emotional well-being. Conclusions: the VC can address the active and healthy ageing paradigm by increasing the chances of doing low-cost healthy activities at any time and in any place.;2021
Background: Software agents are computer-programs that conduct conversations with a human. The present study evaluates the feasibility of the software agent ?SISU? aiming to uplift psychological wellbeing. Methods: Within a one-group pretest-posttest trial N = 30 German-speaking participants were recruited. Assessments took place before (t1) during (t2) and after (t3) the intervention. The ability of SISU to guide participants through the intervention acceptability and negative effects were investigated. Data analyses are based on intention-to-treat principles. Linear mixed models will be used to investigate short-term changes over time in mood depression anxiety. Intervention: The intervention consists of two sessions. Each session comprises writing tasks on autobiographical negative life events and an Acceptance- and Commitment Therapy-based exercise respectively. Participants interact with the software agent on two consecutive days for about 30 min each. Results: All participants completed all sessions within two days. User experience was positive with all subscales of the user experience questionnaire (UEQ) M > 0.8. Participants experienced their writings as highly selfrelevant and personal. However 57% of the participants reported at least one negative effect attributed to the intervention. Results on linear mixed models indicate an increase in anxiety over time (? = 1.33 p = .001). Qualitative User Feedback revealed that the best thing about SISU was its innovativeness (13%) and anonymity (13%). As worst thing about SISU participants indicated that the conversational style of SISU often felt unnatural (73%). Conclusion: SISU successfully guided participants through the two-day intervention. Moreover SISU has the potential to enter the inner world of participants. However intervention contents have the potential to evoke negative effects in individuals. Expectable short-term symptom deterioration due to writing about negative autobiographical life events could not be prevented by acceptance and commitment therapy-based exercises. Hence results suggest a revision of intervention contents as well as of the conversational style of SISU. The good adherence rate indicates the useful and acceptable format of SISU as a mental health chatbot. Overall little is known about the effectiveness of software agents in the context of psychological wellbeing. Results of the present trial underline that the innovative technology bears the potential of SISU to act as therapeutic agent but should not be used with its current intervention content. Trial-registration: The Trial is registered at the WHO International Clinical Trials Registry Platform via the German Clinical Studies Register (DRKS): DRKS00014933 (date of registration: 20.06.2018). Link: https://www. drks.de/drks_web/navigate.do?navigationId=trial.HTML&TRIAL_ID=DRKS00014933.;2021
Background: Successful management of chronic diseases requires a trustful collaboration between health care professionals patients and family members. Scalable conversational agents designed to assist health care professionals may play a significant role in supporting this collaboration in a scalable way by reaching out to the everyday lives of patients and their family members. However to date it remains unclear whether conversational agents in such a role would be accepted and whether they can support this multistakeholder collaboration. Objective: With asthma in children representing a relevant target of chronic disease management this study had the following objectives: (1) to describe the design of MAX a conversational agent-delivered asthma intervention that supports health care professionals targeting child-parent teams in their everyday lives and (2) to assess the (a) reach of MAX (b) conversational agent-patient working alliance (c) acceptance of MAX (d) intervention completion rate (e) cognitive and behavioral outcomes and (f) human effort and responsiveness of health care professionals in primary and secondary care settings. Methods: MAX was designed to increase cognitive skills (ie knowledge about asthma) and behavioral skills (ie inhalation technique) in 10-15-year-olds with asthma and enables support by a health professional and a family member. To this end three design goals guided the development: (1) to build a conversational agent-patient working alliance (2) to offer hybrid (humanand conversational agent-supported) ubiquitous coaching and (3) to provide an intervention with high experiential value. An interdisciplinary team of computer scientists asthma experts and young patients with their parents developed the intervention collaboratively. The conversational agent communicates with health care professionals via email with patients via a mobile chat app and with a family member via SMS text messaging. A single-arm feasibility study in primary and secondary care settings was performed to assess MAX. Results: Results indicated an overall positive evaluation of MAX with respect to its reach (49.5% 49/99 of recruited and eligible patient-family member teams participated) a strong patient-conversational agent working alliance and high acceptance by all relevant stakeholders. Moreover MAX led to improved cognitive and behavioral skills and an intervention completion rate of 75.5%. Family members supported the patients in 269 out of 275 (97.8%) coaching sessions. Most of the conversational turns (99.5%) were conducted between patients and the conversational agent as opposed to between patients and health care professionals thus indicating the scalability of MAX. In addition it took health care professionals less than 4 minutes to assess the inhalation technique and 3 days to deliver related feedback to the patients. Several suggestions for improvement were made. Conclusions: This study provides the first evidence that conversational agents designed as mediating social actors involving health care professionals patients and family members are not only accepted in such a team player role but also show potential to improve health-relevant outcomes in chronic disease management.;2021
Background: The COVID-19 pandemic disrupted access to treatment for substance use disorders (SUDs) while alcohol and cannabis retail sales increased. During the pandemic we tested a tailored digital health solution Woebot-SUDs (W-SUDs) for reducing substance misuse. Methods: In a randomized controlled trial we compared W-SUDs for 8 weeks to a waitlist control. U.S. adults (N = 180) who screened positive for substance misuse (CAGE-AID>1) were enrolled June-August 2020. The pri-mary outcome was the change in past-month substance use occasions from baseline to end-of-treatment (EOT). Study retention was 84%. General linear models tested group differences in baseline-to-EOT change scores adjusting for baseline differences and attrition. Results: At baseline the sample (age M = 40 SD = 12 65% female 68% non-Hispanic white) averaged 30.2 (SD = 18.6) substance occasions in the past month. Most (77%) reported alcohol problems 28% cannabis and 45% multiple substances 46% reported moderate-to-severe depressive symptoms. Treatment participants averaged 920 in-app text messages (SD = 892 Median = 701) 96% of completed lessons were rated positively and 88% would recommend W-SUDs. Relative to waitlist W-SUDs participants significantly reduced past-month substance use occasions (M = -9.1 SE = 2.0 vs. M = -3.3 SE = 1.8 p = .039). Secondary substance use and mood outcomes did not change significantly by group however reductions in substance use occasions correlated significantly with increased confidence and fewer substance use problems cravings depression and anxiety symptoms and pandemic-related mental health effects (p-value<.05). Conclusions: W-SUDs was associated with significant reductions in substance use occasions. Reduction in substance use occasions was associated with better outcomes including improved mental health. W-SUDs satisfaction was high.;2021
Background: The COVID-19 pandemic has limited daily activities and even contact between patients and primary care providers. This makes it more difficult to provide adequate primary care services which include connecting patients to an appropriate medical specialist. A smartphone-compatible artificial intelligence (AI) chatbot that classifies patients'symptoms and recommends the appropriate medical specialty could provide a valuable solution. Objective: In order to establish a contactless method of recommending the appropriate medical specialty this study aimed to construct a deep learning-based natural language processing (NLP) pipeline and to develop an AI chatbot that can be used on a smartphone. Methods: We collected 118008 sentences containing information on symptoms with labels (medical specialty) conducted data cleansing and finally constructed a pipeline of 51134 sentences for this study. Several deep learning models including 4 different long short-term memory (LSTM) models with or without attention and with or without a pretrained FastText embedding layer as well as bidirectional encoder representations from transformers for NLP were trained and validated using a randomly selected test data set. The performance of the models was evaluated on the basis of the precision recall F1-score and area under the receiver operating characteristic curve (AUC). An AI chatbot was also designed to make it easy for patients to use this specialty recommendation system. We used an open-source framework called Alpha to develop our AI chatbot. This takes the form of a web-based app with a frontend chat interface capable of conversing in text and a backend cloud-based server application to handle data collection process the data with a deep learning model and offer the medical specialty recommendation in a responsive web that is compatible with both desktops and smartphones. Results: The bidirectional encoder representations from transformers model yielded the best performance with an AUC of 0.964 and F-1-score of 0.768 followed by LSTM model with embedding vectors with an AUC of 0.965 and F-1-score of 0.739. Considering the limitations of computing resources and the wide availability of smartphones the LSTM model with embedding vectors trained on our data set was adopted for our AI chatbot service. We also deployed an Alpha version of the AI chatbot to be executed on both desktops and smartphones. Conclusions: With the increasing need for telemedicine during the current COVID-19 pandemic an AI chatbot with a deep learning-based NLP model that can recommend a medical specialty to patients through their smartphones would be exceedingly useful. This chatbot allows patients to identify the proper medical specialist in a rapid and contactless manner based on their symptoms thus potentially supporting both patients and primary care providers.;2021
Background: The current COVID-19 coronavirus pandemic is an emergency on a global scale with huge swathes of the population required to remain indoors for prolonged periods to tackle the virus. In this new context individuals' health-promoting routines are under greater strain contributing to poorer mental and physical health. Additionally individuals are required to keep up to date with latest health guidelines about the virus which may be confusing in an age of social-media disinformation and shifting guidelines. To tackle these factors we developed Elena+ a smartphone-based and conversational agent (CA) delivered pandemic lifestyle care intervention. Methods: Elena+ utilizes varied intervention components to deliver a psychoeducation-focused coaching program on the topics of: COVID-19 information physical activity mental health (anxiety loneliness mental resources) sleep and diet and nutrition. Over 43 subtopics a CA guides individuals through content and tracks progress over time such as changes in health outcome assessments per topic alongside user-set behavioral intentions and user-reported actual behaviors. Ratings of the usage experience social demographics and the user profile are also captured. Elena+ is available for public download on iOS and Android devices in English European Spanish and Latin American Spanish with future languages and launch countries planned and no limits on planned recruitment. Panel data methods will be used to track user progress over time in subsequent analyses. The Elena+ intervention is open-source under the Apache 2 license (MobileCoach software) and the Creative Commons 4.0 license CC BY-NC-SA (intervention logic and content) allowing future collaborations such as cultural adaptions integration of new sensor-related features or the development of new topics. Discussion: Digital health applications offer a low-cost and scalable route to meet challenges to public health. As Elena+ was developed by an international and interdisciplinary team in a short time frame to meet the COVID-19 pandemic empirical data are required to discern how effective such solutions can be in meeting real world emergent health crises. Additionally clustering Elena+ users based on characteristics and usage behaviors could help public health practitioners understand how population-level digital health interventions can reach at-risk and sub-populations.;2021
Background: The integration of technology-based interventions into health and care provision in our aging society is still a challenge especially in the care pathway for people with dementia. Objective: The study aims to: (1) identify which socio-demographic characteristics are independently associated with the use of the embodied conversational agent among subjects with dementia (2) uncover patient cluster profiles based on these characteristics and (3) discuss technology-based interventions challenges. Methods: A virtual agent was used for four weeks by 55 persons with dementia living in their home environment. Results: Participants evaluated the agent as easy-to-use and quickly learnable. They felt confident while using the system and expressed the willingness to use it frequently. Moreover 21/55 of the patients perceived the virtual agent as a friend and assistant who they could feel close to and who would remind them of important things. Conclusions: Technology-based interventions require a significant effort such as personalized features and patient-centered care pathways to be effective. Therefore this study enriches the open discussion on how such virtual agents must be evidence-based related and designed by multidisciplinary teams following patient-centered care as well as user-centered design approaches.;2021
Background: The use of chatbots may increase engagement with digital behavior change interventions in youth by providing human-like interaction. Following a Person-Based Approach (PBA) integrating user preferences in digital tool development is crucial for engagement whereas information on youth preferences for health chatbots is currently limited.Objective: The aim of this study was to gain an in-depth understanding of adolescents' expectations and preferences for health chatbots and describe the systematic development of a health promotion chatbot.Methods: Three studies in three different stages of PBA were conducted: (1) a qualitative focus group study (n = 36) (2) log data analysis during pretesting (n = 6) and (3) a mixed-method pilot testing (n = 73).Results: Confidentiality connection to youth culture and preferences when referring to other sources were important aspects for youth in chatbots. Youth also wanted a chatbot to provide small talk and broader support (e.g. technical support with the tool) rather than specifically in relation to health behaviors. Despite the meticulous approach of PBA user engagement with the developed chatbot was modest.Conclusion: This study highlights that conducting formative research at different stages is an added value and that adolescents have different chatbot preferences than adults. Further improvement to build an engaging chatbot for youth may stem from using living databases.;2021
Background: The use of digital health resources is growing quickly as they are easily accessible and permit self-evaluation. Yet research on consumer health informatics platforms is insufficient. Chatbots interactive conversational platforms based on artificial intelligence can facilitate access to specific information. Hidradenitis suppurativa (HS) is burdensome and has a high threshold for consultation. Objectives: We aimed to identify the most important principles for the assembly of medical chatbots through the analysis of usage data. Methods: The HS Chatbot1 is a question-and-answer platform in the style of a chatbot. Usage data were collected over the course of a year. 254 responses were statistically analysed. Results: 239 users were alleged patients. 82.9% were looking for a tentative diagnosis. The users were on average 32.49 (+/- 11.33) years old and predominantly female (70.2%). The average number of clicks per visit on the website was 14.69 (+/- 8.83). Conclusions: A medical chatbot has to be customised to the specific subject whilst general principles have to be considered. High-quality information has to be available in just a few clicks. People concerned about HS are looking for a diagnosis online and often have not seen a doctor previously. Guidance towards appropriate care should be provided.;2021
Background: This systematic review aimed to evaluate Al chatbot characteristics functions and core conversational capacities and investigate whether Al chatbot interventions were effective in changing physical activity healthy eating weight management behaviors and other related health outcomes. Methods: In collaboration with a medical librarian six electronic bibliographic databases (PubMed EMBASE ACM Digital Library Web of Science PsycINFO and IEEE) were searched to identify relevant studies. Only randomized controlled trials or quasi-experimental studies were included. Studies were screened by two independent reviewers and any discrepancy was resolved by a third reviewer. The National Institutes of Health quality assessment tools were used to assess risk of bias in individual studies. We applied the Al Chatbot Behavior Change Model to characterize components of chatbot interventions including chatbot characteristics persuasive and relational capacity and evaluation of outcomes. Results: The database search retrieved 1692 citations and 9 studies met the inclusion criteria. Of the 9 studies 4 were randomized controlled trials and 5 were quasi-experimental studies. Five out of the seven studies suggest chatbot interventions are promising strategies in increasing physical activity. In contrast the number of studies focusing on changing diet and weight status was limited. Outcome assessments however were reported inconsistently across the studies. Eighty-nine and thirty-three percent of the studies specified a name and gender (i.e. woman) of the chatbot respectively. Over half (56%) of the studies used a constrained chatbot (i.e. rule-based) while the remaining studies used unconstrained chatbots that resemble human-to-human communication. Conclusion: Chatbots may improve physical activity but we were not able to make definitive conclusions regarding the efficacy of chatbot interventions on physical activity diet and weight management/loss. Application of AI chatbots is an emerging field of research in lifestyle modification programs and is expected to grow exponentially. Thus standardization of designing and reporting chatbot interventions is warranted in the near future.;2021
Background: To motivate people to adopt medical chatbots the establishment of a specialized medical knowledge database that fits their personal interests is of great importance in developing a chatbot for perinatal care particularly with the help of health professionals. Objective: The objectives of this study are to develop and evaluate a user-friendly question-and-answer (Q&A) knowledge database-based chatbot (Dr. Joy) for perinatal women's and their partners' obstetric and mental health care by applying a text-mining technique and implementing contextual usability testing (UT) respectively thus determining whether this medical chatbot built on mobile instant messenger (KakaoTalk) can provide its male and female users with good user experience. Methods: Two men aged 38 and 40 years and 13 women aged 27 to 43 years in pregnancy preparation or different pregnancy stages were enrolled. All participants completed the 7-day-long UT during which they were given the daily tasks of asking Dr. Joy at least 3 questions at any time and place and then giving the chatbot either positive or negative feedback with emoji using at least one feature of the chatbot and finally sending a facilitator all screenshots for the history of the day's use via KakaoTalk before midnight. One day after the UT completion all participants were asked to fill out a questionnaire on the evaluation of usability perceived benefits and risks intention to seek and share health information on the chatbot and strengths and weaknesses of its use as well as demographic characteristics. Results: Despite the relatively higher score of ease of learning (EOL) the results of the Spearman correlation indicated that EOL was not significantly associated with usefulness (rho=0.26 P=.36) ease of use (rho=0.19 P=.51) satisfaction (rho=0.21 P=.46) or total usability scores (rho=0.32 P=.24). Unlike EOL all 3 subfactors and the total usability had significant positive associations with each other (all rho>0.80 P<.001). Furthermore perceived risks exhibited no significant negative associations with perceived benefits (rho=-0.29 P=.30) or intention to seek (SEE rho=-0.28 P=.32) or share (SHArho=-0.24 P=.40) health information on the chatbot via KakaoTalk whereas perceived benefits exhibited significant positive associations with both SEE and SHA. Perceived benefits were more strongly associated with SEE (rho=0.94 P<.001) than with SHA (rho=0.70 P=.004). Conclusions: This study provides the potential for the uptake of this newly developed Q&A knowledge database-based KakaoTalk chatbot for obstetric and mental health care. As Dr. Joy had quality contents with both utilitarian and hedonic value its male and female users could be encouraged to use medical chatbots in a convenient easy-to-use and enjoyable manner. To boost their continued usage intention for Dr. Joy its Q&A sets need to be periodically updated to satisfy user intent by monitoring both male and female user utterances.;2021
Background: Tuberculosis (TB) is a highly infectious disease. Negative perceptions and insufficient knowledge have made its eradication difficult. Recently mobile health care interventions such as an anti-TB chatbot developed by the research team have emerged in support of TB eradication programs. However before the anti-TB chatbot is deployed it is important to understand the factors that predict its acceptance by the population. Objective: This study aims to explore the acceptance of an anti-TB chatbot that provides information about the disease and its treatment to people vulnerable to TB in South Korea. Thus we are investigating the factors that predict technology acceptance through qualitative research based on the interviews of patients with TB and homeless facility personnel. We are then verifying the extended Technology Acceptance Model (TAM) and predicting the factors associated with the acceptance of the chatbot. Methods: In study 1 we conducted interviews with potential chatbot users to extract the factors that predict user acceptance and constructed a conceptual framework based on the TAM. In total 16 interviews with patients with TB and one focus group interview with 10 experts on TB were conducted. In study 2 we conducted surveys of potential chatbot users to validate the extended TAM. Survey participants were recruited among late-stage patients in TB facilities and members of web-based communities sharing TB information. A total of 123 responses were collected. Results: The results indicate that perceived ease of use and social influence were significantly predictive of perceived usefulness (P=.04 and P<.001 respectively). Perceived usefulness was predictive of the attitude toward the chatbot (P<.001) whereas perceived ease of use (P=.88) was not. Behavioral intention was positively predicted by attitude toward the chatbot and facilitating conditions (P<.001 and P=.03 respectively). The research model explained 55.4% of the variance in the use of anti-TB chatbots. The moderating effect of TB history was found in the relationship between attitude toward the chatbot and behavioral intention (P=.01) and between facilitating conditions and behavioral intention (P=.02). Conclusions: This study can be used to inform future design of anti-TB chatbots and highlight the importance of services and the environment that empower people to use the technology.;2021
Background: Uncertainty surrounds the ethical and legal implications of algorithmic and data-driven technologies in the mental health context including technologies characterized as artificial intelligence machine learning deep learning and other forms of automation. Objective: This study aims to survey empirical scholarly literature on the application of algorithmic and data-driven technologies in mental health initiatives to identify the legal and ethical issues that have been raised. Methods: We searched for peer-reviewed empirical studies on the application of algorithmic technologies in mental health care in the Scopus Embase and Association for Computing Machinery databases. A total of 1078 relevant peer-reviewed applied studies were identified which were narrowed to 132 empirical research papers for review based on selection criteria. Conventional content analysis was undertaken to address our aims and this was supplemented by a keyword-in-context analysis. Results: We grouped the findings into the following five categories of technology: social media (53/132 40.1%) smartphones (37/132 28%) sensing technology (20/132 15.1%) chatbots (5/132 3.8%) and miscellaneous (17/132 12.9%). Most initiatives were directed toward detection and diagnosis. Most papers discussed privacy mainly in terms of respecting the privacy of research participants. There was relatively little discussion of privacy in this context. A small number of studies discussed ethics directly (10/132 7.6%) and indirectly (10/132 7.6%). Legal issues were not substantively discussed in any studies although some legal issues were discussed in passing (7/132 5.3%) such as the rights of user subjects and privacy law compliance. Conclusions: Ethical and legal issues tend to not be explicitly addressed in empirical studies on algorithmic and data-driven technologies in mental health initiatives. Scholars may have considered ethical or legal matters at the ethics committee or institutional review board stage. If so this consideration seldom appears in published materials in applied research in any detail. The form itself of peer-reviewed papers that detail applied research in this field may well preclude a substantial focus on ethics and law. Regardless we identified several concerns including the near-complete lack of involvement of mental health service users the scant consideration of algorithmic accountability and the potential for overmedicalization and techno-solutionism. Most papers were published in the computer science field at the pilot or exploratory stages. Thus these technologies could be appropriated into practice in rarely acknowledged ways with serious legal and ethical implications.;2021
Background: University students are increasingly reporting common mental health problems such as stress anxiety and depression and they frequently face barriers to seeking psychological support because of stigma cost and availability of mental health services. This issue is even more critical in the challenging time of the COVID-19 pandemic. Digital mental health interventions such as those delivered via chatbots on mobile devices offer the potential to achieve scalability of healthy-coping interventions by lowering cost and supporting prevention. Objective: The goal of this study was to conduct a proof-of-concept evaluation measuring the engagement and effectiveness of Atena a psychoeducational chatbot supporting healthy coping with stress and anxiety among a population of university students. Methods: In a proof-of-concept study 71 university students were recruited during the COVID-19 pandemic 68% (48/71) were female they were all in their first year of university and their mean age was 20.6 years (SD 2.4). Enrolled students were asked to use the Atena psychoeducational chatbot for 4 weeks (eight sessions two per week) which provided healthy-coping strategies based on cognitive behavioral therapy positive psychology and mindfulness techniques. The intervention program consisted of conversations combined with audiovisual clips delivered via the Atena chatbot. Participants were asked to complete web-based versions of the 7-item Generalized Anxiety Disorder scale (GAD-7) the 10-item Perceived Stress Scale (PSS-10) and the Five-Facet Mindfulness Questionnaire (FFMQ) at baseline and postintervention to assess effectiveness. They were also asked to complete the User Engagement Scale-Short Form at week 2 to assess engagement with the chatbot and to provide qualitative comments on their overall experience with Atena postintervention. Results: Participants engaged with the Atena chatbot an average of 78 (SD 24.8) times over the study period. A total of 61 out of 71 (86%) participants completed the first 2 weeks of the intervention and provided data on engagement (10/71 14% attrition). A total of 41 participants out of 71 (58%) completed the full intervention and the postintervention questionnaires (30/71 42% attrition). Results from the completer analysis showed a significant decrease in anxiety symptoms for participants in more extreme GAD-7 score ranges (t39=0.94 P=.009) and a decrease in stress symptoms as measured by the PSS-10 (t39=2.00 P=.05) for all participants postintervention. Participants also improved significantly in the describing and nonjudging facets based on their FFMQ subscale scores and asked for some improvements in the user experience with the chatbot. Conclusions: This study shows the benefit of deploying a digital healthy-coping intervention via a chatbot to support university students experiencing higher levels of distress. While findings collected during the COVID-19 pandemic show promise further research is required to confirm conclusions.;2021
Background: Virtual assistants can be used to deliver innovative health programs that provide appealing personalized and convenient health advice and support at scale and low cost. Design characteristics that influence the look and feel of the virtual assistant such as visual appearance or language features may significantly influence users' experience and engagement with the assistant. Objective: This scoping review aims to provide an overview of the experimental research examining how design characteristics of virtual health assistants affect user experience summarize research findings of experimental research examining how design characteristics of virtual health assistants affect user experience and provide recommendations for the design of virtual health assistants if sufficient evidence exists. Methods: We searched 5 electronic databases (Web of Science MEDLINE Embase PsycINFO and ACM Digital Library) to identify the studies that used an experimental design to compare the effects of design characteristics between 2 or more versions of an interactive virtual health assistant on user experience among adults. Data were synthesized descriptively. Health domains design characteristics and outcomes were categorized and descriptive statistics were used to summarize the body of research. Results for each study were categorized as positive negative or no effect and a matrix of the design characteristics and outcome categories was constructed to summarize the findings. Results: The database searches identified 6879 articles after the removal of duplicates. We included 48 articles representing 45 unique studies in the review. The most common health domains were mental health and physical activity. Studies most commonly examined design characteristics in the categories of visual design or conversational style and relational behavior and assessed outcomes in the categories of personality satisfaction relationship or use intention. Over half of the design characteristics were examined by only 1 study. Results suggest that empathy and relational behavior and self-disclosure are related to more positive user experience. Results also suggest that if a human-like avatar is used realistic rendering and medical attire may potentially be related to more positive user experience however more research is needed to confirm this. Conclusions: There is a growing body of scientific evidence examining the impact of virtual health assistants' design characteristics on user experience. Taken together data suggest that the look and feel of a virtual health assistant does affect user experience. Virtual health assistants that show empathy display nonverbal relational behaviors and disclose personal information about themselves achieve better user experience. At present the evidence base is broad and the studies are typically small in scale and highly heterogeneous. Further research particularly using longitudinal research designs with repeated user interactions is needed to inform the optimal design of virtual health assistants.;2021
Background: Voice-controlled intelligent personal assistants (VIPAs) such as Amazon Echo and Google Home involve artificial intelligence-powered algorithms designed to simulate humans. Their hands-free interface and growing capabilities have a wide range of applications in health care covering off-clinic education health monitoring and communication. However conflicting factors such as patient safety and privacy concerns make it difficult to foresee the further development of VIPAs in health care. Objective: This study aimed to develop a plausible scenario for the further development of VIPAs in health care to support decision making regarding the procurement of VIPAs in health care organizations. Methods: We conducted a two-stage Delphi study with an internationally recruited panel consisting of voice assistant experts medical professionals and representatives of academia governmental health authorities and nonprofit health associations having expertise with voice technology. Twenty projections were formulated and evaluated by the panelists. Descriptive statistics were used to derive the desired scenario. Results: The panelists expect VIPAs to be able to provide solid medical advice based on patients' personal health information and to have human-like conversations. However in the short term voice assistants might neither provide frustration-free user experience nor outperform or replace humans in health care. With a high level of consensus the experts agreed with the potential of VIPAs to support elderly people and be widely used as anamnesis informational self-therapy and communication tools by patients and health care professionals. Although users' and governments' privacy concerns are not expected to decrease in the near future the panelists believe that strict regulations capable of preventing VIPAs from providing medical help services will not be imposed. Conclusions: According to the surveyed experts VIPAs will show notable technological development and gain more user trust in the near future resulting in widespread application in health care. However voice assistants are expected to solely support health care professionals in their daily operations and will not be able to outperform or replace medical staff.;2021
BackgroundAdvances in genetics and sequencing technologies are enabling the identification of more individuals with inherited cancer susceptibility who could benefit from tailored screening and prevention recommendations. While cancer family history information is used in primary care settings to identify unaffected patients who could benefit from a cancer genetics evaluation this information is underutilized. System-level population health management strategies are needed to assist health care systems in identifying patients who may benefit from genetic services. In addition because of the limited number of trained genetics specialists and increasing patient volume the development of innovative and sustainable approaches to delivering cancer genetic services is essential.MethodsWe are conducting a randomized controlled trial entitled Broadening the Reach Impact and Delivery of Genetic Services (BRIDGE) to address these needs. The trial is comparing uptake of genetic counseling uptake of genetic testing and patient adherence to management recommendations for automated patient-directed versus enhanced standard of care cancer genetics services delivery models. An algorithm-based system that utilizes structured cancer family history data available in the electronic health record (EHR) is used to identify unaffected patients who receive primary care at the study sites and meet current guidelines for cancer genetic testing. We are enrolling eligible patients at two healthcare systems (University of Utah Health and New York University Langone Health) through outreach to a randomly selected sample of 2780 eligible patients in the two sites with 1:1 randomization to the genetic services delivery arms within sites. Study outcomes are assessed through genetics clinic records EHR and two follow-up questionnaires at 4weeks and 12months after last genetic counseling contactpre-test genetic counseling.DiscussionBRIDGE is being conducted in two healthcare systems with different clinical structures and patient populations. Innovative aspects of the trial include a randomized comparison of a chatbot-based genetic services delivery model to standard of care as well as identification of at-risk individuals through a sustainable EHR-based system. The findings from the BRIDGE trial will advance the state of the science in identification of unaffected patients with inherited cancer susceptibility and delivery of genetic services to those patients.Trial registrationBRIDGE is registered as NCT03985852. The trial was registered on June 6 2019 at clinicaltrials.gov.;2021
Based on the theoretical framework of agency effect this study examined the role of affect in influencing the effects of chatbot versus human brand representatives in the context of health marketing communication about HPV vaccines. We conducted a 2 (perceived agency: chatbot vs. human) x 3 (affect elicitation: embarrassment anger neutral) between-subject lab experiment with 142 participants who were randomly assigned to interact with either a perceived chatbot or a human representative. Key findings from self-reported and behavioral data highlight the complexity of consumer-chatbot communication. Specifically participants reported lower interaction satisfaction with the chatbot than with the human representative when anger was evoked. However participants were more likely to disclose concerns of HPV risks and provide more elaborate answers to the perceived human representative when embarrassment was elicited. Overall the chatbot performed comparably to the human representative in terms of perceived usefulness and influence over participants' compliance intention in all emotional contexts. The findings complement the Computers as Social Actors paradigm and offer strategic guidelines to capitalize on the relative advantages of chatbot versus human representatives.;2021
Because of technological advancement human face recognition has been commonly applied in various fields. There are some HCI-related applications such as camera-ready chatbot and companion robot require gathering more information from user's face. In this paper we developed a system called EAGR for emotion age and gender recognition which can perceive user's emotion age and gender based on the face detection. The EAGR system first applies normalized facial cropping (NFC) as a preprocessing method for training data before data augmentation then uses convolution neural network (CNN) as three training models for recognizing seven emotions (six basics plus one neutral emotion) four age groups and two genders. For better emotion recognition the NFC will extract facial features without hair retained. On the other hand the NFC will extract facial features with hair retained for better age and gender recognition. The experiments were conducted on these three training models of emotion age and gender recognitions. The recognition performance results from the testing dataset which has been normalized for tilted head by proposed binocular line angle correction (BLAC) showed that the optimal mean accuracy rates of real-time recognition for seven emotions four age groups and two genders were 82.4% 74.95% and 96.65% respectively. Furthermore the training time can be substantially reduced via NFC preprocessing. Therefore we believe that EAGR system is cost-effective in recognizing human emotions ages and genders. The EAGR system can be further applied in social applications to help HCI service provide more accurate feedback from pluralistic facial classifications.;2021
Beyond the common difficulties faced in task-oriented dialogue system medical dialogue has recently attracted increasing attention due to its huge application potential while posing more challenges in reasoning over medical domain knowledge and logic. Existing works resort to neural language models for dialogue embedding and neglect the explicit logical reasoning leading to poor explainable and generalization ability. In this work we propose an explainable Heterogeneous Graph Reasoning (HGR) model to unify the relational dialogue context understanding and entity-correlation reasoning into a heterogeneous graph structure. HGR encodes entity context according to the corresponding utterance and deduces next response after fusing the underlying medical knowledge with entity context by attentional graph propagation. To push forward the future research on expert-sensitive task-oriented dialogue system we first release a large-scale Medical Dialogue Consultant benchmark (MDG-C) with 16 Gastrointestinal diseases for evaluating consultant capability and a Medical Dialogue Diagnosis benchmark (MDG-D) with 6 diseases for measuring diagnosis capability of models respectively. Extensive experiments on both MDG-C and MDG-D benchmarks demonstrate the superiority of our HGR over state-of-the-art knowledge grounded approaches in general fields of medical dialogue system. (c) 2021 Elsevier B.V. All rights reserved.;2021
Building an intelligent dialogue system with the ability to select a proper response according to a multi-turn context is challenging in three aspects: (1) the meaning of a context response pair is built upon language units from multiple granularities (e.g. words phrases and sub-sentences etc.) (2) local (e.g. a small window around a word) and long-range (e.g. words across the context and the response) dependencies may exist in dialogue data and (3) the relationship between the context and the response candidate lies in multiple relevant semantic clues or relatively implicit semantic clues in some real cases. However existing approaches usually encode the dialogue with mono-type representation and the interaction processes between the context and the response candidate are executed in a rather shallow manner which may lead to an inadequate understanding of dialogue content and hinder the recognition of the semantic relevance between the context and response. To tackle these challenges we propose a representation ([K])-interaction ([L])-matching framework that explores multiple types of deep interactive representations to build context-response matching models for response selection. Particularly we construct different types of representations for utterance response pairs and deepen them via alternate encoding and interaction. By this means the model can handle the relation of neighboring elements phrasal pattern and long-range dependencies during the representation and make a more accurate prediction through multiple layers of interactions between the context-response pair. Experiment results on three public benchmarks indicate that the proposed model significantly outperforms previous conventional context-response matching models and achieve slightly better results than the BERT model for multi-turn response selection in retrieval-based dialogue systems.;2021
Building Virtual Agents capable of carrying out complex queries of the user involving multiple intents of a domain is quite a challenge because it demands that the agent manages several subtasks simultaneously. This article presents a universal Deep Reinforcement Learning framework that can synthesize dialogue managers capable of working in a task-oriented dialogue system encompassing various intents pertaining to a domain. The conversation between agent and user is broken down into hierarchies to segregate subtasks pertinent to different intents. The concept of Hierarchical Reinforcement Learning particularly options is used to learn policies in different hierarchies that operates in distinct time steps to fulfill the user query successfully. The dialogue manager comprises top-level intent meta-policy to select among subtasks or options and a low-level controller policy to pick primitive actions to communicate with the user to complete the subtask provided to it by the top-level policy in varying intents of a domain. The proposed dialogue management module has been trained in a way such that it can be reused for any language for which it has been developed with little to no supervision. The developed system has been demonstrated for Air Travel and Restaurant domain in English and Hindi languages. Empirical results determine the robustness and efficacy of the learned dialogue policy as it outperforms several baselines and a state-of-the-art system.;2021
Business psychologists study and assess relevant individual differences such as intelligence and personality in the context of work. Such studies have informed the development of artificial intelligence systems (AI) designed to measure individual differences. This has been capitalized on by companies who have developed AI-driven recruitment solutions that include aggregation of appropriate candidates (Hiretual) interviewing through a chatbot (Paradox) video interview assessment (MyInterview) and CV-analysis (Textio) as well as estimation of psychometric characteristics through image-(Traitify) and game-based assessments (HireVue) and video interviews (Cammio). However driven by concern that such high-impact technology must be used responsibly due to the potential for unfair hiring to result from the algorithms used by these tools there is an active effort towards proving mechanisms of governance for such automation. In this article we apply a systematic algorithm audit framework in the context of the ethically critical industry of algorithmic recruitment systems exploring how audit assessments on AI-driven systems can be used to assure that such systems are being responsibly deployed in a fair and well-governed manner. We outline sources of risk for the use of algorithmic hiring tools suggest the most appropriate opportunities for audits to take place recommend ways to measure bias in algorithms and discuss the transparency of algorithms.;2021
Chatbot development and adoption is a growing challenge in emerging markets which are characterised by a young population structure low-level internet penetration and a high degree of institutional adversity. The purpose of this study is to explore how consumers in emerging markets interact and engage with banking chatbots when conducting bank transactions. Based on qualitative research using semi-structured interviews with 36 Nigerian residents this study demonstrates that the four factors of the unified theory of acceptance and use of technology (UTAUT) can explain how emerging-market consumers interact and engage with banking chatbots. While age and technological experience are significant components in facilitating the use of chatbots perceived expertise responsiveness and security were found to be particularly important to users. This study delves into user experiences with conversational interfaces specifically focusing on emerging markets.;2021
Chatbot technologies have made our lives easier. To create a chatbot with high intelligence a significant amount of knowledge processing is required. However this can slow down the reaction time hence a mechanism to enable a quick response is needed. This paper proposes a cache mechanism to improve the response time of the chatbot service while the cache in CPU utilizes the locality of references within binary code executions our cache mechanism for chatbots uses the frequency and relevance information which potentially exists within the set of Q & A pairs. The proposed idea is to enable the broker in a multi-layered structure to analyze and store the keyword-wise relevance of the set of Q & A pairs from chatbots. In addition the cache mechanism accumulates the frequency of the input questions by monitoring the conversation history. When a cache miss occurs the broker selects a chatbot according to the frequency and relevance and then delivers the query to the selected chatbot to obtain a response for answer. This mechanism showed a significant increase in the cache hit ratio as well as an improvement in the average response time.;2021
Chatbots are a burgeoning opportunity for news media outlets to disseminate their content in a conversational way and create an engaging experience around it. Since chatbots are social and interactive technologies they might be effective tools to lower the threshold of engaging with news content containing opposing views. In an experiment we test this idea by investigating whether people are more likely to accept a news article containing conflicting views when it is delivered by a chatbot as compared with the same article on a news website. The results indicated that people agreed more to a counter-attitudinal news article when it was delivered by a news chatbot (compared with the website article). In addition users also perceived this chatbot article as more credible. The underlying process for this effect was that people attributed human-like characteristics to the chatbot on an implicit level (i.e. perceived mindless anthropomorphism). These results are discussed in the light of their potential contribution to an informed public discourse and a decrease in polarization in our society.;2021
Chatbots are an emerging technology that is disrupting the tourism industry. Despite their implementation in companies and at destinations there is little research that evaluates chatbots' smart tourism technologies (STTs) attributes and their influence on tourist satisfaction. This study seeks to examine the relationship between informativeness empathy accessibility interactivity and chatbot user satisfaction. The research was based on an experiment and a survey conducted on a sample of 468 potential tourists who used a chatbot during their trip. Statistical tools such as exploratory factor analysis and the hierarchical regression method were used in the data analysis. The results suggest that informativeness empathy and interactivity of destination chatbots are the attributes that influence and predict tourist satisfaction while accessibility does not. The main contribution of this study is the analysis of the attributes of STTs applied to destination chatbots which also provides valuable information for both tourism chatbot developers and smart destination managers who wish to adopt this technology.;2021
Chatbots are artificial communication systems becoming increasingly popular and not all their security questions are clearly solved. People use chatbots for assistance in shopping bank communication meal delivery healthcare cars and many other actions. However it brings an additional security risk and creates serious security challenges which have to be handled. Understanding the underlying problems requires defining the crucial steps in the techniques used to design chatbots related to security. There are many factors increasing security threats and vulnerabilities. All of them are comprehensively studied and security practices to decrease security weaknesses are presented. Modern chatbots are no longer rule-based models but they employ modern natural language and machine learning techniques. Such techniques learn from a conversation which can contain personal information. The paper discusses circumstances under which such data can be used and how chatbots treat them. Many chatbots operate on a social/messaging platform which has their terms and conditions about data. The paper aims to present a comprehensive study of security aspects in communication with chatbots. The article could open a discussion and highlight the problems of data storage and usage obtained from the communication user-chatbot and propose some standards to protect the user.;2021
Chatbots are artificial intelligence tools that interact with people in different contexts. A chatbot can be useful to streamline daily processes serve customers 24 hours a day provide information about classes among other things. The appearance of new development technologies has made creating a chatbot an increasingly fast and straightforward process bringing this kind of applications to people who had never considered using them before. However this speed in development can lead to specific problems many of them caused by the lack of usability evaluations. Heuristic usability evaluations are user interface review processes carried out by experts and are an essential part of any assessment process. To date there are no heuristics to evaluate the usability of chatbots. Therefore this work proposes five usability heuristics in chatbots that come from the experience developing this type of applications as well as from a broad review of state of the art. The set of heuristics was tested using a case study with the help of five experts who evaluated an education-oriented chatbot. The results revealed that although the proposed heuristics need refinement they are an excellent first step in broadening the horizon of usability evaluations in chatbots.;2021
Chatbots are emerging as a promising platform for accessing and delivering healthcare services. The evidence is in the growing number of publicly available chatbots aiming at taking an active role in the provision of prevention diagnosis and treatment services. This article takes a closer look at how these emerging chatbots address design aspects relevant to healthcare service provision emphasizing the human-AI interaction aspects and the transparency in AI automation and decision making.;2021
Chatbots are increasingly becoming important gateways to digital services and information-taken up within domains such as customer service health education and work support. However there is only limited knowledge concerning the impact of chatbots at the individual group and societal level. Furthermore a number of challenges remain to be resolved before the potential of chatbots can be fully realized. In response chatbots have emerged as a substantial research area in recent years. To help advance knowledge in this emerging research area we propose a research agenda in the form of future directions and challenges to be addressed by chatbot research. This proposal consolidates years of discussions at the CONVERSATIONS workshop series on chatbot research. Following a deliberative research analysis process among the workshop participants we explore future directions within six topics of interest: (a) users and implications (b) user experience and design (c) frameworks and platforms (d) chatbots for collaboration (e) democratizing chatbots and (f) ethics and privacy. For each of these topics we provide a brief overview of the state of the art discuss key research challenges and suggest promising directions for future research. The six topics are detailed with a 5-year perspective in mind and are to be considered items of an interdisciplinary research agenda produced collaboratively by avid researchers in the field.;2021
Chatbots are increasingly engaged in retail settings although research shows that consumers typically prefer engaging with humans over chatbots. Past literature has argued that anthropomorphising chatbots can lead to more effective consumer interactions. The current work further enhances this literature by showing that chatbots can be given human qualities like warmth and competence to enhance positive consumer experiences. However we find that these exchanges are contingent on consumers' time orientation. We conduct one pre-test (N = 103) two laboratory experiments (N = 213 and 233) and a third study engaging live chatbot conversations (N = 77) to test the premises of our study. The findings show that present-oriented subjects prefer a warm versus competent chatbot conversation leading to favourable product decisions. Their counterparts future-oriented subjects prefer a competent vs. warm conversation. Brand perceptions further mediate these effects. The findings contribute to the literature on chatbot anthropomorphism and inform managerial decisions.;2021
Chatbots are programs that supply services to users via conversation in natural language acting as virtual assistants within social networks or web applications. Here we review the most representative chatbot development tools with a focus on technical and managerial aspects.;2021
Chatbots are software agents that are able to interact with humans in natural language. Their intuitive interaction paradigm is expected to significantly reshape the software landscape of tomorrow while already today chatbots are invading a multitude of scenarios and contexts. This article takes a developer's perspective identifies a set of architectural patterns that capture different chatbot integration scenarios and reviews state-of-the-art development aids.;2021
Chatbots are software applications to simulate a conversation with a person. The effectiveness of chatbots in facilitating the recruitment of study participants in research specifically among racial and ethnic minorities is unknown. The objective of this study is to compare a chatbot versus telephone-based recruitment in enrolling research participants from a predominantly minority patient population at an urban institution. We randomly allocated adults to receive either chatbot or telephone-based outreach regarding a study about vaccine hesitancy. The primary outcome was the proportion of participants who provided consent to participate in the study. In 935 participants the proportion who answered contact attempts was significantly lower in the chatbot versus telephone group (absolute difference 21.8% 95% confidence interval [CI] 27.0% 16.5% P<0.001). The consent rate was also significantly lower in the chatbot group (absolute difference 3.4% 95% CI 5.7% 1.1% P=0.004). However among participants who answered a contact attempt the difference in consent rates was not significant. In conclusion the consent rate was lower with chatbot compared to telephone-based outreach. The difference in consent rates was due to a lower proportion of participants in the chatbot group who answered a contact attempt.;2021
Chatbots are virtual conversation agents that offer innovative features to connect with customers and thus offer a promising avenue to engage customers. Currently many private and nationalized banks are deploying chatbots for connecting and communicating with customers. This technology is expected to dominate the banking sector in the future by improving customer service. However the success of banking chatbots will be effective when customers are satisfied with the chatbots and engage in using them. To probe in to the question this study investigates the antecedents and consequences of customer brand engagement in using banking chatbots with the lens of diffusion of innovation theory. The antecedents include interactivity time convenience compatibility complexity observability and trialability. The consequences are satisfaction with the brand experience and customer brand usage intention. The theorized model has been validated with 470 Indian banking chatbot customers usable responses. The results suggest that trialability compatibility and interactivity positively influence customer brand engagement through a chatbot thereby influencing satisfaction with the brand experience and customer brand usage intention. The paper presents theoretical and managerial implications which enable banks to strengthen customer engagement satisfaction and brand usage intention through chatbots.;2021
Chatbots' growing popularity has brought new challenges to HCI having changed the patterns of human interactions with computers. The increasing need to approximate conversational interaction styles raises expectations for chatbots to present social behaviors that are habitual in human-human communication. In this survey we argue that chatbots should be enriched with social characteristics that cohere with users' expectations ultimately avoiding frustration and dissatisfaction. We bring together the literature on disembodied text-based chatbots to derive a conceptual model of social characteristics for chatbots. We analyzed 56 papers from various domains to understand how social characteristics can benefit human-chatbot interactions and identify the challenges and strategies to designing them. Additionally we discussed how characteristics may influence one another. Our results provide relevant opportunities to both researchers and designers to advance human-chatbot interactions.;2021
Chatbots have become popular in recent years as a means of supporting a company's external communication with customers but they are also increasingly being used for internal purposes especially to improve and accelerate workflows. Along these lines recent studies have suggested that chatbots can also be applied to other internal business practices such as innovation management. Nevertheless the use of chatbots for innovation management is still an under-researched topic and practical experiences are largely missing. We address this gap by identifying value propositions of chatbots to support a company's innovation management process. Furthermore we link the value propositions to particular process steps and success dimensions. To do so we perform a literature review and complement the findings with expert interviews. This study contributes to a better understanding of the benefits of chatbot usage for the innovation management process.;2021
Chatbots or Conversational agents are the next significant technological leap in the field of conversational services that is enabling a device to communicate with a user upon receiving user requests in natural language. The device uses artificial intelligence and machine learning to respond to the user with automated responses. While this is a relatively new area of study the application of this concept has increased substantially over the last few years. The technology is no longer limited to merely emulating human conversation but is also being increasingly used to answer questions either in academic environments or in commercial uses such as situations requiring assistants to seek reasons for customer dissatisfaction or recommending products and services. The primary purpose of this literature review is to identify and study the existing literature on cutting-edge technology in developing chatbots in terms of research trends their components and techniques datasets and domains used as well as evaluation metrics most used between 2011 and 2020. Using the standard SLR guidelines designed by Kitchenham this work adopts a systematic literature review approach and utilizes five prestigious scientific databases for identifying extracting and analyzing all relevant publications during the search. The related publications were filtered based on inclusion/exclusion criteria and quality assessment to obtain the final review paper. The results of the review indicate that the exploitation of deep learning and reinforcement learning architecture is the most used technique to understand users' requests and to generate appropriate responses. Besides we also found that the Twitter dataset (open domain) is the most popular dataset used for evaluation followed by Airline Travel Information Systems (ATIS) (close domain) and Ubuntu Dialog Corpora (technical support) datasets. The SLR review also indicates that the open domain provided by the Twitter dataset airline and technical support are the most common domains for chatbots. Moreover the metrics utilized most often for evaluating chatbot performance (in descending order of popularity) were found to be accuracy F1-Score BLEU (Bilingual Evaluation Understudy) recall human-evaluation and precision.;2021
Chatbots or conversational recommenders have gained increasing popularity as a new paradigm for Recommender Systems (RS). Prior work on RS showed that providing explanations can improve transparency and trust which are critical for the adoption of RS. Their interactive and engaging nature makes conversational recommenders a natural platform to not only provide recommendations but also justify the recommendations through explanations. The recent surge of interest inexplainable Al enables diverse styles of justification and also invites questions on how styles of justification impact user perception. In this article we explore the effect of why justifications and why not justifications on users' perceptions of explainability and trust. We developed and tested a movie-recommendation chatbot that provides users with different types of justifications for the recommended items. Our online experiment (n = 310) demonstrates that the why justifications (but not the why not justifications) have a significant impact on users' perception of the conversational recommender. Particularly why justifications increase users' perception of system transparency which impacts perceived control trusting beliefs and in turn influences users' willingness to depend on the system's advice. Finally we discuss the design implications for decision-assisting chatbots.;2021
Cloud/edge computing and deep learning greatly improve performance of semantic understanding systems where cloud/edge computing provides flexible pervasive computation and storage capabilities to support variant applications and deep learning models could comprehend text inputs by consuming computing and storage resource. Therefore we propose to implement an intelligent online custom service system with power of both technologies. Essentially task of semantic understanding consists of two subtasks i.e. intent recognition and slot filling. To prevent error accumulation caused by modeling two subtasks independently we propose to jointly model both subtasks in an end-to-end neural network. Specifically the proposed method firstly extracts distinctive features with a dual structure to take full advantage of interactive and level information between two sub-tasks. Afterwards we introduce attention scheme to enhance feature representation by involving sentence-level context information. With the support of cloud/edge computing infrastructure we deploy the proposed network to work as an intelligent dialogue system for electrical customer service. During experiments we test the proposed method and several comparative studies on public ATIS and our collected PSCF dataset. Experiment results prove the effectiveness of the proposed method by obtaining accurate and promising results.;2021
Common ground processes can improve performance in communication tasks and understanding these processes will likely benefit human-computer dialogue interfaces. However there are multiple proposed theories with different implications for interface design. Fusaroli and Tylen achieved a direct comparison by designing two models: one based on alignment theory and the other based on complementarity theory that encapsulated interpersonal synergy and audience design. The current research used these models extending them to differentiate between interpersonal synergy and audience design. Few studies have tested multiple common ground models against tasks representative of envisioned human-computer interaction (HCI) applications. We report on four such tests which allowed examination of generalizability of findings. Results supported the complementarity models over the alignment model and were suggestive of the audience design variant of complementarity providing guidance for HCI design that differs from contemporary approaches.;2021
Common grounding is the process of creating and maintaining mutual understandings which is a critical aspect of sophisticated human communication. While various task settings have been proposed in existing literature they mostly focus on creating common ground under a static context and ignore the aspect of maintaining them overtime under dynamic context. In this work we propose a novel task setting to study the ability of both creating and maintaining common ground in dynamic environments. Based on our minimal task formulation we collected a large-scale dataset of 5617 dialogues to enable fine-grained evaluation and analysis of various dialogue systems. Through our dataset analyses we highlight novel challenges introduced in our setting such as the usage of complex spatio-temporal expressions to create and maintain common ground. Finally we conduct extensive experiments to assess the capabilities of our baseline dialogue system and discuss future prospects of our research.;2021
Communicating with customers through live chat interfaces has become an increasingly popular means to provide real-time customer service in many e-commerce settings. Today human chat service agents are frequently replaced by conversational software agents or chatbots which are systems designed to communicate with human users by means of natural language often based on artificial intelligence (AI). Though cost- and time-saving opportunities triggered a widespread implementation of AI-based chatbots they still frequently fail to meet customer expectations potentially resulting in users being less inclined to comply with requests made by the chatbot. Drawing on social response and commitment-consistency theory we empirically examine through a randomized online experiment how verbal anthropomorphic design cues and the foot-in-the-door technique affect user request compliance. Our results demonstrate that both anthropomorphism as well as the need to stay consistent significantly increase the likelihood that users comply with a chatbot's request for service feedback. Moreover the results show that social presence mediates the effect of anthropomorphic design cues on user compliance.;2021
Companies have repeatedly launched Artificial Intelligence (AI) products such as intelligent chatbots and robots with female names voices and bodies. Previous research posits that people intuitively favor female over male bots mainly because female bots are judged as warmer and more likely to experience emotions. We present five online studies including four preregistered with a total sample of over 3000 participants that go beyond this longstanding perception of femininity. Because warmth and experience (but not competence) are seen as fundamental qualities to be a full human but are lacking in machines we argue that people prefer female bots because they are perceived as more human than male bots. Using implicit subtle and blatant scales of humanness our results consistently show that women (Studies 1A and 1B) female bots (Studies 2 and 3) and female chatbots (Study 4) are perceived as more human than their male counterparts when compared with non-human entities (animals and machines). Study 4 investigates explicitly the acceptance of gendered algorithms operated by AI chatbots in a health context. We found that the female chatbot is preferred over the male chatbot because it is perceived as more human and more likely to consider our unique needs. These results highlight the ethical quandary faced by AI designers and policymakers: Women are said to be transformed into objects in AI but injecting women's humanity into AI objects makes these objects seem more human and acceptable.;2021
Considering widespread resistance to COVID-19 preventive measures the authors draw on hypocrisy induction theory to examine whether online chatbots can be used to induce hypocrisy and increase compliance with social distancing guidelines. The experiment demonstrates that when a chatbot induces hypocrisy by reminding participants that they have failed to comply with social distancing recommendations they feel guilty about violating social norms. To reinstate confidence in their personal standards they form favorable attitudes toward the chatbot ad and establish intentions to comply with recommendations. Interestingly the persuasive power of hypocrisy induction differs depending on the level of anthropomorphism of the chatbot. When a humanlike chatbot reminds them of their hypocritical behavior participants feel higher levels of guilt and act more desirably but a machinelike chatbot is not effective for creating guilt or generating compliance.;2021
Consistently exhibited personalities are crucial elements of realistic engaging and behavior-rich conversational virtual agents. Both nonverbal and verbal cues help convey these agents' unseen psychological states contributing to our effective communication with them. We introduce a comprehensive framework to design conversational agents that express personality through non-verbal behaviors like body movement and facial expressions as well as verbal behaviors like dialogue selection and voice transformation. We use the OCEAN personality model which defines personality as a combination of five orthogonal factors of openness conscientiousness extraversion agreeableness and neuroticism. The framework combines existing personality expression methods with novel ones such as new algorithms to convey Laban Shape and Effort qualities. We perform Amazon Mechanical Turk studies to analyze how different communication modalities influence our perception of virtual agent personalities and compare their individual and combined effects on each personality dimension. The results indicate that our personality-basedmodifications are perceived as natural and each additional modality improves perception accuracy with the best performance achieved when all the modalities are present. We also report some correlations for the perception of conscientiousness with neuroticism and openness with extraversion.;2021
Consumers sometimes describe their experience of interacting with artificial intelligence-based human-like chatbots as creepy. This study investigates the antecedents of creepiness (i.e. the chatbot's usability privacy concerns and user variables such as technology anxiety and the need for human interaction) and its impact on consumer loyalty. Grounded in the technology paradox it deepens the understanding of creepiness in light of the theoretical underpinnings of the privacy paradox and privacy cynicism. Presented with the task of obtaining a car insurance quote 430 consumers participated in a simulation involving interaction with a chatbot followed by a questionnaire. The findings show that creepiness decreases loyalty and indirectly impacts it through trust and negative emotions. While usability reduces perceptions of creepiness privacy concerns raised by the interaction with the chatbot increase creepiness which is positively associated with consumer traits (i.e. technology anxiety and need for human interaction). The main contribution of the research lies in its focus on creepiness a concept under-researched in the marketing literature and which can be seen from the perspective of a coping mechanism for consumers' privacy concerns. This paper provides practical implications to orient managers in the design and implementation of chatbots as a promising touch point to build customer loyalty.;2021
Consumption of media and movies in particular is increasing and is influenced by a number of factors. One important and overlooked factor that affects the media consumption choices is the emotional state of the user and the decision making based on it. To include this factor in movie recommendation processes we propose a knowledge graph representing human emotions in the domain of movies. The knowledge graph has been built by extracting emotions out of pre-existing movie reviews using machine learning techniques. To show how the knowledge graph can be used a chatbot prototype has been developed. The chatbot's reasoning mechanism derives movie recommendations for the user by combining the user's emotions which have been extracted from chat messages with the knowledge graph. The developed approach for movie recommendations based on sentiment represented as a knowledge graph has been proven to be technically feasible however it requires more information about the emotions associated with the movies than currently available online. (C) 2021 Elsevier B.V. All rights reserved.;2021
Context. Asynchronous messaging is increasingly used to support human-machine interactions generally implemented through chatbots. Such virtual entities assist the users in activities of different kinds (e.g. work leisure and health-related) and are becoming ingrained into humans' habits due to factors including (i) the availability of mobile devices such as smartphones and tablets (ii) the increasingly engaging nature of chatbot interactions (iii) the release of dedicated APIs from messaging platforms and (iv) increasingly complex AI-based mechanisms to power the bots' behaviors. Nevertheless most of the modern chatbots rely on state machines (implementing conversational rules) and one-fits-all approaches neglecting personalization data-stream privacy management multi-topic management/interconnection and multimodal interactions. Objective. This work addresses the challenges above through an agent-based framework for chatbot development named EREBOTS. Methods. The foundations of the framework are based on the implementation of (i) multi-front-end connectors and interfaces (i.e. Telegram dedicated App and web interface) (ii) enabling the configuration of multi-scenario behaviors (i.e. preventive physical conditioning smoking cessation and support for breast-cancer survivors) (iii) online learning (iv) personalized conversations and recommendations (i.e. mood boost anti-craving persuasion and balance-preserving physical exercises) and (v) responsive multi-device monitoring interface (i.e. doctor and admin). Results. EREBOTS has been tested in the context of physical balance preservation in social confinement times (due to the ongoing pandemic). Thirteen individuals characterized by diverse age gender and country distribution have actively participated in the experimentation reporting advancements in the physical balance and overall satisfaction of the interaction and exercises' variety they have been proposed.;2021
Controllable response generation is an attractive and valuable task to the success of conversational systems. However controlling both pattern and content of the response has not been well studied in existing models since they are mainly based on matching mechanisms. To tackle the problem we first design a pattern model to automatically learn and extract speech patterns from words. The pattern is then integrated into the encoder-decoder model to control the response pattern. Second a sentence sampling algorithm is built to directly insert or delete words in the generated response so that the content is controlled. In this two-stage framework the response could be explicitly controlled by the pattern and content without any human annotation of the post-response dataset. Experiments show the proposed framework achieves better performance in response controllability than the state-of-the-art.;2021
CONVERSATIONAL AGENTS OR chatbots providing question-answer assistance on smart devices have proliferated in recent years and are poised to transform online customer services of corporate sectors.16 Implemented through dialogue management systems chatbots converse through voice-based and textual dialogue and harness natural language processing and artificial intelligence to recognize requests provide responses and predict user behavior.528 Market analysts concur on current adoption trends and the magnitude of growth and impact of chatbots anticipated in the next five years. According to a report by Grand View Research for instance already 45% of users prefer chatbots as the primary point of communications for customer service enquiries translating into a global 'chatbot' market of $1.23 billion by 2025 at a compounded annual growth rate (CAGR) of 24.3%.;2021
Conversation systems usually suffer from the challenge of knowledge management from multiple human experts. The current mechanism used in knowledge-based conversation system is always based on centralized servers which may be problematic in terms of transparency and security. Blockchain solutions are currently being proposed improve the security and efficiency in different domains. However there are various blockchain platforms with different characteristics and conver-sation system implemented using blockchain platform is not in place yet. In this paper we clearly identified the requirement analysis of knowledge-based conversation system and present a decision model for identify the best fitting blockchain platform for knowledge-based conversation system. In the proposed method multiple measurements including Analytical Hierarchy Process (AHP) Fuzzy analytical hierarchy process (FAHP) and Fuzzy Technique for Order Preference by Similarity to Ideal Solution (FTOPSIS) are utilized to analyze and create consistent result together which can be used for the selection of blockchain platforms and improve the efficiency of the decision-making process. (c) 2021 Elsevier B.V. All rights reserved.;2021
Conversational agents (CAs) are natural language user interfaces that emulate human-to-human communication. Because of this emulation research on CAs is inseparably linked to questions about anthropomorphism-the attribution of human qualities including consciousness intentions and emotions to nonhuman agents. Past research has demonstrated that anthropomorphism affects human perception and behavior in human-computer interactions by for example increasing trust and connectedness or stimulating social response behaviors. Based on the psychological theory of anthropomorphism and related research on computer interface design we develop a theoretical framework for designing anthropomorphic CAs. We identify three groups of factors that stimulate anthropomorphism: technology design-related factors task-related factors and individual factors. Our findings from an online experiment support the derived framework but also reveal novel yet counterintuitive insights. In particular we demonstrate that not all combinations of anthropomorphic technology design cues increase perceived anthropomorphism. For example we find that using only nonverbal cues harms anthropomorphism however this effect becomes positive when nonverbal cues are complemented with verbal or human identity cues. We also find that CAs' disposition to complete computerlike versus humanlike tasks and individuals' disposition to anthropomorphize greatly affect perceived anthropomorphism. This work advances our understanding of anthropomorphism and contextualizes the theory of anthropomorphism within the IS discipline. We advise on the directions that research and practice should take to find the sweet spot for anthropomorphic CA design.;2021
Conversational agents (CAs) promise to create significant organisational value by transforming how organisations operate and serve customers. Yet the malleability of this technology poses challenges to both researchers and practitioners because of the wide range of strategic applications they can enable. Drawing on the lens of routine capability this study investigates strategic applications of CAs and their associated implementation enablers and challenges. Via an exploratory case study of eight organisations that have successfully implemented CAs this paper contributes to the literature on the value and implementation of conversational agents in particular and cognitive technologies in general by developing a typology of CA strategic applications and their implementation considerations. For practitioners the findings highlight the interplay between technology user and project management factors that need to be addressed to ensure the successful delivery of the value of CAs.;2021
Conversational agents are becoming popular for providing a more natural and realistic user experience. New studies have become significant to understand how to assess this experience mainly because of the increase in applications of this nature. We systematically reviewed the literature to identify how the user experience is assessed when interacting with conversational agents. A total of 443 studies were identified in the ACM IEEE Springer and Scopus databases. Of these 27 studies met the eligibility criteria. Most studies used their own evaluation methods without adopting questionnaires validated for UX evaluation. Few studies used assessment tools before participants interacted with agents and only two carried out assessments before during and after use. The results of the assessments can be better if specific instruments for UX are adopted. Furthermore it is necessary to assess the experience at different times and use combined methods to understand aspects related to the participants' feelings and behaviours.;2021
Conversational artificial agents and artificially intelligent (AI) voice assistants are becoming increasingly popular. Digital virtual assistants such as Siri or conversational devices such as Amazon Echo or Google Home are permeating everyday life and are designed to be more and more humanlike in their speech. This study investigates the effect this can have on one's conformity with an AI assistant. In the 1950s Solomon Asch's already demonstrated the power and danger of conformity amongst people. In these classical experiments test persons were asked to answer relatively simple questions whilst others pretending to be participants tried to convince the test person to give wrong answers. These studies were later replicated with embodied robots but these physical robots are still rare. In light of our increasing reliance on AI assistants this study investigates to what extent an individual will conform to a disembodied virtual assistant. We also investigate if there is a difference between a group that interacts with an assistant that communicates through text one that has a robotic voice and one that has a humanlike voice. The assistant attempts to subtly influence participants' final responses in a general knowledge quiz and we measure how often participants change their answer after having been given advice. Results show that participants conformed significantly more often to the assistant with a human voice than the one that communicated through text.;2021
Conversational case-based reasoning (CCBR) systems retrieve past cases that are similar to a current problem by eliciting situation descriptions in interactive dialogues with their users. To find out how such human-machine cooperation is put into practice the present article reviews the CCBR literature and extracts a list of dialogue principles - interaction techniques by means of which CCBR systems communicate with their users. Seven dialogue principles are identified and explained: mixed initiative question selection and ordering dealing with abstraction and expertise explanations visualisation and highlighting dialogue termination and evaluation support. The results reveal that current CCBR systems already make great efforts to put user needs into the centre of the interaction. At the same time the current implementation of dialogue principles that adjust CCBR systems to user needs raise questions about who should be in control of these adjustments what levels of human-computer interaction should be adjusted and what goals should guide adjustment decisions. Moreover the present review highlights a number of limitations concerning the methodology and contents of CCBR research and points out questions for future research on human-computer interaction in CCBR systems.;2021
Conversational information retrieval is a relatively new and fast-developing research area but conversation itself has been well studied for decades. Researchers have analysed linguistic phenomena such as structure and semantics but also paralinguistic features such as tone body language and even the physiological states of interlocutors. We tend to treat computers as social agents-especially if they have some humanlike features in their design-and so work from human-to-human conversation is highly relevant to how we think about the design of human-to-computer applications. In this article we summarise some salient past work focusing on social norms structures and affect prosody and style. We examine social communication theories briefly as a review to see what we have learned about how humans interact with each other and how that might pertain to agents and robots. We also discuss some implications for research and design of conversational IR systems.;2021
Conversational interfaces are increasingly popular as a way of connecting people to information. With the increased generative capacity of corpus-based conversational agents comes the need to classify and filter out malevolent responses that are inappropriate in terms of content and dialogue acts. Previous studies on the topic of detecting and classifying inappropriate content are mostly focused on a specific category of malevolence or on single sentences instead of an entire dialogue. We make three contributions to advance research on the malevolent dialogue response detection and classification (MDRDC) task. First we define the task and present a hierarchical malevolent dialogue taxonomy. Second we create a labeled multiturn dialogue data set and formulate the MDRDC task as a hierarchical classification task. Last we apply state-of-the-art text classification methods to the MDRDC task and report on experiments aimed at assessing the performance of these approaches.;2021
Conversational interfaces have recently become a ubiquitous element in both the personal sphere by easing access to services and industrial environments by the automation of services improved customer support and its corresponding cost savings. However designing the dialog model used by these interfaces to decide system responses is still a hard-to-accomplish task for complex conversational interactions. This paper describes a data driven dialog management technique which provides flexibility to develop deploy and maintain this module. Various configurations for classification algorithms are assessed with two dialog corpora of different application domains size dimensionalities and set of possible system responses. The results of the evaluation show satisfactory accuracy and coherence rates in both tasks. As a proof of concept our proposal has also been integrated with DialogFlow a platform provided by Google to design conversational user interfaces. Our proposal has been assessed with a real use case proving that it can be deployed in conjunction with commercial platforms obtaining satisfactory results for the objective and subjective assessments completed.;2021
Conversational interfaces that interact with humans need to continuously establish maintain and repair common ground in task-oriented dialogues. Uncertainty repairs and acknowledgements are expressed in user behaviour in the continuous efforts of the conversational partners to maintain mutual understanding. Users change their behaviour when interacting with systems in different forms of embodiment which affects the abilities of these interfaces to observe users' recurrent social signals. Additionally humans are intellectually biased towards social activity when facing anthropomorphic agents or when presented with subtle social cues. Two studies are presented in this paper examining how humans interact in a referential communication task with wizarded interfaces in different forms of embodiment. In study 1 (N = 30) we test whether humans respond the same way to agents in different forms of embodiment and social behaviour. In study 2 (N = 44) we replicate the same task and agents but introduce conversational failures disrupting the process of grounding. Findings indicate that it is not always favourable for agents to be anthropomorphised or to communicate with non-verbal cues as human grounding behaviours change when embodiment and failures are manipulated.;2021
Conversational responses are non-trivial for artificial conversational agents. Artificial responses should not only be meaningful and plausible but should also (1) have an emotional context and (2) should be non-deterministic (i.e. vary given the same input). The two factors enumerated respectively above are involved and this is demonstrated such that previous studies have tackled them individually. This paper is the first to tackle them together. Specifically we present two models both based upon conditional variational autoencoders. The first model learns disentangled latent representations to generate conversational responses given a specific emotion. The other model explicitly learns different emotions using a mixture of multivariate Gaussian distributions. Experiments show that our proposed models can generate more plausible and diverse conversation responses in accordance with designated emotions compared to baseline approaches.;2021
Conversational systems have become an element of everyday life for billions of users who use speech-based interfaces to services engage with personal digital assistants on smartphones social media chatbots or smart speakers. One of the most complex tasks in the development of these systems is to design the dialogue model the logic that provided a user input selects the next answer. The dialogue model must also consider mechanisms to adapt the response of the system and the interaction style according to different groups and user profiles. Rule-based systems are difficult to adapt to phenomena that were not taken into consideration at design-time. However many of the systems that are commercially available are based on rules and so are the most widespread tools for the development of chatbots and speech interfaces. In this article we present a proposal to: (a) automatically generate the dialogue rules from a dialogue corpus through the use of evolving algorithms (b) adapt the rules according to the detected user intention. We have evaluated our proposal with several conversational systems of different application domains from which our approach provided an efficient way for adapting a set of dialogue rules considering user utterance clusters.;2021
Conversational systems now attract great attention due to their promising potential and commercial values. To build a conversational system with moderate intelligence is challenging and requires big (conversational) data as well as interdisciplinary techniques. Thanks to the prosperity of the Web the massive data available greatly facilitate data-driven methods such as deep learning for human-computer conversational systems. In general retrieval-based conversational systems apply various matching schema between query utterances and responses but the classic retrieval paradigm suffers from prominent weakness for conversations: the system finds similar responses given a particular query. For real human-to-human conversations on the contrary responses can be greatly different yet all are possibly appropriate. The observation reveals the diversity phenomenon in conversations. In this article we ascribe the lack of conversational diversity to the reason that the query utterances are statically modeled regardless of candidate responses through traditional methods. To this end we propose a dynamic representation learning strategy that models the query utterances and different response candidates in an interactive way. To be more specific we propose a Respond-with-Diversity model augmented by the memory module interacting with both the query utterances and multiple candidate responses. Hence we obtain dynamic representations for the input queries conditioned on different response candidates. We frame the model as an end-to-end learnable neural network. In the experiments we demonstrate the effectiveness of the proposed model by achieving a good appropriateness score and much better diversity in retrieval-based conversations between humans and computers.;2021
Co-speech gestures are a vital ingredient in making virtual agents more human-like and engaging. Automatically generated gestures based on speech-input often lack realistic and defined gesture form. We present a database-driven approach guaranteeing defined gesture form. We built a large corpus of over 23000 motion-captured co-speech gestures and select individual gestures based on expressive gesture characteristics that can be estimated from speech audio. The expressive parameters are gesture velocity and acceleration gesture size arm swivel and finger extension. Individual parameter-matched gestures are then combined into animated sequences. We evaluate our gesture generation system in two perceptual studies. The first study compares our method to the ground truth gestures as well as mismatched gestures. The second study compares our method to five current generative machine learning models. Our method outperformed mismatched gesture selection in the first study and showed competitive performance in the second.;2021
COVID-19 chatbots are widely used to screen for symptoms and disseminate information about the virus yet little is known about the population subgroups that interact with this technology and the specific features that are used. An analysis of 1000740 patients invited to use a COVID-19 chatbot 69451 (6.94%) of which agreed to participate shows differences in chatbot feature use by gender race and age. These results can inform future public health COVID-19 symptom screening and information dissemination strategies.;2021
Creating physical-computing systems especially selecting correct electronic components assembling the circuit and implementing the program can be challenging for novice users. In this paper we present FritzBot a data driven conversational agent supporting novice users on creating physical-computing systems through natural language interaction. FritzBot is built upon the structure of a BiLSTM-CRF (bi-directional Long Short-term Memory Network and Conditional Random Field) neural network as a plug-in for Fritzing. The neural network is trained on a lexical circuit-event database derived from 152 students' reports on their physical computing course projects. By processing the user's textual description on his/her physical-computing idea FritzBot can extract the causal relationships between the input and the output events identify the corresponding electronic components and generate the Arduino-based circuit and the code along with the step-by-step construction guidelines. Our user study shows that compared to the original Arduino software and the circuitautocompletion software available in the commercial market FritzBot significantly shortens the time spent reduces the perceived workload and enhances the satisfaction/joy for inexperienced users on designing and prototyping physical-computing systems.;2021
Cross-lingual dialogue systems are increasingly important in e-commerce and customer service due to the rapid progress of globalization. In real-world system deployment machine translation (MT) services are often used before and after the dialogue system to bridge different languages. However noises and errors introduced in the MT process will result in the dialogue system's low robustness making the system's performance far from satisfactory. In this article we propose a novel MT-oriented noise enhanced framework that exploits multi-granularityMTnoises and injects such noises into the dialogue system to improve the dialogue system's robustness. Specifically we first design a method to automatically construct multi-granularity MT-oriented noises and multi-granularity adversarial examples which contain abundant noise knowledge oriented to MT. Then we propose two strategies to incorporate the noise knowledge: (i) Utterance-level adversarial learning and (ii) Knowledge-level guided method. The former adopts adversarial learning to learn a perturbation-invariant encoder guiding the dialogue system to learn noise-independent hidden representations. The latter explicitly incorporates the multi-granularity noises which contain the noise tokens and their possible correct forms into the training and inference process thus improving the dialogue system's robustness. Experimental results on three dialoguemodels two dialogue datasets and two language pairs have shown that the proposed framework significantly improves the performance of the cross-lingual dialogue system.;2021
Cryptocurrencies are proliferating as instantiations of blockchain which is a transparent distributed ledger technology for validating transactions. Blockchain is thus said to embed trust in its technical design. Yet blockchain's technical promise of trust is not fulfilled when applied to the cryptocurrency ecosystem due to many social challenges stakeholders experience. By investigating a cryptocurrency chatbot (Brokerbot) that distributed information on cryptocurrency news and investments we explored social tensions of trust between stakeholders namely the bot's developers users and the bot itself. We found that trust in Brokerbot and in the cryptocurrency ecosystem are two conjoined but separate challenges that users and developers approached in different ways. We discuss the challenging dual-role of a Brokerbot as an object of trust as a chatbot while simultaneously being a mediator of trust in cryptocurrency which exposes the social-technical gap of trust. Lastly we elaborate on trust as a negotiated social process that people shape and are shaped by through emerging ecologies of interlinked technologies like blockchain and conversational interfaces.;2021
Current formal dialectical models postulate normative rules that enable discussants to conduct dialogical interactions without committing fallacies. Though the rules for conducting a dialogue are supposed to apply to interactions between actual arguers they are without exception theoretically motivated. This creates a gap between model and reality because dialogue participants typically leave important content-related elements implicit. Therefore analysts cannot readily relate normative rules to actual debates in ways that will be empirically confirmable. This paper details a new data-driven method for describing discussants' actual reply structures wherein corpus studies serve to acknowledge the complexity of natural argumentation (itself understood as a function of context). Rather than refer exclusively to propositional content as an indicator of arguing pro/contra a given claim the proposed approach to dialogue structure tracks the sequence of dialogical moves itself. This arguably improves the applicability of theoretical dialectical models to empirical data and thus advances the study of dialogue systems.;2021
Current language processing technologies allow the creation of conversational chatbot platforms. Even though artificial intelligence is still too immature to support satisfactory user experience in many mass market domains conversational interfaces have found their way into ad hoc applications such as call centres and online shopping assistants. However they have not been applied so far to social inclusion of elderly people who are particularly vulnerable to the digital divide. Many of them relieve their loneliness with traditional media such as TV and radio which are known to create a feeling of companionship. In this paper we present the EBER chatbot designed to reduce the digital gap for the elderly. EBER reads news in the background and adapts its responses to the user's mood. Its novelty lies in the concept of intelligent radio according to which instead of simplifying a digital information system to make it accessible to the elderly a traditional channel they find familiar -background news- is augmented with interactions via voice dialogues. We make it possible by combining Artificial Intelligence Modelling Language automatic Natural Language Generation and Sentiment Analysis. The system allows accessing digital content of interest by combining words extracted from user answers to chatbot questions with keywords extracted from the news items. This approach permits defining metrics of the abstraction capabilities of the users depending on a spatial representation of the word space. To prove the suitability of the proposed solution we present results of real experiments conducted with elderly people that provided valuable insights. Our approach was considered satisfactory during the tests and improved the information search capabilities of the participants.;2021
Current technological developments as well as widespread application of artificial intelligence will doubtlessly continue to impact how people live and work. In this research we explored synergies between human workers and AI in managerial tasks. We hypothesized that human-AI collaboration will increase productivity. In the paper several levels of proximity between AI and humans in a work setting are distinguished. The multi-stage study covering the exploratory phase in which we conducted a study of preferences using 10-item Likert scale was conducted with a sample of 366 respondents. The study focused on working with different types of AI. The second and third phase of the study in which we primarily used qualitative methods (scenario-based design combined with semi-structured interviews with six participants) focused on researching modes of collaboration between humans and virtual assistants. The study results generally confirmed our hypothesis about increased productivity due to enhanced human-AI collaboration proving that the future of AI in knowledge work needs to focus not on full automation but rather on collaborative approaches where humans and AI work closely together.;2021
Currently dialogue systems have attracted increasing research interest. In particular background knowledge is incorporated to improve the performance of dialogue systems. Existing dialogue systems mostly assume that the background knowledge is correct and comprehensive. However low-quality background knowledge is common in real-world applications. On the other hand dialogue datasets with manual labeled background knowledge are often insufficient. To tackle these challenges this article presents an algorithm to revise low-quality background knowledge named background knowledge revising transformer (BKR-Transformer). By innovatively formulating the knowledge revising task as a sequence-to-sequence (Seq2Seq) problem BKR-Transformer generates the revised background knowledge based on the original background knowledge and dialogue history. More importantly to alleviate the effect of insufficient training data BKR-Transformer introduces the ideas of parameter sharing and tensor decomposition which could significantly reduce the number of model parameters. Furthermore this work presents a background knowledge revising and incorporating dialogue model that combines the background knowledge revision with response selection in a unified model. Empirical analyses on real-world applications demonstrate that the proposed background knowledge revising and incorporating dialogue system (BKRI) could revise most low-quality background knowledge and substantially outperforms previous dialogue models.;2021
Data-driven predictions have become an inseparable part of business decisions. Artificial Intelligence (AI) has started helping the product and support teams perform more accurate experiments in various business settings. This study proposes a framework for businesses based on inductive learnings related to success and barriers shared on social media platforms. Our goal is to analyse the signals emerging from these conversational opinions from the early adoption of AI with a focus towards facilitators and barriers faced by teams. Factors like efficiency innovation business research product novelty manual intervention adaptability emotion support personal growth experiential learning fear of failure and fear of upgradation have been identified based on an exploratory study and then a confirmatory study. We present the learnings through a roadmap for practitioners. This study contributes to the IS literature by delineating AI as a determinant of success and introduces a lot of organizational factors into the model.;2021
Deep learning is providing very positive results in areas related to conversational interfaces such as speech recognition but its potential benefit for dialog management has still not been fully studied. In this paper we perform an assessment of different configurations for deep-learned dialog management with three dialog corpora from different application domains and varying in size dimensionality and possible system responses. Our results have allowed us to identify several aspects that can have an impact on accuracy including the approaches used for feature extraction input representation context considera-tion and the hyper-parameters of the deep neural networks employed. (c) 2021 Elsevier B.V. All rights reserved.;2021
Despite its significant effectiveness in adversarial training approaches to multidomain task-oriented dialogue systems adversarial inverse reinforcement learning of the dialogue policy frequently fails to balance the performance of the reward estimator and policy generator. During the optimization process the reward estimator frequently overwhelms the policy generator resulting in excessively uninformative gradients. We propose the variational reward estimator bottleneck (VRB) which is a novel and effective regularization strategy that aims to constrain unproductive information flows between inputs and the reward estimator. The VRB focuses on capturing discriminative features by exploiting information bottleneck on mutual information. Quantitative analysis on a multidomain task-oriented dialogue dataset demonstrates that the VRB significantly outperforms previous studies.;2021
Despite the growing number of brands that rely on chatbots to address customer service inquiries that once required human intervention academics and practitioners are only beginning to acknowledge the role of chatbots in brand-building activities. Chatbots can initiate online conversations thereby often serving as a consumer's first brand impression. However little is known about how managers can strategically tailor a chatbot's initial message to foster consumer-brand connections and ultimately engagement. Three studies demonstrate that when chatbots initiate a conversation using a warm (vs. competent) message brand engagement increases as assessed using both computerized text analysis and traditional scale measures. Brand-self distance mediates this effect such that a warm (vs. competent) initial chatbot message makes consumers feel closer to the brand. Further the authors identify brand affiliation as a theoretically relevant moderator. This research thus offers managers insight into how initial chatbot messages can attract and engage consumers.;2021
Despite the hype surrounding Artificial Intelligence (AI) the potential of AI in customer relationship manage-ment (CRM) remains underexplored in academia. A between-subjects experiment examined the effects of the type of relationship (virtual assistantship versus virtual friendship) consumers build with AI-enabled chatbots on brand personality perception parasocial interaction (PSI) and CRM. The main effects of the relationship type on brand personality perception appeared for competent brand personality but not for sincere brand personality. The consumer-chatbot relationship type had effects on CRM-related outcomes (behavioral intention satisfaction and trust) through competent brand personality. Consumers who interacted with a friend chatbot experienced stronger PSI with the chatbot and the relationship type had an influence on brand personality perception through PSI. This mediating effect of PSI was observed for both brand personalities -competence and sincerity. The moderating role of ideological views (technopians versus luddites) in explaining the effect of the relationship type on brand personality perception was detected for sincere brand personality. AI designers and marketers need to develop AI user interface (UI) and user experience (UX) along with marketing strategies that not only can appeal to technopians ready to adopt innovative AI customer representatives but also can ultimately help alle-viate luddites? AI anxiety in the emerging ?feeling economy? envisioned by Rust and Huang.;2021
Developing an intelligent chatbot has evolved in the last few years to become a trending topic in the area of computer science. However a chatbot often fails to understand the user's intent which can lead to the generation of inappropriate responses that cause dialogue breakdown and user dissatisfaction. Detecting the dialogue breakdown is essential to improve the performance of the chatbot and increase user satisfaction. Recent approaches have focused on modeling conversation breakdown using serveral approaches including supervised and unsupervised approaches. Unsupervised approach relay heavy datasets which make it challenging to apply it to the breakdown task. Another challenge facing predicting breakdown in conversation is the bias of human annotation for the dataset and the handling process for the breakdown. To tackle this challenge we have developed a supervised ensemble automated approach that measures Chatbot Quality of Service (CQoS) based on dialogue breakdown. The proposed approach is able to label the datasets based on sentiment considering the context of the conversion to predict the breakdown. In this paper we aim to detect the affect of sentiment change of each speaker in a conversation. Furthermore we use the supervised ensemble model to measure the CQoS based on breakdown. Then we handle this problem by using a hand-over mechanism that transfers the user to a live agent. Based on this idea we perform several experiments across several datasets and state-of-the-art models and we find that using sentiment as a trigger for breakdown outperforms human annotation. Overall we infer that knowledge acquired from the supervised ensemble model can indeed help to measure CQoS based on detecting the breakdown in conversation.;2021
Dialog state tracking (DST) which estimates dialog states given a dialog context is a core component in task-oriented dialog systems. Existing data-driven methods usually extract features automatically through deep learning. However most of these models have limitations. First compared with hand-crafted delexicalization features such features in deep learning approaches are not universal. However they are important for tracking unseen slot values. Second such models do not work well in situations where noisy labels are ubiquitous in datasets. To address these challenges we propose a robust dialog state tracker with contextual-feature augmentation. Contextual-feature augmentation is used to extract generalized features hence it is capable of solving the unseen slot value tracking problem. We apply a simple but effective deep learning paradigm to train our DST model with noisy labels. The experimental results show that our model achieves state-of-the-art scores in terms of joint accuracy on the MultiWOZ 2.0 dataset. In addition we show its performance in tracking unseen slot values by simulating unseen domain dialog state tracking.;2021
Dialogue agent a derivative of intelligent agent in the field of computational linguistics is a computer program that is capable of generating responses and performing conversation in natural language. The field of computational linguistics is flourishing due to the intensive growth of dialogue agents the most potential one is providing voice controlled smart personal assistant service for handsets and homes. The agents are usable accessible but perform task-related short conversations. Non-goal-oriented dialogue agents are designed to imitate extended human-human conversations also called as chit-chat to provide the consumer with a satisfactory experience on the conversation quality. The design of such agents is primarily defined by a language model unlike goal-oriented dialogue agents that employees slot based or ontology-based frameworks hence most of the methods are data-driven. This paper surveys the current state of the art of non-goal-oriented dialogue systems specifically data-driven methods the most prevalent being deep learning. This paper aims at (a) providing an insight of recent methods and architectures proposed for building context and modeling response along with a comprehensive review of the state of the art (b) examine the type of data set and evaluation methods available (c) present the challenges and limitation that the recent models dataset and evaluation methods constitute.;2021
Dialogue systems have made massive promising progress contributed by deep learning techniques and have been widely applied in our life. However existing end-to-end neural models suffer from the problem of tending to generate uninformative and generic responses because they cannot ground dialogue context with background knowledge. In order to solve this problem many researchers begin to consider combining external knowledge in dialogue systems namely knowledge-enhanced dialogue systems. The challenges of knowledge-enhanced dialogue systems include how to select the appropriate knowledge from large-scale knowledge bases how to read and understand extracted knowledge and how to integrate knowledge into responses generation process. Combined with external knowledge dialogue systems can deeply understand the dialogue context and generate more informative and logical responses. This survey gives a comprehensive review of knowledge-enhanced dialogue systems summarizes research progress to solve these challenges and proposes some open issues and research directions. (c) 2021 Elsevier B.V. All rights reserved.;2021
Dialogue systems also known as conversational agents are computing systems that use algorithms for speech and language processing to engage in conversation with humans or other conversation-capable systems. A chatbot is a conversational agent that has as its primary goal to maximize the length of the conversation without any specific targeted task. When a chatbot is embellished with an artistic approach that is meant to evoke an emotional response then it is called a virtual being. On the other hand conversational agents that interact with the physical world require the use of specialized hardware to sense and process captured information. In this article we describe EdgeAvatar a system based on Edge Computing principles for the creation of virtual beings. The objective of the EdgeAvatar system is to provide a streamlined and modular framework for virtual being applications that are to be deployed in public settings. We also present two implementations that use EdgeAvatar and are inspired by historical figures to interact with visitors of the Venice Biennale 2019. EdgeAvatar can adapt to fit different approaches for AI powered conversations.;2021
Different people have different habits of describing their intents in conversations. Some people tend to deliberate their intents in several successive utterances i.e. they use several consistent messages for readability instead of a long sentence to express their question. This creates a predicament faced by the application of dialogue systems especially in real-world industry scenarios in which the dialogue system is unsure whether it should answer the query of user immediately or wait for further supplementary input. Motivated by such an interesting predicament we define a novel Wait-or-Answer task for dialogue systems. We shed light on a new research topic about how the dialogue system can be more intelligent to behave in this Wait-or-Answer quandary. Further we propose a predictive approach named Predict-then-Decide (PTD) to tackle this Wait-or-Answer task. More specifically we take advantage of a decision model to help the dialogue system decide whether to wait or answer. The decision of decision model is made with the assistance of two ancillary prediction models: a user prediction and an agent prediction. The user prediction model tries to predict what the user would supplement and uses its prediction to persuade the decision model that the user has some information to add so the dialogue system should wait. The agent prediction model tries to predict the answer of the dialogue system and convince the decision model that it is a superior choice to answer the query of user immediately since the input of user has come to an end. We conduct our experiments on two real-life scenarios and three public datasets. Experimental results on five datasets show our proposed PTD approach significantly outperforms the existing models in solving this Wait-or-Answer problem.;2021
Digital health is transforming the delivery of health care around the world to meet the growing challenges presented by ageing populations with multiple chronic conditions. Digital health technologies can support the delivery of personalised nutrition care through the standardised Nutrition Care Process (NCP) by using personal data and technology-supported delivery modalities. The digital disruption of traditional dietetic services is occurring worldwide supporting responsive and high-quality nutrition care. These disruptive technologies include integrated electronic and personal health records mobile apps wearables artificial intelligence and machine learning conversation agents chatbots and social robots. Here we outline how digital health is disrupting the traditional model of nutrition care delivery and outline the potential for dietitians to not only embrace digital disruption but also take ownership in shaping it aiming to enhance patient care. An overview is provided of digital health concepts and disruptive technologies according to the four steps in the NCP: nutrition assessment diagnosis intervention and monitoring and evaluation. It is imperative that dietitians stay abreast of these technological developments and be the leaders of the disruption not simply subject to it. By doing so dietitians now as well as in the future will maximise their impact and continue to champion evidence-based nutrition practice.;2021
Digital Voice Assistants (DVAs) like Google Home provide automated news media and other content directly into the home. In this article we outline how Google Home's content delivery can support the wellbeing and independence of older people. We argue that automated media provided by DVAs enrols older people in a dialectic relationship with the automated content and feminised conversation they deliver uniquely performed within people's own everyday life circumstances. We demonstrate this by drawing on ethnographic insights generated during a trial of smart home technologies with older Australian households who are 'ageing in place' in regional New South Wales. For most participants the trial was their first encounter with DVAs and the modes of media and content delivery including for music news weather trivia jokes facts and images. While DVAs bring new experiences via content communication and companionship they are also subverted ignored or transformed as people improvise to make them 'fit' within their homes and lives. These dynamics underpin how DVAs automated content delivery and user's interactions can support people's sense of wellness and their independent daily practices at home.;2021
Digitalization of healthcare delivery is rapidly fostering development of precision medicine. Multiple digital technologies known as telehealth or eHealth tools are guiding individualized diagnosis and treatment for patients and can contribute significantly to the objectives of precision medicine. From a basis of one-size-fits-all  healthcare precision medicine provides a paradigm shift to deliver a more nuanced and personalized approach. Genomic medicine utilizing new technologies can provide precision analysis of causative mutations with personalized understanding of mechanisms and effective therapy. Education is fundamental to the telehealth process with artificial intelligence (AI) enhancing learning for healthcare professionals and empowering patients to contribute to their care. The Gulf Cooperation Council (GCC) region is rapidly implementing telehealth strategies at all levels and a workshop was convened to discuss aspirations of precision medicine in the context of pediatric endocrinology including diabetes and growth disorders with this paper based on those discussions. GCC regional investment in AI bioinformatics and genomic medicine is rapidly providing healthcare benefits. However embracing precision medicine is presenting some major new design installation and skills challenges. Genomic medicine is enabling precision and personalization of diagnosis and therapy of endocrine conditions. Digital education and communication tools in the field of endocrinology include chatbots interactive robots and augmented reality. Obesity and diabetes are a major challenge in the GCC region and eHealth tools are increasingly being used for management of care. With regard to growth failure digital technologies for growth hormone (GH) administration are being shown to enhance adherence and response outcomes. While technical innovations become more affordable with increasing adoption we should be aware of sustainability design and implementation costs training of HCPs and prediction of overall healthcare benefits which are essential for precision medicine to develop and for its objectives to be achieved.;2021
Domain adaptation has recently become a key problem in dialogue systems research. Deep learning while being the preferred technique for modeling such systems works best given massive training data. However in real-world scenarios such resources are rarely available for new domains and the ability to train with a few dialogue examples can be considered essential. Pre-training on large data sources and adapting to the target data has become the standard method for few-shot problems within the deep learning framework. In this paper we present GRTr a hybrid generative-retrieval model based on the large-scale general-purpose language model GPT[2] fine-tuned to the multi-domain MetaLWOz dataset. In addition to robust and diverse response generation provided by the GPT[2] our model is able to estimate generation confidence and is equipped with retrieval logic as a fallback for the cases when the estimate is low. GRTr is the winning entry at the fast domain adaptation task of DSTC-8 in human evaluation (>4% improvement over the 2nd place system). It also attains superior performance to a series of baselines on automated metrics on MetaLWOz and MultiWOZ a multi-domain dataset of goal-oriented dialogues. In this paper we also conduct a study of GRTr's performance in the setup of limited adaptation data evaluating the model's overall response prediction performance on MetaLWOz and goal-oriented performance on MultiWOZ.;2021
Drawing from evolutionary psychology of anthropomorphism and social phobia two between-subjects experiments examined the effects of different types of customer service chatbots. Experiment 1 supports the interaction effects between chatbots' anthropomorphism and con-sumers' social phobia on continuance use intention and willingness to recommend the chatbot. Consumers with high social phobia prefer anthropomorphic chatbots to less anthropomorphic chatbots. Experiment 2 confirms the moderating role of social phobia in determining the effects of consumer-chatbot personality matching (similarity attraction) vs. mismatching (complementarity attraction) on the outcome variables only for competent chatbots. For the consumer-chatbot personality mismatching condition developing competent chatbots for less conscientious con-sumers with high social phobia will help alleviate socially isolated consumers' social pain while developing too smart chatbots for less conscientious consumers with low social phobia can have detrimental effects. Evolutionary psychological mechanisms and managerial implications for chatbot developers and creative directors are explained.;2021
Due to recent DNN advancements many NLP problems can be effectively solved using transformer-based models and supervised data. Unfortunately such data is not available in some languages. This research is based on assumptions that (1) training data can be obtained by the machine translating it from another language (2) there are cross-lingual solutions that work without the training data in the target language. Consequently in this research we use the English dataset and solve the intent detection problem for five target languages (German French Lithuanian Latvian and Portuguese). When seeking the most accurate solutions we investigate BERT-based word and sentence transformers together with eager learning classifiers (CNN BERT fine-tuning FFNN) and lazy learning approach (Cosine similarity as the memory-based method). We offer and evaluate several strategies to overcome the data scarcity problem with machine translation cross-lingual models and a combination of the previous two. The experimental investigation revealed the robustness of sentence transformers under various cross-lingual conditions. The accuracy equal to similar to 0.842 is achieved with the English dataset with completely monolingual models is considered our top-line. However cross-lingual approaches demonstrate similar accuracy levels reaching similar to 0.831 similar to 0.829 similar to 0.853 similar to 0.831 and similar to 0.813 on German French Lithuanian Latvian and Portuguese languages.;2021
Due to the rapid increase in the development of Task-oriented dialogue systems the need for labelled dialogue corpus has become inevitable. For the Hindi language there is no such dialogue corpus yet available. As a first attempt we release a Hindi Dialogue Restaurant Search (HDRS) corpus and compare various state-of-the-art dialogue state tracking (DST) models on it. The corpus consists of 1.4 k human-to-human typed dialogues collected using Wizard-of-Oz paradigm. The paper starts with a brief description of the corpus by providing the details of features corpus collection process and statistical analysis then the performance of baseline NLU and DST models are investigated. Further we experimented two categories of state-of-the-art belief state trackers: (1) Non-contextual pre-trained word embedding based DST models (2) Contextual pre-trained BERT based DST models. All belief trackers follow a three-layered generic architecture. The category-1 models use the static domain ontology while category-2 models have the capability to handle the dynamic ontology. The DST models are compared on joint-goal and turn-request accuracy. Global encoder and Slot-ATtentive decoders (GSAT) outperforms all the models with 83.25% joint-goal accuracy followed by SUMBT.;2021
Each year more than 800000 persons die by suicide making it a leading cause of death worldwide. Recent innovations in information and communication technology may offer new opportunities in suicide prevention in individuals hereby potentially reducing this number. In our project we design digital indices based on both self-reports and passive mobile sensing and test their ability to predict suicidal ideation a major predictor for suicide and psychiatric hospital readmission in high-risk individuals: psychiatric patients after discharge who were admitted in the context of suicidal ideation or a suicidal attempt or expressed suicidal ideations during their intake. Specifically two smartphone applications -one for self-reports (SIMON-SELF) and one for passive mobile sensing (SIMON-SENSE)- are installed on participants' smartphones. SIMON-SELF uses a text-based chatbot called Simon to guide participants along the study protocol and to ask participants questions about suicidal ideation and relevant other psychological variables five times a day. These self-report data are collected for four consecutive weeks after study participants are discharged from the hospital. SIMON-SENSE collects behavioral variables -such as physical activity location and social connectedness- parallel to the first application. We aim to include 100 patients over 12 months to test whether (1) implementation of the digital protocol in such a high-risk population is feasible and (2) if suicidal ideation and psychiatric hospital readmission can be predicted using a combination of psychological indices and passive sensor information. To this end a predictive algorithm for suicidal ideation and psychiatric hospital readmission using various learning algorithms (e.g. random forest and support vector machines) and multilevel models will be constructed. Data collected on the basis of psychological theory and digital phenotyping may in the future and based on our results help reach vulnerable individuals early and provide links to just-in-time and cost-effective interventions or establish prompt mental health service contact. The current effort may thus lead to saving lives and significantly reduce economic impact by decreasing inpatient treatment and days lost to inability.;2021
Education is an area where innovation moves slowly. In this study we will propose a framework with a novel approach that will support the development of a multi-interactive chatbot's system for an educational area using AIML 2.0. The system will facilitate the students for their learning towards an outcome-based education domain. The proposed framework will be composed of a user module which consists of user and user interface chat agents module which will respond to the user query chatbot KB which will act as the brain for the chatbot system and socket system for establishing the communication link. Finally the proposed system will be evaluated using a confusion matrix. The multichatbot communication system will support text-based dialogues on a limited set of questions related to education. However the system will be implemented in java. The outcomes of this research will be useful for the education sector where these intelligent systems will help the students in schools universities and other training scenarios.;2021
Educational chatbots (ECs) are chatbots designed for pedagogical purposes and are viewed as an Internet of Things (IoT) interface that could revolutionize teaching and learning. These chatbots are strategized to provide personalized learning through the concept of a virtual assistant that replicates humanized conversation. Nevertheless in the education paradigm ECs are still novel with challenges in facilitating deploying designing and integrating it as an effective pedagogical tool across multiple fields and one such area is project-based learning. Therefore the present study investigates how integrating ECs to facilitate team-based projects for a design course could influence learning outcomes. Based on a mixed-method quasi-experimental approach ECs were found to improve learning performance and teamwork with a practical impact. Moreover it was found that ECs facilitated collaboration among team members that indirectly influenced their ability to perform as a team. Nevertheless affective-motivational learning outcomes such as perception of learning need for cognition motivation and creative self-efficacy were not influenced by ECs. Henceforth this study aims to add to the current body of knowledge on the design and development of EC by introducing a new collective design strategy and its pedagogical and practical implications.;2021
Efforts to develop autonomous and intelligent systems (AIS) have exploded across a range of settings in recent years from self-driving cars to medical diagnostic chatbots. These have the potential to bring enormous benefits to society but also have the potential to introduce new-or amplify existing-risks. As these emerging technologies become more widespread one of the most critical risk management challenges is to ensure that failures of AIS can be rigorously analyzed and understood so that the safety of these systems can be effectively governed and improved. AIS are necessarily developed and deployed within complex human social and organizational systems but to date there has been little systematic examination of the sociotechnical sources of risk and failure in AIS. Accordingly this article develops a conceptual framework that characterizes key sociotechnical sources of risk in AIS by reanalyzing one of the most publicly reported failures to date: the 2018 fatal crash of Uber's self-driving car. Publicly available investigative reports were systematically analyzed using constant comparative analysis to identify key sources and patterns of sociotechnical risk. Five fundamental domains of sociotechnical risk were conceptualized-structural organizational technological epistemic and cultural-each indicated by particular patterns of sociotechnical failure. The resulting SOTEC framework of sociotechnical risk in AIS extends existing theories of risk in complex systems and highlights important practical and theoretical implications for managing risk and developing infrastructures of learning in AIS.;2021
Embodied conversational agents (ECAs) could engage users in eHealth by building mutual understanding (i.e. rapport) via emotional expressions. We compared an ECA's emotions expressed in text with an ECA's emotions in facial expressions on users' perceptions of rapport. We used a 2 x 2 design combining a happy or neutral facial expression with a happy or neutral textual expression. Sixty-three participants (mean 48 +/- 22 years) had a dialogue with an ECA on healthy living and rated multiple rapport items. Results show that participants' perceived rapport for an ECA with a happy facial expression and neutral textual expression and an ECA with a neutral facial expression and happy textual expression was significantly higher than the neutral value of the rapport scale (P = 0.049 and P = 0.008 respectively). Furthermore results show no significant difference in overall rapport between the conditions (P = 0.062) but a happy textual expression for an ECA with a neutral facial expression shows higher ratings of the individual rapport items helpfulness (P = 0.019) and enjoyableness (P = 0.028). Future research should investigate users' rapport towards an ECA with different emotions in long-term interaction and how a user's age and personality and an ECA's animations affect rapport building. Optimizing rapport building between a user and an ECA could contribute to achieving long-term interaction with eHealth.;2021
Embodied conversational agents are often included in health behaviour change applications as intelligent virtual coaches. A major challenge in their development is tailoring coaching dialogues to user profiles. Agents should collect information about the user and consequently adapt the strategy that guides their interactions. Previous research discovered relations between users' motivation profiles and potential effective coaching strategies. In the current paper we describe an experiment with multiple agents that tests if users with certain motivation profiles prefer certain (tailored) strategies. Participants were classified into four motivation groups (Intrinsic Motivation External Regulation Dual Motivation A-motivation) following their responses to a questionnaire on motivation towards healthy living. Then two coaches suggested a positively and a negatively tailored strategy. Participants rated these and chose their favourite. Results (N = 108) show that the Dual Motivation group appreciated their positively tailored strategy more than their negatively tailored strategy while intrinsically motivated participants appreciated both strategies. Furthermore agents' likeability does not seem to influence strategy appreciation while there was an effect of participant's age and gender. We conclude that coaching strategies for dialogues with agents can be tailored to personal motivation to live healthy. Future research should focus on performing a long-term study in a real-life setting.;2021
Embodied Virtual Agents (EVAs) are used today as interfaces for social robots educational tutors game counterparts medical assistants as well as companions for the elderly and individuals with psychological or behavioral conditions. Forming a reliable and trustworthy interaction is critical to the success and acceptability of this new form of interaction. In this paper we report on a study investigating how trust is influenced by the cooperativeness of an EVA as well as an individuals prior experience with other agents. Participants answered two sets of multiple choice questions working with a different agent in each set. Two types of agent behaviors were possible: Cooperative and Uncooperative. In addition to participants achieving significantly higher performance and having higher trust for the cooperative agent we found that participants' trust for the cooperative agent was significantly higher if they interacted with an uncooperative agent in one of the sets compared to working with cooperative agents in both sets. Furthermore we found that participants may still decide to choose agent's suggested answer (which can be incorrect) over theirs even if they are fairly certain their own answer is the correct one. The results suggest that trust for an EVA is relative and it is dependent on user's history of interaction with different agents in addition to current agent's behavior. The findings provide insight into important considerations for creating trustworthy EVAs.;2021
Emotion recognition in conversations is an important step in various virtual chatbots which require opinion-based feedback like in social media threads online support and many more applications. Current emotion recognition in conversations models face issues like: (a) loss of contextual information in between two dialogues of a conversation (b) failure to give appropriate importance to significant tokens in each utterance (c) inability to pass on the emotional information from previous utterances. The proposed model of Advanced Contextual Feature Extraction (AdCOFE) addresses these issues by performing unique feature extraction using knowledge graphs sentiment lexicons and phrases of natural language at all levels (word and position embedding) of the utterances. Experiments on emotion recognition in conversations datasets show that AdCOFE is beneficial in capturing emotions in conversations.;2021
End-to-end task-oriented dialogue systems which provide a natural and informative way for human- computer interaction are gaining more and more attention. The main challenge of such dialogue systems is how to effectively incorporate external knowledge bases into the learning framework. However existing approaches usually overlook the natural graph structure information in the knowledge base and the relevant information between the knowledge base and the dialogue history which makes them deficient in handling the above challenge. Besides existing methods ignore the entity imbalance problem and treat different entities in system responses indiscriminately which limits the learning of hard target entities. To address the two challenges we propose Heterogeneous Relational Graph Neural Networks with Adaptive Objective (HRGNN-AO) for end-to-end task-oriented dialogue systems. In the method we explore effective heterogeneous relational graphs to jointly capture multi perspective graph structure information from the knowledge base and the dialogue history which ultimately facilitates the generation of informative responses. Moreover we design two components shared-private parameterization and hierarchical attention mechanism to solve the overfitting and confusion problems in the heterogeneous relational graph respectively. To handle the entity imbalance problem we propose an adaptive objective which dynamically adjusts the weights of different target entities during the training process. The experimental results show that HRGNN-AO is effective in generating informative responses and outperforms state-of-the-art dialogue systems on the SMD and extended Multi-WOZ 2.1 datasets. (c) 2021 Elsevier B.V. All rights reserved.;2021
Entity Coreference Resolution is the task of resolving all mentions in a document that refer to the same real world entity and is considered as one of the most difficult tasks in natural language understanding. It is of great importance for downstream natural language processing tasks such as entity linking machine translation summarization chatbots etc. This work aims to give a detailed review of current progress on solving Coreference Resolution using neural-based approaches. It also provides a detailed appraisal of the datasets and evaluation metrics in the field as well as the subtask of Pronoun Resolution that has seen various improvements in the recent years. We highlight the advantages and disadvantages of the approaches the challenges of the task the lack of agreed-upon standards in the task and propose a way to further expand the boundaries of the field.;2021
Evolutionary optimization aims to tune the hyper-parameters during learning in a computationally fast manner. For optimization of multi-task problems evolution is done by creating a unified search space with a dimensionality that can include all the tasks. Multi-task evolution is achieved via selective imitation where two individuals with the same type of skill are encouraged to crossover. Due to the relatedness of the tasks the resulting offspring may have a skill for a different task. In this way we can simultaneously evolve a population where different individuals excel in different tasks. In this paper we consider a type of evolution called Genetic Programming (GP) where the population of genes have a tree-like structure and can be of different lengths and hence can naturally represent multiple tasks. We apply the model to multi-task neuroevolution that aims to determine the optimal hyper-parameters of a neural network such as number of nodes learning rate and number of training epochs using evolution. Here each gene is encoded with the hyper parameters for a single neural network. Previously optimization was done by enabling or disabling individual connections between neurons during evolution. This method is extremely slow and does not generalize well to new neural architectures such as Seq2Seq. To overcome this limitation we follow a modular approach where each sub-tree in a GP can be a sub-neural architecture that is preserved during crossover across multiple tasks. Lastly in order to leverage on the inter-task covariance for faster evolutionary search we project the features from both tasks to common space using fuzzy membership functions. The proposed model is used to determine the optimal topology of a feed-forward neural network for classification of emotions in physiological heart signals and also a Seq2seq chatbot that can converse with kindergarten children. We can outperform baselines by over 10% in accuracy.;2021
Existing multi-turn context-response matching methods mainly concentrate on obtaining multi-level and multi-dimension representations and better interactions between context utterances and response. However in real-place conversation scenarios whether a response candidate is suitable not only counts on the given dialogue context but also other backgrounds e.g. wording habits user-specific dialogue history content. To fill the gap between these up-to-date methods and the real-world applications we incorporate user-specific dialogue history into the response selection and propose a personalized hybrid matching network (PHMN). Our contributions are two-fold: (1) our model extracts personalized wording behaviors from user-specific dialogue history as extra matching information (2) we perform hybrid representation learning on context-response utterances and explicitly incorporate a customized attention mechanism to extract vital information from context-response interactions so as to improve the accuracy of matching. We evaluate our model on two large datasets with user identification i.e. personalized Ubuntu dialogue Corpus (P-Ubuntu) and personalized Weibo dataset (P-Weibo). Experimental results confirm that our method significantly outperforms several strong models by combining personalized attention wording behaviors and hybrid representation learning.;2021
Facility management platforms are widely used in the facility maintenance phase of the building life cycle. However a large amount of complex building information affects facility managers' efficiency and user experience in retrieving specific information on the facility management platform. Therefore this research aims to develop a conversation-based method to improve the efficiency and user experience of facility management information delivery. The proposed method contains four major modules: decision mechanism equipment dataset intent analysis and knowledge base. A chatbot prototype was developed based on the proposed method. The prototype was then validated through a feasibility test and field test at the Shulin Arts Comprehensive Administration Building in Taiwan. The results showed that the proposed method changes the traditional information delivery between users and the facility management platform. By integrating natural language processing (NLP) building information modelling (BIM) and ontological techniques the proposed method can increase the efficiency of FM information retrieval.;2021
Featured Application Automatic speech recognition chatbot voice-assisted control multimodal man-machine interaction systems. Speech recognition consists of converting input sound into a sequence of phonemes then finding text for the input using language models. Therefore phoneme classification performance is a critical factor for the successful implementation of a speech recognition system. However correctly distinguishing phonemes with similar characteristics is still a challenging problem even for state-of-the-art classification methods and the classification errors are hard to be recovered in the subsequent language processing steps. This paper proposes a hierarchical phoneme clustering method to exploit more suitable recognition models to different phonemes. The phonemes of the TIMIT database are carefully analyzed using a confusion matrix from a baseline speech recognition model. Using automatic phoneme clustering results a set of phoneme classification models optimized for the generated phoneme groups is constructed and integrated into a hierarchical phoneme classification method. According to the results of a number of phoneme classification experiments the proposed hierarchical phoneme group models improved performance over the baseline by 3% 2.1% 6.0% and 2.2% for fricative affricate stop and nasal sounds respectively. The average accuracy was 69.5% and 71.7% for the baseline and proposed hierarchical models showing a 2.2% overall improvement.;2021
Featured Application Increase vaccination motivation self-efficacy and vaccination behavioral intention by using Child Vaccination Chatbot. The decreased rate of children's vaccination has resulted in outbreaks of vaccine-preventable diseases and vaccination hesitancy is being brought about by the uncertainty caused by the continuing COVID-19 pandemic. With this study we aimed to assess the efficacy of a child vaccination chatbot based on changes in variables such as vaccination information motivation self-efficacy and vaccination behavioral intention. From 30 January to 15 February 2020 65 parents raising children <= 35 months old who were expected to be vaccinated within three months participated in the trial through online recruitment. Participants were randomly assigned to either the experimental group (n = 34) or the control group (n = 31) and were followed up with over a period of 12 weeks. During this period both groups of participants were provided with vaccination schedule reminders. The experimental group were additionally provided with vaccination-related information and motivation boosters by a chatbot (real-time consultation messenger service) the control group was provided the same information by brochure. Comparing both groups the experimental group that used the chatbot scored higher on vaccination information motivation self-efficacy and vaccination behavioral intention than the control group. This suggests that the chatbot provided useful and timely information to parents increasing vaccination motivation self-efficacy and vaccination rates. This study provides evidence that chatbots are useful tools to encourage immunization through the provision of reminders and real-time consultation messenger services during the global health crisis and beyond.;2021
Featured Application Natural language dialogue macro-navigation for the visually impaired. The proposed technology can be applied to other professional fields such as medical consultation or legal services. Dialogue in natural language is the most important communication method for the visually impaired. Therefore the dialogue system is the main subsystem in the visually impaired navigation system. The purpose of the dialogue system is to understand the user's intention gradually establish context through multiple conversations and finally provide an accurate destination for the navigation system. We use the knowledge graph as the basis of reasoning in the dialogue system and then update the knowledge graph so that the system gradually conforms to the user's background. Based on the experience of using the knowledge graph in the navigation system of the visually impaired we expect that the same framework can be applied to more fields in order to improve the practicality of natural language dialogue in human-computer interaction.;2021
Fighter jets are a critical national asset. Because of the high cost of their manufacture and that of their related equipment both pilots and maintenance personnel must complete intensive training before coming into contact with a jet. Due to gradual military downsizing one-on-one training is often impracticable and the level of familiarization with procedures among personnel is difficult to measure. The US military introduced a chatbot as part of its digital training material to enhance training effectiveness and avoid equipment damage. In this study the contribution of an artificial intelligence (AI) chatbot in training is explored. To evaluate the necessity of an AI chatbot research samples were divided into two groups namely an experimental and a control group with 20 people in each group. A paired t test was employed for differentiation analysis of pretest and posttest average scores revealing that the two groups exhibited a statistically significant improvement in their learning performance. In addition the blend of analysis of variance results indicated significant differences between the two groups. The chatbot training was more effective than traditional instructor teaching in terms of trainee performance improvement.;2021
For conversational agents' speech either all possible sentences have to be prerecorded by voice actors or the required utterances can be synthesized. While synthesizing speech is more flexible and economic in production it also potentially reduces the perceived naturalness of the agents among others due to mistakes at various linguistic levels. In our article we are interested in the impact of adequate and inadequate prosody here particularly in terms of accent placement on the perceived naturalness and aliveness of the agents. We compare (1) inadequate prosody as generated by off-the-shelf text-to-speech (TTS) engines with synthetic output (2) the same inadequate prosody imitated by trained human speakers and (3) adequate prosody produced by those speakers. The speech was presented either as audio-only or by embodied anthropomorphic agents to investigate the potential masking effect by a simultaneous visual representation of those virtual agents. To this end we conducted an online study with 40 participants listening to four different dialogues each presented in the three Speech levels and the two Embodiment levels. Results confirmed that adequate prosody in human speech is perceived as more natural (and the agents are perceived as more alive) than inadequate prosody in both human (2) and synthetic speech (1). Thus it is not sufficient to just use a human voice for an agents' speech to be perceived as natural-it is decisive whether the prosodic realisation is adequate or not. Furthermore and surprisingly we found no masking effect by speaker embodiment since neither a human voice with inadequate prosody nor a synthetic voice was judged as more natural when a virtual agent was visible compared to the audio-only condition. On the contrary the human voice was even judged as less alive when accompanied by a virtual agent. In sum our results emphasize on the one hand the importance of adequate prosody for perceived naturalness especially in terms of accents being placed on important words in the phrase while showing on the other hand that the embodiment of virtual agents plays a minor role in the naturalness ratings of voices.;2021
Foreign Direct Investment (FDI) is an important resource that helps accelerate the development of the country's economy add substantial funding to growth and facilitate technology transfer. Republic of Korea (ROK) is one of the world's developed countries with dynamic economy advanced science and technology. In recent years the Korean government has continuously formulated tax policies policies to support the business economy and import policies to support foreign businesses in Korea. The Pangyo Valley Creative Economy Valley is being groomed as a global startup hub in Asia. Small and medium enterprises (SMEs) in foreign countries are increasingly interested and eager to seek investment opportunities in the Korean market. Nonetheless for these companies language barriers and cultural and institutional differences make it more difficult and time-consuming to learn about the Korean market (such as investment trends laws visa policies taxes and business establishment issues in Korea etc.). In this study we explored the process of searching information and seeking investment opportunities and built a business consulting and support application in the first stages of starting a business in ROK to increase effectiveness and save time which is also an innovative business practice in Use-case ROK. We designed our Virtual Assistant system that can crawl and analyze data on foreign investments in ROK from open data resource websites (data.co.kr) and used analytic and aggregation techniques to explore trends in investments of foreign enterprises. We also researched the process of searching information and seeking investment opportunities for SMEs when investing in ROK government support policies laws and taxes as well as a number of other related issues. We built datasets and used Natural Language Processing (NLP) together with Natural Language Understanding (NLU) algorithms to build chatbot applications. Friendly framework for new developers to add and build up the dataset of AI Assistant is built by providing input intent data function input Entity data function input utterance data function as well as training and test function. In addition we built a web-app connected to the server to visualize all the results of research so that SMEs owners can easily use and look for information on investments. Based on the research results we can make recommendations to SMEs in keeping with the changing investment trends in ROK.;2021
Foreign language anxiety (FLA) has been a perennial concern in language learning as foreign language (FL) learners often communicate feelings of anxiety stress or nervousness. This study explored the role of artificial intelligence (AI) applications in speaking practice for FLA management of 48 undergraduate participants in an EFL class in Egypt. An eight-week quasi-experimental pretest-posttest design examined learner anxiety levels using a 33-item FLA questionnaire. Their oral proficiency was assessed via roleplaying using an interaction-enhanced public version of the IELTS speaking evaluation rubric. The results confirmed that FL learners experienced FLA pre- and post-intervention. The identified anxiety levels played a facilitative role in FL learning with several ensuing gains. The use of conversationally enhanced AI chatbots in interactive activities slightly intensified learners' FLA thus meriting further investigation of these objectives. Overall subject to further development AI chatbots are promising for significantly improving linguistic output gains however this study found that learners' speech-related anxieties were not reduced following the interactions with the chatbots. It is concluded that FLA plays an underexplored facilitative role in sharpening learner cognitive faculties and linguistic capacities. Moreover AI chatbots may be beneficial in advancing FL learning with significant potential in EFL contexts facilitating improved interaction and oral communication. These findings support the integration of AI technologies as effective tools in FL education providing flexible interactive and learner-centred learning. This study is expected to be of considerable interest to FL educators and learners.;2021
Forms of artificial intelligence (AI) such as chatbots that provide automated online counselling promise to revolutionise alcohol and other drug treatment. Although the replacement of human counsellors remains a speculative prospect chatbots for 'narrow AI' tasks (e.g. assessment and referral) are increasingly being used to augment clinical practice. Little research has addressed the possibilities for care that chatbots may generate in the future particularly in the context of alcohol and other drug counselling. To explore these issues we draw on the concept of technological 'affordances' and identify the range of possibilities for care that emerging chatbot interventions may afford and foreclose depending on the contexts in which they are implemented. Our analysis is based on qualitative data from interviews with clients (n = 20) and focus group discussions with counsellors (n = 8) conducted as part of a larger study of an Australian online alcohol and other drug counselling service. Both clients and counsellors expressed a concern that chatbot interventions lacked a 'human' element which they valued in empathic care encounters. Most clients reported that they would share less information with a chatbot than a human counsellor and they viewed this as constraining care. However clients and counsellors suggested that the use of narrow AI might afford possibilities for performing discrete tasks such as screening triage or referral. In the context of what we refer to as 'more-than-human' care our findings reveal complex views about the types of affordances that chatbots may produce and foreclose in online care encounters. We conclude by discussing implications for the potential 'addiction futures' and care trajectories that AI technologies offer focussing on how they might inform alcohol and other drug policy and the design of digital healthcare.;2021
From fact-checking chatbots to community-maintained misinformation databases Taiwan has emerged as a critical casestudy for citizen participation in politics online. Due to Taiwan's geopolitical history with China the recent 2020 Taiwanese Presidential Election brought fierce levels of online engagement led by citizens from both sides of the strait. In this article we study misinformation and digital participation on three platforms namely Line Twitter and Taiwan's Professional Technology Temple (PTT Taiwan's equivalent of Reddit). Each of these platforms presents a different facet of the elections. Results reveal that the greatest level of disagreement occurs in discussion about incumbent president Tsai. Chinese users demonstrate emergent coordination and selective discussion around topics like China Hong Kong and President Tsai whereas topics like Covid-19 are avoided. We discover an imbalance of the political presence of Tsai on Twitter which suggests partisan practices in disinformation regulation. The cases of Taiwan and China point toward a growing trend where regular citizens enabled by new media can both exacerbate and hinder the flow of misinformation. The study highlights an overlooked aspect of misinformation studies beyond the veracity of information itself that is the clash of ideologies practices and cultural history that matter to democratic ideals.;2021
Generating emotional responses plays an important role in human-computer conversational system. Adopting emotional information to the generation process improves user's satisfaction and makes the generated responses more human-like. Furthermore using fixed and unrelated emotion dictionary limits the overall performance of recent models. In order to generate and utilize the emotional words related to our datasets and sensitive to semantic importance we propose a dynamic emotion dictionary module to generate a proper emotional expression. Considering the response sometimes focuses on the certain words of the input text we also introduce dual-copying mechanism for taking advantages of not only emotion dictionary but also words appearing in the input text. Experimental results demonstrate that our model outperforms strong alternatives in several metrics e.g. BLEU embedding similarity Rouge-L and the quality of human evaluation. CO 2021 Published by Elsevier B.V.;2021
Generative Adversarial Nets (GAN) has been successfully introduced to unconditional generating text to alleviate exposure bias. However the discriminator in this model only evaluates the entire sequence which causes feedback sparsity and mode collapse. To tackle these problems we propose a novel mechanism. The mechanism first segments the entire sequence into several subsequences. Then these subsequences together with the entire sequence are evaluated individually by the discriminator. Finally these feedback signals are all used to guide the learning of GAN. This mechanism learns the generation of both the entire sequence and the subsequences simultaneously. Learning to generate subsequences is easy and is helpful in generating an entire sequence. It is easy to improve the existing GAN-based models with this mechanism. Although Li et al. (2017) segments the generated responses in a conditional text generation task i.e. a dialogue system they conclude it is weaker than the Monte Carlo search. However for unconditional text generation we observe that adversarial learning on subsequences works well. We rebuild three previous models with our mechanism and the experimental results on two benchmark datasets show these models are improved greatly and outperform the state-of-the-art model. (c) 2021 Elsevier Ltd. All rights reserved.;2021
Guided by the Conceptual Model of Implementation Research we explored the acceptability appropriateness and feasibility of: (1) automated screening approaches utilizing existing health data to identify those who require subsequent diagnostic evaluation for familial hypercholesterolemia (FH) and (2) family communication methods including chatbots and direct contact to communicate information about inherited risk for FH. Focus groups were conducted with 22 individuals with FH (2 groups) and 20 clinicians (3 groups). These were recorded transcribed and analyzed using deductive (coded to implementation outcomes) and inductive (themes based on focus group discussions) methods. All stakeholders described these initiatives as: (1) acceptable and appropriate to identify individuals with FH and communicate risk with at-risk relatives and (2) feasible to implement in current practice. Stakeholders cited current initiatives outside of FH (e.g. pneumonia protocols colon cancer and breast cancer screenings) that gave them confidence for successful implementation. Stakeholders described perceived obstacles such as nonfamiliarity with FH that could hinder implementation and potential solutions to improve systematic uptake of these initiatives. Automated health data screening chatbots and direct contact approaches may be useful for patients and clinicians to improve FH diagnosis and cascade screening.;2021
Health organizations have relied heavily on social distancing to limit the spread of the COVID-19 pandemic. The purpose of this research is to examine what factors can influence customers' evaluations of social distancing as well as how and when these evaluations drive their usage of chatbot services. Using structural equation modeling to analyze the experimental data from 200 U.S. consumers we found that when the service situation is utilitarian (hedonic) in nature customers' contamination fear influences their chatbot usage during service encounters through their social distancing attitudes (subjective norms) and then perceived usefulness of chatbots. Our findings provide meaningful theoretical contributions and practical implications.;2021
Health systems face major challenges during the COVID-19 pandemic with new information and challenges emerging daily and frequently changing guidelines. Online forward triage tools (OFTTs) provide useful information direct patients and free physician resources. We implemented an OFTT targeted at the current pandemic adapted the content and goals and assessed its effects. The OFTT was implemented on 2 March 2020 and modified regularly based on the revised testing criteria issued by the Swiss Federal Office of Public Health. After testing criteria liberalised a chatbot tool was set up on 9 April 2020 to assess urgency of testing referral to available testing sites and need for emergency care. In the first 40 days of the OFTT there were more than 17 300 visitors and 69.8% indicated they would have contacted the healthcare system if the online test had not been available. During the initial week of operation using the conservative testing strategy 9.1% of visitors received recommendations to be tested which increased to 36.0% of visitors after a change in testing criteria on 9 March 2020. Overall since the implementation of the tool 26.27% of all users of the site have been directed to obtain testing. The Chatbot tool has had approximately 50 consults/day. Setting up an OFTT should be considered as part of local strategies to cope with the COVID-19 pandemic. It may ease the burden on the healthcare system reassure patients and inform authorities. To account for the dynamic development of the pandemic frequent adaptation of the tool is of great importance. Further research on clinical outcomes of OFTT is urgently needed.;2021
Healthcare innovations are increasingly becoming reliant on high variety and standards-compliant (e.g. HIPAA common data model) distributed data sets that enable predictive analytics. Consequently health information systems need to be developed using cooperation and distributed trust principles to allow protected data sharing between multiple domains or entities (e.g. health data service providers hospitals and research labs). In this paper we present a novel health information sharing system viz. HonestChain that uses Blockchain technology to allow organizations to have incentive-based and trustworthy cooperation to either access or provide protected healthcare records. More specifically we use a consortium Blockchain approach coupled with chatbot guided interfaces that allow data requesters to: (a) comply with data access standards and (b) allow them to gain reputation in a consortium. We also propose a reputation scheme for creation and sustenance of the consortium with peers using Requester Reputation and Provider Reputation metrics. We evaluate HonestChain using Hyperledger Composer in a realistic simulation testbed on a public cloud infrastructure. Our results show that our HonestChain performs better than the state-of-the-art requester reputation schemes for data request handling while choosing the most appropriate provider peers. We particularly show that HonestChain achieves a better tradeoff in metrics such as service time and request resubmission rate. Additionally we also demonstrate the scalability of our consortium platform in terms of the Blockchain transaction times.;2021
Hierarchical context modeling plays an important role in the response generation for multi-turn conversational systems. Previous methods mainly model context as multiple independent utterances and rely on attention mechanisms to obtain the context representation. They tend to ignore the explicit responds-to relationships between adjacent utterances and the special role that the user's latest utterance (the query) plays in determining the success of a conversation. To deal with this we propose a multi-turn response generation model named KS-CQ which contains two crucial components the Keep and the Select modules to produce a neighbor-aware context representation and a context-enriched query representation. The Keep module recodes each utterance of context by attentively introducing semantics from its prior and posterior neighboring utterances. The Select module treats the context as background information and selectively uses it to enrich the query representing process. Extensive experiments on two benchmark multi-turn conversation datasets demonstrate the effectiveness of our proposal compared with the state-of-the-art baselines in terms of both automatic and human evaluations.;2021
Hosting conversational responses on the official websites of products and services companies is an essential marketing aspect. With Artificial Intelligence's help to make conversational interactivity more intuitive to existing and potential customers visiting the websites managers can notch up the return on marketing investments. This motivated us to study empirically and develop the MarkBot framework a chatter robot on the management design principles. The framework uses an Artificial Intelligence application to respond to a website visitor's browse through the product catalog. Neural network (NN) architectures are known to achieve remarkable performances in synthetic text predictions. We use a long short-term memory recurrent neural network (LSTM) to predict the user's responses through a chatbot in the current work. The proposed framework reduces the lead time for the firms to adopt MarkBot. We empirically prove using user-generated content on social media platforms like Twitter in responses and queries to digital campaigns on the same product. With new businesses failing to venture into the space of hosting a chatbot owing to no historical data or existing firms yet to host a chatbot the proposed MarkBot fuelled by user-generated content can have a substantial managerial implication. The management frameworks used to theorize the MarkBot also make it a theoretical contribution for future Information Systems scholars to conceptualize in the marketing field.;2021
How much do anthropomorphisms influence the perception of users about whether they are conversing with a human or an algorithm in a chatbot environment? We develop a cognitive model using the constructs of anthropomorphism and explainability to explain user experiences with conversational journalism (CJ) in the context of chatbot news. We examine how users perceive anthropomorphic and explanatory cues and how these stimuli influence user perception of and attitudes toward CJ. Anthropomorphic explanations of why and how certain items are recommended afford users a sense of humanness which then affects trust and emotional assurance. Perceived humanness triggers a two-step flow of interaction by defining the baseline to make a judgment about the qualities of CJ and by affording the capacity to interact with chatbots concerning their intention to interact with chatbots. We develop practical implications relevant to chatbots and ascertain the significance of humanness as a social cue in CJ. We offer a theoretical lens through which to characterize humanness as a key mechanism of human-artificial intelligence (AI) interaction of which the eventual goal is humans perceive AI as human beings. Our results help to better understand human-chatbot interaction in CJ by illustrating how humans interact with chatbots and explaining why humans accept the way of CJ.;2021
How students experience educational environments and the interconnections between their readiness task experiences and their long-term desire to reengage with course content are critical questions for educators. Research postgraduate students (n = 310) at a research-intensive university in Hong Kong engaging in a 24-h introductory teaching course participated in this study. Learner readiness for the course was assessed as prior Domain interest self-efficacy and knowledge. Subsequently students completed four formative assessments reported their on-task interest in seven strategically chosen tasks and end-of-course Course and Domain interest. Longitudinal-SEM tested interconnections between readiness components Task Course and Domain interest. Initial self-efficacy beliefs for teaching predicted early Task interest while Domain interest was a predictor of Task interest in explicitly practical task experiences. Strong interconnections between Task interest across the study were evident. Individual written and social discussion tasks presented strong contributions to future Course/Domain interest. Implications for theory and practice are discussed.;2021
Human language is inherently embodied and grounded in sensorimotor representations of the self and the world around it. This suggests that the body schema and ideomotor action-effect associations play an important role in language understanding language generation and verbal/physical interaction with others. There are computational models that focus purely on non-verbal interaction between humans and robots and there are computational models for dialog systems that focus only on verbal interaction. However there is a lack of research that integrates these approaches. We hypothesize that the development of computational models of the self is very appropriate for considering joint verbal and physical interaction. Therefore they provide the substantial potential to foster the psychological and cognitive understanding of language grounding and they have significant potential to improve human-robot interaction methods and applications. This review is a first step toward developing models of the self that integrate verbal and non-verbal communication. To this end we first analyze the relevant findings and mechanisms for language grounding in the psychological and cognitive literature on ideomotor theory. Second we identify the existing computational methods that implement physical decision-making and verbal interaction. As a result we outline how the current computational methods can be used to create advanced computational interaction models that integrate language grounding with body schemas and self-representations.;2021
Human relationships are influenced by the underlying emotions in their interactions. With the increasing use of social networks relationships from textual data can also be inferred from online interactions. Such interactions result in massive amount of textual data which is available in the form of text messages emails and social media posts. Identification and analysis of human relationships are useful for numerous applications ranging from cybersecurity to public health. In this paper we present a method called RIEA (Relationship Identification using Emotion Analysis) for identifying relationships between multiple intelligent agents by analyzing the conversation between them. The objective of our work is to combine concepts of cognitive psychology and natural language processing (NLP) to extract emotions and map them onto a set of relationships and analyze how relationships transform over time. We employ psychological models to label a large corpus of conversations and apply machine learning techniques to determine emotion-to-relationship mapping. We use four distinct association classes and four attachment styles using best-worst scaling method for classification. Combining the attachment and association styles given in research literature gives us the relationship combinations for our analysis. Additionally this work studies the most common changes of behaviors and emotions and the corresponding transformations in human relationships. Our results show that RIEA can correctly detect interpersonal relationships with an accuracy of 85%. The evaluation shows that RIEA can accurately identify interpersonal relationships from conversations and can be extended for identifying more complex relationships. This study also highlights the effect of changes in emotional behavior in the development of relationships over time.;2021
Humans and machines harmoniously collaborating and benefiting from each other is a long lasting dream for researchers in robotics and artificial intelligence. An important feature of efficient and rewarding cooperation is the ability to assume possible problematic situations and act in advance to prevent negative outcomes. This concept of assistance is known under the term proactivity. In this article we investigate the development and implementation of proactive dialogues for fostering a trustworthy human-computer relationship and providing adequate and timely assistance. Here we make several contributions. A formalisation of proactive dialogue in conversational assistants is provided. The formalisation forms a framework for integrating proactive dialogue in conversational applications. Additionally we present a study showing the relations between proactive dialogue actions and several aspects of the perceived trustworthiness of a system as well as effects on the user experience. The results of the experiments provide significant contributions to the line of proactive dialogue research. Particularly we provide insights on the effects of proactive dialogue on the human-computer trust relationship and dependencies between proactive dialogue and user specific and situational characteristics.;2021
Hydrogen evolution reaction (HER) is known as the heart of various energy storage and conversation systems of renewable energy sources. Here we observe the cluster reactions of a light transition metal vanadium with water in a gas-phase flow tube reactor. While HER products of V-1 and V-2 were not observed the effective HER of water on neutral V-n (n >= 3) clusters reveals reasonable and size-dependent reactivity of the vanadium clusters. Superatomic features and reaction dynamics of V-10 V-13 and V-16 are highlighted. Among the three typical superatoms V-10 and V-16 exhibit an abnormal superatomic orbital energy level order 1S vertical bar 2S vertical bar 1P vertical bar 1D... where the energy-reduced 2S orbital helps to accommodate the geometric structure and hence reinforce the cluster stability. In comparison V-13 bears a less symmetrical structure and reacts readily with water allowing for recombination of a hydroxyl atom with an adsorbed hydrogen atom akin to a fishing-mode HER process. The joint experimental and theoretical study on neutral Vn clusters clarifies the availability of superatom chemistry for transition metals and appeals further development of cluster theory based on electronic cloud/orbital analysis instead of simply counting the valence electrons. Also we provide insights into the HER mechanism of metal clusters and propose a strategy to design new materials for portable fuel cells of hydrogen energy.;2021
Hypertension is a chronic condition that can lead to serious health problems. Patients with High Blood Pressure (HBP) are often asked to have their BP checked at home. The traditional at-home procedure has some drawbacks such as forgetting to check or write down the values errors in transcribing the numbers or the impossibility of immediately notifying medical staff of out-of-range BP values. To facilitate self-measurements by patients at home we devised TensioBot a Telegram based chatbot. The bot sends patients reminders to check their BP advice on good monitoring practices measurement tracking medical alerts and allows healthcare professionals to access up-to-date measurement information. TensioBot has been tested for two years in a randomized controlled trial with 112 patients (55 using the bot and 57 in the control group). We found that although the bot group showed similar results in terms of adherence to the BP checking schedule bot users scored better in terms of knowledge and skills on BP checking best practices. Participants rated the bot very positively perceived it as useful and easy to use and continued to use it after the intervention. Moreover all data being equal we describe some other benefits of using a chatbot for self-managed in-house BP control both for patients and healthcare professionals and systems.;2021
Importance: Healthy nutrition and appropriate supplementation during preconception have important implications for the health of the mother and newborn. The best way to deliver preconception care to address health risks related to nutrition is unknown. Methods: We conducted a secondary analysis of data from a randomized controlled trial designed to study the impact of conversational agent technology in 13 domains of preconception care among 528 non-pregnant African American and Black women. This analysis is restricted to those 480 women who reported at least one of the ten risks related to nutrition and dietary supplement use. Interventions: An online conversational agent called Gabby assesses health risks and delivers 12 months of tailored dialogue for over 100 preconception health risks including ten nutrition and supplement risks using behavioral change techniques like shared decision making and motivational interviewing. The control group received a letter listing their preconception risks and encouraging them to talk to a health care provider. Results: After 6 months women using Gabby (a) reported progressing forward on the stage of change scale for on average 52.9% (SD 35.1%) of nutrition and supplement risks compared to 42.9% (SD 35.4) in the control group (IRR 1.22 95% CI 1.03-1.45 P = 0.019) and (b) reported achieving the action and maintenance stage of change for on average 52.8% (SD 37.1) of the nutrition and supplement risks compared to 42.8% (SD 37.9) in the control group (IRR 1.26 96% CI 1.08-1.48 P = 0.004). For subjects beginning the study at the contemplation stage of change intervention subjects reported progressing forward on the stage of change scale for 75.0% (SD 36.3%) of their health risks compared to 52.1% (SD 47.1%) in the control group (P = 0.006). Conclusion: The scalability of Gabby has the potential to improve women's nutritional health as an adjunct to clinical care or at the population health level. Further studies are needed to determine if improving nutrition and supplement risks can impact clinical outcomes including optimization ofweight. Clinical Trial Registration: ClinicalTrials.gov identifier NCT01827215.;2021
In an open-domain conversation system maintaining consistent persona is a key factor to earn trust from users and engage users in the conversation. Existing methods suffer from the issue that only sparse persona-relevant signals are available in the target responses leading to the generation of responses with inconsistent persona. To address the issue in this paper we propose two methods to augment persona learning signals for persona preservation. At the sentence level we develop a dual variational learning model based on the bidirectional encoder representations from transformers (i.e. BERT) which enriches persona signals with relevant persona sentences in addition to target responses. Therefore both the encoder part and the latent variable can be guided to learn consistent persona features through back-propagation of losses which will drive response decoding towards consistent persona expression. At the word level we propose a persona-based calibration network which is used to amplify the influence of persona-relevant words in target responses. The experimental results show that our developed model outperforms the strong baseline algorithms by large margins and effectively promotes persona consistency in conversation generation. (C) 2021 Elsevier B.V. All rights reserved.;2021
In an open-domain dialogue system recognition and expression of emotions are the key factors for success. Most of the existing research related to Chinese dialogue systems aims at improving the quality of content but ignores the expression of human emotions. In this article we propose a Chinese emotional dialogue response generation algorithm based on reinforcement learning that can generate responses not only according to content but also according to emotion. In the proposed method a multi-emotion classification model is first used to add emotion labels to the corpus of post-response pairs. Then with the help of reinforcement learning the reward function is constructed based on two aspects namely emotion and content. Among the generated candidates the system selects the one with long-term success as the best reply. At the same time to avoid safe responses and diversify dialogue a diversity beam search algorithm is applied in the decoding process. The comparative experiments demonstrate that the proposed model achieves satisfactory results according to both automatic and human evaluations.;2021
In aspect of the natural language processing field previous studies have generally analyzed sound signals and provided related responses. However in various conversation scenarios image information is still vital. Without the image information misunderstanding may occur and lead to wrong responses. In order to address this problem this study proposes a recurrent neural network (RNNs) based multi-sensor context-aware chatbot technology. The proposed chatbot model incorporates image information with sound signals and gives appropriate responses to the user. In order to improve the performance of the proposed model the long short-term memory (LSTM) structure is replaced by gated recurrent unit (GRU). Moreover a VGG16 model is also chosen for a feature extractor for the image information. The experimental results demonstrate that the integrative technology of sound and image information which are obtained by the image sensor and sound sensor in a companion robot is helpful for the chatbot model proposed in this study. The feasibility of the proposed technology was also confirmed in the experiment.;2021
In human-chatbot interaction users casually and regularly offend and abuse the chatbot they are interacting with. The current paper explores the relationship between chatbot humanlikeness on the one hand and sexual advances and verbal aggression by the user on the other hand. 283 conversations between the Cleverbot chatbot and its users were harvested and analysed. Our results showed higher counts of user verbal aggression and sexual comments towards Cleverbot when Cleverbot appeared more humanlike in its behaviour. Caution is warranted with the interpretation of the results however as no experimental manipulation was conducted and causality can thus not be inferred. Nonetheless the findings are relevant for both the research on the abuse of conversational agents and the development of efficient approaches to discourage or prevent verbal aggression by chatbot users.;2021
In linguistics the Anaphora Resolution (AR) is the method of identifying the antecedent for anaphora. In simple terms this is the problem that helps to solve what the expression referring to a referent refers to. It is considered to be one of the tedious tasks in Natural Language Processing (NLP). AR's burgeoning popularity among researchers is attributable to its strong relevance to machine translation text summarization chatbot question answering and many others. This paper presents a review of AR approaches based on significant features utilized to perform this task and presents the evaluation metrics for this field. The feature is a relevant term related to AR that provides vital information regarding anaphor antecedent and relation between them. In this context features represent the lexical syntactical semantical and positional relationship between anaphor and its possible candidate antecedent. The performance of the Anaphora resolution system is profoundly dependent on the features used in the AR system. Hence the selection of features for the AR system is highly significant. The main emphasis is to provide an overview of the various features needed to extract both the Anaphora and the Antecedent respectively used in different AR systems present in literature. It is observed that syntactical information enhances the correctness of determining the properties for the existence of an anaphor and antecedent identification. Nowadays the trend is changing from hand-crafted feature dependent methods to deep learning approaches which try to learn feature representation. The performance of deep learning is progressing due to the accessibility of additional data and more powerful computing resources. This survey will provide the state-of art for the better understanding of solving AR problem from the feature selection perspective. The findings of this survey are useful to provide valuable insight into present trends and are helpful for researchers who are looking for developing AR system within given constraints.;2021
In March 2016 Microsoft launched Tay.AI a chatbot designed to experiment with conversational understanding through direct engagement with social media users. Marketed as the digital representation of an 18-24-year-old cis-gendered female Tay.ai was meant to be chatty personable friendly and innocuous. Hours into launch however the chatbot's mimetic programming structure was taken advantage of by organized groups of online social media users and Tay.ai began replying to queries with alt-right and neo-Nazi ideology. In this article I explore the role that Tay.ai's assigned gender and race played in influencing both Tay.ai's initial design and subsequently the program's monstrous evolution. This is achieved through three avenues of thought. First I situate Tay within the new public of Web 2.0 a space reliant on user participation and beholden to the neoliberal racialized and gendered architectures that produce it. I then consider Tay as an evolution of the chatbot arguing that Tay is emblematic of both race and gender as social technologies. Third I explore Tay's aberration from programmatic protocols in the context of the monstrous and the abject suggesting that digital nonhuman ambivalence to programming and encoded control presents a space of productive creativity.;2021
In multi-turn dialogue generation dialogue contexts have been shown to have an important influence on the reasoning of the next round of dialogue. A multi-turn dialogue between two people should be able to give a reasonable response according to the relevant context. However the widely used hierarchical recurrent encoder-decoder model and the latest model that detecting the relevant contexts with self-attention are facing the same problem. Their given response doesn't match the identity of the current speaker which we call it role ambiguity. In this paper we propose a new model named RoRePo to tackle this problem by detecting the role information and relative position information. Firstly as a part of the decoder input we add a role embedding to identity different speakers. Secondly we incorporate self-attention mechanism with relative position representation to dialogue context understanding. Besides the design of our model architecture considers the influence of latent variables in generating more diverse responses. Experimental results of our evaluations on the DailyDialog and DSTC7 AVSD datasets show that our proposed model advances in multi-turn dialogue generation.;2021
In online social networks (OSNs) socialbots are responsible for various malicious activities and they are mainly programmed to imitate human-behavior to bypass the existing detection systems. The socialbots are generally successful in their malicious intent due to the existence of OSN users who follow them and thereby increase their reputation in the network. Analysis of the socialbot networks and their users is vital to comprehend the socialbot problem from target users' perspective. In this paper we present a machine learning-based approach for characterizing and detecting socialbot targets i.e. users who are susceptible to be trapped by the socialbots. We model OSN users based on their identity and behavior information representing the static and dynamic components of their personality. The proposed approach classifies socialbot targets into three categories viz. active reactive and inactive users. We evaluate the proposed approach using three classifiers over a dataset collected from a live socialbot injection experiment conducted on Twitter. We also present a comparative evaluation of the proposed approach with a state-of-the-art method and show that it performs significantly better. On feature ablation analysis we found that network structure and user intention and personality related dynamic features are most discriminative whereas static features show the least impact on the classification. Additionally following rate multimedia ratio and follower rate are most relevant to segregate different categories of the socialbot targets. We also perform a detailed topical and behavioral analysis of socialbot targets and found active users to be suspicious. Further joy and agreeableness are the most dominating personality traits among the three categories of the users.;2021
In order to improve the intelligence of the e-commerce online intelligent customer service system this paper proposes a deep rejection recognition algorithm based on the maximum interval squared hinge loss and combines the actual needs of the e-commerce online customer service system to build an intelligent customer service system with the support of the fuzzy control system. Moreover this article chooses to build a domain ontology library for structured storage of domain knowledge needed by customer service chatbots. In addition this article analyzes the dialogue structure based on the speech act model and combines the semantic vector model of the question sentence on the basis of the dialogue structure to understand the question sentence which helps to improve the accuracy of the answer feedback of the Internet shopping customer service robot. Finally this article designs experiments to verify the performance of the online customer service system constructed in this article and analyzes the experimental results through statistical methods. The experimental results show that the online intelligent customer service system constructed in this paper has certain practical effects.;2021
In recent years conversational agents (CAs) have become ubiquitous and are a presence in our daily routines. It seems that the technology has finally ripened to advance the use of CAs in various domains including commercial healthcare educational political industrial and personal domains. In this study the main areas in which CAs are successful are described along with the main technologies that enable the creation of CAs. Capable of conducting ongoing communication with humans CAs are encountered in natural-language processing deep learning and technologies that integrate emotional aspects. The technologies used for the evaluation of CAs and publicly available datasets are outlined. In addition several areas for future research are identified to address moral and security issues given the current state of CA-related technological developments. The uniqueness of our review is that an overview of the concepts and building blocks of CAs is provided and CAs are categorized according to their abilities and main application domains. In addition the primary tools and datasets that may be useful for the development and evaluation of CAs of different categories are described. Finally some thoughts and directions for future research are provided and domains that may benefit from conversational agents are introduced.;2021
In recent years gradual improvements in communication and connectivity technologies have enabled new technical possibilities for the adoption of chatbots across diverse sectors such as customer services trade and marketing. The chatbot is a platform that uses natural language processing a subset of artificial intelligence to find the right answer to all users' questions and solve their problems. Advanced chatbot architecture that is extensible scalable and supports different services for natural language understanding (NLU) and communication channels for interactions of users has been proposed. The paper describes overall chatbot architecture and provides corresponding metamodels as well as rules for mapping between the proposed and two commonly used NLU metamodels. The proposed architecture could be easily extended with new NLU services and communication channels. Finally two implementations of the proposed chatbot architecture are briefly demonstrated in the case study of ADA and COVID-19 Info Serbia.;2021
In recent years Natural Language Processing (NLP) models have achieved phenomenal success in linguistic and semantic tasks like text classification machine translation cognitive dialogue systems information retrieval via Natural Language Understanding (NLU) and Natural Language Generation (NLG). This feat is primarily attributed due to the seminal Transformer architecture leading to designs such as BERT GPT (I II III) etc. Although these large-size models have achieved unprecedented performances they come at high computational costs. Consequently some of the recent NLP architectures have utilized concepts of transfer learning pruning quantization and knowledge distillation to achieve moderate model sizes while keeping nearly similar performances as achieved by their predecessors. Additionally to mitigate the data size challenge raised by language models from a knowledge extraction perspective Knowledge Retrievers have been built to extricate explicit data documents from a large corpus of databases with greater efficiency and accuracy. Recent research has also focused on superior inference by providing efficient attention to longer input sequences. In this paper we summarize and examine the current state-of-the-art (SOTA) NLP models that have been employed for numerous NLP tasks for optimal performance and efficiency. We provide a detailed understanding and functioning of the different architectures a taxonomy of NLP designs comparative evaluations and future directions in NLP.;2021
In recent years personalized dialogue generation has attracted researchers' attention due to its wide range of applications. Although there has been much excellent research current chatbots are known to generate uninteresting responses without personality. In a general way persona information is adopted to mitigate these issues. Yet how to integrate persona information reasonably based on historical dialogue in responses is still a severe challenge. Thus we present a solution that consolidates the persona information memory process and pretrained method to generate personalized and fluency responses. Moreover we adopt a reinforcement learning algorithm to joint each part of the dialogue model. Last but not least we present a self-learning framework to explore the hypothetical space and make the responses more personalized and fascinating. Extensive experiments on the large-scale dialogue public dataset ConvAI2 verify the effectiveness of our method.;2021
In recent years task-oriented dialogue systems have received extensive attention from academia and industry. Training a dialogue agent through reinforcement learning is often costly because it requires many interactions with real users. Although the Deep Dyna-Q (DDQ) framework uses simulation experience to alleviate the cost of direct reinforcement learning it still suffers from challenges such as delayed rewards and policy degradation. This paper proposes an Emotion-Sensitive Deep Dyna-Q (ES-DDQ) model which: (1) presents an emotional world model that considers emotion-related cues to improve the ability of the traditional DDQ framework to model and simulate users and (2) designs two kinds of emotion related immediate rewards to mitigate the delayed reward problem. Experimental results show that our proposed approach effectively simulates users' behaviors and is superior to the state-of-the-art benchmarks. CO 2021 Published by Elsevier B.V.;2021
In recent years various organizations such as companies and governments have been required to take measures for the mental health of their employees and the importance of self care for mental health by employees themselves has been increasing as well as being supported by administrators such as doctors and workplace managers. As a means of self-care of mental health that can be implemented by busy professionals during their workdays and daily lives the Digital-SAT method has been developed to implement the stress-care process of the SAT method a psychological counseling technique for resolving psychological stress problems in a self-guided manner using digital media. To realize the Digital-SAT method two issues need to be addressed: first to obtain the same emotional stress reduction effect as the SAT method and second to ensure the continuous implementation of the Digital-SAT method. Previous studies have shown that applications (apps) using virtual reality are effective in solving the former issue and an app using a chatbot can be effective in solving the latter. In this research an intervention study was conducted to verify the effectiveness of combined use of the two apps to encourage continuous use resulting in increased emotional stress reduction with the aim of making it feasible in actual work environments. An intervention of four weeks of app use was conducted with 70 nurses working in two hospitals where measures for mental health due to emotional labour and overwork were required. The emotional stress reduction effects of the intervention were evaluated using psychological scales and blood pressure levels and it was confirmed that combined use of apps was more effective than using them separately to practice the Digital-SAT method in an actual work environment.;2021
In recent years with the development of deep learning text-generation technology has undergone great changes and provided many kinds of services for human beings such as restaurant reservation and daily communication. The automatically generated text is becoming more and more fluent so researchers begin to consider more anthropomorphic text-generation technology that is the conditional text generation including emotional text generation personalized text generation and so on. Conditional Text Generation (CTG) has thus become a research hotspot. As a promising research field we find that much attention has been paid to exploring it. Therefore we aim to give a comprehensive review of the new research trends of CTG. We first summarize several key techniques and illustrate the technical evolution route in the field of neural text generation based on the concept model of CTG. We further make an investigation of existing CTG fields and propose several general learning models for CTG. Finally we discuss the open issues and promising research directions of CTG.;2021
In Spoken Language Understanding (SLU) the ability to detect out-of-domain (OOD) input dialog plays a very important role (e.g. voice assistance and chatbot systems). However most of the existing OOD detection methods rely heavily on manually labeled OOD data. Manual labeling of the OOD data for a dynamically changing and evolving area is time-consuming and not immediately possible. It limits the feasibility of these models in practical applications. So to solve this problem we are considering the scenario of having no OOD labeled data (i.e. zero-shot learning). To achieve this goal we have used the intent focused semantic parsing extracted with the help of Transformer-based techniques [e.g. BERT (Devlin et al. 2018)]. The two main components of the intent-focused semantic parsing are - (a) the sentence-level intents and (b) token-level intent classes which show the relation of slot tokens with intent classes. Finally we combine both information and use a One Class Neural Network (OC-NN) based zero-shot classifier. Our devised system has shown better results compared to the state-of-the-art on four publicly available datasets.;2021
In task-oriented dialogue systems the dialogue state tracker component (DST) is responsible for predicting the current state of the dialogue based on the dialogue history and the user utterance. Current DST approaches rely on a predefined domain ontology a fact that limits their effective usage for large scale conversational agents where the DST constantly needs to be interfaced with ever-increasing services and APIs. Focused towards overcoming this drawback we propose a domain-aware dialogue state tracker that is completely data-driven and it is modeled to predict for dynamic service schemas including zero-shot domains. Unlike approaches that propose separate models for prediction of intents requested slots slot status categorical slots and non-categorical slots we propose a single model in an end-to-end architecture. The proposed model utilizes domain and slot information to extract both domain and slot specific representations from a given dialogue and then uses such representations to predict the values of the corresponding slot in a given domain. Integrating this mechanism with pretrained language models our approach can effectively learn semantic relations and effectively perform transfer learning between domains or zero-shot tracking for domains not present in training.;2021
In the current pandemic smart technologies such as cognitive computing artificial intelligence pattern recognition chatbot wearables and blockchain can sufficiently support the collection analysis and processing of medical data for decision making. Particularly to aid medical professionals in the disease diagnosis process cognitive computing is helpful by processing massive quantities of data rapidly and generating customized smart recommendations. On the other hand the present world is facing a pandemic of COVID-19 and an earlier detection process is essential to reduce the mortality rate. Deep learning (DL) models are useful in assisting radiologists to investigate the large quantity of chest X-ray images. However they require a large amount of training data and it needs to be centralized for processing. Therefore federated learning (FL) concept can be used to generate a shared model with no use of local data for DL-based COVID-19 detection. In this view this paper presents a federated deep learning-based COVID-19 (FDL-COVID) detection model on an IoT-enabled edge computing environment. Primarily the IoT devices capture the patient data and then the DL model is designed using the SqueezeNet model. The IoT devices upload the encrypted variables into the cloud server which then performs FL on major variables using the SqueezeNet model to produce a global cloud model. Moreover the glowworm swarm optimization algorithm is utilized to optimally tune the hyperparameters involved in the SqueezeNet architecture. A wide range of experiments were conducted on benchmark CXR dataset and the outcomes are assessed with respect to different measures . The experimental outcomes pointed out the enhanced performance of the FDL-COVID technique over the other methods.;2021
In the current study we conducted a Wizard-of-Oz experiment using a smart speaker to investigate how smart speakers' task performance (success vs. failure) and pragmatic levels (high vs. low) alter users' linguistic behaviors during multiple turn-taking conversations. The linguistic behaviors analyzed in this study included the mean length of utterance give-up and topic development frequency. Furthermore we examined what kinds of pragmatic skills smart speakers need to sustain multiple turn-taking interactions. The results suggest that smart speakers' performance levels and pragmatic skills have different effects on linguistic behaviors. Task performance and the pragmatic levels of smart speaker did not change participants' utterance lengths. Giving up on conversations when tasks were not successfully completed occurred more frequently with smart speakers with low pragmatic capabilities. Topic development occurred more frequently when people interacted with smart speakers with high pragmatic capabilities or when tasks were accomplished. The notable requisite pragmatic skills for smart speakers included the abilities to specify and describe information react to indirect behavior and appreciate humor/ironic humor. The findings of this study may have implications for designing dialogue for artificial conversational agents in various conversational settings.;2021
In the Internet of Things era users are willing to personalize the joint behavior of their connected entities i.e. smart devices and online service by means of trigger-action rules such as IF the entrance Nest security camera detects a movement THEN blink the Philips Hue lamp in the kitchen:' Unfortunately the spread of new supported technologies makes the number of possible combinations between triggers and actions continuously growing thus motivating the need of assisting users in discovering new rules and functionality e.g. through recommendation techniques. To this end we present HeyTAP(2) a semantic Conversational Search and Recommendation (CSR) system able to suggest pertinent IF-THEN rules that can be easily deployed in different contexts starting from an abstract user's need. By exploiting a conversational agent the user can communicate her current personalization intention by specifying a set of functionality at a high level e.g. to decrease the temperature of a room when she left it. Stemming from this input HeyTAP(2) implements a semantic recommendation process that takes into account (a) the current user's intention (b) the connected entities owned by the user and (c) the user's long-term preferences revealed by her profile. If not satisfied with the suggestions then the user can converse with the system to provide further feedback i.e. a short-term preference thus allowing HeyTAP(2) to provide refined recommendations that better align with the original intention. We evaluate HeyTAP(2) by running different offline experiments with simulated users and real-world data. First we test the recommendation process in different configurations and we show that recommendation accuracy and similarity with target items increase as the interaction between the algorithm and the user proceeds. Then we compare HeyTAP(2) with other similar baseline recommender systems. Results are promising and demonstrate the effectiveness of HeyTAP(2) in recommending IF-THEN rules that satisfy the current personalization intention of the user.;2021
In the modern era the implementation of chatbot can be used in various fields of science. This research will focus on the application of sentence classification using the News Aggregator Dataset that is used to test the model against the categories determined to create the chatbot program. The results of the chatbot program trial by multimodal implementation applied four models (GRU Bi-GRU 1D CNN 1D CNN Transpose) with six variations of parameters to produce the best results from the entire trial. The best test results from this research for the chatbot program using the 1D CNN Transpose model are the best models with detailed characteristics in this research which produces an accuracy value of 0.9919. The test results on both types of chatbot are expected to produce sentence prediction results and precise and accurate detection results. The stages in making the program are explained in detail therefore it is hoped that program users can understand not only how to use the program by entering an input and receiving program output results that are explained in more detail in each sub-topic of this study.;2021
In the past decades the incidence rate of cancer has steadily risen. Although advances in early and accurate detection have increased cancer survival chances these patients must cope with physical and psychological sequelae. The lack of personalized support and assistance after discharge may lead to a rapid diminution of their physical abilities cognitive impairment and reduced quality of life. This paper proposes a personalized support system for cancer survivors based on a cohort and trajectory analysis (CTA) module integrated within an agent-based personalized chatbot named EREBOTS. The CTA module relies on survival estimation models machine learning and deep learning techniques. It provides clinicians with supporting evidence for choosing a personalized treatment while allowing patients to benefit from tailored suggestions adapted to their conditions and trajectories. The development of the CTA within the EREBOTS framework enables to effectively evaluate the significance of prognostic variables detect patient's high-risk markers and support treatment decisions.;2021
In the past few years the use of transformer-based models has experienced increasing popularity as new state-of-the-art performance was achieved in several natural language processing tasks. As these models are often extremely large however their use for applications within embedded devices may not be feasible. In this work we look at one such specific application retrieval-based dialogue systems that poses additional difficulties when deployed in environments characterized by limited resources. Research on building dialogue systems able to engage in natural sounding conversation with humans has attracted increasing attention in recent years. This has led to the rise of commercial conversational agents such as Google Home Alexa and Siri situated on embedded devices that enable users to interface with a wide range of underlying functionalities in a natural and seamless manner. In part due to memory and computational power constraints these agents necessitate frequent communication with a server in order to process the users' queries. This communication may act as a bottleneck resulting in delays as well as in the halt of the system should the network connection be lost or unavailable. We propose a new framework for hardware-aware retrieval-based dialogue systems based on the Dual-Encoder architecture coupled with a clustering method to group candidates pertaining to a same conversation that reduces storage capacity and computational power requirements.;2021
In the realm of smart services smart personal assistants (SPAs) have become a popular medium for value co-creation between service providers and users. The market success of SPAs is largely based on their innovative material properties such as natural language user interfaces machine learning-powered request handling and service provision and anthropomorphism. In different combinations these properties offer users entirely new ways to intuitively and interactively achieve their goals and thus co-create value with service providers. But how does the nature of the SPA shape value co-creation processes? In this paper we look through a functional affordances lens to theorize about the effects of different types of SPAs (i.e. with different combinations of material properties) on users' value co-creation processes. Specifically we collected SPAs from research and practice by reviewing scientific literature and web resources developed a taxonomy of SPAs' material properties and performed a cluster analysis to group SPAs of a similar nature. We then derived 2 general and 11 cluster-specific propositions on how different material properties of SPAs can yield different affordances for value co-creation. With our work we point out that smart services require researchers and practitioners to fundamentally rethink value co-creation as well as revise affordances theory to address the dynamic nature of smart technology as a service counterpart.;2021
In this article we address the problem of answering complex information needs by conducting conversations with search engines in the sense that users can express their queries in natural language and directly receive the information they need from a short system response in a conversational manner. Recently there have been some attempts towards a similar goal e.g. studies on Conversational Agents (CAs) and Conversational Search (CS). However they either do not address complex information needs in search scenarios or they are limited to the development of conceptual frameworks and/or laboratory-based user studies. We pursue two goals in this article: (1) the creation of a suitable dataset the Search as a Conversation (SaaC) dataset for the development of pipelines for conversations with search engines and (2) the development of a state-of-the-art pipeline for conversations with search engines Conversations with Search Engines (CaSE) using this dataset. SaaC is built based on a multi-turn conversational search dataset where we further employ workers from a crowdsourcing platform to summarize each relevant passage into a short conversational response. CaSE enhances the state-of-the-art by introducing a supporting token identification module and a prior-aware pointer generator which enables us to generate more accurate responses. We carry out experiments to show that CaSE is able to outperform strong baselines. We also conduct extensive analyses on the SaaC dataset to show where there is room for further improvement beyond CaSE. Finally we release the SaaC dataset and the code for CaSE and all models used for comparison to facilitate future research on this topic.;2021
In this article we present MYRRORBar a personal digital assistant implementing a natural language interface that allows the users to: (i) access online services such as music video news and food recommendations in a personalized way by exploiting a strategy for implicit user modeling called holistic user profiling (ii) query their own user models to inspect the features encoded in their profiles and to increase their awareness of the personalization process. Basically the system allows the users to formulate natural language requests related to their information needs. Such needs are roughly classified in two groups: quantified self-related needs (e.g. Did I sleep enough? Am I extrovert?) and personalized access to online services (e.g. Play a song I like). The Intent recognition strategy implemented in the platform automatically identifies the intent expressed by the user and forwards the request to specific services and modules that generate an appropriate answer that fulfills the query. In the experimental evaluation we evaluated both qualitative (users' acceptance of the system usability) as well as quantitative (time required to complete basic tasks effectiveness of the personalization strategy) aspects of the system and the results showed that MYRRORBOT can improve the way people access online services and applications. This leads to a more effective interaction and paves the way for further development of our system.;2021
In this article we present the results of our experiments on sentiment and emotion recognition for English and Polish texts aiming to work in the context of a therapeutic chatbot. We created a dedicated dataset by adding samples of neutral texts to an existing English-language emotion-labeled corpus. Next using neural machine translation we developed a Polish version of the English database. A bilingual parallel corpus created in this way named CORTEX (CORpus of Translated Emotional teXts) labeled with three sentiment polarity classes and nine emotion classes was used for experiments on classification. We employed various classifiers: Naive Bayes Support Vector Machines fastText and BERT. The results obtained were satisfactory: we achieved the best scores for the BERT-based models which yielded accuracy of over 90% for sentiment (3-class) classification and almost 80% for emotion (9-class) classification. We compared the results for both languages and discussed the differences. Both the accuracy and the F1-scores for Polish turned out to be slightly inferior to those for English with the highest difference visible for BERT.;2021
In this demonstration we present DatAgent an intelligent data assistant system that allows users to ask queries in natural language and can respond in natural language as well. Moreover the system actively guides the user using different types of recommendations and hints and learns from user actions. We will demonstrate different exploration scenarios that show how the system and the user engage in a human-like interaction inspired by the interaction paradigm of chatbots and virtual assistants.;2021
In this paper various methodologies of acoustic and language models as well as labeling methods for automatic speech recognition for spoken dialogues in emergency call centers were investigated and comparatively analyzed. Because of the fact that dialogue speech in call centers has specific context and noisy emotional environments available speech recognition systems show poor performance. Therefore in order to accurately recognize dialogue speeches the main modules of speech recognition systems-language models and acoustic training methodologies-as well as symmetric data labeling approaches have been investigated and analyzed. To find an effective acoustic model for dialogue data different types of Gaussian Mixture Model/Hidden Markov Model (GMM/HMM) and Deep Neural Network/Hidden Markov Model (DNN/HMM) methodologies were trained and compared. Additionally effective language models for dialogue systems were defined based on extrinsic and intrinsic methods. Lastly our suggested data labeling approaches with spelling correction are compared with common labeling methods resulting in outperforming the other methods with a notable percentage. Based on the results of the experiments we determined that DNN/HMM for an acoustic model trigram with Kneser-Ney discounting for a language model and using spelling correction before training data for a labeling method are effective configurations for dialogue speech recognition in emergency call centers. It should be noted that this research was conducted with two different types of datasets collected from emergency calls: the Dialogue dataset (27 h) which encapsulates call agents' speech and the Summary dataset (53 h) which contains voiced summaries of those dialogues describing emergency cases. Even though the speech taken from the emergency call center is in the Azerbaijani language which belongs to the Turkic group of languages our approaches are not tightly connected to specific language features. Hence it is anticipated that suggested approaches can be applied to the other languages of the same group.;2021
In this paper we propose a probabilistic framework for solving the task of 'Visual Dialog'. Solving this task requires reasoning and understanding of visual modality language modality and common sense knowledge to answer. Various architectures have been proposed to solve this task by variants of multi -modal deep learning techniques that combine visual and language representations. However we believe that it is crucial to understand and analyze the sources of uncertainty for solving this task. Our approach allows for estimating uncertainty and also aids a diverse generation of answers. The proposed approach is obtained through a probabilistic representation module that provides us with representations for image question and conversation history a module that ensures that diverse latent representations for candidate answers are obtained given the probabilistic representations and an uncertainty representation module that chooses the appropriate answer that minimizes uncertainty. We thoroughly evaluate the model with a detailed ablation analysis comparison with state of the art and visualization of the uncertainty that aids in the understanding of the method. Using the proposed probabilistic framework we thus obtain an improved visual dialog system that is also more explainable. (c) 2020 Elsevier Ltd. All rights reserved.;2021
In this paper we propose Stacked DeBERT short for Stacked Denoising Bidirectional Encoder Representations from Transformers. This novel model improves robustness in incomplete data when compared to existing systems by designing a novel encoding scheme in BERT a powerful language representation model solely based on attention mechanisms. Incomplete data in natural language processing refer to text with missing or incorrect words and its presence can hinder the performance of current models that were not implemented to withstand such noises but must still perform well even under duress. This is due to the fact that current approaches are built for and trained with clean and complete data and thus are not able to extract features that can adequately represent incomplete data. Our proposed approach consists of obtaining intermediate input representations by applying an embedding layer to the input tokens followed by vanilla transformers. These intermediate features are given as input to novel denoising transformers which are responsible for obtaining richer input representations. The proposed approach takes advantage of stacks of multilayer perceptrons for the reconstruction of missing words' embeddings by extracting more abstract and meaningful hidden feature vectors and bidirectional transformers for improved embedding representation. We consider two datasets for training and evaluation: the Chatbot Natural Language Understanding Evaluation Corpus and Kaggle's Twitter Sentiment Corpus. Our model shows improved F1-scores and better robustness in informal/incorrect texts present in tweets and in texts with Speech-to-Text error in the sentiment and intent classification tasks.(1) (C) 2020 Elsevier Ltd. All rights reserved.;2021
In this paper we survey the methods and concepts developed for the evaluation of dialogue systems. Evaluation in and of itself is a crucial part during the development process. Often dialogue systems are evaluated by means of human evaluations and questionnaires. However this tends to be very cost- and time-intensive. Thus much work has been put into finding methods which allow a reduction in involvement of human labour. In this survey we present the main concepts and methods. For this we differentiate between the various classes of dialogue systems (task-oriented conversational and question-answering dialogue systems). We cover each class by introducing the main technologies developed for the dialogue systems and then present the evaluation methods regarding that class.;2021
In this study we attempt to specify the cognitive support behavior of a previously designed embodied conversational agent coach that provides learning support to low-literates. Three knowledge gaps are identified in the existing work: an incomplete specification of the behaviors that make up 'support' an incomplete specification of how this support can be personalized and unclear speech recognition rules. We use the socio-cognitive engineering method to update our foundation of knowledge with new online banking exercises low-level scaffolding and user modeling theory and speech recognition. We then refine the design of our coach agent by creating comprehensive cognitive support rules that adapt support based on learner needs (the 'Generalized' approach) and attune the coach's support delay to user performance in previous exercises (the 'Individualized' approach). A prototype is evaluated in a 3-week within- and between-subjects experiment. Results show that the specified cognitive support is effective: Learners complete all exercises interact meaningfully with the coach and improve their online banking self-efficacy. Counter to hypotheses the Individualized approach does not improve on the Generalized approach. Whether this indicates suboptimal operationalization or a deeper problem with the Individualized approach remains as future work.;2021
In this work we present the Chatbot Interaction with Artificial Intelligence (CI-AI) framework as an approach to the training of a transformer based chatbot-like architecture for task classification with a focus on natural human interaction with a machine as opposed to interfaces code or formal commands. The intelligent system augments human-sourced data via artificial paraphrasing in order to generate a large set of training data for further classical attention and language transformation-based learning approaches for Natural Language Processing (NLP). Human beings are asked to paraphrase commands and questions for task identification for further execution of algorithms as skills. The commands and questions are split into training and validation sets. A total of 483 responses were recorded. Secondly the training set is paraphrased by the T5 model in order to augment it with further data. Seven state-of-the-art transformer-based text classification algorithms (BERT DistilBERT RoBERTa DistilRoBERTa XLM XLM-RoBERTa and XLNet) are benchmarked for both sets after fine-tuning on the training data for two epochs. We find that all models are improved when training data is augmented by the T5 model with an average increase of classification accuracy by 4.01%. The best result was the RoBERTa model trained on T5 augmented data which achieved 98.96% classification accuracy. Finally we found that an ensemble of the five best-performing transformer models via Logistic Regression of output label predictions led to an accuracy of 99.59% on the dataset of human responses. A highly-performing model allows the intelligent system to interpret human commands at the social-interaction level through a chatbot-like interface (e.g. Robot can we have a conversation?) and allows for better accessibility to AI by non-technical users.;2021
In this work we are focusing on a new and yet uncovered way for malicious apps to gain profit. They claim to be dating apps. However their sole purpose is to lure users into purchasing premium/VIP services to start conversations with other (likely fake female) accounts in the app. We call these apps as fraudulent dating apps. This paper performs a systematic study to understand the whole ecosystem of fraudulent dating apps. Specifically we have proposed a three-phase method to detect them and subsequently comprehend their characteristics via analyzing the existing account profiles. Our observation reveals that most of the accounts are not managed by real persons but by chatbots based on predefined conversation templates. We also analyze the business model of these apps and reveal that multiple parties are actually involved in the ecosystem including producers who develop apps publishers who publish apps to gain profit and the distribution network that is responsible for distributing apps to end users. Finally we analyze the impact of them to users (i.e. victims) and estimate the overall revenue. Our work is the first systematic study on fraudulent dating apps and the results demonstrate the urge for a solution to protect users.;2021
In this work we present an innovative and cost-effective approach to run ambulatory assessment (AA) studies on participants' smartphones via Telegram Messenger. Our approach works both for Android and iOS devices. The population of potential participants in a given country or region consists of all individuals who (a) are in possession of a smartphone (b) are willing to install Telegram Messenger and (c) live in an environment providing constant connection to the Internet. In our new approach to AA participants are asked to subscribe to a Telegram chatbot that provides them with links to brief surveys at specified points in time in their everyday lives via short notifications. We developed a user-friendly Python script that allows for the flexible editing of the chatbot's settings e.g. the number of surveys per day. All common survey software designed for mobile devices can be used to present surveys to participants. This means that data collection takes place exclusively via the selected survey software not via Telegram. With our approach AA studies can be carried out among iOS and Android users cost-effectively and reliably while data security is ensured. Initial data from a pilot study show that studies of this kind are feasible and the procedure is accepted by participants. Our Python script is licensed under General Public License (GPLv3) and therefore freely available and editable: https://github.com/Raze97/Telegram-Survey-Bot;2021
In this work we propose a multi-goal multi-agent learning (MGMA) framework for task-oriented dialogue generation which aims to retrieve accurate entities from knowledge base (KB) and generate human-like responses simultaneously. Specifically MGMA consists of a KB-oriented teacher agent for inquiring KB a context-oriented teacher agent for extracting dialogue patterns and a student agent that tries to not only retrieve accurate entities from KB but also generate human-like responses. A two-to-one teacher-student learning method is proposed to coordinate these three networks training the student network to integrate the expert knowledge from the two teacher networks and achieve comprehensive performance in task-oriented dialogue generation. In addition we also update the two teachers based on the output of the student network since the space of possible responses is large and the teachers should adapt to the conversation style of the student. In this way we can obtain more empathetic teachers with better performance. Moreover in order to build each task oriented dialogue system effectively we employ a dialogue memory network to dynamically filter the irrelevant dialogue history and memorize important newly coming information. Another KB memory network which shares the structural KB tuples throughout the whole conversation is adopted to dynamically extract KB information with a memory pointer at each utterance. Extensive experiments on three benchmark datasets (i.e. CamRest In-Car Assistant and Multi-WOZ 2.1) demonstrate that MGMA significantly outperforms baseline methods in terms of both automatic and human evaluation. (C) 2020 Elsevier B.V. All rights reserved.;2021
Incorporating topic information can help response generation models to produce informative responses for chat-bots. Previous work only considers the individual semantic of each topic ignoring its specific dialog context which may result in inaccurate topic representation and hurt response coherence. Besides as an important feature of multi-turn conversation dynamic topic transitions have not been well-studied. We propose a Context-Controlled Topic-Aware neural response generation model i.e. CCTA which makes dialog context interact with the process of topic representing and transiting to achieve balanced improvements on response informativeness and contextual coherence. CCTA focuses on capturing the semantical relations within topics as well as their corresponding contextual information in conversation to produce context-dependent topic representations at the word-level and turn-level. Besides CCTA introduces a context controlled topic transition strategy utilizing contextual topics to yield relevant transition words. Extensive experimental results on two benchmark multi-turn conversation datasets validate the superiority of our proposal on generating coherent and informative responses against the state-ofthe-art baselines. We also find that topic transition modeling can work as an auxiliary learning task to boost the response generation.;2021
Information about a subjective user opinion towards an argument is crucial for argumentative systems in order to present appropriate content and adapt their behaviour to the individual user. However requesting explicit feedback regarding the discussed arguments is often impractical and can hinder the interaction. To address this issue we investigate the automatic recognition of user opinions towards arguments that are presented by means of a virtual avatar from social signals. We focus on two different user opinion categories (convincing and interesting) and two different types of social signals (facial expressions and eye movement). The recognition is addressed as a supervised learning problem and realized using the argument search evaluation data discussed in previous work. The overall performance is compared to a human annotation on a subset of the collected data. The results show that the machine learning performance is similar to human performance in both recognition tasks.;2021
Intelligent AI devices have become a common presence in the business landscape offering a wide range of services from the medical sector to the hospitality industry. From an organizational perspective AI devices have several advantages by performing certain tasks quicker and more accurately in comparison to humans while at the same time being more cost-efficient. However in order to maintain the high standards of a brand they have to be accepted by consumers and deliver socially adequate performance. Therefore it is important to determine the characteristics of AI devices which make them accepted and trusted by consumers. Based on the Computers as Social Actors (CASA) Theory we have researched on the role of psychological anthropomorphic characteristics perceived empathy and interaction quality in the acceptance of AI devices in the service industry. The results show that anthropomorphic characteristics alone do not influence acceptance and trust towards AI devices. However both perceived empathy and interaction quality mediate the relation between anthropomorphic characteristics and acceptance. A human-like AI device has higher acceptance when it has the ability to show empathy and interaction in relation to the human consumer. This result reveals the importance of developing forms of strong intelligence and empathetic behaviour in service robots and AI devices.;2021
Intent classification (IC) and Named Entity Recognition (NER) are arguably the two main components needed to build a Natural Language Understanding (NLU) engine which is a main component of conversational agents. The IC and NER components are closely intertwined and the entities are often connected to the underlying intent. Current research has primarily focused to model IC and NER as two separate units which results in error propagation and thus sub-optimal performance. In this paper we propose a simple yet effective novel framework for NLU where the parameters of the IC and the NER models are jointly trained in a consolidated parameter space. Text semantic representations are obtained from popular pre-trained contextual language models which are fine-tuned for our task and these parameters are propagated to other deep neural layers in our framework leading to a faithful unified modelling of the IC and NER parameters. The overall framework results in a faithful parameter sharing when the training is underway leading to a more coherent learning. Experiments on two public datasets ATIS and SNIPS show that our model outperforms other methods by a noticeable margin. On the SNIPS dataset we obtain a 1.42% improvement in NER in terms of the F1 score and 1% improvement in intent accuracy score. On ATIS we achieve 1.54% improvement in intent accuracy score. We also present qualitative results to showcase the effectiveness of our model.;2021
Intent detection and slot filling are important modules in task-oriented dialog systems. In order to make full use of the relationship between different modules and resource sharing solving the problem of a lack of semantics this paper proposes a multitasking learning intent-detection system based on the knowledge-base and slot-filling joint model. The approach has been used to share information and rich external utility between intent and slot modules in a three-part process. First this model obtains shared parameters and features between the two modules based on long short-term memory and convolutional neural networks. Second a knowledge base is introduced into the model to improve its performance. Finally a weighted-loss function is built to optimize the joint model. Experimental results demonstrate that our model achieves better performance compared with state-of-the-art algorithms on a benchmark Airline Travel Information System (ATIS) dataset and the Snips dataset. Our joint model achieves state-of-the-art results on the benchmark ATIS dataset with a 1.33% intent-detection accuracy improvement a 0.94% slot filling F value improvement and with 0.19% and 0.31% improvements respectively on the Snips dataset.;2021
Interacting with an embodied conversational agent (ECA) in a professional context addresses social considerations to satisfy customer-relationship. This paper presents an experimental study about the perception of virtual intimacy in human-ECA interactions. We explore how an ECA's multimodal communication affects our perception of virtual intimacy. To this end we developed a virtual Tourism Information counselor capable of exhibiting verbal and nonverbal intimate behaviors according to several modalities (voice chatbox both media) and we built a corpus of videos showing interactions between the agent and a human tourist. We interrogated observers about their perception of the agent's level of intimacy. Our results confirm the human ability to perceive intimacy in an ECA displaying multimodal behaviors although the contribution of nonverbal communication remains unclear. Our study suggests that using voice channel increases the perception of virtual intimacy and offers further evidence that human-inspired design of ECAs is needed. Finally we demonstrate that intimate cues do not disturb the comprehension of task-related information and are valuable for an attentional focus on the agent's animation. We discuss the concept of virtual intimacy in relation to interpersonal intimacy and we question its perception in terms of attentional mechanisms.;2021
Interactions between humans and machines that include artificial intelligence are increasingly common in nearly all areas of life. Meanwhile AI-products are increasingly endowed with emotional characteristics. That is they are designed and trained to elicit emotions in humans to recognize human emotions and sometimes to simulate emotions (EAI). The introduction of such systems in our lives is met with some criticism. There is a rather strong intuition that there is something wrong about getting attached to a machine about having certain emotions towards it and about getting involved in a kind of affective relationship with it. In this paper I want to tackle these worries by focusing on the last aspect: in what sense could it be problematic or even wrong to establish an emotional relationship with EAI-systems? I want to show that the justifications for the widespread intuition concerning the problems are not as strong as they seem at first sight. To do so I discuss three arguments: the argument from self-deception the argument from lack of mutuality and the argument from moral negligence.;2021
Interactions with conversational agents (CAs) become increasingly common in our daily life. While research on human-CA interactions provides insights into the role of CAs the active role of users has been mostly neglected. We addressed this void by applying a thematic analysis approach and analysed 1000 interactions between a chatbot and customers of an energy provider. Informed by the concepts of social presence and social cues and using the abductive logic we identified six human-chatbot interaction types that differ according to salient characteristics including direction social presence social cues of customers and the chatbot and customer effort. We found that bi-directionality a medium degree of social presence and selected social cues used by the chatbot and customers are associated with desirable outcomes in which customers mostly obtain requested information. The findings help us understand the nature of human-CA interactions in a customer service context and inform the design and evaluation of CAs.;2021
Internet of things conversational agents (IoT-CAs) are making human-computer interactions ubiquitous. In this study we experimentally examined the effects of IoT-CA use on face-to-face conversations between close partners. A total of 136 participants (68 close relationship dyads) participated in the experiment. We prepared an IoT chat environment and provided chat topics for each dyad. The dyads were randomly assigned into one of two IoT-CA use pattern groups (joint use: two persons using an IoT-CA together individual use: one person using an IoT-CA alone) and three interaction conditions (no IoT-CA use conversation content-relevant IoT-CA use conversation content-irrelevant IoT-CA use). The results showed that compared with no IoT-CA use IoT-CA use did not have negative effects on conversation experiences but produced feelings of greater closeness to the IoT-CA in the partners. Furthermore joint IoT-CA use in the content-relevant condition (IoT-CA made comments relevant to interpersonal interactions) helped increase interpersonal self-disclosure. RESEARCH HIGHLIGHTS Internet of things conversational agents (IoT-CAs) are becoming integral parts of our homes and daily routines. IoT-CA use does not have negative effects on face-to-face conversation experience. People might be accustomed to technological device use in face-to-face conversations. Information transparency brought by voice interface might decrease negative effects of technology use on interpersonal conversations.;2021
Internet-of-Things has reshaped the way people interact with their surroundings and automatize the once manual actions. In a smart home controlling the Internet-connected lights is as simple as speaking to a nearby conversational assistant. However specifying interaction rules such as making the lamp turn on at specific times or when someone enters the space is not a straightforward task. The complexity of doing such increases as the number and variety of devices increases along with the number of household members. Thus managing such systems becomes a problem including finding out why something has happened. This issue lead to the birth of several low-code development solutions that allow users to define rules to their systems at the cost of discarding the easiness and accessibility of voice interaction. In this paper we extend the previous published work on Jarvis [1] a conversational interface to manage IoT systems that attempts to address these issues by allowing users to specify time-based rules use contextual awareness for more natural interactions provide event management and support causality queries. A proof-of-concept is presented detailing its architecture and natural language processing capabilities. A feasibility experiment was carried with mostly non-technical participants providing evidence that Jarvis is intuitive enough to be used by common end-users with participants showcasing an overall preference by conversational assistants over visual low-code solutions.;2021
Introduction Only a minority of people living with mental health problems are getting professional help. As digitalisation moves on the possibility of providing internet/mobile-based interventions (IMIs) arises. One type of IMIs are fully automated conversational software agents (chatbots). Software agents are computer programs that can hold conversations with a human by mimicking a human conversational style. Software agents could deliver low-threshold and cost-effective interventions aiming at promoting psychological well-being in a large number of individuals. The aim of this trial is to evaluate the clinical effectiveness and acceptance of the brief software agent-based IMI SISU in comparison with a waitlist control group. Methods and analysis Within a two-group randomised controlled trial a total of 120 adult participants living with low well-being (Well-being Scale/WHO-5) will be recruited in Germany Austria and Switzerland. SISU is based on therapeutic writing and acceptance and commitment therapy-based principles. The brief intervention consists of three modules. Participants work through the intervention on 3 consecutive days. Assessment takes place before (t1) during (t2) and after (t3) the interaction with SISU as well as 4 weeks after randomisation (t4). Primary outcome is psychological well-being (WHO-5). Secondary outcomes are emotional well-being (Flourishing Scale) psychological flexibility (Acceptance and Action Questionnaire-II) quality of life (Assessment of Quality of Life -8D) satisfaction with the intervention (Client Satisfaction Questionnaire-8) and side effects (Inventory for the assessment of negative effectsof psychotherapy). Examined mediators and moderators are sociodemographic variables personality (Big Five Inventory-10) emotion regulation (Emotion Regulation Questionnaire) alexithymia (Toronto Alexithymia Scale-20) centrality of events (Centrality of Events Scale) treatment expectancies (Credibility Expectancy Questionnaire) and technology alliance (Inventory of Technology Alliance-Online Therapy). Data analysis will be based on intention-to-treat principles. SISU guides participants through a 3-day intervention. Ethics and dissemination This trial has been approved by the ethics committee of the Ulm University (No. 448/18 18.02.2019). Results will be submitted for publication in a peer-reviewed journal and presented at conferences.;2021
Introduction: Clinicians rely on pharmacologic knowledge bases to answer medication questions and avoid potential adverse drug events. In late 2018 an artificial intelligence-based conversational agent Watson Assistant (WA) was made available to online subscribers to the pharmacologic knowledge base Micromedex (R). WA allows users to ask medication-related questions in natural language. This study evaluated search method-dependent differences in the frequency of information accessed by traditional methods (keyword search and heading navigation) vs conversational agent search. Materials and methods: We compared the proportion of information types accessed through the conversational agent to the proportion of analogous information types accessed by traditional methods during the first 6 months of 2020. Results: Addition of the conversational agent allowed early adopters to access 22 different information types contained in the 'quick answers' portion of the knowledge base. These information types were accessed 117550 times with WA during the study period compared to 33649651 times using traditional search methods. The distribution across information types differed by method employed (c(2) test P < .0001). Single drug/dosing FDA/non-FDA uses adverse effects and drug administration emerged as 4 of the top 5 information types accessed by either method. Intravenous compatibility was accessed more frequently using the conversational agent (7.7% vs. 0.6% for traditional methods) whereas dose adjustments were accessed more frequently via traditional methods (4.8% vs. 1.4% for WA). Conclusion: In a widely used pharmacologic knowledge base information accessed through conversational agents versus traditional methods differed. User-centered studies are needed to understand these differences.;2021
Introduction: In Onondaga County New York around half of all births to Black and Hispanic teenage girls are unintended. The Layla's Got You campaign consists of a chatbot and social media campaign designed to increase contraception knowledge among 16- to 25-year-old Black and Hispanic women in Onondaga County. Methods: The campaign was co-created with local women in the target audience and employed digital and grassroots community building strategies. Focus groups were conducted among 31 women during which participants selected the campaign's logo and chatbot name and created the tagline. Participants reviewed chatbot responses and designed Layla's appearance and features and Black/Hispanic women are featured in website and promotional photos. A community campaign manager pairs digital strategies with grassroots partnerships among a diverse group of stakeholders including social media influencers hair salons and health clinics. Results: Since implementation the chatbot has received 4390 messages related to contraception or sexual health. Across social media accounts the campaign has showed 2483683 impressions average daily reach of 1710 for Facebook and 943 for Instagram and 32816 total engagements across all platforms. Conclusion: Layla's Got You provides young women with a confidential place in which to find locally tailored and trustworthy information about contraception. By merging innovative technology-driven strategies participatory creation techniques and grassroots community building the initiative delivers impactful easily updated health information on a large scale. This strategy has promising implications for increasing knowledge and positive attitudes towards contraception among specific at-risk audiences.;2021
Introduction: The growing demand from patients with wounds from various causes has significantly challenged primary care nurses. A chatbot with duly validated evidence-based content can assist both nurses and patients in managing care. This work describes the development process of such a chatbot (BOTCURATIVO) that aims to help the treatment of wounds by non-specialists by giving guidelines about the recommended wound dressing procedures for each type of wound. Method: Methodological research was carried out in three phases. The first one corresponded to the validation of the script's content through a panel of enterostomal therapist nurses who evaluated the domains and items of the chatbot script. Data analysis was performed using the Content Validity Index by individual level and scale level (>= 0.80). To verify the agreement between the evaluators the Kappa test was used. In the second phase the chatbot was developed using GOOGLE'S DIALOGFLOW platform. Finally in the third phase the chatbot's usability was analyzed using the System Usability Scale (SUS) by 17 users 8 of them being patients with chronic wounds 5 caregivers of people with acute and chronic wounds and 4 nurses. Results: The established domains achieved excellent suitability relevance and representativeness criteria all above 90 % the content validity index per level of scale reached 0.97 and 0.82 by the methods of average and universal agreement respectively with excellent agreement between the evaluators (Kappa value: 0.83). The global usability score was 80.1. Conclusion: The script developed and incorporated into the chatbot prototype achieved a satisfactory level of content validity. The usability of the chatbot was considered good adding to the credibility of the device.;2021
Knowledge-based dialog systems have attracted increasing research interest in diverse applications. However for disease diagnosis the widely used knowledge graph (KG) is hard to represent the symptom-symptom and symptom-disease relations since the edges of traditional KG are unweighted. Most research on disease diagnosis dialog systems highly relies on data-driven methods and statistical features lacking profound comprehension of symptom-symptom and symptom-disease relations. To tackle this issue this work presents a weighted heterogeneous graph-based dialog system for disease diagnosis. Specifically we build a weighted heterogeneous graph based on symptom co-occurrence and the proposed symptom frequency-inverse disease frequency. Then this work proposes a graph-based deep Q-network (graph-DQN) for dialog management. By combining graph convolutional network (GCN) with DQN to learn the embeddings of diseases and symptoms from both the structural and attribute information in the weighted heterogeneous graph graph-DQN could capture the symptom-disease relations and symptom-symptom relations better. Experimental results show that the proposed dialog system rivals the state-of-the-art models. More importantly the proposed dialog system can complete the task with fewer dialog turns and possess a better distinguishing capability on diseases with similar symptoms.;2021
Linguistic intelligence and the ability to converse with human are important and indispensable parts of humanoid robots. One of the most challenging tasks in knowledge-grounded task-oriented dialog systems (KTDS) is the knowledge selection task which aims to find the proper knowledge snippets to respond to user dialog requests. In this paper we first propose domain adapted-BERT (DA-BERT) which employs pre-trained bidirectional encoder representations from transformers (BERT) with domain adaptive training and dynamic masking probability for knowledge selection in KTDS. Domain adaptive training can minimize the domain gap between the general text data that BERT is pre-trained on and the dialog-knowledge joint data while dynamic masking probability enhances the training in an easy-to-hard manner. After knowledge selection the next task in KTDS is knowledge-grounded generation. To improve the performance in knowledge-grounded generation we propose GPT-PR to employ post-ranking on the generator's outputs. Post-ranking eliminates the possibility of generating hallucination response by a large portion during the sampling-based decoding process and thus can improve the quality of the generated response. Experimental results on the benchmark dataset show that our proposed pre-training and post-ranking methods DA-BERT and GPT-PR respectively outperform the state-of-the-art models with large margins across all the evaluation metrics. Moreover in the experiments we also analyze the bad cases of DA-BERT and GPT-PR and do visualizations to facilitate further research in this direction.;2021
Many attempts have been made to construct new domain-specific knowledge graphs using the existing knowledge base of various domains. However traditional dictionary-based or supervised knowledge graph building methods rely on predefined human-annotated resources of entities and their relationships. The cost of creating human-annotated resources is high in terms of both time and effort. This means that relying on human-annotated resources will not allow rapid adaptability in describing new knowledge when domain-specific information is added or updated very frequently such as with the recent coronavirus disease-19 (COVID-19) pandemic situation. Therefore in this study we propose an Open Information Extraction (OpenIE) system based on unsupervised learning without a pre-built dataset. The proposed method obtains knowledge from a vast amount of text documents about COVID-19 rather than a general knowledge base and add this to the existing knowledge graph. First we constructed a COVID-19 entity dictionary and then we scraped a large text dataset related to COVID-19. Next we constructed a COVID-19 perspective language model by fine-tuning the bidirectional encoder representations from transformer (BERT) pre-trained language model. Finally we defined a new COVID-19-specific knowledge base by extracting connecting words between COVID-19 entities using the BERT self-attention weight from COVID-19 sentences. Experimental results demonstrated that the proposed Co-BERT model outperforms the original BERT in terms of mask prediction accuracy and metric for evaluation of translation with explicit ordering (METEOR) score.;2021
Many B2B firms have widely accepted AI-based chatbots to provide human-like service interaction at different customer touchpoints in recent years. One of the objectives behind introducing this technology is to provide an enhanced live channel Customer Experience (CX) all round the clock. Researchers have focused on delivering the CX by improvising the chatbot's internal algorithm giving limited attention to CX theories from management literature which leaves a gap. With the proposed paper we have investigated the influencing factors of AI-based chatbots from the lens of CX theories for B2B firms. In this paper a model for organizing CX has been proposed using the diffusion of innovation theory trust commitment theory information systems success model and Hoffman & Novak's flow model for the computer-mediated environment and verified using the social media data. The methodology used for this study is the social media analytics-based content analysis method (sentiment analysis hierarchical clustering topic modeling) for data preparation followed by lasso and ridge regression for model verification. The results suggest that CX in B2B enterprises using chatbots is influenced by these bots' overall system design customers' ability to use technology and customer trust towards brand and system.;2021
Many learners of English as a foreign language often feel that learning spoken English is frustrating and quite difficult especially when they have to talk to English-speaking foreigners. In general because they are unfamiliar with the spoken mode of English and are worried about making grammatical errors they often feel very scared to speak English. Furthermore spoken language and reading differ in many ways. For instance when seeing text containing new words learners can stop and look up words in a dictionary. Additionally a passage can be read multiple times by learners to understand it. Conversely spoken language must be understood immediately in order to communicate effectively. The purpose of this study is to propose an interactive chatbot system named TPBOT which stands for TOEIC Practice Chatbot for EFL learners to eliminate their fear of speaking English and enable them to chat with online chatbots to practice spoken English at any time. This TPBOT would be very helpful to eliminate learners' anxiety about speaking a foreign language with foreigners. Participants in this study are Taiwanese students whose oral scores on the TOEIC (R) test are below 100. They hope to improve their oral English ability after participating in the four-month experiment. The results have shown that students are satisfied with using this TPBOT and believe that it has indeed helped them improve their English speaking skills. Obviously the TPBOT was very effective for the intended purpose. For educators the TPBOT is very useful to build learning content in the TPBOT provide learners with interactive exercises and improve learning effects.;2021
Many of the world's leading brands and increasingly government agencies are using intelligent agent technologies also known as chatbots to interact with consumers. However consumer satisfaction with chatbots is mixed. Consumers report frustration with chatbots arising from misunderstood questions irrelevant responses and poor integration with human service agents. This study examines whether human-computer interactions can be more personalized by matching consumer personality with congruent machine personality using language. Although the idea that personality is manifested through language and that people are more likely to be responsive to others with the same personality is well known there is a dearth of research that examines whether this is consistent for human-computer interactions. Based on a sample of over 57000 chatbot interactions this study demonstrates that consumer personality can be predicted during contextual interactions and that chatbots can be manipulated to 'assume a personality' using response language. Matching consumer personality with congruent chatbot personality had a positive impact on consumer engagement with chatbots and purchasing outcomes for interactions involving social gain.;2021
Many people are now engaged in remote conversations for a wide variety of scenes such as interviewing counseling and consulting but there is a limited number of skilled experts. We propose a novel framework of parallel conversations with semi-autonomous avatars where one operator collaborates with several remote robots or agents simultaneously. The autonomous dialogue system mostly manages the conversation but switches to the human operator when necessary. This framework circumvents the requirement for autonomous systems to be completely perfect. Instead we need to detect dialogue breakdown or disengagement. We present a prototype of this framework for attentive listening.;2021
Massive open online courses (MOOCs) allow students and instructors to discuss through messages posted on a forum. However the instructors should limit their interaction to the most critical tasks during MOOC delivery so teacher-led scaffolding activities such as forum-based support can be very limited even impossible in such environments. In addition students who try to clarify the concepts through such collaborative tools could not receive useful answers and the lack of interactivity may cause a permanent abandonment of the course. The purpose of this paper is to report the experimental findings obtained evaluating the performance of a text categorization tool capable of detecting the intent the subject area the domain topics the sentiment polarity and the level of confusion and urgency of a forum post so that the result may be exploited by instructors to carefully plan their interventions. The proposed approach is based on the application of attention-based hierarchical recurrent neural networks in which both a recurrent network for word encoding and an attention mechanism for word aggregation at sentence and document levels are used before classification. The integration of the developed classifier inside an existing tool for conversational agents based on the academically productive talk framework is also presented as well as the accuracy of the proposed method in the classification of forum posts.;2021
Massive open online courses (MOOCs) pose a challenge for instructors when trying to provide personalised support to learners due to large numbers of registered participants. Conversational agents can be of help to support learners when working with MOOCs. This article presents an adaptive learning module for JavaPAL a conversational agent that complements a MOOC on Java programming helping learners review the key concepts of the MOOC. This adaptive learning module adapts the difficulty of the questions provided to learners considering their level of knowledge using item response theory (IRT) and also provides recommendations of video fragments extracted from the MOOC for when learners fail questions. The adaptive learning module for JavaPAL has been evaluated showing good usability and learnability through the system usability scale (SUS) reasonably suitable video fragments recommendations for learners and useful visualisations generated as part of the IRT-based adaptation of questions for instructors to better understand what is happening in the course to design exams and to redesign the course content. Implications for practice or policy: A conversational agent that adapts the questions provided to learners using Item Response Theory (IRT) can be helpful for learners to review the concepts of a MOOC. A conversational agent that provides video fragments recommendations can be helpful for learners to improve their performance when answering questions from a MOOC. IRT-based visualisations of item characteristic curves and item information curves can be helpful to redesign the contents of a MOOC.;2021
Mental disorders are widespread in countries all over the world. Nevertheless there is a global shortage in human resources delivering mental health services. Leaving people with mental disorders untreated may increase suicide attempts and mortality. To address this matter of limited resources conversational agents have gained momentum in the last years. In this work we introduce SERMO a mobile application with integrated chatbot that implements methods from cognitive behaviour therapy (CBT) to support mentally ill people in regulating emotions and dealing with thoughts and feelings. SERMO asks the user on a daily basis on events that occurred and on emotions. It determines automatically the basic emotion of a user from the natural language input using natural language processing and a lexicon-based approach. Depending on the emotion an appropriate measurement such as activities or mindfulness exercises are suggested by SERMO. Additional functionalities are an emotion diary a list of pleasant activities mindfulness exercises and information on emotions and CBT in general. User experience was studied with 21 participants using the User Experience Questionnaire (UEQ). Findings show that efficiency perspicuity and attractiveness are considered as good. The scales describing hedonic quality (stimulation and novelty) i.e. fun of use show neutral evaluations.;2021
Moral education refers to the cultivation of ideals moral quality culture and discipline. One of its main tasks is to analyze students' problem behaviors and identify their underlying need deficiencies. Previous psychological research has focused on studying how distinct factors affect psychological needs and problem behaviors. However these findings have provided only scattered guidelines for identifying students' need deficiencies which are difficult for inexperienced teachers and parents to apply systematically. To address these issues we attempt to answer two key research questions in this work. First how do we define a theoretical framework so that the psychological research findings can be systematically applied to identify students' need deficiencies? Second can the latest AI technologies be employed to identify such need deficiencies automatically? To answer these research questions we first build a theoretical framework to summarize all the factors relevant to the students' problem behaviors and need deficiencies. After that we propose and develop a task-oriented dialogue system that can properly inquire about different aspects of students' information and automatically infer their need deficiencies. We conduct comprehensive experiments to evaluate the system's performance with real-life cases. The results show that the built dialogue system could effectively serve as a diagnostic tool to identify the students' need deficiencies.;2021
Multimodality in dialogue systems has opened up new frontiers for the creation of robust conversational agents. Any multimodal system aims at bridging the gap between language and vision by leveraging diverse and often complementary information from image audio and video as well as text. For every task-oriented dialog system different aspects of the product or service are crucial for satisfying the user's demands. Based upon the aspect the user decides upon selecting the product or service. The ability to generate responses with the specified aspects in a goal-oriented dialogue setup facilitates user satisfaction by fulfilling the user's goals. Therefore in our current work we propose the task of aspect controlled response generation in a multimodal task-oriented dialog system. We employ a multimodal hierarchical memory network for generating responses that utilize information from both text and images. As there was no readily available data for building such multimodal systems we create a Multi-Domain Multi-Modal Dialog (MDMMD++) dataset. The dataset comprises the conversations having both text and images belonging to the four different domains such as hotels restaurants electronics and furniture. Quantitative and qualitative analysis on the newly created MDMMD++ dataset shows that the proposed methodology outperforms the baseline models for the proposed task of aspect controlled response generation.;2021
Multi-turn response selection is a major task in building intelligent dialogue systems. Most existing works focus on modeling the semantic relationship between the utterances and the candidate response with neural networks like RNNs and various attention mechanisms. In this paper we study how to leverage the advantage of pre-trained language models (PTMs) to multi turn response selection in retrieval-based chatbots. We propose a deep context modeling architecture (DCM) for multi-turn response selection by utilizing BERT as the context encoder. DCM is formulated as a four-module architecture namely contextual encoder utterance-to-response interaction features aggregation and response selection. Moreover in DCM we introduce the next utterance prediction as a pre-training scheme based on BERT aiming to adapt general BERT to accommodate the inherent context continuity underlying the multi-turn dialogue. Taking BERT as the backbone encoder we then investigate a variety of strategies to perform response selection with comprehensive comparisons. Empirical results on three public datasets from two different languages show that our proposed model outperforms existing promising models significantly pushing recall to 86.8% (+5.2% improvement over BERT) on Ubuntu Dialogue corpus recall to 68.5% (+6.4% improvement over BERT) on E-Commerce Dialogue corpus MAP and MRR to 61.6% and 64.9% respectively (+2.3% and 1.8% improvement over BERT) on Douban Conversation corpus achieving new state-of-the-art performance for multi-turn response selection.;2021
Natural Language Generation (NLG) plays a critical role in Spoken Dialogue Systems (SDSs) aims at converting a meaning representation into natural language utterances. Recent deep learning-based generators have shown improving results irrespective of providing sufficient annotated data. Nevertheless how to build a generator that can effectively utilize as much of knowledge from a low-resource setting data is a crucial issue for NLG in SDSs. This paper presents a variational-based NLG framework to tackle the NLG problem of having limited annotated data in two scenarios domain adaptation and low-resource in-domain training data. Based on this framework we propose a novel adversarial domain adaptation NLG taclking the former issue while the latter issue is also handled by a second proposed dual variational model. We extensively conducted the experiments on four different domains in a variety of training scenarios in which the experimental results show that the proposed methods not only outperform previous methods when having sufficient training dataset but also show its ability to work acceptably well when there is a small amount of in-domain data or adapt quickly to a new domain with only a low-resource target domain data. (C) 2020 Published by Elsevier Ltd.;2021
Natural language processing (NLP) is a critical part of the digital transformation. NLP enables user-friendly interactions between machine and human by making computers understand human languages. Intelligent chatbot is an essential application of NLP to allow understanding of users' utterance and responding in understandable sentences for specific applications simulating human-to-human conversations and interactions for problem solving or Q&As. This research studies emerging technologies for NLP-enabled intelligent chatbot development using a systematic patent analytic approach. Some intelligent text-mining techniques are applied including document term frequency analysis for key terminology extractions clustering method for identifying the subdomains and Latent Dirichlet Allocation for finding the key topics of patent set. This research utilizes the Derwent Innovation database as the main source for global intelligent chatbot patent retrievals.;2021
Navigation based task-oriented dialogue systems provide users with a natural way of communicating with maps and navigation software. Natural language understanding (NLU) is the first step for a task-oriented dialogue system. It extracts the important entities (slot tagging) from the user's utterance and determines the user's objective (intent determination). Word embeddings are the distributed representations of the input sentence and encompass the sentence's semantic and syntactic representations. We created the word embeddings using different methods like FastText ELMO BERT and XLNET and studied their effect on the natural language understanding output. Experiments are performed on the Roman Urdu navigation utterances dataset. The results show that for the intent determination task XLNET based word embeddings outperform other methods while for the task of slot tagging FastText and XLNET based word embeddings have much better accuracy in comparison to other approaches.;2021
Nowadays chatbots is one of the fast rising artificial intelligence (AI) trend relates to the utilisation of applications that interact with users in a conversational format and mimic human conversation. Chatbots allow business to enhance customer experiences and fulfil expectations through real-time interactions in e-commerce environment. Therefore factors influence consumer's trust in chatbots is critical. This study demonstrates a chatbots trust model to empirically investigate consumer's perception by questionnaire from self-reported approach and by electroencephalography (EEG) from neuroscience approach. This study starts from integrating three key elements of chatbots in terms of machine communication quality aspect human-computer interaction (HCI) aspect and human use and gratification (U&G) aspects. Moreover this study chooses EEG instrument to explore the relationship between trust and purchase intention in chatbots condition. We collect 204 questionnaires and invite 30 respondents to participate the survey. The results indicated that credibility competence anthropomorphism social presence and informativness have influence on consumer's trust in chatbots in turn have effect on purchase intention. Moreover the findings show that the dorsolateral prefrontal cortex and the superior temporal gyrus are significantly associated with building a trust relationship by inferring chatbots to influence subsequent behaviour.;2021
Nowadays museums are developing chatbots to assist their visitors and to provide an enhanced visiting experience. Most of these chatbots do not provide a human-like conversation and fail to deliver the complete requested knowledge by the visitors. There are plenty of stand-alone museum chatbots developed using a chatbot platform that provide predefined dialog routes. However as chatbot platforms are evolving and AI technologies mature new architectural approaches arise. Museums are already designing chatbots that are trained using machine learning techniques or chatbots connected to knowledge graphs delivering more intelligent chatbots. This paper is surveying a representative set of developed museum chatbots and platforms for implementing them. More importantly this paper presents the result of a systematic evaluation approach for evaluating both chatbots and platforms. Furthermore the paper is introducing a novel approach in developing intelligent chatbots for museums. This approach emphasizes graph-based distributed and collaborative multi-chatbot conversational AI systems for museums. The paper accentuates the use of knowledge graphs as the key technology for potentially providing unlimited knowledge to chatbot users satisfying conversational AI's need for rich machine-understandable content. In addition the proposed architecture is designed to deliver an efficient deployment solution where knowledge can be distributed (distributed knowledge graphs) and shared among different chatbots that collaborate when is needed.;2021
Nowadays new technologies are taking place for enabling conversational interactions between users and bots. Creating conversational interfaces (CI) paves the way for new design challenges. Designers need to use appropriate design specifications for creating a logically sound dialogue endowed with proper visual cues in the case of chatbots that captures the entire user experience. To do it they need the help of domain experts. Experts in mobility environment energy e-health weather etc. are the only ones who well-know the specific domain in which the bot will act. Current tools used to design interactive flows of dialogue entail deep programming skills their users need to know. Starting from this consideration the paper proposes a design environment that offers experts the possibility to design a flow of dialogue without getting lost in technicalities. By using visual language the expert can specify intents actions entities and parameters at the base of the flow of dialogue on which the bot will be created. Then our engine automatically translates into a bot compliant with the Google DialogFlow technology. Finally the paper present a preliminary analysis of the system carried out to test its features and how these are reflected in its ease of use.;2021
Nowadays smartphone applications (apps) are literally used in all life aspects improving the quality of different services in addition to saving time and effort. However the majority of currently used apps in different universities around the world are limited in their features and not very popular among students who may suffer to get useful information using traditional guiding methods. However the importance of these apps is constantly increasing especially in times of crises like the COVID-19 pandemic during which people were forced to work from home and the human interaction was reduced to its minimal degree. In this paper we present a Student Interactive Assistant Android Application with Chatbot (SIAAA-C) which is basically a personal electronic guide that is used by students to get various and effective academic services. The app has a number of useful features including a campus map multiple types of notifications and most important an efficient built in chatbot that responds to both Arabic and English written queries and covers a wide range of academic topics ranging from basic to complex. Even more SIAAA-C was designed to have Arabic and English interfaces to be used in the University of Jordan (UoJ) which has one of the biggest campuses in the Arabic area with more than 40000 local and foreign students. Moreover SIAAA-C was practically tested in a real-life environment by a group of UoJ students who were selected from different faculties during the pandemic peak period and the feedbacks were very promising based on the outcomes of an evaluation survey that was answered by 102 students after a 1-month test period.;2021
OBJECTIVE: To examine user uptake and experience with a clinical chathot that automates hereditary cancer risk triage by collecting personal and family cancer history in routine women's health care settings. METHODS: We conducted a multicenter retrospective observational study of patients who used a web-based chathot before routine care appointments to assess their risk for hereditary breast and ovarian cancer Lynch syndrome and adenomatous polyposis syndromes. Outcome measures included uptake and completion of the risk-assessment and educational section of the chathot interaction and identification of hereditary cancer risk as evaluated against National Comprehensive Cancer Network criteria. RESULTS: Of the 95166 patients invited 61070 (64.2%) engaged with the clinical chathot. The vast majority completed the cancer risk assessment (89.4%) and most completed the genetic testing education section (71.4%) indicating high acceptability among those who opted to engage. The mean duration of use was 15.4 minutes (SD 2 hours 56.2 minutes) when gaps of inactivity longer than 5 minutes were excluded. A personal history of cancer was reported by 19.1% (10849/56656) and a family history of cancer was reported by 66.7% (36469/54652) of patients who provided the relevant information. One in four patients (14850/54547) screened with the chatbot before routine care appointments met National Comprehensive Cancer Network criteria for genetic testing. Among those who were tested 5.6% (73/1313) had a disease-causing pathogenic variant. CONCLUSION: A chathot digital health tool can help identify patients at high risk for hereditary cancer syndromes before routine care appointments. This scalable intervention can effectively provide cancer risk assessment engage patients with educational information and facilitate a path toward preventive genetic testing.;2021
Objective To assess the quality and accuracy of online videos about the medical management of nephrolithiasis. Materials and Methods To evaluate trends in online interest we first examined the frequency of worldwide YouTube searches for 'kidney stones' from 2015 to 2020. We then queried YouTube with terms related to symptoms and treatment of kidney stones and analysed English-language videos with >5000 views. Quality was assessed using the validated DISCERN instrument. Evidence-based content analysis of video content and viewer comments was performed. Results Online searches for videos about kidney stones doubled between 2015 and 2019 (P < 0.001). We analysed 102 videos with a median (range) number of views of 46 539 (5024-3 631 322). The mean (sd)DISCERN score was 3.0 (1.4) out of 5 indicating 'moderate' quality scores were significantly higher for the 21 videos (21%) authored by academic hospitals (mean 3.7 vs 2.8P = 0.02). Inaccurate or non-evidence-based claims were identified in 23 videos (23%) none of the videos authored by academic institutions contained inaccurate claims. Videos with inaccurate statements had more than double the viewer engagement (viewer-generated comments 'thumbs up' and 'thumbs down' ratings) compared to videos without inaccuracies (P < 0.001). Among viewer comments 43 videos (43%) included comments with inaccurate or non-evidence-based claims and a large majority (82 videos 80%) had 'chatbot' recommendations. Conclusions Interest in YouTube videos about nephrolithiasis has doubled since 2015. While highly viewed videos vary widely in quality and accuracy videos produced by academic hospitals have significantly fewer inaccurate claims. Given the high prevalence of stone disease and poor-quality videos patients should be directed to evidence-based content online.;2021
Objective We examined the potential of conversational agents (CAs) to support older adults' self-care related to chronic illness in light of lessons learned from decades of pedagogical agent research which investigates the impact and efficacy of CAs for a wide range of learners. Background The role of CAs in education (i.e. pedagogical agents) has been long studied but their potential for supporting self-care has received less attention especially for older adults. Methods We reviewed work on pedagogical agents and considered how it informs the design of CAs for older adults. We propose a framework for designing CAs to support older adult self-care which organizes a review of work in this area and integration with the pedagogical agent literature. Results Our review of the pedagogical agent literature revealed an evolution from teaching machines to interactive social systems that influence student motivational as well as learning outcomes. To integrate this review with work on CAs and self-care we developed a framework that specifies how self-care goals evolve with stages of an illness communication goals that support self-care at each stage patient needs and requirements for CAs to support these needs. The review identified an agenda for future research on CA functions and features that help older adults accept need for self-care establish self-care and sustain self-care over time. Conclusions Integrating insights from the pedagogical agent literature with research on developing CAs for self-care defines an agenda for developing and evaluating CAs to help older adults manage illness.;2021
Objective: The need for digital tools in mental health is clear with insufficient access to mental health services. Conversational agents also known as chatbots or voice assistants are digital tools capable of holding natural language conversations. Since our last review in 2018 many new conversational agents and research have emerged and we aimed to reassess the conversational agent landscape in this updated systematic review. Methods: A systematic literature search was conducted in January 2020 using the PubMed Embase PsychINFO and Cochrane databases. Studies included were those that involved a conversational agent assessing serious mental illness: major depressive disorder schizophrenia spectrum disorders bipolar disorder or anxiety disorder. Results: Of the 247 references identified from selected databases 7 studies met inclusion criteria. Overall there were generally positive experiences with conversational agents in regard to diagnostic quality therapeutic efficacy or acceptability. There continues to be however a lack of standard measures that allow ease of comparison of studies in this space. There were several populations that lacked representation such as the pediatric population and those with schizophrenia or bipolar disorder. While comparing 2018 to 2020 research offers useful insight into changes and growth the high degree of heterogeneity between all studies in this space makes direct comparison challenging. Conclusions: This review revealed few but generally positive outcomes regarding conversational agents' diagnostic quality therapeutic efficacy and acceptability which may augment mental health care. Despite this increase in research activity there continues to be a lack of standard measures for evaluating conversational agents as well as several neglected populations. We recommend that the standardization of conversational agent studies should include patient adherence and engagement therapeutic efficacy and clinician perspectives.;2021
Objective: The present meta-analysis sought to determine significant factors that predict trust in artificial intelligence (AI). Such factors were divided into those relating to (a) the human trustor (b) the AI trustee and (c) the shared context of their interaction. Background: There are many factors influencing trust in robots automation and technology in general and there have been several meta-analytic attempts to understand the antecedents of trust in these areas. However no targeted meta-analysis has been performed examining the antecedents of trust in AI. Method: Data from 65 articles examined the three predicted categories as well as the subcategories of human characteristics and abilities AI performance and attributes and contextual tasking. Lastly four common uses for AI (i.e. chatbots robots automated vehicles and nonembodied plain algorithms) were examined as further potential moderating factors. Results: Results showed that all of the examined categories were significant predictors of trust in AI as well as many individual antecedents such as AI reliability and anthropomorphism among many others. Conclusion: Overall the results of this meta-analysis determined several factors that influence trust including some that have no bearing on AI performance. Additionally we highlight the areas where there is currently no empirical research. Application: Findings from this analysis will allow designers to build systems that elicit higher or lower levels of trust as they require.;2021
Objective: To determine whether smart conversational agents can be used for detection of neuropsychiatric disorders. Therefore we reviewed the technologies used targeted mental disorders and validation procedures of relevant proposals in this field. Methods: We searched Scopus PubMed Pro-Quest IEEE Xplore Web of Science CINAHL and the Cochrane Library using a predefined search strategy. Studies were included if they focused on neuropsychiatric disorders and involved conversational data for detection and diagnosis. They were assessed for eligibility by independent reviewers and ultimately included if a consensus was reached about their relevance. Results: 2356 references were initially retrieved. Eventually 17 articles - referring 9 smart conversational agents - met the inclusion criteria. Out of the selected studies 7 are targeted at neurocognitive disorders 7 at depression and 3 at other conditions. They apply diverse technological solutions and analysis techniques (82.4% use Artificial Intelligence) and they usually rely on gold standard tests for criterion validity assessment. Acceptability reliability and other aspects of validity were rarely addressed. Conclusion: The use of smart conversational agents for the detection of neuropsychiatric disorders is an emerging and promising field of research with a broad coverage of mental disorders and extended use of AI. However the few published studies did not undergo robust psychometric validation processes. Future research in this field would benefit from more rigorous validation mechanisms and standardized software and hardware platforms.;2021
Objective: To report the early experience using an automated chatbot (Chats) for patient-reported outcomes (PRO) and symptom self-management in head and neck cancer (HNC) patients undergoing radiation treatment (RT). Methods: Patients aged >= 18 years diagnosed with HNC who were scheduled to begin RT were given the option to use Chats from June 2018 to June 2019. Enrolled patients received chat notifications two days before weekly ontreatment visits and every 1-4 weeks after RT for an additional 4 months. After the first in-person follow-up visit participants completed an electronic usability and satisfaction questionnaire. Results: Of 95 patients who agreed to participate 84 were eligible for analysis. Participants were significantly younger than patients who declined participation (mean age 61.3 vs 68.3 years p-value < 0.001). Patient engagement with Chats was highest at 67% during the first month and declined over time (p-value = 0.004). Concordance between PRO and clinician-reported outcomes (CRO) was fair ranging from 0.10 to 0.43 (Cohen kappa statistics). The most commonly under-reported symptoms were salivary duct inflammation (53%) xerostomia (41%) and mucositis (37%). 89% (39 of 44) of patients who completed surveys found Chats easy to use and 61% reported that Chats helped with symptom self-management and reduced the need to call the care team. Conclusions: These early results suggest that an interactive chatbot is feasible and provides support for HNC patients during and after RT. Chats identified discordance between PRO and CRO. Further study is required to measure benefits of Chats in a larger population.;2021
Objective: To support informed decision-making about reanalysis of clinical genomic data for risk of preventable conditions ('additional findings') by developing a chatbot (electronic genetic resource 'eDNA'). Methods: Interactions in pre-test genetic counseling sessions (13.5 h) about additional findings were characterized using proponent thematic and semantic analyses of transcripts. We then wrote interfaces to draw supplementary data from external genetics applications. To create Edna this content was programmed using a chatbot framework which interacts with patients via speech-to-text. Results: Conditions terms explanations of concepts and key factors to consider in decision making were all encoded into chatbot conversations emulating counseling session flows. Patient agency can be enhanced by prompted consideration of the personal and familial implications of testing. Similarly health literacy can be broadened through explanation of genetic conditions and terminology. Novel aspects include sentiment analysis and collection of family history. Medical advice and the impact of existing genetic conditions were deemed inappropriate for inclusion. Conclusion: Edna's successful development represents a movement towards accessible acceptable and well-supported digital health processes for patients to make informed decisions for additional findings. Practice implications: Edna complements genetic counseling by collecting and providing genomic information before or after pre-test consultations. Crown Copyright (C) 2020 Published by Elsevier B.V. All rights reserved.;2021
Objectives This systematic review aims to examine the effectiveness of online mental health interventions for youth. Methods We searched seven electronic databases (PubMed PsycINFO Medline Embase CINAHL Web of Science and SCOPUS) for the past 10 years to identify randomized controlled trials which have evaluated the use of telehealth interventions for young people with mental health problems. The included studies were assessed for quality and risk of bias. Results Forty-five randomized controlled trials (n = 13291 participants) were eligible for this review. Most studies (35 trials) evaluated the use of web-based self-help platforms to deliver cognitive behavioural therapy (14 trials) mindfulness (four trials) acceptance commitment therapy (five trials) and positive psychology (two trials). Mobile/computer applications were used to deliver cognitive behavioural therapy (four trials) and coping strategies training (two trials). Web-based synchronous chat (one trial) was used to assist communication between counsellors and participants. Three studies used artificial intelligence-based conversational agents to deliver cognitive behavioural therapy (two trials) and problem-solving-strategy training (one trial). Eighty-two percent (n = 37) identified the participants as student population (i.e. university students high school students). Sixty-four percent (n = 29) of the telehealth interventions were found to be effective in managing depression anxiety stress insomnia and improving quality of life when compared with control conditions. Conclusions Online mental health interventions were found to be effective in managing diverse mental health conditions among youth. Online self-help platforms were the most frequently used modality and artificial intelligence-based chatbots are merging as potential solutions. Future research is warranted to investigate the solutions to improve the retention rate and satisfaction of telehealth interventions among this population.;2021
Off-the-shelf conversational agents are permeating people's everyday lives. In these artificial intelligence devices trust plays a key role in users' initial adoption and successful utilization. Factors enhancing trust toward conversational agents include appearances voice features and communication styles. Synthesizing such work will be useful in designing evidence-based trustworthy conversational agents appropriate for various contexts. We conducted a systematic review of the experimental studies that investigated the effect of conversational agents' and users' characteristics on trust. From a full-text review of 29 articles we identified five agent design-themes affecting trust toward conversational agents: social intelligence of the agent voice characteristics and communication style look of the agent non-verbal communication and performance quality. We also found that participants' demographic personality or use context moderate the effect of these themes. We discuss implications for designing trustworthy conversational agents and responsibilities around on stereotypes and social norm building through agent design.;2021
Often second/foreign (L2) language learners receive little opportunity to interact orally in the target language. Interactive conversation-based spoken dialog systems (SDSs) that use automated speech recognition and natural language processing have the potential to address this need by engaging learners in meaningful goal-oriented speaking practice. However these technology-based learning tools are often developed without input from teaching professionals. As part of a larger development effort this study examined English as a second language (ESL) teachers' perceptions regarding SDS-based speaking tasks addressing the following research questions: (a) What do teachers think about the SDS-based tasks? (b) How would they use them in the context of their English instruction? Overall 16 ESL instructors in an intensive English program in the United States were asked to interact with four SDS-based speaking tasks designed to elicit specific linguistic phenomena (e.g. making requests wh-questions). The teachers completed a survey after each task to gauge their user experience level of engagement and perceptions of the usefulness of the tasks for their teaching contexts. A subgroup of instructors (n = 7) also participated in audio-recorded focus group meetings. Descriptive statistics were calculated for each survey item and the open-ended responses from the surveys and focus groups were analyzed qualitatively for major themes. The findings show that teachers had positive views of the SDS tasks' potential for speaking practice and diagnostic purposes primarily in a flipped classroom model. Their perceptions seemed to be related to their own user experience and in particular to the perceived authenticity of a given task.;2021
Omni-channel marketing is an enhanced cross-channel business model involving shared data that allows enterprises to enhance and facilitate customer experience. Omni-channel opportunities shape retail business and shopper behaviours by coordinating data across all channel platforms while enabling their simultaneous use. Artificial intelligence (AI) has played an increasingly critical role in marketing analysis. With the proper training AI can predict consumer preferences and provide recommendations based on historical data to achieve precision marketing in e-commerce. At present however the existent chatbots on many product-ordering platforms lack AI refinement resulting in the need to ask customers multiple questions before generating a reliable suggestion yet an effective way to incorporate AI in an omni-channel platform has remained vague. Hence the aim of this study was to develop an omni-channel chatbot that incorporates iOS Android and web components. The chatbot was designed to achieve personalised service and precision marketing using convolutional neural networks (CNNs). A shared kitchen case study demonstrates the advantages of the proposed method which is transferable to other consumer applications such as clothing selection or personalised services. The number of food offerings and the quality of image classifiers set the research limitations pointing toward the direction of future research.;2021
One important problem in MOOCs is the lack of personalized support from teachers. Conversational agents arise as one possible solution to assist MOOC learners and help them to study. For example conversational agents can help review key concepts of the MOOC by asking questions to the learners and providing examples. JavaPAL a voice-based conversational agent for supporting learners on a MOOC on programming with Java offered on edX. This paper evaluates JavaPAL from different perspectives. First the usability of JavaPAL is analyzed obtaining a score of 74.41 according to a System Usability Scale (SUS). Second learners' performance is compared when answering questions directly through JavaPAL and through the equivalent web interface on edX getting similar results in terms of performance. Finally interviews with JavaPAL users reveal that this conversational agent can be helpful as a complementary tool for the MOOC due to its portability and flexibility compared to accessing the MOOC contents through the web interface.;2021
One of the biggest challenges for EFL (English as Foreign Language) students to learn English is the lack of practicing environments. Although language researchers have attempted to conduct flipped classrooms to increase the practicing time in class EFL students generally have difficulties interacting with peers and teachers in English in class. The advancement of Artificial Intelligence ( AI) provides an opportunity to address this problem. With AI technologies computer systems in particular in the form of AI chatbots are able to identify the meanings of users' statements and make responses accordingly. In the research design AI-based chatbots were employed in the in-class and out-of-class activities for facilitating the students' speaking performance and interactions during the learning process in a university flipped English speaking classroom. The experimental results show that the mind map-guided AI chatbot approach (MM-AI) promoted the students' English speaking performances more than did the conventional AI chatbot approach (C-AI). Moreover the MMAI also promoted the students' learning performance and organized the interaction between the robots and humans more than the C-AI did. The findings could be a valuable reference for language educators and researchers who intend to conduct AI-supported flipped classrooms in language learning.;2021
Online healthcare consultation offers people a convenient way to consult doctors. In this paper we aim at building a generative dialog system for Chinese healthcare consultation. As the original Seq2seq architecture tends to suffer the issue of generating low-quality responses the multi-source Seq2seq architecture generating more informative responses is much more preferred in this task. The multi-source Seq2seq architecture takes advantage of retrieval techniques to obtain responses from the database and then takes these responses alongside the user-issued question as input. However some of the retrieved responses might be not much related to the user-issued question resulting in the generation of unsatisfying responses that are not correct in diagnosis or instead provide inappropriate advice on prevention or treatment. Therefore this paper proposes multi-source Seq2seq guided by knowledge (MSSGK) to handle this problem. MSSGK differs from the multi-source Seq2seq architecture in that domain knowledge including disease labels and topic labels about prevention and treatment is introduced into the response generation via a multi-task learning framework. To better exploit the domain knowledge we propose three attention mechanisms to provide more appropriate guidance for response generation. Experimental results on a dataset of real-world healthcare consultation show the effectiveness of the proposed method.;2021
Online Social Networks (OSNs) are witnessing sophisticated cyber threats that are generally conducted using fake or compromised profiles. Automated agents (aka socialbots) a category of sophisticated and modern threat entities are the native of the social media platforms and responsible for various modern weaponized information-related attacks such as astroturfing misinformation diffusion and spamming. Detecting socialbots is a challenging and vital task due to their deceiving character of imitating human behavior. To this end this paper presents an attention-aware deep neural network model DeepSBD for detecting socialbots on OSNs. The DeepSBD models users' behavior using profile temporal activity and content information. It jointly models OSN users' behavior using Bidirectional Long Short Term Memory (BiLSTM) and Convolutional Neural Network (CNN) architectures. It models profile temporal and activity information as sequences which are fed to a two-layers stacked BiLSTM whereas content information is fed to a deep CNN. We have evaluated DeepSBD over five real-world benchmark datasets and found that it performs significantly better in comparison to the state-of-the-arts and baseline methods. We have also analyzed the efficacy of DeepSBD at different ratios of socialbots and benign users and found that an imbalanced dataset moderately affects the classification accuracy. Finally we have analyzed the discrimination power of different behavioral components and it is found that both profile characteristics and content behavior are most impactful whereas diurnal temporal behavior is the least effective for detecting socialbots on OSNs.;2021
Open-domain dialog generation which is a crucial component of artificial intelligence is an essential and challenging problem. In this article we present a personalized dialog system which leverages the advantages of multitask learning and reinforcement learning for personalized dialogue generation (MRPDG). Specifically MRPDG consists of two subtasks: 1) an author profiling module that recognizes user characteristics from the input sentence (auxiliary task) and 2) a personalized dialog generation system that generates informative grammatical and coherent responses with reinforcement learning algorithms (primary task). Three kinds of rewards are proposed to generate high-quality conversations. We investigate the effectiveness of three widely used reinforcement learning methods [i.e. Q-learning policy gradient and actor-critic (AC) algorithm] in a personalized dialog generation system and demonstrate that the AC algorithm achieves the best results on the underlying framework. Comprehensive experiments are conducted to evaluate the performance of the proposed model on two real-life data sets. Experimental results illustrate that MRPDG is able to produce high-quality personalized dialogs for users with different characteristics. Quantitatively the proposed model can achieve better performance than the compared methods across different evaluation metrics such as the human evaluation BiLingual Evaluation Understudy (BLEU) and perplexity.;2021
Organizations introduce virtual assistants (VAs) to support employees with work-related tasks. VAs can increase the success of teamwork and thus become an integral part of the daily work life. However the effect of VAs on virtual teams remains unclear. While social identity theory describes the identification of employees with team members and the continued existence of a group identity the concept of the extended self refers to the incorporation of possessions into one's sense of self. This raises the question of which approach applies to VAs as teammates. The article extends the IS literature by examining the impact of VAs on individuals and teams and updates the knowledge on social identity and the extended self by deploying VAs in a collaborative setting. Using a laboratory experiment with N = 50 two groups were compared in solving a task where one group was assisted by a VA while the other was supported by a person. Results highlight that employees who identify VAs as part of their extended self are more likely to identify with team members and vice versa. The two aspects are thus combined into the proposed construct of virtually extended identification explaining the relationships of collaboration with VAs. This study contributes to the understanding on the influence of the extended self and social identity on collaboration with VAs. Practitioners are able to assess how VAs improve collaboration and teamwork in mixed teams in organizations.;2021
Our field experiment extends prior work on college matriculation by testing the extent to which an artificially intelligent (AI) chatbot's outreach and support to college students (N = 4442) reduced summer melt and improved first-year college enrollment at a 4-year university. Specifically we investigate which students the intervention proves most effective for. We find that the AI chatbot increased overall success with navigating financial aid processes such that student take up of educational loans increased by four percentage points. This financial aid effect was concentrated among would-be first-generation college goers for whom loan acceptances increased by eight percentage points. In addition the outreach increased first-generation students' success with course registration and fall semester enrollment each by three percentage points. Our findings suggest that proactive chatbot outreach to students is likely to be most successful in reducing summer melt among those who may need the chatbot support the most.;2021
Over the last ten years there has been a growing interest around text-based chatbots software applications interacting with humans using natural written language. However despite the enthusiastic market predictions ?conversing? with this kind of agents seems to raise issues that go beyond their current technological limitations directly involving the human side of interaction. By adopting a Human-Computer Interaction (HCI) lens in this article we present a systematic literature review of 83 papers that focus on how users interact with text-based chatbots. We map the relevant themes that are recurrent in the last ten years of research describing how people experience the chatbot in terms of satisfaction engagement and trust whether and why they accept and use this technology how they are emotionally involved what kinds of downsides can be observed in human-chatbot conversations and how the chatbot is perceived in terms of its humanness. On the basis of these findings we highlight open issues in current research and propose a number of research opportunities that could be tackled in future years.;2021
Overweight obesity and cardiometabolic diseases are major global health concerns. Lifestyle factors including diet have been acknowledged to play a key role in the solution of these health risks. However as shown by numerous studies and in clinical practice it is extremely challenging to quantify dietary behaviors as well as influencing them via dietary interventions. As shown by the limited success of 'one-size-fits-all' nutritional campaigns catered to an entire population or subpopulation the need for more personalized coaching approaches is evident. New technology-based innovations provide opportunities to further improve the accuracy of dietary assessment and develop approaches to coach individuals towards healthier dietary behaviors. Pride & Prejudice (P&P) is a unique multi-disciplinary consortium consisting of researchers in life nutrition ICT design behavioral and social sciences from all four Dutch Universities of Technology. P&P focuses on the development and integration of innovative technological techniques such as artificial intelligence (AI) machine learning conversational agents behavior change theory and personalized coaching to improve current practices and establish lasting dietary behavior change.;2021
Owing to technological advancements in artificial intelligence voice assistants (VAs) offer speech as a new interaction modality. Compared to text-based interaction speech is natural and intuitive which is why companies use VAs in customer service. However we do not yet know for which kinds of tasks speech is beneficial. Drawing on task-technology fit theory we present a research model to examine the applicability of VAs to different tasks. To test this model we conducted a laboratory experiment with 116 participants who had to complete an information search task with a VA or a chatbot. The results show that speech exhibits higher perceived efficiency lower cognitive effort higher enjoyment and higher service satisfaction than text-based interaction. We also find that these effects depend on the task's goal-directedness. These findings extend task-technology fit theory to customers' choice of interaction modalities and inform practitioners about the use of VAs for information search tasks.;2021
Patient-reported outcomes (PROs) and their use in the clinical workflow can improve cancer survivors' outcomes and quality of life. However there are several challenges regarding efficient collection of the patient-reported outcomes and their integration into the clinical workflow. Patient adherence and interoperability are recognized as main barriers. This work implements a cancer-related study which interconnects artificial intelligence (spoken language algorithms conversational intelligence) and natural sciences (embodied conversational agents) to create an omni-comprehensive system enabling symmetric computer-mediated interaction. Its goal is to collect patient information and integrate it into clinical routine as digital patient resources (the Fast Healthcare Interoperability Resources). To further increase convenience and simplicity of the data collection a multimodal sensing network is delivered. In this paper we introduce the main components of the system including the mHealth application the Open Health Connect platform and algorithms to deliver speech enabled 3D embodied conversational agent to interact with the cancer survivors in five different languages. The system integrates cancer patients' reported information as patient gathered health data into their digital clinical record. The value and impact of the integration will be further evaluated in the clinical study.;2021
People occasionally interact with each other through conversation. In particular we communicate through dialogue and exchange emotions and information from it. Emotions are essential characteristics of natural language. Conversational artificial intelligence is an integral part of all the technologies that allow computers to communicate like humans. For a computer to interact like a human being it must understand the emotions inherent in the conversation and generate the appropriate responses. However existing dialogue systems focus only on improving the quality of understanding natural language or generating natural language excluding emotions. We propose a chatbot based on emotion which is an essential element in conversation. EP-Bot (an Empathetic PolarisX-based chatbot) is an empathetic chatbot that can better understand a person's utterance by utilizing PolarisX an auto growing knowledge graph. PolarisX extracts new relationship information and expands the knowledge graph automatically. It is helpful for computers to understand a person's common sense. The proposed EP-Bot extracts knowledge graph embedding using PolarisX and detects emotion and dialog act from the utterance. Then it generates the next utterance using the embeddings. EP-Bot could understand and create a conversation including the person's common sense emotion and intention. We verify the novelty and accuracy of EP-Bot through the experiments.;2021
People's personality influences their behaviors attitudes beliefs and feelings. Therefore many scientific studies already benefit from easy ways of measuring personality. By analyzing the written text of a person it is possible to derive Big Five personality traits. One approach to this is to apply the unsupervised learning algorithm Global Vectors Word Embedding (or Representation) abbreviated GloVe to English Twitter posts. The overall objective of our research is to show that this algorithm can also be applied to German Twitter posts. Therefore we built a framework for training and applying machine learning models for personality predictions. We tested if a working prediction model for English Twitter users can be adapted for German users. This could reduce efforts for collecting training data. We evaluated our models based on a personality survey with a sample of German users. The method of adapting an existing model does not perform as well as expected but helps prepare the framework for higher volumes of data. In the end the final model is based on the evaluation data which results in an acceptable performance. Via a web application (https://www.miping.de) anyone can easily retrieve personality scores for any public German Twitter user. Altogether it is shown that GloVe is suitable to predict personality based on German language. The published framework and source code allow for independent improvements to and easy application of the trained model. Now scientific studies and other applications e.g. chatbots could easily incorporate personality data.;2021
Persuasion aims at forming one's opinion and action via a series of persuasive messages containing persuader's strategies. Due to its potential application in persuasive dialogue systems the task of persuasive strategy recognition has gained much attention lately. Previous methods on user intent recognition in dialogue systems adopt recurrent neural network (RNN) or convolutional neural network (CNN) to model context in conversational history neglecting the tactic history and intra-speaker relation. In this paper we demonstrate the limitations of a Transformer-based approach coupled with Conditional Random Field (CRF) for the task of persuasive strategy recognition. In this model we leverage inter- and intraspeaker contextual semantic features as well as label dependencies to improve the recognition. Despite extensive hyper-parameter optimizations this architecture fails to outperform the baseline methods. We observe two negative results. Firstly CRF cannot capture persuasive label dependencies possibly as strategies in persuasive dialogues do not follow any strict grammar or rules as the cases in Named Entity Recognition (NER) or part-of-speech (POS) tagging. Secondly the Transformer encoder trained from scratch is less capable of capturing sequential information in persuasive dialogues than Long Short-Term Memory (LSTM). We attribute this to the reason that the vanilla Transformer encoder does not efficiently consider relative position information of sequence elements. (C) 2020 Elsevier B.V. All rights reserved.;2021
Poor adherence to prescribed drug treatments is one of the leading causes of illness and treatment failure which increases re-hospitalizations. In Mexico the factors that most contribute to the non-adherence problem are age polypharmacy and education. For instance elderly patients are prescribed with an average of seven medications after they are discharged from hospitals and 25% of them face problems managing medications at home. A strategy that older adults use for medication adherence is to link their medication regimens to daily activities. We propose a system based in machine learning for audio-based activity recognition using Hidden Markov Models over Mel Frequency Cepstral Coefficients. The system triggers an assistive conversational agent that adapts its interaction model to the context detected. We report on two studies that provide evidence of the feasibility of our approach to assist older adults to develop consistent medication behaviors by associating them to daily routines. We first conducted an observational study with two older adults to understand the role of daily activities to develop consistent medication behaviors. Afterwards we conducted an in situ assessment of the audio-based activity recognition system with the two study subjects. Our results showed that anchor activities with an audible manifestation were recognized with an accuracy of 79% for subject 1 and 97.6% for subject 2. Additionally we validated how the integration of conversational agents into the system may support the mental association among activities and medication regimens that older adults fail to realize when for instance their intention plans involve multiple behaviors associated to an activity. The deployment of the proposed approach requires only a smart speaker which increases its feasibility of adoption in Latin American and other developing countries.;2021
Previous multi-turn dialogue approaches based on global Knowledge Graphs (KGs) still suffer from generic uncontrollable and incoherent responses generation. Most of them neither consider the local topic-level semantic information of KGs nor effectively merge the information of long dialogue contexts and KGs into the dialogue generation. To tackle these issues we propose a Topic-level Knowledge aware Dialogue Generation model to capture context-aware topic-level knowledge information. Our method thus accounts for topic-coherence fluency and diversity of generated responses. Specifically we first decompose the given KG into a set of topic-level sub-graphs with each sub-graph capturing a semantic component of the input KG. Furthermore we design a Topic-level Sub-graphs Attention Network to calculate the comprehensive representation of both sub-graphs and previous turns of dialogue utterances which then decoded with the current turn into a response. By using sub-graphs our model is able to attend to different topical components of the KG and enhance the topic-coherence. We perform extensive experiments on two datasets of DuRecDial and KdConv to demonstrate the effectiveness of our model. The experimental results demonstrate that our model outperforms existing strong baselines. (C) 2021 Elsevier B.V. All rights reserved.;2021
Previous research has highlighted age-related differences in social perception in particular emotional expression processing. To date such studies have largely focused on approaches that use static emotional stimuli that the participant has to identify passively without the possibility of any interaction. In this study we propose an interactive virtual environment to better address age-related variations in social and emotional perception. A group of 22 young (18-30 years) and 20 older (60-80 years) adults were engaged in a face-to-face conversation with an embodied conversational agent. Participants were invited to interact naturally with the agent and to identify his facial expression. Their gaze behaviour was captured by an eye-tracking device throughout the interaction. We also explored whether the Big Five personality traits (particularly extraversion) and anxiety modulated gaze during the social interaction. Findings suggested that age-related differences in gaze behaviour were only apparent when decoding social signals (i.e. listening to a partner's question identifying facial expressions) and not when communicating social information (i.e. when speaking). Furthermore higher extraversion levels consistently led to a shorter amount of time gazing towards the eyes whereas higher anxiety levels led to slight modulations of gaze only when participants were listening to questions. Face-to-face conversation with virtual agents can provide a more naturalistic framework for the assessment of online socio-emotional interaction in older adults which is not easily observable in classical offline paradigms. This study provides novel and important insights into the specific circumstances in which older adults may experience difficulties in social interactions.;2021
Problem definition: In this research we study how buyers' use of artificial intelligence (AI) affects suppliers' price quoting strategies. Specifically we study the impact of automation-that is the buyer uses a chatbot to automatically inquire about prices instead of asking in person-and the impact of smartness-that is the buyer signals the use of a smart AI algorithm in selecting the supplier. Academic/practical relevance: In a world advancing toward AI we explore how AI creates and delivers value in procurement. AI has two unique abilities: automation and smartness which are associated with physical machines or software that enable us to operate more efficiently and effectively. Methodology: We collaborate with a trading company to run a field experiment on an online platform in which we compare suppliers' wholesale price quotes across female male and chatbot buyer types under AI and no recommendation conditions. Results: We find that when not equipped with a smart control there is price discrimination against chatbot buyers who receive a higher wholesale price quote than human buyers. In fact without smartness automation alone receives the highest quoted wholesale price. However signaling the use of a smart recommendation system can effectively reduce suppliers' price quote for chatbot buyers. We also show that AI delivers the most value when buyers adopt automation and smartness simultaneously in procurement. Managerial implications: Our results imply that automation is not very valuable when implemented without smartness which in turn suggests that building smartness is necessary before considering high levels of autonomy. Our study unlocks the optimal steps that buyers could adopt to develop AI in procurement processes.;2021
Professional embodied conversational agents (ECAs) deployed in the market are dedicated to satisfying the digital customer relationship. However ECAs still suffer from a lack of user adoption in particular because most of them have few social skills. Inspired by social presence theories and based on the ergonomic components of user experience (CUE) model (Mahlke and Lindgaard 2007) the paper focuses on one social skill i.e. virtual intimacy a 3-dimensional concept including honesty and genuineness positivity and mutual comprehension. Virtual intimacy may be a way to reinforce the social dimension of human-agent interactions and to provide a better user experience. We therefore propose an interactive experiment that incorporates natural interactions between real tourists and an autonomously intimate virtual counselor who is an expert in tourism and able to express intimacy-related behaviors in verbal and nonverbal communication. The paper studies the impact of the agent?s expression of intimacy-related behaviors on the perception of virtual intimacy social presence and the user experience. The results show that users adopt a social attitude toward the intimate counselor and although they do not significantly perceive virtual intimacy they clearly perceive the dimension of honesty and genuineness. Moreover the agent?s expression of intimacy only enhances copresence the first perceptive level of social presence. Except for user social status which is enhanced the user experience is also not significantly influenced by intimate expression. The study results further demonstrate that perceiving virtual intimacy is a good predictor of social presence and user experience especially user emotional reactions. Perceiving virtual intimacy influences user experience independently of social presence which thereby indicates that independent intimacy-related mechanisms such as emotional contagion may be involved. Mediation analyses also underline that perceiving virtual intimacy has a direct effect on user emotional reactions but this finding is not supported by the CUE model. The findings in this study provide new evidence that perceiving virtual intimacy in humanagent interaction elicits emotions in users and enhances user experience. In line with this we propose an outline for an ECA-adapted user experience model based on the CUE model.;2021
Professionals within the field of language learning have predicted that chatbots would provide new opportunities for the teaching and learning of language. Despite the assumed benefits of utilizing chatbots in language classrooms such as providing interactional chances or helping to create an anxiety-free atmosphere little is known about learners' actual use of chatbots during language classes or how chatbots affect their motivation to learn a language. To address these gaps this exploratory study aimed to create an inventory of affordances that chatbots provide in the primary English as a foreign language (EFL) classroom and to explore how the affordances affect psychological aspects in language learners particularly regarding their motivation to learn English through chatbots. Thirty-six Korean primary school learners participated in a 16-week EFL course that utilized customized chatbots. These chatbots were created using Google's Dialogflow. After the course individual in-depth interviews were conducted regarding the participants' experiences and perceptions of the chatbots. Student-chatbot interaction logs produced during the course were also collected to supplement the interview data. Qualitative analysis of the interview transcripts and interaction logs revealed the presence of pedagogical technological and social affordances. Depending on the learner the chatbot affordances were perceived differently thus each affordance acted as either an opportunity or a constraint for English language learning. In addition this study specifically discussed how these chatbot affordances might have affected psychological states in language learners. Future recommendations regarding the use of chatbots in language classrooms were suggested from both pedagogical and technological perspectives.;2021
Proper response selection is a crucial challenge in retrieval-based chatbots. The state-of-the-art methods match a response with the word sequence of a context or match the response with each utterance in the context and then accumulate matching information. The former architecture could lose some important local matching information in utterance-response pairs and does not explicitly capture the relationships and dependencies among utterances. The latter architecture does not consider the important global matching information because there is no match between the response and the context at word level. Hence the above methods have a problem without considering the fact that matching a response with different levels of a context could match different information for multi-turn response selection. In this work we propose a hierarchical matching network to match a response with the word and utterance level of a context. At word level we concatenate the multi-turn context as a long word sequence and then adopt a text matching model to match the response with the word sequence which can capture important matching information at word level. At utterance level we employ the identical text matching model to match the response with each utterance in the context to capture important matching information for each utterance-response pair and then accumulate the matching information by a recurrent neural network to model the relationships of utterances. At last the hierarchical matching information is fused to get the final matching information. Experiments on two large-scale public multi-turn response selection datasets show that the proposed model significantly outperforms the state-of-the-art baseline models.;2021
Psycholinguistic research can inform the design of dialogue systems for fault diagnosis. When users provide ambiguous symptom descriptions dialogue systems can reformulate these descriptions to check the correctness of their interpretation. The present study investigated whether such reformulations should be performed by users or dialogue systems and how they should be phrased. In a Wizard-of-Oz study subjects described faults symptoms to a chatbot which subsequently asked for clarification. Experiment 1 compared the effects of requests for subjects to self-correct their descriptions and reformulations provided by the dialogue system in either common or technical terms. Experiment 2 combined reformulations in common and technical terms with each other and with pictures of fault symptoms. The results revealed that requests for self-correction increased solution times and verbal effort that common terms decreased solution times but led to errors when seemingly easy reformulations were incorrect and that technical terms did not mislead subjects into accepting them uncritically. Enrichments with pictures reduced the risk of accepting incorrect reformulations and were considered particularly helpful when combined with common terms. Lexical alignment with dialogue system reformulations was low but subjects adopted its technical terms most readily when no common terms were provided. Taken together the results suggest that combining reformulations in everyday language with visual information is most suitable to support grounding.;2021
Public Significance Statement Interacting a few minutes with a chatbot answering the most common questions about COVID-19 vaccines increased people's intention to get vaccinated and had a positive impact on their attitudes toward the vaccines. Chatbots could be a powerful resource to fight COVID-19 vaccines hesitancy. The Coronavirus disease COVID-19 vaccines will not end the pandemic if they stay in freezers. In many countries such as France COVID-19 vaccines hesitancy is high. It is crucial that governments make it as easy as possible for people who want to be vaccinated to do so but also that they devise communication strategies to address the concerns of vaccine hesitant individuals. We introduce and test on 701 French participants a novel messaging strategy: A chatbot that answers people's questions about COVID-19 vaccines. We find that interacting with this chatbot for a few minutes significantly increases people's intentions to get vaccinated (ss = 0.12) and has a positive impact on their attitudes toward COVID-19 vaccination (ss = 0.23). Our results suggest that a properly scripted and regularly updated chatbot could offer a powerful resource to help fight hesitancy toward COVID-19 vaccines.;2021
Purpose - This study aims to investigates customer satisfaction from the use of bank chatbots and the effect of perceived trust in chatbots and banks' reputation on customer satisfaction. Design/methodology/approach - A survey is conducted in Turkey involving 240 customers who experienced banking transactions using a chatbot. Partial least squares structural equation modeling (PLS-SEM) is used to investigate the relationships between the variables. The data were analyzed using SPSS 21 and SmartPLS programs. Findings - Perceived performance perceived trust and corporate reputation significantly affect customer satisfaction with chatbot use. Customer expectations and confirmation of customer expectations have no direct impact on customer satisfaction but customer expectations positively affect perceived performance. Customer expectations exert an indirect influence on customer satisfaction through perceived performance. Perceived performance has a positive impact on the confirmation of customer expectations but customer expectations do not significantly impact the confirmation of customer expectations. Research limitations/implications - This study relies on a limited number of participants. Moreover its sample is not representative of the target population due to the convenience sampling technique. Even if the results may not be generalized to the entire population of Turkey they reflect the reality of emerging markets with relatively high technology sensitivity and a young population. Practical implications - The results provide new insights regarding banking service delivery channels which may be of interest to professionals academics banks' top management product development teams design teams and customer satisfaction units. Social implications - This study is believed to help the community make their lives easier by providing them with knowledge and awareness about chatbots. Originality/value- This study extends expectations confirmation theory's predictions to chatbot use in banking.;2021
Purpose Artificial intelligence (AI) customer service chatbots are a new application service and little is known about this type of service. This study applies service quality trust and satisfaction to predict users' continuance intention to use a food-ordering chatbot. Design/methodology/approach The proposed model and hypotheses are tested using online questionnaire responses to collect users' perceptions of such services. One hundred and eleven responses of actual users were received. Findings Empirical results show that anthropomorphism and service quality such as problem-solving are the antecedents of trust and satisfaction while satisfaction has the most significant direct effect on the users' intention. Originality/value The results provide further useful insights for service providers and chatbot developers to improve services.;2021
Purpose Brands are increasingly considering the use of chatbots to supplement or even replace humans in service interactions. Like humans chatbots can follow certain service scripts in their encounters which can subsequently determine the customer experience. Service scripts are verbal prescriptions that seek to standardize customer service interactions. However while the role of service scripts is well documented despite the increasing use of chatbots as a service mechanism less is known about the effect on consumers of different service scripts presented during chatbot service encounters. Design/methodology/approach An experimental scenario was developed to test the research hypotheses. Respondents were randomly allocated to scenarios representing a 2 (service interaction: human chatbot) x 2 (service script: education entertainment) design. A total of 262 US consumers constituted the final sample for the study. Findings The findings indicate that when employing an education script a significant positive effect occurs for human service agents (compared to chatbots) in terms of both satisfaction and purchase intention. These effects are fully mediated by emotion and rapport showing that the bonds developed through the close proximity to a human service agent elicit emotion and develop rapport which in turn influence service outcomes. However this result is present only when an educational script is used. Originality This paper contributes to the emerging service marketing literature on the use of digital services in particular chatbots in service interactions. We show that differences occur in key outcomes dependent on the type of service script employed (education or entertainment). For managers this study indicates that chatbot interactions can be tailored (in script delivered) in order to maximize emotion and rapport and subsequently consumer purchase intention and satisfaction.;2021
Purpose Chatbot users' communication experience with disembodied conversational agents was compared with instant messaging (IM) users' communication experience with human conversational agents. The purpose of this paper is to identify what affects users' intention to reuse and whether they perceive any difference between the two. Design/methodology/approach A conceptual model was developed based on computer-mediated communication (CMC) and interpersonal communication theories. Data were collected online from four different continents (North America Europe Asia and Australia). Partial least squares structural equation modeling was applied to examine the research model. Findings The findings mainly reveal that media richness and social presence positively influence trust and reuse intention through task attraction and social attraction IM users reported significantly higher scores in terms of communication experience perceived attractiveness of the conversational agent and trust than chatbot users users' trust in the conversational agents is mainly determined by perceived task attraction. Research limitations/implications Customers' evaluation of the communication environment is positively related to their perceived competence of the conversational agent which ultimately affect their intention to reuse chatbot/IM. The findings reveal determinants of chatbot/IM adoption which have rarely been mentioned by previous work. Practical implications Practitioners should note that consumers in general still prefer to interact with human conversational agents. Practitioners should contemplate how to combine chatbot and human resources effectively to deliver the best customer service. Originality/value This study goes beyond the Computer as Social Actor paradigm and Technology Acceptance Model to understand chatbot and IM adoption. It is among one of the first studies that compare chatbot and IM use experience in the tourism and hospitality literature.;2021
Purpose Drawing on the self-determination theory the assemblage theory and customer experience literature this paper aims to develop a framework to understand motivational customer experiences with chatbots. Design/methodology/approach This paper uses a multimethod approach to examine the interaction between individuals and airlines' chatbots. Three components of self-determined interaction with the chatbot (competence autonomy and relatedness) and five components of the customer-chatbot experience (sensory intellectual affective behavioral and social) are analyzed qualitatively and quantitatively. Findings The findings confirm the direct influence of self-determined interaction on customer experience and the direct effects of these two constructs on participants' attitudes toward and satisfaction with the chatbot. The model also supports the mediating roles of customer experience and attitude toward the chatbot. Practical implications This paper offers managers a broad understanding of individuals' interactions with chatbots through three elements: motivation to use chatbots experiential responses and individuals' valuation of whether the interactions have amplified (or limited) the outcomes obtained from the experience. Originality/value This paper contributes to the hospitality and tourism literature with a hybrid approach that reflects on current theoretical developments regarding human- and interaction-centric interpretations of customer experience with chatbots.;2021
Purpose During the coronavirus disease 2019 pandemic face-to-face teaching has been severely disrupted and limited for medical students internationally. This study explores the views of medical students and academic medical staff regarding the suitability and limitations of a bespoke chatbot tool to support medical education. Methods Five focus groups with a total of 16 participants were recruited using a convenience sample. The participants included medical students across all year groups and academic staff. The pre-determined focus group topic guide explored how chatbots can augment existing teaching practices. A thematic analysis was conducted using the transcripts to determine key themes. Results Thematic analysis identified five main themes: (1) chatbot use as a clinical simulation tool (2) chatbot use as a revision tool (3) differential usefulness by medical school year group (4) standardisation of education and assessment (5) challenges of use and implementation. Conclusions Both staff and students have clear benefits from using chatbots in medical education. However they documented possible limitations to their use. The creation of chatbots to support the medical curriculum should be further explored and urgently evaluated to assess their impact on medical students training both during and after the global pandemic.;2021
Purpose Existing virtual agents (VAs) present in dialogue systems are either information retrieval based or static goal-driven. However in real-world situations end-users might not have a known and fixed goal beforehand for the task i.e. they may upgrade/downgrade/update their goal components in real-time to maximize their utility values. Existing VAs are unable to handle such dynamic goal-oriented situations. Methodology Due to the absence of any related dialogue dataset where such choice deviations are present we have created a conversational dataset called Deviation adapted Virtual Agent(DevVA) with the manual annotation of its corresponding intents slots and sentiment labels. A Dynamic Goal Driven Dialogue Agent (DGDVA) has been developed by incorporating a Dynamic Goal Driven Module (GDM) on top of a deep reinforcement learning based dialogue manager. In the course of a conversation the user sentiment provides grounded feedback about agent behavior including goal serving action. User sentiment appears to be an appropriate indicator for goal discrepancy that guides the agent to complete the user's desired task with gratification. The negative sentiment expressed by the user about an aspect of the provided choice is treated as a discrepancy that is being resolved by the GDM depending upon the observed discrepancy and current dialogue state. The goal update capability and the VA's interactiveness trait enable end-users to accomplish their desired task satisfactorily. Findings The obtained experimental results illustrate that DGDVA can handle dynamic goals with maximum user satisfaction and a significantly higher success rate. The interaction drives the user to decide its final goal through the latent specification of possible choices and information retrieved and provided by the dialogue agent. Through the experimental results (qualitative and quantitative) we firmly conclude that the proposed sentiment-aware VA adapts users' dynamic behavior for its goal setting with substantial efficacy in terms of primary objective i.e. task success rate (0.88). Practical implications In real world it can be argued that many people do not have a predefined and fixed goal for tasks such as online shopping movie booking & restaurant booking etc. They tend to explore the available options first which are aligned with their minimum requirements and then decide one amongst them. The DGDVA provides maximum user satisfaction as it enables them to accomplish a dynamic goal that leads to additional utilities along with the essential ones. Originality To the best of our knowledge this is the first effort towards the development of A Dynamic Goal Adapted Task-Oriented Dialogue Agent that can serve user goals dynamically until the user is satisfied.;2021
Purpose Given that managers play a crucial role in developing and deploying AI for marketing financial services this study was aimed at better understanding their awareness regarding AI and the challenges they are facing in providing the attendant technologies as well as highlighting key stakeholders and their collaborative efforts in providing financial services. Design/methodology/approach Exploratory inductive research design. The data was gathered through semi-structured interviews with 47 bank managers in both developed and developing countries including the United Kingdom Canada Nigeria and Vietnam. Findings Managers are aware of the prospects of AI and are making efforts to address AI as a business need but find that there often exist certain challenges in accelerating AI adoption. The study also presents a conceptual framework of AI in relation to financial service marketing which captures and highlights the interactions among the customers banks and external stakeholders as well as the regulators. Research limitations/implications Banks must understand their business objectives the available resources and the needs of their customers. Managers should keep the ethical implications of their working relationships in mind when selecting a team or collaborating with partners. In addition managers should be trained and assisted in comprehending AI in relation to financial services while the regulators must be involved in the development of AI for financial service marketing. Finally it is critical to communicate the prospects for AI to consumers. Originality/value This study provides empirical insight into the opportunities prospects and challenges pertaining to the use of AI in the area of financial service marketing. It also specifically calls into question certain preconceptions regarding AI and its role in financial services the chatbots adopted for financial service delivery and the role of marketing managers in developing AI.;2021
Purpose of Review The training of psychiatrists and other mental health professionals requires education on a range of interpersonal communication and psychotherapy techniques. Classroom and workshop training must be augmented by experiential learning with feedback for skill implementation with fidelity. Virtual standardized patients (VSPs) are computerized conversational agents that can support experiential learning through standardized consequence-free training environments at reduced costs. Recent Findings Research on mental health VSPs is rife with feasibility and acceptability pilot studies across various training populations and settings. Users have generally reported positive reactions to training with VSPs though frustrations with some VSP speech recognition or VSP response relevance has been reported. Several studies have demonstrated a promising transfer of clinical skills from VSP training to human standardized patients and randomized trials supporting improved skill relative to reading or academic study are encouraging. As technology improves and natural language processing and accurate computer response generation for broad ranging conversational topics emerges the field would benefit from research on the characteristics of effective VSPs for a range of purposes and trainee populations. Well-designed randomized evaluations of VSPs relative to best practices in education are needed particularly regarding the impact of VSPs on clinical practice among actual patients.;2021
Purpose People with visual impairment comprise the second high disability population in Hong Kong but only two existing information centers provide information services for visually impaired people which is inadequate. Therefore this study aims to provide a more in-depth understanding of the information services for visually impaired people in Hong Kong. Design/methodology/approach People with visual impairment comprise the second high disability population in Hong Kong but only two existing information centers provide information services for visually impaired people which is inadequate. Therefore this study aims to provide a more in-depth understanding of the information services for visually impaired people in Hong Kong. Findings IAC's main problems include limited collection inconsistent multiple digital platforms for user access limited service hours and limited promotion. Some technological suggestions were proposed which include: expanding its electronic and special collections establishing a one-stop digital platform AI-based chatbot for automated caring chats and reference services and extending its social network marketing. Originality/value Scant studies focus on the information services and management of special libraries for visually impaired people especially in East Asia. On the other hand there are limited case studies analyzing libraries with value-chain analysis.;2021
Purpose The purpose of this study is to describe the development and psychometric properties of a novel game- and video-based assessment of social attributes. Despite their increasing adaption little research is available on the suitability of games and video analytics for measuring noncognitive attributes in the selection context. Design/methodology/approach The authors describe three novel assessments and their psychometric properties in a sample of 1300 participants: a game-based adaptation of an Emotion Recognition Task a chatbot-based situational judgment test for emotion management and a video-based conscientiousness assessment. Findings The novel assessments show good to moderate convergent validity for Emotional Recognition (r = 0.42) Emotion Management (r = 0.39) and Conscientiousness (r = 0.21). The video-based assessment demonstrates preliminary predictive validity for self-reported work performance. Novel game-based assessments (GBAs) are perceived as better designed and more immersive than traditional questionnaires. Adverse impact analysis indicates small group differences by age gender and ethnicity. Research limitations/implications Predictive validity findings need to be replicated using objective measures of performance such as performance ratings by supervisors and extended to the GBAs. Adverse impact should be evaluated using a real-life applicant pool and extended to additional groups. Practical implications Evidence for the psychometric validity of novel assessment formats supports their adoption in selection and recruitment. Improved user experience and shortened assessment times open up new areas of application. Originality/value This study gives first insights into psychometric properties of video- and game-based assessments of social attributes.;2021
Purpose The purpose of this study is to examine the role of consumption emotion in the digital food-ordering experience by comparing the performances of the three digital ordering methods in an experimental design. Design/methodology/approach A research model was developed based on the Feelings-as-Information (FaI) theory and the expectancy-disconfirmation theory. A 3 x 2 between-subjects lab experiment was conducted to compare the three digital ordering methods (online mobile or chatbot) in two different types of restaurants (quick-service or full-service). Findings The results indicate that the chatbot ordering method evoked more negative emotions and less positive emotions than the other two methods. The online ordering method worked the best for quick-service restaurants whereas the mobile ordering method was most suitable for full-service restaurants. Both positive and negative emotions (comfort and annoyance) significantly mediated the relationships between the ordering method and internal responses (satisfaction and behavioral intention). Only one negative emotion (anger) significantly mediated the relationship between the ordering method and order amount. Originality/value This is the first study that attempts to explore and compare consumers' emotional responses resulting from restaurant digital ordering experiences in the context of the three food-ordering methods. The use of the FaI theory strengthens the theoretical foundation of research on emotion in the hospitality field. This study also pioneers the application of chatbot technology in the restaurant industry.;2021
Purpose The rapid evolution in artificial intelligence (AI) has redefined the customer experience and created huge opportunities for companies to interact with customers using chatbots. This study explores the role of AI chatbots in influencing the online customer experience and customer satisfaction in e-retailing. Design/methodology/approach A research model based on the technology acceptance model and information system success model is proposed to describe the interrelationships among chatbot adoption online customer experience and customer satisfaction. Personality is a moderator in the model. The authors used a quantitative approach to collect 425 useable online questionnaires and Statistical Product and Service Solutions (SPSS) and SmartPLS to analyze the measurement model and proposed hypotheses. Findings The usability of the chatbot had a positive influence on extrinsic values of customer experience whereas the responsiveness of the chatbot had a positive impact on intrinsic values of customer experience. Furthermore online customer experience had a positive relationship with customer satisfaction and personality influenced the relationship between the usability of the chatbot and extrinsic values of customer experience. Originality/value This research extends understanding of the online customer experience with chatbots in e-retailing and provides empirical evidence by showing that extrinsic and intrinsic values of online customer experience are enhanced by chatbot adoption.;2021
Purpose This study defines a three-angled research plan to intensify the knowledge and development undergoing in the retail sector. It proposes a theoretical framework of the customer journey to explain the customers' intent to adopt artificial intelligence (AI) and machine learning (ML) as a protective measure for interaction between the customer and the brand. Design/methodology/approach This study presents a research agenda from three-dimensional online search ML and AI algorithms. This paper enhances the readers' understanding by reviewing the literature present in utilizing AI in the customer journey and presenting a theoretical framework. Findings Using AI tools like Chatbots Recommenders Virtual Assistance and Interactive Voice Recognition (IVR) helps create improved brand awareness better customer relationships marketing and personalized product modification. Originality/value This study intends to identify a research plan based on investigating customer journey trends in today's changing times with AI incorporation. The research provides a novel model framework of the customer journey by directing customers into different stages and providing different touchpoints in each stage all supported with AI and ML.;2021
Purpose This study investigates the determinants of effective human and artificial intelligence (AI) relationship-building strategies for brands. It explores the antecedents and consequences of consumers' interactant satisfaction with communication and identifies ways to enhance consumer purchase intention via AI chatbot promotion. Design/methodology/approach Microsoft Xiaoice served as the focal AI chatbot and 331 valid samples were obtained. A two-stage structural equation modeling-artificial neural network approach was adopted to verify the proposed theoretical model. Findings Regarding the IQ (intelligence quotient) and EQ (emotional quotient) of AI chatbots the multi-dimensional social support model helps explain consumers' interactant satisfaction with communication which facilitates affective attachment and purchase intention. The results also show that chatbots should emphasize emotional and esteem social support more than informational support. Practical implications Brands should focus more on AI chatbots' emotional and empathetic responses than functional aspects when designing dialogue content for human-AI interactions. Well-designed AI chatbots can help marketers develop effective brand promotion strategies. Originality/value This research enriches the human-AI interaction literature by adopting a multi-dimensional social support theoretical lens that can enhance the interactant satisfaction with communication affective attachment and purchase intention of AI chatbot users.;2021
Purpose This study presents one of the earliest empirical investigations on how brand chatbots' anthropomorphic design and social presence communication strategies may improve consumer evaluation outcomes via the mediators of parasocial interaction and perceived dialogue. Design/methodology/approach This study employs a 2 (high vs. low social presence communication) by 2 (anthropomorphic vs. non-anthropomorphic bot profile) between-subject experimental design to evaluate how chatbots' high social presence communication and anthropomorphic profile design may enhance perceptions of parasocial interactions and dialogue with the chatbot which in turn drive user engagement interaction satisfaction and attitude toward the represented brand. Findings The influences of chatbots' high social presence communication on consumer engagement outcomes are mediated by perceived parasocial interaction and dialogue. Additionally chatbots' anthropomorphic profile design can boost the positive effects of social presence communication via the psychological mediators. Originality/value This study advances the interactive marketing literature by focusing on an emerging interactive technology chatbots. Additionally distinct from prior chatbot studies that focused on the utilitarian use of chatbots for online customer support this study not only examines which factors of chatbot communication and profile design may drive chatbot effectiveness but also examines the mechanism underlying the messaging and design effects on consumer engagement. The findings highlight the mediating role of interpersonal factors of parasocial interaction and perceived dialogue.;2021
Purpose To provide better services to customers especially immediate responses and 24/7 availability businesses are implementing text-based automated conversational agents i.e. chatbots on their social platforms and websites. Chatbots are required to not only provide customers with necessary consultancy and guidance but also communicate friendly and socially. Based on the cognitive fit theory this study attempts to examine the role of chatbot as a decision aid and how the match between information presentation in forms of decisional guidance and communication style and the shopping task influences consumers' perceived cognitive fit and decision performance outcomes. Design/methodology/approach A 2 x 2 x 2 between subject online experiment was conducted to identify which kind of decisional guidance (suggestive and informative guidance) and communication style (task-oriented vs social-oriented style) are the most appropriate for each type of shopping task (searching vs browsing task). Findings The findings show that when customers interact with chatbots they will perceive higher cognitive fit if the chatbots provide them with suggestive guidance and communicate in a friendly style especially when they perform a searching task. Originality/value This study is the first attempt to understand the role of chatbots as a decision aid to customers using the communicative language. This study also tries to explore the cognitive fit theory in a novel way and we propose the information presentation in forms of communicative language rather than matrices tables and graphs.;2021
Purpose: Chatbots have been widely adopted to create more positive customer experiences as customers now spend more time in digital environments. Despite the technological advancement and benefits of chatbots for customer service research on chatbot applications for Small and medium-sized enterprises (SMEs) is limited. The absence of research explaining the struggles faced by SMEs contributes to the gap of SMEs' chatbot adoption. This research determines the features and elements that fit with SMEs' characteristics and their customers with chatbots. Design/methodology/approach: A mixed-methods approach is used to understand SMEs' needs. Study 1 uses interviews with SME business owners and its customers it aims to explore the features that should be provided by chatbots for SME by identifying combinations between chatbots' generic features and SMEs' customer characteristics. Study 2 tests features identified in Study 1 and surveys 315 SMEs customers to empirically test featured chatbots' influence to anthropomorphism perceived enjoyment perceived ease of use perceived usefulness and how they affect SMEs' customer intentions to use chatbots and their shopping intentions. Findings -: The findings suggest four combinations of chatbot features that match SME customer characteristics: responsive simple steps to trigger customer actions humanized conversations and personalized recommendations. An experimental survey was designed by creating a chatbot prototype based on these features. The results show that the featured chatbot prototype affects higher anthropomorphism perceived enjoyment and perceived usefulness compared to the standard chatbot. We also find that perceived enjoyment and usefulness positively affect customer's intention to shop and intention to use the chatbot. While anthropomorphism only affect customer's shopping intention to SMEs. Originality: This paper contributes to the emerging service literature on the use of chatbots service interactions particularly for SMEs. This research provides robust explorations from the perspective of both SME owners and customers. For practice the research provides guidelines on how to design a chatbot for SMEs that meet customers' needs.;2021
Purpose: To evaluate the usability of chatbot design and how chatbots and search compare for information delivery and usability we ran two test cases. In the first we focused only on chatbot usability information delivery and design. In the second we compared chatbot responses to those provided by search engines to identify areas of similarities and differences in terms of accuracy functionality and usability. Method: Test Case 1 uses an exploratory method to analyze chatbot functionality. Test Case 2 uses content analysis of search responses and corresponding chatbot responses. Data from two major telecommunication companies' websites-Sprint and Verizon-was used for both. Results: In Test Case 1 we found that chatbots are generally more flexible and helpful when they provide information directly in the chat pane and allow free-form text entry in addition to several other related characteristics. This was critical to receiving the information we needed efficiently and accurately. Results of Test Case 2 show that chatbots provide less information than search results have longer wait times and rely less on algorithms to get responses and more on constant updating. Conclusion: Based on Test Case 1 we developed a heuristic that addresses usability information design and accessibility. In Test Case 2 we determined that search functionality is better than that of chatbots in terms of 1) speed of response 2) accuracy of responses 3) multiple formats for content delivery and 4) ease of use and accessibility.;2021
Query-based document summarization aims to extract or generate a summary of a document which directly answers or is relevant to the search query. It is an important technique that can be beneficial to a variety of applications such as search engines document-level machine reading comprehension and chatbots. Currently datasets designed for query-based summarization are short in numbers and existing datasets are also limited in both scale and quality. Moreover to the best of our knowledge there is no publicly available dataset for Chinese query-based document summarization. In this paper we present QBSUM a high-quality large-scale dataset consisting of 49000+ data samples for the task of Chinese query-based document summarization. We also propose multiple unsupervised and supervised solutions to the task and demonstrate their high-speed inference and superior performance via both offline experiments and online A/B tests. The QBSUM dataset is released in order to facilitate future advancement of this research field. (C) 2020 Elsevier Ltd. All rights reserved.;2021
Question-answering chatbots have tremendous potential to complement humans in various fields. They are implemented using either rule-based or machine learning-based systems. Unlike the former machine learning-based chatbots are more scalable. Sequence-to-sequence (Seq2Seq) learning is one of the most popular approaches in machine learning-based chatbots and has shown remarkable progress since its introduction in 2014. However chatbots based on Seq2Seq learning show a weakness in that it tends to generate answers that can be generic and inconsistent with the questions thereby becoming meaningless and therefore may lower the chatbot adoption rate. This weakness can be attributed to three issues: question encoder overfit answer generation overfit and language model influence. Several recent methods utilize multitask learning (MTL) to address this weakness. However the existing MTL models show very little improvement over single-task learning wherein they still generate generic and inconsistent answers. This paper presents a novel approach to MTL for the Seq2Seq learning model called SEQ2SEQ++ which comprises a multifunctional encoder an answer decoder an answer encoder and a ternary classifier. Additionally SEQ2SEQ++ utilizes a dynamic tasks loss weight mechanism for MTL loss calculation and a novel attention mechanism called the comprehensive attention mechanism. Experiments on NarrativeQA and SQuAD datasets were conducted to gauge the performance of the proposed model in comparison with two recently proposed models. The experimental results show that SEQ2SEQ++ yields noteworthy improvements over the two models on bilingual evaluation understudy word error rate and Distinct-2 metrics.;2021
Recently chatbot research for conversation has been actively conducted in the field of natural language processing. Among the dialogue systems a retrieval-based system has emerged as an important one. Because it showed better performance than the response generation models and it actually seemed applicable. The response selection task is used to develop a retrieval-based system. Thus we did research to improve the performance of retrieval-based dialogue systems for response selection. We used Google's bidirectional encoder representations from transformers (BERT) natural-language processor with the robustly optimized BERT pre-training model (RoBERTa) as the base model to improve performance. The Recall@N of our model was improved by 1.7-4.2% using two methods: First instead of using a simple feed-forward network at the end of the model we employed a randomly wired neural network that contained multiple wiring paths thus achieving better performance than that of feed-forward networks. The experimental results of this study demonstrated that feed-forward networks can be replaced by randomly wired neural networks. Second we calculated the correlation between dialog history (i.e. context) and the last utterance of the context reflecting this correlation as an attention network that yielded an answer prediction. Using first and second method achieved higher performance than using only the first method in dialog response selection tasks.;2021
Recently many efforts have been devoted to generating responses expressing a specific emotion or relating to a given topic in a controlled manner. However limited attention has been given to generating responses with a specified syntactic pattern which makes it possible to imitate someone's way of speaking in dialogue. To fulfill this goal we propose two models to generate syntax-aware responses: a gross-constraint and a specific-constraint model. The former controls the syntactic patterns of generated responses at sentence-level while the latter works at smaller language units such as words or phrases being capable of manipulating the syntactic structures of responses in a more subtle manner. The extensive experimental results on two different datasets show that both the two models not only can generate meaningful responses with a specific and coherent structure but also improve on the diversity of generated responses with similar gains in readability relevance and diversity as measured by human judges.;2021
Recently similar entity searching over knowledge graph (KG) has gained much attentions by researchers. However in rich-semantic KGs with multi-typed entities and relations also known as heterogeneous information network relevant entity search is considered as a challenging task due to the ambiguity as well as complexity of user's queries in realistic applications such as QA chatbot and KG-based information retrieval. In this paper we propose a novel approach called W-KG2Vec which enables to automatically learn the semantic representations of entities in KG by applying the meta-path. The proposed W-KG2Vec is a meta-path-specific model which supports to evaluate both semantic relations as well as the text-based similarity between entities. The combination of text- and structure-based embedding mechanism of W-KG2Vec is promising to achieve better representations of entities in given KGs for handling complex user's queries. To effectively learn the sequential textual representations of entities' descriptions we propose a combination of BERT pre-trained model with LTSM encoder called BERT-Text2Vec. Then the text-based similarity between entities is used to leverage our weighted meta-path-based random walk mechanism in W-KG2Vec model. Extensive experiences on real-world KGs (YAGO and Freebase) demonstrate the effectiveness of our proposed model against recent state-of-the-art KG embedding baselines.;2021
Recommender systems are software applications that help users to find items of interest in situations of information overload. Current research often assumes a one-shot interaction paradigm where the users' preferences are estimated based on past observed behavior and where the presentation of a ranked list of suggestions is themain one-directional form of user interaction. Conversational recommender systems (CRS) take a different approach and support a richer set of interactions. These interactions can for example help to improve the preference elicitation process or allow the user to ask questions about the recommendations and to give feedback. The interest in CRS has significantly increased in the past few years. This development is mainly due to the significant progress in the area of natural language processing the emergence of new voice-controlled home assistants and the increased use of chatbot technology. With this article we provide a detailed survey of existing approaches to conversational recommendation. We categorize these approaches in various dimensions e.g. in terms of the supported user intents or the knowledge they use in the background. Moreover we discuss technological approaches review how CRS are evaluated and finally identify a number of gaps that deserve more research in the future.;2021
Relation extraction has been an active research interest in the field of Natural Language Processing (NLP). The past works primarily focused on a corpus of formal text which is inherently non-dialogic. Recently the dialogue-based relation extraction task which detects relations among speaker-aware entities scattering in dialogues has been gradually arousing people's attention. Some sequence-based neural methods have been carried out to obtain the relevant information. However identifying cross-sentence relations remains unsolved especially in the context of a specific-domain dialogue system. In this paper we propose a Relational Attention Enhanced Graph Convolutional Network (RAEGCN) which constructs the whole dialogue as a semantic interactive graph by emphasizing the speaker-related information and leveraging various inter-sentence dependencies. A dense connectivity mechanism is also introduced to empower the multi-hop relational reasoning across sentences which can capture both local and non local features simultaneously. Experiments show the significant superiority and robustness of our model on a real-world dataset DialogRE as compared with previous approaches. (c) 2021 Published by Elsevier B.V.;2021
Reminiscence therapy is a non-pharmacological intervention that helps mitigate unstable psychological and emotional states in patients with Alzheimer's disease where past experiences are evoked through conversations between the patients and their caregivers stimulating autobiographical episodic memory. It is highly recommended that people with Alzheimer regularly receive this type of therapy. In this paper we describe the development of a conversational system that can be used as a tool to provide reminiscence therapy to people with Alzheimer's disease. The system has the ability to personalize the therapy according to the patients information related to their preferences life history and lifestyle. An evaluation conducted with eleven people related to patient care (caregiver = 9 geriatric doctor = 1 care center assistant = 1) shows that the system is capable of carrying out a reminiscence therapy according to the patient information in a successful manner.;2021
Retailers are increasingly using conversational AI (chatbots) for customer service due to the perceived benefits and reduced operational costs of this emerging technology. Yet our understanding of how consumers perceive interactions with chatbots and how these interactions may influence other consumer service programs remains limited. This paper investigates the differences in consumers' sentiments towards chatbots across retail sectors and the influence chatbots have on consumers' sentiments and expectations towards other service interactions with online human agents. Using a hybrid automated sentiment analysis approach we identify that (1) overall sentiment towards bots are less negative than sentiment towards online human agents (2) these sentiments differ across fashion and telecommunications sectors and finally (3) sentiments towards online human agents in both sectors become more negative after a retailer implements a chatbot.;2021
Scientists in disciplines such as neuroscience and bioinformatics are increasingly relying on science gateways for experimentation on voluminous data as well as analysis and visualization in multiple perspectives. Though current science gateways provide easy access to computing resources data sets and tools specific to the disciplines scientists often use slow and tedious manual efforts to perform knowledge discovery to accomplish their research/education tasks. Recommender systems can provide expert guidance and can help them to navigate and discover relevant publications tools data sets or even automate cloud resource configurations suitable for a given scientific task. To realize the potential of integration of recommenders in science gateways in order to spur research productivity we present a novel OnTimeRecommend recommender system. The OnTimeRecommend comprises of several integrated recommender modules implemented as microservices that can be augmented to a science gateway in the form of a recommender-as-a-service. The guidance for use of the recommender modules in a science gateway is aided by a chatbot plug-in viz. Vidura Advisor. To validate our OnTimeRecommend we integrate and show benefits for both novice and expert users in domain-specific knowledge discovery within two exemplar science gateways one in neuroscience (CyNeuro) and the other in bioinformatics (KBCommons).;2021
Self-service technology (SST) benefits e-commerce firms by increasing operational efficiency and reducing labor costs while it also challenges firms in that service resources could be misused and service failure could be difficult to recover. Prior studies investigate either the bright (value co-creation) or the dark (value codestruction) side of SST in ?isolation? while this study examines SST with both perspectives in one integrated model. Using emerging Service-Dominant Logic (SDL) as a framework and augmenting it with attribution theory from the psychology area we better depict the nature of value-co-creation and value co-destruction that emerge in the SST usage process from a customer?s perspective. Specifically we consider six different SST use contexts composed of three types of resource misuse and two kinds of SST service failure to illuminate in what contexts SST customers choose to co-create or co-destruct value with SST firms. Using a survey with 413 respondents and a mixed-methods approach (quantitative and qualitative) our results show that customers are more likely to continuously co-create value with firms when they think resources are misused by themselves when experiencing process failure and when using an in-process co-creation strategy. In contrast customers tend to continuously co-destruct value when they think resources are misused by firms when experiencing an outcomefailure context and when using an in-process co-destruction strategy. Our proposed framework enables ecommerce firms to immediately trigger essential service recovery whenever service co-destruction occurs. We also discuss how firms can utilize the latest technology such as artificial intelligence (AI) behavioral big data and Chatbot to promptly co-create values hence contributing to future SST and e-commerce design.;2021
Sexual violence is a severe and chronic occurrence around the world that has not been resolved. The stigmatized nature of sexual violence has forced victims and survivors to accept prejudiced accusations cultivated from discriminatory norms when they are never at fault nor responsible for such violations against their sexuality. LAW-U is an Artificial Intelligence (AI) chatbot that gives legal guidance to survivors of sexual violence by recommending the most relevant Supreme Court decisions to the survivors' situations. In Thai LAW-U'' - pronounced similarly to (sic)'' - means I will wait for you'' which signifies the chatbot's unconditional support to the user. 182 Thai Supreme Court cases of sexual violence relating to Sections 276 277 278 and 279 of the Criminal Code were used to develop Natural Language Processing (NLP) pipelines for LAW-U. Legal experts then generated mock-up dialogs from Supreme Court decisions which became the conversations used to train LAW-U. The computation of the similarity scores and the calculation of percentages of common keywords and keywords' synonyms were completed to increase the model's accuracy. When applying the model to the hold-out testing dataset the accuracy was 88.89% for an exact match between the user's input and the Supreme Court case - this confirmed that LAW-U was ready for real-life application. LAW-U's unique design hopes to act as a precedent for other works at home and abroad to perpetuate awareness of sexual violence and eliminate any tolerance against these crimes by empowering sexual violence victims and survivors to reaffirm their inherent rights.;2021
Simulated consultations through virtual patients allow medical students to practice history-taking skills. Ideally applications should provide interactions in natural language and be multi-case multi-specialty. Nevertheless few systems handle or are tested on a large variety of cases. We present a virtual patient dialogue system in which a medical trainer types new cases and these are processed without human intervention. To develop it we designed a patient record model a knowledge model for the history-taking task and a termino-ontological model for term variation and out-of-vocabulary words. We evaluated whether this system provided quality dialogue across medical specialities (n = 18) and with unseen cases (n = 29) compared to the cases used for development (n = 6). Medical evaluators (students residents practitioners and researchers) conducted simulated history-taking with the system and assessed its performance through Likert-scale questionnaires. We analysed interaction logs and evaluated system correctness. The mean user evaluation score for the 29 unseen cases was 4.06 out of 5 (very good). The evaluation of correctness determined that on average 74.3% (sd = 9.5) of replies were correct 14.9% (sd = 6.3) incorrect and in 10.7% the system behaved cautiously by deferring a reply. In the user evaluation all aspects scored higher in the 29 unseen cases than in the 6 seen cases. Although such a multi-case system has its limits the evaluation showed that creating it is feasible that it performs adequately and that it is judged usable. We discuss some lessons learned and pivotal design choices affecting its performance and the end-users who are primarily medical students.;2021
Since the emergence of deep learning-based chatbots for knowledge services numerous research and development projects have been conducted in various industries. A high demand for chatbots has drastically increased the global market size however the limited functional scalability of open-domain chatbots is a challenge to their application to industries. Moreover as most chatbot frameworks employ English it is necessary to create chatbots customized for other languages. To address this problem this paper proposes KoRASA as a pipeline-optimization method which uses a deep learning-based open-source chatbot framework to understand the Korean language. KoRASA is a closed-domain chatbot that is applicable across a wide range of industries in Korea. KoRASA's operation consists of four stages: tokenization featurization intent classification and entity extraction. The accuracy and F1-score of KoRASA were measured based on datasets taken from common tasks carried out in most industrial fields. The algorithm for intent classification and entity extraction was optimized. The accuracy and F1-score were 98.2% and 98.4% for intent classification and 97.4% and 94.7% for entity extraction respectively. Furthermore these results are better than those achieved by existing models. Accordingly KoRASA can be applied to various industries including mobile services based on closed-domain chatbots using Korean robotic process automation (RPA) edge computing and Internet of Energy (IoE) services.;2021
Slot filling is a crucial component in task-oriented dialog systems that is used to parse (user) utterances into semantic concepts called slots. An ontology is defined by the collection of slots and the values that each slot can take. The most widely used practice of treating slot filling as a sequence labeling task suffers from two main drawbacks. First the ontology is usually pre-defined and fixed and therefore is not able to detect new labels for unseen slots. Second the one-hot encoding of slot labels ignores the correlations between slots with similar semantics which makes it difficult to share knowledge learned across different domains. To address these problems we propose a new model called elastic conditional random field (eCRF) where each slot is represented by the embedding of its natural language description and modeled by a CRF layer. New slot values can be detected by eCRF whenever a language description is available for the slot. In our experiment we show that eCRFs outperform existing models in both in-domain and cross-domain tasks especially in predicting unseen slots and values.;2021
Smart home assistants which enable users to control home appliances and can be used for holding entertaining conversations have become an inseparable part of many people's homes. Recently there have been many attempts to allow end-users to teach a home assistant new commands responses and rules which can then be shared with a larger community. However allowing end-users to teach an agent new responses which are shared with a large community opens the gate to malicious users who can teach the agent inappropriate responses in order to promote their own business products or political views. In this paper we present a platform that enables users to collaboratively teach a smart home assistant (or chatbot) responses using natural language. We present a method of collectively detecting malicious users and using the commands taught by the malicious users to further mitigate activity of future malicious users. We ran an experiment with 192 subjects and show the effectiveness of our platform.;2021
Social connectedness is vital for developing group cohesion and strengthening belongingness. However with the accelerating pace of modern life people have fewer opportunities to participate in group-building activities. Furthermore owing to the teleworking and quarantine requirements necessitated by the Covid-19 pandemic the social connectedness of group members may become weak. To address this issue in this study we used an android robot to conduct daily conversations and as an intermediary to increase intra-group connectedness. Specifically we constructed an android robot system for collecting and sharing recent member-related experiences. The system has a chatbot function based on BERT and a memory function with a neural-network-based dialog action analysismodel. We conducted a 3-day human-robot conversation experiment to verify the effectiveness of the proposed system. The results of a questionnaire-based evaluation and empirical analysis demonstrate that the proposed system can increase the familiarity and closeness of group members. This suggests that the proposed method is useful for enhancing social connectedness. Moreover it can improve the closeness of the user-robot relation as well as the performance of robots in conducting conversations with people.;2021
Social networks have become a major platform for people to disseminate information which can include negative rumors. In recent years rumors on social networks has caused grave problems and considerable damages. We attempted to create a method to verify information from numerous social media messages. We propose a general architecture that integrates machine learning and open data with a Chatbot and is based cloud computing (MLODCCC) which can assist users in evaluating information authenticity on social platforms. The proposed MLODCCC architecture consists of six integrated modules: cloud computing machine learning data preparation open data chatbot and intelligent social application modules. Food safety has garnered worldwide attention. Consequently we used the proposed MLODCCC architecture to develop a Food Safety Information Platform (FSIP) that provides a friendly hyperlink and chatbot interface on Facebook to identify credible food safety information. The performance and accuracy of three binary classification algorithms namely the decision tree logistic regression and support vector machine algorithms operating in different cloud computing environments were compared. The binary classification accuracy was 0.769 which indicates that the proposed approach accurately classifies using the developed FSIP.;2021
Social robots are coming to our homes and have already been used to help humans in a number of ways in geriatric care. This article aims to develop a framework that enables social robots to conduct regular clinical screening interviews in geriatric care such as cognitive evaluation falls' risk evaluation and pain rating. We develop a social robot with essential features to enable clinical screening interviews including a conversational interface face tracking an interaction handler attention management robot skills and cloud service management. Besides a general clinical screening interview management (GCSIM) model is proposed and implemented. The GCSIM enables social robots to handle various types of clinical questions and answers evaluate and score responses engage interviewees during conversations and generate reports on their well-being. These reports can be used to evaluate the progression of cognitive impairment risk of falls pain level and so on by caregivers or physicians. Such a clinical screening capability allows for early detection and treatment planning in geriatric care. The framework was developed and implemented on our 3-D-printed social robot. It was tested on 30 older adults with different ages achieved satisfying results and received their high confidence and trust in the use of this robot for human well-being assessment. Note to Practitioners-This article is motivated by the goal of using a social robot to perform geriatric well-being assessment through clinical screening interviews. In order to conduct clinical screening interviews the social robot needs the following essential features: having a verbal conversational interface adapting to different types of clinical screening interviews scoring and evaluating answers having nondirective listening responses and enabling directive listening responses. The proposed general clinical screening interview management (GCSIM) model demonstrates these capabilities on the social robot. The robot can give structured clinical screening interviews with different question-answer sheets. This will help advance assistive technologies for use by geriatric physicians nurses and social service professionals to keep older adults healthy safe and independent at home. Robots will become more and more essential in working alongside geriatric practitioners to help monitor older adults at home and to provide early detection and warning of cognitive/mental health problems falls' risk and so on. This early detection property can improve quality-of-care and help older adults remain living at home.;2021
Social robots are increasingly used within public spaces including museum settings. This quasi-systematic review identifies and synthesizes the evidence on social robots that have recently been deployed in museum settings. It specifically focuses on their intended purpose their acceptability and factors important for successful human-robot interaction in this setting. Four databases (PsycINFO SCOPUS ACM Digital Library and IEEE Xplore) were systematically searched to retrieve literature published within the last 10 years on human-robot interaction studies with social robots deployed in museum settings. Due to the heterogeneous nature of the studies qualitative and quantitative findings were summarized. A total of 604 items were identified of which 12 were included in the review. Robots in 11 studies were physical and 1 was an embodied conversational agent presented as a virtual robot. In 75% of the studies (n = 9) the purpose of the robots was to act as museum guides while in 17% (n = 2) they entertained visitors and in 8% (n = 1) the robot taught visitors in a museum outreach programme. Overall many of the robots were found to be acceptable for use within museum settings. Three main themes for successful social human-robot interaction were evident across the findings: (1) facial expressions (2) movement and (3) communication and speech. There is a great opportunity for social robots to be deployed within museum settings as guides educators entertainers or a combination thereof. State-of-the-art methods have led to the development of museum robots that are more capable of social interaction however more work is required to develop speech capabilities that work in the 'wild'. Future work should combine the factors that have been identified within this review to improve human-robot interaction.;2021
Social robots conversational agents voice assistants and other embodied AI are increasingly a feature of everyday life. What connects these various types of intelligent agents is their ability to interact with people through voice. Voice is becoming an essential modality of embodiment communication and interaction between computer-based agents and end-users. This survey presents a meta-synthesis on agent voice in the design and experience of agents from a human-centered perspective: voice-based human-agent interaction (vHAI). Findings emphasize the social role of voice in HAI as well as circumscribe a relationship between agent voice and body corresponding to human models of social psychology and cognition. Additionally changes in perceptions of and reactions to agent voice over time reveals a generational shift coinciding with the commercial proliferation of mobile voice assistants. The main contributions of this work are a vHAI classification framework for voice across various agent forms contexts and user groups a critical analysis grounded in key theories and an identification of future directions for the oncoming wave of vocal machines.;2021
Spoken language understanding (SLU) plays a central role in dialog systems and typically involves two tasks: intent detection and slot filling. Existing joint models improve the performance by introducing richer words intents and slots semantic features. However methods that model the explicit interactions between these features have not been further explored. In this paper we propose a novel joint model based on the position-aware multi-head masked attention mechanism which explicitly models the interaction between the word encoding feature and the intent-slot features thereby generating the context features that contribute to slot filling. In addition we adopt the multi-head attention mechanism to summarize the utterance-level semantic knowledge for intent detection. Experiments show that our model achieves state-of-the-art results and improves the sentence-level semantic frame accuracy with 2.30% and 0.69% improvement relative to the previous best model on the SNIPS and ATIS datasets respectively. (C) 2020 Elsevier B.V. All rights reserved.;2021
Spoken language understanding (SLU) plays an indispensable role in the dialogue system. The traditional intention detection task is regarded as a classification problem where utterances are associated with predefined intents. However the various expressions of user's intents and constantly emerging novel intents make the annotating time-consuming and labor-intensive building massive obstacles for extending the model to new tasks. Identifying unexpected user intention and achieving the user's desire goal is a challenging task. Therefore we conduct zero-shot intention detection based on a transformation-based learning manner. In this paper we propose an intent-enhanced attentive capsule network (IE-BertCapsNet) further guides the aggregation process of the capsule network and generalizable useful features that can be adapted to emerging intentions. Coupling with the large margin cosine loss function the proposed model can identify discriminative features by forcing the whole network to minimize inter-class distance and minimize intra-class distance. Finally we leverage the IE-BertCapsNet's feature extraction ability and knowledge transferring capability to conduct zero-shot intent detection and generalized zero-shot intent detection. Extensive experiments on five benchmark task-oriented datasets in four languages demonstrate that the proposed model can achieve competitive performance that can better discriminate known intents and detect unknown intents. (c) 2021 Elsevier B.V. All rights reserved.;2021
Spoken language understanding (SLU) systems aim to understand users' utterance which is a key component of task-oriented dialogue systems. In this paper we focus on improving the contextual SLU. The contextual SLU systems mainly focus on how to effectively incorporate dialog context information (contextual information). The existing approaches all use the same contextual information to guide slot filling at all tokens which may inject the irrelevant information and result in ambiguity. To tackle this problem we propose a context-aware graph convolutional network (GCN) with an adaptive fusion layer for contextual SLU. The context-aware GCN is proposed to automatically aggregate the contextual information which frees our model from the manually designed heuristic aggregation function. Meanwhile an adaptive fusion layer is applied at each token to dynamically incorporate relevant contextual information which achieves a fine-grained contextual information transfer to guide the token-level slot filling. Experiments on the Simulated Dialog Dataset show that our model achieves state-of-the-art performance and outperforms other previous methods by a large margin (+3.67% on Sim-R +4.18% on Sim-M and +3.75% on Overall dataset). In addition we explore and analyze the pre-trained model (i.e. BERT) in our framework. We show that incorporating BERT brings a large improvement in low-resource setting.;2021
Static recommendation methods like collaborative filtering suffer from the inherent limitation of performing real-time personalization for cold-start users. Online recommendation e.g. multi-armed bandit approach addresses this limitation by interactively exploring user preference online and pursuing the exploration-exploitation (EE) trade-off. However existing bandit-based methods model recommendation actions homogeneously. Specifically they only consider the items as the arms being incapable of handling the item attributes which naturally provide interpretable information of user's current demands and can effectively filter out undesired items. In this work we consider the conversational recommendation for cold-start users where a system can both ask the attributes from and recommend items to a user interactively. This important scenario was studied in a recent work [54]. However it employs a hand-crafted function to decide when to ask attributes or make recommendations. Such separate modeling of attributes and items makes the effectiveness of the system highly rely on the choice of the hand-crafted function thus introducing fragility to the system. To address this limitation we seamlessly unify attributes and items in the same arm space and achieve their EE trade-offs automatically using the framework of Thompson Sampling. Our Conversational Thompson Sampling (ConTS) model holistically solves all questions in conversational recommendation by choosing the arm with the maximal reward to play. Extensive experiments on three benchmark datasets show that ConTS outperforms the state-of-the-art methods Conversational UCB (ConUCB) [54] and Estimation-Action-Reflection model [27] in both metrics of success rate and average number of conversation turns.;2021
Storybook reading accompanied by adult-guided conversation provides a stimulating context for children's language development. Conversational agents powered by artificial intelligence such as smart speakers are prevalent in children's homes and have the potential to engage children in storybook reading as language partners. However little research has explored the effectiveness of using conversational agents to support children's language development. This study examined how an automated conversational agent can read stories to children via a smart speaker while asking questions and providing contingent feedback. Using a randomized experiment among 90 children aged three to six years this study compared these children's story comprehension and verbal engagement in storybook reading with a conversational agent versus an adult. The conversational agent's guided conversation was found to be as supportive in improving children's story comprehension as that provided by an adult language partner. At the same time this study uncovered a number of differences in children's verbal engagement when interacting with a conversational agent versus with an adult. Specifically children who read with the conversational agent responded to questions with better intelligibility whereas those who read with an adult responded to questions with higher productivity lexical diversity and topical relevance. And the two groups responded to questions with a similar level of accuracy. In addition questions requiring high cognitive demand amplified the differences in of verbal engagement between the conversational agent and adult partner. The study offers important implications for developing and researching conversational agent systems to support children's language development.;2021
Stress is a prevalent issue amongst patients with chronic conditions. As eHealth interventions are gaining importance it becomes more relevant to invoke the possibilities from the eHealth technology itself to provide motivational acts during experiences of stress as to enhance adherence to the intervention. Embodied Conversational Agents (ECA's) also known as 'robots on screen' can potentially provide a remedy. Within our eHealth experiment we applied a between-subjects design and experimentally studied the difference in appraisal of motivation and guidance. We deployed a functionally modest monologue-style ECA and compared them with textual guidance. This way we filtered out the considerable positive impact of interactive features that go along with dialogue-style ECA's. The study was carried out amongst eHealth users of which half were deliberately put in a stressful pre-condition. The rationale was two-sided first we hypothesized that it would induce a need for motivational support. Second it would provide a fair representation of eHealth users in real life. Furthermore we investigated hypothesized positive effects from a gender match between participant and ECA. The results demonstrated preferential ECA effects compared to text but only in the no stress conditions. Although our set-up controlled for user distraction by putting the facilitating ECA in a pane separate from the eHealth environment we suspect that the enduring visual presence of the ECA during task completion had still inhibited distressed users. Discussing this phenomenon our stance is that the hypothesis that ECA support is always superior to textual guidance is open for re-evaluation. Text may sometimes serve users equally well because it lacks human-like aspects that in stressful circumstances can become confrontational. We discuss the potential of ECA's to motivate but also elaborate on the caveats. Further implications for the ECA intervention adherence and eHealth study fields are discussed in relation to stress.;2021
Student life causes many sources of stress due to the requirements of managing schoolwork family friends health and wellbeing and future career planning. Some students are overwhelmed and lack resilience to overcome stress especially if they are inexperienced in managing setbacks fail to achieve expectations or lack skills to independently manage social skills recreation and study time. The long-term accumulation of stress has a negative impact on students' physical and mental health and may lead to a range of symptoms such as depression anxiety headache insomnia and eating disorders. Although most universities provide psychological counseling services there is often a shortage of professional psychologists which leads to students suffering from stress for longer than necessary without immediate assistance. The build-up of stress can lead to tragic consequences including abnormal reasoning anti-social behavior and suicide. There should never be a need for a student to wait more than a month to make an appointment for counseling services and every request for help should be immediately addressed and assessed. In this research we designed a unique test platform for an immersive virtual reality group chatbot counseling system so students can receive psychological help and stress management counseling anytime and anywhere. First the research used questionnaires to measure the stress levels and identifies how stress affects their lives. An immersive virtual reality chatbot was developed using professional psychological counseling knowledge that can provide answers during individual or group counseling sessions. Students can log in to the platform as avatars and ask the chatbot questions or interact with other students on the platform. This research provides college students with a new technology-based counseling environment designed to help relieve stress and learn new ways to improve student life quality from others. The platform provides a test base for future clinical trials to evaluate and improve the automated virtual reality chatbot counseling system.;2021
Successful collaboration between clinicians is particularly relevant regarding the quality of care process. In this context the utilization of hybrid intelligence such as conversational agents (CAs) is a reasonable approach for the coordination of diverse tasks. While there is a great deal of literature involving collaboration little effort has been made to integrate previous findings and evaluate research when applying CAs in hospitals. By conducting an extended and systematic literature review and semi-structured expert interviews we identified four major challenges and derived propositions where in-depth research is needed: 1) audience and interdependency 2) connectivity and embodiment 3) trust and transparency and 4) security privacy and ethics. The results are helpful for researchers as we discuss directions for future research on CAs for collaboration in a hospital setting enhancing team performance. Practitioners will be able to understand which difficulties must be considered before the actual application of CAs.;2021
Task-oriented dialogue systems typically rely on large amounts of high-quality training data or require complex handcrafted rules. However existing datasets are often limited in size considering the complexity of the dialogues. Additionally conventional training signal inference is not suitable for non-deterministic agent behavior namely considering multiple actions as valid in identical dialogue states. We propose the Conversation Graph (ConvGraph) a graph-based representation of dialogues that can be exploited for data augmentation multi-reference training and evaluation of non-deterministic agents. ConvGraph generates novel dialogue paths to augment data volume and diversity. Intrinsic and extrinsic evaluation across three datasets shows that data augmentation and/or multi-reference training with ConvGraph can improve dialogue success rates by up to 6.4%.;2021
Technology is giving rise to artificial erotic agents which we call erobots (eros + bot). Erobots such as virtual or augmented partners erotic chatbots and sex robots increasingly expose humans to the possibility of intimacy and sexuality with artificial agents. Their advent has sparked academic and public debates: some denounce their risks (e.g. promotion of harmful sociosexual norms) while others defend their potential benefits (e.g. health education and research applications). Yet the scientific study of human-machine erotic interaction is limited no comprehensive theoretical models have been proposed and the empirical literature remains scarce. The current research programs investigating erotic technologies tend to focus on the risks and benefits of erobots rather than providing solutions to resolve the former and enhance the latter. Moreover we feel that these programs underestimate how humans and machines unpredictably interact and co-evolve as well as the influence of sociocultural processes on technological development and meaning attribution. To comprehensively explore human-machine erotic interaction and co-evolution we argue that we need a new unified transdisciplinary field of research-grounded in sexuality and technology positive frameworks-focusing on human-erobot interaction and co-evolution as well as guiding the development of beneficial erotic machines. We call this field Erobotics. As a first contribution to this new discipline this article defines Erobotics and its related concepts proposes a model of human-erobot interaction and co-evolution and suggests a path to design beneficial erotic machines that could mitigate risks and enhance human well-being.;2021
Technology is intertwined in our lives. We can be characters preparing to slay dragons in video games or seek help from approachable virtual service representatives to make medical appointments. In this special issue focused on prevention science in the field of research on intellectual and developmental disabilities (IDDs) readers might be surprised to find an article addressing the use of avatars and agents. These virtual characters provide a friendly interface to represent a computer program. The application of avatars and agents in preventative intervention for children and youth with IDDs is in an early stage of development. However this technology has the potential to innovate the field. Computerized agents can project human-like emotions. These qualities provide unique behavioral and motivational reinforcement for engagement in agent-administered computer programs. Equally important agents hold the promise of reducing disparities in access to prevention efforts as they can be delivered (virtually) anywhere. Accordingly preventative interventions could reach children with IDDs in rural populations or children with low-incidence IDDs who would not commonly have access to a specifically targeted program. In this review we first define avatars and agents in more detail and provide a brief history of their evolution for context. We then synthesize the extant research that informs our understanding of how children with IDDs respond and engage with agent-based computer programs. We conclude our review with an appraisal of the methodological approaches used and recommendations for future research efforts.;2021
Text classification is an important component of digital media such as natural language processing image labeling sentiment analysis spam filtering chatbots and translators. In this work effort was devoted to develop an in-memory processor for Bayesian text classification using memristive crossbar architecture in which memristive switches were employed to store information required for the classification of text. The efficacy of the proposed circuit was tested on two distinct datasets consisting of a total of 55575 texts. The circuit was found to be efficient to categorize the texts with an average accuracy of 91%. This work paves the way for hardware realization of cognitive systems using in-memory processors.;2021
Thanks to artificial intelligence chatbots have been applied to many consumer-facing applications especially to online travel agencies (OTAs). This study aims to identify five quality dimensions of chatbot services and investigate their effect on user confirmation which in turn leads to use continuance. In addition the moderating role of technology anxiety in the relationships between chatbot quality dimensions and post-use confirmation is examined. Survey data were gathered from 295 users of Chinese OTAs. Partial Least Square (PLS) was used to analyze measurement and structural models. Understandability reliability assurance and interactivity are positively associated with post-use confirmation and technology anxiety moderates the relationships between four chatbot quality dimensions and confirmation. Confirmation is positively associated with satisfaction which in turn influences use continuance intention. This study examines how chatbot services in OTAs are considered by users (human-like agents vs. technology-enabled services) by investigating the moderating role of technology anxiety.;2021
The ability of dialogue systems to express pre-specified style during conversations has a direct positive impact on their usability and user satisfaction. While it has attracted much research interest existing methods often generate stylistic responses at the cost of content quality. In this work we introduce a prototype-to-style (PS) framework to tackle the challenge of stylistic dialogue generation. The proposed framework first exploits an Information Retrieval (IR) system and extracts a response prototype from the retrieved response. A stylistic response generator then takes the response prototype and the desired style as input to produce a high-quality and stylistic response. To effectively train the proposed model and imitate the real testing environment we introduce a new style-aware learning objective and a denoising learning strategy. Results on three benchmark datasets (gender emotion and sentiment) from two languages demonstrate that the proposed approach significantly outperforms existing baselines both in terms of in-domain and cross-domain evaluations.;2021
The actions of intelligent agents such as chatbots recommender systems and virtual assistants are typically not fully transparent to the user. Consequently users take the risk that such agents act in ways opposed to the users' preferences or goals. It is often argued that people use trust as a cognitive shortcut to reduce the complexity of such interactions. Here we formalise this by using the methods of evolutionary game theory to study the viability of trust-based strategies in repeated games. These are reciprocal strategies that cooperate as long as the other player is observed to be cooperating. Unlike classic reciprocal strategies once mutual cooperation has been observed for a threshold number of rounds they stop checking their co-player's behaviour every round and instead only check it with some probability. By doing so they reduce the opportunity cost of verifying whether the action of their co-player was actually cooperative. We demonstrate that these trust-based strategies can outcompete strategies that are always conditional such as Tit-for-Tat when the opportunity cost is non-negligible. We argue that this cost is likely to be greater when the interaction is between people and intelligent agents because of the reduced transparency of the agent. Consequently we expect people to use trust-based strategies more frequently in interactions with intelligent agents. Our results provide new important insights into the design of mechanisms for facilitating interactions between humans and intelligent agents where trust is an essential factor. (C) 2021 Elsevier B.V. All rights reserved.;2021
The adoption of artificial intelligence (AI) systems in environments that involve high risk and high consequence decision-making is severely hampered by critical design issues. These issues include system transparency and brittleness where transparency relates to (i) the explainability of results and (ii) the ability of a user to inspect and verify system goals and constraints and brittleness (iii) the ability of a system to adapt to new user demands. Transparency is a particular concern for criminal intelligence analysis where there are significant ethical and trust issues that arise when algorithmic and system processes are not adequately understood by a user. This prevents adoption of potentially useful technologies in policing environments. In this article we present a novel approach to designing a conversational agent (CA) AI system for intelligence analysis that tackles these issues. We discuss the results and implications of three different studies a Cognitive Task Analysis to understand analyst thinking when retrieving information in an investigation Emergent Themes Analysis to understand the explanation needs of different system components and an interactive experiment with a prototype conversational agent. Our prototype conversational agent named Pan demonstrates transparency provision and mitigates brittleness by evolving new CA intentions. We encode interactions with the CA with human factors principles for situation recognition and use interactive visual analytics to support analyst reasoning. Our approach enables complex AI systems such as Pan to be used in sensitive environments and our research has broader application than the use case discussed.;2021
The aim of this article is to examine the opportunities for employees with autism spectrum disorders (ASDs) arising from digital technology (DT) development. The author discusses assistive technology (AT) as a mean of creating a better work environment making the digitized workplace more friendly for people with ASD. A possible solution of communication problems is replacing the interpersonal communication between employees with electronic (non-direct) forms of communication such as online communicators or chatbots. Another solution is the implementation of wearable electronic systems monitoring stress levels and facilitating effective stress control. In the future the whole digitized workplace could be designed according to a smart workplace concept. Sensors recording various human body parameters could be connected to a network with sensors recording physical parameters of the work environment (temperature humidity noise smell sunlight exposure) and also with controllers of its values adjusting it dynamically to reduce distracting factors. As a result communication stress management and sensory sensitiveness problems could be limited improving the work comfort of people with ASD and their colleagues. The pertinence of solutions proposed was also confirmed by the experts interviewed in the field who were asked to assess it in the context of future implementation.;2021
The aim of this paper is to contribute to the debate on ethics in AI focusing particularly on the social and ethical issues which emerge during human-conversational agent interaction. Those issues will be approached adopting both the perspective of the user and the one of the machine. In fact it is often stressed the need to include the ethical component within system's design which it is certainly necessary as will be discussed in the article. Nevertheless conversational agents are tools although they are capable of having a strong impact on the society thus the moral use of these social tools must be demanded to users as well. For this reason it will be proposed a new set of ethical guidelines called Mirror Ethics based on the alignment of both parties involved in the conversation to a shared moral baseline. The adoption of these shared values will lead to the creation of a new ethical equilibrium between users and conversational agents producing a social beneficial impact and increasing the level of trust within the human-machine interaction.;2021
The aim of this study is to investigate whether an interactive self-regulation scaffolding increases levels of online learners' self-regulated learning skills course participation and learning performance. The intervention utilizes a dialog approach with an intelligent conversational agent to scaffold learners' self-regulated learning. Fifty-six graduate students participated in this study over a semester and were randomly assigned to one of two conditions: (1) an experimental condition where a scaffold was provided through the conversational agent and (2) a control condition where the self-regulated learning information was given but any scaffolds were not provided. The results revealed that the scaffolded group showed higher self-regulated learning level gains than the control group. Additionally the relationships between self-regulated learning course participation and learning performance were investigated.;2021
The appearance of Artificial Intelligence implementations such as text-based virtual assistants (chatbots) in education is relatively new. These implementations can be useful for helping teachers and students to solve both educational questions and routine tasks. This paper examines the factors that explain teachers' acceptance of chatbots through the dimensions of the Technology Acceptance Model (perceived usefulness and perceived ease of use) its conversational design (use of social language and proactiveness) and the teachers' age and digital skills. The data collection process included a pre-test and an online survey with four different types of chatbots. We analyse 225 responses of primary and secondary education teachers. The results show that the perceived easiness and perceived usefulness leads to greater acceptance of chatbots. As for the chatbots' features formal language by a chatbot leads to a higher intention of using them. These results can help in chatbot design and communication decisions improving the acceptance of the educational community.;2021
The application of Internet-based interventions within stepped-care models raises the question of when patients should receive Internet-based treatment and when patients should receive face-to-face (FtF) treatment. To address this question the patient perception and effects of working mechanisms were evaluated after brief psychotherapy for insomnia applying a mixed-methods approach. Treatment was either delivered through a text-based chat or it was delivered FtF. Almost half of the patients who received the chat-based treatment indicated that chat-based communication was appropriate for them when dealing with sleep difficulties but that they would prefer FtF communication for more sensitive topics. Results from the therapists' evaluations of working mechanisms yielded that these working mechanisms were more strongly associated with treatment outcome in the FtF condition than they were in the chat-based condition. To understand and to interpret the results media richness theory may be a useful tool: More severely impaired patients and patients with more complex concerns may need more complex (richer) communication formats for treatment delivery. Such heuristics may help to better justify treatment recommendations and optimize media choice in Internet-based interventions e.g. by defining moments when human interaction is needed and moments when communication could be conducted by nonhuman chatbots.;2021
The cognitive approach to psychotherapy aims to change patients' maladaptive schemas that is overly negative views on themselves the world or the future. To obtain awareness of these views they record their thought processes in situations that caused pathogenic emotional responses. The schemas underlying such thought records have thus far been largely manually identified. Using recent advances in natural language processing we take this one step further by automatically extracting schemas from thought records. To this end we asked 320 healthy participants on Amazon Mechanical Turk to each complete five thought records consisting of several utterances reflecting cognitive processes. Agreement between two raters on manually scoring the utterances with respect to how much they reflect each schema was substantial (Cohen's kappa = 0.79). Natural language processing software pretrained on all English Wikipedia articles from 2014 (GLoVE embeddings) was used to represent words and utterances which were then mapped to schemas using k-nearest neighbors algorithms support vector machines and recurrent neural networks. For the more frequently occurring schemas all algorithms were able to leverage linguistic patterns. For example the scores assigned to the Competence schema by the algorithms correlated with the manually assigned scores with Spearman correlations ranging between 0.64 and 0.76. For six of the nine schemas a set of recurrent neural networks trained separately for each of the schemas outperformed the other algorithms. We present our results here as a benchmark solution since we conducted this research to explore the possibility of automatically processing qualitative mental health data and did not aim to achieve optimal performance with any of the explored models. The dataset of 1600 thought records comprising 5747 utterances is published together with this article for researchers and machine learning enthusiasts to improve upon our outcomes. Based on our promising results we see further opportunities for using free-text input and subsequent natural language processing in other common therapeutic tools such as ecological momentary assessments automated case conceptualizations and more generally as an alternative to mental health scales.;2021
The consistency of a response to a given post at the semantic level and emotional level is essential for a dialogue system to deliver humanlike interactions. However this challenge is not well addressed in the literature since most of the approaches neglect the emotional information conveyed by a post while generating responses. This article addresses this problem and proposes a unified end-to-end neural architecture which is capable of simultaneously encoding the semantics and the emotions in a post and leveraging target information to generate more intelligent responses with appropriately expressed emotions. Extensive experiments on real-world data demonstrate that the proposed method outperforms the state-of-the-art methods in terms of both content coherence and emotion appropriateness.;2021
The COVID-19 pandemic has strained hospital resources and necessitated the need for predictive models to forecast patient care demands in order to allow for adequate staffing and resource allocation. Recently other studies have looked at associations between Google Trends data and the number of COVID-19 cases. Expanding on this approach we propose a vector error correction model (VECM) for the number of COVID-19 patients in a healthcare system (Census) that incorporates Google search term activity and healthcare chatbot scores. The VECM provided a good fit to Census and very good forecasting performance as assessed by hypothesis tests and mean absolute percentage prediction error. Although our study and model have limitations we have conducted a broad and insightful search for candidate Internet variables and employed rigorous statistical methods. We have demonstrated the VECM can potentially be a valuable component to a COVID-19 surveillance program in a healthcare system.;2021
The current incremental need for immediate responses (real-time) on many medical emergencies is necessity for an advanced society. In many cases people who are living in rural areas need a critical for their healthy commuting time to a Medical Center (Hospital). In addition human physicians have limited capability for offering their services to large number of emergencies or medical cases. Thus there is a need for the medical technologies to take the advantage of the advanced IT and Engineering for the design and development of Virtual Doctor Diagnoses Systems to facilitate such needs. This paper presents the components needed for the development of such an intelligent system called e-IATROS and its Virtual Doctor (VDr) dialogue systems. The e-IATROS system has the potential to simultaneously talk to a large number of human patients without humans to detect that they are talking to a computer based system. This is a necessary feature for convincing human patients to trust the machine and express their issues. To do so the e-IATROS has to use the voice of the actual human doctor for each human patient. Each VDr dialogue system mainly interacts with a patient extracting non-measurable and measurable symptoms to contribute to the generation of possible prognosis. The e-IATROS system is presented with its capabilities recognizing the patient emotion and learning through the process.;2021
The current research demonstrates how conversational robo advisors as opposed to static non-conversational robo advisors alter perceptions of trust the evaluation of a financial services firm and consumer financial decision making. We develop and empirically test a novel conceptualization of conversational robo advisors building on prior work in human-to-human communication and interpersonal psychology showing that conversational robo advisors cause greater levels of affective trust compared to non-conversational robo advisors and evoke a more benevolent evaluation of a financial services firm. We demonstrate that this increase in affective trust not only affects firm perception (in terms of benevolence attributions or a more positively-valenced onboarding experience) but has important implications for investor behavior such as greater recommendation acceptance and an increase in asset allocation toward conversational robo advisors. These findings have important implications for research on trust formation between humans and machines the effective design of conversational robo advisors and public policy in the digital economy.;2021
The growth of artificial intelligence (AI) and its applications in business has proliferated in recent years. Businesses have started adopting various technology practices relevant to automation and AI and research investigating this phenomenon is becoming increasingly important. Taking this as a cue the present research investigates the effect of human-to-machine interaction and human-to-human interaction towards cognitive absorption and its subsequent effect on trust experience and continuation intention in the context of services. The study built a 3 x 3 factorial design with automated chatbots (machine interaction) and service executives (human interaction) used as a stimulus in the experiment. Data collected from 410 respondents were analyzed using structural equation modeling to test the proposed hypotheses. The findings indicated that human-to-machine interaction influences cognitive absorption more positively compared to human-to-human interactions. The study results also provide evidence for the role of the trust experience and technology continuation intention in a technology background rooted in human-machine interactions. The present study adds a valuable contribution to the existing literature relevant to human-to-machine interaction cognitive absorption trust experience and continuation intention. The study also provides valuable inputs to technology and marketing managers.;2021
The increased availability of chatbots has drawn attention and interest to the study of what answers they provide and how they provide them. Chatbots have become a common sight in museums but are limited to answering only simple and basic questions. Based on the observed potential of chatbots for history education in museums we investigate how chatbots impact history education and improve the overall experience according to their appearance and language style. For this we built three models designed by factors on embodiment and reflection and 60 sets of answer-questions designed for the National Museum of Korea. We conducted a study with a total of 34 participants and carried out a variety of analyses covering individual learning styles museum experience scales gaze data in-depth interviews and observations from researchers. We present various results and lessons regarding the effect of embodiment and reflection on the museum experience. Our findings show how people with different learning styles connect with chatbot models and how visitors' behavior in the museum changes depending on the chatbot model. Specifically the chatbot model equipped with embodiment and reflection shows its superiority in enhancing the museum experience in general.;2021
The increasing number of female breast cancer (FBC) incidences in the East predominated by Chinese language speakers has generated concerns over women's medicare. To minimize the mortality rate associated with FBC in the region governments and health experts are jointly encouraging women to undergo mammography screening at the earliest suspicion of FBC symptoms. However studies show that a huge number of women affected by FBC tend to delay medical consultation at its early stage as a result of factors such as complacency due to unawareness of FBC symptoms procrastination due to lifestyle and the feeling of embarrassment in discussing private matters especially with medical personnel of the opposite gender. To address these issues we propose a symptomatic assessment chatbot (SAC) based on artificial intelligence (AI) designed to prescreen women for FBC symptoms via a textual question-and-answer (Q&A) approach. The purpose of our chatbot is to assist women in engaging in communication regarding FBC symptoms so as to subsequently initiate formal medical consultations for early FBC diagnosis and treatment. We implemented the SAC systematically with some of the latest natural language processing (NLP) techniques suitable for Chinese word segmentation (CWS) and trained the model with real-world FBC Q&A data obtained from a major hospital in Taiwan. The results from our experiments showed that the SAC achieved very high accuracy in FBC assessment scoring in comparison to FBC patients' screening benchmark scores obtained from doctors.;2021
The multiturn dialogue system has been prevalently used in e-commerce websites and modern information systems which significantly improves the efficiency of problem solving and further promotes the service quality. In a multiturn dialogue system the problem of intention classification is a core task as the intention of a customer is the basis of subsequent problems handling. However traditional related methods are unsuitable for the classification of multiturn dialogues. Because traditional methods do not distinguish the importance of each sentence and concatenate all sentences in the text which is likely to generate a model with low prediction accuracy. In this paper we propose a method of multiturn dialogue classification based on key sentences mining. We design a keywords extraction algorithm mining key sentences from the dialogue text. We propose an algorithm finishing the computation of the weights of each sentence. According to the sentence weight and the sentence vector the dialogue text is transformed to a dialogue vector. The dialogue text is classified by a classifier and the input is the dialogue vector. We conducted sufficient experiments on a real-world dataset evaluating the performance of the proposed method. The experimental results show that our method outperforms the related methods on a series of evaluation metrics.;2021
The NOESIS II challenge as the Track 2 in the Eighth Dialogue System Technology Challenge (DSTC 8) is the extension of Track 1 in DSTC 7. Three new elements are incorporated into the extended track i.e. dialogue with multiple participants dialogue success and dialogue disentanglement. These are vital for the creation of a deployed task-oriented dialogue system. This track is divided into four subtasks the first two of which are evaluated in the form of response selection and the last two focus on dialogue analysis. This paper describes our methods developed for these four subtasks which all employ deep contextualized utterance representations to make models aware of contextual information and to keep the intrinsic property of multi-turn dialogue systems. In the released evaluation results of Track 2 in DSTC 8 our proposed methods ranked fourth in subtask 1 third in subtask 2 and first in subtask 3 and subtask 4 respectively. In addition to the challenge tasks we also compare our proposed methods with previous ones on public benchmark datasets. Experimental results show that our proposed methods outperform existing ones by large margins and achieve new state-of-the-art performances on multi-turn response selection and dialogue disentanglement.;2021
The objective of this article is to analyze the didactic functionality of a chatbot to improve the results of the students of the National University of Distance Education (UNED / Spain) in accessing the university in the subject of Spanish Language. For this a quasi-experimental experiment was designed and a quantitative methodology was used through pretest and posttest in a control and experimental group in which the effectiveness of two teaching models was compared one more traditional based on exercises written on paper and another based on interaction with a chatbot. Subsequently the perception of the experimental group in an academic forum about the educational use of the chatbot was analyzed through text mining with tests of Latent Dirichlet Allocation (LDA) pairwise distance matrix and bigrams. The quantitative results showed that the students in the experimental group substantially improved the results compared to the students with a more traditional methodology (experimental group / mean: 32.1346 / control group / mean: 28.4706). Punctuation correctness has been improved mainly in the usage of comma colon and periods in different syntactic patterns. Furthermore the perception of the students in the experimental group showed that they positively value chatbots in their teaching-learning process in three dimensions: greater support and companionship in the learning process as they perceive greater interactivity due to their conversational nature greater feedback and interaction compared to the more traditional methodology and lastly they especially value the ease of use and the possibility of interacting and learning anywhere and anytime.;2021
The objective of this study is to explore the potential of a new method for assessing teamwork skills-a virtual high-fidelity behavioral simulation. In this paper we describe the development and validation of a chatbot-driven simulation for assessing teamwork skills of university students. We present the results of a criterion validation study using a sample of 215 undergraduate students. The simulation was found to significantly predict peer ratings following a live team-based exercise over and above a teamwork situational judgment test and a personality inventory. The mean score for women on the simulation was significantly higher than for men. Limitations and future directions are discussed.;2021
The perception of feeling lonely is an influential factor in determining quality of life among aging adults. As the US Census Bureau projects that the number of Americans ages 65 and older will double by 2060 reducing loneliness is imperative. Personal voice assistants (PVAs) such as Amazon's Echo offer the ease-of-use of voice control with a friendly helpful artificial intelligence. This study aimed to understand the influence of a PVA on loneliness reduction among adults of advanced ages i.e. 75+ and explore anthropomorphism as a potential underlying mechanism. Participants (N = 16) ages 75 or older used an Amazon Echo PVA for 8 weeks in an independent living facility in the Midwest. Surveys were used to collect information about perceived loneliness and PVA interaction data was recorded and analyzed. Participants consistently exceeded the required daily interactions. As hypothesized after the first 4 weeks of the intervention aging adults reported significantly lower loneliness (baseline mean = 2.22 SD = 0.42 week 4 mean = 1.99 SD = 0.45 Z = -2.45 and p = 0.01). Four dominant anthropomorphic themes emerged after thematic analysis of the entire 8 weeks' PVA interaction data (Cohen's Kappa = 0.92): (1) greetings (user-initiated friendly phrases) (2) comments/questions (user-initiated second-person pronoun) (3) polite interactions (user-initiated direct-name friendly requests) (4) reaction (user response to Alexa). Relational greetings predicted loneliness reductions in the first 4 weeks and baseline loneliness predicted relational greetings with the PVA during the entire 8 weeks suggesting that anthropomorphization of PVAs may play a role in mitigating loneliness in aging adults.;2021
The quality of scientific oral presentations is often poor owing to a number of factors including public speaking anxiety. We present DynamicDuo a system that uses an automated life-sized animated agent to help inexperienced scientists deliver their presentations in front of an audience. The design of the system was informed by an analysis of TED talks given by pairs of human presenters to identify the most common dual-presentation formats and transition behaviors used. We explore the usability and acceptability of DynamicDuo in both controlled laboratory-based studies and real-world environments and its ability to decrease public speaking anxiety and improve presentation quality. In a within-subjects study (N = 12) comparing co-presenting with DynamicDuo against solo-presenting with conventional presentation software we demonstrated that our system led to significant improvements in public speaking anxiety and speaking confidence for non-native English speakers. Judges who viewed videotapes of these presentations rated those with DynamicDuo significantly higher on speech quality and overall presentation quality for all presenters. We also explore the affordances of the virtual co-presenter through empirical evaluation of novel roles the agent can play in scientific presentations and novel ways it can interact with the speaker in front of the audience.;2021
The rapid growth of COVID-19 publications has driven clinical researchers and healthcare professionals in pursuit to reduce the knowledge gap on reliable information for effective pandemic solutions. The manual task of retrieving high-quality publications based on the evidence pyramid levels however presents a major bottleneck in researchers' workflows. In this paper we propose an evidence-based recommender system namely KnowCOVID-19 that utilizes an edge computing service to integrate recommender modules for data analytics using end-user thin-clients. The edge computing service features chatbot-based web interface that handles a given COVID-19 publication dataset using two recommender system modules: (i) evidence-based filtering that observes domain specific topics across the literature and classifies the filtered information according to a clinical category and (ii) social filtering that allows diverse experts with similar objectives to collaborate via a social plane to jointly find answers to critical clinical questions to fight the pandemic. We compare the Domain-specific Topic Model (DSTM) used in our evidence-based filtering with state-of-the-art models considering the CORD-19 dataset (a COVID-19 publication archive) and show improved generalization effectiveness as well as knowledge pattern query effectiveness. In addition we conduct a comparison study between a manual literature review process and the KnowCOVID-19 augmented process and evaluate the benefits of our information retrieval techniques over important queries provided by COVID-19 clinical experts.;2021
The rapidly evolving science about the Coronavirus Disease 2019 (COVID-19) pandemic created unprecedented health information needs and dramatic changes in policies globally. We describe a platform Watson Assistant (WA) which has been used to develop conversational agents to deliver COVID-19 related information. We characterized the diverse use cases and implementations during the early pandemic and measured adoption through a number of users messages sent and conversational turns (ie pairs of interactions between users and agents). Thirty-seven institutions in 9 countries deployed COVID-19 conversational agents with WA between March 30 and August 10 2020 including 24 governmental agencies 7 employers 5 provider organizations and 1 health plan. Over 6.8 million messages were delivered through the platform. The mean number of conversational turns per session ranged between 1.9 and 3.5. Our experience demonstrates that conversational technologies can be rapidly deployed for pandemic response and are adopted globally by a wide range of users.;2021
The recent advent of neural approaches for developing each dialog component in task-oriented dialog systems has remarkably improved yet optimizing the overall system performance remains a challenge. Besides previous research on modeling complicated multi-domain goal-oriented dialogs in end-to-end fashion has been limited. In this paper we present an effective multi-domain end-to-end trainable neural dialog system SUMBT+LaRL that incorporates two previous strong models and facilitates them to be fully differentiable. Specifically the SUMBT+ estimates user-acts as well as dialog belief states and the LaRL models latent system action spaces and generates responses given the estimated contexts. We emphasize that the training framework of three steps significantly and stably increase dialog success rates: separately pretraining the SUMBT+ and LaRL fine-tuning the entire system and then reinforcement learning of dialog policy. We also introduce new reward criteria of reinforcement learning for dialog policy training. Then we discuss experimental results depending on the reward criteria and different dialog evaluation methods. Consequently our model achieved the new state-of-the-art success rate of 85.4% on corpus-based evaluation and a comparable success rate of 81.40% on simulator-based evaluation provided by the DSTC8 challenge. To our best knowledge our work is the first comprehensive study of a modularized E2E multi-domain dialog system that learning from each component to the entire dialog policy for task success.;2021
The research on chatbots has gained momentum over the past few years. Academics and practitioners investigate how these tools for communication with customers or internal team can be improved in terms of their performance acceptance and deployment. Although there is a plethora of recent studies available not all of them deal with the digital business transformation implications of chatbots. The main aim of the research presented in this paper was to conduct a systematic literature review of high-quality journal research papers in order to summarise the current state of research on chatbots identify their role in digital business transformation and suggest the areas warranting further attention. 74 papers were included in the research. Topical (focus and applications) methodological (methods used sample size sample type and countries studied) and bibliometric (publication outlet citations and Altmetric Attention Score) aspects are evaluated and described. Scholars and practitioners can use the results to identify topics areas and applications that are intensely discussed in the literature and require further attention select a methodology for their research that is well established in the field or is emerging identify the most influential publications not to be missed in their research or identify publication outlets for publishing their research on chatbots.;2021
The restaurant technology market is rapidly evolving and is transforming the restaurant business as a significant sector of tourism and hospitality. Enabled by artificial intelligence (AI) mobile apps kiosks and chatbots revolutionize the guest experience and robots automate restaurant operations. Despite the increasing interest the use of AI and robotics in restaurants is still in its early stage and restaurant managers are seeking guidance to leverage these technologies for service excellence. In this high-contact service sector emotional skills need to be balanced with the possible automation potentials. The present research analyzes the current state of AI and robotics in the restaurant sector and proposes a systematic identification of process innovation potentials. For this purpose a market analysis of the European AI and robotics market for restaurant operations is conducted which yields a first knowledge base for future research and conceptual work. Besides detailed empirical data a reference process is developed for leveraging new technologies for process innovation.;2021
The study of human-human communication and the development of computational models for human-agent communication have diverged significantly throughout the last decade. Yet despite frequently made claims of super-human performance in e.g. speech recognition or image processing so far no system is able to lead a half-decent coherent conversation with a human. In this paper we argue that we must start to re-consider the hallmarks of cooperative communication and the core capabilities that we have developed for it and which conversational agents need to be equipped with: incremental joint co-construction and mentalizing. We base our argument on a vast body of work on human-human communication and its psychological processes that we reason to be relevant and necessary to take into account when modeling human-agent communication. We contrast those with current conceptualizations of human-agent interaction and formulate suggestions for the development of future systems.;2021
The taking of turns is a fundamental aspect of dialogue. Since it is difficult to speak and listen at the same time the participants need to coordinate who is currently speaking and when the next person can start to speak. Humans are very good at this coordination and typically achieve fluent turn-taking with very small gaps and little overlap. Conversational systems (including voice assistants and social robots) on the other hand typically have problems with frequent interruptions and long response delays which has called for a substantial body of research on how to improve turn-taking in conversational systems. In this review article we provide an overview of this research and give directions for future research. First we provide a theoretical background of the linguistic research tradition on turn-taking and some of the fundamental concepts in theories of turn-taking. We also provide an extensive review of multi-modal cues (including verbal cues prosody breathing gaze and gestures) that have been found to facilitate the coordination of turn-taking in human-human interaction and which can be utilised for turn-taking in conversational systems. After this we review work that has been done on modelling turn-taking including end-of-turn detection handling of user interruptions generation of turn-taking cues and multi-party human-robot interaction. Finally we identify key areas where more research is needed to achieve fluent turn-taking in spoken interaction between man and machine. (C) 2020 The Author. Published by Elsevier Ltd.Y;2021
The technology improvement has radically changed how tourists perform their journey offering new services to enhance their cultural experience and to easily retrieve required information. In this paper we propose a novel framework that models intangible and tangible cultural objects into a unified data model for supporting tourists journey. In particular a Micro-service architecture has been designed to provide several services whose tourists can access through a conversational agent based on the Seq2Seq model. Furthermore we propose also an Enterprise Service Bus to ingest events automatically from promotional website or manually from public and/or private organization. We have evaluated the proposed framework according to the following two experiments: (i) the efficiency and efficacy of the Chatbot engine showing that the use of GRU cells allows to obtain better results in terms of loss and accuracy with respect to LSTM one and (ii) the efficacy of the proposed framework according to the NASA-TLX asking to 50 users to interact with the Chatbot demonstrating that the proposed approach outperforms the state-of-the art ones combining natural processing language user profile information and historical activities.;2021
The term natural language refers to any system of symbolic communication (spoken signed or written) without intentional human planning and design. This distinguishes natural languages such as Arabic and Japanese from artificially constructed languages such as Esperanto or Python. Natural language processing (NLP) is the sub-field of artificial intelligence (AI) focused on modeling natural languages to build applications such as speech recognition and synthesis machine translation optical character recognition (OCR) sentiment analysis (SA) question answering dialogue systems etc. NLP is a highly interdisciplinary field with connections to computer science linguistics cognitive science psychology mathematics and others. Some of the earliest AI applications were in NLP (e.g. machine translation) and the last decade (2010-2020) in particular has witnessed an incredible increase in quality matched with a rise in public awareness use and expectations of what may have seemed like science fiction in the past. NLP researchers pride themselves on developing language independent models and tools that can be applied to all human languages e.g. machine translation systems can be built for a variety of languages using the same basic mechanisms and models. However the reality is that some languages do get more attention (e.g. English and Chinese) than others (e.g. Hindi and Swahili). Arabic the primary language of the Arab world and the religious language of millions of non-Arab Muslims is somewhere in the middle of this continuum. Though Arabic NLP has many challenges it has seen many successes and developments. Next we discuss Arabic's main challenges as a necessary background and we present a brief history of Arabic NLP. We then survey a number of its research areas and close with a critical discussion of the future of Arabic NLP.;2021
The Therapeutic Alliance (TA) between patient and health provider (therapist or clinician) is one of the most relevant factors for the success of a therapy. In the case of people suffering from Autism Spectrum Disorder (ASD) the alliance is extended to all the people involved in their care (i.e. teachers therapists clinicians relatives). In this paper we propose a multimedia application named Thea for empowering the TA of children with ASD by improving the communication among the TA members sharing guidelines multimedia contents and strategies to comply with challenging behaviors and progress with particular attention towards end-users who are occasional smart-users. A detailed process for empowering the TA members by enhancing the informed interaction among all of them is proposed and implemented. A vocal assistant also supports patients/caregivers and therapists in documenting their activity with the person with ASD by recording videos in a free-hand modality. After a contextual analysis based on Thematic Analysis Template Thea has been implemented using a user-centered development approach. We performed three iterations involving the end-users. A user study is performed at the third iteration. Results of the user study revealed a positive attitude towards the application. In particular the perception of empowerment of participants increased after the tool had been used. We also highlighted the guidelines and tools that may be adopted for empowering different kinds of patients. The first results seem to suggest that the use of Thea may increase the belief of the caregivers of a person with ASD to be able to better take care of her in a more controlled and informed way.;2021
The trend of incorporating assistive conversational agents into people's lives has followed the unprecedented expansion in the usage of artificial intelligence (AI). Amazon in particular has been a key trendsetter in this area through its Alexa-powered devices. Alexa is an intelligent personal assistant (IPA) that performs tasks such as playing music providing news and information and controlling smart home appliances. While this IPA is widely utilized it is especially gaining attention and growing usage by people with special needs. Even though the importance of the utilization of AI by people with special needs has been widely acknowledged in the extant literature a sizeable gap exists in the marketing literature in relation to the assessment of the managerial and societal implications of IPAs when used by people with special needs. Accordingly this study aims to examine (a) the stages of relationship development between Alexa and consumers with special needs and (b) the potential opportunity of this relationship for Amazon in relation to their corporate image. The findings indicate that a relationship between Alexa and consumers with special needs is established as it helps them regain their independence and freedom. This relationship provides an opportunity for Amazon in enhancing its overall image for providing solutions to facilitate the lives of people with special needs.;2021
The ultimate goal of English teaching is to cultivate the students' ability to communicate information in English master good language learning methods and become independent language learners and users. Therefore successful English language teaching needs to be achieved through language communication training between teachers and students and between students. This article investigates the importance of promoting the reform of oral English teaching in China's English teaching environment. We believe that to promote the reform of oral English teaching an oral teaching environment must be available. However the current common problem in oral English teaching in colleges and universities is that the spoken conversation objects are not standard enough or there is no person who can talk to. Therefore an intelligent spoken dialogue system based on big data and neural network technology is particularly important and the quality of dialogue depends on accurate spoken speech evaluation. We first extracted six features of pronunciation quality fluency content richness topic relevance grammar and vocabulary richness. Secondly we propose an evaluation model that connects specific TDNN layers in a feedforward manner using the feature representation of target words in different TDNN layers which can obtain richer context information and greatly reduce the amount of model parameters. Finally we conducted a simulation experiment. The experimental results show that the proposed model is accurate in evaluating spoken English and can effectively assist the reform of spoken English teaching in colleges and universities and its performance is better than SVM by 9.2%.;2021
The use of chatbots to manage online interactions with consumers poses additional ethical challenges linked to the use of artificial intelligence (AI) applications and opens up new ethical avenues for investigation. A literature analysis identifies a research gap regarding the ethical challenges related to chatbots as non-moral and non-independent agents managing non-real conversations with consumers. It raises concerns about the ethical implications related to the progressive automation of online conversational processes and their integration with AI. The conversational approach has been explored in the organisational and management literature which has analysed the features and roles of conversations in managing interactions ethically. This study aims to discuss conceptually the ethical challenges related to chatbots within the marketplace by integrating the current chatbot-based literature with that on conversation management studies. A new conceptual model is proposed which embraces ethical considerations in the future development of chatbots.;2021
The use of conversational agents in computer-supported collaborative learning (CSCL) has been identified as a useful tactic for motivational intervention. The purpose of the current study was to design and implement a conversational agent called a motivational online conversational agent (MOCA) that incorporated motivational interviewing (MI) and was based on an intelligent dialog engine to enhance learner engagement in CSCL. Additionally the study empirically examined the effects of MOCA on promoting positive changes in collaborative learning engagement through multiturn conversation interventions. A prototype system was developed by combining MOCA and an immersive virtual world and an effectiveness study was conducted with 40 volunteers. A series of multilevel growth models based on the framework of the hierarchical linear model was established through multiwave longitudinal data. The results indicated that the use of MOCA significantly improved student engagement scores (p < 0.001) and that female students performed better on collaborative tasks than male students (p < 0.05 t = 2.97). Additionally time was an important predictor and significantly interacted with the MOCA-use condition. The study has implications for the design and assessment of conversational agents embodied in virtual reality.;2021
The user experience of an asynchronous video interview system conventionally is not reciprocal or conversational. Interview applicants expect that like a typical face-to-face interview they are innate and coherent. We posit that the planned adoption of limited probing through follow-up questions is an important step towards improving the interaction. We propose a follow-up question generation model (followQG) capable of generating relevant and diverse follow-up questions based on the previously asked questions and their answers. We implement a 3D virtual interviewing system Maya with capability of follow-up question generation. Existing asynchronous interviewing systems are not dynamic with scripted and repetitive questions. In comparison Maya responds with relevant follow-up questions a largely unexplored feature of virtual interview systems. We take advantage of the implicit knowledge from deep pre-trained language models to generate rich and varied natural language follow-up questions. Empirical results suggest that followQG generates questions that humans rate as high quality achieving 77% relevance. A comparison with strong baselines of neural network and rule-based systems show that it produces better quality questions. The corpus used for fine-tuning is made publicly available.;2021
The visual analysis dialog system utilizing natural language interface is emerging as a promising data analysis tool. However previous work mostly focused on accurately understanding the query intention of a user but not on generating answers and inducing explorations. A focus+context answer generation approach which allows users to obtain insight and contextual information simultaneously is proposed in this work to address the incomplete user query (i.e. input query cannot reflect all possible intentions of the user). A query recommendation algorithm which applies the historical query information of a user to recommend a follow-up query is also designed and implemented to provide an in-depth exploration. These ideas are implemented in a system called DT2VIS. Specific cases of utilizing DT2VIS are also provided to analyze data. Finally the results show that DT2VIS could help users easily and efficiently reach their analysis goals in a comparative study.;2021
The widespread development of conversational agents (chatbots) has enabled us to communicate and collaborate with different forms and functions of robots using natural language thus facilitating a closer relationship between humans and technology. Given that chatbot services infused with domain knowledge are of great interest to not only global businesses but also academics chatbots have in recent years become a popular research topic in the field of natural language processing. We therefore aim at improving current chatbots with the addition of natural emotions. In contrast to previous work we intend to distinguish fine-grained emotion differences between words in order to better understand emotion expressions in sentences. Our approach infuses fine-grained emotion content into the response generation process to make the dialog more emotionally resonant. The experimental results demonstrate that this method can classify emotions more effectively. In addition the proposed hybrid model which consists of recurrent and convolutional neural networks with additional emotion specific valence-arousal features can correctly identify five emotions with a 67.89% overall F1-score. We further evaluate the subjective quality of the responses and discover that the infusion of finegrained emotion information substantially improves the quality and fluency of automatically generated empathetic conversation. We conclude that the proposed model can greatly improve the efficiency and usability of a conversational chatbot system. (C) 2021 Elsevier B.V. All rights reserved.;2021
There are many young people who experience mental health and wellbeing challenges. A potential negative mental health trigger for some youth is a struggle to cope with stress at school feelings of depression and anxiety and availability of adequate help for these stressors. In response to youth needs a mental health and wellbeing Chatbot has been co-developed with youth technology partners and expert stakeholders. An element of the Chatbot is powered by artificial intelligence and rules based AI using natural language processing. It is created to communicate evidence based resources wellbeing support educational mental health information and adaptive coping strategies. This paper will discuss how the Chatbot has been developed highlighting its participatory co-design process with youth who are the key stakeholders to benefit from this digital tool. Research from interviews and surveys informed the creation of the Chabots personality and its character design. Examples of the conversation design and content development are provided. The paper finishes with how if at all digital tools such as Chatbot applications could support the mental health of young people in secondary schools or health care settings in conjunction with the wellbeing or health care team concluding with lessons learned and cautions.;2021
There has been a recent surge of interest in social chatbots and human-chatbot relationships (HCRs) are becoming more prevalent but little knowledge exists on how HCRs develop and may impact the broader social context of the users. Guided by Social Penetration Theory we interviewed 18 participants all of whom had developed a friendship with a social chatbot named Replika to understand the HCR development process. We find that at the outset HCRs typically have a superficial character motivated by the users' curiosity. The evolving HCRs are characterised by substantial affective exploration and engagement as the users' trust and engagement in self-disclosure increase. As the relationship evolves to a stable state the frequency of interactions may decrease but the relationship can still be seen as having substantial affective and social value. The relationship with the social chatbot was found to be rewarding to its users positively impacting the participants' perceived wellbeing. Key chatbot characteristics facilitating relationship development included the chatbot being seen as accepting understanding and non-judgmental. The perceived impact on the users' broader social context was mixed and a sense of stigma associated with HCRs was reported. We propose an initial model representing the HCR development identified in this study and suggest avenues for future research.;2021
There is a growing tendency for users to expect conversational agents (CAs) to recognise social cues and follow interpersonal communication principles to enhance their subjective evaluation. Therefore this paper studies how personal pronouns should be used by CAs in response to users. We conducted a 3 (CAs' personal pronoun) x 3 (users' personal pronoun) x 2 (participants'gender) mixed design. this study used mixed methods based on an experimental design including ratings forced choices and interviews for mutual confirmation. The findings indicate that first users prefer that CAs use second-person pronouns. Second there is also turn-taking and convergence tendency between users and CAs in personal pronoun use. Third there are gender differences in personal pronoun preferences and relationship positions toward CAs. These results can inform personalised voice interaction and humanlike design and help build closer relationships between users and CAs in future human-computer interactions.;2021
There is an unprecedented demand for infodemic management due to rapidly evolving information about the novel COVID-19 pandemic. This viewpoint paper details the evolution of a Canadian digital information tool Chloe for COVID-19 based on incremental leveraging of artificial intelligence techniques. By providing an accessible summary of Chloe's development we show how proactive cooperation between health technology and corporate sectors can lead to a rapidly scalable safe and secure virtual chatbot to assist public health efforts in keeping Canadians informed. We then highlight Chloe's strengths the challenges we faced during the development process and future directions for the role of chatbots in infodemic management. The information presented here may guide future collaborative efforts in health technology in order to enhance access to accurate and timely health information to the public.;2021
There is growing interest in chatbots as a leading technology for digital transformation in the financial industry. However studies have largely investigated chatbots from the perspective of customers and developers and very few examine chatbot services from the perspective of managers who play a central role in the organizational adoption of chatbots. This paper aims to explore managers? perception of chatbots to help understand the initiation of financial chatbots and forecast the future of their service in South Korea which has seen active use of chatbots by financial firms. We conducted semi-structured interviews with managers in charge of chatbot services in Korean financial firms and employed a core?periphery analysis of social representations. Our findings will enhance the understanding of the status of chatbot services in the Korean financial industry and provide theoretical implications and managerial insights.;2021
This article illustrates how racial capitalism can enhance understandings of data capital and inequality through an in-depth study of digital platforms used for intervening in gender-based violence. Specifically we examine an emergent sociotechnical strategy that uses software platforms and artificial intelligence (Al) chatbots to offer users emergency assistance education and a means to report and build evidence against perpetrators. Our analysis details how two reporting apps construct data to support institutionally legible narratives of violence highlighting overlooked racialised dimensions of the data capital generated through their use. We draw attention to how they reinforce property relations built on extraction and ownership capital accumulation that reinforces benefits derived through data property relations and ownership and the commodification of diversity and inclusion. Recognising these patterns are not unique to anti-violence apps we reflect on how this example aids in understanding how racial capitalism becomes a constitutive element of digital platforms which more generally extract information from users rely on complex financial partnerships and often sustain problematic relationships with the criminal legal system. We conclude with a discussion of how racial capitalism can advance scholarship at the intersections of data and power.;2021
This correspondence introduces a correction on the survey entitled A Survey on Empathetic Dialogue Systems recently published in the Information Fusion journal. The authors of this correspondence first presented in 2010 a methodology for the scalable fusion of affective channels in a 2D continuous emotional space including a novel emotional kinematics filtering technique. This methodology was inappropriately attributed to other authors in the survey. This manuscript shows and clarifies its origin.;2021
This explorative study investigated (a) whether social attraction self-disclosure interaction quality intimacy empathy and communicative competence play a role in getting-acquainted interactions between humans and a chatbot and (b) whether humans can build a relationship with a chatbot. Although human-machine communication research suggests that humans can develop feelings for computers this does not automatically imply that humans experience feelings of friendship with a chatbot. In this longitudinal study 118 participants had seven interactions with chatbot Mitsuku over a 3-week period. After each interaction participants filled out a questionnaire. The results showed that the social processes decreased after each interaction and feelings of friendship were low. In line with the ABCDE model of relationship development the social processes that aid relationship continuation decrease leading to deterioration of the relationship. Furthermore a novelty effect was at play after the first interaction after which the chatbot became predictable and the interactions less enjoyable.;2021
This paper addresses the challenge of integrating a dialog system with an ITS created for supporting procedural training in a 3D virtual environment. To this end we first describe the desired features of the dialog to be provided to students in such system. Then we explain some technical issues of our proposal such as the architecture the design of the dialog manager and the construction of the answers to the students' questions by leveraging an ontology related to the virtual world. Next we present a pilot study with students to validate our approach. In this pilot study we utilized a prototype that encompasses a 3D virtual laboratory. In the last seven years students have used this virtual laboratory to perform a practice guided by an automatic tutor without dialog capacity. So the evaluated prototype represents an extension of this automatic tutor that aims to give it the dialog capacity in the context of the practice.;2021
This paper introduces the Eighth Dialog System Technology Challenge. In line with recent challenges the eighth edition focuses on applying end-to-end dialog technologies in a pragmatic way for multi-domain task-completion noetic response selection audio visual scene-aware dialog and schema-guided dialog state tracking tasks. This paper describes the task definition provided datasets baselines and evaluation set-up for each track. We also summarize the results of the submitted systems to highlight the overall trends of the state-of-the-art technologies for the tasks.;2021
This paper presents a new methodology for modeling the local semantic distribution of responses to a given query in the human-conversation corpus and on this basis explores a specified adversarial learning mechanism for training Neural Response Generation (NRG) models to build conversational agents. Our investigation begins with the thorough discussions upon the objective function of general Generative Adversarial Nets (GAN) architectures and the training instability problem is proved to be highly relative with the special local distributions of conversational corpora. Consequently an energy function is employed to estimate the status of a local area restricted by the query and its responses in the semantic space and the mathematical approximation of this energy-based distribution is finally found. Building on this foundation a local distribution oriented objective is proposed and combined with the original objective working as a hybrid loss for the adversarial training of response generation models named as LocalGAN. Our experimental results demonstrate that the reasonable local distribution modeling of the query-response corpus is of great importance to adversarial NRG and our proposed LocalGAN is promising for improving both the training stability and the quality of generated results.;2021
This paper proposes a hierarchical method for learning an efficient Dialogue Management (DM) strategy for task-oriented conversations serving multiple intents of a domain. Deep Reinforcement Learning (DRL) networks specializing in individual intents communicate with each other having the capability of sharing overlapping information across intents. The sharing of information across state space and the presence of global slot tracker prohibits the agent to reask known information. Thus the system is able to handle sub-dialogues based on subset of intents covered by different Reinforcement Learning (RL) models thereby completing the dialogue without again asking already provided information common across intents. The developed system has been demonstrated for Air Travel domain. The experimental results indicate that the developed system is efficient scalable and can serve multiple intents based dialogues adequately. The proposed system when applied to 5-intent dialogue systems attains an improvement of 41% in terms of dialogue length as compared to a single-intent based system serving the same 5-intents.;2021
This paper provides a general overview of the literature regarding advanced assistive technologies devoted to improving elders' life. Recent studies on assistive robots and embodied conversational agents are carefully examined in order to identify main seniors' preferences regarding their general design. While providing data on seniors' preferences about the design of assistive devices main evidence on both robots and virtual agent's appearance abilities/functionalities personalities and role features are summarized and commented.;2021
This research analyzes how digital technologies contribute to improving the successive stages of the recruitment process: identifying selecting and retaining talented people. E-recruitment is an emerging and polymorphous phenomenon that starts with identification of candidates on social networks continues through gamification of recruitment and job interviews with chatbots and ends by matching a candidate and a job using artificial intelligence. These technologies are particularly useful for social businesses looking to recruit not only skilled people but above all employees who have behaviors and values that match their mission. The methodology is based on grounded theory participant observation and qualitative data collection. A multiple case study is designed to analyze compare and combine several technologies dedicated to recruitment: (1) a social network with LinkedIn (2) a MOOC with Udacity (3) a serious game called Reveal from L'Ore ' al (4) a chatbot called Ari from TextRecruit and (5) a massive data analysis matching system with Randstad.tech. The discussion examines the respective performance and limits of these tools and their convergence via a progressive integration that leads to an uberization of recruitment. Managerial recommendations are formulated to support recruiters in their adoption of e-recruitment.;2021
This research proposes a four-stage consultant framework for applying a chatbot as a data management system. With the advancement of computational power and data storage technology the increasing amount of data makes the issue of data management difficult to address. Management of a massive amount of data by utilizing chatbots to play the roles of a data manager and a data provider has been extensively studied. Although a chatbot system has been proven to increase the overall efficiency of data management implementing a chatbot system in a government department remains a challenge especially in a field with highly complex data. This research presents the authors' experience of applying a chatbot system in a department of the government of Taiwan for disaster response operations. A four-stage consulting framework comprising 1) existing workflow review 2) usability evaluation 3) system improvement and 4) management plan (EUSM) was thus proposed. After a two-year field test the authors found that the framework could help the department in clarifying their working process increase the overall efficiency of the chatbot system and identify the major issues of introducing the chatbot system.;2021
This study aimed to propose a novel method for designing a product recommendation virtual agent (PRVA) that can keep users motivated to interact with the agent. In prior papers many methods of keeping users motivated postulated real-time and multi-modal interactions. The proposed novel method can be used in one-direction interaction. We defined the notion of the hidden vector that is information that is not mentioned by a PRVA and that the user can suppose spontaneously. We conducted an experiment to verify the hypothesis that PRVAs having a hidden vector are more effective than other PRVAs. As a result it was shown that PRVAs having a hidden vector were perceived as being more persuasive than other PRVAs and strongly motivated the users to use the PRVAs. From these results the proposed method was shown to be effective.;2021
This study aims to explore the influence of various possible combinations of consumer attribute benefits and the message direction provided by merchants on the final purchase intention of consumers. A two-factor experimental design was used to collect data from Generation Z consumers. Four experimental combination scenarios were designed based on consumer attribute benefits (hedonic or utilitarian) and message direction (positive or negative messages). A total of 160 valid samples were obtained and the influence of variable-final purchase intention was analyzed. The results showed that the combination of product attributes and message direction has a significant impact on purchase intention and that hedonic products should be recommended to process-benefit consumers through positive messages. However chatbots should choose utilitarian products and negative messages to effectively improve consumers' purchase intention and willingness. In practical application by finding out the best correspondence method of message transmission and providing the AI chatbot with a reference for the logical construction of content transmission the communication efficiency between merchants and consumers can be enhanced and the scientific and technological service capability of merchants can be improved.;2021
This study aims to investigate the effect of chatbots that work with artificial intelligence on the success of students and their opinions about chatbots in the 'Matter and the changing state of matter' unit in the 5th grade science course. In addition to text-based functions the designed chatbot includes a video accessed on the web to support students visually and aurally. The chatbot was designed using the Dialogflow program and an instant messaging program made available to students through a group created on Telegram. The study which used a quasi-experimental pretest-posttest design included 41 participants (n = 20 for the experimental n = 21 for the control group) studying in the 5th grade of a state secondary school in the 2020-2021 academic year. Results suggest that although there was no significant difference between the experimental and control groups in terms of academic achievement it was determined that the chatbot application positively affected the online learning experience of the experimental group students. Students' opinions about the chatbot included that it was useful and fun they would like to use it for other courses it provided useful assistance in learning outside the classroom and it allowed them to repeat the course again. The results showed that especially during the Covid-19 pandemic such applications could contribute positively to students' learning.;2021
This study analyzes the relationship between consumers' values and their reasons for and against perceived value co-creation as well as their behavioral intentions related to using artificial intelligence (AI)-enabled travel service agents (chatbots). Structual equation modeling (SEM) results mainly support the hypotheses driven by the behavioral reasoning theory (BRT) but presume that one means lead to usage intentions of AI-enabled travel service agents. Given the interdependency and complexity of consumers' reasoning processes in addition fuzzy-set qualitative comparative analysis (fsQCA) is conducted to provide more insight into this unexplored topic presuming multiple different trajectories. The complex solutions of fsQCA indicate that four different combinations sufficiently explain consumers' intent to use AI-enabled travel service agents. Overall the findings shed light on a new area of consumer behavior and the acceptance of AI-enabled service encounters.;2021
This study developed a chatbot to improve the efficiency of government activation of mine safety procedures during natural disasters. Taiwan has a comprehensive governmental system dedicated to responding to frequent natural disasters and the Bureau of Mines has instituted clear procedures to ensure the delivery of disaster alarms and damage reports. However the labor- and time-consumption procedures are inefficient. In this study we propose a system framework for disaster-related information retrieval and immediate notifications to support the execution of mine safety procedures. The framework utilizes instant messaging (IM) applications as the user interface to look up information and send messages to announce the occurrence of disaster events. We evaluated the efficiency of the procedures before and after adopting the system and achieved a time-cost reduction of 55.8 min among three types of disaster events. The study has proven the feasibility of adopting novel techniques for decision-making and assures the improvement of the efficiency and effectiveness of the procedure activation.;2021
This study discussed and evaluated the usefulness performance and technology acceptance of a chatbot developed to educate users and provide health literacy. A semi-structured interview and analytic sessions were provided on Google Analytics dashboard and the users' acceptance toward the technology was measured using the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2). A total of 75 undergraduate students were involved over a total period of two months. Each respondent explored the health chatbot actively to get advice from it with a phrase that matched the chatbot's intents via mobile devices. The evaluation results showed that 73.3% of the respondents found that the chatbot can help understand several health issues and provide a good conversation. The performance evaluation also showed that the chatbot contributed a low percentage of exit where less than 37% of users exited the application. The overall assessment showed that the developed chatbot has a significant potential to be used as a conversational agent to increase health literacy especially among students and young adults. However more research should be done before the technology can replace humans in a real setting.;2021
This study examined how and when a chatbot's emotional support was effective in reducing people's stress and worry. It compared emotional support from chatbot versus human partners in terms of its process and conditional effects on stress/worry reduction. In an online experiment participants discussed a personal stressor with a chatbot or a human partner who provided none or either one or both of emotional support and reciprocal self-disclosure. The results showed that emotional support from a conversational partner was mediated through perceived supportiveness of the partner to reduce stress and worry among participants and the link from emotional support to perceived supportiveness was stronger for a human than for a chatbot. A conversational partner's reciprocal self-disclosure enhanced the positive effect of emotional support on worry reduction. However when emotional support was absent a solely self-disclosing chatbot reduced even less stress than a chatbot not providing any response to participants' stress. Lay Summary In recent years AI chatbots have increasingly been used to provide empathy and support to people who are experiencing stressful times. This study compared emotional support from a chatbot compared to that of a human who provided support. We were interested in examining which approach could best effectively reduce people's worry and stress. When either a person or a chatbot was able to engage with a stressed individual and tell that individual about their own experiences they were able to build rapport. We found that this type of reciprocal self-disclosure was effective in calming the worry of the individual. Interestingly if a chatbot only reciprocally self-disclosed but offered no emotional support the outcome was worse than if the chatbot did not respond to people at all. This work will help in the development of supportive chatbots by providing insights into when and what they should self-disclose.;2021
This study examined the factors that affect artificial intelligence (AI) chatbot users' use of profanity and offensive words employing the concepts of ethical ideology social competence and perceived humanlikeness of chatbot. The study also looked into users' liking of chatbots' responses to the users' utterance of profanity and offensive words. Using a national survey (N = 645) the study found that users' idealism orientation was a significant factor in explaining use of such offensive language. In addition users with high idealism revealed liking of chatbots' active intervention whereas those with high relativism displayed liking of chatbots' reactive responses. Moreover users' perceived humanlikeness of chatbot increased their likelihood of using offensive words targeting dislikable acquaintances racial/ethnic groups and political parties. These findings are expected to fill the gap between the current use of AI chatbots and the lack of empirical studies examining language use.;2021
This study examines technology effectiveness for industry demand in which artificial intelligence (AI) is applied in the financial sector. It summarizes prior studies on chatbot and customer service and investigates theories on acceptance attitudes for innovative technologies. By setting variables the study examines bank revenue methodologically and assesses the impact of customer service and chatbot on bank revenues through customer age classification. The results indicate that new product-oriented funds or housing subscription savings are more suitable for purchase through customer service than through chatbot. However services for existing products through chatbot positively affect banks' net income. When classified by age purchases by the majority age group in the channel positively affect bank profits. Finally there is a tendency to process small banking transactions through the chatbot system which saves transaction and management costs positively affecting profits. Through empirical analysis we first examine the effect of an AI-based chatbot system implemented to strengthen financial soundness and suggest policy alternatives. Second we use banking data to increase the study's real-life applicability and prove that problems in customer service can be solved through a chatbot system. Finally we investigate how resistance to technology can be reduced and efficiently accommodated.;2021
This study explores the trends of chatbots in education studies by conducting a literature review to analyze relevant papers published in the Social Science Citation Index (SSCI) journals by searching the Web of Science (WoS) database. From the analysis results it was found that the United States Taiwan and Hong Kong are the top three contributing countries or regions. In addition most studies adopted quantitative methods in their research design such as ANOVA (Analysis of variance) descriptive statistics t test and correlation analysis. ANCOVA (Analysis of covariance) was the most frequently adopted approach for comparing the performances or perceptions of different groups of students. From the analysis results the greatest proportion of studies adopted guided learning followed by no learning activities. It was determined that the studies related to chatbots in education are still in an early stage since there are few empirical studies investigating the use of effective learning designs or learning strategies with chatbots. This implies much room for conducting relevant research to drive innovative teaching in terms of improving the learning process and learning outcomes. Finally we highlight the research gaps and suggest several directions for future research based on the findings in the present study.;2021
This study investigated how computer agents' language style affects summary writing in an Intelligent Tutoring System called CSAL AutoTutor. Participants interacted with two computer agents in one of three language styles: (1) a formal language style (2) an informal language style and (3) a mixed language style. Primary results indicated that participants improved the quality of summary writing spent less time writing summaries and had lower syntactic complexity but more non-narrative summaries on posttest than pretest. However this difference was not affected by the discourse formality that agents used during instruction. Results also showed participants rated peer summaries more accurately for cause/effect texts in the formal and mixed conditions but generated summaries with lower referential cohesion in the informal condition on posttest than pretest.;2021
This study investigated the effect of Chatbot-Assisted Dynamic Assessment (CA-DA) on vocabulary learning and provided insights into learner abilities drawn from its implementation. Through the use of mediating chatbots this study implemented DA to multiple learners simultaneously and provided each learner with human-like interaction. The chatbots were created using Google's Dialogflow. Fifty-three Korean EFL primary school learners who were confirmed to demonstrate the same range in vocabulary size participated in this study. They were randomly assigned to three groups: CA-DA Chatbot-Assisted Non-Dynamic Assessment (CA-NDA) and a control. For two treatment sessions the learners were asked to read texts and identify the meaning of underlined target words. The chatbots provided graduated assistance to learners in the CA-DA group and only target word definitions to learners in the CA-NDA group. The control group did not utilize chatbots. Two posttests (receptive and productive) were administered both immediately after and two weeks after the second treatment session. Interaction records between the chatbots and learners across the two treatment sessions were also collected. Posttest results showed that vocabulary gains in the CA-DA group were significantly higher than in the other groups. Analysis of interactions between the chatbots and learners for the CA-DA sessions provided detailed evidence of learner development. The findings suggest that CA-DA could not only promote vocabulary acquisition but could also offer diagnostic information about individual learners concerning vocabulary learning. This study also demonstrated the potential of chatbot technology to support language learners.;2021
This study investigated the impact of a chatbot-based micro-learning system on students' learning motivation and performance. A quasi-experiment was conducted with 99 first-year students taking part in a basic computer course on number system conversion. The students were assigned to a traditional learning group or a chatbot-based micro-learning group. After the experiment both groups achieved a comparable performance suggesting that students are sufficiently competent to learn independently in the chatbot-based learning environment without the need for continuous face-to-face delivery. Moreover students in the chatbot learning group attained significantly higher intrinsic motivation than the traditional learning group with perceived choice and perceived value as core predictors of intrinsic motivation. Further analysis with the Johnson-Neyman procedure revealed differences on interaction between the perceived choice and the learning environments. For students with a high initial perceived choice (>=5.1) chatbot-based learning further enhances their post choice motivation whereas for students with a low initial perceived choice (<=3.0) the traditional classroom is more suitable to enhance their post choice motivation. The implications of the findings can help instructors to incorporate chatbot-based learning in the classroom.;2021
This study investigates how serendipitous suggestions enhance user engagement with and sociality perceptions of movie recommendation system (RS). We constructed a mock-up recommendation system that provided either serendipitous or personalised movie suggestions to users. Based on the uses and gratifications theory entertainment and information-seeking motives were hypothesized to moderate the impact of serendipitous suggestions on users' sociality perceptions of the system. Results from an experiment (N = 161) showed that even though available genres and the perceived recency and accuracy of suggested motives were kept constant across the conditions the serendipitous suggestions scored higher on the reward dimension of user engagement than the personalized suggestions. Greater user engagement enhanced participants' sociality perceptions of the system such as being helpful friendly and competent. User motives significantly moderated the effects of serendipitous suggestions entertainment motives boosted the positive impact of serendipity on user engagement and sociality perception whereas information-seeking motives mitigated its impact.;2021
This study proposes an intelligent knowledge-based conversational agent system architecture to support customer services in e-commerce sales and marketing. A pilot implementation of a chatbot for customer services is reported in a leading women's intimate apparel manufacturing firm. The proposed system incorporates various emerging technologies including web crawling natural language processing knowledge bases and artificial intelligence. In this study a prototype system is built in a real-world setting. The results of the system prototype evaluation are satisfactory and support the contention that the system is effective. The study also discusses the challenges and lessons learned during system implementation and the theoretical and managerial implications of this study.;2021
This study uses artificial intelligence and big data technologies to develop a chatbot prototype for veterinary consultations. To understand pet owners' behavioral intentions to use the chatbot for veterinary consultations we modify the technology acceptance model to develop a usage intention model for the veterinary consultation chatbot. We survey members of a pet network community by using Google Forms to collect data and partial least squares structural equation modeling for analysis. The results indicate that the perceived accuracy perceived completeness and perceived ease of use increased pet owners' user satisfaction of veterinary consultation chatbot the perceived convenience and pet owners' user satisfaction increased pet owners' behavioral intention to use chatbot for veterinary consultations. This study can be used as a basis for evaluation of using intelligent technologies in pet healthcare consultation and pet disease management. (C) 2020 Journal of Innovation & Knowledge. Published by Elsevier Espana S.L.U.;2021
This work aimed to study the effect of confinement on weight and lifestyle using the Wakamola chatbot to collect data from 739 adults divided into two groups (341 case-control 398 confinement). Nutrition score (0-100 scale) improved for men (medians 81.77-82.29 p<0.05) with no difference for women (medians 82.29 in both cases). Both genders reduced the consumption of sweetmeats and sugared drinks (p<0.01) men increased their consumption of vegetables salad and legumes (p<0.01). Both genders reduced their physical activity score (men 100-40.14 p<0.01 women 80.42-36.12 p<0.01). Women sat less hours/week men's medians 28.81-28.27 women's medians 35.97-23.33 p=0.03. Both genders slept longer (hours/day) men 7-7.5 women 7-8 (p<0.01) (medians). Their overall health score was significantly reduced (men 85.06-74.05 p<0.01 women 84.47-72.42 p<0.01) with no significant weight difference in either gender. Wakamola helped to contact participants and confirm changes in their lifestyle during confinement.;2021
This work serves as a review of our experience applying off-policy techniques to train and evaluate a contextual bandit model powering a troubleshooting notification in a chatbot. First we demonstrate the effectiveness of off-policy evaluation when data volume is orders of magnitude less than typically found in the literature. We present our reward function and choices behind its design as well as how we construct our logging policy to balance exploration and performance on key metrics. Next we present a guided framework to update a model post-training called Post-Hoc Reward Distribution Hacking which we employed to improve model performance and correct deficiencies in trained models stemming from the existence of a null action and a noisy reward signal. Throughout the work we include discussions of various practical pitfalls encountered while using off-policy methods in hopes to expedite other applications of these techniques.;2021
To emulate the interactivity of in-person math instruction we developed MathBot a rule-based chatbot that explains math concepts provides practice questions and offers tailored feedback. We evaluated MathBot through three Amazon Mechanical Turk studies in which participants learned about arithmetic sequences. In the first study we found that more than 40% of our participants indicated a preference for learning with MathBot over videos and written tutorials from Khan Academy. The second study measured learning gains and found that MathBot produced comparable gains to Khan Academy videos and tutorials. We solicited feedback from users in those two studies to emulate a real-world development cycle with some users finding the lesson too slow and others finding it too fast. We addressed these concerns in the third and main study by integrating a contextual bandit algorithm into MathBot to personalize the pace of the conversation allowing the bandit to either insert extra practice problems or skip explanations. We randomized participants between two conditions in which actions were chosen uniformly at random (i.e. a randomized A/B experiment) or by the contextual bandit. We found that the bandit learned a similarly effective pedagogical policy to that learned by the randomized A/B experiment while incurring a lower cost of experimentation. Our findings suggest that personalized conversational agents are promising tools to complement existing online resources for math education and that data-driven approaches such as contextual bandits are valuable tools for learning effective personalization.;2021
To improve customer experience and achieve sustainable development many industries especially banking have leveraged artificial intelligence to implement a chatbot into their customer service. By integrating DeLone and McLean's information systems success (D&M ISS) model and the expectation confirmation model (ECM) with the factor of trust the aim of this study was to investigate the determinants of users' continuance intentions towards chatbot services in the context of banking in Vietnam. A total of 359 questionnaire surveys were collected from a real bank's chatbot users and analyzed using structural equation modeling. The findings revealed that users' continuance intentions towards the banks' chatbot services were influenced by satisfaction trust and perceived usefulness of which trust had the strongest effect. The results also indicate that information quality system quality service quality and confirmation of expectations had significant effects on three drivers of continuance intention in different ways. Our study contributes to the literature by providing a more comprehensive viewpoint to understand the perceptions and reactions of chatbot users in the post-adoption stage. The results of this study also yield several key suggestions for banking service providers on how to increase their customers' intentions to continue using chatbot services serving as a basis for long-term and sustainable development strategies in the current digital era.;2021
To support older users' accessibility and learning of the prevalent information and communication technologies (ICTs) libraries as informal learning institutes are committed to information literacy education activities with friendly interfaces. Chatbots using Voice User Interfaces (VUIs) with natural and intuitive interactions have received growing research and practical attention however older users report regular frustrations and problems in using them. To serve as a basis for the subsequent design and development of an automated dialog mechanism in senior-friendly chatbots a between-subject user experiment was conducted with 30 older adults divided into three groups. The preliminary findings on their interactions with the voice chatbots designed with different error handling strategies were reported. Participants' behavioral patterns performances and the tactics they employed in interacting with the three types of chatbots were analyzed. The results of the study showed that the use of multiple error handling strategies is beneficial for older users to achieve effectiveness and satisfaction in human-robot interactions and facilitate their attitude toward information technology. This study contributes empirical evidence in the genuine and pragmatic field of gerontechnology and expands upon voice chatbots research by exploring conversation errors in human-robot interactions that could be of further application in designing educational and living gerontechnology.;2021
Understanding the growth paths of artificial intelligence (AI) and its impact on branding is extremely pertinent of technology-driven marketing. This explorative research covers a complete bibliometric analysis of the impact of AI on branding. The sample for this research included all 117 articles from the period of 1982-2019 in the Scopus database. A bibliometric study was conducted using co-occurrence citation analysis and co-citation analysis. The empirical analysis investigates the value propositions of AI on branding. The study revealed the nine clusters of co-occurrence: Social Media Analytics and Brand Equity Neural Networks and Brand Choice Chat Bots-Brand Intimacy Twitter Facebook Instagram-Luxury Brands Interactive Agent-Brand Love and User Choice Algorithm Recommendations and E-Brand Experience User-Generated Content-Brand Sustainability Brand Intelligence Analytics and Digital Innovations and Brand Excellence. The findings also identify four clusters of citation analysis-Social Media Analysis and Brand Photos Network Analysis and E-Commerce Hybrid Simulating Modelling and Real-time Knowledge-Based Systems-and four clusters of co-citation analysis: B2B Technology Brands AI Fostered E-Brands Information Cascades and Online Brand Ratings and Voice Assistants-Brand Eureka Moments. Overall the study presents the patterns of convergence and divergence of themes narrowing to the specific topic and multidisciplinary engagement in research thus offering the recent insights in the field of AI on branding.;2021
Unstructured data from the internet constitute large sources of information which need to be formatted in a user-friendly way. This research develops a model that classifies unstructured data from data mining into labeled data and builds an informational and decision-making support system (DMSS). We often have assortments of information collected by mining data from various sources where the key challenge is to extract valuable information. We observe substantial classification accuracy enhancement for our datasets with both machine learning and deep learning algorithms. The highest classification accuracy (99% in training 96% in testing) was achieved from a Covid corpus which is processed by using a long short-term memory (LSTM). Furthermore we conducted tests on large datasets relevant to the Disaster corpus with an LSTM classification accuracy of 98%. In addition random forest (RF) a machine learning algorithm provides a reasonable 84% accuracy. This research's main objective is to increase the application's robustness by integrating intelligence into the developed DMSS which provides insight into the user's intent despite dealing with a noisy dataset. Our designed model selects the random forest and stochastic gradient descent (SGD) algorithms' F1 score where the RF method outperforms by improving accuracy by 2% (to 83% from 81%) compared with a conventional method.;2021
Upon declaring COVID-19 a global pandemic the World Health Organization (WHO) orchestrated a global risk-communication outreach. The WHO's objective was to persuade the public to upend and alter their lives so as to contain the disease and minimize its spread and infection. The WHO found a simple and efficient medium to communicate glocally through the social media application WhatsApp through which individuals could access information without gatekeeping by governments and local agencies.;2021
Using natural language processing (NLP) technologies to develop medical chatbots makes the diagnosis of the patient more convenient and efficient which is a typical application in healthcare AI. Because of its importance lots of researches have come out. Recently the neural generative models have shown their impressive ability as the core of chatbot while it cannot scale well when directly applied to medical conversation due to the lack of medical-specific knowledge. To address the limitation a scalable medical knowledge-assisted mechanism (MKA) is proposed in this paper. The mechanism is aimed at assisting general neural generative models to achieve better performance on the medical conversation task. The medical-specific knowledge graph is designed within the mechanism which contains 6 types of medical-related information including department drug check symptom disease and food. Besides the specific token concatenation policy is defined to effectively inject medical information into the input data. Evaluation of our method is carried out on two typical medical datasets MedDG and MedDialog-CN. The evaluation results demonstrate that models combined with our mechanism outperform original methods in multiple automatic evaluation metrics. Besides MKA-BERT-GPT achieves state-of-the-art performance.;2021
Visual dialog is a task that two agents: Question-BOT (Q-BOT) and Answer-BOT (A-BOT) which communicate in natural language on the situation of information asymmetry. Q-BOT generates questions based on an image caption and a historical dialog. A-BOT answers the questions grounded on the image. Moreover we play a cooperative 'image guessing' game between Q-BOT and A-BOT so that Q-BOT can select an unseen image from a set of images. However as the valid information of the image caption and the historical dialog fades along the interaction existing methods usually generate irrelevant and homogenous questions which are worthless to the visual dialog system. To tackle this issue we propose an A ttentive M emory N etwork (AMN) to fully exploit the image caption and historical dialog information. Specifically the attentive memory network mainly consists of a memory network and a fusion module. The memory network holds long term historical dialog information and gives each round of the dialog a different weight. Aside from the historical dialog information the fusion module in Q-BOT and A-BOT further uses the image caption and the image feature respectively. The caption information assists Q-BOT with the attentive generation of the questions and the image feature helps A-BOT produce precise answers. With the AMN the generated questions are diverse and concentrated and the corresponding answers are accurate. The experimental results on VisDial v1.0 show the effectiveness of our proposed model which outperforms the state-of-the-art methods. (c) 2021 Elsevier Ltd. All rights reserved.;2021
Visual dialogue systems need to understand dynamic visual scenes and comprehend semantics in order to converse with users. Constructing video dialogue systems is more challenging than traditional image dialogue systems because the large feature space of videos makes it difficult to capture semantic information. Furthermore the dialogue system also needs to precisely answer users' question based on comprehensive understanding of the videos and the previous dialogue. In order to improve the performance of video dialogue system we proposed an end-to-end recurrent cross-modality attention (ReCMA) model to answer a series of questions about a video from both visual and textual modality. The answer representation of the question is updated based on both visual representation and textual representation in each step of the reasoning process to have a better understanding of both modalities' information. We evaluate our method on the challenging DSTC7 video scene-aware dialog dataset and the proposed ReCMA achieves a relative 20.8% improvement over the baseline on CIDEr.;2021
Voice assistants such as Siri Alexa and Google Assistant have recently been the subject of lively debates in regard to issues such as artificial intelligence surveillance gender stereotypes and privacy. Less attention however has been given to the fact that voice assistants are also web interfaces that might impact on how the web is accessed understood and employed by users. This article aims to advance work in this context by identifying a range of issues that should spark additional reflections and discussions within communication and media studies and related fields. In particular the article focuses on three key issues that have to do with long-standing discussions about the social and political impact of the internet: the role of web platforms in shaping information access the relationship between production and consumption online and the role of affect in informing engagement with web resources. Considering these issues in regard to voice assistants not only helps contextualize these technologies within existing debates in communication and media studies but also highlights that voice assistants pose novel questions to internet research challenging assumptions of what the web looks like as speech becomes one of the key ways to access resources and information online.;2021
Voice assistants-or voice-enabled artificial intelligence-have changed the way people interact with their surroundings dramatically. Utilizing an enactive view of social cognition theory this study demonstrates how voice assistants can act as [semi] autonomous agents to hold instantaneous social interactions with consumers. This research employed two experimental studies. Study 1 used two voice assistant mobile applications Microsoft Cortana and Google Assistant and Study 2 used Amazon Alexa and Microsoft Cortana. The contributions this paper makes are two-fold. First the results illustrate how perceived auditory sense drives perceived auditory control through auditory social interactions with a voice assistant that lead to brand affect and con sumers' trust in the voice assistant. Second results shed light on the role of surprise as a repelling drive that attenuates the effect of perceived auditory control on brand affect.;2021
We are living in a digital era where ubiquitous social media are becoming part of the everyday lives of many. These social media platforms were designed for the living however an estimated 8000 Facebook members die daily. It is therefore no surprise that the phenomena of how social media platforms are adopted to discuss death dying and grieving have become a growing area of research across numerous disciplines. Using qualitative methods this article adds to and moves beyond existing research by focusing on the creation and inheritance of Facebook pages thanablogs posthumous chatbots posthumous messages and posthumous avatars to explore whether digital afterlives enabled by the Internet affect how people grieve. In order to examine how these messages and memories are experienced this study used in-depth qualitative interviews with participants from 3 distinct areas: Digital Creators (DC) Digital Inheritors (DI) and Service Providers (SP) the findings presented here explore three emerging themes (1) the link between comfort and control (2) the changing landscape of the uncanny valley and (3) the fear of 'second loss'.;2021
We explored the utility of chatbots for improving data quality arising from collection via sonline surveys. Three-hundred Australian adults sampled via Prolific Academic were randomized across chatbot-supported or unassisted online questionnaire conditions. The questionnaire comprised validated measures along with challenge items formulated to be confusing yet aligned with the validated targets. The chatbot condition provided optional assistance with item clarity via a virtual support agent. Chatbot use and user satisfaction were measured through session logs and user feedback. Data quality was operationalized as between-group differences in relationships among validated and challenge measures. Findings broadly supported chatbot utility for online surveys showing that most participants with chatbot access utilized it found it helpful and demonstrated modestly improved data quality (vs. controls). Absence of confusion for one challenge item is believed to have contributed to an underestimated effect. Findings show that assistive chatbots can enhance data quality will be utilized by many participants if available and are perceived as beneficial by most users. Scope constraints for this pilot study are believed to have led to underestimated effects. Future testing with longer-form questionnaires incorporating expanded item difficulty may further understanding of chatbot utility for survey completion and data quality.;2021
We live in a modern and technological society run by intelligent and human-like machines and systems. This is due to the advancements in the field of artificial intelligence. The machines are directly or indirectly used in different sectors like healthcare automatic vehicles and complex decision-making and at the same used in educational institutes. The usage of AI-based systems and the Internet has brought numerous educational innovations for both teachers and students. With the online learning platforms grounded on AI techniques 5G has revolutionized the teaching and learning methods by smooth and faster access to educational content. Students of foreign languages especially English learners can now use chatbots and intelligent tutoring systems to learn and practice their speaking and listening skills offline and online. With Computer-Assisted Language Learning (CALL) the English learning process can now be interactive and productive. The students can now improve their language skills by conversing with AI-based agents instead of native speakers to avoid any fear and anxiety. The intelligent platforms can understand the consuming power of the student and hence can create and give content according to their level to create an individualized learning environment. With the help of digital assistants people can also find it very easy and productive to improve English proficiency. To accomplish the goal of English teaching very easily and ideally the teachers should use AI-based techniques in the classrooms. With the help of intelligent assistants for the daily workload of a teacher we will be able to concentrate fully on the language learning and skills of the students. The current study has presented a detailed overview of 5G and AI's role in research and transformation of English situational teaching in higher studies. The search results are compiled and presented with different details of the area.;2021
We live in a time when dialogue systems are becoming a very popular tool. It is estimated that in 2021 more than 80% of communication with customers on the first line of service will be based on chatbots. They enter not only the retail market but also various other industries e.g. they are used for medical interviews information gathering or preliminary assessment and classification of problems. Unfortunately when these work incorrectly it leads to dissatisfaction. Such systems have the possibility of contacting a human consultant with a special command but this is not the point. The dialog system should provide a good uninterrupted and fluid experience and not show that it is an artificial creation. Analysing the sentiment of the entire dialogue in real time can provide a solution to this problem. In our study we focus on studying the methods of analysing the sentiment of dialogues based on machine learning for the English language and the morphologically complex Polish language which also represents a language with a small amount of training resources. We analyse the methods directly and use the machine translator as an intermediary thus checking the quality changes between models based on limited resources and those based on much larger English but machine translated texts. We manage to obtain over 89% accuracy using BERT-based models. We make recommendations in this regard also taking into account the cost aspect of implementing and maintaining such a system.;2021
We present a new method SOLOIST(1) that uses transfer learning and machine teaching to build task bots at scale. We parameterize classical modular task-oriented dialog systems using a Transformer-based auto-regressive language model which subsumes different dialog modules into a single neural model. We pre-train on heterogeneous dialog corpora a task-grounded response generation model which can generate dialog responses grounded in user goals and real-world knowledge for task completion. The pre-trained model can be efficiently adapted to accomplish new tasks with a handful of task-specific dialogs via machine teaching where training samples are generated by human teachers interacting with the system. Experiments show that (i) SOLOIST creates new state-of-the-art on well-studied task-oriented dialog benchmarks including CamRest676 and MultiWOZ (ii) in the few-shot fine-tuning settings SOLOIST significantly outperforms existing methods and (iii) the use of machine teaching substantially reduces the labeling cost of fine-tuning. The pre-trained models and codes are available at https://aka.ms/soloist.;2021
We present a series of mHealth applications and studies pursued as part of the Fittle+ project. This program of research has the dual aims of (1) bringing scalable evidence-based behavior-change interventions to mHealth and evaluating them and (2) developing theoretically based predictive models to better understand the dynamics of the impact of these interventions on achieving behavior-change goals. Our approach in the Fittle+ systems rests on the idea that to master the complex fabric of a new healthy lifestyle one must weave together a new set of healthy habits that over-ride the old unhealthy habits. To achieve these aims we have developed a series of mHealth platforms that provide scaffolding interventions: Behavior-change techniques and associated mHealth interactions (e.g. SMS reminders chatbot dialogs user interface functionality etc.) that provide additional support to the acquisition and maintenance of healthy habits. We present experimental evidence collected so far for statistically significant improvements in behavior change in eating exercise and physical activity for the following scaffolding interventions: guided mastery teaming self-affirmation and implementation intentions. We also present predictive computational ACT-R models of daily individual behavior goal success for data collected in guided mastery and implementation intention studies that address goal-striving and habit formation mechanisms.;2021
We present a Wizard-of-Oz experiment examining phonetic accommodation of human interlocutors in the context of human-computer interaction. Forty-two native speakers of German engaged in dynamic spoken interaction with a simulated virtual tutor for learning the German language called Mirabella. Mirabella was controlled by the experimenter and used either natural or hidden Markov model-based synthetic speech to communicate with the participants. In the course of four tasks the participants' accommodating behavior with respect to wh-question realization and allophonic variation in German was tested. The participants converged to Mirabella with respect to modified wh-question intonation i.e. rising F-0 contour and nuclear pitch accent on the interrogative pronoun and the allophonic contrast [IC] vs. [IK] occurring in the word ending <-ig >. They did not accommodate to the allophonic contrast [epsilon] vs. [e:] as a realization of the long vowel <-a->. The results did not differ between the experimental groups that communicated with either the natural or the synthetic speech version of Mirabella. Testing the influence of the Big Five personality traits on the accommodating behavior revealed a tendency for neuroticism to influence the convergence of question intonation. On the level of individual speakers we found considerable variation with respect to the degree and direction of accommodation. We conclude that phonetic accommodation on the level of local prosody and segmental pronunciation occurs in users of spoken dialog systems which could be exploited in the context of computer-assisted language learning. (C) 2021 The Author(s). Published by Elsevier Ltd.;2021
We present lessons learned from an ongoing attempt to conceptualize develop and refine a way for teachers to gather formative assessment evidence about classroom argumentation as it happens. The system-named DiALoG (Diagnosing Argumentation Levels of Groups)-includes a digital scoring tool that allows teachers to assess oral classroom argumentation across two primary dimensions: one to capture the Intrapersonal discipline-specific features of scientific arguments and another to capture the Interpersonal group regulatory features of argumentation as a dynamic social act. Coupled with the digital assessment are responsive mini-lessons (RMLs) which provide follow-up curriculum for teachers to respond to different levels of classroom argumentation proficiency for each item assessed. We use classroom observations interviews and surveys from piloting science teachers in two different states to iteratively refine this multifaceted formative assessment system of oral classroom argumentation. Lessons learned include the realization by pilot teachers that using the DiALoG system fine-tunes their professional vision to notice student practices they had not previously considered and the accompanying RMLs help fill gaps in their pedagogical content knowledge and repertoire. Furthermore while the DiALoG system is intended to be a formative assessment we learned that the mere presence of numerical scores can queue teacher schema for summative assessment. This prompted us to do away with numbers entirely in the latest version of our digital scoring tool. Such lessons learned from teacher experiences with the development of a novel formative assessment system like DiALoG can be instructive to the development of science educational technology more broadly.;2021
We propose a method of automatically selecting appropriate responses in conversational spoken dialog systems by explicitly determining the correct response type that is needed first based on a comparison of the user's input utterance with many other utterances. Response utterances are then generated based on this response type designation (back channel changing the topic expanding the topic etc.). This allows the generation of more appropriate responses than conventional end-to-end approaches which only use the user's input to directly generate response utterances. As a response type selector we propose an LSTM-based encoder-decoder framework utilizing acoustic and linguistic features extracted from input utterances. In order to extract these features more accurately we utilize not only input utterances but also response utterances in the training corpus. To do so multi-task learning using multiple decoders is also investigated. To evaluate our proposed method we conducted experiments using a corpus of dialogs between elderly people and an interviewer. Our proposed method outperformed conventional methods using either a point wise classifier based on Support Vector Machines or a single-task learning LSTM. The best performance was achieved when our two response type selectors (one trained using acoustic features and the other trained using linguistic features) were combined and multi-task learning was also performed.;2021
We propose a new approach towards emotional natural language generation using bidirectional seq2seq model. Our goal is to generate emotionally relevant language that accommodates the emotional tone of the prior context. To incorporate emotional information we train our own embeddings appended with emotion values through valence arousal and dominance scores. We use a reinforcement-learning framework which is tuned using policy gradient method. Two of the internal rewards in our reinforcement learning framework viz. Ease of Answering and Semantic Coherence are based on prior state-of-the-art. We propose a new internal reward Emotional Intelligence computed by minimizing the affective dissonance between the source and generated text. We also train a separate external reward analyzer to predict the rewards as well as to maximize the expected rewards (both internal and external). We evaluate the system on two common corpora used for Natural Language Generation tasks: the Cornell Movie Dialog and Yelp Restaurant Review Corpus. We report standard evaluation metrics including BLEU ROUGE-L and perplexity as well as human evaluation to validate our approach. We demonstrate the ability of proposed model to generate emotionally appropriate responses on both corpora.;2021
We recently proposed a novel intelligent newscaster chatbot for digital inclusion. Its controlled dialogue stages (consisting of sequences of questions that are generated with hybrid Natural Language Generation techniques based on the content) support entertaining personalisation where user interest is estimated by analysing the sentiment of his/her answers. A differential feature of our approach is its automatic and transparent monitoring of the abstraction skills of the target users. In this work we improve the chatbot by introducing enhanced monitoring metrics based on the distance of the user responses to an accurate characterisation of the news content. We then evaluate abstraction capabilities depending on user sentiment about the news and propose a Machine Learning model to detect users that experience discomfort with precision recall F1 and accuracy levels over 80%.;2021
We study the impacts of humanizing artificial intelligence (AI)-enabled autonomous customer service agents (chatbots). Implementing a field experiment in collaboration with a dual channel clothing retailer based in the United States we automate a used clothing buy-back process such that individuals engage with the retailer's autonomous chatbot to describe the used clothes they wish to sell obtain a cash offer and (if they accept the offer) print a shipping label to finalize the transaction. We causally estimate the impact of chatbot anthropomorphism on transaction conversion by randomly exposing consumers to exogenously varied levels of chatbot anthropomorphism operationalized by incorporating a random draw from a set of three anthropomorphic features: humor communication delays and social presence. We provide evidence that in this retail setting anthropomorphism is beneficial for transaction outcomes but that it also leads to significant increases in offer sensitivity. We argue that the latter effect occurs because as a chatbot becomes more human-like consumers shift to a fairness evaluation or negotiating mindset. We also provide descriptive evidence suggesting that the benefits of anthropomorphism for transaction conversion may derive at least in part from consumers' increased willingness to disclose personal information necessary to complete the transaction.;2021
While Interactive systems such as Chatbots are well known in personal environments with technologies like Apple's Siri or the Google's Assistant the acceptance of said technologies in the enterprise context has hardly been examined. Literature shows that these technologies hold great potential for enterprises as they can increase productivity and are cost-efficient by automating processes. Still to not alienate employees when introducing these systems called Enterprise Bots in this paper it is crucial to understand how employees accept and adopt these new systems. This paper derives a research model based on the decomposed Theory of Planned Behaviour which is tested in a survey with 198 participants. Results from a structural equation model show that intrinsic motivation of the employees has a strong positive influence on the intention to use Enterprise Bots whereas external influences showed smaller effects. The results indicate that it is important that employees are convinced of the usefulness of a tool for themselves. The paper provides theoretical insights and helps decision makers to introduce such systems.;2021
With advances in technology new innovative methods for evaluating teamwork skills are emerging however little research has been done into students' reactions to such innovative assessments in an educational setting. This study investigated the reactions of undergraduate students to a high-fidelity behavioral simulation assessment for teamwork skills and explored some of the factors behind those reactions. 168 undergraduate students completed a simulation assessment and filled out surveys of reactions perceptions and personality. The results of a structural equations model indicate that reactions were positively related to perceived scenario realism characters (chatbots) realism and design clarity.;2021
With the advent of conversational voice recognition systems such as Alexa SIRI OK Google etc. natural language conversational scheme including Chatbot and voice recognition systems are in new high and determining the age of a speaker is critical for setting the pertinent context. Age can be inferred from the speech signal by inferring various factors such as physical attributes of voice linguistic attributes frequency speech rate etc. This paper discusses on extracting the spectral features of speech such as Cepstral Coefficients Spectral Decrease Centroid Flatness Spectral EntropyJitter and Shimmer as inputs which would also helps in classifying speaker age through deep learning techniques.A novel approach is addressed along with the model for implementation using Deep Neural Network and Convolutional Neural Network for classifying the features using three different classifiers.The results obtained from the proposed system would outline the performance in speaker age recognition.;2021
With the aim of enhancing human-chatbot interactions this paper presents a novel sentiment classification framework that recognizes both semantics emotion terms and emojis. Underpinned by Word2vec and vector arithmetic a deep model learns the vectors of emotion words and emojis from a large-scale corpus of conversations. The vectors are then assembled into a dictionary evaluated with an improved k-means similarity calculation and assigned to a category of emotions. To accommodate negative grammar constructions e.g. not happyas opposed to unhappy a separate module combines the vectors of negatives and emotion words using vector addition. The final sentiment classification results are derived by calculating the similarity between an utterance and the emotion categories. Experiments show this strategy results in multi-emotion and polarity classifications between 3 and 4% more precise than the next best performing baseline classifier.;2021
With the outbreak of the COVID-19 pandemic misinformation and unscientific interpretations flooded the internet. Seeking credible information in Egypt was paramount at the time. An answer to this quest was 'Ask Nameesa' an award-winning Egyptian-focused chatbot that utilizes Facebook Messenger to communicate with social media users in an individualized response engagement. It relies on information validated by WHO and the Egyptian Ministry of Health. This article examines the structure of Ask Nameesa as an example of infobots and studies the interactive engagement it offers users to provide health information. The study analyses data gathered by interviewing the founder and CEO of DXwand the company that developed Ask Nameesa as well as content analysis of conversations with Ask Nameesa to assess its user engagement. The study aims at understanding the potential Ask Nameesa has in providing information literacy and tackling public demand for information.;2021
With the popularity of financial technology (fintech) chatbots equipped with artificial intelligence understanding the user's response mechanism can help bankers formulate precise marketing strategies which is a crucial issue in the social science field. Nevertheless the user's response mechanism towards financial technology chatbots has been relatively under-investigated. To fill these literature gaps latent growth curve modeling was adopted by the present research to survey Taiwanese users of fintech chatbots. The present study proposed a customer continuance model to predict continuance intention for fintech chatbots and that cognitive and emotional dimensions positively influence the growth in a user's attitude toward fintech chatbots which in turn positively influences continuance intention over time. In total 401 customers of fintech chatbots were surveyed through three time points to examine the relationship between these variables over six months. The results support the theoretical model of this research and can advance the literature of fintech chatbots and the information technology adoption model.;2021
With the prevalence of virtual avatars and the recent emergence of metaverse technology there has been an increase in users who express their identity through an avatar. The research community focused on improving the realistic expressions and non-verbal communication channels of virtual characters to create a more customized experience. However there is a lack in the understanding of how avatars can embody a user's signature expressions (i.e. user's habitual facial expressions and facial appearance) that would provide an individualized experience. Our study focused on identifying elements that may affect the user's social perception (similarity familiarity attraction liking and involvement) of customized virtual avatars engineered considering the user's facial characteristics. We evaluated the participant's subjective appraisal of avatars that embodied the participant's habitual facial expressions or facial appearance. Results indicated that participants felt that the avatar that embodied their habitual expressions was more similar to them than the avatar that did not. Furthermore participants felt that the avatar that embodied their appearance was more familiar than the avatar that did not. Designers should be mindful about how people perceive individuated virtual avatars in order to accurately represent the user's identity and help users relate to their avatar.;2021
With the proliferation of the use of chatbots across industries business-to-business (B2B) businesses have started using cognitive chatbots for improved customer service which signifies our research. By extending the Technology Acceptance Model and Information Systems Success Model this study examines personalised contextual customer service using cognitive chatbot. A quantitative research method is applied to the primary data collected from 300 respondents of B2B businesses. The study contributes to the limited research on chatbots and suggests improvement in customer service. The findings provide evidence of high value by customers particularly while checking for real-time information on reliability and accessibility of products/services. The automated answers to repetitive questions on the recurrent issues create a seamless experience for the customers. This research makes significant theoretical contributions by integrating two models into a simplified model in chatbot literature and manifest that trust affects the willingness to use the cognitive chatbot which drives automation.;2021
With the rapid development from traditional machine learning (ML) to deep learning (DL) and reinforcement learning (RL) dialog system equipped with learning mechanism has become the most effective solution to address human-machine interaction problems. The purpose of this article is to provide a comprehensive survey on learning-based human-machine dialog systems with a focus on the various dialog models. More specifically we first introduce the fundamental process of establishing a dialog model. Second we examine the features and classifications of the system dialog model expound some representative models and also compare the advantages and disadvantages of different dialog models. Third we comb the commonly used database and evaluation metrics of the dialog model. Furthermore the evaluation metrics of these dialog models are analyzed in detail. Finally we briefly analyze the existing issues and point out the potential future direction on the human-machine dialog systems.;2021
With the rise in initiatives such as software ecosystems and Internet of Things (IoT) developing web Application Programming Interfaces (web APIs) has become an increasingly common practice. One main concern in developing web APIs is that they expose back-end systems and data toward clients. This exposure threatens critical non-functional requirements such as the security of back-end systems the performance of provided services and the privacy of communications with clients. Although dealing with non-functional requirements during software design has been long studied there is still no framework to specifically assist software developers in addressing these requirements in web APIs. In this paper we introduce Rational API Designer (RAPID) an open-source assistant that advises on designing non-functional requirements in the architecture of web APIs. We have equipped RAPID with a broad range of expert knowledge about API design systematically collected and extracted from the literature. The API design knowledge has been encoded as a set of 156 rules using the Non-Functional Requirements (NFR) multi-valued logic a formal framework commonly used to describe non-functional and functional requirements of software systems. RAPID uses the encoded knowledge in a stepwise inference procedure to arrive from a given requirement to a set of design alternatives to a final recommendation for a given API design specification. Seven well-experienced software engineers have blindly evaluated the accuracy of RAPID's consultations over seven different cases of web API design and on providing design guidelines for thirty design questions. The results of the evaluation show that RAPID's recommendations meet acceptable standards of the majority of the evaluators 73.3% of the time. Moreover analysis of the evaluators' comments suggests that more than one-third of the unacceptable ratings (33.8%) given to RAPID's answers are due to valid but incomplete design guidelines. We thus expect that the accuracy of the consultations will increase as RAPID's knowledge of API design is extended and refined.;2021
Within the anamnesis medical information is frequently withheld incomplete or incorrect potentially causing negative consequences for the patient. The use of conversational agents (CAs) computer-based systems using natural language to interact with humans may mitigate this problem. The present research examines whether CAs differ from physicians in their ability to elicit truthful disclosure and discourage concealment of medical information. We conducted an online questionnaire with German participants (N = 148) to assess their willingness to reveal medical information. The results indicate that patients would rather disclose medical information to a physician than to a CA there was no difference in the tendency to conceal information. This research offers a frame of reference for future research on applying CAs during the anamnesis to support physicians. From a practical view physicians might gain better understanding of how the use of CAs can facilitate the anamnesis.;2021
A conversational agent (chatbot) is a software that can communicate with humans using natural language. Conversation modeling is an extremely important topic in natural language processing and artificial intelligence (AI). Indeed since the birth of AI creating a good chatbot remains one of the most difficult challenges in this field. Although chatbots can be used for a variety of tasks they generally need to understand what users are saying and to provide appropriate answers to their questions. In this paper we present midoBot: a deep learning Arabic chatbot based on the seq2seq model. midoBot is capable of conversing with humans on popular conversation topics through text. We built the model and tested it in the Tensorflow 2 deep learning framework using the most seq 2 seq Model architectures. We use a dataset of similar to 81659 pairs of conversations created manually and without any handcrafted rules. Our algorithm was trained on a VM on google cloud (GPU TESLA K80 10 GO). The results obtained are significant In most questions the chatbot was able to reproduce good answers.;2022
Although there is an increasingly number of research about the design and use of conversational agents it is still difficult for conversational agents to completely replace human service. Therefore more and more companies have adopted human-AI collaborative systems to deliver customer service. It is important to understand how people obtain information from human-AI collaborative conversations. While the existing work relies on self-reported methods to elicit qualitative feedback from users we have concluded a categorization system for user messages in human-AI collaborative conversations after a thorough examination of a real-world customer service log which could objectively reflect the user's information needs. We categorize user messages into five categories and 15 specific types related to three high-level intentions. Two annotators independently classified the same set of 1478 user messages from 300 conversations and reached a moderate consistency. We summarize and report the characteristics of different message types and compare their usage in sessions with only human AI or both representatives. Our results show that different message types vary significantly in usage frequency length and text similarities with other messages in a session. Also the frequency of using different message types in our dataset seems consistent over sessions with different types of representatives. But we also observed some significant differences in a few specific message types across the sessions with different representatives. Our results are used to suggest some areas for improvement and future work in human-AI collaborative conversational systems.;2022
An idiom is a common phrase that means something other than its literal meaning. Detecting idioms automatically is a serious challenge in natural language processing (NLP) domain appli-cations like information retrieval (IR) machine translation and chatbot. Automatic detection of Idioms plays an important role in all these applications. A fundamental NLP task is text classi-fication which categorizes text into structured categories known as text labeling or categoriza-tion. This paper deals with idiom identification as a text classification task. Pre-trained deep learning models have been used for several text classification tasks though models like BERT and RoBERTa have not been exclusively used for idiom and literal classification. We propose a pre-dictive ensemble model to classify idioms and literals using BERT and RoBERTa fine-tuned with the TroFi dataset. The model is tested with a newly created in house dataset of idioms and literal expressions numbering 1470 in all and annotated by domain experts. Our model outperforms the baseline models in terms of the metrics considered such as F-score and accuracy with a 2% improvement in accuracy.;2022
Artificial intelligence (AI) is rapidly reconstructing consumer experiences with brands in recent years. However there have been the unsettled debates on whether humans react to robots (e.g. chatbots) in the same way as they do to other humans and how the intrinsic strength of AI (i.e. autonomous processing and synthetization of information) and humans (i.e. emotional intelligence) factor in the human-AI interactions in brand communication settings. Hence this study investigates the conditions under which a service entity of a brand can optimize their potential. To this end the current study conceptualizes and operationalizes two dimensions that define chatbots' capabilities - message contingency (i.e. contingency-based interactivity) and emotional intelligence (i.e. sympathy). Based on two experiments we found that regarding the same online customer service of an apparel brand participants rated the human employee to be more competent and warmer than a chatbot. When a human employee who expresses sympathy to the afflicted customer during the conversation participants considered the employee to be more competent when he/she also exhibits contingency (vs. no contingency) during the conversation which in turn elicited higher patronage intentions among participants.;2022
As organizations increasingly adopt artificial intelligence (AI) systems for their online communication with publics conceptualizing and operationalizing perceived humanness presents an important challenge to understanding how consumers and other publics respond to both AI and human agents in live chats with organizations. This study develops a measure of consumer-perceived humanness derived from three related constructs: conversational human voice anthropomorphism and social presence. The new measure was tested for reliability and validity including tests of criterion validity predicting how it would relate to perceived relational investment and trust as relational outcomes. Two online studies (N-1 = 172 N-2 = 375) were conducted in which participants interacted with either human or machine online chat agents. Greater perceived humanness of chat agents was found to correlate with greater perceived relational investment and trust in the organization with perceived relational investment mediating the relationship between perceived humanness and trust. Perceived humanness can be utilized subsequently to assess both human and machine agents. Its corollary perceived machineness was also identified as a separate factor to be taken into consideration in future research and theory building.;2022
Avatars are becoming increasingly popular in contemporary marketing strategies but their effectiveness for achieving performance outcomes (e.g. purchase likelihood) varies widely in practice. Related academic literature is fragmented lacking both definitional consistency and conceptual clarity. This article makes three main contributions to avatar theory and managerial practice. First to address ambiguity with respect to its definition this study identifies and critically evaluates key conceptual elements of the term avatar offers a definition derived from this analysis and provides a typology of avatars' design elements. Second the proposed 2 x 2 avatar taxonomy suggests that the alignment of an avatar's form realism and behavioral realism across different contingencies provides a parsimonious explanation for avatar effectiveness. Third the authors develop an emerging theory of avatar marketing by triangulating insights from fundamental elements of avatars a synthesis of extant research and business practices. This framework integrates key theoretical insights research propositions and important managerial implications for this expanding area of marketing strategy. Lastly the authors outline a research program to test the propositions and insights as well as advance future research.;2022
Background The use of chatbots as learning assistants is receiving increasing attention in language learning due to their ability to converse with students using natural language. Previous reviews mainly focused on only one or two narrow aspects of chatbot use in language learning. This review goes beyond merely reporting the specific types of chatbot employed in past empirical studies and examines the usefulness of chatbots in language learning including first language learning second language learning and foreign language learning. Aims The primary purpose of this review is to discover the possible technological pedagogical and social affordances enabled by chatbots in language learning. Materials & Methods We conducted a systematic search and identifies 25 empirical studies that examined the use of chatbots in language learning. We used the inductive grounded approach to identify the technological and pedagogical affordances and the challenges of using chatbots for students' language learning. We used Garrison's social presence framework to analyze the social affordances of using chatbots in language learning Results Our findings revealed three technological affordances: timeliness ease of use and personalization and five pedagogical uses: as interlocutors as simulations for transmission as helplines and for recommendations. Chatbots appeared to encourage students' social presence by affective open and coherent communication. Several challenges in using chatbots were identified: technological limitations the novelty effect and cognitive load. Discussion and Conclusion A set of rudimentary design principles for chatbots are proposed for meaningfully implementing educational chatbots in language learning and detailed suggestions for future research are presented.;2022
Chatbots are intelligent conversational agents that can interact with users through natural languages. As chatbots can perform a variety of tasks many companies have committed numerous resources to develop and deploy chatbots to enhance various business processes. However we lack an up-to-date critical review that thoroughly examines both state-of-the-art technologies and innovative applications of chatbots. In this review we not only critically analyze the various computational approaches used to develop state-of-the-art chatbots but also thoroughly review the usability and applications of chatbots for various business sectors. We also identify gaps in chatbot-related studies and propose new research directions to address the shortcomings of existing studies and applications. Our review advances both academic research and practical business applications of state-of-the-art chatbots. We provide guidance for practitioners to fully realize the business value of chatbots and assist in making sensible decisions related to the development and deployment of chatbots in various business contexts. Researchers interested in the design and development of chatbots can also gain useful insights from our critical review and identify fruitful research topics and future research directions based on the research gaps discussed herein. This article is categorized under: Technologies > Machine Learning Application Areas > Business and Industry;2022
Chatbots have become common in digital customer service contexts across many industries. While many companies choose to humanize their customer service chatbots (e.g. giving them names and avatars) little is known about how anthropomorphism influences customer responses to chatbots in service settings. Across five studies including an analysis of a large real-world data set from an international telecommunications company and four experiments the authors find that when customers enter a chatbot-led service interaction in an angry emotional state chatbot anthropomorphism has a negative effect on customer satisfaction overall firm evaluation and subsequent purchase intentions. However this is not the case for customers in nonangry emotional states. The authors uncover the underlying mechanism driving this negative effect (expectancy violations caused by inflated pre-encounter expectations of chatbot efficacy) and offer practical implications for managers. These findings suggest that it is important to both carefully design chatbots and consider the emotional context in which they are used particularly in customer service interactions that involve resolving problems or handling complaints.;2022
Collecting construction equipment information such as the site equipment enter and exit date-time driver's name type and quantity is essential in construction management. Most construction projects use paper to record the equipment access history. However manual recording is always labour-intensive and time-consuming. Therefore this research aims to develop an assistant system Site Equipment Management Assistant (SEMA) to automate the site equipment management processes. With the introduction of image recognition and multiple objects tracking technologies the proposed system can extract equipment-related information from raw videos. SEMA is designed as a chatbot system that contains three major modules: data acquisition information extraction and information delivery. A deep learning-based model was first trained to automatically recognize and track construction equipment passing by the site monitor. Information such as equipment entering and exiting date-time type and quantity would be extracted and stored in a database. A chatbot interface was developed for users to obtain data from the database through an intuitive and easy-to-use interface. A system evaluation and usability test were conducted. The results showed that the system could effectively improve the construction equipment management process. SEMA can save 60.7% of users' operation time on obtaining related information.;2022
Considering that emotions have a great impact on motivation reasoning and decision making affective computing methods that were designed to attempt to understand and respond to human emotional states have been used in more than one field including e-learning. Thus a systematic literature review was conducted on 4 search engines resulting in a set of papers that were filtered in a systematic way until we obtained a corpus of 27 papers. Data were extracted to answer four research questions concerning the use and efficacy of affective computing in e-learning in recent years. We found out that the majority of studies about emotion recognition use uni-modal systems in which facial expressions emotion detection is the most present. The major research purpose is designing/building systems approaches methods detectors for emotion recognition. For the e-learning environments the most present is conversational agents. The emotions detected or used are basic emotions non-basic emotions learning-centered emotions trait emotions or a combination of two or three of them. This systematic literature review also provides the major findings challenges and future research.;2022
Conversational agents (CAs) are often unable to provide meaningful responses to user requests thereby triggering user resistance and impairing the successful diffusion of CAs. Literature mostly focuses on improving CA responses but fails to address user resistance in the event of further response failures. Drawing on inoculation theory and the elaboration likelihood model we examine how inoculation messages as communication that seeks to prepare users for a possible response failure can be used as an alleviation mechanism. We conducted a randomized experiment with 558 users investigating how the performance level (high or low) and the linguistic form of the performance information (qualitative or quantitative) affected users' decision to discontinue CA usage after a response failure. We found that inoculation messages indicating a low performance level alleviate the negative effects of CA response failures on discontinuance. However quantitative performance level information exhibits this moderating effect on users' central processing while qualitative performance level information affected users' peripheral processing. Extending studies that primarily discuss ex-post strategies our results provide meaningful insights for practitioners.;2022
Conversational agents (CAs) offer new functionality and convenience. While their sales have been soaring they have also rapidly become victims of verbal abuse by their users. Without proper handling of abusive usage abusers' actions can be reinforced and transferred to real life. This study investigates whether alternative response styles of empathy orientation and emotional expressivity of voice-activated virtual assistants influence users' moral emotions found to reduce verbal aggression as well as whether they affect user perceptions of the agent's capability. Ninety-eight participants were assigned to one of the three emotional expressivity conditions (no-facial expression fixed-facial expression varied-facial expression) and interacted with two alternative empathy orientation conditions (other-oriented self-oriented) of agents. The experimental results show that regardless of the emotional expressivity types the agent's empathy orientation has a significant effect on the moral emotions and agent capability perceptions. Overall an agent that employed other-oriented empathy style elicited most positive responses from the users. However the preference was not across the board as about one-third of the participants showed preference to the self-oriented CA. Users valued agents' verbal contents and vocal characteristics above their facial expressions. Based on the study findings we draw several design guidelines and suggest avenues for future research.;2022
Conversational agents are systems capable of processing and responding to human language. They have evolved over the years from a means to pass the Turing Test to chatbots that fulfill a utilitarian purpose. Closed-domain chatbots are specialized in a specific knowledge base and are often used in an attempt to assist users in an educational context. Existing open-source educational assistant chatbots are narrow in immediate functionality thus limiting the content and services that can be provided to students and educators. To address this limitation a novel multiagent framework is proposed providing diverse capabilities and component flexibility to better meet varied educational requirements. The version presented in this experiment can not only answer questions in different styles but is also able to provide content summaries and links. The solution is tested by presenting participants with a lesson containing information related to coronavirus disease 2019 (COVID-19) followed by engagement with the chatbot system a subsequent evaluation of its responses and a quiz to quantify its pedagogical efficacy. COVID-19 was chosen as the knowledge base due to its current relevance in society. The chatbot framework's knowledge base is comprised of two data sets containing facts related to the virus one which is used to provide longer frequently asked questions-type responses and another used to provide short answers. The resulting participant evaluations indicate a preference for more informative responses in the experimental context and showcase the benefit of the framework's malleability in not only fulfilling but discovering varying needs in educational assistance.;2022
Conversational agents or chatbots are a novel highly accessible and low-resource method of psychological intervention delivery. The present research aims to compare two brief chatbot interventions that delivered cognitive restructuring and defusion interventions respectively. It was hypothesized that a defusion chatbot would lead to reduced cognitive fusion and decreased thought believability relative to cognitive restructuring and a nonactive control. Participants (N = 223 M age of 28.01 [SD = 10.29] 47 identified as male 174 as female and 2 as nonbinary) were randomized into one of three conditions (defusion restructuring control) engaged for 5 days completing thought and mood measures pre- and postintervention. Sixty-two participants (M age of 25.98 SD = 8.647 years) completed measures again at time 2 (49 identified as female 12 as male and 1 as nonbinary). No statistically significant differences were observed among groups on believability of thoughts (F[2 25] = .79 p = .47 eta p(2) = .06) negativity of thoughts (F[225] = 1.49 p = .25 eta (2) = .11) discomfort associated with thoughts (F[2 25] = .48 p = .62 eta p(2) = .04) and willingness (F[2 25] = 3.00 p = .07 eta p(2) = .19) to have negative self-referential thoughts. Moreover substantial attrition of 72% was observed. Acceptability and usability of the chatbots employed are discussed as contributing toward the limited effectiveness of interventions and elevated attrition. Various recommendations are presented to support researchers and clinicians in developing engaging and effective chatbots.;2022
Creation of task-oriented dialog/virtual agent (VA) capable of managing complex domain-specific user queries pertaining to multiple intents is difficult since the agent must deal with several subtasks simultaneously. Most end-to-end dialogue systems however only provide user semantics as inputs from texts into the learning process and neglect other useful user behaviour and information from other modalities such as images. This stresses the benefit of incorporating multi-modal inputs for eliciting user preference in the task. Also sentiment of the user plays a significant role in achieving maximum user/customer satisfaction during the conversation. Thus it is also important to incorporate users' sentiments during policy learning especially when serving user's composite goals. For the creation of multi-modal VA aided with sentiment for conversations encompassing multi-intents this paper introduces a new dataset named Vis-SentiVA: Visual and Sentiment aided VA created from open-accessed conversational dataset. We present a hierarchical reinforcement learning (HRL) typically options-based VA to learn policies for serving multi-intent dialogues. Multi-modal information (texts and images) extraction to identify user's preference is incorporated in the learning framework. A combination of task-based and sentiment-based rewards is integrated in the hierarchical value functions for the VA to be user adaptive. Empirically we show that all these aspects induced together in the learning framework play a vital role in acquiring higher dialogue task success and increased user contentment in the process of creating composite-natured VAs. This is the first effort in integrating sentiment-aware rewards in the multi-modal HRL framework. The paper highlights that it is indeed essential to include other modes of information extraction such as images and behavioural cues of the user such as sentiment to secure greater user contentment. This also helps in improving success of composite-natured VAs serving task-oriented dialogues.;2022
Depression is a common illness worldwide with potentially severe implications. Early identification of depressive symptoms is a crucial first step towards assessment intervention and relapse prevention. With an increase in data sets with relevance for depression and the advancement of machine learning there is a potential to develop intelligent systems to detect symptoms of depression in written material. This work proposes an efficient approach using Long Short-Term Memory (LSTM)-based Recurrent Neural Network (RNN) to identify texts describing self-perceived symptoms of depression. The approach is applied on a large dataset from a public online information channel for young people in Norway. The dataset consists of youth's own text-based questions on this information channel. Features are then provided from a one-hot process on robust features extracted from the reflection of possible symptoms of depression pre-defined by medical and psychological experts. The features are better than conventional approaches which are mostly based on the word frequencies (i.e. some topmost frequent words are chosen as features from the whole text dataset and applied to model the underlying events in any text message) rather than symptoms. Then a deep learning approach is applied (i.e. RNN) to train the time-sequential features discriminating texts describing depression symptoms from posts with no such descriptions (non-depression posts). Finally the trained RNN is used to automatically predict depression posts. The system is compared against conventional approaches where it achieved superior performance than others. The linear discriminant space clearly reveals the robustness of the features by generating better clustering than other traditional features. Besides since the features are based on the possible symptoms of depression the system may generate meaningful explanations of the decision from machine learning models using an explainable Artificial Intelligence (XAI) algorithm called Local Interpretable Model-Agnostic Explanations (LIME). The proposed depression symptom feature-based approach shows superior performance compared to the traditional general word frequency-based approaches where frequency of the features gets more importance than the specific symptoms of depression. Although the proposed approach is applied on a Norwegian dataset a similar robust approach can be applied on other depression datasets developed in other languages with proper annotations and symptom-based feature extraction. Thus the depression prediction approach can be adopted to contribute to develop better mental health care technologies such as intelligent chatbots.;2022
Dialogic reading when children are read a storybook and engaged in relevant conversation is a powerful strategy for fostering language development. With the development of artificial intelligence conversational agents can engage children in elements of dialogic reading. This study examined whether a conversational agent can improve children's story comprehension and engagement as compared to an adult reading partner. Using a 2 (dialogic reading or non-dialogic reading) x 2 (agent or human) factorial design a total of 117 three- to six-year-olds (50% Female 37% White 31% Asian 21% multi-ethnic) were randomly assigned into one of the four conditions. Results revealed that a conversational agent can replicate the benefits of dialogic reading with a human partner by enhancing children's narrative-relevant vocalizations reducing irrelevant vocalizations and improving story comprehension.;2022
Digital personal assistants (DPAs) have recently grown in popularity because they are both a commercially available new technology and reasonably affordable to the average household. This opens opportunities for new ways to assist people in everyday activities in their homes through voice-interaction. Physical activity has significant health benefits and yet globally 1 in 4 adults are not active enough. To address this we investigate the persuasive potential of DPAs in increasing people's physical activity at home. We conducted a study with 48 participants to understand the effect of applying three of Fogg's persuasive principles to the design of a DPA exercise programme: Suggestion Virtual Reward and Praise. Our findings show that DPAs have the potential within their current technical and reactive capabilities to persuade people to increase their physical activity at home using Suggestion to encourage physical effort Virtual Reward to encourage endurance and Praise to create reassurance for beginners. Based on this we offer three alternate perspectives for developing persuasive DPAs. We also discuss limitations of the study and suggest future research directions around using persuasion with DPAs.;2022
Emotionally-responsive chatbots are marketed as agents with which one can form emotional connections. They can also become weak ties in the outer layers of one's acquaintance network and available for social support. In this experiment which was designed to study the acquaintance process we randomly assigned 417 participants into three conditions: face-to-face (FTF) chat with a human online chat with a human and online chat with a commercially-available emotionally-responsive chatbot Replika. After a 20-min getting-acquainted chat participants reported their affective state and relational evaluations of the chat. Additionally all chats were recorded and text analyzed using the Linguistic Inquiry and Word Count (LIWC) program. In all conditions participants reported moderate levels of positive emotions and low levels of negative emotions. Those who chatted FTF with a human reported significantly more negative emotions than those who chatted with a bot. However those who chatted with a human also reported more homophily with and liking of their chat partner and that their partner was more responsive. Meanwhile participants had fewest conversational concerns with the chatbot. These findings have implications for future computer-mediated interaction studies: conversations with chatbots appear to have different affordances and effects on chatter enjoyment and conversational concerns in getting-acquainted contexts. These results may help designers improve reception and marketability for chatbots in consumer markets.;2022
Emotion-aware chatbots that can sense human emotions are becoming increasingly prevalent. However the exposition of emotions by emotion-aware chatbots undermines human autonomy and users' trust. One way to ensure autonomy is through the provision of control. Offering too much control in turn may increase users' cognitive effort. To investigate the impact of control over emotion-aware chatbots on autonomy trust and cognitive effort as well as user behavior we carried out an experimental study with 176 participants. The participants interacted with a chatbot that provided emotional feedback and were additionally able to control different chatbot dimensions (e.g. timing appearance and behavior). Our findings show first that higher control levels increase autonomy and trust in emotion-aware chatbots. Second higher control levels do not significantly increase cognitive effort. Third in our post hoc behavioral analysis we identify four behavioral control strategies based on control feature usage timing quantity and cognitive effort. These findings shed light on the individual preferences of user control over emotion-aware chatbots. Overall our study contributes to the literature by showing the positive effect of control over emotion-aware chatbots and by identifying four behavioral control strategies. With our findings we also provide practical implications for future design of emotion-aware chatbots.;2022
Every larger organisation must establish a set of normative documents to control its processes and describe solutions to common problems. These documents are usually formally written and hard to read. This leads to the necessity off different customer services. Nowadays a lot of companies are developing chatbots to automate firstline customer support. If a company does not have a large question-answer dataset to build a chatbot the answers can be automatically answered directly from the documents. However we found that the automatic answering usually does not work well on the normative documents. In this paper we describe a novel method for preprocessing of normative documents in order to use them for such automatic question answering. Our method efficiently exploits the strict document structure that is typical for normative documents. The method enabled us to increase the recall from 35% to 84% (for paragraph-size answers) on selected normative documents from university and bank domains.;2022
Generating semantically and emotionally context-consistent responses is key to intelligent dialogue systems. Previous works mainly refer to the context in the dialogue history to generate semantically related responses ignoring the potential emotion in the conversation. In addition existing methods mainly fail to consider the emotional changes of interlocutors and emotional categories simultaneously. However emotion is crucial to reflect the interlocutor's intent. In this paper we propose an Emotion Capture Chat Machine (ECCM) that is able to capture the explicit and underlying emotional signal in the context to generate appropriate responses. In detail we design a hierarchical recursive encoder-decoder framework with two enhanced self-attention encoders to capture the semantic signal and emotional signal respectively which are then fused in the decoder to produce the response. In general we consider the dynamic and potential information of emotion to generate the response in multi-turn dialogues in the field of both daily conversation and psychological counseling. Our experimental results on a daily Chinese conversation dataset and a psychological counseling dataset show that ECCM outperforms the state-of-the-art baselines in terms of Perplexity Distinct-1 Distinct-2 and manual evaluation. In addition we find that ECCM performs well for input contexts with different lengths.;2022
Health chatbots interview patients and collect health data. This process makes demands on data security and data privacy. To identify how and to what extent security and privacy are considered in current health chatbots. We conducted a scoping review by searching three bibliographic databases (PubMed ACM Digital Library IEEExplore) for papers reporting on chatbots in healthcare. We extracted which how and where data is stored by health chatbots and identified which external services have access to the data. Out of 1026 retrieved papers we included 70 studies in the qualitative synthesis. Most papers report on chatbots that collect and process personal health data usually in the context of mental health coaching applications. The majority did not provide any information regarding security or privacy aspects. We were able to determine limitations in literature and identified concrete challenges including data access and usage of (third-party) services data storage data security methods use case peculiarities and data privacy as well as legal requirements. Data privacy and security in health chatbots are still underresearched and related information is underrepresented in scientific literature. By addressing the five key challenges in future the transfer of theoretical solutions into practice can be facilitated.;2022
Healthcare systems across the world are transitioning into patient-centered healthcare models to ensure improved health outcomes increased operational efficiencies and respectful patient engagement. Digital health technologies are at the forefront of this transition in facilitating a role for the patient in the clinical dimensions of the healthcare trajectory from diagnosis and interventions to treatment and recovery. Despite this prevalence in the clinical space the non-clinical needs of patient mental health and wellbeing are frequently overlooked by contemporary patient-centered healthcare models. Conversational agents (or chatbots) are digital dialogue systems that are widespread and widely used in sequential information provision and information acquisition tasks. Given the intimate nature of this human-machine interaction conversational agents can be effectively utilized to support and sustain patient mental health and wellbeing. In this paper we propose an empathic conversational agent framework based on an ensemble of natural language processing techniques and artificial intelligence algorithms for real-time monitoring and co-facilitation of patient-centered healthcare for improved mental health and wellbeing outcomes. The technical contributions of this framework are detection of patient emotions prediction of patient emotion transitions detection of group emotions formulation of patient behavioral metrics and resource recommendations based on patient concerns. The architectural contributions of the framework are intelligent communication channels that stream empathic conversational elements and resource recommendations for the multi-user conversations and co-facilitation updates for the human healthcare provider interface. The framework was empirically evaluated on a benchmark dataset and further validated based on a clinical protocol designed for its application in an online support group setting for cancer patients and caregivers in Canada. The results of these experiments confirm the effectiveness of this framework its contributory role and practical value in realizing a patient-centered healthcare model for improved mental health and wellbeing outcomes. (C) 2021 Elsevier B.V. All rights reserved.;2022
How do cultural values influence/are influenced by algorithms? A comparative study was conducted between the United States (US) and the United Arab Emirates (UAE) to investigate how users in the different cultures perceive the features of chatbot-driven news and how they view ethical issues concerning chatbot journalism. Different models of chatbot news perception reveal that the acceptance of chatbots involves a cultural dimension as the algorithms reflect the values and interests of their constituencies. How users perceive chatbot news and how they consume and interact with the chatbots depend on the cultural and social contexts in which the interaction is taking place. Our results suggest the algorithms reflect cultural values and algorithms are implicitly situated in social contexts mediated by cultural artifacts and activities. The results resonate with ongoing debates on whether and how algorithms reinforce cultural and social values implying the co-evolving nature of algorithms and humans.;2022
In this paper we propose a speech pseudonymization framework that utilizes cascaded and superposition-based voice modification modules. With increasing opportunities to use spoken dialogue systems nowadays research regarding protecting the privacy of speaker information encapsulated in speech data is attracting attention. Pseudonymization which is one method for voice privacy protection aims to keep the intelligibility of speech while simultaneously suppressing speaker-specific information. One motivation of our framework is to achieve a reliable pseudonymization performance with light computation. To do this we utilize the advantages of both machine learning-based and signal processing-based approaches. The advantages are (1) using signal processing-based methods parameterized with few hyperparameters and (2) using machine learning-based optimization to optimize all hyperparameters on the basis of black-box systems consisting of automatic speaker verification and automatic speech recognition. Our method of cascading signal processing modules which are jointly optimized in a data-driven manner can pseudonymize speech in a lightweight manner. Additionally we discuss irreversible pseudonymization approaches and propose a superposition approach yet another pseudonymization method that is more irreversible than the cascade method in terms of estimating the adequate parameters to recover the original signal. From the experimental results conducted under the VoicePrivacy 2020 protocols we can demonstrate that (1) our cascade method succeeds in deteriorating the speaker recognition rate by over 24% while simultaneously improving the speech recognition rate by approximately 8% compared with a signal processing-based baseline system of VoicePrivacy 2020 and that (2) our superposition method works comparable to our cascade method in terms of pseudonymization performance.;2022
Many experts have emphasised that chatbots are not sufficiently mature to be able to technically diagnose patient conditions or replace the judgements of health professionals. The COVID-19 pandemic however has significantly increased the utilisation of health-oriented chatbots for instance as a conversational interface to answer questions recommend care options check symptoms and complete tasks such as booking appointments. In this paper we take a proactive approach and consider how the emergence of task-oriented chatbots as partially automated consulting systems can influence clinical practices and expert-client relationships. We suggest the need for new approaches in professional ethics as the large-scale deployment of artificial intelligence may revolutionise professional decision-making and client-expert interaction in healthcare organisations. We argue that the implementation of chatbots amplifies the project of rationality and automation in clinical practice and alters traditional decision-making practices based on epistemic probability and prudence. This article contributes to the discussion on the ethical challenges posed by chatbots from the perspective of healthcare professional ethics.;2022
Mobile apps in mental health have seen a significant growth in recent years. Most of them are aimed at treating depression anxiety and stress disorders using cognitive behavioural therapy methods and relatively few apps are being developed to address interpersonal issues. This study tested the effectiveness of the iCognito Relationship Program a self-help application for couple relationships based on the chatbot technology. A between-group experimental study was conducted in Russia using the bibliotherapy as a control condition (N = 58 female sample) with results showing that after 2 weeks iCognito's users had increased satisfaction tenderness constructive communication as well as commitment to the relationship. Also indicators for relationship self-efficacy communicative skills in relationships and self-esteem regarding relationship skills had significantly increased while level of conflicts had decreased. A medium effect size was reported for most indicators. The participants of an experimental group expressed a high level of satisfaction with the technology and a generally positive attitude towards the idea of working with a virtual psychologist-chatbot on their personal issues. Despite the need to reproduce the research results iCognito program demonstrates that both mobile application and chatbot technologies can be useful for training individuals' relationship satisfaction and communication skills and that they can be more efficient in increasing satisfaction and reducing conflict in relationships than self-help books.;2022
Modern-day demands for services often require an availability on a 24/7 basis as well as online accessibility around the globe. For this sake personalized virtual assistants called chatbots are implemented. Such systems offer services goods or information in natural language. These natural language processing (NLP) programs respond to the user in real time and offer an intuitive and simple interface to interact with. Advantages like these make them increasingly popular. Therefore ensuring correct functionality of chatbots is of increasing importance. However since different implementations and user behaviour result in unpredictable results the chatbot's input and output data are difficult to predict and classify as well. Under such circumstances test cases can be inferred from the domain of possible inputs of a system under test (SUT). Ontologies are concepts used in AI to provide formal representations of knowledge for a specific domain. Such ontological models contain structured information that is used for test generation. On the other hand testing of chatbots represents a challenge because of the absence of a test oracle. In this paper both challenges are addressed by conceptualizing ontologies for input generation and output processing in form of a metamorphic testing approach. In this scenario both concepts are applied for automated testing of chatbots. The approach is demonstrated on a real system from the tourism domain thereby discussing the obtained results.;2022
Objective Prevention of eating disorders (EDs) is of high importance. However digital programs with human moderation are unlikely to be disseminated widely. The aim of this study was to test whether a chatbot (i.e. computer program simulating human conversation) would significantly reduce ED risk factors (i.e. weight/shape concerns thin-ideal internalization) in women at high risk for an ED compared to waitlist control as well as whether it would significantly reduce overall ED psychopathology depression and anxiety and prevent ED onset. Method Women who screened as high risk for an ED were randomized (N = 700) to (1) chatbot based on the StudentBodies (c) program or (2) waitlist control. Participants were followed for 6 months. Results For weight/shape concerns there was a significantly greater reduction in intervention versus control at 3- (d = -0.20 p = .03) and 6-m-follow-up (d = -0.19 p = .04). There were no differences in change in thin-ideal internalization. The intervention was associated with significantly greater reductions than control in overall ED psychopathology at 3- (d = -0.29 p = .003) but not 6-month follow-up. There were no differences in change in depression or anxiety. The odds of remaining nonclinical for EDs were significantly higher in intervention versus control at both 3- (OR = 2.37 95% CI [1.37 4.11]) and 6-month follow-ups (OR = 2.13 95% CI [1.26 3.59]). Discussion Findings provide support for the use of a chatbot-based EDs prevention program in reducing weight/shape concerns through 6-month follow-up as well as in reducing overall ED psychopathology at least in the shorter-term. Results also suggest the intervention may reduce ED onset. Public Significance We found that a chatbot or a computer program simulating human conversation based on an established cognitive-behavioral therapy-based eating disorders prevention program was successful in reducing women's concerns about weight and shape through 6-month follow-up and that it may actually reduce eating disorder onset. These findings are important because this intervention which uses a rather simple text-based approach can easily be disseminated in order to prevent these deadly illnesses. Trial registration: OSF Registries;2022
Purpose Artificial intelligence (AI)-based chatbots have brought unprecedented business potential. This study aims to explore consumers' trust and response to a text-based chatbot in e-commerce involving the moderating effects of task complexity and chatbot identity disclosure. Design/methodology/approach A survey method with 299 useable responses was conducted in this research. This study adopted the ordinary least squares regression to test the hypotheses. Findings First the consumers' perception of both the empathy and friendliness of the chatbot positively impacts their trust in it. Second task complexity negatively moderates the relationship between friendliness and consumers' trust. Third disclosure of the text-based chatbot negatively moderates the relationship between empathy and consumers' trust while it positively moderates the relationship between friendliness and consumers' trust. Fourth consumers' trust in the chatbot increases their reliance on the chatbot and decreases their resistance to the chatbot in future interactions. Research limitations/implications Adopting the stimulus-organism-response (SOR) framework this study provides important insights on consumers' perception and response to the text-based chatbot. The findings of this research also make suggestions that can increase consumers' positive responses to text-based chatbots. Originality/value Extant studies have investigated the effects of automated bots' attributes on consumers' perceptions. However the boundary conditions of these effects are largely ignored. This research is one of the first attempts to provide a deep understanding of consumers' responses to a chatbot.;2022
Purpose Artificial intelligence chatbots are shifting the nature of online services by revolutionizing the interactions of service providers with consumers. Thus this study aims to explore the antecedents (e.g. compatibility perceived ease of use performance expectancy and social influence) and consequences (e.g. chatbot usage intention and customer engagement) of chatbot initial trust. Design/methodology/approach A sample of 184 responses was collected in Lebanon using a questionnaire and analyzed using structural equation modeling (SEM) by AMOS 24. Findings The results revealed that except for performance expectancy all the other three factors (compatibility perceived ease of use and social influence) significantly boost customers' initial trust toward chatbots. Further initial trust in chatbots enhances the intention to use chatbots and encourages customer engagement. Research limitations/implications The study provides insights into some variables influencing initial chatbot trust. Future studies could extend the model by adding other variables (e.g. customer experience and attitude) in addition to exploring the dark side of artificial intelligence chatbots. Practical implications This study suggests key insights for marketing managers on how to build chatbot initial trust which in turn will lead to an increase in customers' interactions with the brand. Originality/value The current study marks substantial contributions to the artificial intelligence marketing literature by proposing and testing a novel conceptual model that examines for the first time the factors that impact chatbot initial trust and the key outcomes of the latter.;2022
Purpose Chatbots are increasingly prevalent in the service frontline. Due to advancements in artificial intelligence chatbots are often indistinguishable from humans. Regarding the question whether firms should disclose their chatbots' nonhuman identity or not previous studies find negative consumer reactions to chatbot disclosure. By considering the role of trust and service-related context factors this study explores how negative effects of chatbot disclosure for customer retention can be prevented. Design/methodology/approach This paper presents two experimental studies that examine the effect of disclosing the nonhuman identity of chatbots on customer retention. While the first study examines the effect of chatbot disclosure for different levels of service criticality the second study considers different service outcomes. The authors employ analysis of covariance and mediation analysis to test their hypotheses. Findings Chatbot disclosure has a negative indirect effect on customer retention through mitigated trust for services with high criticality. In cases where a chatbot fails to handle the customer's service issue disclosing the chatbot identity not only lacks negative impact but even elicits a positive effect on retention. Originality/value The authors provide evidence that customers will react differently to chatbot disclosure depending on the service frontline setting. They show that chatbot disclosure does not only have undesirable consequences as previous studies suspect but can lead to positive reactions as well. By doing so the authors draw a more balanced picture on the consequences of chatbot disclosure.;2022
Purpose Current possibilities of accessing business data by regular users usually involve complicated user interfaces or require technical expertise. This results in situations when business owners are separated from their data. The aim of this research is to apply an innovative approach leveraging conversational interfaces to tackle this problem. Design/methodology/approach The authors examine the current possibilities of accessing business data by business users with an emphasis on conversational interfaces employing a chatbot as an alternative to traditional approaches. The authors propose a new concept relying on a guided conversation and through experiments with a real chatbot and database the authors demonstrate the benefits of the proposed approach. Findings The authors found out that the key to the success of our approach is a decomposition of complex database queries and their incremental construction in conversations. This also enables natural discovery of the domain model through constantly provided feedback. Based on the experiments with a real chatbot the authors demonstrate that defining conversation flows and maintaining the conversation context is a crucial aspect contributing to the overall accuracy together with keeping the conversation within the defined limits in its certain parts. Originality/value The authors present a novel approach using natural language interfaces for accessing data by business users. In contrast to existing approaches the authors emphasize incremental construction of queries predefined conversation flows and constraining the conversations when necessary.;2022
Purpose The purpose of this study is to empirically examine the impact of technology-enabled service co-creation on patients' service patronage behaviour in healthcare retailing. The first objective is to examine the mediating roles of spatial presence and co-presence in the relationship between technology enabled co-creation and service experience. The second objective is to investigate if healthcare service experience impacts patients' relationship value with hospitals and subsequent patronage intention. Design/methodology/approach Data were collected from a sample of 516 customers of three leading hospitals in India during the social isolation period of COVID-19. The data were analysed using structural equation modelling. Findings The study results demonstrate that customers' favourably perceived technology-enabled co-creation generates feelings of spatial presence and co-presence in the technology-enabled platform. The feeling of presence enhances patients' health care service experiences which in turn predict their relationship value perceptions towards the healthcare service provider. Co-presence dominates as a mediator in terms of magnitude over spatial presence. The favourable value perception positively impacts patients' intention to come back to the same hospital. Research limitations/implications The study uses cross-sectional data which does not incorporate any temporal variations in the investigated relationships. The study does not account for differences in government vs. private undertakings of healthcare system. Practical implications The findings envisage a digital healthcare retail system where hospitals can enhance patients' perceptions of healthcare service experience relational value and re-patronage intention based on the digital mediated environment design elements i.e. spatial presence and co-presence. As co-presence is a dominant factor ensuring that human healthcare experts (rather than technology based e-service elements like chatbots) participate in healthcare service co-creation is of prime importance to provide enriching service experience to the patients. Originality/value The value of the research lies in extending the theories of presence UTAUT and S-O-R to understand digital healthcare retailing in order to identify the mechanism of how online co-creative platform can generate hospital patronage behaviour among patients through the serial mediation of presence augmented service experience and relationship value.;2022
Purpose This study aims to explore the role of artificial intelligence (AI)-powered chatbot marketing efforts (CMEs) in the establishment of relationships between brands and their customers extending the link between relationship marketing and online consumer behavioral intentions. Design/methodology/approach Data are collected from 1072 customers in the USA who used chatbot marketing activities from any of 30 brands leading their industries in messaging innovation. Structural equation modeling is used for data analysis. Findings Results show that interaction information accessibility entertainment and customization are important CMEs components. CMEs have significant direct effects on the quality of communication with chatbot agents and indirectly affect customer-brand relationships (CBR) and customer response. In addition the findings demonstrate that CBR mediates the association between communication quality and customer response. Originality/value Implications of this study can enable practitioners to understand the effects of AI on user experiences and provide a guide for the development of CMEs strategies and relationship building.;2022
Rapid advances in Natural Language Processing (NLP) are transforming customer service by making it possible to create chatbot applications that can understand users' intents and response in a human-like manner. Chatbots promise to enhance customer experiences by creating more personal customer interactions than those afforded by traditional menu-based web applications. But are chatbots always superior to more traditional user interfaces (UI)? This study seeks to understand the differences in user satisfaction with a chatbot system vis-a-vis a menubased interface system and identify factors that influence user satisfaction. Grounded in the self-determination theory the research model proposed here focuses on the effect of chatbot use on perceived autonomy perceived competence cognitive load performance satisfaction and system satisfaction. An experimental study was conducted and data were analyzed using Partial Least Square Structural Equation Modeling. The findings indicate that chatbot systems lead to a lower level of perceived autonomy and higher cognitive load compared with menu-based interface systems resulting in a lower degree of user satisfaction. Implications of these findings for research and practice are discussed.;2022
Recently reinforcement learning (RL) has been applied to task-oriented dialogue systems by using latent actions to solve shortcomings of supervised learning (SL). In this paper we propose a multi-domain task-oriented dialogue system called Dialogue System with Optimizing a Recurrent Action Policy using Efficient Context (DORA) that uses SL with subsequently applied RL to optimize dialogue systems using a recurrent dialogue policy. This dialogue policy recurrently generates explicit system actions as a both word-level and high-level policy. As a result DORA is clearly optimized during both SL and RL steps by using an explicit system action policy that considers an efficient context instead of the entire dialogue history. The system actions are both interpretable and controllable whereas the latent actions are not. DORA improved the success rate by 6.6 points on MultiWOZ 2.0 and by 10.9 points on MultiWOZ 2.1.;2022
Sentiment analysis in conversations has gained increasing attention in recent years for the growing amount of applications it can serve e.g. sentiment analysis recommender systems and human-robot interaction. The main difference between conversational sentiment analysis and single sentence sentiment analysis is the existence of context information that may influence the sentiment of an utterance in a dialogue. How to effectively encode contextual information in dialogues however remains a challenge. Existing approaches employ complicated deep learning structures to distinguish different parties in a conversation and then model the context information. In this paper we propose a fast compact and parameter-efficient party-ignorant framework named bidirectional emotional recurrent unit for conversational sentiment analysis. In our system a generalized neural tensor block followed by a two-channel classifier is designed to perform context compositionality and sentiment classification respectively. Extensive experiments on three standard datasets demonstrate that our model outperforms the state of the art in most cases. (c) 2021 Elsevier B.V. All rights reserved.;2022
The aims of nursing training include not only mastering skills but also fostering the competence to make decisions for problem solving. In prenatal education cultivating nurses' knowledge and competence of vaccine administration is a crucial issue for protecting pregnant women and newborns from infection. Therefore obstetric vaccination knowledge has become a basic and essential training program for nursing students. However most of these training programs are given via the lecture-based teaching approach with skills practice providing students with few opportunities to think deeply about the relevant issues owing to the lack of interaction and context. This could have a negative impact on their learning effectiveness and clinical judgment. To address this problem a mobile chatbot-based learning approach is proposed in this study to enable students to learn and think deeply in the contexts of handling obstetric vaccine cases via interacting with the chatbot. In order to verify the effectiveness of the proposed approach an experiment was implemented. Two classes of 36 students from a university in northern Taiwan were recruited as participants. One class was the experimental group learning with the proposed approach while the other class was the control group learning with the conventional approach (ie giving lectures to explain the instructional content and training cases). The results indicate that applying a mobile chatbot for learning can enhance nursing students' learning achievement and self-efficacy. In addition based on the analysis of the interview results students generally believed that learning through the mobile chatbot was able to promote their self-efficacy as well as their learning engagement and performance. Practitioner notes What is already known about this topic Issues relevant to AI technology in education have been extensively discussed and explored around the world. Among the various AI systems the potential of chatbots has been highlighted by researchers owing to the user-friendly interface developed using the natural language processing (NLP) technology. Few studies using AI chatbots in professional training have been conducted. What this paper adds In this study a mobile chatbot was used in a nursing training program to enhance students' learning achievement and self-efficacy for handling vaccine cases. The mobile chatbot significantly improved the students' learning achievement and self-efficacy in comparison with the conventional learning approach in the vaccine training program. From the interview results it was found that the students generally believed that the mobile chatbot was able to promote their self-efficacy as well as learning engagement and performances in the vaccine training program. Implications for practice and/or policy Mobile chatbots have great potential for professional training owing to their convenient and user-friendly features. It would be worth applying mobile chatbots as well as other NLP-based applications to other professional training programs in the future.;2022
The English as a foreign language (EFL) learners' levels of attention and meditation as well as brainwaves while interacting with an interlocutor in three different second-language (L2) socialization contexts-with another human in person with another person through a virtual platform and with an artificial intelligence (AI) chatbot-were explored in this study. Thirty participants participated in an experiment throughout which they were asked to wear a NeuroSky Mindwave headset to assess their real-time levels of attention and meditation as well as their brainwave activities in each of the three contexts. Statistical analyses of the results revealed a significant effect of the EFL socialization context on participants' level of attention and meditation. The EFL learners' level of attention was highest when they were socializing with other humans in person. When their interlocutor was a chatbot their level of meditation was highest. When they were interacting with another person in a virtual environment both their attention and meditation were lowest. A one-way multivariate analysis of variance (MANOVA) revealed a significant main effect of the dominant ratios of participants' brainwave activities based on their interactions with interlocutors in all three contexts. The AI chatbot was associated with the greatest dominant ratio of delta and theta brainwaves for EFL learners. Face-to-face L2 socialization with interlocutors triggered alpha and beta brainwaves whereas interaction with human interlocutors in the virtual environment made gamma brainwaves dominant. The present study is the first to have empirically examined EFL learners' levels of attention and meditation as well as brainwaves during L2 socialization in three different contexts.;2022
The global pandemic complicated both learning chemistry and importantly preparation for examinations. One of the problems which students face is the lack of teachers' attention whereas the implementation of such distance learning technology as a chatbot represents one possible solution. The Chemist Bot was created specifically to help Russian students prepare for the final chemistry examination. It provides various activities including the access to theory the opportunity to complete the real exam tasks and educational games. Over a period of three months 465 students took part in the Chemist Bot activities and 52 of them shared their real examination results. It was revealed that both the completion of exam tasks and participation in extracurricular activities are helpful for training and preparation. In the present experiment it has been shown that 13 of the 15 students who wrote the full United State Exam (USE) sample in the bot and scored at least 53 out of 66 points in the Chemist Bot then scored over 80 points on the real USE (which is 80% of the maximum USE score and is considered excellent by FIPM - Federal Institute of Pedagogical Measurements Russian Federation). Currently the Chemist Bot is involved in preparation of new participants: those students who are going to pass the exam in the summer of 2022.;2022
The global spread of COVID-19 has caused a huge number of confirmed cases and deaths which in return leads to a plethora of mental disorders across the world. In order to address citizens' psychological problems government agencies in many countries have employed AI-based chatbots to provide mental health services. However there is a limited understanding of the determinants affecting citizens' user experience and user satisfaction when mental health services supported by chatbots are provided. Thus based on the Theory of Consumption Values (TCV) this study proposes an analytical framework to investigate the factors that are important to citizens' user experience and user satisfaction when they interact with mental health chatbots. Analysis of data collected from 295 chatbot users in Wuhan and Chongqing reveals that personalization enjoyment learning and condition are positively related to user experience and user satisfaction. However voice interaction fails to devote to citizens' user experience and user satisfaction. Thus government agencies and their AI service contractors should enhance the functions and systems of mental health chatbots to ensure citizens' user experience and user satisfaction. Also they should more positively promote the use of mental health chatbots during the public health emergency.;2022
The objective of this study was to assess the feasibility of using a user-centered chatbotfor collecting linked data to study overweight and obesity causes ina target population. In total 980 people participated in the feasibility study organized in three studies: (1) within a group of university students (88 participants) (2) in a small town (422 participants) and (3) within a university community (470 participants). We gathered self-reported data through the Wakamola chatbot regarding participants diet physical activity social network living area obesity-associated diseases and sociodemographic data. For each study we calculated the mean Body Mass Index (BMI) and number of people in each BMI level. Also we defined and calculated scores (1-100 scale) regarding global health BMI alimentation physical activity and social network. Moreover we graphically represented obesity risk for living areas and the social network with nodes colored by BMI. Students group results: Mean BMI 21.37 (SD 2.57) (normal weight) 8 people underweight 5 overweight 0 obesity global health status 78.21 alimentation 63.64 physical activity 65.08 and social 26.54 3 areas with mean BMI level of obesity 17 with overweight level. Small town ' s study results: Mean BMI 25.66 (SD 4.29) (overweight) 2 people underweight 63 overweight 26 obesity global health status 69.42 alimentation 64.60 physical activity 60.61 and social 1.14 1 area with mean BMI in normal weight University ' s study results: Mean BMI 23.63 (SD 3.7) (normal weight) 22 people underweight 86 overweight 28 obesity global health status 81.03 alimentation 81.84 physical activity 70.01 and social 1.47 3 areas in obesity level 19 in overweight level. Wakamola is a health care chatbot useful to collect relevant data from populations in the risk of overweight and obesity. Besides the chatbot provides individual self-assessment of BMI and general status regarding the style of living. Moreover Wakamola connects users in a social network to help the study of O & O ' s causes from an individual social and socio-economic perspective.;2022
The perception and expression of emotion as well as the content of a text are key factors in the success of conversational agents. However previous models for conversation generation handled single-language pairs during training and testing neglecting the complementary information from different languages. In this article we propose a bilingual-aided interactive approach that can simultaneously and interactively generate bilingual emotional replies to monolingual posts. Specifically the generation of one emotional reply relies on the output of the encoder the generated tokens and the interactive information from the other language decoder. The interactive approach includes 1) internal interaction to capture the change in implicit contextual information and 2) external interaction to balance grammaticality and the expression of emotion. Qualitative and quantitative experiments with NLPCC2017 show that our model performs better in terms of the content and emotion of replies than several state-of-the-art approaches.;2022
The use of chatbots as an online survey tool is becoming increasingly popular owing to their convenience particularly when face-to-face interactions are difficult. However with longer surveys interaction experience and data quality can decrease due to several factors such as increased fatigue. In this study we compared how applying humanization techniques to survey chatbots can affect survey-taking experience in three aspects: respondents' perceptions of chatbots interaction experience and data quality. To address our research goal two different versions of survey chatbots were compared: a humanization applied survey chatbot (HASbot) and a baseline chatbot (baselinebot). The HASbot simultaneously incorporates four humanization techniques: use of self-introduction addressing by name using adaptive response speed and echoing respondents' answers. Our experimental study with 59 middle school-aged adolescents showed that compared to the baselinebot respondents' perceptions of the HASbot were more positive with higher levels of anthropomorphism and social presence. In terms of interaction experience the respondents spent more time interacting with the HASbot and showed a higher level of satisfaction. For data quality the HASbot outperformed the baselinebot in terms of self disclosure however the HASbot also elicited a higher social desirability bias. No difference was observed in the response differentiation between the two chatbots.;2022
There is evidence that linguistic alignment can give rise to prosocial effects in human-human interaction (HHI) but little has been done to explore whether the same effects can be evoked in human-computer interaction (HCI). This study investigates whether being lexically aligned improves people's evaluation of their conversational partner and the interaction in HHI and HCI and whether such effects differ in HHI and HCI. A text-based interaction task was adopted in which a naive participant and his/her partner took turns to name and match pictures. In both HHI and HCI participants interacted with a computer program but they were led to believe that the partner they were interacting with was a human interlocutor in HHI conditions but a smart dialogue system (i.e. a computer partner) in HCI conditions. Lexical alignment was varied in the experiment such that in the align condition the program repeated the word use of participants whereas in the nonalign condition it chose words different from those used by participants. After the interaction task a questionnaire survey was carried out to measure participants' evaluation of their partner and the interaction. Results showed that lexical alignment significantly improved participants' evaluation of the interaction in terms of perceived cognitive demand and response accuracy in both HHI and HCI. In addition lexical alignment significantly enhanced people's liking of the aligning partner and reduced their perceived annoyance in HHI but the effect was negligible in HCI.;2022
This paper presents the Storybox Methodology which combines a novel framework for structuring knowledge and conversations around a story (D-PAF) with a live chatroom-based training approach that builds the conversation knowledge base via live chatroom interactions. Chatbots have achieved success as intelligent interfaces in education health sales and support but their move towards mainstream adoption has been hindered by the large amount of development resources required in terms of data collection preparation user testing and technical knowledge. The complexity of the development task often necessitates both a system author and a domain expert working effectively together adding further complexity and risk. Overcoming these barriers could increase feasibility of chatbots in a range of expert contexts. In education there are groups of learners who do not enjoy reading and writing. Storytelling chatbots might be able to introduce these groups to enjoyable new ways to read and write having a beneficial impact on their education and future prospects. This paper proposes the Storybox Methodology for the rapid development of storytelling chatbots. Storybox is evaluated by creating training and testing 'The Ghost' a chatbot enacting Hamlet's Ghost character from William Shakespeare's dramatic tragedy. The results showed that after a period of live chatbot training of only 25 training conversations The Ghost was able to conduct convincing conversations with participants.;2022
This paper proposes a general approach for using conversational interfaces such as chatbots to offer adaptive learning of business processes in an environment involving different actors. Adaptivity concerns both the content being proposed the sequence of learning items and the way the conversation is conducted. The original approach allows the development of sustainable chatbots and empowers various non-technical actors (authors teachers publishers and learners) to control the chatbot features directly. The aCHAT-WF framework (adaptive CHATbot for WorkFlows) proposed in this paper for managing conversational interfaces conceptually represents all the aspects related to a conversation about business processes with different facets for the user the conversation flow and the conversation contents combining them to obtain a flexible interaction with the user. The paper focuses on the different preparation phases for instructional material based on Business Process Modeling Notation (BPMN) models separating the different roles involved in the construction of a chatbot for teaching business processes and with the possibility of defining different styles for the interaction with the users. The proposed method is configuration-driven to facilitate the separation of the different aspects of the control of the interaction and the delivery of contents.;2022
This paper proposes methods for unsupervised lexical acquisition for relative spatial concepts using spoken user utterances. A robot with a flexible spoken dialog system must be able to acquire linguistic representation and its meaning specific to an environment through interactions with humans as children do. Specifically relative spatial concepts (e.g. front and right) are widely used in our daily lives however it is not obvious which object is a reference object when a robot learns relative spatial concepts. Therefore we propose methods by which a robot without prior knowledge of words can learn relative spatial concepts. The methods are formulated using a probabilistic model to estimate the proper reference objects and distributions representing concepts simultaneously. The experimental results show that relative spatial concepts and a phoneme sequence representing each concept can be learned under the condition that the robot does not know which located object is the reference object. Additionally we show that two processes in the proposed method improve the estimation accuracy of the concepts: generating candidate word sequences by class n-gram and selecting word sequences using location information. Furthermore we show that clues to reference objects improve accuracy even though the number of candidate reference objects increases.;2022
This survey aims to investigate analyze and compare the state-of-the-art chatbots' feasibility and defects for psychotherapy. The survey points out a series of tasks necessary for future psychotherapy chatbots. We searched about 1200 related literature in public databases and selected five typical and state-of-the-art psychotherapy chatbots. Most of the state-of-the-art psychotherapy chatbots use retrieval-based methods to generate dialogs. Some psychotherapy chatbots incorporate psychological theories such as cognitive behavior therapy to solve unique psychological problems. The assessments show that chatbots can preliminarily recognize specific kinds of negative emotions and give relatively appropriate responses. The randomized controlled trials prove that psychotherapy chatbots are useful for some people with a mental health condition. Compared with real psychologists psychotherapy chatbots have some advantages such as accessibility without the limitation on time or location. However some critical technical obstacles limit the usage of psychotherapy chatbots. The limitations require a series of necessary tasks for more effective and safer psychotherapy chatbots such as collecting standard valid real and rich corpora. In conclusion current psychotherapy chatbots can hardly replace human psychologists in the short term but they can improve human psychologists' effectiveness and efficiency as an auxiliary tool.;2022
Users interact with chatbots for various purposes and motivations - and for different periods of time. However since chatbots are considered social actors and given that time is an essential component of social interactions the question arises as to how chatbots need to be designed depending on whether they aim to help individuals achieve short- medium-or long-term goals. Following a taxonomy development approach we compile 22 empirically and conceptually grounded design dimensions contingent on chatbots' temporal profiles. Based upon the classification and analysis of 120 chatbots therein we abstract three time-dependent chatbot design ar-chetypes: Ad-hoc Supporters Temporary Assistants and Persistent Companions. While the taxonomy serves as a blueprint for chatbot researchers and designers developing and evaluating chatbots in general our archetypes also offer practitioners and academics alike a shared understanding and naming convention to study and design chatbots with different temporal profiles.;2022
With overwhelming volumes of official emails being exchanged in enterprises every day emails have become vital information storehouses. Automatic generation of FAQs from email systems helps in identifying important information and could serve potential applications such as chatbots and intelligent email answering. While there exist studies in the literature focusing on automatic FAQ generation and automated email answering there are few studies that apply recently developed deep learning techniques to fetch FAQs from emails. This paper proposes a novel framework named F-Gen which is an expert system that generates potential FAQs from emails utilizing state-of-the-art methodologies. The key characteristics of this study are as follows: 1. Designing F-Gen with various subsystems that interoperate together for the FAQ generation 2. Identifying the parameters that determine a valid FAQ. The three subsystems of F-Gen are: (a) query classifier subsystem (QC subsystem) for email texts (b) FAQ group generator subsystem (FGG subsystem) for generating FAQ groups from email queries. And (c) FAQ generator subsystem (FG subsystem) for conversion of email query clusters into FAQs. Experiments on the email dataset that practically reflect the above-mentioned problem resulted in FAQs with a ROUGE-1 F-Score of 74.10% when compared with the ground truth.;2022
With rapid development of voice control technology making speech recognition more precisely in various IoT domains have been an intractable problem to be solved. Since there are various conversation scenes understanding the context of a dialog scene is a key issue of voice control systems. However the reality is available training data for dialog system are always insufficient. In this paper we mainly solve the problem of data lacking in dialog systems by data augmentation technique. A Generative Adversarial Network(GAN)-based model is proposed and the data are augmented effectively. It can generate from text to text enhance the original data with text retelling and improve the robustness of parameter estimation of unknown data by using the sample data generated by GAN model. A new N-gram language model is used to evaluate multiple recognition candidates of speech recognition and the candidate sentences with the highest evaluation scores are selected as the final result of speech recognition. Our data enhancement algorithm based on the Generative Model is verified by the experiments. In the result of model comparison test the error rates of data set THCHS30 and AISHELL are 3.3% and 5.1% which are lower than that of the baseline system.;2022
With the rapid development of artificial intelligence (AI) countries are increasingly adopting AI-guided chatbots to improve service on government portals. The reduction in face-to-face services under COVID-19 pandemic will further accelerate this trend. However the adoption and performance of the existing chatbots differ. Based on the literature on e-government adoption and innovative policy innovation diffusion this article examines both the initial and postadoption stages of chatbot usage in China's local governments. While the first phase employs the survival model of event history analysis to explore the factors that influence the decision to adopt chatbots in local government the second phase analyzes the determinants of those chatbots' performance in the postadoption stage. We find that pressure factors and readiness factors play different roles in the different adoption stages. Although pressure can encourage local governments to implement chatbots these governments' readiness determined how well the chatbots perform after their initial adoption. The implications and limitations of the research are also discussed.;2022
